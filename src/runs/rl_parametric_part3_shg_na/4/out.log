Using TensorFlow backend.
[2019-03-26 14:17:20,377] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=5e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 14:17:20,378] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 14:17:20.414550: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 14:17:36,785] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 14:17:36,785] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 14:17:36,794] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 14:17:36,798] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 14:17:36,803] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 14:17:36,808] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 14:17:36,811] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 14:17:36,811] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:36,811] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 14:17:36,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:36,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 14:17:37,812] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:37,814] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 14:17:37,902] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:37,903] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 14:17:37,996] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 14:17:37,997] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:17:37,998] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:17:37,998] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:37,998] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:17:37,999] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:17:37,998] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:37,999] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:17:37,999] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:38,000] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:38,000] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:38,004] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 14:17:38,005] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 14:17:38,022] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 14:17:38,029] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 14:17:38,039] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 14:17:38,815] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:38,816] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 14:17:38,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:38,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 14:17:39,816] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:39,820] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 14:17:39,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:39,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 14:17:40,380] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 14:17:40,381] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.53333333333333, 57.66666666666667, 1.0, 2.0, 0.7999716153154702, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1118497.012246173, 1118497.012246173, 243962.0850104216]
[2019-03-26 14:17:40,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:17:40,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.2964851  0.14258157 0.16419286 0.17073953 0.22600089], sampled 0.09889977322173837
[2019-03-26 14:17:40,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1118497.012246173 W.
[2019-03-26 14:17:40,819] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:40,820] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 14:17:40,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:40,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 14:17:41,821] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:41,827] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 14:17:41,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:41,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 14:17:42,824] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:42,825] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 14:17:42,924] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:42,925] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 14:17:43,826] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:43,830] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 14:17:43,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:43,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 14:17:44,830] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:44,831] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 14:17:44,908] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:44,908] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 14:17:45,832] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:45,833] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 14:17:45,932] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:45,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 14:17:46,834] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:46,837] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 14:17:46,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:46,929] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 14:17:47,838] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:47,840] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 14:17:47,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:47,912] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 14:17:48,841] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:48,844] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 14:17:48,904] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:48,905] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 14:17:49,845] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:49,850] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 14:17:49,905] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:49,906] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 14:17:50,849] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:50,850] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 14:17:50,941] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:50,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 14:17:51,850] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 14:17:51,854] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 14:17:51,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:17:51,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 14:17:55,071] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 14:17:55,071] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.4, 77.0, 1.0, 2.0, 0.2166086070983905, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3940355874883323, 6.911199999999999, 6.9112, 168.912956510431, 694366.9548050828, 694366.9548050833, 206876.6795414944]
[2019-03-26 14:17:55,072] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:17:55,073] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.34197646 0.22738151 0.17463249 0.10436454 0.15164495], sampled 0.7804416836073611
[2019-03-26 14:18:04,645] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 14:18:04,647] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.4, 84.0, 1.0, 2.0, 0.6927305296817368, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1086988.962656374, 1086988.962656374, 233728.1980048604]
[2019-03-26 14:18:04,649] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:18:04,652] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.29278693 0.14340763 0.1687785  0.14839542 0.24663155], sampled 0.5490856248184744
[2019-03-26 14:18:55,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 14:18:55,151] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.75452633833333, 88.78790693833332, 1.0, 2.0, 0.3488280329319914, 1.0, 1.0, 0.3488280329319914, 1.0, 2.0, 0.6057989340095867, 6.9112, 6.9112, 171.5212843490159, 1462809.585924016, 1462809.585924016, 326573.1281232405]
[2019-03-26 14:18:55,152] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:18:55,154] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.40997106 0.15160595 0.12500416 0.12607297 0.1873459 ], sampled 0.10934738166810765
[2019-03-26 14:18:55,155] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1462809.585924016 W.
[2019-03-26 14:19:33,868] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3498.8438 3487127684.1481 1454.0000
[2019-03-26 14:19:33,893] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3635.0853 3338337311.8596 1383.0000
[2019-03-26 14:19:34,039] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3777.2219 3277458878.7194 1153.0000
[2019-03-26 14:19:34,266] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3735.3460 3182718602.9227 960.0000
[2019-03-26 14:19:34,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3806.1966 3155243347.5954 776.0000
[2019-03-26 14:19:35,333] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3498.8438415472474, 3487127684.1481295, 1454.0, 3777.221908063061, 3277458878.719409, 1153.0, 3806.196602288938, 3155243347.595425, 776.0, 3635.085290688775, 3338337311.859558, 1383.0, 3735.3460215680634, 3182718602.922653, 960.0]
[2019-03-26 14:19:38,870] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.43318874 0.16031337 0.1735448  0.05724352 0.17570965], sum to 1.0000
[2019-03-26 14:19:38,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3902
[2019-03-26 14:19:38,975] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 84.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5945036808653044, 6.911199999999999, 6.9112, 168.912956510431, 520693.205055482, 520693.2050554826, 165178.5884425033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 28800.0000, 
sim time next is 29400.0000, 
raw observation next is [22.51666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6429554133428937, 6.911200000000001, 6.9112, 168.912956510431, 562941.8508880544, 562941.8508880538, 172791.095033338], 
processed observation next is [1.0, 0.34782608695652173, 0.2661927330173777, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5645797723693826, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15637273635779286, 0.15637273635779272, 0.25789715676617614], 
reward next is 0.7421, 
noisyNet noise sample is [array([0.97535145], dtype=float32), -0.10532586]. 
=============================================
[2019-03-26 14:19:40,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.41793716 0.16595644 0.14465381 0.09114194 0.18031064], sum to 1.0000
[2019-03-26 14:19:40,748] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7977
[2019-03-26 14:19:40,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.16666666666667, 67.5, 1.0, 2.0, 0.4882454282280354, 1.0, 1.0, 0.4882454282280354, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1427170.817943591, 1427170.817943591, 303935.6635246651], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 57000.0000, 
sim time next is 57600.0000, 
raw observation next is [27.1, 68.0, 1.0, 2.0, 0.4964046707014874, 1.0, 2.0, 0.4964046707014874, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1436112.954623439, 1436112.954623439, 304849.5431503321], 
processed observation next is [1.0, 0.6956521739130435, 0.4834123222748816, 0.68, 1.0, 1.0, 0.3932586393993824, 1.0, 1.0, 0.3932586393993824, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3989202651731775, 0.3989202651731775, 0.454999318134824], 
reward next is 0.5450, 
noisyNet noise sample is [array([1.3179929], dtype=float32), -0.6605733]. 
=============================================
[2019-03-26 14:19:43,400] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [0.24535573 0.33474007 0.27240986 0.07714804 0.07034623], sum to 1.0000
[2019-03-26 14:19:43,414] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4098
[2019-03-26 14:19:43,515] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 1.0, 0.1952810940573481, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3462761356864077, 6.9112, 6.9112, 168.912956510431, 599667.7422333704, 599667.7422333704, 199603.803120146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99000.0000, 
sim time next is 99600.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3842614662740169, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591120.1740616008, 591120.1740616008, 174190.4810696677], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.2581463449084541, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16420004835044466, 0.16420004835044466, 0.25998579264129507], 
reward next is 0.7400, 
noisyNet noise sample is [array([0.478417], dtype=float32), -1.2954112]. 
=============================================
[2019-03-26 14:19:52,475] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5225565e-06 9.7950763e-01 2.0488573e-02 2.3907032e-06 4.5848317e-08], sum to 1.0000
[2019-03-26 14:19:52,481] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3296
[2019-03-26 14:19:52,589] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 90.66666666666667, 1.0, 2.0, 0.2943811953996872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471934.3171387933, 471934.3171387933, 165087.7251199895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 250800.0000, 
sim time next is 251400.0000, 
raw observation next is [20.73333333333333, 90.83333333333334, 1.0, 2.0, 0.293988935910098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471426.8767904231, 471426.8767904231, 165053.0886931898], 
processed observation next is [0.0, 0.9130434782608695, 0.18167456556082143, 0.9083333333333334, 1.0, 1.0, 0.1493842601326482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13095191021956198, 0.13095191021956198, 0.2463478935719251], 
reward next is 0.7537, 
noisyNet noise sample is [array([0.89431226], dtype=float32), 0.78927875]. 
=============================================
[2019-03-26 14:19:54,974] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7881: loss 2.5653
[2019-03-26 14:19:55,029] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7881: learning rate 0.0000
[2019-03-26 14:19:55,036] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7888: loss 2.6291
[2019-03-26 14:19:55,037] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7888: learning rate 0.0000
[2019-03-26 14:19:55,052] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7898: loss 2.4898
[2019-03-26 14:19:55,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7898: learning rate 0.0000
[2019-03-26 14:19:55,097] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 7917: loss 2.6423
[2019-03-26 14:19:55,100] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 7917: learning rate 0.0000
[2019-03-26 14:19:55,153] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7943: loss 2.4970
[2019-03-26 14:19:55,154] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7943: learning rate 0.0000
[2019-03-26 14:19:55,228] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7978: loss 2.5937
[2019-03-26 14:19:55,229] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7978: learning rate 0.0000
[2019-03-26 14:19:55,234] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7980: loss 2.4398
[2019-03-26 14:19:55,237] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7980: learning rate 0.0000
[2019-03-26 14:19:55,264] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7994: loss 2.3943
[2019-03-26 14:19:55,266] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7995: loss 2.4043
[2019-03-26 14:19:55,269] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7995: learning rate 0.0000
[2019-03-26 14:19:55,269] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7995: learning rate 0.0000
[2019-03-26 14:19:55,322] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8019: loss 2.4536
[2019-03-26 14:19:55,322] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 8019: loss 2.5017
[2019-03-26 14:19:55,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8020: learning rate 0.0000
[2019-03-26 14:19:55,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 8020: learning rate 0.0000
[2019-03-26 14:19:55,330] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8021: loss 2.3722
[2019-03-26 14:19:55,333] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8021: learning rate 0.0000
[2019-03-26 14:19:55,356] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8035: loss 2.4226
[2019-03-26 14:19:55,358] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8035: learning rate 0.0000
[2019-03-26 14:19:55,376] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8042: loss 2.3087
[2019-03-26 14:19:55,381] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8042: learning rate 0.0000
[2019-03-26 14:19:55,399] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 8054: loss 2.3438
[2019-03-26 14:19:55,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 8054: learning rate 0.0000
[2019-03-26 14:19:55,591] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8139: loss 2.2304
[2019-03-26 14:19:55,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8141: learning rate 0.0000
[2019-03-26 14:19:56,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0304967e-10 9.9793684e-01 2.0631952e-03 2.1486674e-10 7.0457394e-12], sum to 1.0000
[2019-03-26 14:19:56,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2892
[2019-03-26 14:19:56,344] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 77.16666666666667, 1.0, 2.0, 0.3136728975625669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494428.568492173, 494428.5684921724, 166575.4995984131], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 313800.0000, 
sim time next is 314400.0000, 
raw observation next is [23.26666666666667, 77.33333333333334, 1.0, 2.0, 0.3122301602290706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492632.268274088, 492632.268274088, 166453.4960338545], 
processed observation next is [0.0, 0.6521739130434783, 0.3017377567140602, 0.7733333333333334, 1.0, 1.0, 0.1713616388302055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1368422967428022, 0.1368422967428022, 0.24843805378187236], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.8584209], dtype=float32), -1.1646429]. 
=============================================
[2019-03-26 14:19:56,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4186294e-11 9.9915838e-01 8.4159995e-04 2.1024610e-10 2.9789832e-12], sum to 1.0000
[2019-03-26 14:19:57,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4071
[2019-03-26 14:19:57,106] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 86.0, 1.0, 2.0, 0.284091025076415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456391.554335087, 456391.554335087, 164024.0112794014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 332400.0000, 
sim time next is 333000.0000, 
raw observation next is [21.2, 86.0, 1.0, 2.0, 0.2830604192682807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 455026.1301090805, 455026.1301090805, 163933.381175378], 
processed observation next is [0.0, 0.8695652173913043, 0.20379146919431282, 0.86, 1.0, 1.0, 0.13621737261238637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12639614725252238, 0.12639614725252238, 0.2446766883214597], 
reward next is 0.7553, 
noisyNet noise sample is [array([1.6018995], dtype=float32), -0.78465927]. 
=============================================
[2019-03-26 14:19:57,125] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[45.021824]
 [44.996212]
 [44.96112 ]
 [44.938244]
 [44.91495 ]], R is [[45.34900284]
 [45.65069962]
 [45.94924927]
 [46.24468231]
 [46.53704453]].
[2019-03-26 14:20:01,378] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.1025149e-17 9.9999666e-01 3.3198955e-06 3.2323750e-17 4.5145067e-19], sum to 1.0000
[2019-03-26 14:20:01,387] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1168
[2019-03-26 14:20:01,393] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 78.5, 1.0, 2.0, 0.5127419440580625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821956.079211097, 821956.079211097, 197287.736454933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 402600.0000, 
sim time next is 403200.0000, 
raw observation next is [22.3, 79.0, 1.0, 2.0, 0.5194579589806202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832403.5516147703, 832403.5516147703, 198503.980414632], 
processed observation next is [1.0, 0.6956521739130435, 0.25592417061611383, 0.79, 1.0, 1.0, 0.4210336855188195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23122320878188066, 0.23122320878188066, 0.2962745976337791], 
reward next is 0.7037, 
noisyNet noise sample is [array([0.75893694], dtype=float32), 1.4239845]. 
=============================================
[2019-03-26 14:20:12,544] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 15848: loss 0.0256
[2019-03-26 14:20:12,548] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 15849: learning rate 0.0000
[2019-03-26 14:20:12,636] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 15890: loss 0.0419
[2019-03-26 14:20:12,639] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 15890: learning rate 0.0000
[2019-03-26 14:20:12,644] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15892: loss 0.0443
[2019-03-26 14:20:12,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15893: learning rate 0.0000
[2019-03-26 14:20:12,695] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15916: loss 0.0271
[2019-03-26 14:20:12,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15916: learning rate 0.0000
[2019-03-26 14:20:12,711] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15921: loss 0.0409
[2019-03-26 14:20:12,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15921: learning rate 0.0000
[2019-03-26 14:20:12,721] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15924: loss 0.0734
[2019-03-26 14:20:12,726] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15927: learning rate 0.0000
[2019-03-26 14:20:12,797] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15962: loss 0.0537
[2019-03-26 14:20:12,802] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15963: learning rate 0.0000
[2019-03-26 14:20:12,838] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15978: loss 0.0474
[2019-03-26 14:20:12,839] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15978: learning rate 0.0000
[2019-03-26 14:20:12,842] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15979: loss 0.0342
[2019-03-26 14:20:12,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15980: learning rate 0.0000
[2019-03-26 14:20:12,922] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 16016: loss 0.0435
[2019-03-26 14:20:12,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 16016: learning rate 0.0000
[2019-03-26 14:20:12,947] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 16028: loss 0.0462
[2019-03-26 14:20:12,950] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 16028: learning rate 0.0000
[2019-03-26 14:20:12,958] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16032: loss 0.0650
[2019-03-26 14:20:12,961] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16033: learning rate 0.0000
[2019-03-26 14:20:12,979] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16042: loss 0.0431
[2019-03-26 14:20:12,987] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16044: learning rate 0.0000
[2019-03-26 14:20:13,121] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16107: loss 0.0344
[2019-03-26 14:20:13,124] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16109: learning rate 0.0000
[2019-03-26 14:20:13,164] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 16123: loss 0.0435
[2019-03-26 14:20:13,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 16124: learning rate 0.0000
[2019-03-26 14:20:13,217] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 16149: loss 0.0268
[2019-03-26 14:20:13,223] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 16149: learning rate 0.0000
[2019-03-26 14:20:21,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1096760e-19 1.0000000e+00 1.8183798e-08 2.0264517e-17 1.5978641e-19], sum to 1.0000
[2019-03-26 14:20:21,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6739
[2019-03-26 14:20:21,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.01666666666667, 50.0, 1.0, 2.0, 0.6101124164259905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1006275.576645778, 1006275.576645778, 217768.6788588425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 749400.0000, 
sim time next is 750000.0000, 
raw observation next is [24.93333333333334, 50.0, 1.0, 2.0, 0.5761181493514851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950958.3910729398, 950958.3910729398, 210527.7958741349], 
processed observation next is [1.0, 0.6956521739130435, 0.3807266982622437, 0.5, 1.0, 1.0, 0.48929897512227116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2641551086313722, 0.2641551086313722, 0.3142205908569178], 
reward next is 0.6858, 
noisyNet noise sample is [array([-0.07959379], dtype=float32), -1.0521753]. 
=============================================
[2019-03-26 14:20:21,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[79.48896 ]
 [79.41743 ]
 [79.338165]
 [79.25664 ]
 [79.18971 ]], R is [[79.43266296]
 [79.31330872]
 [79.19030762]
 [79.06803894]
 [78.95201874]].
[2019-03-26 14:20:23,248] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5183734e-17 9.9999976e-01 2.6238220e-07 1.2829033e-16 2.5654773e-18], sum to 1.0000
[2019-03-26 14:20:23,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-26 14:20:23,259] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.55, 88.5, 1.0, 2.0, 0.2543699431186543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417835.6658879847, 417835.6658879847, 161344.0834414767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [19.53333333333333, 88.66666666666666, 1.0, 2.0, 0.2538946702498717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417037.6318998868, 417037.6318998868, 161296.6966982902], 
processed observation next is [1.0, 1.0, 0.12480252764612951, 0.8866666666666666, 1.0, 1.0, 0.10107791596370086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11584378663885746, 0.11584378663885746, 0.24074133835565703], 
reward next is 0.7593, 
noisyNet noise sample is [array([0.12386996], dtype=float32), 0.06759624]. 
=============================================
[2019-03-26 14:20:25,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.1416634e-16 9.9998653e-01 1.3503988e-05 1.5642877e-13 1.1098390e-16], sum to 1.0000
[2019-03-26 14:20:25,106] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6842
[2019-03-26 14:20:25,207] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 61.0, 1.0, 2.0, 0.2905335464335926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464842.1801283869, 464842.1801283869, 164585.4630859079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 817200.0000, 
sim time next is 817800.0000, 
raw observation next is [25.16666666666666, 61.16666666666667, 1.0, 2.0, 0.2901229016614191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464232.1456606248, 464232.1456606248, 164543.8388322107], 
processed observation next is [0.0, 0.4782608695652174, 0.3917851500789887, 0.6116666666666667, 1.0, 1.0, 0.1447263875438784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.128953373794618, 0.128953373794618, 0.24558781915255326], 
reward next is 0.7544, 
noisyNet noise sample is [array([-1.2321931], dtype=float32), -0.7392177]. 
=============================================
[2019-03-26 14:20:29,976] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23835: loss 0.0395
[2019-03-26 14:20:29,982] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23837: learning rate 0.0000
[2019-03-26 14:20:30,001] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23848: loss 0.0335
[2019-03-26 14:20:30,004] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23849: learning rate 0.0000
[2019-03-26 14:20:30,071] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23880: loss 0.0414
[2019-03-26 14:20:30,073] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23880: learning rate 0.0000
[2019-03-26 14:20:30,076] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23881: loss 0.0110
[2019-03-26 14:20:30,079] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23882: learning rate 0.0000
[2019-03-26 14:20:30,097] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 23891: loss 0.0477
[2019-03-26 14:20:30,099] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 23892: learning rate 0.0000
[2019-03-26 14:20:30,186] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23933: loss 0.0218
[2019-03-26 14:20:30,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23933: learning rate 0.0000
[2019-03-26 14:20:30,271] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23972: loss 0.0150
[2019-03-26 14:20:30,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23972: learning rate 0.0000
[2019-03-26 14:20:30,306] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23986: loss 0.0151
[2019-03-26 14:20:30,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23987: learning rate 0.0000
[2019-03-26 14:20:30,378] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24025: loss 0.0237
[2019-03-26 14:20:30,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24025: learning rate 0.0000
[2019-03-26 14:20:30,391] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 24032: loss 0.0132
[2019-03-26 14:20:30,392] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 24032: learning rate 0.0000
[2019-03-26 14:20:30,403] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 24036: loss 0.0069
[2019-03-26 14:20:30,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 24036: learning rate 0.0000
[2019-03-26 14:20:30,448] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24055: loss 0.0177
[2019-03-26 14:20:30,451] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24056: learning rate 0.0000
[2019-03-26 14:20:30,469] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 24063: loss 0.0060
[2019-03-26 14:20:30,472] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 24064: learning rate 0.0000
[2019-03-26 14:20:30,539] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 24097: loss 0.0233
[2019-03-26 14:20:30,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 24098: learning rate 0.0000
[2019-03-26 14:20:30,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24104: loss 0.0108
[2019-03-26 14:20:30,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24106: learning rate 0.0000
[2019-03-26 14:20:30,734] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 24188: loss 0.0231
[2019-03-26 14:20:30,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 24188: learning rate 0.0000
[2019-03-26 14:20:32,490] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 14:20:32,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3454948e-20 1.0000000e+00 3.4941522e-08 3.4676817e-19 7.4231579e-22], sum to 1.0000
[2019-03-26 14:20:32,494] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:20:32,495] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:20:32,495] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:32,495] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:32,497] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:20:32,495] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:20:32,498] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:20:32,499] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:32,499] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:32,500] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9257
[2019-03-26 14:20:32,499] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:20:32,508] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 14:20:32,528] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 14:20:32,529] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 14:20:32,530] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 14:20:32,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 14:20:32,708] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 87.0, 1.0, 2.0, 0.3364201343177969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 521150.1697820369, 521150.1697820375, 168383.5065111133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 936000.0000, 
sim time next is 936600.0000, 
raw observation next is [22.65, 87.33333333333333, 1.0, 2.0, 0.3373738956977538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522494.233093371, 522494.2330933705, 168486.0527523659], 
processed observation next is [0.0, 0.8695652173913043, 0.2725118483412322, 0.8733333333333333, 1.0, 1.0, 0.2016552960213901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14513728697038084, 0.1451372869703807, 0.25147172052591926], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.8095311], dtype=float32), 1.9208728]. 
=============================================
[2019-03-26 14:20:45,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:20:45,526] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.12598995166667, 84.46286554666668, 1.0, 2.0, 0.233979389088254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 388155.1857849892, 388155.1857849885, 159164.0548760894]
[2019-03-26 14:20:45,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:20:45,530] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1514878e-19 1.0000000e+00 5.9339772e-08 6.0311765e-18 2.1574560e-20], sampled 0.9904086545422465
[2019-03-26 14:20:53,744] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:20:53,745] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.2, 51.0, 1.0, 2.0, 0.2744804342319558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 445576.2249908865, 445576.2249908865, 163285.2276423454]
[2019-03-26 14:20:53,746] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:20:53,749] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1876000e-18 9.9999988e-01 1.2460451e-07 1.7812089e-17 1.4224876e-19], sampled 0.7505836310401856
[2019-03-26 14:21:37,215] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:21:37,216] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.86666666666667, 48.33333333333334, 1.0, 2.0, 0.7648003255824801, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979329909211, 6.9112, 168.9123160187005, 1965811.262796897, 1898571.799069103, 399331.6119770745]
[2019-03-26 14:21:37,218] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:21:37,221] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.6333126e-22 1.0000000e+00 6.6089898e-09 1.4403974e-20 6.1486842e-23], sampled 0.8054752760467868
[2019-03-26 14:21:37,223] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1965811.262796897 W.
[2019-03-26 14:22:01,085] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:22:01,088] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.5, 75.0, 1.0, 2.0, 1.019508911052293, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005994404615503, 6.9112, 168.9123174056572, 2322308.59937272, 2255058.440617804, 469355.4078619841]
[2019-03-26 14:22:01,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:22:01,095] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9836777e-21 1.0000000e+00 6.3108780e-09 7.6798085e-20 1.3093858e-22], sampled 0.7733100198280448
[2019-03-26 14:22:01,095] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2322308.59937272 W.
[2019-03-26 14:22:08,894] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:22:08,895] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.48922452833333, 71.64665842166666, 1.0, 2.0, 0.5628889889002514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786582.4439396384, 786582.4439396384, 194035.7574497289]
[2019-03-26 14:22:08,896] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:22:08,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8545397e-21 1.0000000e+00 1.2032061e-08 5.2103325e-20 1.8961981e-22], sampled 0.7728246168498463
[2019-03-26 14:22:09,768] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:22:09,769] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.7, 67.0, 1.0, 2.0, 1.025993549854838, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988357202091168, 6.9112, 168.9123390349152, 2331385.263497718, 2276647.488887561, 472060.6787407757]
[2019-03-26 14:22:09,770] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:22:09,776] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.6976154e-22 1.0000000e+00 7.0164585e-09 3.2433122e-20 8.6254424e-23], sampled 0.07153613832222883
[2019-03-26 14:22:09,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2331385.263497718 W.
[2019-03-26 14:22:29,151] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08170526], dtype=float32), 0.06401175]
[2019-03-26 14:22:29,153] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.41063479333333, 76.89057263333333, 1.0, 2.0, 0.532274702416008, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.9873327288, 743786.9873327281, 188806.5568437139]
[2019-03-26 14:22:29,154] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:22:29,157] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.6246877e-22 1.0000000e+00 6.8260948e-09 1.6526148e-20 6.6025417e-23], sampled 0.5854945454123904
[2019-03-26 14:22:29,394] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3940 2779173803.8581 933.0000
[2019-03-26 14:22:29,461] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:22:29,468] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 14:22:29,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927288569.2262 1338.0000
[2019-03-26 14:22:29,572] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:22:30,588] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 25000, evaluation results [25000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8252.928340699773, 2927288569.2262216, 1338.0, 8661.39403466329, 2779173803.858108, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:22:31,024] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0150210e-20 1.0000000e+00 1.4923843e-08 4.2137821e-18 6.7494872e-21], sum to 1.0000
[2019-03-26 14:22:31,032] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2375
[2019-03-26 14:22:31,133] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 92.0, 1.0, 2.0, 0.3410723180482942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527645.53783535, 527645.5378353494, 168880.0675782755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943200.0000, 
sim time next is 943800.0000, 
raw observation next is [22.05, 92.33333333333334, 1.0, 2.0, 0.3412681066332428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527977.0730229522, 527977.0730229522, 168907.5150377784], 
processed observation next is [0.0, 0.9565217391304348, 0.24407582938388633, 0.9233333333333335, 1.0, 1.0, 0.20634711642559375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14666029806193115, 0.14666029806193115, 0.25210076871310205], 
reward next is 0.7479, 
noisyNet noise sample is [array([-0.9936522], dtype=float32), -1.8358723]. 
=============================================
[2019-03-26 14:22:35,740] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0270542e-17 9.9999976e-01 2.1470142e-07 3.1492192e-17 8.0016262e-19], sum to 1.0000
[2019-03-26 14:22:35,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7451
[2019-03-26 14:22:35,754] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.88333333333333, 96.0, 1.0, 2.0, 0.3550228499169847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544961.1711800643, 544961.1711800649, 170169.5309732765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1025400.0000, 
sim time next is 1026000.0000, 
raw observation next is [21.9, 96.0, 1.0, 2.0, 0.3558575022666999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 545970.8818041197, 545970.8818041203, 170245.4826661911], 
processed observation next is [1.0, 0.9130434782608695, 0.23696682464454974, 0.96, 1.0, 1.0, 0.22392470152614444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15165857827892212, 0.1516585782789223, 0.25409773532267327], 
reward next is 0.7459, 
noisyNet noise sample is [array([1.2321007], dtype=float32), 0.034678094]. 
=============================================
[2019-03-26 14:22:35,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[79.07791]
 [79.21921]
 [79.32977]
 [79.4306 ]
 [79.49929]], R is [[78.9287262 ]
 [78.8854599 ]
 [78.84265137]
 [78.80020142]
 [78.75814819]].
[2019-03-26 14:22:36,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8044084e-17 9.9999893e-01 1.1041881e-06 6.4592801e-18 2.2530390e-18], sum to 1.0000
[2019-03-26 14:22:36,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0878
[2019-03-26 14:22:36,438] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 97.16666666666667, 1.0, 2.0, 0.3622591237435236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 553264.9287388698, 553264.9287388698, 170782.7768147032], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1030200.0000, 
sim time next is 1030800.0000, 
raw observation next is [21.93333333333333, 97.33333333333334, 1.0, 2.0, 0.3636611244506445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554782.474965627, 554782.4749656275, 170892.6030231996], 
processed observation next is [1.0, 0.9565217391304348, 0.23854660347551332, 0.9733333333333334, 1.0, 1.0, 0.23332665596463195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15410624304600748, 0.15410624304600765, 0.25506358660179046], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.3166028], dtype=float32), -0.8494545]. 
=============================================
[2019-03-26 14:22:36,981] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.2515041e-17 9.9999964e-01 3.4245247e-07 2.5176061e-16 1.1438911e-18], sum to 1.0000
[2019-03-26 14:22:36,990] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5148
[2019-03-26 14:22:36,994] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 96.0, 1.0, 2.0, 0.3844018335886054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576693.127541197, 576693.1275411964, 172509.1392122945], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1044000.0000, 
sim time next is 1044600.0000, 
raw observation next is [22.45, 96.16666666666666, 1.0, 2.0, 0.4858714802355741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731001.4755006314, 731001.475500632, 187824.1420854495], 
processed observation next is [1.0, 0.08695652173913043, 0.26303317535545023, 0.9616666666666666, 1.0, 1.0, 0.3805680484765953, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20305596541684204, 0.2030559654168422, 0.28033454042604405], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.9651222], dtype=float32), -0.34314138]. 
=============================================
[2019-03-26 14:22:44,204] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.7664304e-20 1.0000000e+00 3.4331682e-09 2.2787661e-17 1.2064014e-21], sum to 1.0000
[2019-03-26 14:22:44,210] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4991
[2019-03-26 14:22:44,321] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.7571340012460842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1158839.270742973, 1158839.270742974, 246728.8250263947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165200.0000, 
sim time next is 1165800.0000, 
raw observation next is [26.2, 66.5, 1.0, 2.0, 0.7591755966018255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161510.352173782, 1161510.352173782, 247199.7190342867], 
processed observation next is [1.0, 0.4782608695652174, 0.44075829383886256, 0.665, 1.0, 1.0, 0.7098501163877416, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3226417644927172, 0.3226417644927172, 0.36895480452878615], 
reward next is 0.6310, 
noisyNet noise sample is [array([-0.5969563], dtype=float32), 1.7689297]. 
=============================================
[2019-03-26 14:22:46,109] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31771: loss 0.2342
[2019-03-26 14:22:46,110] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31771: learning rate 0.0000
[2019-03-26 14:22:46,244] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 31830: loss 0.2297
[2019-03-26 14:22:46,247] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 31831: learning rate 0.0000
[2019-03-26 14:22:46,284] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 31846: loss 0.2776
[2019-03-26 14:22:46,291] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 31847: learning rate 0.0000
[2019-03-26 14:22:46,327] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31864: loss 0.2250
[2019-03-26 14:22:46,330] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31865: learning rate 0.0000
[2019-03-26 14:22:46,361] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31883: loss 0.1910
[2019-03-26 14:22:46,364] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31884: learning rate 0.0000
[2019-03-26 14:22:46,370] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31886: loss 0.1755
[2019-03-26 14:22:46,373] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31886: learning rate 0.0000
[2019-03-26 14:22:46,493] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31943: loss 0.1960
[2019-03-26 14:22:46,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31943: learning rate 0.0000
[2019-03-26 14:22:46,577] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31981: loss 0.1533
[2019-03-26 14:22:46,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31984: learning rate 0.0000
[2019-03-26 14:22:46,688] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32030: loss 0.1392
[2019-03-26 14:22:46,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32030: learning rate 0.0000
[2019-03-26 14:22:46,766] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32065: loss 0.1732
[2019-03-26 14:22:46,767] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32065: loss 0.1604
[2019-03-26 14:22:46,770] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32065: learning rate 0.0000
[2019-03-26 14:22:46,772] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32065: learning rate 0.0000
[2019-03-26 14:22:46,814] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 32086: loss 0.1395
[2019-03-26 14:22:46,816] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 32087: learning rate 0.0000
[2019-03-26 14:22:46,829] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 32093: loss 0.1068
[2019-03-26 14:22:46,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 32093: learning rate 0.0000
[2019-03-26 14:22:46,915] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32133: loss 0.1284
[2019-03-26 14:22:46,918] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32134: learning rate 0.0000
[2019-03-26 14:22:46,968] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32157: loss 0.1252
[2019-03-26 14:22:46,972] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32157: learning rate 0.0000
[2019-03-26 14:22:47,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 32192: loss 0.0993
[2019-03-26 14:22:47,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 32192: learning rate 0.0000
[2019-03-26 14:22:52,153] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6141357e-19 1.0000000e+00 3.0692696e-10 2.0880900e-19 4.0187558e-22], sum to 1.0000
[2019-03-26 14:22:52,163] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6512
[2019-03-26 14:22:52,279] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 93.16666666666667, 1.0, 2.0, 0.4692794729524349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660787.5824006919, 660787.5824006925, 179575.0919112472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1289400.0000, 
sim time next is 1290000.0000, 
raw observation next is [24.53333333333333, 93.33333333333334, 1.0, 2.0, 0.4686659165150509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660260.844352134, 660260.8443521347, 179527.2354870941], 
processed observation next is [1.0, 0.9565217391304348, 0.36176935229067925, 0.9333333333333335, 1.0, 1.0, 0.3598384536325915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18340579009781502, 0.1834057900978152, 0.2679510977419315], 
reward next is 0.7320, 
noisyNet noise sample is [array([-0.87991244], dtype=float32), -1.641372]. 
=============================================
[2019-03-26 14:22:52,307] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[77.39248 ]
 [77.10422 ]
 [76.96938 ]
 [76.9328  ]
 [76.224236]], R is [[77.39292145]
 [77.35097504]
 [77.3094635 ]
 [77.26844788]
 [77.2277832 ]].
[2019-03-26 14:22:56,963] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0112245e-18 1.0000000e+00 4.0573286e-10 2.2732713e-16 5.5157365e-19], sum to 1.0000
[2019-03-26 14:22:56,973] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8001
[2019-03-26 14:22:56,978] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 94.83333333333333, 1.0, 2.0, 0.3246202013418588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 511649.2636062397, 511649.2636062391, 167874.5646775391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1371000.0000, 
sim time next is 1371600.0000, 
raw observation next is [21.0, 95.0, 1.0, 2.0, 0.3227843354490936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508922.2850250268, 508922.2850250274, 167669.4591381972], 
processed observation next is [1.0, 0.9130434782608695, 0.19431279620853087, 0.95, 1.0, 1.0, 0.18407751258926935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14136730139584078, 0.14136730139584094, 0.2502529240868615], 
reward next is 0.7497, 
noisyNet noise sample is [array([2.1710916], dtype=float32), -0.43116832]. 
=============================================
[2019-03-26 14:23:03,918] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39760: loss 0.0256
[2019-03-26 14:23:03,920] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39761: learning rate 0.0000
[2019-03-26 14:23:04,040] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39817: loss 0.0163
[2019-03-26 14:23:04,044] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39817: learning rate 0.0000
[2019-03-26 14:23:04,059] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 39826: loss 0.0242
[2019-03-26 14:23:04,062] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 39827: learning rate 0.0000
[2019-03-26 14:23:04,146] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39872: loss 0.0321
[2019-03-26 14:23:04,148] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39873: learning rate 0.0000
[2019-03-26 14:23:04,166] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39882: loss 0.0263
[2019-03-26 14:23:04,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39882: learning rate 0.0000
[2019-03-26 14:23:04,245] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 39917: loss 0.0134
[2019-03-26 14:23:04,250] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 39919: learning rate 0.0000
[2019-03-26 14:23:04,292] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39940: loss 0.0121
[2019-03-26 14:23:04,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39940: learning rate 0.0000
[2019-03-26 14:23:04,401] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39987: loss 0.0229
[2019-03-26 14:23:04,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39989: learning rate 0.0000
[2019-03-26 14:23:04,463] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40015: loss 0.0076
[2019-03-26 14:23:04,470] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40016: learning rate 0.0000
[2019-03-26 14:23:04,519] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 40043: loss 0.0111
[2019-03-26 14:23:04,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 40043: learning rate 0.0000
[2019-03-26 14:23:04,558] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 40058: loss 0.0179
[2019-03-26 14:23:04,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 40058: learning rate 0.0000
[2019-03-26 14:23:04,562] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40058: loss 0.0122
[2019-03-26 14:23:04,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40059: learning rate 0.0000
[2019-03-26 14:23:04,662] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 40107: loss 0.0062
[2019-03-26 14:23:04,666] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 40107: learning rate 0.0000
[2019-03-26 14:23:04,775] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 40159: loss 0.0059
[2019-03-26 14:23:04,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 40159: learning rate 0.0000
[2019-03-26 14:23:04,803] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40168: loss 0.0181
[2019-03-26 14:23:04,805] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40169: learning rate 0.0000
[2019-03-26 14:23:04,904] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40215: loss 0.0168
[2019-03-26 14:23:04,906] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40215: learning rate 0.0000
[2019-03-26 14:23:08,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4731244e-20 1.0000000e+00 4.2271378e-10 2.7511173e-18 6.5113287e-21], sum to 1.0000
[2019-03-26 14:23:08,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4945
[2019-03-26 14:23:08,107] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.73333333333333, 91.0, 1.0, 2.0, 0.3285881520650155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 514803.0287488053, 514803.0287488059, 168048.1391282832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1558200.0000, 
sim time next is 1558800.0000, 
raw observation next is [21.7, 91.0, 1.0, 2.0, 0.3271180828983243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 512930.2020848742, 512930.2020848735, 167913.7722458612], 
processed observation next is [1.0, 0.043478260869565216, 0.2274881516587678, 0.91, 1.0, 1.0, 0.189298895058222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14248061169024284, 0.14248061169024265, 0.25061757051621075], 
reward next is 0.7494, 
noisyNet noise sample is [array([1.7189626], dtype=float32), 1.6317129]. 
=============================================
[2019-03-26 14:23:09,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3413598e-19 1.0000000e+00 2.3090418e-10 6.3730084e-19 8.7792439e-22], sum to 1.0000
[2019-03-26 14:23:09,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6044
[2019-03-26 14:23:09,988] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.46666666666667, 85.0, 1.0, 2.0, 0.6278567526424211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 958441.4162134654, 958441.4162134654, 216058.5645501286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1586400.0000, 
sim time next is 1587000.0000, 
raw observation next is [23.48333333333333, 85.0, 1.0, 2.0, 0.6512030949133567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 993527.5107505558, 993527.5107505564, 221069.339980343], 
processed observation next is [1.0, 0.34782608695652173, 0.3120063191153238, 0.85, 1.0, 1.0, 0.5797627649558514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2759798640973766, 0.2759798640973768, 0.3299542387766314], 
reward next is 0.6700, 
noisyNet noise sample is [array([-2.7394066], dtype=float32), 0.16909762]. 
=============================================
[2019-03-26 14:23:10,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[83.49523 ]
 [83.16372 ]
 [82.92691 ]
 [82.755875]
 [82.68137 ]], R is [[83.66094208]
 [83.50185394]
 [83.36523438]
 [83.25056458]
 [83.15720367]].
[2019-03-26 14:23:18,078] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.8662937e-21 1.0000000e+00 1.0257921e-11 1.1168728e-19 5.6967460e-22], sum to 1.0000
[2019-03-26 14:23:18,086] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5925
[2019-03-26 14:23:18,092] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 94.0, 1.0, 2.0, 0.4892350096337261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683625.0742379685, 683625.0742379691, 181926.5683401431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1731000.0000, 
sim time next is 1731600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.487367544571237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681014.7639859874, 681014.7639859874, 181640.4386340415], 
processed observation next is [1.0, 0.043478260869565216, 0.38388625592417064, 0.94, 1.0, 1.0, 0.38237053562799633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1891707677738854, 0.1891707677738854, 0.2711051322896142], 
reward next is 0.7289, 
noisyNet noise sample is [array([-0.866127], dtype=float32), 2.6781096]. 
=============================================
[2019-03-26 14:23:21,457] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47758: loss 0.0014
[2019-03-26 14:23:21,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47758: learning rate 0.0000
[2019-03-26 14:23:21,470] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47765: loss 0.0004
[2019-03-26 14:23:21,472] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47765: learning rate 0.0000
[2019-03-26 14:23:21,562] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 47807: loss 0.0001
[2019-03-26 14:23:21,565] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 47807: learning rate 0.0000
[2019-03-26 14:23:21,656] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47850: loss 0.0001
[2019-03-26 14:23:21,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47851: learning rate 0.0000
[2019-03-26 14:23:21,809] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47919: loss 0.0019
[2019-03-26 14:23:21,813] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47919: learning rate 0.0000
[2019-03-26 14:23:21,845] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47933: loss 0.0005
[2019-03-26 14:23:21,848] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47934: learning rate 0.0000
[2019-03-26 14:23:21,922] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 47970: loss 0.0042
[2019-03-26 14:23:21,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 47971: learning rate 0.0000
[2019-03-26 14:23:21,955] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47983: loss 0.0038
[2019-03-26 14:23:21,961] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47984: learning rate 0.0000
[2019-03-26 14:23:22,072] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48037: loss 0.0036
[2019-03-26 14:23:22,075] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48038: learning rate 0.0000
[2019-03-26 14:23:22,088] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 48041: loss 0.0035
[2019-03-26 14:23:22,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 48041: learning rate 0.0000
[2019-03-26 14:23:22,129] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 48062: loss 0.0068
[2019-03-26 14:23:22,131] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 48062: loss 0.0057
[2019-03-26 14:23:22,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 48062: learning rate 0.0000
[2019-03-26 14:23:22,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 48062: learning rate 0.0000
[2019-03-26 14:23:22,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48093: loss 0.0027
[2019-03-26 14:23:22,208] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48093: learning rate 0.0000
[2019-03-26 14:23:22,260] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 48122: loss 0.0072
[2019-03-26 14:23:22,264] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 48123: learning rate 0.0000
[2019-03-26 14:23:22,409] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48190: loss 0.0006
[2019-03-26 14:23:22,411] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48190: learning rate 0.0000
[2019-03-26 14:23:22,425] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48199: loss 0.0011
[2019-03-26 14:23:22,427] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48200: learning rate 0.0000
[2019-03-26 14:23:26,314] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 14:23:26,315] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:23:26,316] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:23:26,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:26,316] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:23:26,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:23:26,320] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:23:26,321] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:26,318] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:26,322] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:26,326] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:23:26,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 14:23:26,342] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 14:23:26,359] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 14:23:26,360] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 14:23:26,412] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 14:23:29,728] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:23:29,729] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.77057919, 91.66635338666666, 1.0, 2.0, 0.2841490920316521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462603.387094269, 462603.3870942696, 164388.9093498374]
[2019-03-26 14:23:29,730] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:23:29,733] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.4627770e-19 1.0000000e+00 2.5993945e-11 7.4823640e-18 3.7646621e-20], sampled 0.6584028678394579
[2019-03-26 14:23:36,132] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:23:36,133] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.63333333333333, 44.16666666666667, 1.0, 2.0, 0.4547740380730161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727499.7478716387, 727499.7478716393, 187122.224760218]
[2019-03-26 14:23:36,135] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:23:36,140] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2654189e-19 1.0000000e+00 2.0850779e-11 4.2528945e-18 3.0482746e-20], sampled 0.6020807948249383
[2019-03-26 14:23:46,096] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:23:46,098] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.1, 90.33333333333334, 1.0, 2.0, 0.7073749373864812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1126891.352322282, 1126891.352322282, 238815.6066203841]
[2019-03-26 14:23:46,099] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:23:46,101] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.7645292e-20 1.0000000e+00 6.8992013e-12 1.0228462e-18 4.6067381e-21], sampled 0.8131055239441004
[2019-03-26 14:24:27,787] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:24:27,787] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.45668416, 86.05579169, 1.0, 2.0, 0.5469726144593231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764332.8612236194, 764332.86122362, 191282.2219589604]
[2019-03-26 14:24:27,789] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:24:27,794] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5012549e-19 1.0000000e+00 8.2158672e-12 7.7968245e-19 7.3256884e-21], sampled 0.9790071083494409
[2019-03-26 14:24:56,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:24:56,749] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.13009343666667, 80.41679843833333, 1.0, 2.0, 0.5120761477814636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728040.6398114088, 728040.6398114081, 187106.3715868691]
[2019-03-26 14:24:56,751] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:24:56,753] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7621641e-20 1.0000000e+00 3.2204187e-12 2.2297837e-19 1.4818966e-21], sampled 0.49786415275550633
[2019-03-26 14:24:59,985] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:24:59,986] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.9, 69.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.263562892781607, 6.9112, 168.9055425718466, 2413761.110724551, 1454390.440455452, 310968.5482550927]
[2019-03-26 14:24:59,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:24:59,989] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4379009e-18 1.0000000e+00 2.8635091e-11 4.0503630e-17 7.9815950e-20], sampled 0.07982843407636087
[2019-03-26 14:24:59,991] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2413761.110724551 W.
[2019-03-26 14:25:01,950] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:25:01,953] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.87233782, 52.65940708, 1.0, 2.0, 0.8690057253282572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1214595.341139315, 1214595.341139315, 261550.4661101406]
[2019-03-26 14:25:01,956] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:25:01,958] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.8340970e-20 1.0000000e+00 8.4351840e-12 1.0389101e-18 6.5033356e-21], sampled 0.7588366008485602
[2019-03-26 14:25:21,785] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:25:22,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07028573], dtype=float32), 0.054536834]
[2019-03-26 14:25:22,133] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.95, 62.66666666666666, 1.0, 2.0, 0.4164837763575825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652068.1405718764, 652068.1405718764, 179889.4618195297]
[2019-03-26 14:25:22,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:25:22,136] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.6707353e-19 1.0000000e+00 2.7563375e-11 7.1463980e-18 4.8506576e-20], sampled 0.5558211513617966
[2019-03-26 14:25:22,463] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 14:25:22,567] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2146 3007648997.1407 1766.0000
[2019-03-26 14:25:22,931] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6989 2842542529.7934 1131.0000
[2019-03-26 14:25:22,941] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 14:25:23,958] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 50000, evaluation results [50000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.214591785093, 3007648997.140727, 1766.0, 8496.698924355454, 2842542529.793428, 1131.0]
[2019-03-26 14:25:25,408] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.3371550e-21 1.0000000e+00 2.6366439e-12 5.9658447e-19 1.3822441e-21], sum to 1.0000
[2019-03-26 14:25:25,417] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0365
[2019-03-26 14:25:25,517] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 96.0, 1.0, 2.0, 0.4667344213826579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657379.6927654248, 657379.6927654248, 179220.1032692424], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1908000.0000, 
sim time next is 1908600.0000, 
raw observation next is [24.15, 95.83333333333333, 1.0, 2.0, 0.7425589817473437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1048103.116334434, 1048103.116334434, 231712.7912930236], 
processed observation next is [1.0, 0.08695652173913043, 0.34360189573459715, 0.9583333333333333, 1.0, 1.0, 0.6898300984907755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2911397545373428, 0.2911397545373428, 0.3458399870045128], 
reward next is 0.6542, 
noisyNet noise sample is [array([0.01372485], dtype=float32), 1.069271]. 
=============================================
[2019-03-26 14:25:30,417] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.3191662e-20 1.0000000e+00 8.5213059e-13 4.2913362e-19 1.3141252e-21], sum to 1.0000
[2019-03-26 14:25:30,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8404
[2019-03-26 14:25:30,433] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333333, 97.66666666666667, 1.0, 2.0, 0.4488983664727622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642619.5072123181, 642619.5072123181, 177953.8439553231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984800.0000, 
sim time next is 1985400.0000, 
raw observation next is [23.7, 97.5, 1.0, 2.0, 0.4504408295010301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643562.3911438324, 643562.3911438324, 178017.7064078728], 
processed observation next is [1.0, 1.0, 0.3222748815165877, 0.975, 1.0, 1.0, 0.33788051747112063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17876733087328678, 0.17876733087328678, 0.26569806926548184], 
reward next is 0.7343, 
noisyNet noise sample is [array([0.35011718], dtype=float32), 1.0500083]. 
=============================================
[2019-03-26 14:25:35,225] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4203678e-21 1.0000000e+00 7.1052203e-13 6.0309868e-20 5.1264161e-23], sum to 1.0000
[2019-03-26 14:25:35,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8749
[2019-03-26 14:25:35,240] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 94.00000000000001, 1.0, 2.0, 0.4709198399032556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659292.5582719826, 659292.5582719819, 179329.0786444363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2070600.0000, 
sim time next is 2071200.0000, 
raw observation next is [24.56666666666667, 94.0, 1.0, 2.0, 0.4698459700214774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 658284.6062091653, 658284.6062091653, 179234.0391854889], 
processed observation next is [0.0, 1.0, 0.3633491311216432, 0.94, 1.0, 1.0, 0.3612602048451535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18285683505810146, 0.18285683505810146, 0.2675134913216252], 
reward next is 0.7325, 
noisyNet noise sample is [array([-1.73533], dtype=float32), 0.56938475]. 
=============================================
[2019-03-26 14:25:36,587] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5204077e-22 1.0000000e+00 7.4018076e-15 9.8999565e-22 1.8397451e-22], sum to 1.0000
[2019-03-26 14:25:36,594] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8125
[2019-03-26 14:25:36,598] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 96.5, 1.0, 2.0, 0.4581625852114105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647824.8115850058, 647824.8115850058, 178285.9516952029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086200.0000, 
sim time next is 2086800.0000, 
raw observation next is [24.03333333333333, 96.66666666666666, 1.0, 2.0, 0.4587731826357281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648564.1280802464, 648564.128080247, 178359.3039740096], 
processed observation next is [0.0, 0.13043478260869565, 0.3380726698262243, 0.9666666666666666, 1.0, 1.0, 0.3479194971514796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18015670224451288, 0.18015670224451305, 0.26620791637911884], 
reward next is 0.7338, 
noisyNet noise sample is [array([-0.2799216], dtype=float32), 0.87446487]. 
=============================================
[2019-03-26 14:25:36,652] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55767: loss 0.0019
[2019-03-26 14:25:36,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55768: learning rate 0.0000
[2019-03-26 14:25:36,754] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55808: loss 0.0000
[2019-03-26 14:25:36,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55811: learning rate 0.0000
[2019-03-26 14:25:36,858] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55861: loss 0.0004
[2019-03-26 14:25:36,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55861: learning rate 0.0000
[2019-03-26 14:25:36,886] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 55873: loss 0.0002
[2019-03-26 14:25:36,888] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 55873: learning rate 0.0000
[2019-03-26 14:25:36,898] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55878: loss 0.0002
[2019-03-26 14:25:36,900] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55878: learning rate 0.0000
[2019-03-26 14:25:37,021] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 55939: loss 0.0008
[2019-03-26 14:25:37,022] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 55939: learning rate 0.0000
[2019-03-26 14:25:37,051] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55950: loss 0.0009
[2019-03-26 14:25:37,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55951: learning rate 0.0000
[2019-03-26 14:25:37,110] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55974: loss 0.0001
[2019-03-26 14:25:37,113] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55974: learning rate 0.0000
[2019-03-26 14:25:37,130] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55982: loss 0.0015
[2019-03-26 14:25:37,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55984: learning rate 0.0000
[2019-03-26 14:25:37,221] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56027: loss 0.0001
[2019-03-26 14:25:37,222] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56027: learning rate 0.0000
[2019-03-26 14:25:37,278] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56050: loss 0.0012
[2019-03-26 14:25:37,283] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56050: learning rate 0.0000
[2019-03-26 14:25:37,376] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 56092: loss 0.0016
[2019-03-26 14:25:37,380] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 56093: learning rate 0.0000
[2019-03-26 14:25:37,395] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56101: loss 0.0038
[2019-03-26 14:25:37,397] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56101: learning rate 0.0000
[2019-03-26 14:25:37,425] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 56116: loss 0.0008
[2019-03-26 14:25:37,427] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 56117: learning rate 0.0000
[2019-03-26 14:25:37,494] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56148: loss 0.0006
[2019-03-26 14:25:37,496] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56149: learning rate 0.0000
[2019-03-26 14:25:37,619] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56208: loss 0.0006
[2019-03-26 14:25:37,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56208: learning rate 0.0000
[2019-03-26 14:25:47,501] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0915292e-19 1.0000000e+00 3.0499371e-13 7.8928550e-19 1.6957718e-21], sum to 1.0000
[2019-03-26 14:25:47,510] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6380
[2019-03-26 14:25:47,513] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.93333333333334, 76.66666666666667, 1.0, 2.0, 0.661238315044903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 924075.8179274382, 924075.8179274389, 212698.9042671591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2272800.0000, 
sim time next is 2273400.0000, 
raw observation next is [28.1, 76.0, 1.0, 2.0, 0.6760677007443725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944808.9966840319, 944808.9966840319, 215762.2623978976], 
processed observation next is [1.0, 0.30434782608695654, 0.5308056872037916, 0.76, 1.0, 1.0, 0.6097201213787621, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2624469435233422, 0.2624469435233422, 0.32203322745954865], 
reward next is 0.6780, 
noisyNet noise sample is [array([-0.23902649], dtype=float32), 0.90594393]. 
=============================================
[2019-03-26 14:25:51,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.5970367e-21 1.0000000e+00 1.7684082e-15 1.1814316e-19 1.5095055e-21], sum to 1.0000
[2019-03-26 14:25:51,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-26 14:25:51,477] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 82.0, 1.0, 2.0, 0.6655486001863871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 930102.0482365907, 930102.0482365907, 213582.6950682274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2349600.0000, 
sim time next is 2350200.0000, 
raw observation next is [27.13333333333333, 82.0, 1.0, 2.0, 0.6682611215593884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 933894.4548958407, 933894.4548958407, 214141.528037051], 
processed observation next is [1.0, 0.17391304347826086, 0.484992101105845, 0.82, 1.0, 1.0, 0.6003146042884198, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2594151263599558, 0.2594151263599558, 0.31961422095082237], 
reward next is 0.6804, 
noisyNet noise sample is [array([-0.8702912], dtype=float32), 0.20838271]. 
=============================================
[2019-03-26 14:25:54,254] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63802: loss 17.4266
[2019-03-26 14:25:54,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63803: learning rate 0.0000
[2019-03-26 14:25:54,371] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63857: loss 14.2377
[2019-03-26 14:25:54,376] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63860: learning rate 0.0000
[2019-03-26 14:25:54,379] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63861: loss 16.5208
[2019-03-26 14:25:54,381] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63861: learning rate 0.0000
[2019-03-26 14:25:54,396] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 63867: loss 14.6718
[2019-03-26 14:25:54,398] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 63868: learning rate 0.0000
[2019-03-26 14:25:54,409] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63873: loss 14.4089
[2019-03-26 14:25:54,411] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63874: learning rate 0.0000
[2019-03-26 14:25:54,608] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 63961: loss 16.3567
[2019-03-26 14:25:54,610] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 63961: learning rate 0.0000
[2019-03-26 14:25:54,657] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63979: loss 12.6853
[2019-03-26 14:25:54,660] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63979: learning rate 0.0000
[2019-03-26 14:25:54,673] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63989: loss 17.2753
[2019-03-26 14:25:54,679] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63991: learning rate 0.0000
[2019-03-26 14:25:54,700] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 64000: loss 18.8962
[2019-03-26 14:25:54,704] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 64001: learning rate 0.0000
[2019-03-26 14:25:54,772] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64033: loss 19.9694
[2019-03-26 14:25:54,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64033: learning rate 0.0000
[2019-03-26 14:25:54,776] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64033: loss 12.1358
[2019-03-26 14:25:54,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64034: learning rate 0.0000
[2019-03-26 14:25:54,790] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 64040: loss 16.2141
[2019-03-26 14:25:54,794] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 64041: learning rate 0.0000
[2019-03-26 14:25:54,822] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64052: loss 10.8288
[2019-03-26 14:25:54,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64053: learning rate 0.0000
[2019-03-26 14:25:54,933] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 64106: loss 12.6668
[2019-03-26 14:25:54,937] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 64107: learning rate 0.0000
[2019-03-26 14:25:55,044] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64150: loss 26.1936
[2019-03-26 14:25:55,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64153: learning rate 0.0000
[2019-03-26 14:25:55,215] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64235: loss 11.4690
[2019-03-26 14:25:55,217] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64235: learning rate 0.0000
[2019-03-26 14:26:05,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2466584e-11 1.0000000e+00 1.9782743e-10 3.9200847e-12 5.2966508e-14], sum to 1.0000
[2019-03-26 14:26:05,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-26 14:26:05,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2111227.775058973 W.
[2019-03-26 14:26:05,144] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.35, 74.5, 1.0, 2.0, 0.7549478853439827, 1.0, 2.0, 0.7549478853439827, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2111227.775058973, 2111227.775058973, 398532.4152186014], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2565000.0000, 
sim time next is 2565600.0000, 
raw observation next is [29.26666666666667, 75.0, 1.0, 2.0, 0.8566289198687457, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.990063488700669, 6.9112, 168.91248783892, 2094330.73326309, 2038382.415343527, 422905.0978673733], 
processed observation next is [1.0, 0.6956521739130435, 0.5860979462875199, 0.75, 1.0, 1.0, 0.8272637588780068, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00788634887006694, 0.0, 0.8294376437606249, 0.581758537017525, 0.5662173375954241, 0.6312016386080199], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08317789], dtype=float32), 1.6992177]. 
=============================================
[2019-03-26 14:26:06,751] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9959714e-21 1.0000000e+00 1.2571544e-16 1.2896723e-20 2.9000045e-23], sum to 1.0000
[2019-03-26 14:26:06,760] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6536
[2019-03-26 14:26:06,767] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 92.0, 1.0, 2.0, 0.4417324161473611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636596.4127780722, 636596.4127780729, 177456.4061942771], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2601600.0000, 
sim time next is 2602200.0000, 
raw observation next is [24.13333333333333, 92.0, 1.0, 2.0, 0.4399230405821846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634846.1989082854, 634846.1989082847, 177304.0313787904], 
processed observation next is [0.0, 0.08695652173913043, 0.3428120063191152, 0.92, 1.0, 1.0, 0.32520848262913815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1763461663634126, 0.1763461663634124, 0.26463288265491103], 
reward next is 0.7354, 
noisyNet noise sample is [array([0.9849572], dtype=float32), -0.40360162]. 
=============================================
[2019-03-26 14:26:08,613] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3056649e-22 1.0000000e+00 2.1724807e-18 7.8270552e-23 5.7654309e-24], sum to 1.0000
[2019-03-26 14:26:08,623] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6605
[2019-03-26 14:26:08,630] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4763915593832231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665672.8520295065, 665672.8520295065, 179979.603333494], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2632800.0000, 
sim time next is 2633400.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.4773453548638306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667006.0307422256, 667006.0307422249, 180122.5480859272], 
processed observation next is [0.0, 0.4782608695652174, 0.4549763033175356, 0.815, 1.0, 1.0, 0.3702956082696755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18527945298395154, 0.18527945298395135, 0.2688396240088466], 
reward next is 0.7312, 
noisyNet noise sample is [array([0.08202407], dtype=float32), 0.867347]. 
=============================================
[2019-03-26 14:26:10,435] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1818517e-22 1.0000000e+00 4.9257150e-18 2.8180290e-22 9.0032127e-24], sum to 1.0000
[2019-03-26 14:26:10,443] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7215
[2019-03-26 14:26:10,449] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4151983863922045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612542.7685328014, 612542.768532802, 175511.5393493354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.411376980288663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608200.7687486969, 608200.7687486969, 175139.2544711489], 
processed observation next is [0.0, 0.8260869565217391, 0.3206951026856238, 0.9066666666666667, 1.0, 1.0, 0.29081563890200357, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16894465798574915, 0.16894465798574915, 0.26140187234499834], 
reward next is 0.7386, 
noisyNet noise sample is [array([-0.68533415], dtype=float32), -0.5574802]. 
=============================================
[2019-03-26 14:26:11,550] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71643: loss 0.0127
[2019-03-26 14:26:11,553] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71644: learning rate 0.0000
[2019-03-26 14:26:11,893] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71800: loss 0.0075
[2019-03-26 14:26:11,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71800: learning rate 0.0000
[2019-03-26 14:26:11,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71810: loss 0.0062
[2019-03-26 14:26:11,917] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71810: learning rate 0.0000
[2019-03-26 14:26:11,954] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 71825: loss 0.0077
[2019-03-26 14:26:11,958] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 71827: learning rate 0.0000
[2019-03-26 14:26:12,045] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71870: loss 0.0055
[2019-03-26 14:26:12,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71870: learning rate 0.0000
[2019-03-26 14:26:12,222] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 71950: loss 0.0081
[2019-03-26 14:26:12,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 71951: learning rate 0.0000
[2019-03-26 14:26:12,343] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 72000: loss 0.0034
[2019-03-26 14:26:12,347] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 72002: learning rate 0.0000
[2019-03-26 14:26:12,372] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 72013: loss 0.0039
[2019-03-26 14:26:12,376] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 72014: learning rate 0.0000
[2019-03-26 14:26:12,389] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 72024: loss 0.0015
[2019-03-26 14:26:12,393] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 72024: learning rate 0.0000
[2019-03-26 14:26:12,452] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72053: loss 0.0042
[2019-03-26 14:26:12,455] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72055: learning rate 0.0000
[2019-03-26 14:26:12,468] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72060: loss 0.0017
[2019-03-26 14:26:12,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72060: learning rate 0.0000
[2019-03-26 14:26:12,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 72068: loss 0.0013
[2019-03-26 14:26:12,488] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 72069: learning rate 0.0000
[2019-03-26 14:26:12,489] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72070: loss 0.0012
[2019-03-26 14:26:12,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72070: learning rate 0.0000
[2019-03-26 14:26:12,654] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72144: loss 0.0018
[2019-03-26 14:26:12,655] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72144: learning rate 0.0000
[2019-03-26 14:26:12,761] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 72195: loss 0.0003
[2019-03-26 14:26:12,762] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 72195: learning rate 0.0000
[2019-03-26 14:26:12,883] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72247: loss 0.0001
[2019-03-26 14:26:12,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72247: learning rate 0.0000
[2019-03-26 14:26:13,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4491148e-22 1.0000000e+00 2.5852045e-18 4.7554511e-23 5.8761843e-24], sum to 1.0000
[2019-03-26 14:26:13,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7504
[2019-03-26 14:26:13,447] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.409181697380103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 174749.847841923], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 1.0, 1.0, 1.0, 0.28817071973506386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16784845999691392, 0.16784845999691392, 0.2608206684207806], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.26335275], dtype=float32), 0.7214733]. 
=============================================
[2019-03-26 14:26:19,061] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 14:26:19,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:26:19,064] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:19,065] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:26:19,067] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:19,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:26:19,069] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:26:19,069] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:19,070] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:26:19,070] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:19,073] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:26:19,090] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 14:26:19,109] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 14:26:19,131] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 14:26:19,146] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 14:26:19,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 14:26:20,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:26:20,727] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.830640235, 61.68133957, 1.0, 2.0, 0.470411260327565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737532.9389078664, 737532.938907867, 188457.4787846364]
[2019-03-26 14:26:20,728] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:26:20,729] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0435949e-22 1.0000000e+00 1.3617363e-17 8.6021170e-22 7.7851839e-24], sampled 0.5834356428509858
[2019-03-26 14:26:39,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:26:39,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.1, 95.0, 1.0, 2.0, 0.3225379551858542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507450.764792115, 507450.7647921143, 167533.8054971398]
[2019-03-26 14:26:39,814] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:26:39,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7662234e-22 1.0000000e+00 1.8224270e-17 1.2741410e-21 1.4384020e-23], sampled 0.7170124293524943
[2019-03-26 14:26:48,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:26:48,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.58333333333334, 94.00000000000001, 1.0, 2.0, 0.5055580618583821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706441.4263932309, 706441.4263932309, 184471.7488103448]
[2019-03-26 14:26:48,930] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:26:48,933] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2937759e-23 1.0000000e+00 5.5713766e-18 2.7092139e-22 3.0150427e-24], sampled 0.7748862022384836
[2019-03-26 14:27:18,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:18,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.80335893333334, 78.06566559000001, 1.0, 2.0, 0.5190792326837262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725341.6816040882, 725341.6816040876, 186638.5546971684]
[2019-03-26 14:27:18,528] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:27:18,532] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4384284e-17 1.0000000e+00 1.5067522e-14 1.1716264e-17 1.5541420e-19], sampled 0.4642050197429991
[2019-03-26 14:27:21,198] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:21,200] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.13333333333333, 62.33333333333333, 1.0, 2.0, 0.5919686203882834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 827234.2158977598, 827234.2158977604, 199259.1020526501]
[2019-03-26 14:27:21,200] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:27:21,203] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7764427e-20 1.0000000e+00 1.9821548e-16 4.4752882e-20 2.8508772e-22], sampled 0.046520276093917845
[2019-03-26 14:27:25,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:25,825] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.33333333333334, 79.0, 1.0, 2.0, 0.5251308930394936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733800.9636913787, 733800.9636913781, 187627.6321228274]
[2019-03-26 14:27:25,826] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:27:25,830] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.7171754e-23 1.0000000e+00 7.9711061e-18 4.0111593e-22 4.7622381e-24], sampled 0.8962596741853209
[2019-03-26 14:27:36,063] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:36,065] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.33333333333334, 69.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.306753291347249, 6.9112, 168.9050811647179, 3274598.818579561, 2284591.442411836, 472653.8634284354]
[2019-03-26 14:27:36,065] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:27:36,068] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8587673e-18 1.0000000e+00 1.0417179e-14 6.8939184e-18 7.8563534e-20], sampled 0.5763926171853079
[2019-03-26 14:27:36,069] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3274598.818579561 W.
[2019-03-26 14:27:36,811] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:36,814] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.6, 86.66666666666667, 1.0, 2.0, 0.5773297826347883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806769.7079644799, 806769.7079644799, 196598.8073998505]
[2019-03-26 14:27:36,817] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:27:36,819] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5718598e-23 1.0000000e+00 4.2736948e-18 2.2250560e-22 1.4356768e-24], sampled 0.5846884830548772
[2019-03-26 14:27:44,029] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07223093], dtype=float32), 0.054280043]
[2019-03-26 14:27:44,031] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.26532622, 56.59557307, 1.0, 2.0, 0.5910049122682768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 825886.9784815122, 825886.9784815127, 199081.7646861386]
[2019-03-26 14:27:44,032] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:27:44,036] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9310762e-22 1.0000000e+00 1.3561222e-17 7.0824977e-22 8.9345124e-24], sampled 0.12950998149967807
[2019-03-26 14:28:15,634] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:28:15,650] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:28:15,657] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4187 3164052187.7637 1778.0000
[2019-03-26 14:28:15,749] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 14:28:15,835] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3940 2779173803.8581 933.0000
[2019-03-26 14:28:16,849] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 75000, evaluation results [75000.0, 7883.418744751638, 3164052187.7636957, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.39403466329, 2779173803.858108, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:28:21,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8802723e-22 1.0000000e+00 1.8404157e-18 1.1308077e-23 1.7496322e-24], sum to 1.0000
[2019-03-26 14:28:21,512] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5502
[2019-03-26 14:28:21,625] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 89.83333333333333, 1.0, 2.0, 0.7239476025630669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1107836.51087096, 1107836.51087096, 238384.3031321589], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2891400.0000, 
sim time next is 2892000.0000, 
raw observation next is [22.8, 89.66666666666667, 1.0, 2.0, 0.6677887869136984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1020972.470796245, 1020972.470796246, 225019.6831321651], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.8966666666666667, 1.0, 1.0, 0.5997455264020461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28360346411006804, 0.2836034641100683, 0.33585027333158973], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.3977665], dtype=float32), -1.3224974]. 
=============================================
[2019-03-26 14:28:21,647] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.98191 ]
 [76.839836]
 [76.7999  ]
 [76.73702 ]
 [76.66968 ]], R is [[76.92991638]
 [76.80482483]
 [76.71226501]
 [76.61986542]
 [76.53256226]].
[2019-03-26 14:28:22,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2329363e-23 1.0000000e+00 1.0496257e-18 9.1200184e-23 2.0518574e-24], sum to 1.0000
[2019-03-26 14:28:22,088] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7494
[2019-03-26 14:28:22,097] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 94.00000000000001, 1.0, 2.0, 0.5686072264897417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851744.2705237466, 851744.2705237466, 202139.1769588858], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2898600.0000, 
sim time next is 2899200.0000, 
raw observation next is [22.66666666666667, 94.0, 1.0, 2.0, 0.6903514935496612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1039737.312066003, 1039737.312066004, 228390.7154094192], 
processed observation next is [1.0, 0.5652173913043478, 0.27330173775671435, 0.94, 1.0, 1.0, 0.6269295103007966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28881592001833417, 0.28881592001833445, 0.3408816647901779], 
reward next is 0.6591, 
noisyNet noise sample is [array([-0.89290094], dtype=float32), -0.7902557]. 
=============================================
[2019-03-26 14:28:26,860] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79594: loss 0.0715
[2019-03-26 14:28:26,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79594: learning rate 0.0000
[2019-03-26 14:28:27,315] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79787: loss 0.0298
[2019-03-26 14:28:27,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79787: learning rate 0.0000
[2019-03-26 14:28:27,454] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 79823: loss 0.0260
[2019-03-26 14:28:27,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 79824: learning rate 0.0000
[2019-03-26 14:28:27,604] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79869: loss 0.0203
[2019-03-26 14:28:27,608] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79869: learning rate 0.0000
[2019-03-26 14:28:27,726] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79893: loss 0.0269
[2019-03-26 14:28:27,728] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79893: learning rate 0.0000
[2019-03-26 14:28:27,933] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 79963: loss 0.0249
[2019-03-26 14:28:27,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 79963: learning rate 0.0000
[2019-03-26 14:28:28,052] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79985: loss 0.0232
[2019-03-26 14:28:28,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79985: learning rate 0.0000
[2019-03-26 14:28:28,237] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80045: loss 0.0291
[2019-03-26 14:28:28,239] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80046: learning rate 0.0000
[2019-03-26 14:28:28,242] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 80049: loss 0.0325
[2019-03-26 14:28:28,319] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 80051: learning rate 0.0000
[2019-03-26 14:28:28,403] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 80071: loss 0.0279
[2019-03-26 14:28:28,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 80071: learning rate 0.0000
[2019-03-26 14:28:28,408] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80071: loss 0.0284
[2019-03-26 14:28:28,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80071: learning rate 0.0000
[2019-03-26 14:28:28,584] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 80081: loss 0.0176
[2019-03-26 14:28:28,588] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 80082: learning rate 0.0000
[2019-03-26 14:28:28,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80092: loss 0.0198
[2019-03-26 14:28:28,682] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80093: learning rate 0.0000
[2019-03-26 14:28:28,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80104: loss 0.0202
[2019-03-26 14:28:28,774] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80104: learning rate 0.0000
[2019-03-26 14:28:28,920] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 80149: loss 0.0132
[2019-03-26 14:28:28,921] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 80149: learning rate 0.0000
[2019-03-26 14:28:29,196] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80250: loss 0.0140
[2019-03-26 14:28:29,200] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80252: learning rate 0.0000
[2019-03-26 14:28:37,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.03093714e-22 1.00000000e+00 2.77856048e-18 1.02149883e-22
 2.85956596e-24], sum to 1.0000
[2019-03-26 14:28:37,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0917
[2019-03-26 14:28:37,074] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 91.5, 1.0, 2.0, 0.6531035362529316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1000958.272467623, 1000958.272467623, 221994.5514946665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3141000.0000, 
sim time next is 3141600.0000, 
raw observation next is [22.66666666666666, 90.66666666666666, 1.0, 2.0, 0.669519341242912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024165.140682468, 1024165.140682468, 225473.9364249042], 
processed observation next is [1.0, 0.34782608695652173, 0.27330173775671385, 0.9066666666666666, 1.0, 1.0, 0.6018305316179663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2844903168562411, 0.2844903168562411, 0.33652826332075253], 
reward next is 0.6635, 
noisyNet noise sample is [array([-0.10146929], dtype=float32), 1.3654066]. 
=============================================
[2019-03-26 14:28:39,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0801017e-21 1.0000000e+00 7.0995531e-18 6.5943933e-21 6.0954380e-23], sum to 1.0000
[2019-03-26 14:28:39,657] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9266
[2019-03-26 14:28:39,662] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4894258108128207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683891.7731756506, 683891.77317565, 181955.7322039544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4874377884848182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681112.9495931175, 681112.9495931175, 181651.1779037188], 
processed observation next is [1.0, 1.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.3824551668491786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18919804155364373, 0.18919804155364373, 0.2711211610503266], 
reward next is 0.7289, 
noisyNet noise sample is [array([1.1522017], dtype=float32), 0.22625232]. 
=============================================
[2019-03-26 14:28:39,677] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[70.10497 ]
 [70.09655 ]
 [70.075424]
 [70.06097 ]
 [70.039055]], R is [[70.13462067]
 [70.16169739]
 [70.18792725]
 [70.21327972]
 [70.23744965]].
[2019-03-26 14:28:40,065] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0470436e-22 1.0000000e+00 4.3841313e-18 1.1394296e-22 5.4604329e-24], sum to 1.0000
[2019-03-26 14:28:40,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5584
[2019-03-26 14:28:40,079] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.00000000000001, 1.0, 2.0, 0.4865847357625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679920.5693278117, 679920.5693278117, 181520.8536546495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3197400.0000, 
sim time next is 3198000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4863212203183043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 679552.2329093028, 679552.2329093022, 181480.6389402947], 
processed observation next is [0.0, 0.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.3811099039979571, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.188764509141473, 0.18876450914147283, 0.27086662528402194], 
reward next is 0.7291, 
noisyNet noise sample is [array([1.1847291], dtype=float32), -0.9510022]. 
=============================================
[2019-03-26 14:28:40,088] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[71.55628]
 [71.64104]
 [71.70158]
 [71.69512]
 [71.68236]], R is [[71.53018951]
 [71.54396057]
 [71.55760956]
 [71.57120514]
 [71.5846405 ]].
[2019-03-26 14:28:45,120] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87553: loss 0.0346
[2019-03-26 14:28:45,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87554: learning rate 0.0000
[2019-03-26 14:28:45,504] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 87729: loss 0.0151
[2019-03-26 14:28:45,509] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 87730: learning rate 0.0000
[2019-03-26 14:28:45,535] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87741: loss 0.0144
[2019-03-26 14:28:45,537] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87741: learning rate 0.0000
[2019-03-26 14:28:45,786] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87857: loss 0.0176
[2019-03-26 14:28:45,788] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87857: learning rate 0.0000
[2019-03-26 14:28:45,852] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87888: loss 0.0172
[2019-03-26 14:28:45,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87889: learning rate 0.0000
[2019-03-26 14:28:45,947] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87930: loss 0.0252
[2019-03-26 14:28:45,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87930: learning rate 0.0000
[2019-03-26 14:28:46,052] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 87982: loss 0.0359
[2019-03-26 14:28:46,057] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 87984: learning rate 0.0000
[2019-03-26 14:28:46,152] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88026: loss 0.0395
[2019-03-26 14:28:46,154] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88026: learning rate 0.0000
[2019-03-26 14:28:46,243] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88067: loss 0.0337
[2019-03-26 14:28:46,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88067: learning rate 0.0000
[2019-03-26 14:28:46,256] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 88073: loss 0.0456
[2019-03-26 14:28:46,257] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 88073: learning rate 0.0000
[2019-03-26 14:28:46,278] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 88081: loss 0.0464
[2019-03-26 14:28:46,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 88082: learning rate 0.0000
[2019-03-26 14:28:46,349] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88114: loss 0.0451
[2019-03-26 14:28:46,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88114: learning rate 0.0000
[2019-03-26 14:28:46,385] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88132: loss 0.0520
[2019-03-26 14:28:46,388] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88132: learning rate 0.0000
[2019-03-26 14:28:46,457] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88164: loss 0.0503
[2019-03-26 14:28:46,463] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88166: learning rate 0.0000
[2019-03-26 14:28:46,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.7851282e-23 1.0000000e+00 1.4673865e-17 9.7649620e-23 2.9924584e-24], sum to 1.0000
[2019-03-26 14:28:46,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4893
[2019-03-26 14:28:46,500] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 70.0, 1.0, 2.0, 0.4972080054590089, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694769.66157284, 694769.6615728405, 183159.9795494174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3315600.0000, 
sim time next is 3316200.0000, 
raw observation next is [29.0, 70.66666666666667, 1.0, 2.0, 0.5004055813089475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 699239.2393830349, 699239.2393830356, 183659.9082472191], 
processed observation next is [0.0, 0.391304347826087, 0.5734597156398105, 0.7066666666666667, 1.0, 1.0, 0.39807901362523795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19423312205084303, 0.19423312205084323, 0.27411926604062553], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.41828242], dtype=float32), -1.8520036]. 
=============================================
[2019-03-26 14:28:46,525] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 88195: loss 0.0363
[2019-03-26 14:28:46,528] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 88195: learning rate 0.0000
[2019-03-26 14:28:46,660] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88257: loss 0.0538
[2019-03-26 14:28:46,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88258: learning rate 0.0000
[2019-03-26 14:28:56,494] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.1422724e-17 1.0000000e+00 1.6067371e-14 1.6764802e-16 1.8984664e-19], sum to 1.0000
[2019-03-26 14:28:56,504] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9073
[2019-03-26 14:28:56,513] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2061026.011402804 W.
[2019-03-26 14:28:56,518] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.4913424221671117, 1.0, 1.0, 0.4913424221671117, 1.0, 2.0, 0.8383066952213583, 6.9112, 6.9112, 170.5573041426782, 2061026.011402804, 2061026.011402804, 406528.0260853813], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3489600.0000, 
sim time next is 3490200.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.7628790496551874, 1.0, 2.0, 0.7628790496551874, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2133429.531243898, 2133429.531243899, 402196.2486676965], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.714312108018298, 1.0, 1.0, 0.714312108018298, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.592619314234416, 0.5926193142344164, 0.6002929084592485], 
reward next is 0.3997, 
noisyNet noise sample is [array([-1.514801], dtype=float32), -0.50139517]. 
=============================================
[2019-03-26 14:28:59,942] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0081690e-19 1.0000000e+00 2.2224404e-17 4.1283705e-19 5.5517380e-23], sum to 1.0000
[2019-03-26 14:28:59,951] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-26 14:28:59,955] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.485625832047042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 678580.234230278, 678580.2342302772, 181374.384125974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3549000.0000, 
sim time next is 3549600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4846324784678872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677191.7476338005, 677191.7476338011, 181223.0983454054], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3790752752625147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18810881878716681, 0.18810881878716695, 0.270482236336426], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.3906277], dtype=float32), -0.46329156]. 
=============================================
[2019-03-26 14:29:02,607] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95580: loss 58.8468
[2019-03-26 14:29:02,609] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95581: learning rate 0.0000
[2019-03-26 14:29:02,992] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95759: loss -17.1709
[2019-03-26 14:29:02,994] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95760: learning rate 0.0000
[2019-03-26 14:29:03,011] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 95769: loss -102.7995
[2019-03-26 14:29:03,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 95769: learning rate 0.0000
[2019-03-26 14:29:03,203] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95857: loss -198.2693
[2019-03-26 14:29:03,206] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95858: learning rate 0.0000
[2019-03-26 14:29:03,481] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95868: loss -223.4238
[2019-03-26 14:29:03,483] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95868: learning rate 0.0000
[2019-03-26 14:29:03,599] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95927: loss -125.2545
[2019-03-26 14:29:03,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95928: learning rate 0.0000
[2019-03-26 14:29:03,804] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96016: loss -110.0036
[2019-03-26 14:29:03,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96016: learning rate 0.0000
[2019-03-26 14:29:03,828] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96025: loss -207.8215
[2019-03-26 14:29:03,831] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96027: learning rate 0.0000
[2019-03-26 14:29:03,919] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 96069: loss -79.1290
[2019-03-26 14:29:03,923] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 96070: learning rate 0.0000
[2019-03-26 14:29:03,937] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96077: loss -89.2907
[2019-03-26 14:29:03,940] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96078: learning rate 0.0000
[2019-03-26 14:29:04,041] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96121: loss 30.9716
[2019-03-26 14:29:04,043] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96121: learning rate 0.0000
[2019-03-26 14:29:04,046] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 96121: loss -11.4186
[2019-03-26 14:29:04,049] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 96123: learning rate 0.0000
[2019-03-26 14:29:04,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96156: loss -131.4386
[2019-03-26 14:29:04,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96158: learning rate 0.0000
[2019-03-26 14:29:04,160] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96173: loss -224.0583
[2019-03-26 14:29:04,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96174: learning rate 0.0000
[2019-03-26 14:29:04,194] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 96192: loss -88.7596
[2019-03-26 14:29:04,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 96192: learning rate 0.0000
[2019-03-26 14:29:04,376] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96284: loss -189.6608
[2019-03-26 14:29:04,377] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96284: learning rate 0.0000
[2019-03-26 14:29:04,887] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3567682e-18 1.0000000e+00 2.8249907e-16 2.1514670e-18 9.9557790e-22], sum to 1.0000
[2019-03-26 14:29:04,897] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-26 14:29:04,905] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5234008158471993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731382.5773714219, 731382.5773714213, 187343.8294250153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615600.0000, 
sim time next is 3616200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5245965319221539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733054.0070592929, 733054.0070592923, 187539.6007289533], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4272247372556071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2036261130720258, 0.20362611307202563, 0.27990985183425865], 
reward next is 0.7201, 
noisyNet noise sample is [array([-1.8897125], dtype=float32), 0.26318517]. 
=============================================
[2019-03-26 14:29:05,861] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2558320e-20 1.0000000e+00 5.8995609e-18 7.4066185e-20 1.9445725e-24], sum to 1.0000
[2019-03-26 14:29:05,869] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1438
[2019-03-26 14:29:05,874] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 81.5, 1.0, 2.0, 0.5002998492929307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699091.4466625112, 699091.4466625106, 183642.8298205556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3634200.0000, 
sim time next is 3634800.0000, 
raw observation next is [27.0, 80.66666666666667, 1.0, 2.0, 0.4974998686123532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695177.6276825194, 695177.62768252, 183204.9238889904], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.8066666666666668, 1.0, 1.0, 0.3945781549546424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1931048965784776, 0.19310489657847776, 0.2734401849089409], 
reward next is 0.7266, 
noisyNet noise sample is [array([-1.7115525], dtype=float32), -0.6502965]. 
=============================================
[2019-03-26 14:29:06,611] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0157276e-20 1.0000000e+00 2.4034343e-17 2.6866177e-19 1.5440810e-23], sum to 1.0000
[2019-03-26 14:29:06,620] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2052
[2019-03-26 14:29:06,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6238818424582347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 871848.9869346417, 871848.9869346417, 205269.7875840174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3650400.0000, 
sim time next is 3651000.0000, 
raw observation next is [27.16666666666666, 78.16666666666667, 1.0, 2.0, 0.6891340640324746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963077.6037385333, 963077.6037385333, 218513.9988579413], 
processed observation next is [1.0, 0.2608695652173913, 0.4865718799368086, 0.7816666666666667, 1.0, 1.0, 0.6254627277499694, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26752155659403704, 0.26752155659403704, 0.32614029680289747], 
reward next is 0.6739, 
noisyNet noise sample is [array([-0.09853282], dtype=float32), -0.049088355]. 
=============================================
[2019-03-26 14:29:06,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.47272]
 [65.52563]
 [65.49417]
 [65.48532]
 [65.523  ]], R is [[65.4693985 ]
 [65.5083313 ]
 [65.54792786]
 [65.58901215]
 [65.63290405]].
[2019-03-26 14:29:12,146] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 14:29:12,148] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:29:12,149] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:29:12,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:12,149] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:12,149] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:29:12,150] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:29:12,151] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:12,152] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:12,157] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:29:12,158] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:29:12,162] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 14:29:12,175] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 14:29:12,175] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 14:29:12,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 14:29:12,215] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 14:29:14,105] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:14,106] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 66.5, 1.0, 2.0, 0.476874229188514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666347.509147642, 666347.509147642, 180052.3975013182]
[2019-03-26 14:29:14,108] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:29:14,111] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4073649e-18 1.0000000e+00 1.2076845e-16 1.1256466e-17 2.9355226e-22], sampled 0.3348333070557664
[2019-03-26 14:29:28,702] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:28,704] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.2, 88.0, 1.0, 2.0, 0.295114863593383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472232.8534878552, 472232.8534878552, 165101.0634745508]
[2019-03-26 14:29:28,705] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:29:28,709] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1096746e-20 1.0000000e+00 6.8329151e-18 1.9106576e-19 8.6812573e-24], sampled 0.9757406656518289
[2019-03-26 14:29:32,855] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:32,857] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.86666666666667, 48.66666666666667, 1.0, 2.0, 0.289633149338981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 474859.5319223051, 474859.5319223044, 165083.4154468953]
[2019-03-26 14:29:32,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:29:32,862] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.1524551e-20 1.0000000e+00 1.3437068e-17 3.6545630e-19 1.9746987e-23], sampled 0.5153871545748714
[2019-03-26 14:29:43,012] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:43,013] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.23459639166667, 93.78325357833333, 1.0, 2.0, 0.4108837809549286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 609414.7994036191, 609414.7994036186, 175307.5799580571]
[2019-03-26 14:29:43,013] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:29:43,015] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3851880e-21 1.0000000e+00 3.1251876e-18 8.8037679e-20 3.2856575e-24], sampled 0.13401203472134515
[2019-03-26 14:29:46,857] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:46,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.4, 73.0, 1.0, 2.0, 0.520635679238938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765583.608252016, 765583.6082520167, 191665.1006896288]
[2019-03-26 14:29:46,861] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:29:46,863] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.7959873e-20 1.0000000e+00 1.3942683e-17 6.8724626e-19 2.0852918e-23], sampled 0.912883866891195
[2019-03-26 14:29:51,882] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:29:51,883] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.96666666666667, 91.33333333333334, 1.0, 2.0, 0.5179587148398725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723775.3789306416, 723775.3789306416, 186457.1812395663]
[2019-03-26 14:29:51,885] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:29:51,887] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0230793e-20 1.0000000e+00 3.3861145e-18 9.4692716e-20 3.6630815e-24], sampled 0.9806015254549906
[2019-03-26 14:30:08,714] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:30:08,715] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.71468167, 72.15040627666667, 1.0, 2.0, 0.8432939479200201, 1.0, 1.0, 0.8432939479200201, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 171.5212843490159, 2358525.972563469, 2358525.972563469, 441716.5739825001]
[2019-03-26 14:30:08,716] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:30:08,720] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.8948563e-13 1.0000000e+00 2.0939444e-12 4.9540719e-12 2.4907165e-16], sampled 0.1817041883107493
[2019-03-26 14:30:08,721] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2358525.972563469 W.
[2019-03-26 14:30:09,205] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:30:09,205] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 78.66666666666667, 1.0, 2.0, 0.5703407176594951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796999.4145586547, 796999.4145586547, 195349.8991865976]
[2019-03-26 14:30:09,207] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:30:09,208] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5616291e-20 1.0000000e+00 3.2637317e-18 1.2387297e-19 3.1327335e-24], sampled 0.42312893374128935
[2019-03-26 14:30:31,709] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:30:31,710] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.78649835, 82.716377715, 1.0, 2.0, 0.7353757349560961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1027732.464372481, 1027732.464372482, 228679.4367954422]
[2019-03-26 14:30:31,711] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:30:31,712] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2227012e-20 1.0000000e+00 2.6359016e-18 1.0363288e-19 2.3770113e-24], sampled 0.9366258005678055
[2019-03-26 14:30:45,528] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07356811], dtype=float32), 0.04921952]
[2019-03-26 14:30:45,529] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.23333333333333, 88.66666666666667, 1.0, 2.0, 0.5893221445359876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823534.5196235607, 823534.5196235607, 198772.7841659751]
[2019-03-26 14:30:45,533] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:30:45,536] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.4586520e-21 1.0000000e+00 2.2149742e-18 9.7763081e-20 1.6839916e-24], sampled 0.9280527769635064
[2019-03-26 14:31:08,509] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 14:31:09,162] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:31:09,273] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 14:31:09,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:31:09,537] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927401710.6637 1338.0000
[2019-03-26 14:31:10,553] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 100000, evaluation results [100000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8252.928344787482, 2927401710.663696, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:31:16,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7350107e-20 1.0000000e+00 2.8169706e-18 1.1501084e-19 5.8966376e-25], sum to 1.0000
[2019-03-26 14:31:16,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9235
[2019-03-26 14:31:16,522] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.25, 62.0, 1.0, 2.0, 0.6165147167353393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 861549.5588072789, 861549.5588072783, 203863.8159743474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3846600.0000, 
sim time next is 3847200.0000, 
raw observation next is [34.33333333333334, 61.66666666666667, 1.0, 2.0, 0.6165615271090111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861615.000578552, 861615.000578552, 203872.7903916272], 
processed observation next is [0.0, 0.5217391304347826, 0.8262243285939973, 0.6166666666666667, 1.0, 1.0, 0.538025936275917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2393375001607089, 0.2393375001607089, 0.30428774685317495], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.8247236], dtype=float32), 0.42701593]. 
=============================================
[2019-03-26 14:31:18,233] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103540: loss 0.1443
[2019-03-26 14:31:18,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103542: learning rate 0.0000
[2019-03-26 14:31:18,437] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103634: loss 0.1634
[2019-03-26 14:31:18,442] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103634: learning rate 0.0000
[2019-03-26 14:31:18,608] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 103711: loss 0.1849
[2019-03-26 14:31:18,610] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 103711: learning rate 0.0000
[2019-03-26 14:31:18,769] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103786: loss 0.1968
[2019-03-26 14:31:18,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103786: learning rate 0.0000
[2019-03-26 14:31:18,992] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103887: loss 0.1653
[2019-03-26 14:31:18,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103888: learning rate 0.0000
[2019-03-26 14:31:19,000] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103889: loss 0.1607
[2019-03-26 14:31:19,003] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103890: learning rate 0.0000
[2019-03-26 14:31:19,219] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103991: loss 0.1366
[2019-03-26 14:31:19,226] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103992: learning rate 0.0000
[2019-03-26 14:31:19,302] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 104036: loss 0.1096
[2019-03-26 14:31:19,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 104038: learning rate 0.0000
[2019-03-26 14:31:19,317] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104047: loss 0.1094
[2019-03-26 14:31:19,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104047: learning rate 0.0000
[2019-03-26 14:31:19,422] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104091: loss 0.0950
[2019-03-26 14:31:19,429] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104092: learning rate 0.0000
[2019-03-26 14:31:19,527] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 104138: loss 0.0661
[2019-03-26 14:31:19,530] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 104138: learning rate 0.0000
[2019-03-26 14:31:19,555] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104151: loss 0.0626
[2019-03-26 14:31:19,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104151: learning rate 0.0000
[2019-03-26 14:31:19,590] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104165: loss 0.0664
[2019-03-26 14:31:19,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104168: learning rate 0.0000
[2019-03-26 14:31:19,610] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104174: loss 0.0561
[2019-03-26 14:31:19,614] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104175: learning rate 0.0000
[2019-03-26 14:31:19,747] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 104239: loss 0.0510
[2019-03-26 14:31:19,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 104239: learning rate 0.0000
[2019-03-26 14:31:19,902] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104309: loss 0.0403
[2019-03-26 14:31:19,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104310: learning rate 0.0000
[2019-03-26 14:31:23,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.50380395e-21 1.00000000e+00 3.43458522e-19 1.23953265e-20
 1.59980406e-26], sum to 1.0000
[2019-03-26 14:31:23,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7591
[2019-03-26 14:31:23,461] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5900555595911859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 824559.8112500493, 824559.8112500499, 198907.3005377516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3979200.0000, 
sim time next is 3979800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5883725691910666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822207.0440493142, 822207.0440493142, 198599.2459760719], 
processed observation next is [1.0, 0.043478260869565216, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5040633363747791, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22839084556925396, 0.22839084556925396, 0.2964167850389133], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.9154753], dtype=float32), 0.78649724]. 
=============================================
[2019-03-26 14:31:31,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.5181407e-07 9.9999321e-01 1.3461184e-07 5.9616350e-06 5.7059607e-11], sum to 1.0000
[2019-03-26 14:31:31,356] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6469
[2019-03-26 14:31:31,362] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2503159.618631145 W.
[2019-03-26 14:31:31,365] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.83333333333333, 71.0, 1.0, 2.0, 0.8949514045776354, 1.0, 2.0, 0.8949514045776354, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2503159.618631145, 2503159.618631145, 468758.0868690492], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4103400.0000, 
sim time next is 4104000.0000, 
raw observation next is [33.0, 71.0, 1.0, 2.0, 0.944624306503191, 1.0, 2.0, 0.944624306503191, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2642240.549467475, 2642240.549467476, 496435.1371393422], 
processed observation next is [1.0, 0.5217391304347826, 0.7630331753554502, 0.71, 1.0, 1.0, 0.9332822969917963, 1.0, 1.0, 0.9332822969917963, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7339557081854098, 0.73395570818541, 0.7409479658796152], 
reward next is 0.2591, 
noisyNet noise sample is [array([0.7922896], dtype=float32), -0.11691574]. 
=============================================
[2019-03-26 14:31:31,377] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[21.13209 ]
 [20.965742]
 [22.181662]
 [23.627312]
 [23.518164]], R is [[21.64120483]
 [21.72515488]
 [21.70591164]
 [21.48885345]
 [21.55759811]].
[2019-03-26 14:31:33,354] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4178958e-20 1.0000000e+00 1.0011670e-17 5.8073818e-20 1.5236647e-25], sum to 1.0000
[2019-03-26 14:31:33,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4264
[2019-03-26 14:31:33,375] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.9481919089031217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1325341.678273669, 1325341.678273669, 283541.3806938237], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4158000.0000, 
sim time next is 4158600.0000, 
raw observation next is [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.9794442522346938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1369053.020016599, 1369053.020016599, 292728.666948068], 
processed observation next is [1.0, 0.13043478260869565, 0.5655608214849924, 0.8483333333333333, 1.0, 1.0, 0.9752340388369805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38029250556016636, 0.38029250556016636, 0.4369084581314448], 
reward next is 0.5631, 
noisyNet noise sample is [array([1.5015357], dtype=float32), 0.07370102]. 
=============================================
[2019-03-26 14:31:34,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2304799e-20 1.0000000e+00 4.0163275e-18 7.7251748e-20 2.5520949e-26], sum to 1.0000
[2019-03-26 14:31:34,210] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9611
[2019-03-26 14:31:34,213] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 83.16666666666667, 1.0, 2.0, 0.957621953381459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1338530.896345231, 1338530.896345231, 286286.2908198257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4173000.0000, 
sim time next is 4173600.0000, 
raw observation next is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.916186142425426, 6.9112, 168.9128263400949, 1457294.688481161, 1453757.350160787, 311357.4961964511], 
processed observation next is [1.0, 0.30434782608695654, 0.6524486571879939, 0.8233333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0004986142425425832, 0.0, 0.8294393059563603, 0.4048040801336558, 0.4038214861557742, 0.4647126808902255], 
reward next is 0.5104, 
noisyNet noise sample is [array([0.7736567], dtype=float32), -0.78144795]. 
=============================================
[2019-03-26 14:31:35,723] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111578: loss -102.0506
[2019-03-26 14:31:35,726] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111578: learning rate 0.0000
[2019-03-26 14:31:35,891] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111654: loss -148.8066
[2019-03-26 14:31:35,893] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111654: learning rate 0.0000
[2019-03-26 14:31:36,232] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111809: loss -123.1288
[2019-03-26 14:31:36,233] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 111809: loss -94.2568
[2019-03-26 14:31:36,236] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111810: learning rate 0.0000
[2019-03-26 14:31:36,236] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 111810: learning rate 0.0000
[2019-03-26 14:31:36,323] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111850: loss -66.0934
[2019-03-26 14:31:36,326] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111850: learning rate 0.0000
[2019-03-26 14:31:36,421] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111895: loss -138.5157
[2019-03-26 14:31:36,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111895: learning rate 0.0000
[2019-03-26 14:31:36,644] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111997: loss -203.8443
[2019-03-26 14:31:36,648] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111998: learning rate 0.0000
[2019-03-26 14:31:36,707] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112026: loss -120.5744
[2019-03-26 14:31:36,713] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112028: learning rate 0.0000
[2019-03-26 14:31:36,724] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112033: loss -137.7753
[2019-03-26 14:31:36,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112033: learning rate 0.0000
[2019-03-26 14:31:37,115] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 112107: loss -151.2493
[2019-03-26 14:31:37,118] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 112107: learning rate 0.0000
[2019-03-26 14:31:37,132] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112116: loss -181.9605
[2019-03-26 14:31:37,134] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112116: learning rate 0.0000
[2019-03-26 14:31:37,240] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112162: loss -209.1774
[2019-03-26 14:31:37,243] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112163: learning rate 0.0000
[2019-03-26 14:31:37,243] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112164: loss -139.0697
[2019-03-26 14:31:37,247] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112164: learning rate 0.0000
[2019-03-26 14:31:37,335] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 112207: loss -171.7433
[2019-03-26 14:31:37,341] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 112207: learning rate 0.0000
[2019-03-26 14:31:37,394] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112231: loss -111.8081
[2019-03-26 14:31:37,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112231: learning rate 0.0000
[2019-03-26 14:31:37,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112297: loss -155.5501
[2019-03-26 14:31:37,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112297: learning rate 0.0000
[2019-03-26 14:31:40,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0355670e-05 9.9992704e-01 1.4584593e-06 6.1097788e-05 3.2356837e-10], sum to 1.0000
[2019-03-26 14:31:40,866] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1578
[2019-03-26 14:31:40,873] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3150779.52863697 W.
[2019-03-26 14:31:40,988] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.247867848482047, 6.9112, 170.5573041426782, 3150779.52863697, 2909610.653996793, 551882.8002960577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4276800.0000, 
sim time next is 4277400.0000, 
raw observation next is [37.16666666666667, 56.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 8.308950017129188, 6.9112, 170.5573041426782, 3911761.469813982, 2910496.275708848, 545170.2419622907], 
processed observation next is [1.0, 0.5217391304347826, 0.9605055292259086, 0.565, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.13977500171291882, 0.0, 0.8375144448122397, 1.0866004082816616, 0.8084711876969023, 0.8136869283019265], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3407709], dtype=float32), 0.7492217]. 
=============================================
[2019-03-26 14:31:44,919] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6561503e-15 1.0000000e+00 3.1824548e-13 6.2896404e-14 6.0335838e-21], sum to 1.0000
[2019-03-26 14:31:44,928] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4769
[2019-03-26 14:31:44,937] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.9721589028233985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104308, 1358863.146501344, 1358863.146501344, 290563.2352743167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4338000.0000, 
sim time next is 4338600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.754425148362498, 6.9112, 168.9086912352747, 2052362.533882743, 1454164.697731107, 311356.0814194496], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.08432251483624978, 0.0, 0.8294190006986337, 0.5701007038563175, 0.40393463825864084, 0.4647105692827606], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1362011], dtype=float32), -1.1110904]. 
=============================================
[2019-03-26 14:31:48,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3361368e-14 1.0000000e+00 5.3636701e-13 1.4508264e-11 6.9354823e-20], sum to 1.0000
[2019-03-26 14:31:48,417] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7758
[2019-03-26 14:31:48,425] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.5550751307338234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775659.3526796368, 775659.3526796368, 192676.106123211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4386600.0000, 
sim time next is 4387200.0000, 
raw observation next is [32.0, 64.33333333333334, 1.0, 2.0, 0.5525215388099634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772089.6785517579, 772089.6785517579, 192235.1490814873], 
processed observation next is [1.0, 0.782608695652174, 0.7156398104265403, 0.6433333333333334, 1.0, 1.0, 0.4608693238674257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2144693551532661, 0.2144693551532661, 0.28691813295744373], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.7177795], dtype=float32), -0.9246666]. 
=============================================
[2019-03-26 14:31:48,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6899291e-21 1.0000000e+00 2.2797995e-18 2.6755617e-19 2.5338757e-27], sum to 1.0000
[2019-03-26 14:31:48,473] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7854
[2019-03-26 14:31:48,476] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6172120494033209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 862524.4432381731, 862524.4432381738, 203997.1329587804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4396800.0000, 
sim time next is 4397400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.616364673260863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 861339.7952720759, 861339.7952720753, 203835.1097823063], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5377887629648951, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2392610542422433, 0.23926105424224314, 0.3042315071377706], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.7544211], dtype=float32), -0.010634308]. 
=============================================
[2019-03-26 14:31:48,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.6165034e-20 1.0000000e+00 4.6960665e-17 2.3391857e-17 8.7720997e-25], sum to 1.0000
[2019-03-26 14:31:48,675] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4001
[2019-03-26 14:31:48,680] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 63.0, 1.0, 2.0, 0.5300957246783313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740741.078191181, 740741.0781911802, 188445.7701651514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4391400.0000, 
sim time next is 4392000.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5247837973173619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733315.7759126496, 733315.7759126503, 187570.242284233], 
processed observation next is [1.0, 0.8695652173913043, 0.6682464454976303, 0.63, 1.0, 1.0, 0.42745035821368904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20369882664240266, 0.20369882664240285, 0.27995558549885524], 
reward next is 0.7200, 
noisyNet noise sample is [array([-1.5402445], dtype=float32), -0.25490206]. 
=============================================
[2019-03-26 14:31:48,697] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.8065  ]
 [55.099957]
 [53.619843]
 [51.493687]
 [49.77485 ]], R is [[58.05397034]
 [58.19216919]
 [58.32786179]
 [58.46129608]
 [58.59239578]].
[2019-03-26 14:31:51,261] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5552648e-23 1.0000000e+00 5.6697822e-20 7.1946346e-22 3.0687834e-29], sum to 1.0000
[2019-03-26 14:31:51,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6231
[2019-03-26 14:31:51,274] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 79.0, 1.0, 2.0, 0.5995807247293435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 837875.7882265762, 837875.7882265768, 200668.4283339775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4437000.0000, 
sim time next is 4437600.0000, 
raw observation next is [30.66666666666666, 79.0, 1.0, 2.0, 0.6048589406435843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845254.6929803054, 845254.6929803054, 201655.3184220949], 
processed observation next is [0.0, 0.34782608695652173, 0.6524486571879934, 0.79, 1.0, 1.0, 0.5239264345103425, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23479297027230706, 0.23479297027230706, 0.3009780871971566], 
reward next is 0.6990, 
noisyNet noise sample is [array([1.7608029], dtype=float32), -0.05636609]. 
=============================================
[2019-03-26 14:31:53,338] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119475: loss 0.3401
[2019-03-26 14:31:53,340] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119475: learning rate 0.0000
[2019-03-26 14:31:53,674] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119631: loss 0.3388
[2019-03-26 14:31:53,676] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119631: learning rate 0.0000
[2019-03-26 14:31:53,905] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 119732: loss 0.3177
[2019-03-26 14:31:53,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 119733: learning rate 0.0000
[2019-03-26 14:31:53,922] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 119739: loss 0.3244
[2019-03-26 14:31:53,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 119740: learning rate 0.0000
[2019-03-26 14:31:54,047] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119798: loss 0.3231
[2019-03-26 14:31:54,050] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119798: learning rate 0.0000
[2019-03-26 14:31:54,159] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4701875e-25 1.0000000e+00 4.0313928e-22 1.4228268e-23 1.3887378e-31], sum to 1.0000
[2019-03-26 14:31:54,164] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119847: loss 0.3130
[2019-03-26 14:31:54,167] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2044
[2019-03-26 14:31:54,168] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119847: learning rate 0.0000
[2019-03-26 14:31:54,174] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5079805750720062, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709827.6556061554, 709827.655606156, 184855.410145665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4493400.0000, 
sim time next is 4494000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5075207329956939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709184.8798829295, 709184.8798829295, 184782.3339952629], 
processed observation next is [0.0, 0.0, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40665148553698055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19699579996748043, 0.19699579996748043, 0.27579452835113866], 
reward next is 0.7242, 
noisyNet noise sample is [array([1.652826], dtype=float32), -1.980004]. 
=============================================
[2019-03-26 14:31:54,196] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.53195 ]
 [76.74215 ]
 [76.860374]
 [76.808846]
 [76.74977 ]], R is [[76.3948822 ]
 [76.35503387]
 [76.31539154]
 [76.27571869]
 [76.23600769]].
[2019-03-26 14:31:54,414] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119969: loss 0.2677
[2019-03-26 14:31:54,416] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119969: learning rate 0.0000
[2019-03-26 14:31:54,533] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120024: loss 0.2661
[2019-03-26 14:31:54,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120025: loss 0.2417
[2019-03-26 14:31:54,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120025: learning rate 0.0000
[2019-03-26 14:31:54,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120026: learning rate 0.0000
[2019-03-26 14:31:54,760] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 120124: loss 0.2383
[2019-03-26 14:31:54,764] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 120124: learning rate 0.0000
[2019-03-26 14:31:54,821] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120158: loss 0.2353
[2019-03-26 14:31:54,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120158: learning rate 0.0000
[2019-03-26 14:31:54,845] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 120165: loss 0.2166
[2019-03-26 14:31:54,847] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 120165: learning rate 0.0000
[2019-03-26 14:31:54,972] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 120226: loss 0.2098
[2019-03-26 14:31:54,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 120226: learning rate 0.0000
[2019-03-26 14:31:54,992] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120233: loss 0.2176
[2019-03-26 14:31:54,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120234: learning rate 0.0000
[2019-03-26 14:31:55,194] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 120324: loss 0.1906
[2019-03-26 14:31:55,196] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 120324: learning rate 0.0000
[2019-03-26 14:31:55,346] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120393: loss 0.1977
[2019-03-26 14:31:55,350] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120394: learning rate 0.0000
[2019-03-26 14:32:02,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1612256e-05 8.7204188e-01 1.2602324e-05 1.2786393e-01 1.1296379e-09], sum to 1.0000
[2019-03-26 14:32:02,176] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5831
[2019-03-26 14:32:02,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2687124.428060991 W.
[2019-03-26 14:32:02,187] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 67.0, 1.0, 2.0, 0.9606534512047873, 1.0, 2.0, 0.9606534512047873, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2687124.428060991, 2687124.42806099, 505670.2203590749], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4636800.0000, 
sim time next is 4637400.0000, 
raw observation next is [32.66666666666666, 67.5, 1.0, 2.0, 1.032736988774444, 1.0, 2.0, 1.032736988774444, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2888988.491091643, 2888988.491091643, 549086.9919916821], 
processed observation next is [1.0, 0.6956521739130435, 0.7472353870458132, 0.675, 1.0, 1.0, 1.0394421551499324, 1.0, 1.0, 1.0394421551499324, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.8024968030810119, 0.8024968030810119, 0.8195328238681823], 
reward next is 0.1805, 
noisyNet noise sample is [array([0.44467422], dtype=float32), 0.83367056]. 
=============================================
[2019-03-26 14:32:04,438] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3330784e-21 1.0000000e+00 6.0173393e-19 5.7298355e-20 1.2794704e-27], sum to 1.0000
[2019-03-26 14:32:04,447] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1973
[2019-03-26 14:32:04,454] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.830988013210304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161429.53381116, 1161429.53381116, 251659.916831695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689600.0000, 
sim time next is 4690200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7939864652292251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1109687.335726188, 1109687.335726188, 242440.7364978558], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.7517909219629219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30824648214616335, 0.30824648214616335, 0.36185184551918775], 
reward next is 0.6381, 
noisyNet noise sample is [array([-0.12878375], dtype=float32), -0.08371179]. 
=============================================
[2019-03-26 14:32:04,576] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2498769e-23 1.0000000e+00 6.2958028e-20 2.0086001e-21 4.9778217e-29], sum to 1.0000
[2019-03-26 14:32:04,586] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9369
[2019-03-26 14:32:04,590] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.491204384838853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686377.8396673821, 686377.8396673815, 182229.1919985354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4665000.0000, 
sim time next is 4665600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.492324315942019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687943.2670588401, 687943.2670588401, 182401.8646252258], 
processed observation next is [1.0, 0.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.38834254932773365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19109535196078892, 0.19109535196078892, 0.2722415889928743], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.4937063], dtype=float32), 0.9839516]. 
=============================================
[2019-03-26 14:32:04,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.2105810e-21 1.0000000e+00 3.6603408e-18 5.0135024e-19 1.2054047e-26], sum to 1.0000
[2019-03-26 14:32:04,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4319
[2019-03-26 14:32:04,664] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 86.5, 1.0, 2.0, 0.9592886103637915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1340861.963088486, 1340861.963088486, 286767.4255070675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689000.0000, 
sim time next is 4689600.0000, 
raw observation next is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.830988013210304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161429.53381116, 1161429.53381116, 251659.916831695], 
processed observation next is [1.0, 0.2608695652173913, 0.5102685624012636, 0.8566666666666667, 1.0, 1.0, 0.7963711002533783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3226193149475444, 0.3226193149475444, 0.37561181616670897], 
reward next is 0.6244, 
noisyNet noise sample is [array([-0.76000595], dtype=float32), 0.127825]. 
=============================================
[2019-03-26 14:32:05,031] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 14:32:05,034] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:32:05,035] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:05,036] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:32:05,037] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:32:05,038] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:32:05,039] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:05,040] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:05,041] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:32:05,042] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:05,043] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:32:05,058] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 14:32:05,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 14:32:05,079] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 14:32:05,079] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 14:32:05,080] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 14:32:18,803] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:32:18,807] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.31634177666667, 90.12646189333334, 1.0, 2.0, 0.296415472563931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472757.7135366681, 472757.7135366681, 165119.0843676565]
[2019-03-26 14:32:18,808] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:32:18,811] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0604700e-22 1.0000000e+00 2.5577081e-19 4.7293510e-21 3.1229074e-28], sampled 0.41961725534441363
[2019-03-26 14:32:31,995] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:32:31,997] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.89102648, 86.58912184, 1.0, 2.0, 0.27229147355733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 448304.3049896435, 448304.3049896435, 163181.4848794286]
[2019-03-26 14:32:31,997] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:32,000] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4654611e-22 1.0000000e+00 6.5702196e-19 3.6340280e-20 9.4711110e-28], sampled 0.04832808172813241
[2019-03-26 14:32:35,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:32:35,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.3, 94.33333333333334, 1.0, 2.0, 0.4843040548891829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684274.8396376122, 684274.8396376122, 182142.2998436067]
[2019-03-26 14:32:35,135] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:32:35,137] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.4332789e-23 1.0000000e+00 1.1040461e-19 5.4701567e-21 5.7516429e-29], sampled 0.699736636675308
[2019-03-26 14:32:42,692] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:32:42,693] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.2907626, 92.67186866666665, 1.0, 2.0, 0.6124232402071147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 855829.6142546129, 855829.6142546124, 203082.6819042316]
[2019-03-26 14:32:42,694] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:32:42,697] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8395230e-23 1.0000000e+00 7.8975793e-20 4.4687011e-21 3.5098517e-29], sampled 0.36545573487387006
[2019-03-26 14:32:59,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:32:59,042] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.8955024469003753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564978379, 1251651.21244208, 1251651.21244208, 268699.9941978502]
[2019-03-26 14:32:59,043] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:32:59,046] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4187762e-22 1.0000000e+00 5.6455909e-19 3.5713336e-20 6.2797782e-28], sampled 0.7890495843830868
[2019-03-26 14:33:37,042] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05761505], dtype=float32), 0.046044435]
[2019-03-26 14:33:37,044] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.43333333333333, 90.66666666666667, 1.0, 2.0, 0.521970848881068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729383.7039258432, 729383.7039258427, 187110.2387879196]
[2019-03-26 14:33:37,045] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:33:37,049] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.9884669e-23 1.0000000e+00 1.8888588e-19 9.2967831e-21 9.8856178e-29], sampled 0.5588591741956958
[2019-03-26 14:34:02,168] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6638 3164060856.9608 1778.0000
[2019-03-26 14:34:02,234] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6295 2779256357.0602 933.0000
[2019-03-26 14:34:02,265] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:34:02,541] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2115 2927419164.9367 1338.0000
[2019-03-26 14:34:02,570] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 14:34:03,586] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 125000, evaluation results [125000.0, 7882.663803625938, 3164060856.960803, 1778.0, 8254.211531981859, 2927419164.936749, 1338.0, 8660.629516213334, 2779256357.0601926, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:34:09,054] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127513: loss -30.2533
[2019-03-26 14:34:09,056] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127513: learning rate 0.0000
[2019-03-26 14:34:09,401] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 127682: loss -16.1499
[2019-03-26 14:34:09,403] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 127682: learning rate 0.0000
[2019-03-26 14:34:09,529] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127743: loss 34.2319
[2019-03-26 14:34:09,532] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127744: learning rate 0.0000
[2019-03-26 14:34:09,646] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127803: loss -57.5955
[2019-03-26 14:34:09,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127803: learning rate 0.0000
[2019-03-26 14:34:09,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127833: loss -54.8977
[2019-03-26 14:34:09,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127833: learning rate 0.0000
[2019-03-26 14:34:09,862] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127899: loss 71.9336
[2019-03-26 14:34:09,863] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127899: loss 90.6121
[2019-03-26 14:34:09,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127899: learning rate 0.0000
[2019-03-26 14:34:09,865] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127899: learning rate 0.0000
[2019-03-26 14:34:10,070] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127991: loss 84.8886
[2019-03-26 14:34:10,072] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127991: learning rate 0.0000
[2019-03-26 14:34:10,191] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128044: loss -20.1312
[2019-03-26 14:34:10,194] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128045: learning rate 0.0000
[2019-03-26 14:34:10,301] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 128092: loss -57.1342
[2019-03-26 14:34:10,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 128092: learning rate 0.0000
[2019-03-26 14:34:10,410] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128144: loss 9.7767
[2019-03-26 14:34:10,413] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128145: learning rate 0.0000
[2019-03-26 14:34:10,484] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128177: loss -75.2520
[2019-03-26 14:34:10,487] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128177: learning rate 0.0000
[2019-03-26 14:34:10,518] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 128192: loss -51.6359
[2019-03-26 14:34:10,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 128192: learning rate 0.0000
[2019-03-26 14:34:10,553] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128206: loss 17.6147
[2019-03-26 14:34:10,557] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128206: learning rate 0.0000
[2019-03-26 14:34:11,126] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 128300: loss 53.4000
[2019-03-26 14:34:11,130] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 128300: learning rate 0.0000
[2019-03-26 14:34:11,224] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128344: loss -173.5704
[2019-03-26 14:34:11,227] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128344: learning rate 0.0000
[2019-03-26 14:34:18,937] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1618163e-09 9.9995863e-01 4.6680113e-09 4.1391726e-05 3.7356232e-13], sum to 1.0000
[2019-03-26 14:34:18,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5982
[2019-03-26 14:34:18,957] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1940260.783671588 W.
[2019-03-26 14:34:18,960] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7465428997129964, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.974488412440992, 6.9112, 168.9125253350419, 1940260.783671588, 1895361.920278203, 396149.1367304767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4964400.0000, 
sim time next is 4965000.0000, 
raw observation next is [30.03333333333333, 65.83333333333333, 1.0, 2.0, 0.6494785922722567, 1.0, 1.0, 0.6494785922722567, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1816030.679677544, 1816030.679677544, 353240.2491435509], 
processed observation next is [1.0, 0.4782608695652174, 0.622432859399684, 0.6583333333333333, 1.0, 1.0, 0.5776850509304298, 1.0, 0.5, 0.5776850509304298, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5044529665770955, 0.5044529665770955, 0.527224252453061], 
reward next is 0.4728, 
noisyNet noise sample is [array([2.3847775], dtype=float32), -1.3077992]. 
=============================================
[2019-03-26 14:34:18,974] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[24.713364]
 [24.641327]
 [25.703783]
 [26.163168]
 [29.408785]], R is [[24.6434288 ]
 [24.48928642]
 [24.2443943 ]
 [24.00195122]
 [23.76193237]].
[2019-03-26 14:34:19,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2412448e-19 1.0000000e+00 1.5524074e-17 9.8754311e-16 6.6675071e-25], sum to 1.0000
[2019-03-26 14:34:19,872] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4772
[2019-03-26 14:34:19,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3227705.609209482 W.
[2019-03-26 14:34:19,885] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 9.410357623260555, 6.9112, 168.8985381075596, 3227705.609209482, 1454868.519119384, 308148.565598272], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4954800.0000, 
sim time next is 4955400.0000, 
raw observation next is [29.5, 70.0, 1.0, 2.0, 0.5593861427828583, 1.0, 1.0, 0.5593861427828583, 1.0, 1.0, 0.9587939658121474, 6.911199999999999, 6.9112, 170.5573041426782, 2346739.575889118, 2346739.575889118, 456032.8516546953], 
processed observation next is [1.0, 0.34782608695652173, 0.5971563981042655, 0.7, 1.0, 1.0, 0.4691399310636846, 1.0, 0.5, 0.4691399310636846, 1.0, 0.5, 0.9497487387953016, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6518721044136438, 0.6518721044136438, 0.6806460472458139], 
reward next is 0.3194, 
noisyNet noise sample is [array([0.57895756], dtype=float32), -0.35131368]. 
=============================================
[2019-03-26 14:34:26,928] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135470: loss 1.2693
[2019-03-26 14:34:26,930] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135470: learning rate 0.0000
[2019-03-26 14:34:27,353] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 135661: loss 1.2230
[2019-03-26 14:34:27,355] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 135663: learning rate 0.0000
[2019-03-26 14:34:27,477] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135719: loss 1.2195
[2019-03-26 14:34:27,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135719: learning rate 0.0000
[2019-03-26 14:34:27,588] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135768: loss 1.2127
[2019-03-26 14:34:27,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135770: learning rate 0.0000
[2019-03-26 14:34:27,668] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135806: loss 1.1643
[2019-03-26 14:34:27,670] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135806: learning rate 0.0000
[2019-03-26 14:34:27,782] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135856: loss 1.1895
[2019-03-26 14:34:27,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135857: learning rate 0.0000
[2019-03-26 14:34:27,844] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135882: loss 1.1570
[2019-03-26 14:34:27,847] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135882: learning rate 0.0000
[2019-03-26 14:34:28,150] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 136026: loss 1.1483
[2019-03-26 14:34:28,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 136026: learning rate 0.0000
[2019-03-26 14:34:28,162] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136031: loss 1.1064
[2019-03-26 14:34:28,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136031: learning rate 0.0000
[2019-03-26 14:34:28,206] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136051: loss 1.1105
[2019-03-26 14:34:28,212] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136052: learning rate 0.0000
[2019-03-26 14:34:28,433] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136152: loss 1.0702
[2019-03-26 14:34:28,435] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136152: learning rate 0.0000
[2019-03-26 14:34:28,610] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136231: loss 0.9659
[2019-03-26 14:34:28,612] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136232: learning rate 0.0000
[2019-03-26 14:34:28,652] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 136255: loss 0.9879
[2019-03-26 14:34:28,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 136256: learning rate 0.0000
[2019-03-26 14:34:28,727] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136286: loss 0.9535
[2019-03-26 14:34:28,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136286: learning rate 0.0000
[2019-03-26 14:34:28,743] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136291: loss 0.9595
[2019-03-26 14:34:28,744] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136291: learning rate 0.0000
[2019-03-26 14:34:28,753] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 136294: loss 0.9349
[2019-03-26 14:34:28,756] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 136295: learning rate 0.0000
[2019-03-26 14:34:31,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1350015e-25 1.0000000e+00 1.3332822e-22 2.0281257e-21 2.2188582e-31], sum to 1.0000
[2019-03-26 14:34:31,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0355
[2019-03-26 14:34:31,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.52713651146288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736604.5218805672, 736604.5218805678, 187956.8702118441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5166000.0000, 
sim time next is 5166600.0000, 
raw observation next is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5311699439436665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742242.6868791814, 742242.6868791814, 188623.3436413643], 
processed observation next is [0.0, 0.8260869565217391, 0.5655608214849924, 0.7483333333333334, 1.0, 1.0, 0.4351445107755017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20617852413310594, 0.20617852413310594, 0.28152737856920046], 
reward next is 0.7185, 
noisyNet noise sample is [array([-1.5164986], dtype=float32), -0.3888407]. 
=============================================
[2019-03-26 14:34:42,976] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.9168582e-22 1.0000000e+00 1.1914650e-20 4.3475564e-19 1.6123798e-29], sum to 1.0000
[2019-03-26 14:34:42,992] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1733
[2019-03-26 14:34:42,997] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 86.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.41401588712133, 6.9112, 170.3810597889865, 4677914.128340551, 1455697.048234397, 301122.304110757], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5364600.0000, 
sim time next is 5365200.0000, 
raw observation next is [29.2, 87.0, 1.0, 2.0, 0.6803475333278061, 1.0, 1.0, 0.6607638061781657, 1.0, 1.0, 1.03, 7.005096182628445, 6.9112, 170.5573041426782, 2772511.527075974, 2705249.87200671, 515193.8932437238], 
processed observation next is [1.0, 0.08695652173913043, 0.5829383886255924, 0.87, 1.0, 1.0, 0.6148765461780796, 1.0, 0.5, 0.591281694190561, 1.0, 0.5, 1.0365853658536586, 0.00938961826284448, 0.0, 0.8375144448122397, 0.7701420908544372, 0.7514582977796417, 0.7689461093189908], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5392742], dtype=float32), -2.232011]. 
=============================================
[2019-03-26 14:34:44,113] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0032511e-17 1.0000000e+00 5.3909101e-17 2.4492165e-13 1.5774751e-23], sum to 1.0000
[2019-03-26 14:34:44,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-26 14:34:44,133] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 86.0, 1.0, 2.0, 0.8926081449586144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247603.445734231, 1247603.445734231, 267918.0238272033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5378400.0000, 
sim time next is 5379000.0000, 
raw observation next is [29.68333333333334, 84.83333333333334, 1.0, 2.0, 0.9271896082850597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295967.652439482, 1295967.652439482, 277531.9163570409], 
processed observation next is [1.0, 0.2608695652173913, 0.6058451816745659, 0.8483333333333334, 1.0, 1.0, 0.9122766364880237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35999101456652277, 0.35999101456652277, 0.41422674083140426], 
reward next is 0.5858, 
noisyNet noise sample is [array([-0.30632097], dtype=float32), -0.024788478]. 
=============================================
[2019-03-26 14:34:44,143] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[54.089764]
 [51.862343]
 [50.138653]
 [47.892437]
 [46.311195]], R is [[55.04757309]
 [55.09721756]
 [55.15035629]
 [55.20654678]
 [55.26420593]].
[2019-03-26 14:34:44,727] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143567: loss -143.7581
[2019-03-26 14:34:44,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143567: learning rate 0.0000
[2019-03-26 14:34:44,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6426076e-14 1.0000000e+00 4.8768888e-14 2.4991376e-10 1.9854058e-19], sum to 1.0000
[2019-03-26 14:34:44,960] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5374
[2019-03-26 14:34:44,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2605646.149812829 W.
[2019-03-26 14:34:44,973] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.16666666666667, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.364625972061719, 6.9112, 168.9107220827573, 2605646.149812829, 2283974.41473434, 475117.8570178189], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5386800.0000, 
sim time next is 5387400.0000, 
raw observation next is [32.35, 70.5, 1.0, 2.0, 0.9321982476322972, 1.0, 1.0, 0.9321982476322972, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2607446.931711967, 2607446.931711966, 489371.1769817273], 
processed observation next is [1.0, 0.34782608695652173, 0.7322274881516588, 0.705, 1.0, 1.0, 0.9183111417256593, 1.0, 0.5, 0.9183111417256593, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7242908143644353, 0.7242908143644351, 0.7304047417637721], 
reward next is 0.2696, 
noisyNet noise sample is [array([-1.4539292], dtype=float32), 0.30268276]. 
=============================================
[2019-03-26 14:34:45,094] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143730: loss -227.7796
[2019-03-26 14:34:45,097] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143730: learning rate 0.0000
[2019-03-26 14:34:45,199] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 143777: loss -202.1509
[2019-03-26 14:34:45,200] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 143777: learning rate 0.0000
[2019-03-26 14:34:45,371] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143855: loss -266.5041
[2019-03-26 14:34:45,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143855: learning rate 0.0000
[2019-03-26 14:34:45,375] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143856: loss -261.3593
[2019-03-26 14:34:45,378] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143856: learning rate 0.0000
[2019-03-26 14:34:45,425] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143879: loss -274.2615
[2019-03-26 14:34:45,427] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143879: learning rate 0.0000
[2019-03-26 14:34:45,472] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143895: loss -208.3860
[2019-03-26 14:34:45,478] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143898: learning rate 0.0000
[2019-03-26 14:34:45,764] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144028: loss -229.2451
[2019-03-26 14:34:45,766] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144029: learning rate 0.0000
[2019-03-26 14:34:45,805] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 144049: loss -175.6376
[2019-03-26 14:34:45,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 144049: learning rate 0.0000
[2019-03-26 14:34:45,830] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144059: loss -205.7632
[2019-03-26 14:34:45,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144060: learning rate 0.0000
[2019-03-26 14:34:46,042] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144155: loss -174.8308
[2019-03-26 14:34:46,044] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144155: learning rate 0.0000
[2019-03-26 14:34:46,161] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144210: loss -222.2587
[2019-03-26 14:34:46,162] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144210: learning rate 0.0000
[2019-03-26 14:34:46,177] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 144217: loss -215.7639
[2019-03-26 14:34:46,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 144218: learning rate 0.0000
[2019-03-26 14:34:46,193] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144226: loss -256.4117
[2019-03-26 14:34:46,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144227: learning rate 0.0000
[2019-03-26 14:34:46,220] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144236: loss -224.8145
[2019-03-26 14:34:46,223] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144236: learning rate 0.0000
[2019-03-26 14:34:46,232] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144238: loss -228.6589
[2019-03-26 14:34:46,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144239: learning rate 0.0000
[2019-03-26 14:34:46,771] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5289816e-07 1.6857908e-04 2.6850136e-10 9.9983120e-01 3.5905765e-13], sum to 1.0000
[2019-03-26 14:34:46,782] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2040
[2019-03-26 14:34:46,787] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.63333333333333, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.378510474780547, 6.9112, 170.5573041426782, 3244473.166500597, 2909719.664440535, 551151.0036240793], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5409600.0000, 
sim time next is 5410200.0000, 
raw observation next is [37.81666666666666, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 8.283223966590468, 6.9112, 170.5573041426782, 3893311.374966711, 2910474.797331292, 545354.1204245898], 
processed observation next is [1.0, 0.6086956521739131, 0.9913112164296997, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.13720239665904677, 0.0, 0.8375144448122397, 1.0814753819351974, 0.8084652214809145, 0.8139613737680446], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0573794], dtype=float32), 0.3685641]. 
=============================================
[2019-03-26 14:34:48,413] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8597910e-19 1.0000000e+00 1.3672433e-17 8.4103468e-16 4.2363472e-25], sum to 1.0000
[2019-03-26 14:34:48,420] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8753
[2019-03-26 14:34:48,428] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 92.0, 1.0, 2.0, 0.9599290269340075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956505208, 1341757.681915621, 1341757.681915621, 286957.8360892653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5455800.0000, 
sim time next is 5456400.0000, 
raw observation next is [27.76666666666667, 92.0, 1.0, 2.0, 0.9533816800144631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104297, 1332600.268824101, 1332600.268824101, 285046.8811393778], 
processed observation next is [1.0, 0.13043478260869565, 0.515007898894155, 0.92, 1.0, 1.0, 0.9438333494150158, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451522962, 0.370166741340028, 0.370166741340028, 0.42544310617817577], 
reward next is 0.5746, 
noisyNet noise sample is [array([-0.33822733], dtype=float32), -0.3087305]. 
=============================================
[2019-03-26 14:34:50,577] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0043008e-06 7.1719623e-01 1.5722083e-08 2.8280279e-01 2.9255079e-12], sum to 1.0000
[2019-03-26 14:34:50,585] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2532
[2019-03-26 14:34:50,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2691473.918431978 W.
[2019-03-26 14:34:50,600] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.09999999999999, 54.0, 1.0, 2.0, 0.9622067313359604, 1.0, 2.0, 0.9622067313359604, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2691473.918431978, 2691473.918431978, 506575.2293391702], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5488800.0000, 
sim time next is 5489400.0000, 
raw observation next is [36.2, 53.0, 1.0, 2.0, 0.950823110050024, 1.0, 2.0, 0.950823110050024, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2659597.887366707, 2659597.887366707, 499986.2185897041], 
processed observation next is [1.0, 0.5217391304347826, 0.9146919431279622, 0.53, 1.0, 1.0, 0.9407507350000288, 1.0, 1.0, 0.9407507350000288, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7387771909351963, 0.7387771909351963, 0.7462480874473195], 
reward next is 0.2538, 
noisyNet noise sample is [array([0.24995723], dtype=float32), 0.95986253]. 
=============================================
[2019-03-26 14:34:53,118] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1034091e-23 1.0000000e+00 8.3678548e-22 6.2545307e-21 7.1228902e-31], sum to 1.0000
[2019-03-26 14:34:53,127] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7301
[2019-03-26 14:34:53,131] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.78333333333333, 91.66666666666667, 1.0, 2.0, 0.5448151806217578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761317.0090949184, 761317.0090949184, 190915.3531416722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5532600.0000, 
sim time next is 5533200.0000, 
raw observation next is [26.7, 92.0, 1.0, 2.0, 0.5432124238834983, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759076.5392937129, 759076.5392937136, 190643.3372058023], 
processed observation next is [1.0, 0.043478260869565216, 0.46445497630331756, 0.92, 1.0, 1.0, 0.4496535227512028, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2108545942482536, 0.21085459424825378, 0.28454229433701833], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.29417947], dtype=float32), 1.9184203]. 
=============================================
[2019-03-26 14:34:54,236] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9390113e-21 1.0000000e+00 6.6982430e-20 9.7796373e-18 2.0346676e-27], sum to 1.0000
[2019-03-26 14:34:54,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6560
[2019-03-26 14:34:54,250] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 95.0, 1.0, 2.0, 0.6998789823207824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 978100.7408167449, 978100.7408167449, 220818.0815244658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5545200.0000, 
sim time next is 5545800.0000, 
raw observation next is [25.7, 95.0, 1.0, 2.0, 0.680513616185878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 951024.9742693322, 951024.9742693322, 216694.2386626063], 
processed observation next is [1.0, 0.17391304347826086, 0.4170616113744076, 0.95, 1.0, 1.0, 0.6150766460070819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26417360396370343, 0.26417360396370343, 0.32342423680986015], 
reward next is 0.6766, 
noisyNet noise sample is [array([-0.7640128], dtype=float32), 1.5274951]. 
=============================================
[2019-03-26 14:34:54,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.3306847e-21 1.0000000e+00 5.5497350e-20 2.2885652e-18 1.3763515e-28], sum to 1.0000
[2019-03-26 14:34:54,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4240
[2019-03-26 14:34:54,349] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333333, 91.66666666666667, 1.0, 2.0, 0.6955827965759316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 972093.9514108831, 972093.9514108831, 219894.0566086252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550000.0000, 
sim time next is 5550600.0000, 
raw observation next is [26.51666666666667, 90.83333333333333, 1.0, 2.0, 0.6981871930302358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 975735.3311223818, 975735.3311223811, 220453.9923531722], 
processed observation next is [1.0, 0.21739130434782608, 0.45576619273301755, 0.9083333333333333, 1.0, 1.0, 0.6363701120846215, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2710375919784394, 0.2710375919784392, 0.32903580948234656], 
reward next is 0.6710, 
noisyNet noise sample is [array([-1.027977], dtype=float32), 0.32536405]. 
=============================================
[2019-03-26 14:34:56,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4038680e-07 8.5337806e-01 6.7883704e-10 1.4662185e-01 2.0932675e-13], sum to 1.0000
[2019-03-26 14:34:56,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2069
[2019-03-26 14:34:56,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2479800.208394651 W.
[2019-03-26 14:34:56,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.0, 55.0, 1.0, 2.0, 0.8866080241152124, 1.0, 1.0, 0.8866080241152124, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2479800.208394651, 2479800.208394651, 464231.9046809516], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5590800.0000, 
sim time next is 5591400.0000, 
raw observation next is [32.73333333333333, 56.66666666666667, 1.0, 2.0, 0.3790263498698481, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6483607562500439, 6.9112, 6.9112, 168.9129564480483, 1059440.71564675, 1059440.71564675, 249436.8315147854], 
processed observation next is [1.0, 0.7391304347826086, 0.7503949447077406, 0.5666666666666668, 1.0, 1.0, 0.25183897574680497, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.571171653963468, 0.0, 0.0, 0.829439944845975, 0.2942890876796528, 0.2942890876796528, 0.3722937783802767], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2575904], dtype=float32), -0.3196126]. 
=============================================
[2019-03-26 14:34:58,631] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 14:34:58,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:34:58,635] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:34:58,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:58,636] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:58,639] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:34:58,640] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:34:58,641] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:58,642] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:58,642] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:34:58,645] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:34:58,662] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 14:34:58,662] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 14:34:58,663] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 14:34:58,715] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 14:34:58,717] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 14:35:09,812] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05716632], dtype=float32), 0.046744242]
[2019-03-26 14:35:09,813] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.78583112666667, 85.76588319333334, 1.0, 2.0, 0.2174096175018183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 363240.6113138541, 363240.6113138535, 156934.0570762009]
[2019-03-26 14:35:09,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:35:09,819] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7871094e-25 1.0000000e+00 1.6785539e-23 6.5340894e-23 1.4843437e-32], sampled 0.0994526465603156
[2019-03-26 14:35:25,487] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05716632], dtype=float32), 0.046744242]
[2019-03-26 14:35:25,489] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.13002204666667, 96.29783819, 1.0, 2.0, 0.453298134610858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 643141.7890210875, 643141.7890210869, 177860.587749257]
[2019-03-26 14:35:25,490] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:35:25,492] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0787702e-24 1.0000000e+00 1.6761233e-22 5.6571157e-22 4.1054009e-31], sampled 0.349880020825747
[2019-03-26 14:35:32,224] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05716632], dtype=float32), 0.046744242]
[2019-03-26 14:35:32,225] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.25321371166667, 81.95409790166667, 1.0, 2.0, 0.6841920601629405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 956167.9527829997, 956167.952782999, 217478.7522083197]
[2019-03-26 14:35:32,225] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:35:32,228] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9842766e-20 1.0000000e+00 2.5586059e-19 9.6862287e-17 7.2649983e-27], sampled 0.43300223807229987
[2019-03-26 14:36:10,714] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05716632], dtype=float32), 0.046744242]
[2019-03-26 14:36:10,715] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.83333333333334, 66.66666666666667, 1.0, 2.0, 0.3900085862193409, 1.0, 1.0, 0.3900085862193409, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1090148.226727942, 1090148.226727942, 269641.6424924176]
[2019-03-26 14:36:10,717] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:36:10,722] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.8802659e-11 9.9995232e-01 5.6775643e-12 4.7664278e-05 3.7398712e-16], sampled 0.49779799953920645
[2019-03-26 14:36:55,137] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:36:55,839] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.7302 2927535871.0724 1338.0000
[2019-03-26 14:36:55,930] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 14:36:56,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779131868.1217 933.0000
[2019-03-26 14:36:56,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.2253 3164120151.8207 1776.0000
[2019-03-26 14:36:57,084] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 150000, evaluation results [150000.0, 7885.225315249419, 3164120151.8207436, 1776.0, 8252.73018341409, 2927535871.0724225, 1338.0, 8659.98775396918, 2779131868.121704, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 14:36:57,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.9451270e-26 1.0000000e+00 2.1892637e-23 6.9205922e-23 2.6593244e-32], sum to 1.0000
[2019-03-26 14:36:57,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7427
[2019-03-26 14:36:58,005] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666666, 75.0, 1.0, 2.0, 0.531538149414752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742757.3872545608, 742757.3872545602, 188685.3781932706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5647200.0000, 
sim time next is 5647800.0000, 
raw observation next is [29.33333333333334, 74.5, 1.0, 2.0, 0.5343508299725349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746689.1342887529, 746689.1342887529, 189153.5522643041], 
processed observation next is [0.0, 0.34782608695652173, 0.5892575039494474, 0.745, 1.0, 1.0, 0.4389769035813673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20741364841354248, 0.20741364841354248, 0.28231873472284197], 
reward next is 0.7177, 
noisyNet noise sample is [array([-0.23617013], dtype=float32), 1.5665381]. 
=============================================
[2019-03-26 14:37:00,305] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151483: loss 0.0006
[2019-03-26 14:37:00,308] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151483: learning rate 0.0000
[2019-03-26 14:37:00,743] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151685: loss 0.0029
[2019-03-26 14:37:00,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151686: learning rate 0.0000
[2019-03-26 14:37:00,997] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151801: loss 0.0050
[2019-03-26 14:37:00,999] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151802: learning rate 0.0000
[2019-03-26 14:37:01,003] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151802: loss 0.0052
[2019-03-26 14:37:01,006] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151802: learning rate 0.0000
[2019-03-26 14:37:01,089] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151843: loss 0.0045
[2019-03-26 14:37:01,091] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151843: learning rate 0.0000
[2019-03-26 14:37:01,109] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151854: loss 0.0076
[2019-03-26 14:37:01,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151855: learning rate 0.0000
[2019-03-26 14:37:01,142] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151867: loss 0.0062
[2019-03-26 14:37:01,144] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151867: learning rate 0.0000
[2019-03-26 14:37:01,521] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152043: loss 0.0060
[2019-03-26 14:37:01,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152044: learning rate 0.0000
[2019-03-26 14:37:01,555] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 152057: loss 0.0060
[2019-03-26 14:37:01,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 152057: learning rate 0.0000
[2019-03-26 14:37:01,577] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152067: loss 0.0063
[2019-03-26 14:37:01,579] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152067: learning rate 0.0000
[2019-03-26 14:37:01,649] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152101: loss 0.0049
[2019-03-26 14:37:01,651] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152102: learning rate 0.0000
[2019-03-26 14:37:01,781] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152163: loss 0.0008
[2019-03-26 14:37:01,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152163: learning rate 0.0000
[2019-03-26 14:37:01,860] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152198: loss 0.0010
[2019-03-26 14:37:01,868] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152198: learning rate 0.0000
[2019-03-26 14:37:01,980] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152253: loss 0.0001
[2019-03-26 14:37:01,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152253: learning rate 0.0000
[2019-03-26 14:37:01,983] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152253: loss 0.0001
[2019-03-26 14:37:01,986] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152253: learning rate 0.0000
[2019-03-26 14:37:02,076] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152299: loss 0.0006
[2019-03-26 14:37:02,080] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152299: learning rate 0.0000
[2019-03-26 14:37:07,868] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9603297e-22 1.0000000e+00 3.2569360e-21 2.9301568e-19 3.2345617e-29], sum to 1.0000
[2019-03-26 14:37:07,876] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4571
[2019-03-26 14:37:07,880] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 83.0, 1.0, 2.0, 0.8977171774923044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1254748.588977918, 1254748.588977918, 269311.1353555602], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5814000.0000, 
sim time next is 5814600.0000, 
raw observation next is [28.28333333333333, 82.16666666666667, 1.0, 2.0, 0.8528473451741722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1191998.355556287, 1191998.355556287, 257297.132162842], 
processed observation next is [1.0, 0.30434782608695654, 0.5394944707740915, 0.8216666666666668, 1.0, 1.0, 0.8227076447881592, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33111065432119086, 0.33111065432119086, 0.3840255703923015], 
reward next is 0.6160, 
noisyNet noise sample is [array([-0.89787173], dtype=float32), -0.5064968]. 
=============================================
[2019-03-26 14:37:09,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.10087356e-07 8.17945898e-01 3.42406048e-10 1.82053983e-01
 7.31774870e-14], sum to 1.0000
[2019-03-26 14:37:09,938] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5477
[2019-03-26 14:37:09,945] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2822088.701973331 W.
[2019-03-26 14:37:09,948] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.8, 61.33333333333334, 1.0, 2.0, 1.008849066923407, 1.0, 2.0, 1.008849066923407, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2822088.701973331, 2822088.701973331, 534353.4564027218], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5840400.0000, 
sim time next is 5841000.0000, 
raw observation next is [32.75, 61.5, 1.0, 2.0, 0.7354733463761666, 1.0, 2.0, 0.6883267127023459, 1.0, 1.0, 1.03, 7.005100529363059, 6.9112, 170.5573041426782, 2888296.956886951, 2821032.18807487, 532766.7021133624], 
processed observation next is [1.0, 0.6086956521739131, 0.7511848341232228, 0.615, 1.0, 1.0, 0.68129318840502, 1.0, 1.0, 0.6244900153040313, 1.0, 0.5, 1.0365853658536586, 0.009390052936305881, 0.0, 0.8375144448122397, 0.8023047102463753, 0.7836200522430194, 0.7951741822587498], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05361125], dtype=float32), -0.310764]. 
=============================================
[2019-03-26 14:37:09,963] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[25.987392]
 [25.550255]
 [24.765665]
 [24.042229]
 [24.1129  ]], R is [[22.80567741]
 [22.78007889]
 [22.78418922]
 [22.55634689]
 [22.33078384]].
[2019-03-26 14:37:17,982] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 159543: loss -295.5319
[2019-03-26 14:37:17,986] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 159543: learning rate 0.0000
[2019-03-26 14:37:18,440] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159744: loss -385.2832
[2019-03-26 14:37:18,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159744: learning rate 0.0000
[2019-03-26 14:37:18,549] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159798: loss -331.8006
[2019-03-26 14:37:18,551] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159799: learning rate 0.0000
[2019-03-26 14:37:18,672] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159851: loss -461.5646
[2019-03-26 14:37:18,673] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159851: learning rate 0.0000
[2019-03-26 14:37:18,749] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159886: loss -238.5575
[2019-03-26 14:37:18,750] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159886: learning rate 0.0000
[2019-03-26 14:37:18,791] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159902: loss -452.4519
[2019-03-26 14:37:18,793] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159902: learning rate 0.0000
[2019-03-26 14:37:18,826] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159917: loss -362.1797
[2019-03-26 14:37:18,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159917: learning rate 0.0000
[2019-03-26 14:37:19,065] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160025: loss -253.2737
[2019-03-26 14:37:19,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160025: learning rate 0.0000
[2019-03-26 14:37:19,121] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 160047: loss -320.8755
[2019-03-26 14:37:19,125] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 160049: learning rate 0.0000
[2019-03-26 14:37:19,133] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 160053: loss -212.7393
[2019-03-26 14:37:19,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 160055: learning rate 0.0000
[2019-03-26 14:37:19,277] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160119: loss -80.6008
[2019-03-26 14:37:19,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160119: learning rate 0.0000
[2019-03-26 14:37:19,280] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160120: loss -422.5347
[2019-03-26 14:37:19,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160120: learning rate 0.0000
[2019-03-26 14:37:19,309] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160132: loss -276.6291
[2019-03-26 14:37:19,310] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160132: learning rate 0.0000
[2019-03-26 14:37:19,374] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 160160: loss -76.5004
[2019-03-26 14:37:19,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 160161: learning rate 0.0000
[2019-03-26 14:37:19,415] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 160182: loss -613.5117
[2019-03-26 14:37:19,417] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 160184: learning rate 0.0000
[2019-03-26 14:37:19,693] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160305: loss -296.4126
[2019-03-26 14:37:19,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160306: learning rate 0.0000
[2019-03-26 14:37:20,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4052363e-07 1.5480773e-01 7.3078843e-10 8.4519207e-01 5.5956005e-13], sum to 1.0000
[2019-03-26 14:37:20,800] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4529
[2019-03-26 14:37:20,806] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.16666666666667, 66.83333333333333, 1.0, 2.0, 0.5628701715434372, 1.0, 2.0, 0.5628701715434372, 1.0, 1.0, 0.9775193439607738, 6.9112, 6.9112, 170.5573041426782, 2361369.600416239, 2361369.600416239, 461343.9130341467], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.7688051366920536, 1.0, 2.0, 0.7688051366920536, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2150018.762870055, 2150018.762870055, 404968.8653575142], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.7214519719181369, 1.0, 1.0, 0.7214519719181369, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5972274341305709, 0.5972274341305709, 0.604431142324648], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2289311], dtype=float32), -0.7745036]. 
=============================================
[2019-03-26 14:37:22,760] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5015355e-22 1.0000000e+00 8.1634184e-22 1.0190251e-19 6.8336034e-30], sum to 1.0000
[2019-03-26 14:37:22,766] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1524
[2019-03-26 14:37:22,770] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 92.5, 1.0, 2.0, 0.5283083874730912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738242.6348016327, 738242.6348016327, 188150.3274603031], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6053400.0000, 
sim time next is 6054000.0000, 
raw observation next is [26.26666666666667, 92.66666666666667, 1.0, 2.0, 0.5280370825265823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737863.3895590453, 737863.3895590453, 188105.5431718198], 
processed observation next is [1.0, 0.043478260869565216, 0.44391785150079005, 0.9266666666666667, 1.0, 1.0, 0.4313699789476895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20496205265529036, 0.20496205265529036, 0.28075454204749223], 
reward next is 0.7192, 
noisyNet noise sample is [array([-2.1028705], dtype=float32), -0.4448817]. 
=============================================
[2019-03-26 14:37:22,800] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.632442]
 [63.85099 ]
 [63.96715 ]
 [64.14743 ]
 [64.40599 ]], R is [[63.50888443]
 [63.5929718 ]
 [63.67608261]
 [63.75814438]
 [63.83922195]].
[2019-03-26 14:37:22,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.5218995e-21 1.0000000e+00 6.7316681e-21 6.8271310e-18 2.4077338e-28], sum to 1.0000
[2019-03-26 14:37:22,941] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8133
[2019-03-26 14:37:22,948] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 93.0, 1.0, 2.0, 0.6885700099204555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 962288.9705507327, 962288.9705507327, 218396.8103466938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [26.13333333333333, 93.0, 1.0, 2.0, 0.6632363931908579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 926869.336305587, 926869.3363055864, 213109.3370941949], 
processed observation next is [1.0, 0.13043478260869565, 0.43759873617693507, 0.93, 1.0, 1.0, 0.5942607146877806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2574637045293297, 0.25746370452932954, 0.31807363745402223], 
reward next is 0.6819, 
noisyNet noise sample is [array([0.4832965], dtype=float32), 0.6179681]. 
=============================================
[2019-03-26 14:37:23,441] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0678555e-13 1.0000000e+00 1.6656555e-13 7.5688664e-09 1.1993094e-18], sum to 1.0000
[2019-03-26 14:37:23,450] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0903
[2019-03-26 14:37:23,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2050541.806573764 W.
[2019-03-26 14:37:23,465] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.06666666666667, 71.0, 1.0, 2.0, 0.4888454089862923, 1.0, 2.0, 0.4888454089862923, 1.0, 1.0, 0.8459278814990954, 6.9112, 6.9112, 170.5573041426782, 2050541.806573764, 2050541.806573764, 406984.334464595], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6083400.0000, 
sim time next is 6084000.0000, 
raw observation next is [30.2, 70.0, 1.0, 2.0, 0.9181132954480566, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.992426023863043, 6.9112, 168.9124732266119, 2180390.405291701, 2122766.033251205, 439635.5902956444], 
processed observation next is [1.0, 0.43478260869565216, 0.6303317535545023, 0.7, 1.0, 1.0, 0.9013413198169357, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008122602386304311, 0.0, 0.8294375720075026, 0.605664001469917, 0.5896572314586681, 0.65617252282932], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7465284], dtype=float32), -0.78363585]. 
=============================================
[2019-03-26 14:37:23,487] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[35.023273]
 [38.81645 ]
 [40.133965]
 [41.673634]
 [43.205795]], R is [[33.57213211]
 [33.6289711 ]
 [33.71800613]
 [33.82007217]
 [33.93715286]].
[2019-03-26 14:37:29,197] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9600772e-07 3.4865475e-01 1.0852770e-08 6.5134490e-01 9.2848697e-12], sum to 1.0000
[2019-03-26 14:37:29,209] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-26 14:37:29,216] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1954729.390829089 W.
[2019-03-26 14:37:29,222] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.46666666666667, 76.0, 1.0, 2.0, 0.466024724104293, 1.0, 2.0, 0.466024724104293, 1.0, 1.0, 0.8089774342746251, 6.911200000000001, 6.9112, 170.5573041426782, 1954729.390829089, 1954729.390829088, 392387.5495676657], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6175200.0000, 
sim time next is 6175800.0000, 
raw observation next is [29.55, 75.5, 1.0, 2.0, 0.8238605063009188, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.997326572040913, 6.9112, 168.9124440071724, 2048467.641654377, 1987366.672589337, 414145.7423112449], 
processed observation next is [1.0, 0.4782608695652174, 0.5995260663507109, 0.755, 1.0, 1.0, 0.7877837425312274, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008612657204091257, 0.0, 0.829437428526678, 0.5690187893484381, 0.5520462979414825, 0.618127973598873], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1717902], dtype=float32), -0.1449079]. 
=============================================
[2019-03-26 14:37:35,599] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 167551: loss 0.0013
[2019-03-26 14:37:35,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 167551: learning rate 0.0000
[2019-03-26 14:37:36,054] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167716: loss 0.0018
[2019-03-26 14:37:36,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167718: learning rate 0.0000
[2019-03-26 14:37:36,141] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167754: loss 0.0021
[2019-03-26 14:37:36,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167754: learning rate 0.0000
[2019-03-26 14:37:36,201] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167783: loss 0.0034
[2019-03-26 14:37:36,206] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167784: learning rate 0.0000
[2019-03-26 14:37:36,259] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167811: loss 0.0046
[2019-03-26 14:37:36,261] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167811: learning rate 0.0000
[2019-03-26 14:37:36,520] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167929: loss 0.0033
[2019-03-26 14:37:36,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167929: learning rate 0.0000
[2019-03-26 14:37:36,590] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167958: loss 0.0047
[2019-03-26 14:37:36,597] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167959: learning rate 0.0000
[2019-03-26 14:37:36,662] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7705786e-26 1.0000000e+00 9.1606995e-25 3.7052166e-23 7.1572797e-34], sum to 1.0000
[2019-03-26 14:37:36,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5078
[2019-03-26 14:37:36,677] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333334, 84.16666666666667, 1.0, 2.0, 0.5360409041515483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749051.6364257411, 749051.6364257406, 189435.3205819243], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6297000.0000, 
sim time next is 6297600.0000, 
raw observation next is [27.56666666666667, 84.33333333333334, 1.0, 2.0, 0.5373380642153414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750864.899704013, 750864.8997040137, 189652.5980651308], 
processed observation next is [0.0, 0.9130434782608695, 0.505529225908373, 0.8433333333333334, 1.0, 1.0, 0.44257598098233897, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20857358325111472, 0.2085735832511149, 0.28306357920168773], 
reward next is 0.7169, 
noisyNet noise sample is [array([1.423333], dtype=float32), -0.2133351]. 
=============================================
[2019-03-26 14:37:36,713] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168012: loss 0.0041
[2019-03-26 14:37:36,719] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168012: learning rate 0.0000
[2019-03-26 14:37:36,745] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168027: loss 0.0062
[2019-03-26 14:37:36,747] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168028: learning rate 0.0000
[2019-03-26 14:37:36,804] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 168054: loss 0.0023
[2019-03-26 14:37:36,807] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 168056: learning rate 0.0000
[2019-03-26 14:37:36,911] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168104: loss 0.0020
[2019-03-26 14:37:36,916] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168104: learning rate 0.0000
[2019-03-26 14:37:37,010] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168149: loss 0.0017
[2019-03-26 14:37:37,011] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168149: learning rate 0.0000
[2019-03-26 14:37:37,019] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168152: loss 0.0026
[2019-03-26 14:37:37,024] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168154: learning rate 0.0000
[2019-03-26 14:37:37,141] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 168210: loss 0.0006
[2019-03-26 14:37:37,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 168211: learning rate 0.0000
[2019-03-26 14:37:37,175] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168225: loss 0.0009
[2019-03-26 14:37:37,177] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168225: learning rate 0.0000
[2019-03-26 14:37:37,448] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168348: loss 0.0006
[2019-03-26 14:37:37,454] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168349: learning rate 0.0000
[2019-03-26 14:37:40,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4773538e-25 1.0000000e+00 5.9526900e-24 1.1016381e-22 1.3209079e-32], sum to 1.0000
[2019-03-26 14:37:40,479] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2416
[2019-03-26 14:37:40,485] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 75.0, 1.0, 2.0, 0.5164639413585206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721685.9310168019, 721685.9310168013, 186215.6164827244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [28.43333333333333, 75.66666666666667, 1.0, 2.0, 0.5180286488138364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723873.1352450701, 723873.1352450701, 186468.7692289273], 
processed observation next is [0.0, 0.782608695652174, 0.546603475513428, 0.7566666666666667, 1.0, 1.0, 0.4193116250769113, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20107587090140835, 0.20107587090140835, 0.2783115958640706], 
reward next is 0.7217, 
noisyNet noise sample is [array([0.4010233], dtype=float32), 1.3906399]. 
=============================================
[2019-03-26 14:37:41,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.0156675e-26 1.0000000e+00 1.1204331e-24 5.2260899e-23 1.3890225e-33], sum to 1.0000
[2019-03-26 14:37:41,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0878
[2019-03-26 14:37:41,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.23333333333333, 77.66666666666667, 1.0, 2.0, 0.5243435756053749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732700.4122814663, 732700.4122814657, 187497.7452966479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6374400.0000, 
sim time next is 6375000.0000, 
raw observation next is [28.16666666666667, 78.33333333333334, 1.0, 2.0, 0.5261262978023042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735192.3915356952, 735192.3915356958, 187790.3831392881], 
processed observation next is [0.0, 0.782608695652174, 0.5339652448657191, 0.7833333333333334, 1.0, 1.0, 0.42906782867747495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20422010875991534, 0.20422010875991548, 0.280284153939236], 
reward next is 0.7197, 
noisyNet noise sample is [array([-0.27014545], dtype=float32), -0.7136683]. 
=============================================
[2019-03-26 14:37:41,294] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[77.85379 ]
 [77.773605]
 [77.70308 ]
 [77.629105]
 [77.54554 ]], R is [[77.85460663]
 [77.79621887]
 [77.73896027]
 [77.68283081]
 [77.62769318]].
[2019-03-26 14:37:46,087] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4536882e-19 1.0000000e+00 3.4460683e-19 9.2165761e-13 1.6545265e-27], sum to 1.0000
[2019-03-26 14:37:46,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1303
[2019-03-26 14:37:46,106] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 72.5, 1.0, 2.0, 0.5062973892159814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707474.8693109483, 707474.8693109483, 184588.7930917196], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6461400.0000, 
sim time next is 6462000.0000, 
raw observation next is [28.7, 73.0, 1.0, 2.0, 0.5088125220391126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710990.5673872196, 710990.5673872202, 184988.3098795707], 
processed observation next is [1.0, 0.8260869565217391, 0.5592417061611374, 0.73, 1.0, 1.0, 0.40820785787844893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19749737982978324, 0.19749737982978338, 0.27610195504413537], 
reward next is 0.7239, 
noisyNet noise sample is [array([3.0933993], dtype=float32), -1.4743395]. 
=============================================
[2019-03-26 14:37:46,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.16344 ]
 [65.5078  ]
 [63.626484]
 [60.910576]
 [58.719677]], R is [[69.13208771]
 [69.16526031]
 [69.19865417]
 [69.23110962]
 [69.26288605]].
[2019-03-26 14:37:50,960] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0500151e-20 1.0000000e+00 1.1873684e-19 5.8257211e-16 3.1357999e-28], sum to 1.0000
[2019-03-26 14:37:50,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2760
[2019-03-26 14:37:50,971] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 80.33333333333333, 1.0, 2.0, 0.5048544023030813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705457.8414006882, 705457.8414006876, 184360.4312227188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6558600.0000, 
sim time next is 6559200.0000, 
raw observation next is [27.5, 81.0, 1.0, 2.0, 0.5070527216805558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708530.6854465901, 708530.6854465901, 184708.7648661657], 
processed observation next is [1.0, 0.9565217391304348, 0.5023696682464456, 0.81, 1.0, 1.0, 0.40608761648259734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19681407929071945, 0.19681407929071945, 0.27568472368084435], 
reward next is 0.7243, 
noisyNet noise sample is [array([1.258601], dtype=float32), -0.99978805]. 
=============================================
[2019-03-26 14:37:51,684] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.4167935e-20 1.0000000e+00 1.3846943e-19 4.8340054e-16 9.1662787e-28], sum to 1.0000
[2019-03-26 14:37:51,692] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9931
[2019-03-26 14:37:51,696] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 89.33333333333334, 1.0, 2.0, 0.5185196867119601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724559.5265676586, 724559.526567658, 186548.4288508109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6571200.0000, 
sim time next is 6571800.0000, 
raw observation next is [26.35, 89.5, 1.0, 2.0, 0.5175758127689657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723240.1443091163, 723240.1443091156, 186395.4929988685], 
processed observation next is [1.0, 0.043478260869565216, 0.4478672985781992, 0.895, 1.0, 1.0, 0.41876603948068153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20090004008586565, 0.20090004008586546, 0.27820222835652014], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.64410776], dtype=float32), 1.3843958]. 
=============================================
[2019-03-26 14:37:51,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8328261e-20 1.0000000e+00 2.8212371e-20 1.6003676e-16 2.5538065e-28], sum to 1.0000
[2019-03-26 14:37:51,881] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0218
[2019-03-26 14:37:51,890] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 87.0, 1.0, 2.0, 0.5200690135913529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726725.237111787, 726725.237111787, 186800.3863176981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6566400.0000, 
sim time next is 6567000.0000, 
raw observation next is [26.83333333333334, 87.33333333333333, 1.0, 2.0, 0.5196885430402731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726193.3998804901, 726193.3998804907, 186738.5075661945], 
processed observation next is [1.0, 0.0, 0.4707740916271725, 0.8733333333333333, 1.0, 1.0, 0.42131149763888326, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2017203888556917, 0.20172038885569188, 0.2787141903973052], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.6564926], dtype=float32), 0.25063762]. 
=============================================
[2019-03-26 14:37:51,901] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.11041 ]
 [68.5345  ]
 [68.48207 ]
 [68.420746]
 [68.36852 ]], R is [[67.67066193]
 [67.71514893]
 [67.7591629 ]
 [67.80271912]
 [67.8458252 ]].
[2019-03-26 14:37:52,094] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 14:37:52,095] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:37:52,096] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:52,096] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:37:52,097] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:37:52,099] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:37:52,100] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:37:52,098] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:52,100] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:52,101] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:52,102] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:37:52,120] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 14:37:52,120] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 14:37:52,139] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 14:37:52,156] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 14:37:52,204] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 14:37:54,810] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:37:54,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.41666666666667, 96.0, 1.0, 2.0, 0.3845326749506683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580258.5197760034, 580258.5197760027, 172930.3252149941]
[2019-03-26 14:37:54,814] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:37:54,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4476955e-21 1.0000000e+00 5.2960158e-21 1.2302497e-17 6.4092288e-29], sampled 0.8732208970353561
[2019-03-26 14:37:58,697] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:37:58,698] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.9783848, 83.94059772666667, 1.0, 2.0, 0.2649265858166723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 430822.043866537, 430822.0438665364, 162320.8990632684]
[2019-03-26 14:37:58,700] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:37:58,704] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2886129e-22 1.0000000e+00 5.8776728e-21 2.8069076e-19 7.1613123e-29], sampled 0.2645202637929307
[2019-03-26 14:38:20,174] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:38:20,175] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.17191627166667, 96.45984997000001, 1.0, 2.0, 0.3669938212464333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 559993.7461762695, 559993.7461762695, 171341.9721704342]
[2019-03-26 14:38:20,176] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:38:20,178] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9489721e-22 1.0000000e+00 5.1849111e-21 3.3109178e-19 6.5905190e-29], sampled 0.007024325027255585
[2019-03-26 14:38:53,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:38:53,297] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.73333333333333, 56.0, 1.0, 2.0, 0.8333447797965962, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005983610911102, 6.9112, 168.912315986079, 2061741.750188483, 1994499.249395109, 416256.5926240585]
[2019-03-26 14:38:53,299] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:38:53,302] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.04404488e-11 9.99995470e-01 3.18636588e-12 4.51435062e-06
 1.08861085e-16], sampled 0.87099005627498
[2019-03-26 14:38:53,304] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2061741.750188483 W.
[2019-03-26 14:38:58,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:38:58,105] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.74988257333333, 85.21653490333334, 1.0, 2.0, 0.6931490882293797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 968691.2333678192, 968691.2333678186, 219382.125401291]
[2019-03-26 14:38:58,106] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:38:58,110] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0232042e-22 1.0000000e+00 1.4919533e-21 5.1296762e-18 1.3895342e-29], sampled 0.055695872144248426
[2019-03-26 14:38:58,866] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:38:58,867] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.83333333333334, 1.0, 2.0, 0.5251265953594552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733794.9561776898, 733794.9561776898, 187626.4038743898]
[2019-03-26 14:38:58,869] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:38:58,870] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5594308e-22 1.0000000e+00 1.0531134e-21 9.3881339e-19 8.3447738e-30], sampled 0.8850939345255225
[2019-03-26 14:39:14,559] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:39:14,559] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.16666666666666, 71.33333333333333, 1.0, 2.0, 0.5429346205314944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758688.202601192, 758688.202601192, 190596.895140324]
[2019-03-26 14:39:14,560] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:39:14,563] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1339532e-22 1.0000000e+00 4.9935520e-21 1.1335791e-18 7.3949535e-29], sampled 0.2996135410080246
[2019-03-26 14:39:32,991] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:39:32,991] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.13557419666667, 57.49463220333334, 1.0, 2.0, 0.527215795347285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780255.9195737271, 780255.9195737276, 193404.4266541922]
[2019-03-26 14:39:32,993] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:39:32,996] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2236992e-21 1.0000000e+00 1.0951362e-20 2.9907900e-18 2.0790989e-28], sampled 0.7025222167984031
[2019-03-26 14:39:45,495] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05045561], dtype=float32), 0.048579477]
[2019-03-26 14:39:45,495] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.18333333333333, 63.83333333333333, 1.0, 2.0, 0.7317799110844707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1022704.661232577, 1022704.661232577, 227856.9888468909]
[2019-03-26 14:39:45,496] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:39:45,499] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3030859e-18 1.0000000e+00 6.7882515e-19 1.2354749e-13 1.5264805e-25], sampled 0.009596468026935479
[2019-03-26 14:39:48,018] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7921.2636 3160682745.6043 1653.0000
[2019-03-26 14:39:48,865] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8016.5001 3004907638.1606 1697.0000
[2019-03-26 14:39:49,064] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.1596 2841159180.9692 1099.0000
[2019-03-26 14:39:49,117] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.6872 2779376066.4557 930.0000
[2019-03-26 14:39:49,209] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.6276 2926460028.4586 1303.0000
[2019-03-26 14:39:50,225] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 175000, evaluation results [175000.0, 7921.263648211876, 3160682745.604285, 1653.0, 8266.627619161329, 2926460028.4586306, 1303.0, 8658.68716538262, 2779376066.455713, 930.0, 8016.5001456351065, 3004907638.1605573, 1697.0, 8507.159576723572, 2841159180.969221, 1099.0]
[2019-03-26 14:39:51,537] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 175609: loss -854.3626
[2019-03-26 14:39:51,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 175609: learning rate 0.0000
[2019-03-26 14:39:51,818] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175730: loss -602.0003
[2019-03-26 14:39:51,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175730: learning rate 0.0000
[2019-03-26 14:39:51,854] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175749: loss -679.9652
[2019-03-26 14:39:51,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175751: learning rate 0.0000
[2019-03-26 14:39:51,908] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175778: loss -691.5603
[2019-03-26 14:39:51,910] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175778: learning rate 0.0000
[2019-03-26 14:39:51,976] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175803: loss -677.1559
[2019-03-26 14:39:51,978] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175803: learning rate 0.0000
[2019-03-26 14:39:52,299] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175954: loss -912.5071
[2019-03-26 14:39:52,302] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175955: learning rate 0.0000
[2019-03-26 14:39:52,322] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175961: loss -822.5128
[2019-03-26 14:39:52,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175966: learning rate 0.0000
[2019-03-26 14:39:52,471] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176033: loss -771.8461
[2019-03-26 14:39:52,474] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176034: learning rate 0.0000
[2019-03-26 14:39:52,484] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 176039: loss -746.0308
[2019-03-26 14:39:52,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 176039: learning rate 0.0000
[2019-03-26 14:39:52,489] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 176039: loss -700.4467
[2019-03-26 14:39:52,491] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 176039: learning rate 0.0000
[2019-03-26 14:39:52,635] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 176106: loss -775.3541
[2019-03-26 14:39:52,637] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 176107: loss -886.1627
[2019-03-26 14:39:52,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 176107: learning rate 0.0000
[2019-03-26 14:39:52,639] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 176107: learning rate 0.0000
[2019-03-26 14:39:52,731] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176144: loss -732.9993
[2019-03-26 14:39:52,736] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176144: learning rate 0.0000
[2019-03-26 14:39:52,737] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176145: loss -712.9510
[2019-03-26 14:39:52,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176145: learning rate 0.0000
[2019-03-26 14:39:52,843] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176201: loss -779.8455
[2019-03-26 14:39:52,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176201: learning rate 0.0000
[2019-03-26 14:39:53,060] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176293: loss -853.5904
[2019-03-26 14:39:53,061] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176293: learning rate 0.0000
[2019-03-26 14:39:54,374] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8768708e-14 9.9999976e-01 1.1401284e-16 2.2448754e-07 1.2885895e-21], sum to 1.0000
[2019-03-26 14:39:54,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6411
[2019-03-26 14:39:54,380] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 85.0, 1.0, 2.0, 0.5057471964715459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706705.8015089419, 706705.8015089413, 184502.9236026203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6630600.0000, 
sim time next is 6631200.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5108819172072941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713883.2140459766, 713883.2140459772, 185319.6803326282], 
processed observation next is [1.0, 0.782608695652174, 0.4928909952606636, 0.85, 1.0, 1.0, 0.41070110506902907, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19830089279054908, 0.19830089279054922, 0.27659653780989285], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.28325328], dtype=float32), -1.0788339]. 
=============================================
[2019-03-26 14:39:58,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.1152876e-16 1.0000000e+00 1.6710321e-18 1.3806716e-09 2.4404363e-24], sum to 1.0000
[2019-03-26 14:39:58,874] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8641
[2019-03-26 14:39:58,878] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 67.0, 1.0, 2.0, 0.4681830642967822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655446.089847496, 655446.0898474953, 178922.3796425291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718200.0000, 
sim time next is 6718800.0000, 
raw observation next is [28.53333333333333, 67.0, 1.0, 2.0, 0.4637931168143669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 652873.4973243435, 652873.497324343, 178739.0999511212], 
processed observation next is [1.0, 0.782608695652174, 0.5513428120063191, 0.67, 1.0, 1.0, 0.3539676106197192, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1813537492567621, 0.18135374925676193, 0.26677477604644956], 
reward next is 0.7332, 
noisyNet noise sample is [array([-0.10988175], dtype=float32), -0.9766372]. 
=============================================
[2019-03-26 14:40:08,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3214510e-25 1.0000000e+00 3.3839107e-23 6.1776528e-22 1.3679796e-31], sum to 1.0000
[2019-03-26 14:40:08,742] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7436
[2019-03-26 14:40:08,750] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.56666666666667, 34.66666666666667, 1.0, 2.0, 0.2648799904228961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 432452.1975484979, 432452.1975484979, 162377.8519226228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6873600.0000, 
sim time next is 6874200.0000, 
raw observation next is [29.65, 33.5, 1.0, 2.0, 0.2608519516318573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427038.6891723659, 427038.6891723666, 161990.3035745148], 
processed observation next is [0.0, 0.5652173913043478, 0.6042654028436019, 0.335, 1.0, 1.0, 0.1094601826889847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11862185810343497, 0.11862185810343516, 0.24177657249927584], 
reward next is 0.7582, 
noisyNet noise sample is [array([0.237612], dtype=float32), 0.62192976]. 
=============================================
[2019-03-26 14:40:08,917] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 183582: loss 0.0113
[2019-03-26 14:40:08,920] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 183583: learning rate 0.0000
[2019-03-26 14:40:09,162] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183695: loss 0.0068
[2019-03-26 14:40:09,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183696: learning rate 0.0000
[2019-03-26 14:40:09,168] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183697: loss 0.0063
[2019-03-26 14:40:09,174] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183697: learning rate 0.0000
[2019-03-26 14:40:09,250] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183731: loss 0.0027
[2019-03-26 14:40:09,252] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183733: learning rate 0.0000
[2019-03-26 14:40:09,396] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183806: loss 0.0011
[2019-03-26 14:40:09,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183808: learning rate 0.0000
[2019-03-26 14:40:09,558] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183881: loss 0.0002
[2019-03-26 14:40:09,563] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183883: learning rate 0.0000
[2019-03-26 14:40:09,730] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183960: loss 0.0002
[2019-03-26 14:40:09,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183960: learning rate 0.0000
[2019-03-26 14:40:09,803] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 183992: loss 0.0004
[2019-03-26 14:40:09,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 183994: learning rate 0.0000
[2019-03-26 14:40:09,821] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183999: loss 0.0002
[2019-03-26 14:40:09,824] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 184000: learning rate 0.0000
[2019-03-26 14:40:10,072] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 184114: loss 0.0005
[2019-03-26 14:40:10,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 184115: learning rate 0.0000
[2019-03-26 14:40:10,153] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 184152: loss 0.0002
[2019-03-26 14:40:10,154] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 184152: learning rate 0.0000
[2019-03-26 14:40:10,206] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 184175: loss 0.0002
[2019-03-26 14:40:10,207] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 184175: learning rate 0.0000
[2019-03-26 14:40:10,251] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184195: loss 0.0002
[2019-03-26 14:40:10,253] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184196: learning rate 0.0000
[2019-03-26 14:40:10,266] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184202: loss 0.0002
[2019-03-26 14:40:10,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184203: learning rate 0.0000
[2019-03-26 14:40:10,318] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184221: loss 0.0003
[2019-03-26 14:40:10,321] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184223: learning rate 0.0000
[2019-03-26 14:40:10,666] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184383: loss 0.0047
[2019-03-26 14:40:10,668] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184383: learning rate 0.0000
[2019-03-26 14:40:14,875] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.23956304e-25 1.00000000e+00 1.23304616e-23 1.03135064e-21
 4.38612413e-32], sum to 1.0000
[2019-03-26 14:40:14,884] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9582
[2019-03-26 14:40:14,895] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.26666666666667, 57.33333333333334, 1.0, 2.0, 0.4195635980727933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 615679.3197189064, 615679.3197189071, 175717.7498376389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6979200.0000, 
sim time next is 6979800.0000, 
raw observation next is [29.18333333333334, 57.16666666666666, 1.0, 2.0, 0.4145545211978685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610668.623297392, 610668.6232973915, 175308.3842482005], 
processed observation next is [0.0, 0.782608695652174, 0.5821484992101109, 0.5716666666666665, 1.0, 1.0, 0.29464400144321506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16963017313816445, 0.16963017313816428, 0.26165430484806046], 
reward next is 0.7383, 
noisyNet noise sample is [array([-1.1479381], dtype=float32), 0.2557441]. 
=============================================
[2019-03-26 14:40:15,174] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2374926e-26 1.0000000e+00 1.1362647e-23 4.2530967e-22 4.4089719e-32], sum to 1.0000
[2019-03-26 14:40:15,184] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6354
[2019-03-26 14:40:15,188] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 69.0, 1.0, 2.0, 0.4224405810370953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616696.7005535706, 616696.7005535706, 175725.2670841848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6991200.0000, 
sim time next is 6991800.0000, 
raw observation next is [27.18333333333333, 70.16666666666667, 1.0, 2.0, 0.4255749638259517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619419.4547144264, 619419.454714427, 175935.4265831896], 
processed observation next is [0.0, 0.9565217391304348, 0.48736176935229053, 0.7016666666666667, 1.0, 1.0, 0.3079216431637972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17206095964289622, 0.1720609596428964, 0.26259018893013375], 
reward next is 0.7374, 
noisyNet noise sample is [array([-0.85570633], dtype=float32), 0.5651855]. 
=============================================
[2019-03-26 14:40:16,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5475876e-24 1.0000000e+00 1.8862216e-21 2.3161595e-19 3.1765149e-30], sum to 1.0000
[2019-03-26 14:40:16,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2454
[2019-03-26 14:40:16,595] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333334, 79.66666666666667, 1.0, 2.0, 0.4528319381208636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646801.0828001656, 646801.0828001656, 178343.8153820888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7001400.0000, 
sim time next is 7002000.0000, 
raw observation next is [26.1, 80.0, 1.0, 2.0, 0.4536449394158682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647514.3464406335, 647514.3464406335, 178405.7921409908], 
processed observation next is [1.0, 0.043478260869565216, 0.4360189573459717, 0.8, 1.0, 1.0, 0.3417408908624918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17986509623350933, 0.17986509623350933, 0.2662773017029713], 
reward next is 0.7337, 
noisyNet noise sample is [array([-0.14769715], dtype=float32), 0.4070976]. 
=============================================
[2019-03-26 14:40:16,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.71973 ]
 [72.20669 ]
 [72.80083 ]
 [73.372055]
 [74.04993 ]], R is [[71.30215454]
 [71.32295227]
 [71.34352112]
 [71.36374664]
 [71.3837204 ]].
[2019-03-26 14:40:25,099] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7519920e-22 1.0000000e+00 4.0403548e-21 7.0647263e-19 2.9874664e-29], sum to 1.0000
[2019-03-26 14:40:25,112] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5168
[2019-03-26 14:40:25,118] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 86.0, 1.0, 2.0, 0.4761557408519673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665343.2341960453, 665343.2341960459, 179944.324408783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7174800.0000, 
sim time next is 7175400.0000, 
raw observation next is [25.8, 86.16666666666667, 1.0, 2.0, 0.476578657134562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665934.3699529376, 665934.3699529376, 180007.6556964713], 
processed observation next is [1.0, 0.043478260869565216, 0.42180094786729866, 0.8616666666666667, 1.0, 1.0, 0.36937187606573735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18498176943137154, 0.18498176943137154, 0.2686681428305542], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.02105174], dtype=float32), -0.71394366]. 
=============================================
[2019-03-26 14:40:26,266] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191555: loss 0.0021
[2019-03-26 14:40:26,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191558: learning rate 0.0000
[2019-03-26 14:40:26,582] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191700: loss 0.0033
[2019-03-26 14:40:26,585] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191702: learning rate 0.0000
[2019-03-26 14:40:26,645] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191727: loss 0.0026
[2019-03-26 14:40:26,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191727: learning rate 0.0000
[2019-03-26 14:40:26,715] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191762: loss 0.0030
[2019-03-26 14:40:26,718] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191762: learning rate 0.0000
[2019-03-26 14:40:26,826] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191814: loss 0.0040
[2019-03-26 14:40:26,828] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191814: learning rate 0.0000
[2019-03-26 14:40:26,993] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191890: loss 0.0051
[2019-03-26 14:40:26,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191890: learning rate 0.0000
[2019-03-26 14:40:27,110] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191938: loss 0.0077
[2019-03-26 14:40:27,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191938: learning rate 0.0000
[2019-03-26 14:40:27,115] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191939: loss 0.0068
[2019-03-26 14:40:27,123] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191939: learning rate 0.0000
[2019-03-26 14:40:27,181] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 191973: loss 0.0075
[2019-03-26 14:40:27,183] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 191975: learning rate 0.0000
[2019-03-26 14:40:27,425] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 192085: loss 0.0060
[2019-03-26 14:40:27,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 192085: learning rate 0.0000
[2019-03-26 14:40:27,553] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192145: loss 0.0065
[2019-03-26 14:40:27,556] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192146: learning rate 0.0000
[2019-03-26 14:40:27,557] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 192146: loss 0.0074
[2019-03-26 14:40:27,561] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 192146: loss 0.0071
[2019-03-26 14:40:27,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 192146: learning rate 0.0000
[2019-03-26 14:40:27,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 192147: learning rate 0.0000
[2019-03-26 14:40:27,630] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 192175: loss 0.0063
[2019-03-26 14:40:27,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 192177: learning rate 0.0000
[2019-03-26 14:40:27,636] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192177: loss 0.0062
[2019-03-26 14:40:27,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192178: learning rate 0.0000
[2019-03-26 14:40:27,995] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 192338: loss 0.0028
[2019-03-26 14:40:27,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 192338: learning rate 0.0000
[2019-03-26 14:40:30,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.5065836e-23 1.0000000e+00 6.1479105e-23 4.9471773e-20 2.3724089e-32], sum to 1.0000
[2019-03-26 14:40:30,346] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9552
[2019-03-26 14:40:30,351] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 86.0, 1.0, 2.0, 0.3718227657788394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564717.0880237719, 564717.0880237719, 171670.4953149956], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7237800.0000, 
sim time next is 7238400.0000, 
raw observation next is [23.4, 86.66666666666667, 1.0, 2.0, 0.370221184261301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 562460.1829974334, 562460.1829974327, 171480.3139426154], 
processed observation next is [1.0, 0.782608695652174, 0.30805687203791465, 0.8666666666666667, 1.0, 1.0, 0.2412303424834952, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15623893972150926, 0.15623893972150907, 0.2559407670785305], 
reward next is 0.7441, 
noisyNet noise sample is [array([-1.0846096], dtype=float32), -0.62961507]. 
=============================================
[2019-03-26 14:40:39,242] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3607688e-23 1.0000000e+00 7.9940450e-23 2.7897946e-20 8.4160552e-32], sum to 1.0000
[2019-03-26 14:40:39,249] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4039
[2019-03-26 14:40:39,259] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 89.33333333333333, 1.0, 2.0, 0.5318350685422644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859660.5847458986, 859660.5847458986, 201295.2674595128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7404000.0000, 
sim time next is 7404600.0000, 
raw observation next is [20.43333333333333, 89.16666666666667, 1.0, 2.0, 0.537329516017936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869358.8287553352, 869358.8287553352, 202392.1847829527], 
processed observation next is [1.0, 0.6956521739130435, 0.1674565560821484, 0.8916666666666667, 1.0, 1.0, 0.44256568194932044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24148856354314865, 0.24148856354314865, 0.30207788773575034], 
reward next is 0.6979, 
noisyNet noise sample is [array([0.38895872], dtype=float32), -0.03468329]. 
=============================================
[2019-03-26 14:40:43,497] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199537: loss 0.0112
[2019-03-26 14:40:43,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199537: learning rate 0.0000
[2019-03-26 14:40:43,934] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199729: loss 0.0070
[2019-03-26 14:40:43,937] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199730: loss 0.0087
[2019-03-26 14:40:43,937] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199729: learning rate 0.0000
[2019-03-26 14:40:43,941] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199730: loss 0.0067
[2019-03-26 14:40:43,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199730: learning rate 0.0000
[2019-03-26 14:40:43,943] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199730: learning rate 0.0000
[2019-03-26 14:40:44,157] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199830: loss 0.0047
[2019-03-26 14:40:44,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199830: learning rate 0.0000
[2019-03-26 14:40:44,190] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 199841: loss 0.0066
[2019-03-26 14:40:44,194] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 199842: learning rate 0.0000
[2019-03-26 14:40:44,329] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199906: loss 0.0044
[2019-03-26 14:40:44,333] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199906: learning rate 0.0000
[2019-03-26 14:40:44,418] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 199949: loss 0.0060
[2019-03-26 14:40:44,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 199949: learning rate 0.0000
[2019-03-26 14:40:44,527] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200000: loss 0.0031
[2019-03-26 14:40:44,527] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 14:40:44,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200000: learning rate 0.0000
[2019-03-26 14:40:44,530] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:40:44,530] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:40:44,531] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:44,532] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:40:44,533] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:40:44,532] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:44,533] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:40:44,536] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:44,537] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:44,539] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:40:44,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 14:40:44,567] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 14:40:44,568] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 14:40:44,599] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 14:40:44,626] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 14:40:54,404] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04390875], dtype=float32), 0.054991815]
[2019-03-26 14:40:54,406] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.46656688, 79.66441169, 1.0, 2.0, 0.2133611006648407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 356484.5153782121, 356484.5153782121, 156580.7072173633]
[2019-03-26 14:40:54,407] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:40:54,410] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4818144e-25 1.0000000e+00 9.2854624e-24 3.3752342e-23 4.7644149e-33], sampled 0.8258264091231587
[2019-03-26 14:41:19,135] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04390875], dtype=float32), 0.054991815]
[2019-03-26 14:41:19,137] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.55, 74.5, 1.0, 2.0, 0.5714326050483157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798525.8016781245, 798525.8016781245, 195545.2215697849]
[2019-03-26 14:41:19,139] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:41:19,147] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.8025693e-24 1.0000000e+00 7.8103193e-24 2.9307381e-19 1.4397293e-32], sampled 0.45009016108075406
[2019-03-26 14:41:36,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04390875], dtype=float32), 0.054991815]
[2019-03-26 14:41:36,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.0, 81.16666666666666, 1.0, 2.0, 0.5089637676841949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711201.9816518704, 711201.981651871, 185011.5509116416]
[2019-03-26 14:41:36,295] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:41:36,298] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3223142e-25 1.0000000e+00 3.8594038e-24 9.1775333e-23 1.9702869e-33], sampled 0.11306776652020845
[2019-03-26 14:42:33,582] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04390875], dtype=float32), 0.054991815]
[2019-03-26 14:42:33,583] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.66666666666667, 79.0, 1.0, 2.0, 0.7936179888228996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1109172.078632862, 1109172.078632863, 242353.3909796586]
[2019-03-26 14:42:33,584] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:42:33,588] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.5731453e-24 1.0000000e+00 9.4530155e-23 5.7930189e-21 1.8964715e-31], sampled 0.5950966984211168
[2019-03-26 14:42:41,043] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6296 2779265535.0700 933.0000
[2019-03-26 14:42:41,383] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.0785 2842495535.3797 1130.0000
[2019-03-26 14:42:41,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.3446 3164332473.4074 1775.0000
[2019-03-26 14:42:41,483] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2767 3007680316.3481 1766.0000
[2019-03-26 14:42:41,558] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.7349 2927607966.4501 1338.0000
[2019-03-26 14:42:42,572] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 200000, evaluation results [200000.0, 7882.344598088208, 3164332473.407362, 1775.0, 8252.734924932276, 2927607966.4500504, 1338.0, 8660.629559617946, 2779265535.0700107, 933.0, 7998.276703650782, 3007680316.348062, 1766.0, 8495.078459368664, 2842495535.3797135, 1130.0]
[2019-03-26 14:42:42,886] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 200148: loss 0.0062
[2019-03-26 14:42:42,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 200150: learning rate 0.0000
[2019-03-26 14:42:42,956] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 200182: loss 0.0082
[2019-03-26 14:42:42,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 200182: learning rate 0.0000
[2019-03-26 14:42:42,971] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 200189: loss 0.0078
[2019-03-26 14:42:42,974] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 200189: learning rate 0.0000
[2019-03-26 14:42:42,990] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 200197: loss 0.0083
[2019-03-26 14:42:42,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 200197: learning rate 0.0000
[2019-03-26 14:42:43,070] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200231: loss 0.0078
[2019-03-26 14:42:43,073] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200231: learning rate 0.0000
[2019-03-26 14:42:43,237] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200308: loss 0.0083
[2019-03-26 14:42:43,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200312: learning rate 0.0000
[2019-03-26 14:42:43,278] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 200328: loss 0.0085
[2019-03-26 14:42:43,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 200328: learning rate 0.0000
[2019-03-26 14:42:46,921] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.2190890e-26 1.0000000e+00 3.3586254e-24 5.3283118e-23 6.5194129e-34], sum to 1.0000
[2019-03-26 14:42:46,933] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-26 14:42:46,937] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 70.0, 1.0, 2.0, 0.4498106117745951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639194.3125513236, 639194.3125513236, 177483.840978248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7581000.0000, 
sim time next is 7581600.0000, 
raw observation next is [27.7, 71.0, 1.0, 2.0, 0.4507344241044838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639507.7533714027, 639507.7533714027, 177489.4611726356], 
processed observation next is [0.0, 0.782608695652174, 0.5118483412322274, 0.71, 1.0, 1.0, 0.33823424590901663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17764104260316743, 0.17764104260316743, 0.2649096435412472], 
reward next is 0.7351, 
noisyNet noise sample is [array([-0.6845018], dtype=float32), -0.986417]. 
=============================================
[2019-03-26 14:42:47,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.21244342e-26 1.00000000e+00 8.01785849e-25 4.25150274e-24
 1.30067155e-33], sum to 1.0000
[2019-03-26 14:42:47,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4004
[2019-03-26 14:42:47,347] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 88.66666666666667, 1.0, 2.0, 0.4859180628494311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 678988.7080143351, 678988.7080143344, 181419.0336984263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7593600.0000, 
sim time next is 7594200.0000, 
raw observation next is [25.6, 89.0, 1.0, 2.0, 0.484058537974898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676389.5077499435, 676389.5077499435, 181136.0137621213], 
processed observation next is [0.0, 0.9130434782608695, 0.4123222748815167, 0.89, 1.0, 1.0, 0.3783837806926482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1878859743749843, 0.1878859743749843, 0.2703522593464497], 
reward next is 0.7296, 
noisyNet noise sample is [array([-0.5012515], dtype=float32), -0.6387839]. 
=============================================
[2019-03-26 14:42:50,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2152385e-09 9.9979264e-01 2.7436913e-12 2.0734801e-04 1.2748133e-16], sum to 1.0000
[2019-03-26 14:42:50,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5836
[2019-03-26 14:42:50,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1748456.8324069 W.
[2019-03-26 14:42:50,832] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 64.0, 1.0, 2.0, 0.6253314287443879, 1.0, 1.0, 0.6253314287443879, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1748456.8324069, 1748456.8324069, 343789.9332920148], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7657200.0000, 
sim time next is 7657800.0000, 
raw observation next is [30.08333333333334, 64.83333333333334, 1.0, 2.0, 0.3856926119061844, 1.0, 2.0, 0.3856926119061844, 1.0, 1.0, 0.6560192166679366, 6.911200000000001, 6.9112, 170.5573041426782, 1617523.974640608, 1617523.974640607, 343236.5304414401], 
processed observation next is [1.0, 0.6521739130434783, 0.6248025276461299, 0.6483333333333334, 1.0, 1.0, 0.25987061675443907, 1.0, 1.0, 0.25987061675443907, 1.0, 0.5, 0.580511239838947, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.44931221517794667, 0.44931221517794634, 0.5122933290170748], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35539138], dtype=float32), -0.19669947]. 
=============================================
[2019-03-26 14:42:56,941] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9921404e-09 7.6481891e-01 5.5329966e-11 2.3518111e-01 2.2795156e-15], sum to 1.0000
[2019-03-26 14:42:56,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7835
[2019-03-26 14:42:56,960] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.13333333333333, 60.66666666666667, 1.0, 2.0, 0.8514063477719258, 1.0, 2.0, 0.8514063477719258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2381248.992763421, 2381248.992763421, 445664.5803085972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7746000.0000, 
sim time next is 7746600.0000, 
raw observation next is [31.01666666666667, 60.83333333333334, 1.0, 2.0, 0.8397595060624703, 1.0, 2.0, 0.8397595060624703, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2348644.006462396, 2348644.006462395, 439682.4196626547], 
processed observation next is [1.0, 0.6521739130434783, 0.6690363349131123, 0.6083333333333334, 1.0, 1.0, 0.8069391639306871, 1.0, 1.0, 0.8069391639306871, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6524011129062212, 0.6524011129062209, 0.6562424174069473], 
reward next is 0.3438, 
noisyNet noise sample is [array([0.03148022], dtype=float32), -0.4573446]. 
=============================================
[2019-03-26 14:42:59,191] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207569: loss 0.0072
[2019-03-26 14:42:59,193] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207570: learning rate 0.0000
[2019-03-26 14:42:59,303] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207621: loss 0.0070
[2019-03-26 14:42:59,311] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207622: learning rate 0.0000
[2019-03-26 14:42:59,431] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207689: loss 0.0046
[2019-03-26 14:42:59,433] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207689: learning rate 0.0000
[2019-03-26 14:42:59,459] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207702: loss 0.0045
[2019-03-26 14:42:59,462] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207702: learning rate 0.0000
[2019-03-26 14:42:59,684] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 207801: loss 0.0043
[2019-03-26 14:42:59,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 207801: learning rate 0.0000
[2019-03-26 14:42:59,708] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207813: loss 0.0044
[2019-03-26 14:42:59,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207815: learning rate 0.0000
[2019-03-26 14:42:59,896] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207897: loss 0.0048
[2019-03-26 14:42:59,899] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207897: learning rate 0.0000
[2019-03-26 14:42:59,993] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 207942: loss 0.0059
[2019-03-26 14:42:59,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 207944: learning rate 0.0000
[2019-03-26 14:43:00,074] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207978: loss 0.0048
[2019-03-26 14:43:00,077] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207978: learning rate 0.0000
[2019-03-26 14:43:00,421] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 208139: loss 0.0047
[2019-03-26 14:43:00,426] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 208139: learning rate 0.0000
[2019-03-26 14:43:00,514] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 208180: loss 0.0039
[2019-03-26 14:43:00,518] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 208182: learning rate 0.0000
[2019-03-26 14:43:00,563] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208204: loss 0.0042
[2019-03-26 14:43:00,565] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208205: learning rate 0.0000
[2019-03-26 14:43:00,574] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208208: loss 0.0045
[2019-03-26 14:43:00,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208208: learning rate 0.0000
[2019-03-26 14:43:00,623] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 208230: loss 0.0063
[2019-03-26 14:43:00,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 208230: learning rate 0.0000
[2019-03-26 14:43:00,710] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208266: loss 0.0039
[2019-03-26 14:43:00,712] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208266: learning rate 0.0000
[2019-03-26 14:43:00,849] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 208328: loss 0.0042
[2019-03-26 14:43:00,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 208328: learning rate 0.0000
[2019-03-26 14:43:05,242] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3722947e-19 1.0000000e+00 6.3334562e-19 9.4098346e-17 6.9853217e-27], sum to 1.0000
[2019-03-26 14:43:05,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9250
[2019-03-26 14:43:05,258] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 89.33333333333333, 1.0, 2.0, 0.693426089341136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 969078.5251910627, 969078.5251910621, 219431.0477504276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7879200.0000, 
sim time next is 7879800.0000, 
raw observation next is [26.28333333333333, 89.16666666666667, 1.0, 2.0, 0.7334498719807727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1025039.654350252, 1025039.654350252, 228229.3575811335], 
processed observation next is [1.0, 0.17391304347826086, 0.4447077409162717, 0.8916666666666667, 1.0, 1.0, 0.6788552674467141, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28473323731951444, 0.28473323731951444, 0.340640832210647], 
reward next is 0.6594, 
noisyNet noise sample is [array([0.8637612], dtype=float32), -0.73761857]. 
=============================================
[2019-03-26 14:43:08,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:08,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:08,979] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 14:43:09,047] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,050] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 14:43:09,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 14:43:09,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 14:43:09,311] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,311] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 14:43:09,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,337] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 14:43:09,413] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,413] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 14:43:09,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,513] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 14:43:09,561] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,561] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 14:43:09,689] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,689] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,690] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 14:43:09,719] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,719] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 14:43:09,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,750] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 14:43:09,767] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,768] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,769] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 14:43:09,791] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 14:43:09,821] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,821] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,823] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 14:43:09,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 14:43:09,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:09,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 14:43:11,830] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8313437e-23 1.0000000e+00 2.7655495e-21 1.0793311e-19 2.2787695e-29], sum to 1.0000
[2019-03-26 14:43:11,837] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6805
[2019-03-26 14:43:11,844] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 85.66666666666667, 1.0, 2.0, 0.3690137845416782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588413.6889443405, 588413.6889443405, 174182.9217423461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 22200.0000, 
sim time next is 22800.0000, 
raw observation next is [21.73333333333333, 85.33333333333334, 1.0, 2.0, 0.3612055407796835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 575655.3478477785, 575655.3478477779, 173093.5193641669], 
processed observation next is [1.0, 0.2608695652173913, 0.22906793048973137, 0.8533333333333334, 1.0, 1.0, 0.2303681214213054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15990426329104956, 0.15990426329104943, 0.25834853636442817], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.42446116], dtype=float32), 1.1099082]. 
=============================================
[2019-03-26 14:43:13,060] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9682809e-21 1.0000000e+00 7.7208109e-21 2.7843098e-19 3.2507413e-29], sum to 1.0000
[2019-03-26 14:43:13,065] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8814
[2019-03-26 14:43:13,071] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 84.0, 1.0, 2.0, 0.3279442786595308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 519472.6537201722, 519472.6537201722, 168521.9721615786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 27600.0000, 
sim time next is 28200.0000, 
raw observation next is [22.25, 84.0, 1.0, 2.0, 0.3407849861179714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539199.0849194026, 539199.0849194026, 170068.0473758531], 
processed observation next is [1.0, 0.30434782608695654, 0.2535545023696683, 0.84, 1.0, 1.0, 0.20576504351562822, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14977752358872296, 0.14977752358872296, 0.253832906531124], 
reward next is 0.7462, 
noisyNet noise sample is [array([-1.825128], dtype=float32), -0.7301534]. 
=============================================
[2019-03-26 14:43:14,585] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0334945e-21 1.0000000e+00 3.0226250e-21 1.4909778e-17 3.1970244e-29], sum to 1.0000
[2019-03-26 14:43:14,592] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6183
[2019-03-26 14:43:14,597] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.45, 88.0, 1.0, 2.0, 0.3473432723090848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539420.6966323056, 539420.6966323056, 169890.0225572612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 81000.0000, 
sim time next is 81600.0000, 
raw observation next is [22.36666666666667, 88.33333333333333, 1.0, 2.0, 0.3456443531509074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537359.5098161114, 537359.5098161114, 169736.950705746], 
processed observation next is [1.0, 0.9565217391304348, 0.2590837282780413, 0.8833333333333333, 1.0, 1.0, 0.2116197025914547, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1492665305044754, 0.1492665305044754, 0.25333873239663585], 
reward next is 0.7467, 
noisyNet noise sample is [array([-2.025081], dtype=float32), -1.47527]. 
=============================================
[2019-03-26 14:43:28,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1711736e-24 1.0000000e+00 1.4504033e-22 1.6651055e-21 4.3990264e-32], sum to 1.0000
[2019-03-26 14:43:28,876] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9812
[2019-03-26 14:43:28,884] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 76.33333333333333, 1.0, 2.0, 0.3164592760256142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498106.7996662029, 498106.7996662023, 166832.9639899812], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [23.56666666666667, 76.16666666666667, 1.0, 2.0, 0.3167429366759382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498449.7570176365, 498449.7570176359, 166856.1608256341], 
processed observation next is [0.0, 0.5217391304347826, 0.31595576619273325, 0.7616666666666667, 1.0, 1.0, 0.17679871888667256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13845826583823237, 0.1384582658382322, 0.24903904600840912], 
reward next is 0.7510, 
noisyNet noise sample is [array([0.2814484], dtype=float32), 0.4558171]. 
=============================================
[2019-03-26 14:43:36,118] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1618180e-23 1.0000000e+00 5.4991309e-22 9.1499270e-21 2.3786175e-31], sum to 1.0000
[2019-03-26 14:43:36,128] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7401
[2019-03-26 14:43:36,134] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.95, 81.83333333333334, 1.0, 2.0, 0.2303358724793361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 380295.462992765, 380295.4629927656, 158986.5359185053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454200.0000, 
sim time next is 454800.0000, 
raw observation next is [20.0, 81.66666666666667, 1.0, 2.0, 0.2308156578175492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 380968.9817660752, 380968.9817660752, 159036.7521455919], 
processed observation next is [1.0, 0.2608695652173913, 0.1469194312796209, 0.8166666666666668, 1.0, 1.0, 0.07327187688861349, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1058247171572431, 0.1058247171572431, 0.2373682867844655], 
reward next is 0.7626, 
noisyNet noise sample is [array([-0.7531432], dtype=float32), 0.9363196]. 
=============================================
[2019-03-26 14:43:39,054] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 14:43:39,056] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:43:39,056] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:43:39,058] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:43:39,057] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:39,060] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:43:39,058] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:43:39,063] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:39,062] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:39,063] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:39,065] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:43:39,082] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 14:43:39,083] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 14:43:39,099] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 14:43:39,119] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 14:43:39,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 14:43:58,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04067419], dtype=float32), 0.060455915]
[2019-03-26 14:43:58,416] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.8, 58.5, 1.0, 2.0, 0.2159667146243449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 360586.8643218375, 360586.8643218375, 156942.6570130305]
[2019-03-26 14:43:58,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:43:58,422] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4448638e-23 1.0000000e+00 3.0745827e-22 1.1293179e-20 4.5407988e-31], sampled 0.4330552151265882
[2019-03-26 14:44:06,834] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04067419], dtype=float32), 0.060455915]
[2019-03-26 14:44:06,834] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.43228701666667, 97.70452278333333, 1.0, 2.0, 0.4029692704892013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 620977.4472914442, 620977.4472914442, 176902.3358754477]
[2019-03-26 14:44:06,836] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:44:06,839] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9089126e-23 1.0000000e+00 4.6470662e-22 3.0806907e-20 6.0969018e-31], sampled 0.8014022464377963
[2019-03-26 14:44:53,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04067419], dtype=float32), 0.060455915]
[2019-03-26 14:44:53,287] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 83.0, 1.0, 2.0, 0.5890945336109096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823216.3267717306, 823216.3267717306, 198731.6784028377]
[2019-03-26 14:44:53,288] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:44:53,292] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2468149e-23 1.0000000e+00 1.7798393e-22 1.0955708e-20 2.9367074e-31], sampled 0.43881543392760114
[2019-03-26 14:45:27,020] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04067419], dtype=float32), 0.060455915]
[2019-03-26 14:45:27,022] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.15, 57.5, 1.0, 2.0, 0.6696438438906601, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005973388118742, 6.9112, 168.9123160539661, 1832650.639839085, 1765415.391391928, 378219.4003543201]
[2019-03-26 14:45:27,022] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:45:27,026] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.0513905e-11 9.9867404e-01 3.2681960e-13 1.3259996e-03 1.0180166e-17], sampled 0.20849669282077132
[2019-03-26 14:45:27,028] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1832650.639839085 W.
[2019-03-26 14:45:35,086] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 14:45:35,790] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.9418 2927304846.7866 1335.0000
[2019-03-26 14:45:36,005] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.1854 2842313259.2608 1124.0000
[2019-03-26 14:45:36,011] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.3392 3007242515.1492 1760.0000
[2019-03-26 14:45:36,056] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7895.8473 3163406187.0995 1740.0000
[2019-03-26 14:45:37,071] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 225000, evaluation results [225000.0, 7895.847319928248, 3163406187.0995216, 1740.0, 8255.941785643616, 2927304846.786571, 1335.0, 8661.172501768742, 2779322230.897455, 933.0, 8001.339199708006, 3007242515.1492248, 1760.0, 8500.185428109897, 2842313259.2607703, 1124.0]
[2019-03-26 14:45:41,545] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8205362e-21 1.0000000e+00 9.3223216e-20 8.0491150e-18 3.5201762e-29], sum to 1.0000
[2019-03-26 14:45:41,555] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0342
[2019-03-26 14:45:41,561] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666666, 56.5, 1.0, 2.0, 0.6107905061670916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1006836.955491657, 1006836.955491657, 217927.6554883869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 558600.0000, 
sim time next is 559200.0000, 
raw observation next is [24.13333333333333, 56.00000000000001, 1.0, 2.0, 0.6120043508527482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1007447.090773712, 1007447.090773713, 218210.8620675619], 
processed observation next is [1.0, 0.4782608695652174, 0.3428120063191152, 0.56, 1.0, 1.0, 0.5325353624731906, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2798464141038089, 0.27984641410380917, 0.3256878538321819], 
reward next is 0.6743, 
noisyNet noise sample is [array([1.7785759], dtype=float32), -1.7577825]. 
=============================================
[2019-03-26 14:45:42,884] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4697531e-21 1.0000000e+00 6.0320187e-21 1.6184533e-17 3.9092541e-29], sum to 1.0000
[2019-03-26 14:45:42,894] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0877
[2019-03-26 14:45:42,904] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 62.0, 1.0, 2.0, 0.6557078555172644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1072312.234764881, 1072312.234764881, 228040.9128131384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 576000.0000, 
sim time next is 576600.0000, 
raw observation next is [23.58333333333334, 62.33333333333334, 1.0, 2.0, 0.6125995157156127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1001479.958573666, 1001479.958573666, 218273.8191076307], 
processed observation next is [1.0, 0.6956521739130435, 0.31674565560821516, 0.6233333333333334, 1.0, 1.0, 0.5332524285730272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2781888773815739, 0.2781888773815739, 0.3257818195636279], 
reward next is 0.6742, 
noisyNet noise sample is [array([0.03208034], dtype=float32), -0.9075448]. 
=============================================
[2019-03-26 14:45:43,390] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5714886e-22 1.0000000e+00 3.2884462e-21 1.6126902e-18 1.7527873e-29], sum to 1.0000
[2019-03-26 14:45:43,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8060
[2019-03-26 14:45:43,404] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 69.5, 1.0, 2.0, 0.253045115210523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 415820.7852035931, 415820.7852035924, 161210.9314993903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 586200.0000, 
sim time next is 586800.0000, 
raw observation next is [21.9, 70.0, 1.0, 2.0, 0.2508041021938299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412422.978333547, 412422.9783335476, 160985.8883752157], 
processed observation next is [1.0, 0.8260869565217391, 0.23696682464454974, 0.7, 1.0, 1.0, 0.09735433999256617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11456193842598528, 0.11456193842598544, 0.24027744533614284], 
reward next is 0.7597, 
noisyNet noise sample is [array([0.5536781], dtype=float32), 1.1186035]. 
=============================================
[2019-03-26 14:45:49,456] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8384944e-24 1.0000000e+00 1.5326728e-23 1.1683843e-20 1.9343547e-32], sum to 1.0000
[2019-03-26 14:45:49,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9194
[2019-03-26 14:45:49,471] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.53333333333333, 89.33333333333334, 1.0, 2.0, 0.2319900965950066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 384851.1732432463, 384851.1732432463, 158980.2655161958], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 690000.0000, 
sim time next is 690600.0000, 
raw observation next is [18.46666666666667, 89.66666666666666, 1.0, 2.0, 0.230670428857446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 382757.0898627586, 382757.0898627586, 158846.3142472141], 
processed observation next is [1.0, 1.0, 0.0742496050552924, 0.8966666666666666, 1.0, 1.0, 0.07309690223788676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10632141385076628, 0.10632141385076628, 0.23708405111524491], 
reward next is 0.7629, 
noisyNet noise sample is [array([-0.9411762], dtype=float32), 1.1300491]. 
=============================================
[2019-03-26 14:45:51,162] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3765027e-22 1.0000000e+00 3.3060680e-21 2.3765369e-19 1.5048538e-29], sum to 1.0000
[2019-03-26 14:45:51,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7221
[2019-03-26 14:45:51,181] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 61.33333333333334, 1.0, 2.0, 0.5228121604416931, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 851124.0959881367, 851124.095988136, 199873.8175829679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 728400.0000, 
sim time next is 729000.0000, 
raw observation next is [24.25, 60.5, 1.0, 2.0, 0.5156365122273942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838988.3688905883, 838988.3688905883, 198515.1126010719], 
processed observation next is [1.0, 0.43478260869565216, 0.3483412322274882, 0.605, 1.0, 1.0, 0.4164295328040893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23305232469183007, 0.23305232469183007, 0.2962912128374207], 
reward next is 0.7037, 
noisyNet noise sample is [array([-0.72963804], dtype=float32), 0.5875055]. 
=============================================
[2019-03-26 14:45:51,196] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.23991]
 [72.24278]
 [72.29632]
 [72.36387]
 [72.46271]], R is [[72.24050903]
 [72.2197876 ]
 [72.18262482]
 [72.15257263]
 [72.12554169]].
[2019-03-26 14:45:53,100] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5861522e-23 1.0000000e+00 5.8859462e-23 2.7580379e-21 2.4944140e-32], sum to 1.0000
[2019-03-26 14:45:53,107] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1263
[2019-03-26 14:45:53,114] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.58333333333334, 88.16666666666667, 1.0, 2.0, 0.2561306427278197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420762.3612902882, 420762.3612902888, 161520.4565206932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 774600.0000, 
sim time next is 775200.0000, 
raw observation next is [19.56666666666667, 88.33333333333334, 1.0, 2.0, 0.2552014212143335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419218.9642377191, 419218.9642377191, 161427.2336434695], 
processed observation next is [1.0, 1.0, 0.12638230647709342, 0.8833333333333334, 1.0, 1.0, 0.10265231471606442, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1164497122882553, 0.1164497122882553, 0.24093616961711864], 
reward next is 0.7591, 
noisyNet noise sample is [array([-0.15064561], dtype=float32), -1.6386157]. 
=============================================
[2019-03-26 14:45:53,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3127955e-24 1.0000000e+00 1.6989880e-23 2.4128087e-21 9.2860621e-32], sum to 1.0000
[2019-03-26 14:45:53,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2371
[2019-03-26 14:45:53,429] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 81.5, 1.0, 2.0, 0.2557607449046097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 419868.8159036694, 419868.8159036688, 161484.0978469386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 766200.0000, 
sim time next is 766800.0000, 
raw observation next is [20.4, 82.0, 1.0, 2.0, 0.2567924316637124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421572.8536829458, 421572.8536829464, 161587.8803266313], 
processed observation next is [1.0, 0.9130434782608695, 0.16587677725118483, 0.82, 1.0, 1.0, 0.10456919477555711, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11710357046748494, 0.11710357046748511, 0.24117594078601687], 
reward next is 0.7588, 
noisyNet noise sample is [array([-1.2721232], dtype=float32), -1.117661]. 
=============================================
[2019-03-26 14:45:53,571] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7111445e-24 1.0000000e+00 4.3901782e-23 1.9576003e-21 4.0126998e-32], sum to 1.0000
[2019-03-26 14:45:53,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0322
[2019-03-26 14:45:53,588] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 84.5, 1.0, 2.0, 0.2573957288439261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 422645.2378359311, 422645.2378359305, 161648.6407824819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 769800.0000, 
sim time next is 770400.0000, 
raw observation next is [20.0, 85.0, 1.0, 2.0, 0.2564289679765918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 421080.2615530139, 421080.2615530132, 161551.1090656208], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 0.85, 1.0, 1.0, 0.10413128671878531, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11696673932028163, 0.11696673932028144, 0.24112105830689673], 
reward next is 0.7589, 
noisyNet noise sample is [array([0.00428007], dtype=float32), -0.75902885]. 
=============================================
[2019-03-26 14:45:57,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3582505e-26 1.0000000e+00 5.3404192e-23 2.4458535e-22 5.2265418e-33], sum to 1.0000
[2019-03-26 14:45:57,700] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3156
[2019-03-26 14:45:57,704] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 74.66666666666667, 1.0, 2.0, 0.3109348703224167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 491277.5409015107, 491277.5409015114, 166369.0214944375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 840000.0000, 
sim time next is 840600.0000, 
raw observation next is [23.45, 75.5, 1.0, 2.0, 0.3105343506142487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490927.7073007232, 490927.7073007232, 166349.4056229615], 
processed observation next is [0.0, 0.7391304347826086, 0.3104265402843602, 0.755, 1.0, 1.0, 0.1693184947159623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13636880758353423, 0.13636880758353423, 0.24828269495964403], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.5895479], dtype=float32), -0.5766105]. 
=============================================
[2019-03-26 14:46:08,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2504792e-21 1.0000000e+00 1.3159614e-21 8.3761434e-18 3.0088636e-30], sum to 1.0000
[2019-03-26 14:46:08,232] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1639
[2019-03-26 14:46:08,237] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 97.16666666666667, 1.0, 2.0, 0.3576113633991529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549453.8984225335, 549453.8984225335, 170560.0307967989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1014600.0000, 
sim time next is 1015200.0000, 
raw observation next is [21.7, 97.0, 1.0, 2.0, 0.3573041311786649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549303.5648226578, 549303.5648226573, 170556.7196522344], 
processed observation next is [1.0, 0.782608695652174, 0.2274881516587678, 0.97, 1.0, 1.0, 0.22566762792610226, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1525843235618494, 0.15258432356184923, 0.2545622681376633], 
reward next is 0.7454, 
noisyNet noise sample is [array([-0.48293325], dtype=float32), -1.8083432]. 
=============================================
[2019-03-26 14:46:20,085] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1319429e-21 1.0000000e+00 1.1258124e-20 4.5973528e-18 1.0530334e-28], sum to 1.0000
[2019-03-26 14:46:20,093] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0179
[2019-03-26 14:46:20,098] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 81.33333333333333, 1.0, 2.0, 0.7862657705120224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1155656.439618069, 1155656.43961807, 248331.3772217134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [25.38333333333333, 80.66666666666667, 1.0, 2.0, 0.790140451536843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1156353.602854636, 1156353.602854637, 248658.5106076122], 
processed observation next is [1.0, 0.34782608695652173, 0.4020537124802526, 0.8066666666666668, 1.0, 1.0, 0.7471571705263168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32120933412628777, 0.32120933412628805, 0.3711321053844958], 
reward next is 0.6289, 
noisyNet noise sample is [array([0.75138116], dtype=float32), 0.22651295]. 
=============================================
[2019-03-26 14:46:22,119] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2306897e-14 1.0000000e+00 2.2721725e-14 3.3394303e-09 2.2032668e-20], sum to 1.0000
[2019-03-26 14:46:22,128] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9748
[2019-03-26 14:46:22,132] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.11666666666667, 71.16666666666667, 1.0, 2.0, 0.5830406099764436, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9745598822186562, 6.9112, 6.9112, 168.912956510431, 1630131.796049851, 1630131.796049851, 348468.9873133552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1249800.0000, 
sim time next is 1250400.0000, 
raw observation next is [28.13333333333334, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.149037068088592, 6.9112, 168.9059859502001, 2332470.695015531, 1454342.715204455, 311190.5149278906], 
processed observation next is [1.0, 0.4782608695652174, 0.5323854660347555, 0.7133333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.12378370680885924, 0.0, 0.8294057165104326, 0.6479085263932031, 0.40398408755679305, 0.46446345511625464], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19524606], dtype=float32), 0.21070927]. 
=============================================
[2019-03-26 14:46:24,569] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.177543e-21 1.000000e+00 5.587203e-21 9.188341e-19 1.865611e-30], sum to 1.0000
[2019-03-26 14:46:24,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1164
[2019-03-26 14:46:24,586] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.38333333333333, 94.00000000000001, 1.0, 2.0, 0.4636476081755364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654985.2056787602, 654985.2056787602, 179015.5343339711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1293000.0000, 
sim time next is 1293600.0000, 
raw observation next is [24.36666666666667, 94.0, 1.0, 2.0, 0.46242666146235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653740.3159248809, 653740.3159248809, 178897.1077659755], 
processed observation next is [1.0, 1.0, 0.3538704581358612, 0.94, 1.0, 1.0, 0.3523212788703012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1815945322013558, 0.1815945322013558, 0.26701060860593356], 
reward next is 0.7330, 
noisyNet noise sample is [array([-0.80387294], dtype=float32), -0.67437613]. 
=============================================
[2019-03-26 14:46:27,852] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1991521e-21 1.0000000e+00 4.2555515e-20 3.1738089e-18 1.5042683e-29], sum to 1.0000
[2019-03-26 14:46:27,862] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7708
[2019-03-26 14:46:27,871] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333334, 92.33333333333334, 1.0, 2.0, 0.3012415671543864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480381.7677212527, 480381.7677212527, 165658.9165345882], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1358400.0000, 
sim time next is 1359000.0000, 
raw observation next is [20.85, 92.5, 1.0, 2.0, 0.298805755712317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476170.2542246285, 476170.2542246285, 165354.0656031102], 
processed observation next is [1.0, 0.7391304347826086, 0.18720379146919444, 0.925, 1.0, 1.0, 0.15518765748471924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13226951506239681, 0.13226951506239681, 0.246797112840463], 
reward next is 0.7532, 
noisyNet noise sample is [array([-0.63547695], dtype=float32), 0.4414861]. 
=============================================
[2019-03-26 14:46:27,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.58595 ]
 [70.15192 ]
 [69.80476 ]
 [69.713425]
 [69.7128  ]], R is [[70.91822815]
 [70.96179199]
 [70.99304962]
 [70.95851898]
 [70.92436981]].
[2019-03-26 14:46:31,633] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 14:46:31,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:46:31,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:31,639] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:46:31,641] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:46:31,642] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:46:31,642] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:31,642] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:31,643] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:31,643] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:46:31,648] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:46:31,655] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 14:46:31,675] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 14:46:31,676] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 14:46:31,705] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 14:46:31,729] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 14:46:52,448] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:46:52,450] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.38808217333333, 90.70657375333334, 1.0, 2.0, 0.2691300520957281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 449609.6543953765, 449609.6543953771, 161906.6497446606]
[2019-03-26 14:46:52,453] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:46:52,455] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.6807989e-25 1.0000000e+00 1.7208917e-23 1.1794935e-22 8.5402728e-33], sampled 0.8264160847994283
[2019-03-26 14:47:15,377] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:47:15,378] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.61001511, 87.18391601333333, 1.0, 2.0, 0.3529479346379056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545718.0098251493, 545718.0098251493, 170344.8734312006]
[2019-03-26 14:47:15,379] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:47:15,385] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5674740e-25 1.0000000e+00 7.4312251e-24 4.9139351e-23 2.7085583e-33], sampled 0.028693193112361293
[2019-03-26 14:47:45,586] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:47:45,586] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.7, 69.0, 1.0, 2.0, 0.5554822011804442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 776228.3988372843, 776228.3988372849, 192745.2124667702]
[2019-03-26 14:47:45,588] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:47:45,591] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.0491144e-26 1.0000000e+00 9.6322825e-25 1.6433154e-22 3.0287337e-34], sampled 0.7985148455567491
[2019-03-26 14:47:51,770] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:47:51,771] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.58333333333333, 67.16666666666667, 1.0, 2.0, 0.5756468350030285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 804417.039957859, 804417.039957859, 196296.2475110228]
[2019-03-26 14:47:51,772] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:47:51,774] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3578515e-24 1.0000000e+00 9.8033204e-25 4.3529330e-19 1.0794140e-33], sampled 0.8608584451098591
[2019-03-26 14:47:52,796] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:47:52,797] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.7, 49.0, 1.0, 2.0, 0.8331208008748973, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005983596918577, 6.9112, 168.9123159905847, 2061428.269314817, 1994185.778446391, 416185.109114886]
[2019-03-26 14:47:52,798] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:47:52,801] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.6821372e-15 9.9999988e-01 2.3310095e-16 1.2920813e-07 5.5110797e-22], sampled 0.4901582568298276
[2019-03-26 14:47:52,804] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2061428.269314817 W.
[2019-03-26 14:47:54,974] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:47:54,978] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.18269693333333, 60.31437078333334, 1.0, 2.0, 0.9181869802805279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1283376.736517508, 1283376.736517509, 274985.7099234839]
[2019-03-26 14:47:54,978] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:47:54,982] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1623304e-24 1.0000000e+00 6.4070488e-23 5.6658225e-21 7.4227237e-32], sampled 0.15335744968602272
[2019-03-26 14:48:01,669] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:48:01,671] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.44418519, 97.777818465, 1.0, 2.0, 0.6579888105188121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 919532.6926858762, 919532.6926858762, 212040.4527506169]
[2019-03-26 14:48:01,672] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:48:01,676] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.3411879e-25 1.0000000e+00 1.4721645e-23 2.3597215e-22 8.3028156e-33], sampled 0.6403047364612089
[2019-03-26 14:48:17,396] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0393328], dtype=float32), 0.060751084]
[2019-03-26 14:48:17,398] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.7, 92.33333333333334, 1.0, 2.0, 0.6809797864940342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 957410.1870051591, 957410.1870051591, 217556.9984728628]
[2019-03-26 14:48:17,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:48:17,402] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0613553e-24 1.0000000e+00 3.6978600e-23 5.9472711e-22 2.0888729e-32], sampled 0.6115996746144565
[2019-03-26 14:48:27,932] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 14:48:28,236] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 14:48:28,372] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.3755 2842665225.7252 1130.0000
[2019-03-26 14:48:28,580] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 14:48:28,679] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.7367 3164177959.0640 1776.0000
[2019-03-26 14:48:29,694] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 250000, evaluation results [250000.0, 7883.736728126883, 3164177959.063966, 1776.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.375467898235, 2842665225.725238, 1130.0]
[2019-03-26 14:48:34,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.33409997e-26 1.00000000e+00 1.73285462e-23 9.72666443e-24
 1.15039475e-32], sum to 1.0000
[2019-03-26 14:48:34,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1283
[2019-03-26 14:48:34,792] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
processed observation next is [0.0, 0.4782608695652174, 0.575829383886256, 0.51, 1.0, 1.0, 0.21072769292485147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14726038306485484, 0.14726038306485464, 0.25220070279521645], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.54268205], dtype=float32), 0.62789506]. 
=============================================
[2019-03-26 14:48:34,804] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4662745e-25 1.0000000e+00 3.6494290e-23 1.0080279e-22 1.3176467e-32], sum to 1.0000
[2019-03-26 14:48:34,809] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7798
[2019-03-26 14:48:34,814] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 51.0, 1.0, 2.0, 0.3406595343048348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526195.087827559, 526195.087827559, 168738.9939266162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1508400.0000, 
sim time next is 1509000.0000, 
raw observation next is [28.85, 51.0, 1.0, 2.0, 0.3404076519279594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 525745.5316471308, 525745.5316471303, 168701.1901762203], 
processed observation next is [0.0, 0.4782608695652174, 0.5663507109004741, 0.51, 1.0, 1.0, 0.20531042400958965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14604042545753634, 0.14604042545753618, 0.25179282115853774], 
reward next is 0.7482, 
noisyNet noise sample is [array([-0.11500797], dtype=float32), 0.36424235]. 
=============================================
[2019-03-26 14:48:34,827] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.006424]
 [77.95468 ]
 [77.92699 ]
 [77.8891  ]
 [77.8582  ]], R is [[78.03000641]
 [77.99786377]
 [77.96552277]
 [77.93308258]
 [77.9006958 ]].
[2019-03-26 14:48:35,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8935951e-23 1.0000000e+00 4.4162327e-22 1.8908105e-21 6.0234804e-31], sum to 1.0000
[2019-03-26 14:48:35,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5172
[2019-03-26 14:48:35,981] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 90.0, 1.0, 2.0, 0.3265599017474729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 514528.6383058255, 514528.6383058249, 168092.3358277449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1568400.0000, 
sim time next is 1569000.0000, 
raw observation next is [21.61666666666667, 90.0, 1.0, 2.0, 0.3226006728800868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508495.0533680868, 508495.0533680868, 167634.0193741018], 
processed observation next is [1.0, 0.13043478260869565, 0.22353870458135885, 0.9, 1.0, 1.0, 0.18385623238564675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14124862593557966, 0.14124862593557966, 0.25020002891656984], 
reward next is 0.7498, 
noisyNet noise sample is [array([1.2275233], dtype=float32), 0.8171149]. 
=============================================
[2019-03-26 14:48:35,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.18476]
 [73.17623]
 [73.12634]
 [72.98886]
 [72.84952]], R is [[73.25839233]
 [73.27492523]
 [73.29058838]
 [73.30675507]
 [73.31365967]].
[2019-03-26 14:48:37,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2785851e-23 1.0000000e+00 3.6380051e-22 8.6342082e-21 1.2647262e-30], sum to 1.0000
[2019-03-26 14:48:37,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3218
[2019-03-26 14:48:37,462] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 89.16666666666667, 1.0, 2.0, 0.3066885794240479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484786.7941328553, 484786.7941328558, 165898.6661183088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1572600.0000, 
sim time next is 1573200.0000, 
raw observation next is [21.6, 89.0, 1.0, 2.0, 0.3058931738368764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 483763.8062439788, 483763.8062439788, 165829.6271591172], 
processed observation next is [1.0, 0.21739130434782608, 0.22274881516587688, 0.89, 1.0, 1.0, 0.16372671546611617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13437883506777187, 0.13437883506777187, 0.2475069062076376], 
reward next is 0.7525, 
noisyNet noise sample is [array([0.46874356], dtype=float32), 0.8835596]. 
=============================================
[2019-03-26 14:48:38,142] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3256792e-23 1.0000000e+00 9.9502686e-23 1.8353369e-21 1.9286306e-31], sum to 1.0000
[2019-03-26 14:48:38,151] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6229
[2019-03-26 14:48:38,162] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 86.66666666666666, 1.0, 2.0, 0.3295162887998571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 512497.8895576037, 512497.8895576044, 167766.7195883522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1579200.0000, 
sim time next is 1579800.0000, 
raw observation next is [22.7, 86.33333333333334, 1.0, 2.0, 0.3314633320290751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 514757.528934954, 514757.5289349546, 167919.8037900437], 
processed observation next is [1.0, 0.2608695652173913, 0.27488151658767773, 0.8633333333333334, 1.0, 1.0, 0.19453413497478925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14298820248193167, 0.14298820248193184, 0.25062657282096074], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.60897917], dtype=float32), -1.4025815]. 
=============================================
[2019-03-26 14:48:47,032] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1854187e-22 1.0000000e+00 3.6862464e-20 8.0190189e-18 1.2746608e-29], sum to 1.0000
[2019-03-26 14:48:47,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6686
[2019-03-26 14:48:47,042] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 94.00000000000001, 1.0, 2.0, 0.5072102117221868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713654.1920733452, 713654.1920733452, 185362.3277467391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1739400.0000, 
sim time next is 1740000.0000, 
raw observation next is [24.43333333333334, 94.0, 1.0, 2.0, 0.4719187475649988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664982.1040135298, 664982.1040135304, 180030.1480528139], 
processed observation next is [1.0, 0.13043478260869565, 0.3570300157977887, 0.94, 1.0, 1.0, 0.3637575271867456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1847172511148694, 0.18471725111486956, 0.2687017135116625], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.54032797], dtype=float32), 0.6070196]. 
=============================================
[2019-03-26 14:48:47,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.55653]
 [68.57491]
 [68.49181]
 [68.42634]
 [68.33154]], R is [[68.6889267 ]
 [68.72537994]
 [68.76007843]
 [68.79377747]
 [68.82457733]].
[2019-03-26 14:48:48,014] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.9734884e-21 1.0000000e+00 7.7216648e-21 7.5184111e-19 7.2023212e-30], sum to 1.0000
[2019-03-26 14:48:48,026] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8502
[2019-03-26 14:48:48,029] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 91.66666666666667, 1.0, 2.0, 0.6116227370694627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861469.2550439711, 861469.2550439718, 203804.8178290089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1752000.0000, 
sim time next is 1752600.0000, 
raw observation next is [24.83333333333333, 91.33333333333334, 1.0, 2.0, 0.6240031988811429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 878010.2438542672, 878010.2438542666, 206078.7569151067], 
processed observation next is [1.0, 0.2608695652173913, 0.3759873617693521, 0.9133333333333334, 1.0, 1.0, 0.546991805880895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2438917344039631, 0.24389173440396295, 0.3075802342016518], 
reward next is 0.6924, 
noisyNet noise sample is [array([0.49653542], dtype=float32), 0.71939486]. 
=============================================
[2019-03-26 14:48:48,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8213522e-21 1.0000000e+00 3.6803450e-20 5.0615852e-18 4.1093221e-29], sum to 1.0000
[2019-03-26 14:48:49,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4315
[2019-03-26 14:48:49,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 85.5, 1.0, 2.0, 0.3115334276579558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491038.7222584822, 491038.7222584822, 166324.0711696194], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1791000.0000, 
sim time next is 1791600.0000, 
raw observation next is [22.13333333333333, 86.0, 1.0, 2.0, 0.3135263268917957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 494203.9631851632, 494203.9631851626, 166558.9988818591], 
processed observation next is [1.0, 0.7391304347826086, 0.24802527646129527, 0.86, 1.0, 1.0, 0.17292328541180205, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13727887866254534, 0.13727887866254515, 0.24859552071919266], 
reward next is 0.7514, 
noisyNet noise sample is [array([0.6747838], dtype=float32), 1.4072576]. 
=============================================
[2019-03-26 14:49:03,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.3986079e-24 1.0000000e+00 5.0350379e-22 1.7096456e-21 3.0104121e-31], sum to 1.0000
[2019-03-26 14:49:03,433] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6974
[2019-03-26 14:49:03,441] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 84.66666666666667, 1.0, 2.0, 0.5167793546206902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722126.8266303921, 722126.8266303921, 186266.9261211203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2035200.0000, 
sim time next is 2035800.0000, 
raw observation next is [27.25, 84.0, 1.0, 2.0, 0.5168110363721877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722171.1124931996, 722171.1124931996, 186272.0921017974], 
processed observation next is [0.0, 0.5652173913043478, 0.490521327014218, 0.84, 1.0, 1.0, 0.41784462213516593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20060308680366656, 0.20060308680366656, 0.27801804791313045], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.4201236], dtype=float32), -0.69794333]. 
=============================================
[2019-03-26 14:49:04,137] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6671121e-23 1.0000000e+00 2.1595371e-22 4.3988641e-22 1.7294465e-31], sum to 1.0000
[2019-03-26 14:49:04,147] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-26 14:49:04,154] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 87.66666666666667, 1.0, 2.0, 0.4880166059696301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681922.010016076, 681922.010016076, 181739.8203442827], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2054400.0000, 
sim time next is 2055000.0000, 
raw observation next is [25.85, 87.83333333333334, 1.0, 2.0, 0.4869621855938084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 680448.1610901399, 680448.1610901406, 181578.5221855014], 
processed observation next is [0.0, 0.782608695652174, 0.4241706161137442, 0.8783333333333334, 1.0, 1.0, 0.3818821513178415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1890133780805944, 0.1890133780805946, 0.27101271967985285], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.69817233], dtype=float32), -0.72598]. 
=============================================
[2019-03-26 14:49:04,178] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.76555]
 [74.74218]
 [74.72216]
 [74.69764]
 [74.65701]], R is [[74.75465393]
 [74.7358551 ]
 [74.71695709]
 [74.69789124]
 [74.67862701]].
[2019-03-26 14:49:17,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6966104e-13 9.9996209e-01 3.4909430e-15 3.7882059e-05 5.6957940e-21], sum to 1.0000
[2019-03-26 14:49:17,609] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1727
[2019-03-26 14:49:17,614] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.05, 66.0, 1.0, 2.0, 0.5282412928373225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738148.8461510207, 738148.8461510207, 188142.9405194297], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2309400.0000, 
sim time next is 2310000.0000, 
raw observation next is [31.93333333333333, 66.66666666666666, 1.0, 2.0, 0.5393925599316155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753736.8273538827, 753736.8273538821, 190001.1652287472], 
processed observation next is [1.0, 0.7391304347826086, 0.7124802527646128, 0.6666666666666665, 1.0, 1.0, 0.44505127702604275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2093713409316341, 0.20937134093163393, 0.2835838286996227], 
reward next is 0.7164, 
noisyNet noise sample is [array([-0.65491104], dtype=float32), 2.6919653]. 
=============================================
[2019-03-26 14:49:17,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.79167 ]
 [52.950684]
 [48.71156 ]
 [47.70119 ]
 [47.674236]], R is [[60.05782318]
 [60.17643356]
 [59.57466888]
 [59.59834671]
 [59.33987427]].
[2019-03-26 14:49:18,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6567564e-19 1.0000000e+00 2.1431026e-19 2.0960590e-15 1.0183759e-27], sum to 1.0000
[2019-03-26 14:49:18,714] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0582
[2019-03-26 14:49:18,718] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 80.66666666666667, 1.0, 2.0, 0.553764987147905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773827.8973694084, 773827.8973694084, 192448.6338663476], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2328000.0000, 
sim time next is 2328600.0000, 
raw observation next is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.5521788851898377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771610.6828985944, 771610.682898595, 192175.1877840316], 
processed observation next is [1.0, 0.9565217391304348, 0.5584518167456555, 0.8083333333333332, 1.0, 1.0, 0.4604564881805273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2143363008051651, 0.21433630080516528, 0.2868286384836292], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.64129424], dtype=float32), -0.8817095]. 
=============================================
[2019-03-26 14:49:20,684] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.6894300e-19 1.0000000e+00 2.3818009e-19 2.3757531e-15 7.4195442e-27], sum to 1.0000
[2019-03-26 14:49:20,690] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8802
[2019-03-26 14:49:20,695] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 81.0, 1.0, 2.0, 0.5422697994897759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757758.8608835214, 757758.8608835208, 190483.6204383477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2333400.0000, 
sim time next is 2334000.0000, 
raw observation next is [28.23333333333334, 81.0, 1.0, 2.0, 0.5402690607811881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754962.0681075352, 754962.0681075352, 190145.7248019612], 
processed observation next is [1.0, 0.0, 0.5371248025276465, 0.81, 1.0, 1.0, 0.4461073021460097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20971168558542647, 0.20971168558542647, 0.2837995892566585], 
reward next is 0.7162, 
noisyNet noise sample is [array([0.48491403], dtype=float32), -1.2532907]. 
=============================================
[2019-03-26 14:49:20,716] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.560005]
 [67.21535 ]
 [67.86925 ]
 [67.88453 ]
 [67.88991 ]], R is [[66.15350342]
 [66.20766449]
 [66.26108551]
 [66.31356812]
 [66.36501312]].
[2019-03-26 14:49:21,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2999311e-07 4.5441064e-01 2.9525732e-10 5.4558873e-01 3.8149053e-14], sum to 1.0000
[2019-03-26 14:49:21,901] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 14:49:21,902] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8340
[2019-03-26 14:49:21,902] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:49:21,903] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:49:21,904] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:49:21,906] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:21,906] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:21,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:49:21,908] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.3, 64.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.66735716408867, 6.9112, 168.9088492969631, 2820603.52010695, 2284172.646916687, 474386.1437770503], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2374200.0000, 
sim time next is 2374800.0000, 
raw observation next is [32.33333333333334, 64.0, 1.0, 2.0, 0.9142715421897764, 1.0, 1.0, 0.9142715421897764, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2557252.921708121, 2557252.921708121, 479338.3062552646], 
processed observation next is [1.0, 0.4782608695652174, 0.7314375987361774, 0.64, 1.0, 1.0, 0.8967127014334655, 1.0, 0.5, 0.8967127014334655, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7103480338078114, 0.7103480338078114, 0.7154303078436786], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3373838], dtype=float32), -0.89766806]. 
=============================================
[2019-03-26 14:49:21,908] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:21,908] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:21,908] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:49:21,910] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:49:21,925] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 14:49:21,940] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 14:49:21,957] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 14:49:21,958] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 14:49:21,970] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 14:49:25,750] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:49:25,753] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.20061111, 94.16009848, 1.0, 2.0, 0.2846543542798079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 459135.2225574335, 459135.2225574342, 164214.3222758592]
[2019-03-26 14:49:25,755] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:49:25,757] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5991480e-22 1.0000000e+00 1.2893526e-20 2.7988551e-20 5.8466767e-29], sampled 0.9486294118965692
[2019-03-26 14:49:27,558] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:49:27,559] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.0, 45.0, 1.0, 2.0, 0.2127867075227557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 355592.6506680271, 355592.6506680265, 156487.7012955041]
[2019-03-26 14:49:27,561] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:49:27,563] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3253671e-21 1.0000000e+00 2.8355981e-20 2.1690762e-19 2.0389478e-28], sampled 0.10080538369577285
[2019-03-26 14:49:45,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:49:45,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.73992471833333, 89.00413952166667, 1.0, 2.0, 0.324229892454694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512103.0629921436, 512103.0629921436, 167930.3073972139]
[2019-03-26 14:49:45,725] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:49:45,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.0643117e-22 1.0000000e+00 8.9916253e-21 4.0298919e-19 3.6858778e-29], sampled 0.7123860874083762
[2019-03-26 14:49:59,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:49:59,779] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.45, 73.5, 1.0, 2.0, 0.6918966267376657, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987034334189048, 6.9112, 168.9124417938832, 1863789.368470363, 1809990.045719684, 383603.0758212278]
[2019-03-26 14:49:59,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:49:59,783] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8428691e-09 9.2589146e-01 1.2439595e-11 7.4108578e-02 1.2542014e-15], sampled 0.15850487478537112
[2019-03-26 14:49:59,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1863789.368470363 W.
[2019-03-26 14:50:03,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:50:03,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.13740748333333, 96.55937600333334, 1.0, 2.0, 0.4801931170175482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671552.6836803812, 671552.6836803812, 180623.1985958234]
[2019-03-26 14:50:03,828] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:50:03,832] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7515714e-21 1.0000000e+00 5.4350904e-20 6.1374485e-19 4.1360439e-28], sampled 0.13597944032730025
[2019-03-26 14:50:29,962] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:50:29,963] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.43925822666667, 77.92040516833333, 1.0, 2.0, 0.4254554024408835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632393.1685394623, 632393.1685394616, 177529.9700204706]
[2019-03-26 14:50:29,965] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:50:29,968] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.92556483e-21 1.00000000e+00 4.31541644e-20 1.20129265e-17
 2.43898877e-28], sampled 0.8407984918781252
[2019-03-26 14:50:33,590] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:50:33,592] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.8, 54.5, 1.0, 2.0, 0.7018297852498375, 1.0, 1.0, 0.7018297852498375, 0.0, 1.0, 0.0, 6.9112, 6.9112, 169.0403247858759, 1962561.947299519, 1962561.947299519, 374635.9341517258]
[2019-03-26 14:50:33,593] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:50:33,595] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3527675e-09 8.3480197e-01 7.7335239e-12 1.6519806e-01 6.9006107e-16], sampled 0.40452825672471726
[2019-03-26 14:50:33,596] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1962561.947299519 W.
[2019-03-26 14:50:34,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:50:34,082] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.7741817509567692, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990043042704841, 6.9112, 168.9124226599988, 1978940.399525899, 1923006.608242626, 402158.19059532]
[2019-03-26 14:50:34,082] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:50:34,086] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6239964e-09 9.5165557e-01 4.5986158e-12 4.8344359e-02 2.7464877e-16], sampled 0.37617456068269717
[2019-03-26 14:50:34,086] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1978940.399525899 W.
[2019-03-26 14:50:39,192] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:50:39,194] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.569713755, 72.74465433, 1.0, 2.0, 0.4628674747486393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 646769.5856801391, 646769.5856801384, 177984.6602349813]
[2019-03-26 14:50:39,195] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:50:39,198] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7841137e-16 1.0000000e+00 1.8744475e-17 1.1061442e-10 6.3737701e-24], sampled 0.6723067765452834
[2019-03-26 14:51:17,517] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03685069], dtype=float32), 0.05377126]
[2019-03-26 14:51:17,518] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.56666666666667, 65.83333333333333, 1.0, 2.0, 0.3276482269301539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 511137.3345654921, 511137.3345654915, 167706.2349704732]
[2019-03-26 14:51:17,519] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:51:17,522] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7544668e-21 1.0000000e+00 3.0494143e-20 2.6319013e-19 2.4199069e-28], sampled 0.9556138334909554
[2019-03-26 14:51:18,365] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7947.7509 3156478904.6332 1553.0000
[2019-03-26 14:51:18,583] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.2269 2840072326.0305 1075.0000
[2019-03-26 14:51:18,647] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8665.6543 2778886292.2367 920.0000
[2019-03-26 14:51:18,790] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8027.6119 3003809077.7244 1662.0000
[2019-03-26 14:51:18,862] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.7942 2926252241.2708 1296.0000
[2019-03-26 14:51:19,878] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 275000, evaluation results [275000.0, 7947.7509138941305, 3156478904.633211, 1553.0, 8266.79424605969, 2926252241.2708154, 1296.0, 8665.65425438387, 2778886292.236679, 920.0, 8027.611857764496, 3003809077.724397, 1662.0, 8515.22689019682, 2840072326.030523, 1075.0]
[2019-03-26 14:51:25,748] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1798134e-17 1.0000000e+00 2.2052546e-17 1.5084121e-13 1.7673413e-24], sum to 1.0000
[2019-03-26 14:51:25,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8869
[2019-03-26 14:51:25,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1991375.086080634 W.
[2019-03-26 14:51:25,763] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.35, 86.5, 1.0, 2.0, 0.7121299032552998, 1.0, 1.0, 0.7121299032552998, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1991375.086080634, 1991375.086080634, 379358.7367608983], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2449800.0000, 
sim time next is 2450400.0000, 
raw observation next is [27.23333333333333, 86.66666666666667, 1.0, 2.0, 0.4514330170351978, 1.0, 2.0, 0.4514330170351978, 1.0, 1.0, 0.7752436528032529, 6.911199999999999, 6.9112, 170.5573041426782, 1893470.746327988, 1893470.746327988, 381773.3751288337], 
processed observation next is [1.0, 0.34782608695652173, 0.4897314375987361, 0.8666666666666667, 1.0, 1.0, 0.33907592413879245, 1.0, 1.0, 0.33907592413879245, 1.0, 0.5, 0.7259068936625036, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.525964096202219, 0.525964096202219, 0.5698110076549756], 
reward next is 0.4302, 
noisyNet noise sample is [array([1.2223665], dtype=float32), -0.05476066]. 
=============================================
[2019-03-26 14:51:37,417] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0329416e-23 1.0000000e+00 8.8150460e-23 1.6485285e-20 2.6257281e-31], sum to 1.0000
[2019-03-26 14:51:37,429] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0015
[2019-03-26 14:51:37,433] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 89.83333333333334, 1.0, 2.0, 0.4151983863922045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612542.7685328014, 612542.768532802, 175511.5393493354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2661000.0000, 
sim time next is 2661600.0000, 
raw observation next is [23.66666666666666, 90.66666666666667, 1.0, 2.0, 0.411376980288663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608200.7687486969, 608200.7687486969, 175139.2544711489], 
processed observation next is [0.0, 0.8260869565217391, 0.3206951026856238, 0.9066666666666667, 1.0, 1.0, 0.29081563890200357, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16894465798574915, 0.16894465798574915, 0.26140187234499834], 
reward next is 0.7386, 
noisyNet noise sample is [array([-0.4896873], dtype=float32), 0.14502129]. 
=============================================
[2019-03-26 14:51:53,684] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2918317e-23 1.0000000e+00 6.1093585e-23 1.4971822e-20 1.3802874e-31], sum to 1.0000
[2019-03-26 14:51:53,696] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1064
[2019-03-26 14:51:53,702] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3103253255364233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 490725.9357552922, 490725.9357552929, 166337.3279105634], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2950800.0000, 
sim time next is 2951400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.309942844654496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490120.9203563386, 490120.9203563379, 166292.8501386649], 
processed observation next is [1.0, 0.13043478260869565, 0.19431279620853087, 0.94, 1.0, 1.0, 0.16860583693312772, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13614470009898294, 0.13614470009898275, 0.24819828378905207], 
reward next is 0.7518, 
noisyNet noise sample is [array([-1.2133799], dtype=float32), 2.067351]. 
=============================================
[2019-03-26 14:51:57,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9657174e-23 1.0000000e+00 6.1906744e-22 4.2467459e-20 2.2566144e-30], sum to 1.0000
[2019-03-26 14:51:57,582] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-26 14:51:57,587] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3275383449927264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 521563.783305758, 521563.783305758, 168714.6045830214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3032400.0000, 
sim time next is 3033000.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3136293636407088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499421.3290167285, 499421.3290167285, 167037.5342275142], 
processed observation next is [1.0, 0.08695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.17304742607314313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13872814694909125, 0.13872814694909125, 0.2493097525783794], 
reward next is 0.7507, 
noisyNet noise sample is [array([0.2016579], dtype=float32), -0.7550385]. 
=============================================
[2019-03-26 14:51:57,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.227455]
 [74.12903 ]
 [74.0255  ]
 [73.89299 ]
 [73.857994]], R is [[74.38427734]
 [74.38861847]
 [74.38788605]
 [74.39682007]
 [74.40570831]].
[2019-03-26 14:51:57,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.19201324e-23 1.00000000e+00 3.70054114e-23 8.80843309e-21
 3.35649863e-32], sum to 1.0000
[2019-03-26 14:51:57,917] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6985
[2019-03-26 14:51:57,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3050693866945573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485804.1972196756, 485804.197219675, 166039.5910107884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3021600.0000, 
sim time next is 3022200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3038629939412646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483883.6642718208, 483883.6642718214, 165900.8632374746], 
processed observation next is [1.0, 1.0, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16128071559188503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13441212896439467, 0.13441212896439483, 0.24761322871264868], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.52445334], dtype=float32), 0.050298065]. 
=============================================
[2019-03-26 14:52:01,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7928277e-21 1.0000000e+00 6.1433218e-21 9.1312210e-17 3.7019982e-29], sum to 1.0000
[2019-03-26 14:52:01,900] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9594
[2019-03-26 14:52:01,909] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4318133549108204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 626771.4657089156, 626771.4657089162, 176603.617787309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3088800.0000, 
sim time next is 3089400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.43582088633084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632587.1941608032, 632587.1941608032, 177176.022277576], 
processed observation next is [1.0, 0.782608695652174, 0.28909952606635075, 1.0, 1.0, 1.0, 0.3202661281094458, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17571866504466757, 0.17571866504466757, 0.26444182429488955], 
reward next is 0.7356, 
noisyNet noise sample is [array([-0.84902984], dtype=float32), -0.8849062]. 
=============================================
[2019-03-26 14:52:03,823] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.7138971e-21 1.0000000e+00 8.1723336e-21 1.8466605e-18 1.0717763e-29], sum to 1.0000
[2019-03-26 14:52:03,831] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-26 14:52:03,837] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 89.0, 1.0, 2.0, 0.663191505572691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 996052.9649350531, 996052.9649350538, 221913.1927502466], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3144600.0000, 
sim time next is 3145200.0000, 
raw observation next is [23.66666666666667, 89.0, 1.0, 2.0, 0.7330855957331389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1094865.145498275, 1094865.145498275, 237409.9708477152], 
processed observation next is [1.0, 0.391304347826087, 0.3206951026856243, 0.89, 1.0, 1.0, 0.6784163804013722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3041292070828542, 0.3041292070828542, 0.3543432400712167], 
reward next is 0.6457, 
noisyNet noise sample is [array([0.8667905], dtype=float32), -0.84835416]. 
=============================================
[2019-03-26 14:52:06,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2107455e-14 1.0000000e+00 6.2681645e-15 1.5596978e-08 1.3707551e-21], sum to 1.0000
[2019-03-26 14:52:06,780] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9449
[2019-03-26 14:52:06,788] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1659931.816500618 W.
[2019-03-26 14:52:06,795] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.201625928208909, 6.9112, 168.9110128617343, 1659931.816500618, 1453896.038181299, 311348.5784006009], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3168000.0000, 
sim time next is 3168600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.3703767779160253, 1.0, 1.0, 0.3703767779160253, 1.0, 1.0, 0.6305584814723041, 6.9112, 6.9112, 170.5573041426782, 1553245.634710679, 1553245.634710679, 335460.7880199174], 
processed observation next is [1.0, 0.6956521739130435, 0.4786729857819906, 0.84, 1.0, 1.0, 0.24141780471810276, 1.0, 0.5, 0.24141780471810276, 1.0, 0.5, 0.5494615627711025, 0.0, 0.0, 0.8375144448122397, 0.4314571207529664, 0.4314571207529664, 0.5006877433133096], 
reward next is 0.4993, 
noisyNet noise sample is [array([0.7823492], dtype=float32), 0.75369585]. 
=============================================
[2019-03-26 14:52:07,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4844830e-20 1.0000000e+00 2.4359209e-20 8.2593563e-16 8.7660603e-29], sum to 1.0000
[2019-03-26 14:52:07,361] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0362
[2019-03-26 14:52:07,366] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 90.66666666666667, 1.0, 2.0, 0.4947539045591702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691339.3272651251, 691339.3272651251, 182778.2510657697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3180000.0000, 
sim time next is 3180600.0000, 
raw observation next is [25.5, 91.5, 1.0, 2.0, 0.4924721973161032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688149.9741911981, 688149.9741911988, 182425.0814064551], 
processed observation next is [1.0, 0.8260869565217391, 0.40758293838862564, 0.915, 1.0, 1.0, 0.3885207196579557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19115277060866614, 0.19115277060866634, 0.2722762409051569], 
reward next is 0.7277, 
noisyNet noise sample is [array([1.139314], dtype=float32), -0.9762834]. 
=============================================
[2019-03-26 14:52:12,226] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6445884e-22 1.0000000e+00 2.7673844e-22 1.0642766e-20 9.1714063e-31], sum to 1.0000
[2019-03-26 14:52:12,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5735
[2019-03-26 14:52:12,241] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.00000000000001, 1.0, 2.0, 0.5573041287044418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778775.2857123173, 778775.285712318, 193062.1271549221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3244800.0000, 
sim time next is 3245400.0000, 
raw observation next is [32.5, 63.0, 1.0, 2.0, 0.5598152607579185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782285.6270513296, 782285.6270513296, 193499.3783222623], 
processed observation next is [0.0, 0.5652173913043478, 0.7393364928909952, 0.63, 1.0, 1.0, 0.469656940672191, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21730156306981377, 0.21730156306981377, 0.28880504227203324], 
reward next is 0.7112, 
noisyNet noise sample is [array([1.7271274], dtype=float32), -0.20559198]. 
=============================================
[2019-03-26 14:52:14,443] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 14:52:14,446] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:52:14,446] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:52:14,447] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:52:14,448] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:52:14,448] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:52:14,449] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:52:14,452] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:52:14,453] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:52:14,451] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:52:14,455] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:52:14,471] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 14:52:14,488] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 14:52:14,508] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 14:52:14,511] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 14:52:14,555] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 14:52:20,258] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:52:20,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.65557076, 82.94942037666667, 1.0, 2.0, 0.291411577334683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468615.9738583775, 468615.9738583768, 164863.782886331]
[2019-03-26 14:52:20,262] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:52:20,266] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4048315e-22 1.0000000e+00 5.1390110e-21 6.9255942e-20 1.4493142e-29], sampled 0.29098803417471675
[2019-03-26 14:52:46,273] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:52:46,274] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.88333333333333, 76.33333333333334, 1.0, 2.0, 0.5653684545235572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790048.5438035389, 790048.5438035389, 194471.7247832766]
[2019-03-26 14:52:46,277] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:52:46,280] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8761538e-22 1.0000000e+00 3.0017696e-21 7.0880760e-19 8.5153992e-30], sampled 0.45281092647478627
[2019-03-26 14:52:56,516] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:52:56,517] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.82425755833334, 95.64700508833334, 1.0, 2.0, 0.2830824601341679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 457221.9238681244, 457221.923868125, 164082.5883965658]
[2019-03-26 14:52:56,519] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:52:56,522] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7054752e-22 1.0000000e+00 1.0428836e-20 7.6292383e-19 2.3673228e-29], sampled 0.4026411423043552
[2019-03-26 14:53:06,818] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:53:06,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.16768281333333, 79.69077941333335, 1.0, 2.0, 0.5444928878999771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786980.191679543, 786980.191679543, 194177.0419474473]
[2019-03-26 14:53:06,821] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:53:06,823] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.5129985e-22 1.0000000e+00 3.5257681e-21 3.1869465e-19 7.6836954e-30], sampled 0.430921801591546
[2019-03-26 14:53:17,132] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:53:17,135] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.6004596397817472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839104.5010695005, 839104.5010695005, 200831.6371857367]
[2019-03-26 14:53:17,136] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:53:17,139] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.3393347e-22 1.0000000e+00 2.8577709e-21 3.8510915e-18 7.0524621e-30], sampled 0.9238193380018096
[2019-03-26 14:53:37,817] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04262352], dtype=float32), 0.05913577]
[2019-03-26 14:53:37,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.727044615, 69.538471725, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.334763608347357, 6.9112, 168.9103922449074, 1754446.774115945, 1453960.734164139, 311354.5497844322]
[2019-03-26 14:53:37,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:53:37,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1214940e-18 1.0000000e+00 6.3353196e-18 4.2768184e-14 3.2520379e-25], sampled 0.16073406919618727
[2019-03-26 14:53:37,823] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1754446.774115945 W.
[2019-03-26 14:54:10,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8021.7630 3004833021.3100 1690.0000
[2019-03-26 14:54:10,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8871 2779316024.9392 930.0000
[2019-03-26 14:54:10,567] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7926.4962 3159188993.3952 1616.0000
[2019-03-26 14:54:10,670] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8260.2331 2926873570.4730 1318.0000
[2019-03-26 14:54:10,899] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8512.9020 2840414593.6865 1084.0000
[2019-03-26 14:54:11,913] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 300000, evaluation results [300000.0, 7926.496192120613, 3159188993.3952026, 1616.0, 8260.233066596598, 2926873570.4730425, 1318.0, 8659.88712913878, 2779316024.939223, 930.0, 8021.762990827272, 3004833021.309954, 1690.0, 8512.901951441523, 2840414593.6864686, 1084.0]
[2019-03-26 14:54:14,729] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.5252394e-22 1.0000000e+00 1.5035861e-21 9.3299397e-19 2.2708629e-30], sum to 1.0000
[2019-03-26 14:54:14,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5204
[2019-03-26 14:54:14,742] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.5863972459824612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 819445.6115022216, 819445.6115022221, 198239.279135261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3345600.0000, 
sim time next is 3346200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.586482220004516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 819564.4020562081, 819564.4020562088, 198254.7629639177], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.79, 1.0, 1.0, 0.5017858072343566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2276567783489467, 0.2276567783489469, 0.2959026312894294], 
reward next is 0.7041, 
noisyNet noise sample is [array([0.7317501], dtype=float32), 0.33620843]. 
=============================================
[2019-03-26 14:54:14,948] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2626104e-22 1.0000000e+00 9.7231133e-22 4.5938969e-19 7.9838689e-30], sum to 1.0000
[2019-03-26 14:54:14,957] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7296
[2019-03-26 14:54:14,961] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5387947595640994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752901.1765240583, 752901.176524059, 189897.467371552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3368400.0000, 
sim time next is 3369000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5388179412332851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752933.5816124796, 752933.5816124802, 189901.3645148258], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4443589653413073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20914821711457768, 0.20914821711457784, 0.2834348724101878], 
reward next is 0.7166, 
noisyNet noise sample is [array([0.85076916], dtype=float32), 0.35625184]. 
=============================================
[2019-03-26 14:54:14,975] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.07528 ]
 [74.08263 ]
 [74.09587 ]
 [74.11317 ]
 [74.119415]], R is [[74.03701019]
 [74.01320648]
 [73.98997498]
 [73.96717072]
 [73.94452667]].
[2019-03-26 14:54:15,180] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7191744e-18 1.0000000e+00 7.7376286e-18 9.3439078e-14 1.3361568e-25], sum to 1.0000
[2019-03-26 14:54:15,187] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3023
[2019-03-26 14:54:15,197] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.33333333333334, 1.0, 2.0, 0.9607025276207787, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564061214, 1342839.539890208, 1342839.539890208, 287180.2992397143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3379200.0000, 
sim time next is 3379800.0000, 
raw observation next is [26.05, 93.66666666666667, 1.0, 2.0, 0.9263271978219202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104049, 1294761.493988137, 1294761.493988137, 277281.5065165084], 
processed observation next is [1.0, 0.08695652173913043, 0.43364928909952616, 0.9366666666666668, 1.0, 1.0, 0.9112375877372533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451521746, 0.3596559705522603, 0.3596559705522603, 0.4138529948007588], 
reward next is 0.5861, 
noisyNet noise sample is [array([-0.62967014], dtype=float32), -0.69820416]. 
=============================================
[2019-03-26 14:54:15,555] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8132824e-21 1.0000000e+00 2.0427787e-20 7.6736958e-18 2.9281640e-29], sum to 1.0000
[2019-03-26 14:54:15,562] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9749
[2019-03-26 14:54:15,571] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.5855459607091553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818255.5467687334, 818255.546768734, 198084.2774686287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3344400.0000, 
sim time next is 3345000.0000, 
raw observation next is [30.0, 79.00000000000001, 1.0, 2.0, 0.5863806676398069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819422.435591174, 819422.435591174, 198236.2585279407], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7900000000000001, 1.0, 1.0, 0.5016634549877191, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22761734321977056, 0.22761734321977056, 0.2958750127282697], 
reward next is 0.7041, 
noisyNet noise sample is [array([-0.13154843], dtype=float32), 0.18064216]. 
=============================================
[2019-03-26 14:54:15,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.98159]
 [71.94568]
 [71.92687]
 [71.89363]
 [71.8611 ]], R is [[71.98867035]
 [71.9731369 ]
 [71.95730591]
 [71.94124603]
 [71.9249649 ]].
[2019-03-26 14:54:17,450] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3503553e-21 1.0000000e+00 1.2999609e-20 1.5361426e-17 1.0080133e-28], sum to 1.0000
[2019-03-26 14:54:17,460] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5185
[2019-03-26 14:54:17,469] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5375003237314502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751091.7178992851, 751091.7178992851, 189680.1092237539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3367800.0000, 
sim time next is 3368400.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5387947595640994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752901.1765240583, 752901.176524059, 189897.467371552], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44433103561939685, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2091392157011273, 0.2091392157011275, 0.2834290557784358], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.0468805], dtype=float32), 1.221688]. 
=============================================
[2019-03-26 14:54:20,274] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.2725873e-19 1.0000000e+00 2.1967136e-19 2.3890763e-15 2.0790841e-27], sum to 1.0000
[2019-03-26 14:54:20,285] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3728
[2019-03-26 14:54:20,289] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5078598009336115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709658.8352535367, 709658.8352535367, 184836.8505617697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3459600.0000, 
sim time next is 3460200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5074331952403807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709062.5180404293, 709062.5180404286, 184768.9709951507], 
processed observation next is [1.0, 0.043478260869565216, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 0.4065460183619044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19696181056678594, 0.19696181056678574, 0.2757745835748518], 
reward next is 0.7242, 
noisyNet noise sample is [array([-0.73909074], dtype=float32), 1.0393871]. 
=============================================
[2019-03-26 14:54:24,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8715466e-10 2.8775686e-01 1.5225794e-13 7.1224314e-01 8.0637785e-18], sum to 1.0000
[2019-03-26 14:54:24,786] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0925
[2019-03-26 14:54:24,797] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2633446.898377193 W.
[2019-03-26 14:54:24,800] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.00000000000001, 1.0, 2.0, 0.9414838084399766, 1.0, 2.0, 0.9414838084399766, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2633446.898377193, 2633446.898377193, 494632.162479097], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3504000.0000, 
sim time next is 3504600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9873836134636566, 1.0, 2.0, 0.9873836134636566, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2761976.26038618, 2761976.26038618, 521409.5035090486], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9847995342935622, 1.0, 1.0, 0.9847995342935622, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.76721562788505, 0.76721562788505, 0.7782231395657442], 
reward next is 0.2218, 
noisyNet noise sample is [array([2.4491384], dtype=float32), -0.5792153]. 
=============================================
[2019-03-26 14:54:27,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0259867e-18 1.0000000e+00 3.9213870e-19 3.6506688e-15 5.0940483e-26], sum to 1.0000
[2019-03-26 14:54:27,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9720
[2019-03-26 14:54:27,652] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.8070051035911043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1127892.042392526, 1127892.042392526, 245636.3879014691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3568200.0000, 
sim time next is 3568800.0000, 
raw observation next is [28.33333333333334, 77.33333333333334, 1.0, 2.0, 0.9045561497491644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1264313.182788631, 1264313.182788632, 271192.9351764767], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.7733333333333334, 1.0, 1.0, 0.8850074093363427, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3511981063301753, 0.35119810633017556, 0.40476557489026377], 
reward next is 0.5952, 
noisyNet noise sample is [array([1.5268469], dtype=float32), -0.62992066]. 
=============================================
[2019-03-26 14:54:29,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7275951e-09 4.3584317e-02 6.3109777e-13 9.5641565e-01 5.3837616e-17], sum to 1.0000
[2019-03-26 14:54:29,299] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5263
[2019-03-26 14:54:29,303] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 60.33333333333333, 1.0, 2.0, 0.9261654124482298, 1.0, 2.0, 0.9261654124482298, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2590555.025603159, 2590555.02560316, 485967.6155643824], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3595200.0000, 
sim time next is 3595800.0000, 
raw observation next is [33.0, 59.66666666666667, 1.0, 2.0, 0.9103754633021589, 1.0, 2.0, 0.9103754633021589, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2546344.333872292, 2546344.333872293, 477183.181292757], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.5966666666666667, 1.0, 1.0, 0.8920186304845288, 1.0, 1.0, 0.8920186304845288, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7073178705200812, 0.7073178705200814, 0.7122137034220254], 
reward next is 0.2878, 
noisyNet noise sample is [array([-0.00564056], dtype=float32), -1.6332403]. 
=============================================
[2019-03-26 14:54:29,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7387709e-10 5.3346613e-03 2.8204476e-14 9.9466538e-01 7.9054487e-18], sum to 1.0000
[2019-03-26 14:54:29,431] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7159
[2019-03-26 14:54:29,438] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.66666666666667, 1.0, 2.0, 0.8834520153839845, 1.0, 2.0, 0.8834520153839845, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2470964.27513746, 2470964.27513746, 462544.0468280657], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3597000.0000, 
sim time next is 3597600.0000, 
raw observation next is [33.0, 60.33333333333334, 1.0, 2.0, 0.9249012094401545, 1.0, 2.0, 0.9249012094401545, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2587015.292913978, 2587015.292913978, 485258.8956945941], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.6033333333333334, 1.0, 1.0, 0.9095195294459693, 1.0, 1.0, 0.9095195294459693, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7186153591427716, 0.7186153591427716, 0.7242670084993942], 
reward next is 0.2757, 
noisyNet noise sample is [array([0.15725781], dtype=float32), -0.8153945]. 
=============================================
[2019-03-26 14:54:38,579] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8467813e-09 4.8978790e-03 2.5724117e-13 9.9510205e-01 1.7521355e-17], sum to 1.0000
[2019-03-26 14:54:38,585] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5888
[2019-03-26 14:54:38,594] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3371930.741631567 W.
[2019-03-26 14:54:38,597] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.83333333333334, 61.16666666666666, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.556232153873109, 6.9112, 170.5573041426782, 3371930.741631567, 2909867.971581808, 550106.394074586], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3765000.0000, 
sim time next is 3765600.0000, 
raw observation next is [35.0, 60.0, 1.0, 2.0, 0.8722967241376827, 1.0, 2.0, 0.756738401583104, 1.0, 1.0, 1.03, 7.005111321527098, 6.9112, 170.5573041426782, 3175725.112823181, 3108452.613145002, 581274.631489133], 
processed observation next is [1.0, 0.6086956521739131, 0.8578199052132701, 0.6, 1.0, 1.0, 0.8461406314911839, 1.0, 1.0, 0.7069137368471132, 1.0, 0.5, 1.0365853658536586, 0.009391132152709768, 0.0, 0.8375144448122397, 0.8821458646731057, 0.8634590592069451, 0.8675740768494522], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9624031], dtype=float32), -0.43904847]. 
=============================================
[2019-03-26 14:54:42,989] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4608417e-23 1.0000000e+00 7.0456068e-22 5.5865424e-21 8.9985456e-31], sum to 1.0000
[2019-03-26 14:54:42,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0954
[2019-03-26 14:54:43,001] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 73.33333333333334, 1.0, 2.0, 0.5643785685439304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 788664.7589306388, 788664.7589306394, 194297.4962826935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3831600.0000, 
sim time next is 3832200.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.5634554509898192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 787374.3128332719, 787374.3128332726, 194135.4930703647], 
processed observation next is [0.0, 0.34782608695652173, 0.6445497630331753, 0.725, 1.0, 1.0, 0.47404271203592674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2187150868981311, 0.2187150868981313, 0.28975446726920107], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.42254433], dtype=float32), -0.58375984]. 
=============================================
[2019-03-26 14:54:49,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1068059e-23 1.0000000e+00 3.2649203e-22 2.6993842e-21 1.4571466e-30], sum to 1.0000
[2019-03-26 14:54:49,284] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4199
[2019-03-26 14:54:49,287] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5943540290937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 830568.9589360296, 830568.9589360302, 199699.6121076522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3940800.0000, 
sim time next is 3941400.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5944829802785813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 830749.229837461, 830749.2298374603, 199723.4140715139], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5114252774440737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23076367495485028, 0.2307636749548501, 0.29809464786793116], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.5358866], dtype=float32), 0.23651595]. 
=============================================
[2019-03-26 14:54:51,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.1368565e-20 1.0000000e+00 2.3838176e-20 1.9088955e-18 1.0674722e-28], sum to 1.0000
[2019-03-26 14:54:51,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3868
[2019-03-26 14:54:51,645] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 72.33333333333334, 1.0, 2.0, 0.6140346197662262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 858082.3429757889, 858082.3429757889, 203389.8077019726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3967800.0000, 
sim time next is 3968400.0000, 
raw observation next is [31.66666666666667, 73.66666666666667, 1.0, 2.0, 0.6139478136040033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 857960.9867565677, 857960.9867565683, 203373.476075575], 
processed observation next is [0.0, 0.9565217391304348, 0.6998420221169038, 0.7366666666666667, 1.0, 1.0, 0.5348768838602449, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2383224963212688, 0.23832249632126898, 0.3035425016053358], 
reward next is 0.6965, 
noisyNet noise sample is [array([0.3047694], dtype=float32), 0.6712834]. 
=============================================
[2019-03-26 14:54:56,094] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4487141e-19 1.0000000e+00 1.1458912e-19 1.5740312e-15 1.7106778e-27], sum to 1.0000
[2019-03-26 14:54:56,101] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4228
[2019-03-26 14:54:56,104] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.5401544423213469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754801.8454693147, 754801.8454693141, 190126.5668811943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.5411499810021114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756193.4880246483, 756193.4880246476, 190294.3499238946], 
processed observation next is [1.0, 0.9565217391304348, 0.4865718799368086, 0.8816666666666667, 1.0, 1.0, 0.4471686518097728, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2100537466735134, 0.2100537466735132, 0.2840214177968576], 
reward next is 0.7160, 
noisyNet noise sample is [array([-0.0744387], dtype=float32), 1.2665727]. 
=============================================
[2019-03-26 14:55:06,843] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 14:55:06,844] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:55:06,845] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:55:06,848] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:55:06,849] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:55:06,850] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:55:06,852] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:55:06,852] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:55:06,853] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:55:06,855] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:55:06,848] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:55:06,872] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 14:55:06,890] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 14:55:06,911] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 14:55:06,912] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 14:55:06,945] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 14:55:12,775] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:55:12,776] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.3, 56.5, 1.0, 2.0, 0.2120223948624507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 353719.8353625754, 353719.8353625761, 156730.7148626456]
[2019-03-26 14:55:12,776] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:55:12,778] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9415290e-21 1.0000000e+00 2.6185808e-20 7.7853483e-20 2.4681529e-28], sampled 0.5705697165656226
[2019-03-26 14:55:19,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:55:19,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.53333333333333, 54.66666666666667, 1.0, 2.0, 0.8166785614207506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1141419.193901832, 1141419.193901832, 248042.5241878847]
[2019-03-26 14:55:19,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:55:19,094] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3118593e-20 1.0000000e+00 8.5468476e-20 7.1732458e-18 1.2626890e-27], sampled 0.4602717510203106
[2019-03-26 14:55:52,130] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:55:52,130] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.95, 58.5, 1.0, 2.0, 0.7880032555975559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1101320.776149104, 1101320.776149105, 240988.9999393661]
[2019-03-26 14:55:52,132] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:55:52,135] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6917557e-20 1.0000000e+00 8.5872405e-20 8.2605143e-18 1.2717577e-27], sampled 0.042687934092712765
[2019-03-26 14:56:01,486] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:01,487] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.16666666666666, 64.33333333333334, 1.0, 2.0, 0.9054585370251027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1265575.216239999, 1265575.216239998, 271446.2685502849]
[2019-03-26 14:56:01,488] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:56:01,491] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7438446e-20 1.0000000e+00 1.1801118e-19 2.2640620e-17 2.2125657e-27], sampled 0.39618824561024124
[2019-03-26 14:56:14,683] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:14,684] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.95, 74.33333333333334, 1.0, 2.0, 0.557871524082777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779568.4534399306, 779568.4534399306, 193160.0498585035]
[2019-03-26 14:56:14,685] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:56:14,688] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3729531e-21 1.0000000e+00 7.6623340e-21 2.9658390e-19 4.3435224e-29], sampled 0.7524926927620603
[2019-03-26 14:56:34,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:34,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.4, 79.33333333333333, 1.0, 2.0, 0.5614076911778948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784511.7104704, 784511.7104704, 193777.0904040838]
[2019-03-26 14:56:34,161] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:56:34,164] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2045493e-21 1.0000000e+00 7.3637896e-22 2.6636611e-16 4.2399743e-30], sampled 0.19768433738125502
[2019-03-26 14:56:38,187] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:38,189] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.81515552, 78.26179840500001, 1.0, 2.0, 0.7434476657100311, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005977996468599, 6.9112, 168.9123160292712, 1935929.200908528, 1868690.683161602, 394359.3845196033]
[2019-03-26 14:56:38,190] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 14:56:38,193] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9422906e-15 1.0000000e+00 1.3427653e-15 6.0278713e-12 6.1732942e-22], sampled 0.6007510819589907
[2019-03-26 14:56:38,195] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1935929.200908528 W.
[2019-03-26 14:56:50,759] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:50,762] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.08471247666667, 51.42562142833334, 1.0, 2.0, 0.6904040302222825, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964853.2112067679, 964853.2112067679, 218783.8928814632]
[2019-03-26 14:56:50,764] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:56:50,765] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7594105e-21 1.0000000e+00 4.4781571e-20 1.1585591e-18 5.7746198e-28], sampled 0.9968378509181111
[2019-03-26 14:56:51,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:51,509] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.93333333333333, 89.66666666666667, 1.0, 2.0, 0.7731886028394834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1080605.142696126, 1080605.142696126, 237438.9165761317]
[2019-03-26 14:56:51,512] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:56:51,513] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2963130e-21 1.0000000e+00 3.1976977e-20 1.9554239e-18 2.6749780e-28], sampled 0.6922857606600239
[2019-03-26 14:56:55,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05465009], dtype=float32), 0.0547061]
[2019-03-26 14:56:55,973] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.91666666666667, 92.0, 1.0, 2.0, 0.6932037179371177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1103666.675103436, 1103666.675103435, 235280.3307514945]
[2019-03-26 14:56:55,975] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:56:55,978] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4752577e-20 1.0000000e+00 2.7690042e-19 2.1296741e-17 4.9702751e-27], sampled 0.8942761514141753
[2019-03-26 14:57:03,430] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0373 2842430683.1166 1128.0000
[2019-03-26 14:57:03,531] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.2245 3007721581.5884 1763.0000
[2019-03-26 14:57:03,579] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8658.4063 2779272791.5242 933.0000
[2019-03-26 14:57:03,670] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.6434 3164047400.6380 1761.0000
[2019-03-26 14:57:03,824] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1992 2927431310.6522 1338.0000
[2019-03-26 14:57:04,838] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 325000, evaluation results [325000.0, 7887.643374733997, 3164047400.637985, 1761.0, 8254.199174284404, 2927431310.652249, 1338.0, 8658.40634800084, 2779272791.5242395, 933.0, 7999.224543126327, 3007721581.588374, 1763.0, 8496.03734811582, 2842430683.116641, 1128.0]
[2019-03-26 14:57:09,279] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1346341e-19 1.0000000e+00 6.8672967e-20 1.2693953e-15 5.9987474e-28], sum to 1.0000
[2019-03-26 14:57:09,288] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9797
[2019-03-26 14:57:09,293] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.00000000000001, 1.0, 2.0, 0.6225927536582418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 870046.8009729541, 870046.8009729536, 205030.9167263089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4313400.0000, 
sim time next is 4314000.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6213418748053967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868298.0366210239, 868298.0366210239, 204789.8230371206], 
processed observation next is [1.0, 0.9565217391304348, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5437853913318033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24119389906139552, 0.24119389906139552, 0.30565645229420985], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.41440532], dtype=float32), 0.68283147]. 
=============================================
[2019-03-26 14:57:09,307] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.449802]
 [62.51409 ]
 [62.578423]
 [62.31478 ]
 [62.191154]], R is [[62.37674332]
 [62.44696045]
 [62.51731873]
 [62.58746719]
 [62.65748596]].
[2019-03-26 14:57:12,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6128298e-09 7.6506734e-02 8.3239053e-14 9.2349321e-01 1.3474042e-18], sum to 1.0000
[2019-03-26 14:57:12,199] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1737
[2019-03-26 14:57:12,204] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.66666666666666, 56.83333333333333, 1.0, 2.0, 0.8820568760375852, 1.0, 2.0, 0.7616184775330552, 1.0, 1.0, 1.03, 7.005112091564498, 6.9112, 170.5573041426782, 3196231.026184047, 3128957.974896755, 585001.4532504771], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4377000.0000, 
sim time next is 4377600.0000, 
raw observation next is [36.0, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.976730130392064, 6.9112, 170.5573041426782, 3673501.509032292, 2910218.933637931, 547455.3036580831], 
processed observation next is [1.0, 0.6956521739130435, 0.9052132701421801, 0.57, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.10655301303920642, 0.0, 0.8375144448122397, 1.0204170858423034, 0.8083941482327586, 0.8170974681463926], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.350337], dtype=float32), 0.6513538]. 
=============================================
[2019-03-26 14:57:17,013] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5244922e-24 1.0000000e+00 3.2690440e-23 2.8164892e-24 1.4113332e-32], sum to 1.0000
[2019-03-26 14:57:17,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2392
[2019-03-26 14:57:17,033] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5806552444185281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 811418.5355240678, 811418.5355240684, 197197.4085428665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4431000.0000, 
sim time next is 4431600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5807223512139673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811512.3476430596, 811512.3476430596, 197209.5223463447], 
processed observation next is [0.0, 0.30434782608695654, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4948462062818883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22542009656751655, 0.22542009656751655, 0.2943425706661861], 
reward next is 0.7057, 
noisyNet noise sample is [array([-1.5184523], dtype=float32), -0.96547747]. 
=============================================
[2019-03-26 14:57:19,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8039615e-25 1.0000000e+00 6.2915645e-24 5.2566184e-24 2.1547534e-32], sum to 1.0000
[2019-03-26 14:57:19,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5567
[2019-03-26 14:57:19,790] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5107364156530574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713679.8284751853, 713679.8284751853, 185295.2089790481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4517400.0000, 
sim time next is 4518000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5118758042310636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715272.494265225, 715272.494265225, 185477.5739025362], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41189855931453445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1986868039625625, 0.1986868039625625, 0.27683219985453167], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.9333047], dtype=float32), -2.2557151]. 
=============================================
[2019-03-26 14:57:19,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.73861]
 [69.74402]
 [69.74   ]
 [69.74241]
 [69.74409]], R is [[69.77541351]
 [69.80110168]
 [69.82678986]
 [69.85247803]
 [69.87817383]].
[2019-03-26 14:57:23,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1526964e-25 1.0000000e+00 4.9159553e-25 2.3657386e-25 3.0707076e-34], sum to 1.0000
[2019-03-26 14:57:23,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3953
[2019-03-26 14:57:23,707] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 59.0, 1.0, 2.0, 0.5268508633309894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736205.227550024, 736205.2275500234, 187910.214314848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4554000.0000, 
sim time next is 4554600.0000, 
raw observation next is [31.66666666666667, 60.83333333333334, 1.0, 2.0, 0.5312471535549296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742350.6152273774, 742350.6152273774, 188636.7076648846], 
processed observation next is [0.0, 0.7391304347826086, 0.6998420221169038, 0.6083333333333334, 1.0, 1.0, 0.4352375344035296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20620850422982706, 0.20620850422982706, 0.2815473248729621], 
reward next is 0.7185, 
noisyNet noise sample is [array([-0.3813861], dtype=float32), -0.1521849]. 
=============================================
[2019-03-26 14:57:25,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9372699e-22 1.0000000e+00 1.5771337e-21 1.0944477e-19 4.5998354e-29], sum to 1.0000
[2019-03-26 14:57:25,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2450
[2019-03-26 14:57:25,949] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 88.16666666666667, 1.0, 2.0, 0.5706578546402168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 797442.7510791074, 797442.7510791081, 195406.6287452879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4582200.0000, 
sim time next is 4582800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.5749748095201753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803477.5868381604, 803477.5868381604, 196176.1679645576], 
processed observation next is [1.0, 0.043478260869565216, 0.5260663507109005, 0.89, 1.0, 1.0, 0.4879214572532233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22318821856615567, 0.22318821856615567, 0.29280025069336957], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.21359418], dtype=float32), 0.40690216]. 
=============================================
[2019-03-26 14:57:37,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9591662e-10 9.5753634e-01 4.3582132e-14 4.2463660e-02 1.0222494e-19], sum to 1.0000
[2019-03-26 14:57:37,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2790
[2019-03-26 14:57:37,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2972617.47396937 W.
[2019-03-26 14:57:37,079] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.050945499232194, 6.9112, 168.9006853089982, 2972617.47396937, 1454718.65289929, 309145.7434818732], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4798800.0000, 
sim time next is 4799400.0000, 
raw observation next is [31.91666666666667, 63.33333333333333, 1.0, 2.0, 0.5721815689305696, 1.0, 1.0, 0.5721815689305696, 1.0, 1.0, 0.993690161896052, 6.9112, 6.9112, 170.5573041426782, 2400470.569493795, 2400470.569493795, 468648.7119227098], 
processed observation next is [1.0, 0.5652173913043478, 0.7116903633491314, 0.6333333333333333, 1.0, 1.0, 0.48455610714526454, 1.0, 0.5, 0.48455610714526454, 1.0, 0.5, 0.9923050754829901, 0.0, 0.0, 0.8375144448122397, 0.666797380414943, 0.666797380414943, 0.6994756894368802], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5121397], dtype=float32), -0.25859457]. 
=============================================
[2019-03-26 14:57:40,531] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6473921e-18 1.0000000e+00 6.8864502e-19 1.5814349e-14 1.7958560e-26], sum to 1.0000
[2019-03-26 14:57:40,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7754
[2019-03-26 14:57:40,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1915196.085861738 W.
[2019-03-26 14:57:40,558] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.561204040691552, 6.9112, 168.9093175616714, 1915196.085861738, 1454070.782374474, 311349.5056219258], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4869000.0000, 
sim time next is 4869600.0000, 
raw observation next is [28.66666666666666, 75.66666666666666, 1.0, 2.0, 0.4377103411664891, 1.0, 1.0, 0.4377103411664891, 1.0, 1.0, 0.7520322804004819, 6.911200000000001, 6.9112, 170.5573041426782, 1835863.648738508, 1835863.648738508, 373478.9106610816], 
processed observation next is [1.0, 0.34782608695652173, 0.5576619273301735, 0.7566666666666666, 1.0, 1.0, 0.3225425797186615, 1.0, 0.5, 0.3225425797186615, 1.0, 0.5, 0.6976003419518071, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5099621246495856, 0.5099621246495856, 0.5574312099419129], 
reward next is 0.4426, 
noisyNet noise sample is [array([0.16228907], dtype=float32), 0.38842466]. 
=============================================
[2019-03-26 14:57:48,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.15686625e-08 1.11641698e-01 1.44059261e-11 8.88358235e-01
 2.52337087e-15], sum to 1.0000
[2019-03-26 14:57:48,352] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6276
[2019-03-26 14:57:48,358] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.7187108534141328, 1.0, 2.0, 0.7187108534141328, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2009795.086152675, 2009795.086152675, 382232.830319985], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4962600.0000, 
sim time next is 4963200.0000, 
raw observation next is [30.0, 67.33333333333334, 1.0, 2.0, 0.6909193507812313, 1.0, 2.0, 0.6909193507812313, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1932009.160905292, 1932009.160905292, 370256.4676348914], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.6733333333333335, 1.0, 1.0, 0.6276136756400378, 1.0, 1.0, 0.6276136756400378, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5366692113625812, 0.5366692113625812, 0.5526215934849126], 
reward next is 0.4474, 
noisyNet noise sample is [array([-0.65206707], dtype=float32), 0.09639061]. 
=============================================
[2019-03-26 14:57:50,961] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4508190e-20 1.0000000e+00 2.5252665e-21 2.2514972e-16 1.2339511e-28], sum to 1.0000
[2019-03-26 14:57:50,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1707
[2019-03-26 14:57:50,977] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5082536061360354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710209.303639924, 710209.3036399233, 184899.468040855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005200.0000, 
sim time next is 5005800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4085561329174959, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19760962027711804, 0.19760962027711787, 0.27617083395651554], 
reward next is 0.7238, 
noisyNet noise sample is [array([-1.3411694], dtype=float32), 0.7456153]. 
=============================================
[2019-03-26 14:57:51,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0430664e-22 1.0000000e+00 8.6680299e-22 4.0081806e-20 1.3875531e-29], sum to 1.0000
[2019-03-26 14:57:51,615] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4172
[2019-03-26 14:57:51,620] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5031349410749865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703054.358707691, 703054.3587076915, 184088.7353093144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5034000.0000, 
sim time next is 5034600.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.50525111726647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706012.3749141812, 706012.3749141812, 184422.9075002007], 
processed observation next is [0.0, 0.2608695652173913, 0.4549763033175356, 0.865, 1.0, 1.0, 0.4039170087547831, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19611454858727256, 0.19611454858727256, 0.27525807089582194], 
reward next is 0.7247, 
noisyNet noise sample is [array([-1.0926608], dtype=float32), 1.65341]. 
=============================================
[2019-03-26 14:57:59,723] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3049685e-21 1.0000000e+00 5.4506568e-22 8.2676661e-19 6.5930051e-30], sum to 1.0000
[2019-03-26 14:57:59,731] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1853
[2019-03-26 14:57:59,740] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5417049376440679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756969.2510182518, 756969.2510182523, 190388.4717676915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5160600.0000, 
sim time next is 5161200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5407264224986249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755601.404290123, 755601.404290123, 190223.2730833222], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.446658340359789, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20988927896947862, 0.20988927896947862, 0.28391533296018234], 
reward next is 0.7161, 
noisyNet noise sample is [array([0.40037718], dtype=float32), -0.40530917]. 
=============================================
[2019-03-26 14:58:00,178] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 14:58:00,181] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 14:58:00,184] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 14:58:00,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:58:00,186] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:58:00,186] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 14:58:00,187] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 14:58:00,187] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:58:00,188] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 14:58:00,189] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:58:00,190] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 14:58:00,205] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 14:58:00,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 14:58:00,206] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 14:58:00,258] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 14:58:00,258] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 14:58:03,490] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:58:03,492] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.78499274, 100.0, 1.0, 2.0, 0.4578377080619647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649372.9241337801, 649372.9241337801, 178496.2966145606]
[2019-03-26 14:58:03,493] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:58:03,495] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0873882e-20 1.0000000e+00 4.2367299e-20 2.6397972e-17 2.8793397e-28], sampled 0.031932341429609656
[2019-03-26 14:58:12,392] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:58:12,394] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.11369694, 56.47606043333333, 1.0, 2.0, 0.2501755903002061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 415229.529781752, 415229.529781752, 160690.202859732]
[2019-03-26 14:58:12,394] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 14:58:12,398] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.4418310e-21 1.0000000e+00 2.5911258e-20 3.1863888e-18 1.8973355e-28], sampled 0.5501043935339022
[2019-03-26 14:58:14,727] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:58:14,728] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.1, 76.0, 1.0, 2.0, 0.3429775497773968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532991.5280592366, 532991.528059236, 169377.5767444095]
[2019-03-26 14:58:14,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:58:14,732] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2586573e-21 1.0000000e+00 1.0308910e-20 1.1789426e-18 5.6343749e-29], sampled 0.3659963735929065
[2019-03-26 14:58:36,563] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:58:36,564] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.5, 94.0, 1.0, 2.0, 0.3831757515812039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581333.7701884581, 581333.7701884587, 173115.6427647408]
[2019-03-26 14:58:36,565] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 14:58:36,569] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0169232e-21 1.0000000e+00 4.6346227e-21 1.9832560e-19 2.0458107e-29], sampled 0.41232966164262874
[2019-03-26 14:58:56,991] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:58:56,992] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.55, 76.0, 1.0, 2.0, 0.5614608354344256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 784586.0017392073, 784586.0017392067, 193785.3327706938]
[2019-03-26 14:58:56,994] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:58:56,996] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.6564934e-20 1.0000000e+00 5.1048993e-20 2.0586711e-16 3.6273653e-28], sampled 0.7664178183431417
[2019-03-26 14:59:55,521] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:59:55,523] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.23333333333333, 58.66666666666667, 1.0, 2.0, 0.3011971095360058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484872.5975202323, 484872.597520233, 166007.506802498]
[2019-03-26 14:59:55,524] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 14:59:55,526] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.4554656e-20 1.0000000e+00 6.1370242e-20 6.2353424e-17 6.2325014e-28], sampled 0.8540715983137163
[2019-03-26 14:59:56,178] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8504.6393 2841394710.4713 1101.0000
[2019-03-26 14:59:56,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04904358], dtype=float32), 0.062198404]
[2019-03-26 14:59:56,333] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.83333333333334, 71.83333333333333, 1.0, 2.0, 1.031761615511886, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989061723800313, 6.9112, 168.9124306077061, 2339458.982452462, 2284221.367775112, 473861.9025300157]
[2019-03-26 14:59:56,334] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 14:59:56,338] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2194652e-10 9.2985481e-01 4.0459408e-13 7.0145190e-02 1.3686423e-17], sampled 0.5596289533282266
[2019-03-26 14:59:56,338] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2339458.982452462 W.
[2019-03-26 14:59:56,415] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9131 2779066410.8614 926.0000
[2019-03-26 14:59:56,688] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7921.2036 3159515599.1662 1626.0000
[2019-03-26 14:59:56,698] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.2979 2926668060.7834 1316.0000
[2019-03-26 14:59:56,703] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8013.1994 3005168807.2483 1707.0000
[2019-03-26 14:59:57,717] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 350000, evaluation results [350000.0, 7921.203566166316, 3159515599.1661735, 1626.0, 8261.2978714431, 2926668060.7833676, 1316.0, 8659.913063465823, 2779066410.861412, 926.0, 8013.199352775241, 3005168807.2483087, 1707.0, 8504.63934205434, 2841394710.471333, 1101.0]
[2019-03-26 14:59:59,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5093695e-18 1.0000000e+00 5.5075371e-19 5.9220309e-14 9.2924286e-27], sum to 1.0000
[2019-03-26 14:59:59,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4819
[2019-03-26 14:59:59,702] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.8000358085523481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1118146.439688832, 1118146.439688832, 243917.4897771309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5203800.0000, 
sim time next is 5204400.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.8466628224398641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1183349.622610967, 1183349.622610967, 255685.1474889721], 
processed observation next is [1.0, 0.21739130434782608, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.8152564125781495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3287082285030464, 0.3287082285030464, 0.38161962311786884], 
reward next is 0.6184, 
noisyNet noise sample is [array([-0.20338386], dtype=float32), 0.93912]. 
=============================================
[2019-03-26 15:00:02,223] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7709605e-18 1.0000000e+00 9.3695556e-21 4.9606430e-12 4.5391755e-29], sum to 1.0000
[2019-03-26 15:00:02,232] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0626
[2019-03-26 15:00:02,236] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.88333333333333, 78.16666666666667, 1.0, 2.0, 0.5455422302992248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762333.342581263, 762333.3425812636, 191039.1378951606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5253000.0000, 
sim time next is 5253600.0000, 
raw observation next is [28.86666666666667, 78.33333333333334, 1.0, 2.0, 0.5446517207204091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761088.5107141092, 761088.5107141092, 190887.8003842847], 
processed observation next is [1.0, 0.8260869565217391, 0.567140600315956, 0.7833333333333334, 1.0, 1.0, 0.4513876153257941, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21141347519836365, 0.21141347519836365, 0.2849071647526637], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.0548058], dtype=float32), -1.3871744]. 
=============================================
[2019-03-26 15:00:02,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1675165e-18 1.0000000e+00 2.2827920e-19 1.7069311e-14 2.6622848e-27], sum to 1.0000
[2019-03-26 15:00:02,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2518
[2019-03-26 15:00:02,943] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 82.0, 1.0, 2.0, 0.5512454862350286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770305.8851659923, 770305.885165993, 192014.7141803915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265000.0000, 
sim time next is 5265600.0000, 
raw observation next is [28.5, 82.33333333333333, 1.0, 2.0, 0.5520011049038989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771362.1638402259, 771362.1638402259, 192144.7478012505], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8233333333333333, 1.0, 1.0, 0.46024229506493836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21426726773339608, 0.21426726773339608, 0.2867832056735082], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.5346849], dtype=float32), 0.29159415]. 
=============================================
[2019-03-26 15:00:05,524] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4605077e-18 1.0000000e+00 3.7678105e-19 2.5521203e-14 1.9754265e-26], sum to 1.0000
[2019-03-26 15:00:05,533] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9734
[2019-03-26 15:00:05,539] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.96666666666667, 86.66666666666667, 1.0, 2.0, 0.9336353031729447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1304982.578765579, 1304982.57876558, 279361.8553803675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5293200.0000, 
sim time next is 5293800.0000, 
raw observation next is [29.15, 86.0, 1.0, 2.0, 0.9083826145249925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1269664.694248074, 1269664.694248074, 272258.5698155818], 
processed observation next is [1.0, 0.2608695652173913, 0.5805687203791469, 0.86, 1.0, 1.0, 0.8896176078614367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35268463729113164, 0.35268463729113164, 0.4063560743516146], 
reward next is 0.5936, 
noisyNet noise sample is [array([-0.942845], dtype=float32), -0.59786016]. 
=============================================
[2019-03-26 15:00:07,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1686401e-17 1.0000000e+00 3.2245024e-18 1.9767663e-13 2.9091536e-25], sum to 1.0000
[2019-03-26 15:00:07,945] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8163
[2019-03-26 15:00:07,950] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 79.66666666666667, 1.0, 2.0, 0.6217062605328083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868807.4579748324, 868807.457974833, 204859.7899359629], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5347200.0000, 
sim time next is 5347800.0000, 
raw observation next is [30.7, 80.0, 1.0, 2.0, 0.6197149989281698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866023.6220010631, 866023.6220010631, 204476.6192047563], 
processed observation next is [1.0, 0.9130434782608695, 0.6540284360189573, 0.8, 1.0, 1.0, 0.5418252999134576, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24056211722251752, 0.24056211722251752, 0.305188983887696], 
reward next is 0.6948, 
noisyNet noise sample is [array([1.4000891], dtype=float32), -1.3397335]. 
=============================================
[2019-03-26 15:00:12,304] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2037701e-15 1.0000000e+00 5.6666120e-17 2.7914002e-10 1.2053008e-23], sum to 1.0000
[2019-03-26 15:00:12,313] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2342
[2019-03-26 15:00:12,321] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 82.00000000000001, 1.0, 2.0, 0.6182834709956576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864022.3128965896, 864022.3128965896, 204201.8626631692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5433000.0000, 
sim time next is 5433600.0000, 
raw observation next is [30.26666666666667, 82.0, 1.0, 2.0, 0.6158046336834332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860556.8500148747, 860556.8500148754, 203727.530860143], 
processed observation next is [1.0, 0.9130434782608695, 0.6334913112164299, 0.82, 1.0, 1.0, 0.537114016486064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2390435694485763, 0.2390435694485765, 0.30407094158230297], 
reward next is 0.6959, 
noisyNet noise sample is [array([-0.7617022], dtype=float32), -0.953236]. 
=============================================
[2019-03-26 15:00:14,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.26734559e-12 9.99999762e-01 1.09557654e-13 1.91653783e-07
 2.56660185e-19], sum to 1.0000
[2019-03-26 15:00:14,953] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6885
[2019-03-26 15:00:14,957] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 92.5, 1.0, 2.0, 0.3891189643360455, 1.0, 2.0, 0.3891189643360455, 1.0, 2.0, 0.6757709574438042, 6.911199999999999, 6.9112, 170.5573041426782, 1631904.407911684, 1631904.407911684, 346947.6392106539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5452200.0000, 
sim time next is 5452800.0000, 
raw observation next is [27.93333333333333, 92.33333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.399918476859602, 6.9112, 168.9101704534783, 1800700.385843585, 1453992.396677082, 311354.3366700606], 
processed observation next is [1.0, 0.08695652173913043, 0.522906793048973, 0.9233333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0488718476859602, 0.0, 0.8294262643372025, 0.500194551623218, 0.403886776854745, 0.4647079651791949], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8072807], dtype=float32), -1.3310716]. 
=============================================
[2019-03-26 15:00:15,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5251272e-08 9.9489462e-01 2.9353568e-11 5.1054615e-03 3.9342995e-15], sum to 1.0000
[2019-03-26 15:00:15,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7875
[2019-03-26 15:00:15,074] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2440878.290954014 W.
[2019-03-26 15:00:15,079] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.65, 74.0, 1.0, 2.0, 0.8727057699303697, 1.0, 2.0, 0.8727057699303697, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2440878.290954014, 2440878.290954014, 456829.3025538103], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5473800.0000, 
sim time next is 5474400.0000, 
raw observation next is [31.86666666666667, 73.33333333333334, 1.0, 2.0, 0.8483836842475707, 1.0, 2.0, 0.8483836842475707, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2372787.054557836, 2372787.054557836, 444124.8941504212], 
processed observation next is [1.0, 0.34782608695652173, 0.7093206951026858, 0.7333333333333334, 1.0, 1.0, 0.8173297400573141, 1.0, 1.0, 0.8173297400573141, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6591075151549545, 0.6591075151549545, 0.6628729763439123], 
reward next is 0.3371, 
noisyNet noise sample is [array([-0.9417909], dtype=float32), 1.306048]. 
=============================================
[2019-03-26 15:00:18,625] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7026952e-11 2.0529721e-06 1.0624315e-15 9.9999797e-01 7.4359934e-19], sum to 1.0000
[2019-03-26 15:00:18,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7871
[2019-03-26 15:00:18,639] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.46666666666667, 47.33333333333334, 1.0, 2.0, 1.001045753610715, 1.0, 2.0, 1.001045753610715, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2800235.755806089, 2800235.755806089, 529617.3421745062], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5496000.0000, 
sim time next is 5496600.0000, 
raw observation next is [36.33333333333334, 47.66666666666666, 1.0, 2.0, 1.000435333688128, 1.0, 2.0, 1.000435333688128, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2798526.309142809, 2798526.309142809, 529247.970987057], 
processed observation next is [1.0, 0.6086956521739131, 0.9210110584518172, 0.47666666666666657, 1.0, 1.0, 1.0005244984194313, 1.0, 1.0, 1.0005244984194313, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7773684192063358, 0.7773684192063358, 0.7899223447568015], 
reward next is 0.2101, 
noisyNet noise sample is [array([-1.8917365], dtype=float32), -0.29761484]. 
=============================================
[2019-03-26 15:00:19,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4755932e-18 1.0000000e+00 8.7672418e-19 3.5168747e-14 2.8955356e-25], sum to 1.0000
[2019-03-26 15:00:19,479] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1588
[2019-03-26 15:00:19,484] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 95.0, 1.0, 2.0, 0.8468101052220499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1183555.589092286, 1183555.589092286, 255724.3951900942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5544000.0000, 
sim time next is 5544600.0000, 
raw observation next is [25.76666666666667, 95.0, 1.0, 2.0, 0.7545159704464383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1054495.392701224, 1054495.392701224, 233051.5098288052], 
processed observation next is [1.0, 0.17391304347826086, 0.42022116903633505, 0.95, 1.0, 1.0, 0.7042361089716124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2929153868614511, 0.2929153868614511, 0.34783807437135106], 
reward next is 0.6522, 
noisyNet noise sample is [array([-0.85260886], dtype=float32), 1.1340654]. 
=============================================
[2019-03-26 15:00:20,383] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.0533248e-08 1.3946446e-02 4.6154179e-12 9.8605341e-01 3.8472245e-15], sum to 1.0000
[2019-03-26 15:00:20,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1611
[2019-03-26 15:00:20,391] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.1, 64.0, 1.0, 2.0, 0.8079692912912843, 1.0, 2.0, 0.8079692912912843, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2259652.577151449, 2259652.577151449, 423771.8383621747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5568000.0000, 
sim time next is 5568600.0000, 
raw observation next is [32.3, 63.0, 1.0, 2.0, 0.8109417557736444, 1.0, 2.0, 0.8109417557736444, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2267973.229507399, 2267973.229507399, 425235.3521129282], 
processed observation next is [1.0, 0.43478260869565216, 0.7298578199052131, 0.63, 1.0, 1.0, 0.7722189828598125, 1.0, 1.0, 0.7722189828598125, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6299925637520553, 0.6299925637520553, 0.6346796300192957], 
reward next is 0.3653, 
noisyNet noise sample is [array([1.1653837], dtype=float32), -0.77556646]. 
=============================================
[2019-03-26 15:00:20,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4389668e-16 1.0000000e+00 2.8348019e-17 1.8298357e-13 1.2562576e-24], sum to 1.0000
[2019-03-26 15:00:20,700] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5928
[2019-03-26 15:00:20,706] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 80.83333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.981440663791823, 6.9112, 168.9124306376941, 1503620.042500017, 1453789.053247153, 311352.4929811025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5559000.0000, 
sim time next is 5559600.0000, 
raw observation next is [29.2, 79.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.345313430236915, 6.9112, 168.9047713947167, 2471784.636362526, 1454424.511791837, 310804.4880376042], 
processed observation next is [1.0, 0.34782608695652173, 0.5829383886255924, 0.7966666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.14341134302369155, 0.0, 0.8293997524869833, 0.686606843434035, 0.4040068088310658, 0.4638872955785137], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50938874], dtype=float32), 0.28326073]. 
=============================================
[2019-03-26 15:00:24,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2831096e-23 1.0000000e+00 7.2148038e-23 2.9376987e-20 5.6953695e-32], sum to 1.0000
[2019-03-26 15:00:24,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2818
[2019-03-26 15:00:24,992] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 92.5, 1.0, 2.0, 0.5124915535428118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 716133.2050143813, 716133.2050143807, 185576.0142007713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5625000.0000, 
sim time next is 5625600.0000, 
raw observation next is [25.7, 92.33333333333333, 1.0, 2.0, 0.5112668492724083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714421.2815292643, 714421.2815292637, 185379.8402548226], 
processed observation next is [0.0, 0.08695652173913043, 0.4170616113744076, 0.9233333333333333, 1.0, 1.0, 0.41116487864145573, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19845035598035118, 0.19845035598035102, 0.2766863287385412], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.20726435], dtype=float32), 0.14044869]. 
=============================================
[2019-03-26 15:00:35,295] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0516096e-19 1.0000000e+00 1.5694354e-19 1.0704070e-15 3.0497873e-27], sum to 1.0000
[2019-03-26 15:00:35,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0984
[2019-03-26 15:00:35,308] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 92.0, 1.0, 2.0, 0.7604910440428951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1062850.206865031, 1062850.206865031, 234443.2284224976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5808000.0000, 
sim time next is 5808600.0000, 
raw observation next is [26.45, 91.0, 1.0, 2.0, 0.7641237128576236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1067929.720005651, 1067929.720005651, 235294.4849185148], 
processed observation next is [1.0, 0.21739130434782608, 0.45260663507109006, 0.91, 1.0, 1.0, 0.7158117022381008, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29664714444601414, 0.29664714444601414, 0.35118579838584296], 
reward next is 0.6488, 
noisyNet noise sample is [array([0.9011151], dtype=float32), 0.70196575]. 
=============================================
[2019-03-26 15:00:38,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6648641e-20 1.0000000e+00 1.1069343e-20 3.5487276e-17 3.0054353e-29], sum to 1.0000
[2019-03-26 15:00:38,556] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7394
[2019-03-26 15:00:38,567] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 90.0, 1.0, 2.0, 0.5293183546834279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739654.4246990532, 739654.4246990532, 188317.2765606468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5875200.0000, 
sim time next is 5875800.0000, 
raw observation next is [26.63333333333333, 90.33333333333333, 1.0, 2.0, 0.5301574870471409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740827.4133099086, 740827.4133099093, 188456.0373991262], 
processed observation next is [1.0, 0.0, 0.46129541864139006, 0.9033333333333333, 1.0, 1.0, 0.4339246831893264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20578539258608572, 0.2057853925860859, 0.2812776677598898], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.63346696], dtype=float32), -1.0257565]. 
=============================================
[2019-03-26 15:00:46,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8232481e-09 9.7909719e-02 5.3794176e-13 9.0209031e-01 2.4472178e-17], sum to 1.0000
[2019-03-26 15:00:46,370] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7745
[2019-03-26 15:00:46,376] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.53333333333333, 68.33333333333333, 1.0, 2.0, 0.6093610429643973, 1.0, 2.0, 0.6093610429643973, 1.0, 1.0, 1.03, 6.942967458733204, 6.9112, 170.5573041426782, 2556609.0069443, 2533852.684036104, 491398.6305408156], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6003600.0000, 
sim time next is 6004200.0000, 
raw observation next is [32.76666666666667, 67.66666666666667, 1.0, 2.0, 0.9056793539073119, 1.0, 2.0, 0.9056793539073119, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2533195.876119132, 2533195.876119132, 474608.0776301702], 
processed observation next is [1.0, 0.4782608695652174, 0.7519747235387049, 0.6766666666666667, 1.0, 1.0, 0.8863606673582071, 1.0, 1.0, 0.8863606673582071, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7036655211442033, 0.7036655211442033, 0.7083702651196571], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8619612], dtype=float32), 0.9294839]. 
=============================================
[2019-03-26 15:00:46,992] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.7033233e-10 9.6275264e-01 6.9627805e-13 3.7247397e-02 4.5989902e-18], sum to 1.0000
[2019-03-26 15:00:47,000] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1416
[2019-03-26 15:00:47,017] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1725409.4348632 W.
[2019-03-26 15:00:47,021] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.73333333333333, 83.66666666666667, 1.0, 2.0, 0.4113968084114256, 1.0, 2.0, 0.4113968084114256, 1.0, 1.0, 0.6974648380297523, 6.9112, 6.9112, 170.5573041426782, 1725409.4348632, 1725409.4348632, 356789.1618882262], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6013200.0000, 
sim time next is 6013800.0000, 
raw observation next is [27.3, 82.5, 1.0, 2.0, 0.6400220014923623, 1.0, 2.0, 0.6400220014923623, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1789566.682004438, 1789566.682004438, 349499.1565236505], 
processed observation next is [1.0, 0.6086956521739131, 0.4928909952606636, 0.825, 1.0, 1.0, 0.5662915680630871, 1.0, 1.0, 0.5662915680630871, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4971018561123439, 0.4971018561123439, 0.5216405321248515], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3227416], dtype=float32), -0.8575041]. 
=============================================
[2019-03-26 15:00:52,144] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2495629e-14 9.9999976e-01 1.0543775e-17 2.4278216e-07 3.8198562e-24], sum to 1.0000
[2019-03-26 15:00:52,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-26 15:00:52,155] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.63333333333333, 72.33333333333333, 1.0, 2.0, 0.5003638133132469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699180.8558752972, 699180.8558752972, 183655.5954111921], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6111600.0000, 
sim time next is 6112200.0000, 
raw observation next is [29.46666666666667, 73.16666666666667, 1.0, 2.0, 0.5148129557149443, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719378.1289238803, 719378.1289238796, 185951.0403755068], 
processed observation next is [1.0, 0.7391304347826086, 0.5955766192733019, 0.7316666666666667, 1.0, 1.0, 0.4154372960421016, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1998272580344112, 0.199827258034411, 0.2775388662320997], 
reward next is 0.7225, 
noisyNet noise sample is [array([-0.98048156], dtype=float32), -0.1622786]. 
=============================================
[2019-03-26 15:00:53,049] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 15:00:53,052] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:00:53,052] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:53,052] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:00:53,054] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:00:53,055] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:00:53,057] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:00:53,058] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:53,057] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:53,059] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:53,061] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:00:53,077] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 15:00:53,096] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 15:00:53,096] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 15:00:53,114] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 15:00:53,153] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 15:01:17,801] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:01:17,803] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.28333333333333, 99.0, 1.0, 2.0, 0.4686413268067078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675854.8916661543, 675854.8916661543, 181507.2084592294]
[2019-03-26 15:01:17,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:01:17,808] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5189285e-21 1.0000000e+00 1.1583591e-20 1.0049891e-18 7.1942794e-29], sampled 0.8831375582176713
[2019-03-26 15:01:27,838] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:01:27,839] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.856994635, 65.88943411333334, 1.0, 2.0, 0.908143846806023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1269330.764294858, 1269330.764294858, 272192.7877346356]
[2019-03-26 15:01:27,840] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:01:27,844] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.6398975e-19 1.0000000e+00 4.7212626e-19 3.4503769e-15 1.4646283e-26], sampled 0.938261200966496
[2019-03-26 15:01:31,494] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:01:31,496] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.6, 67.5, 1.0, 2.0, 0.8901025457196329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1244099.303693445, 1244099.303693444, 267227.5665224752]
[2019-03-26 15:01:31,497] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:01:31,500] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4370447e-19 1.0000000e+00 2.1401370e-19 1.6107245e-16 4.8503259e-27], sampled 0.9106127096838944
[2019-03-26 15:02:13,811] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:13,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.69881269, 67.529598415, 1.0, 2.0, 0.6525786428033956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 936724.7871453048, 936724.7871453048, 214183.5761381744]
[2019-03-26 15:02:13,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:02:13,816] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.7935502e-15 1.0000000e+00 1.7510136e-17 1.7836649e-08 1.4644015e-23], sampled 0.027215520448355512
[2019-03-26 15:02:14,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:14,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.2, 50.66666666666666, 1.0, 2.0, 0.9176070535181854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1282565.666348296, 1282565.666348296, 274831.6557221952]
[2019-03-26 15:02:14,257] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:02:14,260] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3919270e-18 1.0000000e+00 8.5665668e-19 4.2536738e-14 5.6714520e-26], sampled 0.3302105982921303
[2019-03-26 15:02:16,754] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:16,755] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.99240825666666, 95.21023565666667, 1.0, 2.0, 0.4335948748464007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 637442.0803832037, 637442.0803832031, 177857.4582227548]
[2019-03-26 15:02:16,757] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:02:16,761] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.9646717e-21 1.0000000e+00 2.1478565e-20 8.8025682e-18 1.2537944e-28], sampled 0.5855989173865134
[2019-03-26 15:02:28,813] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:28,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.45292066, 72.58538549333333, 1.0, 2.0, 0.5346983929147902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747174.9812880536, 747174.9812880536, 189210.9854773468]
[2019-03-26 15:02:28,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:02:28,818] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5017178e-20 1.0000000e+00 6.9338156e-20 7.2906885e-17 9.7907114e-28], sampled 0.7781300300399044
[2019-03-26 15:02:32,271] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:32,272] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.36666666666667, 72.83333333333334, 1.0, 2.0, 0.7988435935571773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1116479.299586987, 1116479.299586987, 243629.3433418546]
[2019-03-26 15:02:32,274] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:02:32,275] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7492968e-19 1.0000000e+00 5.3114379e-19 6.7463125e-16 1.6056367e-26], sampled 0.08555362603362182
[2019-03-26 15:02:48,495] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05147961], dtype=float32), 0.06172318]
[2019-03-26 15:02:48,496] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.65, 63.0, 1.0, 2.0, 0.4313722239882787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679005.9524173245, 679005.9524173245, 182470.8272289177]
[2019-03-26 15:02:48,497] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:02:48,500] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8032066e-20 1.0000000e+00 4.8781393e-20 7.6960926e-18 6.3023371e-28], sampled 0.14897990272004225
[2019-03-26 15:02:48,881] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8287.1895 2924462081.2414 1239.0000
[2019-03-26 15:02:49,383] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8522.1524 2839178249.7275 1046.0000
[2019-03-26 15:02:49,472] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8061.2496 2999040929.4949 1556.0000
[2019-03-26 15:02:49,595] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.2277 2778678340.4990 914.0000
[2019-03-26 15:02:49,596] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7981.5848 3153341024.4027 1468.0000
[2019-03-26 15:02:50,610] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 375000, evaluation results [375000.0, 7981.584764813026, 3153341024.4026756, 1468.0, 8287.189534290532, 2924462081.241431, 1239.0, 8668.227748976971, 2778678340.4990396, 914.0, 8061.249585820701, 2999040929.494931, 1556.0, 8522.152420483426, 2839178249.727517, 1046.0]
[2019-03-26 15:02:59,812] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.0911753e-23 1.0000000e+00 3.1795583e-22 2.8767274e-20 3.7359734e-30], sum to 1.0000
[2019-03-26 15:02:59,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7890
[2019-03-26 15:02:59,823] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 74.83333333333334, 1.0, 2.0, 0.5418757336280602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757208.0034848315, 757208.0034848315, 190417.7333256967], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6256200.0000, 
sim time next is 6256800.0000, 
raw observation next is [29.7, 74.0, 1.0, 2.0, 0.5419591470242147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757324.6055087395, 757324.6055087395, 190431.8515311663], 
processed observation next is [0.0, 0.43478260869565216, 0.6066350710900474, 0.74, 1.0, 1.0, 0.4481435506315839, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21036794597464986, 0.21036794597464986, 0.2842266440763676], 
reward next is 0.7158, 
noisyNet noise sample is [array([1.5390326], dtype=float32), 0.90820986]. 
=============================================
[2019-03-26 15:03:02,924] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8596490e-24 1.0000000e+00 4.6473141e-22 1.3241801e-20 1.9550007e-31], sum to 1.0000
[2019-03-26 15:03:02,933] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4196
[2019-03-26 15:03:02,940] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 89.0, 1.0, 2.0, 0.5239633614847792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732168.9305094335, 732168.9305094341, 187435.6785391268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6325200.0000, 
sim time next is 6325800.0000, 
raw observation next is [26.7, 88.33333333333334, 1.0, 2.0, 0.5241172278506576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732384.012359855, 732384.0123598556, 187460.8875729684], 
processed observation next is [0.0, 0.21739130434782608, 0.46445497630331756, 0.8833333333333334, 1.0, 1.0, 0.4266472624706718, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20344000343329305, 0.20344000343329322, 0.2797923695118931], 
reward next is 0.7202, 
noisyNet noise sample is [array([0.2914352], dtype=float32), -1.005705]. 
=============================================
[2019-03-26 15:03:11,514] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8821069e-17 1.0000000e+00 3.0799067e-18 8.8081282e-14 2.9019367e-26], sum to 1.0000
[2019-03-26 15:03:11,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2174
[2019-03-26 15:03:11,530] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.0, 1.0, 2.0, 0.529803634049017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740332.7766027597, 740332.7766027591, 188397.4127823111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6481800.0000, 
sim time next is 6482400.0000, 
raw observation next is [26.76666666666667, 89.33333333333334, 1.0, 2.0, 0.5304935333408877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741297.158962835, 741297.1589628356, 188511.6617082247], 
processed observation next is [1.0, 0.0, 0.46761453396524505, 0.8933333333333334, 1.0, 1.0, 0.4343295582420333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20591587748967638, 0.20591587748967655, 0.2813606891167533], 
reward next is 0.7186, 
noisyNet noise sample is [array([-1.0197055], dtype=float32), -0.1678239]. 
=============================================
[2019-03-26 15:03:14,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8795569e-10 6.1982822e-01 2.0988586e-13 3.8017181e-01 5.9274884e-19], sum to 1.0000
[2019-03-26 15:03:14,288] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9654
[2019-03-26 15:03:14,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3378256.725940479 W.
[2019-03-26 15:03:14,302] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 55.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.6224836996918, 6.9112, 168.8973049252227, 3378256.725940479, 1454956.984924825, 307513.0225750921], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6528000.0000, 
sim time next is 6528600.0000, 
raw observation next is [31.95, 55.5, 1.0, 2.0, 0.5937953348036765, 1.0, 1.0, 0.5937953348036765, 1.0, 1.0, 1.012646342828929, 6.911199999999999, 6.9112, 170.5573041426782, 2491237.086313058, 2491237.086313059, 481964.9488633493], 
processed observation next is [1.0, 0.5652173913043478, 0.7132701421800948, 0.555, 1.0, 1.0, 0.5105967889200922, 1.0, 0.5, 0.5105967889200922, 1.0, 0.5, 1.015422369303572, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6920103017536272, 0.6920103017536275, 0.7193506699452974], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4635183], dtype=float32), 0.47678545]. 
=============================================
[2019-03-26 15:03:21,443] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5209991e-09 1.1405698e-01 3.9480509e-13 8.8594300e-01 2.2954970e-17], sum to 1.0000
[2019-03-26 15:03:21,455] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7218
[2019-03-26 15:03:21,459] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.41666666666666, 61.0, 1.0, 2.0, 0.7725989046835011, 1.0, 2.0, 0.7725989046835011, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2160639.007712451, 2160639.007712451, 406746.6264204733], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6616200.0000, 
sim time next is 6616800.0000, 
raw observation next is [31.5, 60.0, 1.0, 2.0, 0.7678044310342816, 1.0, 2.0, 0.7678044310342816, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2147217.412723587, 2147217.412723587, 404495.7355635309], 
processed observation next is [1.0, 0.6086956521739131, 0.6919431279620853, 0.6, 1.0, 1.0, 0.7202463024509417, 1.0, 1.0, 0.7202463024509417, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5964492813121075, 0.5964492813121075, 0.6037249784530312], 
reward next is 0.3963, 
noisyNet noise sample is [array([0.53741294], dtype=float32), 0.30422786]. 
=============================================
[2019-03-26 15:03:21,625] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4714552e-18 1.0000000e+00 3.5886928e-19 7.7184192e-15 3.6959343e-27], sum to 1.0000
[2019-03-26 15:03:21,637] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2037
[2019-03-26 15:03:21,640] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 93.0, 1.0, 2.0, 0.4951438552691295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 691884.3983671973, 691884.3983671967, 182838.6206398201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6658200.0000, 
sim time next is 6658800.0000, 
raw observation next is [25.23333333333333, 93.33333333333334, 1.0, 2.0, 0.4954802713285547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692354.6392340903, 692354.639234091, 182890.7910992971], 
processed observation next is [1.0, 0.043478260869565216, 0.39494470774091617, 0.9333333333333335, 1.0, 1.0, 0.3921449052151262, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19232073312058065, 0.19232073312058084, 0.27297132999895085], 
reward next is 0.7270, 
noisyNet noise sample is [array([0.52434003], dtype=float32), 1.948786]. 
=============================================
[2019-03-26 15:03:24,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6308387e-12 9.9999917e-01 1.1778657e-13 8.7434745e-07 3.0828057e-19], sum to 1.0000
[2019-03-26 15:03:24,846] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4228
[2019-03-26 15:03:24,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1922788.864051431 W.
[2019-03-26 15:03:24,863] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.86666666666667, 80.0, 1.0, 2.0, 0.734057858805512, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978348239238416, 6.9112, 168.9125023922674, 1922788.864051431, 1875151.72014325, 393181.3764785601], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6687600.0000, 
sim time next is 6688200.0000, 
raw observation next is [28.03333333333333, 79.0, 1.0, 2.0, 0.4527545052060416, 1.0, 1.0, 0.4527545052060416, 1.0, 2.0, 0.7748766428090954, 6.911199999999999, 6.9112, 170.5573041426782, 1899018.450172822, 1899018.450172823, 382157.7569436601], 
processed observation next is [1.0, 0.391304347826087, 0.5276461295418641, 0.79, 1.0, 1.0, 0.34066807856149595, 1.0, 0.5, 0.34066807856149595, 1.0, 1.0, 0.7254593204988968, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5275051250480061, 0.5275051250480064, 0.5703847118562091], 
reward next is 0.4296, 
noisyNet noise sample is [array([1.3169001], dtype=float32), -0.52782077]. 
=============================================
[2019-03-26 15:03:27,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9339046e-19 1.0000000e+00 3.1239003e-18 6.0768659e-15 9.2843906e-26], sum to 1.0000
[2019-03-26 15:03:27,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9421
[2019-03-26 15:03:27,922] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 66.66666666666667, 1.0, 2.0, 0.8505409820210375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1326035.591225285, 1326035.591225284, 274888.0411811259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6772200.0000, 
sim time next is 6772800.0000, 
raw observation next is [25.66666666666667, 65.33333333333334, 1.0, 2.0, 0.8753163340902249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1364327.620822406, 1364327.620822406, 282170.6310863165], 
processed observation next is [1.0, 0.391304347826087, 0.4154818325434442, 0.6533333333333334, 1.0, 1.0, 0.8497787157713553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3789798946728905, 0.3789798946728905, 0.42115019565121864], 
reward next is 0.5788, 
noisyNet noise sample is [array([0.30287853], dtype=float32), 1.2819809]. 
=============================================
[2019-03-26 15:03:31,752] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6411151e-22 1.0000000e+00 1.2688928e-21 2.5457644e-19 1.7331658e-30], sum to 1.0000
[2019-03-26 15:03:31,761] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0170
[2019-03-26 15:03:31,765] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 80.66666666666667, 1.0, 2.0, 0.3321118661138523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519975.3937631316, 519975.3937631322, 168442.7892429112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6835200.0000, 
sim time next is 6835800.0000, 
raw observation next is [23.11666666666667, 80.83333333333333, 1.0, 2.0, 0.332959164817643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 521217.1551355576, 521217.1551355583, 168538.1069724946], 
processed observation next is [0.0, 0.08695652173913043, 0.29462875197472377, 0.8083333333333332, 1.0, 1.0, 0.19633634315378673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14478254309321043, 0.14478254309321062, 0.251549413391783], 
reward next is 0.7485, 
noisyNet noise sample is [array([1.2623526], dtype=float32), 0.79069406]. 
=============================================
[2019-03-26 15:03:34,623] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.0645187e-24 1.0000000e+00 2.7264346e-22 3.5139904e-22 4.0943415e-32], sum to 1.0000
[2019-03-26 15:03:34,635] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0732
[2019-03-26 15:03:34,642] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.65, 63.5, 1.0, 2.0, 0.3629409892860494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 556058.4220116308, 556058.4220116308, 171071.7768577081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6859800.0000, 
sim time next is 6860400.0000, 
raw observation next is [26.83333333333334, 62.0, 1.0, 2.0, 0.3590494259817629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 551357.4794983586, 551357.4794983593, 170710.9904451374], 
processed observation next is [0.0, 0.391304347826087, 0.4707740916271725, 0.62, 1.0, 1.0, 0.22777039274911196, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1531548554162107, 0.1531548554162109, 0.2547925230524439], 
reward next is 0.7452, 
noisyNet noise sample is [array([0.62930495], dtype=float32), 0.67110837]. 
=============================================
[2019-03-26 15:03:39,222] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.2499504e-22 1.0000000e+00 8.7646919e-21 1.1262430e-18 6.9368754e-30], sum to 1.0000
[2019-03-26 15:03:39,234] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4323
[2019-03-26 15:03:39,238] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.88333333333334, 78.16666666666667, 1.0, 2.0, 0.4264226533309549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 620671.1091066434, 620671.1091066428, 176057.0423806288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6936600.0000, 
sim time next is 6937200.0000, 
raw observation next is [26.1, 77.0, 1.0, 2.0, 0.4275852769461792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621469.6596054427, 621469.6596054421, 176109.5352132057], 
processed observation next is [0.0, 0.30434782608695654, 0.4360189573459717, 0.77, 1.0, 1.0, 0.3103437071640713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17263046100151186, 0.1726304610015117, 0.26285005255702343], 
reward next is 0.7371, 
noisyNet noise sample is [array([-0.8510967], dtype=float32), -2.2689166]. 
=============================================
[2019-03-26 15:03:43,174] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2173934e-18 1.0000000e+00 2.5029532e-18 1.9772867e-13 2.6984506e-26], sum to 1.0000
[2019-03-26 15:03:43,188] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4021
[2019-03-26 15:03:43,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 83.66666666666667, 1.0, 2.0, 0.7935991486742273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1129934.362737885, 1129934.362737885, 245252.8569832499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7008000.0000, 
sim time next is 7008600.0000, 
raw observation next is [25.55, 83.83333333333333, 1.0, 2.0, 0.7558927528392865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1077429.981475543, 1077429.981475543, 236255.2720600047], 
processed observation next is [1.0, 0.08695652173913043, 0.40995260663507116, 0.8383333333333333, 1.0, 1.0, 0.7058948829388993, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2992861059654286, 0.2992861059654286, 0.35261980904478313], 
reward next is 0.6474, 
noisyNet noise sample is [array([-0.35447577], dtype=float32), 0.44148326]. 
=============================================
[2019-03-26 15:03:46,025] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 15:03:46,028] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:03:46,030] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:03:46,030] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:46,030] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:46,031] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:03:46,032] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:03:46,033] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:46,035] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:46,035] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:03:46,037] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:03:46,051] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 15:03:46,051] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 15:03:46,085] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 15:03:46,086] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 15:03:46,123] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 15:03:50,943] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:03:50,945] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.7, 80.0, 1.0, 2.0, 0.260472440547457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 427395.153746268, 427395.1537462687, 161960.8703752357]
[2019-03-26 15:03:50,947] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:03:50,950] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9499403e-20 1.0000000e+00 2.1507274e-19 9.9282651e-18 1.7209342e-27], sampled 0.6559099179631803
[2019-03-26 15:03:52,138] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:03:52,140] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.41666666666666, 71.5, 1.0, 2.0, 0.2500901794458318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 412640.9363083482, 412640.9363083476, 160878.3593277543]
[2019-03-26 15:03:52,142] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:03:52,146] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.4582366e-20 1.0000000e+00 3.0347359e-19 1.4315638e-17 2.7507060e-27], sampled 0.5971539093760316
[2019-03-26 15:04:09,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:04:09,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.3, 53.0, 1.0, 2.0, 0.2929474066696316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472023.7687039952, 472023.7687039952, 165100.5950962658]
[2019-03-26 15:04:09,621] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:04:09,624] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.7648536e-20 1.0000000e+00 2.6612802e-19 9.5791525e-17 2.1595728e-27], sampled 0.1580467014289456
[2019-03-26 15:04:35,230] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:04:35,231] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.62618217666667, 87.22635557333334, 1.0, 2.0, 0.5839604821075427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 816039.110982798, 816039.1109827973, 197795.9511126275]
[2019-03-26 15:04:35,233] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:04:35,239] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3162529e-19 1.0000000e+00 9.1770974e-19 3.1338953e-15 9.2864051e-27], sampled 0.0036784310340531867
[2019-03-26 15:04:39,118] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:04:39,119] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.42421648166667, 82.62762826000001, 1.0, 2.0, 0.8333946104238682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1250863.999357736, 1250863.999357737, 264124.6220591688]
[2019-03-26 15:04:39,120] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:04:39,122] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7382897e-16 1.0000000e+00 5.2109368e-17 9.9162970e-12 3.7285814e-24], sampled 0.12495930150060375
[2019-03-26 15:05:18,442] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:05:18,443] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.4, 76.0, 1.0, 2.0, 0.5552222652839665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775865.0328924601, 775865.0328924607, 192700.0715115292]
[2019-03-26 15:05:18,444] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:05:18,447] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.1213249e-19 1.0000000e+00 6.2620095e-19 3.8594213e-15 5.0804614e-27], sampled 0.9923762242310409
[2019-03-26 15:05:35,384] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0496812], dtype=float32), 0.06504544]
[2019-03-26 15:05:35,386] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.00272265666667, 87.73311333333334, 1.0, 2.0, 0.2365603524509956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 395701.69493977, 395701.6949397707, 151097.5439376443]
[2019-03-26 15:05:35,387] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:05:35,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9694668e-19 1.0000000e+00 6.4841442e-19 1.1114639e-16 6.5853230e-27], sampled 0.7540157120511254
[2019-03-26 15:05:42,372] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8721.3345 2773959675.4607 784.0000
[2019-03-26 15:05:42,474] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8167.8028 3138350193.1242 1000.0000
[2019-03-26 15:05:42,652] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8286.0989 2978714826.8472 1005.0000
[2019-03-26 15:05:42,886] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8401.5132 2914221613.9423 957.0000
[2019-03-26 15:05:42,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8630.2786 2829585088.0547 772.0000
[2019-03-26 15:05:43,909] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 400000, evaluation results [400000.0, 8167.802759049426, 3138350193.1242275, 1000.0, 8401.513192121949, 2914221613.942308, 957.0, 8721.334487933571, 2773959675.460698, 784.0, 8286.09885127585, 2978714826.847212, 1005.0, 8630.27857606853, 2829585088.0547237, 772.0]
[2019-03-26 15:05:47,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2951410e-10 9.4272017e-01 2.6478532e-13 5.7279862e-02 4.7798566e-18], sum to 1.0000
[2019-03-26 15:05:47,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6404
[2019-03-26 15:05:47,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2199698.020116084 W.
[2019-03-26 15:05:47,494] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.13333333333333, 69.66666666666666, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.961979232854413, 6.9112, 168.9071327855885, 2199698.020116084, 1454264.768985351, 311346.2427731004], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7126800.0000, 
sim time next is 7127400.0000, 
raw observation next is [28.01666666666667, 70.33333333333334, 1.0, 2.0, 0.6573715803650535, 1.0, 1.0, 0.6573715803650535, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1838119.4805911, 1838119.4805911, 356396.1419128599], 
processed observation next is [1.0, 0.4782608695652174, 0.5268562401263824, 0.7033333333333335, 1.0, 1.0, 0.5871946751386187, 1.0, 0.5, 0.5871946751386187, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5105887446086389, 0.5105887446086389, 0.5319345401684477], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.83075047], dtype=float32), -1.3365034]. 
=============================================
[2019-03-26 15:05:49,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8861534e-17 1.0000000e+00 4.3396881e-18 2.0451757e-13 3.5641093e-26], sum to 1.0000
[2019-03-26 15:05:49,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4003
[2019-03-26 15:05:49,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 78.5, 1.0, 2.0, 0.478114743326414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 677855.911743498, 677855.9117434974, 181493.3092074225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7111800.0000, 
sim time next is 7112400.0000, 
raw observation next is [26.66666666666667, 77.66666666666667, 1.0, 2.0, 0.483100966773526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683841.17663657, 683841.17663657, 182119.4027895072], 
processed observation next is [1.0, 0.30434782608695654, 0.4628751974723541, 0.7766666666666667, 1.0, 1.0, 0.37723008045003126, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18995588239904723, 0.18995588239904723, 0.2718200041634436], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.11300547], dtype=float32), -1.0751058]. 
=============================================
[2019-03-26 15:05:56,704] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8621303e-19 1.0000000e+00 3.0657568e-19 3.5008640e-15 6.3459541e-28], sum to 1.0000
[2019-03-26 15:05:56,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3586
[2019-03-26 15:05:56,717] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.98333333333333, 88.83333333333334, 1.0, 2.0, 0.3297064896064213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516851.6012024212, 516851.6012024212, 168214.3994703708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7261800.0000, 
sim time next is 7262400.0000, 
raw observation next is [21.96666666666667, 88.66666666666667, 1.0, 2.0, 0.3282714456302778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515091.1879423255, 515091.1879423255, 168089.3177428393], 
processed observation next is [1.0, 0.043478260869565216, 0.24012638230647723, 0.8866666666666667, 1.0, 1.0, 0.1906884887111781, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14308088553953485, 0.14308088553953485, 0.2508795787206557], 
reward next is 0.7491, 
noisyNet noise sample is [array([-0.8735147], dtype=float32), -2.022087]. 
=============================================
[2019-03-26 15:05:58,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3405164e-13 9.9999976e-01 1.9417094e-14 2.2365244e-07 2.9308447e-22], sum to 1.0000
[2019-03-26 15:05:58,566] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8383
[2019-03-26 15:05:58,597] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 60.33333333333333, 1.0, 2.0, 0.8088745397397444, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564868439, 1213912.663520154, 1213912.663520155, 257442.1912661326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7312200.0000, 
sim time next is 7312800.0000, 
raw observation next is [27.73333333333333, 60.66666666666667, 1.0, 2.0, 0.94432099842281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104251, 1425409.503166344, 1425409.503166344, 297758.6304106987], 
processed observation next is [1.0, 0.6521739130434783, 0.513428120063191, 0.6066666666666667, 1.0, 1.0, 0.9329168655696506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451522737, 0.39594708421287333, 0.39594708421287333, 0.4444158662846249], 
reward next is 0.5556, 
noisyNet noise sample is [array([-0.24984904], dtype=float32), -0.42867348]. 
=============================================
[2019-03-26 15:06:01,220] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.6712825e-18 1.0000000e+00 2.8526018e-18 8.4874971e-14 7.1020939e-27], sum to 1.0000
[2019-03-26 15:06:01,227] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0576
[2019-03-26 15:06:01,231] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 92.0, 1.0, 2.0, 0.3077772176570869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497613.4900006487, 497613.4900006493, 166909.734932802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7372800.0000, 
sim time next is 7373400.0000, 
raw observation next is [20.16666666666667, 92.0, 1.0, 2.0, 0.3352619262176988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542173.378754787, 542173.3787547864, 170283.4793762723], 
processed observation next is [1.0, 0.34782608695652173, 0.15481832543443946, 0.92, 1.0, 1.0, 0.19911075447915516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15060371632077418, 0.15060371632077402, 0.2541544468302572], 
reward next is 0.7458, 
noisyNet noise sample is [array([0.49947768], dtype=float32), 1.4468029]. 
=============================================
[2019-03-26 15:06:03,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2417068e-17 1.0000000e+00 1.1321665e-17 5.8957402e-13 3.3736071e-26], sum to 1.0000
[2019-03-26 15:06:03,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5052
[2019-03-26 15:06:03,020] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 86.5, 1.0, 2.0, 0.2814994678713811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 455956.5888777226, 455956.5888777226, 163986.9808121778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7408200.0000, 
sim time next is 7408800.0000, 
raw observation next is [20.8, 86.0, 1.0, 2.0, 0.2817799132103656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 456381.3243507242, 456381.3243507236, 164015.811752537], 
processed observation next is [1.0, 0.782608695652174, 0.1848341232227489, 0.86, 1.0, 1.0, 0.13467459422935615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1267725900974234, 0.12677259009742323, 0.24479971903363731], 
reward next is 0.7552, 
noisyNet noise sample is [array([-0.4504724], dtype=float32), -1.2103229]. 
=============================================
[2019-03-26 15:06:03,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.427898e-18 1.000000e+00 7.525014e-18 6.803253e-14 6.601270e-27], sum to 1.0000
[2019-03-26 15:06:03,283] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8549
[2019-03-26 15:06:03,290] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 89.33333333333333, 1.0, 2.0, 0.3078959167489407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490507.2633486398, 490507.2633486398, 166384.1532738123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7422600.0000, 
sim time next is 7423200.0000, 
raw observation next is [21.2, 90.0, 1.0, 2.0, 0.3078431630587793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490075.2105830322, 490075.2105830322, 166347.9432973092], 
processed observation next is [1.0, 0.9565217391304348, 0.20379146919431282, 0.9, 1.0, 1.0, 0.1660761000708184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13613200293973118, 0.13613200293973118, 0.24828051238404356], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.0872441], dtype=float32), -1.5029026]. 
=============================================
[2019-03-26 15:06:06,937] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3700523e-23 1.0000000e+00 9.4574209e-22 1.5955183e-20 1.2033715e-30], sum to 1.0000
[2019-03-26 15:06:06,946] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2738
[2019-03-26 15:06:06,950] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 95.0, 1.0, 2.0, 0.324788456360997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508829.2329260107, 508829.2329260114, 167586.9011929026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7450800.0000, 
sim time next is 7451400.0000, 
raw observation next is [21.28333333333333, 95.0, 1.0, 2.0, 0.3253127911839967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509433.2232813542, 509433.2232813542, 167627.651623421], 
processed observation next is [0.0, 0.21739130434782608, 0.20774091627172192, 0.95, 1.0, 1.0, 0.18712384479999603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14150922868926505, 0.14150922868926505, 0.2501905248110761], 
reward next is 0.7498, 
noisyNet noise sample is [array([-1.360454], dtype=float32), 1.4379518]. 
=============================================
[2019-03-26 15:06:09,519] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0203499e-21 1.0000000e+00 2.6226294e-20 9.9287953e-18 9.3259735e-30], sum to 1.0000
[2019-03-26 15:06:09,528] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8515
[2019-03-26 15:06:09,533] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 86.0, 1.0, 2.0, 0.4029091002163428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594852.926062885, 594852.926062885, 173873.9932508516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [24.3, 86.33333333333334, 1.0, 2.0, 0.4027598588474285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594720.212489671, 594720.2124896715, 173864.3419595282], 
processed observation next is [0.0, 0.8695652173913043, 0.3507109004739337, 0.8633333333333334, 1.0, 1.0, 0.28043356487641985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1652000590249086, 0.16520005902490875, 0.2594990178500421], 
reward next is 0.7405, 
noisyNet noise sample is [array([0.26745507], dtype=float32), -0.48364875]. 
=============================================
[2019-03-26 15:06:13,615] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0866304e-20 1.0000000e+00 7.0662860e-20 3.2910489e-18 1.0208607e-28], sum to 1.0000
[2019-03-26 15:06:13,624] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2588
[2019-03-26 15:06:13,632] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 79.83333333333334, 1.0, 2.0, 0.4495581731745067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636197.6621211666, 636197.6621211666, 177109.231693985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7552200.0000, 
sim time next is 7552800.0000, 
raw observation next is [26.6, 79.0, 1.0, 2.0, 0.4560601381099816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 642495.2227167956, 642495.222716795, 177676.3413378244], 
processed observation next is [0.0, 0.43478260869565216, 0.4597156398104266, 0.79, 1.0, 1.0, 0.3446507688072067, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17847089519910989, 0.17847089519910975, 0.2651885691609319], 
reward next is 0.7348, 
noisyNet noise sample is [array([1.5923017], dtype=float32), 1.2589166]. 
=============================================
[2019-03-26 15:06:14,108] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.6611651e-21 1.0000000e+00 5.6962300e-20 7.6995866e-18 6.7642289e-29], sum to 1.0000
[2019-03-26 15:06:14,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3506
[2019-03-26 15:06:14,121] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333333, 84.66666666666667, 1.0, 2.0, 0.4823736008480358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674034.3476372827, 674034.3476372827, 180880.7620085391], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7588200.0000, 
sim time next is 7588800.0000, 
raw observation next is [26.2, 86.0, 1.0, 2.0, 0.4845946690601449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 677138.8985563354, 677138.8985563348, 181217.898083836], 
processed observation next is [0.0, 0.8695652173913043, 0.44075829383886256, 0.86, 1.0, 1.0, 0.37902972175921074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18809413848787093, 0.18809413848787077, 0.270474474751994], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.414123], dtype=float32), 0.92670995]. 
=============================================
[2019-03-26 15:06:16,625] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2778188e-18 1.0000000e+00 1.3588771e-17 3.5617613e-13 3.9127960e-26], sum to 1.0000
[2019-03-26 15:06:16,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1864
[2019-03-26 15:06:16,645] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.71666666666667, 91.16666666666667, 1.0, 2.0, 0.6029276688474788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 854008.1614414913, 854008.1614414913, 202772.713782027], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7631400.0000, 
sim time next is 7632000.0000, 
raw observation next is [24.8, 91.0, 1.0, 2.0, 0.5626204026534609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 794781.8612301777, 794781.861230177, 195089.2512603661], 
processed observation next is [1.0, 0.34782608695652173, 0.3744075829383887, 0.91, 1.0, 1.0, 0.47303662970296495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22077273923060492, 0.22077273923060473, 0.2911779869557703], 
reward next is 0.7088, 
noisyNet noise sample is [array([0.5360453], dtype=float32), 1.3209292]. 
=============================================
[2019-03-26 15:06:16,662] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[69.00007 ]
 [69.056656]
 [69.124794]
 [69.14331 ]
 [69.17279 ]], R is [[69.10012054]
 [69.10647583]
 [69.11728668]
 [69.13692474]
 [69.15792084]].
[2019-03-26 15:06:17,342] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2410621e-14 9.9999976e-01 4.6646109e-15 2.5078432e-07 6.8794280e-22], sum to 1.0000
[2019-03-26 15:06:17,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-26 15:06:17,356] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 65.33333333333333, 1.0, 2.0, 1.014968762314355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1418741.847979625, 1418741.847979626, 303516.4203787989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7642200.0000, 
sim time next is 7642800.0000, 
raw observation next is [29.6, 64.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.492263709773955, 6.9112, 168.9101325565075, 1866256.975907176, 1454037.273292058, 311347.1315946931], 
processed observation next is [1.0, 0.4782608695652174, 0.6018957345971565, 0.64, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.05810637097739546, 0.0, 0.8294260782457267, 0.5184047155297711, 0.4038992425811272, 0.46469721133536285], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8142298], dtype=float32), 1.6987497]. 
=============================================
[2019-03-26 15:06:19,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.0706328e-09 5.3897917e-01 2.2758493e-11 4.6102080e-01 2.2618572e-16], sum to 1.0000
[2019-03-26 15:06:19,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4100
[2019-03-26 15:06:19,227] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.23333333333333, 61.33333333333334, 1.0, 2.0, 0.3417541370303987, 1.0, 2.0, 0.3417541370303987, 1.0, 1.0, 0.5771390892059828, 6.9112, 6.9112, 170.5573041426782, 1433130.883961654, 1433130.883961654, 321053.0726386195], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7647600.0000, 
sim time next is 7648200.0000, 
raw observation next is [30.3, 61.0, 1.0, 2.0, 0.9738046232458037, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361164.974416144, 1361164.974416144, 291042.8386072225], 
processed observation next is [1.0, 0.5217391304347826, 0.6350710900473934, 0.61, 1.0, 1.0, 0.9684393051154262, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3781013817822622, 0.3781013817822622, 0.43439229642869026], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48821366], dtype=float32), -1.3326708]. 
=============================================
[2019-03-26 15:06:26,253] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.85251613e-17 1.00000000e+00 1.38183044e-17 7.31943759e-12
 4.53110561e-25], sum to 1.0000
[2019-03-26 15:06:26,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3746
[2019-03-26 15:06:26,267] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 82.0, 1.0, 2.0, 0.7750000565356212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1083138.113945953, 1083138.113945952, 237866.0188770856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7804800.0000, 
sim time next is 7805400.0000, 
raw observation next is [27.8, 81.50000000000001, 1.0, 2.0, 0.7127881500550555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 996150.1304022573, 996150.1304022567, 223629.0965376089], 
processed observation next is [1.0, 0.34782608695652173, 0.5165876777251186, 0.8150000000000002, 1.0, 1.0, 0.653961626572356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2767083695561826, 0.27670836955618244, 0.33377477095165503], 
reward next is 0.6662, 
noisyNet noise sample is [array([-1.1907991], dtype=float32), -0.15172489]. 
=============================================
[2019-03-26 15:06:27,155] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2377367e-16 1.0000000e+00 9.8507821e-17 5.8724810e-11 5.4586836e-24], sum to 1.0000
[2019-03-26 15:06:27,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2194
[2019-03-26 15:06:27,176] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.033352266784503, 6.9112, 168.9124136582439, 1540473.016786713, 1453814.27307785, 311349.7422177122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7806000.0000, 
sim time next is 7806600.0000, 
raw observation next is [28.0, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.269608184639154, 6.9112, 168.9052210898378, 2418050.347225101, 1454392.961246871, 310956.4473081857], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.805, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.13584081846391535, 0.0, 0.8294019606958992, 0.6716806520069726, 0.4039980447907975, 0.46411410045997864], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22462268], dtype=float32), -0.62767655]. 
=============================================
[2019-03-26 15:06:27,472] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8164377e-15 1.0000000e+00 3.4795597e-16 1.0717580e-10 5.3873727e-25], sum to 1.0000
[2019-03-26 15:06:27,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2417
[2019-03-26 15:06:27,497] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 85.66666666666667, 1.0, 2.0, 0.5195943645146639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726061.7533430048, 726061.7533430048, 186723.2850285625], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7762800.0000, 
sim time next is 7763400.0000, 
raw observation next is [27.05, 86.0, 1.0, 2.0, 0.5204531958061286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727262.2629279441, 727262.2629279447, 186862.8848569513], 
processed observation next is [1.0, 0.8695652173913043, 0.4810426540284361, 0.86, 1.0, 1.0, 0.4222327660314802, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20201729525776224, 0.2020172952577624, 0.27889982814470343], 
reward next is 0.7211, 
noisyNet noise sample is [array([0.94986117], dtype=float32), -1.5689427]. 
=============================================
[2019-03-26 15:06:30,347] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2243359e-09 5.8729615e-02 2.7264798e-14 9.4127035e-01 1.9408776e-19], sum to 1.0000
[2019-03-26 15:06:30,355] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 15:06:30,360] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.26666666666667, 67.66666666666667, 1.0, 2.0, 0.7658754756722145, 1.0, 2.0, 0.7658754756722145, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2141817.564468508, 2141817.564468507, 403596.1009006164], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7836000.0000, 
sim time next is 7836600.0000, 
raw observation next is [30.08333333333333, 68.83333333333333, 1.0, 2.0, 0.7738947678929742, 1.0, 2.0, 0.7738947678929742, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2164266.661308516, 2164266.661308516, 407358.3878303243], 
processed observation next is [1.0, 0.6956521739130435, 0.6248025276461293, 0.6883333333333332, 1.0, 1.0, 0.7275840577023786, 1.0, 1.0, 0.7275840577023786, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.60118518369681, 0.60118518369681, 0.6079975937766035], 
reward next is 0.3920, 
noisyNet noise sample is [array([-0.33194074], dtype=float32), 1.0363494]. 
=============================================
[2019-03-26 15:06:31,203] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.3330771e-15 9.9999988e-01 3.8701945e-17 6.9367147e-08 6.8591357e-25], sum to 1.0000
[2019-03-26 15:06:31,209] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5844
[2019-03-26 15:06:31,216] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 82.0, 1.0, 2.0, 0.529958914786915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740549.837199248, 740549.8371992473, 188424.0851788764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7844400.0000, 
sim time next is 7845000.0000, 
raw observation next is [28.05, 83.16666666666667, 1.0, 2.0, 0.5330629759383613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744888.8867115227, 744888.8867115227, 188939.2872390155], 
processed observation next is [1.0, 0.8260869565217391, 0.528436018957346, 0.8316666666666667, 1.0, 1.0, 0.4374252722148931, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20691357964208965, 0.20691357964208965, 0.2819989361776351], 
reward next is 0.7180, 
noisyNet noise sample is [array([1.9462448], dtype=float32), -1.1387621]. 
=============================================
[2019-03-26 15:06:31,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.556694]
 [73.48701 ]
 [74.23722 ]
 [74.851425]
 [75.24075 ]], R is [[71.6325531 ]
 [71.63500214]
 [71.63796997]
 [71.64128113]
 [71.64457703]].
[2019-03-26 15:06:33,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1925468e-10 3.0202631e-02 1.9165802e-13 9.6979743e-01 7.5686706e-19], sum to 1.0000
[2019-03-26 15:06:33,914] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8511
[2019-03-26 15:06:33,922] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.53333333333333, 65.0, 1.0, 2.0, 0.6588076578591744, 1.0, 2.0, 0.6588076578591744, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1842138.442225653, 1842138.442225653, 356984.8246273386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7918800.0000, 
sim time next is 7919400.0000, 
raw observation next is [30.56666666666667, 64.5, 1.0, 2.0, 0.6322849422833603, 1.0, 2.0, 0.6322849422833603, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1767915.230163031, 1767915.230163031, 346478.6910434909], 
processed observation next is [1.0, 0.6521739130434783, 0.6477093206951029, 0.645, 1.0, 1.0, 0.5569698099799522, 1.0, 1.0, 0.5569698099799522, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4910875639341753, 0.4910875639341753, 0.5171323746917774], 
reward next is 0.4829, 
noisyNet noise sample is [array([-0.99003094], dtype=float32), -0.104113355]. 
=============================================
[2019-03-26 15:06:34,153] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8432279e-10 5.7281824e-03 6.6179565e-14 9.9427187e-01 5.4064551e-19], sum to 1.0000
[2019-03-26 15:06:34,164] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4301
[2019-03-26 15:06:34,169] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.2, 70.0, 1.0, 2.0, 0.73628448676006, 1.0, 2.0, 0.73628448676006, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2058985.025972098, 2058985.025972098, 390043.3783889532], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7912800.0000, 
sim time next is 7913400.0000, 
raw observation next is [30.23333333333333, 69.5, 1.0, 2.0, 0.7010504608127845, 1.0, 2.0, 0.7010504608127845, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1960364.575810364, 1960364.575810363, 374573.7118611376], 
processed observation next is [1.0, 0.6086956521739131, 0.6319115323854659, 0.695, 1.0, 1.0, 0.6398198323045596, 1.0, 1.0, 0.6398198323045596, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5445457155028789, 0.5445457155028787, 0.5590652415837875], 
reward next is 0.4409, 
noisyNet noise sample is [array([-0.5875406], dtype=float32), 0.71039146]. 
=============================================
[2019-03-26 15:06:35,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:35,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:35,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 15:06:36,112] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,112] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,115] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 15:06:36,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,255] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 15:06:36,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 15:06:36,448] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,450] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 15:06:36,537] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,537] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 15:06:36,662] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,679] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,762] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,762] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 15:06:36,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 15:06:36,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,807] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,808] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 15:06:36,833] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,833] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,835] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 15:06:36,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,872] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 15:06:36,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:36,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:36,990] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 15:06:37,079] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:37,080] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:37,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 15:06:37,150] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:37,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:37,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 15:06:37,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:37,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:37,191] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 15:06:37,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:06:37,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:37,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 15:06:39,746] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 15:06:39,750] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:06:39,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:39,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:06:39,753] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:06:39,754] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:06:39,754] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:39,755] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:39,756] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:39,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:06:39,759] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:06:39,782] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 15:06:39,783] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 15:06:39,798] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 15:06:39,799] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 15:06:39,799] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 15:06:47,304] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0467194], dtype=float32), 0.073619455]
[2019-03-26 15:06:47,305] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.03115108666667, 87.31292245, 1.0, 2.0, 0.318212921702059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500441.5422682075, 500441.5422682081, 166997.9269881]
[2019-03-26 15:06:47,306] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:06:47,309] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6630940e-20 1.0000000e+00 9.5729276e-20 7.6123231e-18 1.9704196e-28], sampled 0.1326717760398528
[2019-03-26 15:07:10,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0467194], dtype=float32), 0.073619455]
[2019-03-26 15:07:10,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.01666666666667, 85.33333333333334, 1.0, 2.0, 0.5163664178829157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721549.6093522084, 721549.6093522079, 186200.1765266009]
[2019-03-26 15:07:10,321] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:07:10,324] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7876527e-20 1.0000000e+00 6.0467898e-20 2.0290817e-17 1.4406883e-28], sampled 0.21420798724585755
[2019-03-26 15:07:21,143] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0467194], dtype=float32), 0.073619455]
[2019-03-26 15:07:21,145] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.5, 97.0, 1.0, 2.0, 0.3334609077491934, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515505.4628424659, 515505.4628424659, 167904.5039443714]
[2019-03-26 15:07:21,146] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:07:21,151] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3475021e-21 1.0000000e+00 3.0386150e-20 1.6470152e-18 6.9236345e-29], sampled 0.3633174879106177
[2019-03-26 15:08:25,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0467194], dtype=float32), 0.073619455]
[2019-03-26 15:08:25,001] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.3, 81.5, 1.0, 2.0, 0.5837015853968739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 815677.1841568399, 815677.1841568404, 197748.4298906578]
[2019-03-26 15:08:25,002] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:08:25,005] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8456244e-19 1.0000000e+00 1.4820169e-19 8.4634828e-16 3.9448346e-28], sampled 0.8215883644986024
[2019-03-26 15:08:35,547] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7977.3165 3152279462.5833 1458.0000
[2019-03-26 15:08:35,827] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8528.0124 2838431372.0588 1022.0000
[2019-03-26 15:08:35,862] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.7741 2778453757.6048 906.0000
[2019-03-26 15:08:35,925] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8079.0619 2997268983.6345 1497.0000
[2019-03-26 15:08:35,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8292.1063 2923213912.6119 1227.0000
[2019-03-26 15:08:36,943] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 425000, evaluation results [425000.0, 7977.316486567981, 3152279462.58327, 1458.0, 8292.106257431951, 2923213912.6118774, 1227.0, 8668.774108219373, 2778453757.6048417, 906.0, 8079.061883655531, 2997268983.634504, 1497.0, 8528.012418664708, 2838431372.0587826, 1022.0]
[2019-03-26 15:08:43,665] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3514698e-16 1.0000000e+00 7.3320181e-18 6.1789567e-12 3.6907095e-26], sum to 1.0000
[2019-03-26 15:08:43,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-26 15:08:43,682] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 96.0, 1.0, 2.0, 0.387615541709788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583942.8171517242, 583942.8171517242, 173233.1815936358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 152400.0000, 
sim time next is 153000.0000, 
raw observation next is [22.45, 96.0, 1.0, 2.0, 0.3851173570638002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 580498.9012723201, 580498.9012723208, 172932.974181683], 
processed observation next is [1.0, 0.782608695652174, 0.26303317535545023, 0.96, 1.0, 1.0, 0.25917753863108456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1612496947978667, 0.16124969479786688, 0.2581089166890791], 
reward next is 0.7419, 
noisyNet noise sample is [array([-1.943091], dtype=float32), -1.4732672]. 
=============================================
[2019-03-26 15:08:43,701] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.06455 ]
 [68.00346 ]
 [67.903366]
 [67.81146 ]
 [67.73545 ]], R is [[68.158638  ]
 [68.2184906 ]
 [68.27815247]
 [68.33792114]
 [68.3973999 ]].
[2019-03-26 15:08:47,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8212304e-23 1.0000000e+00 5.6063967e-21 8.4223005e-21 2.2447490e-30], sum to 1.0000
[2019-03-26 15:08:47,916] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7408
[2019-03-26 15:08:47,924] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.88333333333334, 91.66666666666667, 1.0, 2.0, 0.301606091918902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481326.6202784381, 481326.6202784388, 165731.2482351321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 213000.0000, 
sim time next is 213600.0000, 
raw observation next is [20.96666666666667, 91.33333333333334, 1.0, 2.0, 0.3037413313631027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484300.2789703728, 484300.2789703728, 165939.3758367369], 
processed observation next is [0.0, 0.4782608695652174, 0.1927330173775673, 0.9133333333333334, 1.0, 1.0, 0.1611341341724129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.134527855269548, 0.134527855269548, 0.24767071020408493], 
reward next is 0.7523, 
noisyNet noise sample is [array([-0.12955223], dtype=float32), 1.286964]. 
=============================================
[2019-03-26 15:08:52,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6291895e-24 1.0000000e+00 2.2912686e-22 5.5150522e-23 1.7594042e-31], sum to 1.0000
[2019-03-26 15:08:52,390] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7141
[2019-03-26 15:08:52,397] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 76.5, 1.0, 2.0, 0.3147652218626529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 495543.5162170169, 495543.5162170163, 166643.9633841207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304200.0000, 
sim time next is 304800.0000, 
raw observation next is [23.53333333333333, 76.33333333333333, 1.0, 2.0, 0.3164592760256142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498106.7996662029, 498106.7996662023, 166832.9639899812], 
processed observation next is [0.0, 0.5217391304347826, 0.3143759873617693, 0.7633333333333333, 1.0, 1.0, 0.17645695906700504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1383629999072786, 0.1383629999072784, 0.24900442386564356], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.8485789], dtype=float32), -1.3140706]. 
=============================================
[2019-03-26 15:08:55,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.2963799e-20 1.0000000e+00 2.6237616e-19 1.2419016e-16 1.0491926e-27], sum to 1.0000
[2019-03-26 15:08:55,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-26 15:08:55,205] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.06666666666667, 74.0, 1.0, 2.0, 0.4619755834979364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752241.4872019907, 752241.4872019907, 189065.6488971295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 382800.0000, 
sim time next is 383400.0000, 
raw observation next is [22.15, 73.5, 1.0, 2.0, 0.4780898799845202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 778347.4763162672, 778347.4763162679, 191802.4131019234], 
processed observation next is [1.0, 0.43478260869565216, 0.24881516587677724, 0.735, 1.0, 1.0, 0.3711926264873738, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2162076323100742, 0.2162076323100744, 0.28627225836107967], 
reward next is 0.7137, 
noisyNet noise sample is [array([-2.1351066], dtype=float32), 0.10299862]. 
=============================================
[2019-03-26 15:09:00,055] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.32242008e-21 1.00000000e+00 4.48220538e-21 1.12044145e-17
 6.51164979e-29], sum to 1.0000
[2019-03-26 15:09:00,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4266
[2019-03-26 15:09:00,069] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2376285661083507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 392091.3341572003, 392091.3341572003, 159676.3655643652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 438600.0000, 
sim time next is 439200.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2375883467431448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 392025.2315532363, 392025.2315532357, 159672.5643642883], 
processed observation next is [1.0, 0.08695652173913043, 0.127962085308057, 0.85, 1.0, 1.0, 0.08143174306402987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10889589765367676, 0.10889589765367658, 0.2383172602452064], 
reward next is 0.7617, 
noisyNet noise sample is [array([0.38022184], dtype=float32), -1.6062118]. 
=============================================
[2019-03-26 15:09:00,452] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0200469e-21 1.0000000e+00 1.4860809e-20 1.7219477e-17 2.1932609e-29], sum to 1.0000
[2019-03-26 15:09:00,459] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3360
[2019-03-26 15:09:00,466] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.00000000000001, 1.0, 2.0, 0.2389475910213506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394263.9203123889, 394263.9203123889, 159801.1288835176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 436200.0000, 
sim time next is 436800.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2397853028395814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 395649.4862059378, 395649.4862059372, 159880.4258597444], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08407867811997759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10990263505720495, 0.10990263505720478, 0.2386275012832006], 
reward next is 0.7614, 
noisyNet noise sample is [array([-0.07829159], dtype=float32), -0.41115445]. 
=============================================
[2019-03-26 15:09:02,861] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8509335e-19 1.0000000e+00 1.2551975e-19 2.5286771e-15 5.1063197e-28], sum to 1.0000
[2019-03-26 15:09:02,871] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9411
[2019-03-26 15:09:02,876] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 57.5, 1.0, 2.0, 0.2428323260854071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399503.9608848941, 399503.9608848948, 160206.8695239888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 495000.0000, 
sim time next is 495600.0000, 
raw observation next is [23.66666666666666, 58.66666666666667, 1.0, 2.0, 0.2441484281831629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401794.9482600507, 401794.9482600507, 160331.1385596043], 
processed observation next is [1.0, 0.7391304347826086, 0.3206951026856238, 0.5866666666666667, 1.0, 1.0, 0.08933545564236493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11160970785001408, 0.11160970785001408, 0.23930020680537956], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.79212457], dtype=float32), -0.3658808]. 
=============================================
[2019-03-26 15:09:03,512] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.4249702e-21 1.0000000e+00 4.3105113e-21 5.2964507e-17 7.5128075e-30], sum to 1.0000
[2019-03-26 15:09:03,523] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4494
[2019-03-26 15:09:03,527] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.66666666666667, 82.0, 1.0, 2.0, 0.2388942770793331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395431.8616058314, 395431.8616058314, 159716.1237722852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 508800.0000, 
sim time next is 509400.0000, 
raw observation next is [19.6, 82.5, 1.0, 2.0, 0.2383751792109612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394586.0703036775, 394586.0703036775, 159665.8583637842], 
processed observation next is [1.0, 0.9130434782608695, 0.127962085308057, 0.825, 1.0, 1.0, 0.08237973398910989, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10960724175102153, 0.10960724175102153, 0.23830725128923017], 
reward next is 0.7617, 
noisyNet noise sample is [array([-0.7852934], dtype=float32), 1.0409404]. 
=============================================
[2019-03-26 15:09:11,971] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.0892094e-21 1.0000000e+00 1.3683630e-20 2.1249430e-17 1.5982828e-29], sum to 1.0000
[2019-03-26 15:09:11,981] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5923
[2019-03-26 15:09:11,986] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.16666666666667, 82.0, 1.0, 2.0, 0.2206262193336021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 366859.060484131, 366859.0604841316, 157813.1331042344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 628800.0000, 
sim time next is 629400.0000, 
raw observation next is [19.38333333333334, 81.0, 1.0, 2.0, 0.2198474705210321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 365308.693004809, 365308.6930048096, 157792.595963085], 
processed observation next is [1.0, 0.2608695652173913, 0.11769352290679343, 0.81, 1.0, 1.0, 0.060057193398833836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10147463694578028, 0.10147463694578045, 0.23551133725833584], 
reward next is 0.7645, 
noisyNet noise sample is [array([-0.0411946], dtype=float32), 0.11388218]. 
=============================================
[2019-03-26 15:09:17,868] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1923173e-24 1.0000000e+00 3.7246453e-23 9.9075771e-24 3.8583871e-32], sum to 1.0000
[2019-03-26 15:09:17,877] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-26 15:09:17,884] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 93.0, 1.0, 2.0, 0.2613040230641719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 426970.1042571639, 426970.1042571633, 162020.1651532058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 795000.0000, 
sim time next is 795600.0000, 
raw observation next is [19.4, 93.0, 1.0, 2.0, 0.2615543259106438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 427379.0794828273, 427379.0794828273, 162045.7391234416], 
processed observation next is [0.0, 0.21739130434782608, 0.11848341232227487, 0.93, 1.0, 1.0, 0.11030641675981182, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11871641096745202, 0.11871641096745202, 0.2418593121245397], 
reward next is 0.7581, 
noisyNet noise sample is [array([1.6992705], dtype=float32), -1.7405351]. 
=============================================
[2019-03-26 15:09:23,616] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6481678e-25 1.0000000e+00 5.9360035e-23 1.7892540e-22 1.3293801e-32], sum to 1.0000
[2019-03-26 15:09:23,624] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2161
[2019-03-26 15:09:23,630] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 63.0, 1.0, 2.0, 0.286036871083085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 459124.5221740489, 459124.5221740482, 164207.0414795893], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 826800.0000, 
sim time next is 827400.0000, 
raw observation next is [24.63333333333334, 63.0, 1.0, 2.0, 0.2852090371693841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 458069.2428035328, 458069.2428035334, 164137.1022577812], 
processed observation next is [0.0, 0.5652173913043478, 0.3665086887835707, 0.63, 1.0, 1.0, 0.13880606887877603, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12724145633431466, 0.12724145633431483, 0.2449807496384794], 
reward next is 0.7550, 
noisyNet noise sample is [array([0.71962684], dtype=float32), -0.079512306]. 
=============================================
[2019-03-26 15:09:26,354] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7462542e-21 1.0000000e+00 1.7194180e-20 2.4324412e-18 7.1015958e-30], sum to 1.0000
[2019-03-26 15:09:26,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5626
[2019-03-26 15:09:26,372] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 85.0, 1.0, 2.0, 0.3024544091692027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480719.1836881607, 480719.1836881614, 165658.2429373475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 855000.0000, 
sim time next is 855600.0000, 
raw observation next is [21.86666666666667, 85.33333333333333, 1.0, 2.0, 0.3024213540901036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480559.3748945583, 480559.3748945583, 165644.8633146615], 
processed observation next is [0.0, 0.9130434782608695, 0.23538704581358633, 0.8533333333333333, 1.0, 1.0, 0.15954380010855856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1334887152484884, 0.1334887152484884, 0.24723113927561416], 
reward next is 0.7528, 
noisyNet noise sample is [array([-0.6682205], dtype=float32), 0.18263334]. 
=============================================
[2019-03-26 15:09:30,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.39296043e-22 1.00000000e+00 6.20391679e-21 3.27776651e-19
 1.11272085e-29], sum to 1.0000
[2019-03-26 15:09:30,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1657
[2019-03-26 15:09:31,003] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 90.0, 1.0, 2.0, 0.3377349946549137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 523230.9448159701, 523230.9448159695, 168549.9614464556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 940800.0000, 
sim time next is 941400.0000, 
raw observation next is [22.25, 90.5, 1.0, 2.0, 0.3385836251916731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524352.7180643793, 524352.7180643787, 168633.4857772651], 
processed observation next is [0.0, 0.9130434782608695, 0.2535545023696683, 0.905, 1.0, 1.0, 0.20311280143575075, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14565353279566093, 0.14565353279566076, 0.25169176981681357], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.24755661], dtype=float32), 0.59143436]. 
=============================================
[2019-03-26 15:09:32,131] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 15:09:32,139] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:09:32,141] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:09:32,142] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:09:32,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:09:32,143] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:09:32,144] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:09:32,145] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:09:32,145] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:09:32,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:09:32,150] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:09:32,166] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 15:09:32,183] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 15:09:32,204] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 15:09:32,205] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 15:09:32,238] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 15:09:36,293] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:09:36,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.63333333333334, 87.0, 1.0, 2.0, 0.3060199014625193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 486341.1507683891, 486341.1507683891, 166063.3599309269]
[2019-03-26 15:09:36,299] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:09:36,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2793279e-21 1.0000000e+00 9.8302661e-21 4.3735552e-19 1.2103192e-29], sampled 0.3827399752395233
[2019-03-26 15:10:02,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:10:02,247] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.1, 97.33333333333334, 1.0, 2.0, 0.4669774741565006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 656237.0641911187, 656237.064191118, 179064.9579631308]
[2019-03-26 15:10:02,247] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:10:02,249] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0523292e-22 1.0000000e+00 2.1189407e-21 3.9375891e-20 2.5371024e-30], sampled 0.1278875196898155
[2019-03-26 15:10:09,384] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:10:09,387] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.25, 91.0, 1.0, 2.0, 0.5519825497080537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771336.2255356542, 771336.2255356548, 192141.6382926534]
[2019-03-26 15:10:09,387] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:10:09,390] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9830844e-20 1.0000000e+00 1.8647168e-20 7.9749761e-16 1.4454383e-29], sampled 0.050784116697161985
[2019-03-26 15:10:21,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:10:21,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.4777443173591125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667563.6857008231, 667563.6857008224, 180182.4715767051]
[2019-03-26 15:10:21,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:10:21,321] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7804421e-22 1.0000000e+00 2.7868680e-21 5.8891221e-20 3.5054742e-30], sampled 0.22198705826984666
[2019-03-26 15:10:37,397] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:10:37,398] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 86.5, 1.0, 2.0, 0.5992317017352357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 837387.8586051587, 837387.8586051594, 200602.6772273063]
[2019-03-26 15:10:37,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:10:37,403] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2322574e-21 1.0000000e+00 3.8745592e-21 1.2527346e-18 4.5896498e-30], sampled 0.47970133287769
[2019-03-26 15:10:45,511] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:10:45,512] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.46666666666667, 64.33333333333334, 1.0, 2.0, 0.5506388124867918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769457.817225854, 769457.8172258534, 191910.2134054366]
[2019-03-26 15:10:45,512] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:10:45,515] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.9762475e-21 1.0000000e+00 9.7535435e-21 2.2325350e-17 1.0488034e-29], sampled 0.6445782986102015
[2019-03-26 15:11:03,929] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:11:03,929] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.42534369, 66.98861843, 1.0, 2.0, 0.972071298869695, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510401, 1413937.570130427, 1413937.570130427, 298929.4598307451]
[2019-03-26 15:11:03,931] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:11:03,937] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6126117e-16 1.0000000e+00 4.6856519e-17 4.7183916e-11 1.4572177e-24], sampled 0.3547174698650071
[2019-03-26 15:11:10,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:11:10,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.6654128531676959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947290.1127677842, 947290.1127677842, 215851.9789133081]
[2019-03-26 15:11:10,752] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:11:10,756] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.0261078e-21 1.0000000e+00 1.5959080e-20 3.4207268e-18 2.9059313e-29], sampled 0.37246769067416485
[2019-03-26 15:11:20,749] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04467577], dtype=float32), 0.0766084]
[2019-03-26 15:11:20,751] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.38846899, 84.19283708, 1.0, 2.0, 0.7515574699028936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1050358.610707649, 1050358.610707648, 232369.3773410751]
[2019-03-26 15:11:20,751] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:11:20,757] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5849284e-21 1.0000000e+00 2.0690592e-20 3.6524044e-18 4.2772265e-29], sampled 0.6566366121798781
[2019-03-26 15:11:23,940] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7921.4948 3159835106.5923 1652.0000
[2019-03-26 15:11:24,231] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8008.0621 3006393675.4275 1731.0000
[2019-03-26 15:11:24,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1645 2779289328.2534 931.0000
[2019-03-26 15:11:24,746] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.7513 2841533553.0498 1107.0000
[2019-03-26 15:11:24,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8260.0874 2926646696.6853 1315.0000
[2019-03-26 15:11:25,766] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 450000, evaluation results [450000.0, 7921.494818391171, 3159835106.59231, 1652.0, 8260.087353921046, 2926646696.6852775, 1315.0, 8659.164540067432, 2779289328.2534313, 931.0, 8008.06205103363, 3006393675.427465, 1731.0, 8501.751316492147, 2841533553.0497613, 1107.0]
[2019-03-26 15:11:25,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5383975e-21 1.0000000e+00 2.3068367e-21 1.1409107e-18 1.4838988e-29], sum to 1.0000
[2019-03-26 15:11:25,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8093
[2019-03-26 15:11:25,910] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3803033263627877, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589522.8986981047, 589522.8986981041, 174136.7082311656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 976200.0000, 
sim time next is 976800.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3449124497226351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534645.4057453935, 534645.4057453941, 169474.8919889455], 
processed observation next is [1.0, 0.30434782608695654, 0.23696682464454974, 0.93, 1.0, 1.0, 0.21073789123209044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14851261270705374, 0.1485126127070539, 0.25294759998350075], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.33522466], dtype=float32), 0.8662609]. 
=============================================
[2019-03-26 15:11:26,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8549908e-19 1.0000000e+00 5.2476560e-19 2.8309686e-15 1.1189963e-27], sum to 1.0000
[2019-03-26 15:11:26,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2912
[2019-03-26 15:11:26,365] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 95.0, 1.0, 2.0, 0.4102773023912795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634948.3089447392, 634948.3089447386, 178232.2694986775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 997200.0000, 
sim time next is 997800.0000, 
raw observation next is [21.68333333333333, 95.16666666666667, 1.0, 2.0, 0.3863456947753357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598072.0404958345, 598072.0404958345, 174882.9244018733], 
processed observation next is [1.0, 0.5652173913043478, 0.22669826224328585, 0.9516666666666667, 1.0, 1.0, 0.2606574635847418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16613112235995403, 0.16613112235995403, 0.26101929015204967], 
reward next is 0.7390, 
noisyNet noise sample is [array([-0.5901066], dtype=float32), 1.4219629]. 
=============================================
[2019-03-26 15:11:29,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9071768e-19 1.0000000e+00 6.2896817e-20 1.8582808e-15 1.1407656e-28], sum to 1.0000
[2019-03-26 15:11:29,577] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9417
[2019-03-26 15:11:29,583] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 97.83333333333334, 1.0, 2.0, 0.3713452241191626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563523.7318817053, 563523.731881706, 171552.6863757075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1033800.0000, 
sim time next is 1034400.0000, 
raw observation next is [22.06666666666667, 97.66666666666667, 1.0, 2.0, 0.3720308147603605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564311.300097655, 564311.3000976543, 171613.2578318562], 
processed observation next is [1.0, 1.0, 0.2448657187993683, 0.9766666666666667, 1.0, 1.0, 0.2434106201932054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15675313891601528, 0.15675313891601508, 0.25613919079381525], 
reward next is 0.7439, 
noisyNet noise sample is [array([1.3278409], dtype=float32), 0.5559769]. 
=============================================
[2019-03-26 15:11:29,868] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.4126401e-20 1.0000000e+00 8.8109237e-20 2.6966753e-15 1.6883235e-28], sum to 1.0000
[2019-03-26 15:11:29,876] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8565
[2019-03-26 15:11:29,882] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 97.0, 1.0, 2.0, 0.377724004722255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570211.8655197289, 570211.8655197289, 172045.3802369176], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1038600.0000, 
sim time next is 1039200.0000, 
raw observation next is [22.33333333333333, 97.0, 1.0, 2.0, 0.3792489163321904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571882.005666602, 571882.005666602, 172173.1355732288], 
processed observation next is [1.0, 0.0, 0.2575039494470772, 0.97, 1.0, 1.0, 0.2521071281110727, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15885611268516725, 0.15885611268516725, 0.2569748292137743], 
reward next is 0.7430, 
noisyNet noise sample is [array([-0.22479597], dtype=float32), -1.1528913]. 
=============================================
[2019-03-26 15:11:33,183] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1216268e-17 1.0000000e+00 1.2241778e-17 1.6307437e-12 2.3081688e-26], sum to 1.0000
[2019-03-26 15:11:33,191] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3117
[2019-03-26 15:11:33,199] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 72.5, 1.0, 2.0, 0.3301714180145942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516698.9302897274, 516698.9302897268, 168180.979037402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1104600.0000, 
sim time next is 1105200.0000, 
raw observation next is [24.2, 73.0, 1.0, 2.0, 0.3295946731302897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 516485.2663641399, 516485.2663641393, 168181.3163408892], 
processed observation next is [1.0, 0.8260869565217391, 0.3459715639810427, 0.73, 1.0, 1.0, 0.19228273871119236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14346812954559443, 0.14346812954559424, 0.2510168900610287], 
reward next is 0.7490, 
noisyNet noise sample is [array([-0.15850608], dtype=float32), -1.3831096]. 
=============================================
[2019-03-26 15:11:38,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9183936e-17 1.0000000e+00 3.4182354e-18 2.9224241e-13 1.4323938e-25], sum to 1.0000
[2019-03-26 15:11:38,605] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2709
[2019-03-26 15:11:38,611] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 59.66666666666666, 1.0, 2.0, 0.9932054985899973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1511620.455253242, 1511620.455253242, 315129.8249189805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1176000.0000, 
sim time next is 1176600.0000, 
raw observation next is [27.6, 59.33333333333334, 1.0, 2.0, 0.9917971786540183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1512080.254822638, 1512080.254822638, 315012.3284870182], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.5933333333333334, 1.0, 1.0, 0.9901170827156847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4200222930062883, 0.4200222930062883, 0.4701676544582361], 
reward next is 0.5298, 
noisyNet noise sample is [array([-0.6574354], dtype=float32), 1.425642]. 
=============================================
[2019-03-26 15:11:43,798] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.1587472e-18 1.0000000e+00 2.5504119e-18 2.1436488e-13 1.1876037e-27], sum to 1.0000
[2019-03-26 15:11:43,802] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4686
[2019-03-26 15:11:43,808] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.4652921092080324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 656526.3596905082, 656526.3596905082, 179158.3157068784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1291800.0000, 
sim time next is 1292400.0000, 
raw observation next is [24.4, 94.0, 1.0, 2.0, 0.4646238933654218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655924.6479070106, 655924.6479070106, 179103.355951271], 
processed observation next is [1.0, 1.0, 0.3554502369668246, 0.94, 1.0, 1.0, 0.3549685462233998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18220129108528074, 0.18220129108528074, 0.2673184417183149], 
reward next is 0.7327, 
noisyNet noise sample is [array([-3.2517693], dtype=float32), -0.63672763]. 
=============================================
[2019-03-26 15:11:46,691] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1312352e-15 1.0000000e+00 9.6714970e-17 7.1013972e-10 1.1360047e-23], sum to 1.0000
[2019-03-26 15:11:46,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3833
[2019-03-26 15:11:46,707] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.26666666666667, 92.33333333333334, 1.0, 2.0, 0.6524538832873579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1001912.57165928, 1001912.571659281, 222064.0386547018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1340400.0000, 
sim time next is 1341000.0000, 
raw observation next is [22.2, 92.0, 1.0, 2.0, 0.5936243180710554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 914529.9528314535, 914529.9528314535, 209841.8331625114], 
processed observation next is [1.0, 0.5217391304347826, 0.2511848341232228, 0.92, 1.0, 1.0, 0.5103907446639222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2540360980087371, 0.2540360980087371, 0.31319676591419615], 
reward next is 0.6868, 
noisyNet noise sample is [array([1.2194428], dtype=float32), 0.91345763]. 
=============================================
[2019-03-26 15:11:46,727] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.10689 ]
 [66.92199 ]
 [67.23841 ]
 [67.350395]
 [67.30914 ]], R is [[67.32366943]
 [67.31900024]
 [67.23751068]
 [67.19258118]
 [67.16807556]].
[2019-03-26 15:11:47,208] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8670435e-21 1.0000000e+00 2.9842665e-21 4.4906472e-19 8.2792382e-29], sum to 1.0000
[2019-03-26 15:11:47,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6871
[2019-03-26 15:11:47,217] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333334, 94.66666666666667, 1.0, 2.0, 0.3240559951978547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509367.5124877075, 509367.5124877075, 167669.4512294972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1404600.0000, 
sim time next is 1405200.0000, 
raw observation next is [21.26666666666667, 94.33333333333334, 1.0, 2.0, 0.3258178604321098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511585.9685040126, 511585.9685040131, 167826.8852016396], 
processed observation next is [0.0, 0.2608695652173913, 0.2069510268562403, 0.9433333333333335, 1.0, 1.0, 0.18773236196639737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14210721347333685, 0.14210721347333696, 0.25048788836065616], 
reward next is 0.7495, 
noisyNet noise sample is [array([-0.11608095], dtype=float32), -0.17400496]. 
=============================================
[2019-03-26 15:11:48,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6413964e-18 1.0000000e+00 5.9667809e-18 1.7728079e-12 6.5901015e-26], sum to 1.0000
[2019-03-26 15:11:48,011] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5417
[2019-03-26 15:11:48,018] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 93.33333333333334, 1.0, 2.0, 0.3179549541097438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504321.7038382572, 504321.7038382572, 167376.3973238359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1362000.0000, 
sim time next is 1362600.0000, 
raw observation next is [21.0, 93.5, 1.0, 2.0, 0.3197966538423226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 506622.848828721, 506622.8488287205, 167539.9788568775], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.935, 1.0, 1.0, 0.18047789619556937, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14072856911908915, 0.14072856911908904, 0.25005966993563805], 
reward next is 0.7499, 
noisyNet noise sample is [array([0.30516228], dtype=float32), -0.49089646]. 
=============================================
[2019-03-26 15:11:51,603] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.0885390e-22 1.0000000e+00 1.5214955e-21 1.4737527e-18 1.0441920e-30], sum to 1.0000
[2019-03-26 15:11:51,605] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-26 15:11:51,611] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 69.33333333333333, 1.0, 2.0, 0.4274964091724863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617053.7525163455, 617053.7525163455, 175557.9722771437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1435800.0000, 
sim time next is 1436400.0000, 
raw observation next is [27.6, 69.0, 1.0, 2.0, 0.4277090929814758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617149.4771918209, 617149.4771918209, 175561.0670608429], 
processed observation next is [0.0, 0.6521739130434783, 0.5071090047393366, 0.69, 1.0, 1.0, 0.31049288311021184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17143041033106135, 0.17143041033106135, 0.2620314433743924], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.00961283], dtype=float32), 0.54384625]. 
=============================================
[2019-03-26 15:11:53,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3176836e-22 1.0000000e+00 4.0321791e-21 4.5261612e-19 1.1427418e-30], sum to 1.0000
[2019-03-26 15:11:53,416] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2766
[2019-03-26 15:11:53,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 84.0, 1.0, 2.0, 0.4026097145536569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596571.4829347419, 596571.4829347419, 174099.046317623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450800.0000, 
sim time next is 1451400.0000, 
raw observation next is [24.25, 85.33333333333333, 1.0, 2.0, 0.3996704440224519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593629.365134026, 593629.365134026, 173869.8384149724], 
processed observation next is [0.0, 0.8260869565217391, 0.3483412322274882, 0.8533333333333333, 1.0, 1.0, 0.27671137834030346, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16489704587056278, 0.16489704587056278, 0.25950722151488415], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.57737124], dtype=float32), -1.2994229]. 
=============================================
[2019-03-26 15:11:57,412] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2354124e-22 1.0000000e+00 1.6087001e-21 3.9742287e-20 1.7533283e-30], sum to 1.0000
[2019-03-26 15:11:57,419] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-26 15:11:57,428] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 78.5, 1.0, 2.0, 0.3761821496943077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566772.5059340392, 566772.5059340392, 171707.9712444984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1499400.0000, 
sim time next is 1500000.0000, 
raw observation next is [25.06666666666667, 76.33333333333334, 1.0, 2.0, 0.371240135605223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560304.8119079579, 560304.8119079586, 171176.2902761309], 
processed observation next is [0.0, 0.34782608695652173, 0.38704581358609813, 0.7633333333333334, 1.0, 1.0, 0.24245799470508797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1556402255299883, 0.1556402255299885, 0.2554870004121357], 
reward next is 0.7445, 
noisyNet noise sample is [array([-0.4002358], dtype=float32), 0.6047745]. 
=============================================
[2019-03-26 15:11:57,448] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.555786]
 [75.52894 ]
 [75.50559 ]
 [75.479706]
 [75.4503  ]], R is [[75.58518219]
 [75.57305145]
 [75.56089783]
 [75.54876709]
 [75.53672028]].
[2019-03-26 15:12:02,207] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2406655e-17 1.0000000e+00 4.8759675e-18 4.9268928e-13 1.6509094e-25], sum to 1.0000
[2019-03-26 15:12:02,217] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0128
[2019-03-26 15:12:02,224] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 85.00000000000001, 1.0, 2.0, 0.7915507349907526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1202668.116468185, 1202668.116468186, 254678.1702682478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1591800.0000, 
sim time next is 1592400.0000, 
raw observation next is [23.63333333333334, 85.0, 1.0, 2.0, 0.7516214457489828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1141397.432206658, 1141397.432206658, 244264.1597811578], 
processed observation next is [1.0, 0.43478260869565216, 0.3191153238546607, 0.85, 1.0, 1.0, 0.7007487298180516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3170548422796272, 0.3170548422796272, 0.3645733728076982], 
reward next is 0.6354, 
noisyNet noise sample is [array([-1.3857481], dtype=float32), 0.62672216]. 
=============================================
[2019-03-26 15:12:04,872] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.1042673e-19 1.0000000e+00 2.1653230e-19 2.8541655e-13 4.4282975e-28], sum to 1.0000
[2019-03-26 15:12:04,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-26 15:12:04,885] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 95.0, 1.0, 2.0, 0.4113764989521568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607925.7783420607, 607925.7783420607, 175105.7364780429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1625400.0000, 
sim time next is 1626000.0000, 
raw observation next is [23.16666666666666, 95.0, 1.0, 2.0, 0.4116493389435469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607956.8027249908, 607956.8027249908, 175098.0413635816], 
processed observation next is [1.0, 0.8260869565217391, 0.2969984202211688, 0.95, 1.0, 1.0, 0.29114378185969503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16887688964583078, 0.16887688964583078, 0.26134036024415164], 
reward next is 0.7387, 
noisyNet noise sample is [array([1.2133263], dtype=float32), -0.6731151]. 
=============================================
[2019-03-26 15:12:04,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.85596 ]
 [74.812546]
 [74.81391 ]
 [74.778854]
 [74.79941 ]], R is [[74.8238678 ]
 [74.81427765]
 [74.80480957]
 [74.79553223]
 [74.78636932]].
[2019-03-26 15:12:05,138] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1814488e-21 1.0000000e+00 7.4250591e-21 1.1913214e-17 4.9855754e-29], sum to 1.0000
[2019-03-26 15:12:05,149] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2502
[2019-03-26 15:12:05,154] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 98.66666666666669, 1.0, 2.0, 0.4825703655118966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 689628.8592915381, 689628.8592915375, 182868.4920696368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1664400.0000, 
sim time next is 1665000.0000, 
raw observation next is [23.55, 98.5, 1.0, 2.0, 0.4780335080428666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683266.0980582122, 683266.0980582122, 182182.5091285533], 
processed observation next is [1.0, 0.2608695652173913, 0.3151658767772513, 0.985, 1.0, 1.0, 0.3711247084853814, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1897961383495034, 0.1897961383495034, 0.27191419272918405], 
reward next is 0.7281, 
noisyNet noise sample is [array([-0.68925834], dtype=float32), -0.25065807]. 
=============================================
[2019-03-26 15:12:05,167] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.60513 ]
 [74.57794 ]
 [74.704315]
 [74.712135]
 [74.701195]], R is [[74.61240387]
 [74.59333801]
 [74.56329346]
 [74.54794312]
 [74.53255463]].
[2019-03-26 15:12:16,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5740211e-20 1.0000000e+00 5.1051717e-20 1.1296735e-16 1.8557609e-28], sum to 1.0000
[2019-03-26 15:12:16,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6274
[2019-03-26 15:12:16,069] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 94.66666666666667, 1.0, 2.0, 0.3638138941523408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 560595.237147645, 560595.237147645, 171545.0667072892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1824600.0000, 
sim time next is 1825200.0000, 
raw observation next is [21.9, 95.0, 1.0, 2.0, 0.3646920546257617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561563.3696320932, 561563.3696320932, 171617.7061094161], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.95, 1.0, 1.0, 0.23456874051296592, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15598982489780366, 0.15598982489780366, 0.2561458300140539], 
reward next is 0.7439, 
noisyNet noise sample is [array([-0.72288066], dtype=float32), 0.6724498]. 
=============================================
[2019-03-26 15:12:18,578] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.8129283e-12 9.9998271e-01 1.0155253e-14 1.7231538e-05 2.0186509e-21], sum to 1.0000
[2019-03-26 15:12:18,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1576
[2019-03-26 15:12:18,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1756405.504503039 W.
[2019-03-26 15:12:18,604] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.05, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.337521059127193, 6.9112, 168.9110588598789, 1756405.504503039, 1453962.070154995, 311348.860125414], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1866600.0000, 
sim time next is 1867200.0000, 
raw observation next is [27.03333333333333, 84.33333333333334, 1.0, 2.0, 0.6100918488725985, 1.0, 1.0, 0.6100918488725985, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1705812.31718062, 1705812.31718062, 338004.3348539301], 
processed observation next is [1.0, 0.6086956521739131, 0.48025276461295413, 0.8433333333333334, 1.0, 1.0, 0.5302311432199982, 1.0, 0.5, 0.5302311432199982, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.47383675477239445, 0.47383675477239445, 0.5044840818715375], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4967219], dtype=float32), -1.1072297]. 
=============================================
[2019-03-26 15:12:21,000] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 15:12:21,002] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:12:21,002] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:12:21,004] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:12:21,003] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:12:21,005] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:12:21,006] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:12:21,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:12:21,012] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:12:21,011] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:12:21,007] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:12:21,029] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 15:12:21,029] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 15:12:21,047] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 15:12:21,068] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 15:12:21,103] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 15:12:57,476] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04437963], dtype=float32), 0.07649288]
[2019-03-26 15:12:57,479] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.05, 80.0, 1.0, 2.0, 0.5605059738030047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783251.1850596198, 783251.1850596198, 193618.9294176246]
[2019-03-26 15:12:57,480] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:12:57,483] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4873357e-18 1.0000000e+00 3.8569555e-19 9.6388602e-14 3.9825312e-27], sampled 0.028250954689126084
[2019-03-26 15:13:11,980] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04437963], dtype=float32), 0.07649288]
[2019-03-26 15:13:11,980] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.11666666666667, 63.16666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.60895570460441, 6.9112, 168.9090939603147, 1949094.583661404, 1454093.991405841, 311350.0312841834]
[2019-03-26 15:13:11,982] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:13:11,991] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8028274e-13 9.9980527e-01 2.1091324e-15 1.9477804e-04 3.4014757e-21], sampled 0.3115388620072421
[2019-03-26 15:13:11,992] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1949094.583661404 W.
[2019-03-26 15:13:31,448] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04437963], dtype=float32), 0.07649288]
[2019-03-26 15:13:31,449] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.708105031886024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989602.2348464536, 989602.2348464536, 222601.007603375]
[2019-03-26 15:13:31,450] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:13:31,454] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.4192903e-19 1.0000000e+00 1.6144006e-19 1.7756208e-15 2.3387099e-27], sampled 0.5616055471165814
[2019-03-26 15:13:54,499] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04437963], dtype=float32), 0.07649288]
[2019-03-26 15:13:54,500] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.86112133666667, 81.82217354, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.579823587095198, 6.9112, 168.9096830862617, 1973367.403702316, 1499032.011261268, 318495.3561942236]
[2019-03-26 15:13:54,501] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:13:54,504] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4568253e-19 1.0000000e+00 2.1133003e-19 6.2345403e-15 2.7483145e-27], sampled 0.6089545171749
[2019-03-26 15:13:54,507] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1973367.403702316 W.
[2019-03-26 15:14:01,318] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04437963], dtype=float32), 0.07649288]
[2019-03-26 15:14:01,319] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.53597923, 49.813588435, 1.0, 2.0, 0.3029932437373056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484343.2492582087, 484343.2492582094, 165956.5635111718]
[2019-03-26 15:14:01,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:14:01,323] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6900606e-21 1.0000000e+00 8.9397076e-21 2.8611787e-18 5.5551529e-29], sampled 0.12245149925988152
[2019-03-26 15:14:16,370] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8170.1913 2987956112.5349 1264.0000
[2019-03-26 15:14:16,420] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8687.2302 2775531207.0213 844.0000
[2019-03-26 15:14:16,457] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8080.4610 3143303127.3642 1198.0000
[2019-03-26 15:14:16,554] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8572.8935 2833357845.7128 889.0000
[2019-03-26 15:14:16,618] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8337.1997 2918973259.6070 1102.0000
[2019-03-26 15:14:17,634] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 475000, evaluation results [475000.0, 8080.460961240512, 3143303127.3642154, 1198.0, 8337.199718447104, 2918973259.606961, 1102.0, 8687.230184186108, 2775531207.0213203, 844.0, 8170.191262877376, 2987956112.534928, 1264.0, 8572.893509859914, 2833357845.712806, 889.0]
[2019-03-26 15:14:18,111] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0532942e-08 4.4666839e-01 4.2307915e-12 5.5333155e-01 4.5361891e-16], sum to 1.0000
[2019-03-26 15:14:18,124] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9841
[2019-03-26 15:14:18,132] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.86666666666667, 76.66666666666667, 1.0, 2.0, 0.5677051940345188, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9449499373297493, 6.9112, 6.9112, 168.912956510431, 1587223.22146561, 1587223.22146561, 338458.2750097134], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1944600.0000, 
sim time next is 1945200.0000, 
raw observation next is [26.93333333333334, 76.33333333333334, 1.0, 2.0, 0.4587744270495651, 1.0, 1.0, 0.4587744270495651, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1282476.802348142, 1282476.802348142, 287933.8344705336], 
processed observation next is [1.0, 0.5217391304347826, 0.4755134281200636, 0.7633333333333334, 1.0, 1.0, 0.3479209964452592, 1.0, 0.5, 0.3479209964452592, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3562435562078172, 0.3562435562078172, 0.4297519917470651], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9997184], dtype=float32), 0.58757514]. 
=============================================
[2019-03-26 15:14:22,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1014285e-21 1.0000000e+00 1.1899064e-21 6.7291587e-19 1.2965725e-29], sum to 1.0000
[2019-03-26 15:14:22,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2751
[2019-03-26 15:14:22,669] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 94.0, 1.0, 2.0, 0.5055326534508704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706405.9101563278, 706405.9101563278, 184467.7665702698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2018400.0000, 
sim time next is 2019000.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.505478720649909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706330.5221165643, 706330.522116565, 184459.2315556975], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.94, 1.0, 1.0, 0.4041912296986855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19620292281015675, 0.19620292281015694, 0.2753122859040261], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.40118602], dtype=float32), 1.0692155]. 
=============================================
[2019-03-26 15:14:22,683] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.75975 ]
 [74.72565 ]
 [74.7     ]
 [74.679665]
 [74.65211 ]], R is [[74.76828003]
 [74.7452774 ]
 [74.72252655]
 [74.70009613]
 [74.67803192]].
[2019-03-26 15:14:29,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8576798e-21 1.0000000e+00 3.4858348e-21 2.5335092e-19 1.9594077e-29], sum to 1.0000
[2019-03-26 15:14:29,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3538
[2019-03-26 15:14:29,287] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.6, 75.66666666666666, 1.0, 2.0, 0.5443626739206694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760684.4562303623, 760684.4562303616, 190839.4769303292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2112000.0000, 
sim time next is 2112600.0000, 
raw observation next is [29.8, 74.83333333333334, 1.0, 2.0, 0.5460826286472423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763088.7591808831, 763088.7591808836, 191132.0399709794], 
processed observation next is [0.0, 0.43478260869565216, 0.6113744075829385, 0.7483333333333334, 1.0, 1.0, 0.45311160077981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21196909977246753, 0.21196909977246767, 0.285271701449223], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.3776711], dtype=float32), 0.11501083]. 
=============================================
[2019-03-26 15:14:29,785] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4503983e-20 1.0000000e+00 5.0145330e-20 5.0583448e-17 7.2703693e-29], sum to 1.0000
[2019-03-26 15:14:29,795] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0634
[2019-03-26 15:14:29,801] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.25, 76.16666666666667, 1.0, 2.0, 0.5739163567625523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801997.9322146008, 801997.9322146003, 195987.6671177533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2127000.0000, 
sim time next is 2127600.0000, 
raw observation next is [30.3, 76.0, 1.0, 2.0, 0.5748022414015747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 803236.3466301463, 803236.3466301457, 196145.977948463], 
processed observation next is [0.0, 0.6521739130434783, 0.6350710900473934, 0.76, 1.0, 1.0, 0.48771354385731885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22312120739726285, 0.22312120739726268, 0.29275519096785524], 
reward next is 0.7072, 
noisyNet noise sample is [array([0.44724745], dtype=float32), 1.0106366]. 
=============================================
[2019-03-26 15:14:30,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8283993e-20 1.0000000e+00 6.4133397e-21 5.9443608e-17 1.0555349e-28], sum to 1.0000
[2019-03-26 15:14:30,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-26 15:14:30,072] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.43333333333333, 74.33333333333334, 1.0, 2.0, 0.5707263209780628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 797538.4625146578, 797538.4625146583, 195419.3752981677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2136000.0000, 
sim time next is 2136600.0000, 
raw observation next is [30.25, 75.0, 1.0, 2.0, 0.5683418105705752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794205.0789347552, 794205.0789347552, 194996.6378245307], 
processed observation next is [0.0, 0.7391304347826086, 0.6327014218009479, 0.75, 1.0, 1.0, 0.479929892253705, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2206125219263209, 0.2206125219263209, 0.2910397579470608], 
reward next is 0.7090, 
noisyNet noise sample is [array([-1.0001613], dtype=float32), 0.05013583]. 
=============================================
[2019-03-26 15:14:30,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1116616e-19 1.0000000e+00 8.1943775e-20 1.2064551e-16 4.6092352e-28], sum to 1.0000
[2019-03-26 15:14:30,839] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-26 15:14:30,849] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 76.0, 1.0, 2.0, 0.5622836267046358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785736.1964479298, 785736.1964479298, 193930.428104229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2120400.0000, 
sim time next is 2121000.0000, 
raw observation next is [30.0, 76.16666666666667, 1.0, 2.0, 0.5627679389941809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786413.2258867561, 786413.2258867561, 194015.3221651925], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.7616666666666667, 1.0, 1.0, 0.47321438433033836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2184481183018767, 0.2184481183018767, 0.28957510770924255], 
reward next is 0.7104, 
noisyNet noise sample is [array([1.2776263], dtype=float32), -1.4898043]. 
=============================================
[2019-03-26 15:14:30,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.86238]
 [71.79723]
 [71.75362]
 [71.70703]
 [71.66302]], R is [[71.90628815]
 [71.89777374]
 [71.88942719]
 [71.88134766]
 [71.87374115]].
[2019-03-26 15:14:33,266] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6518627e-15 1.0000000e+00 2.2450294e-17 2.2514986e-11 1.9549843e-25], sum to 1.0000
[2019-03-26 15:14:33,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1908
[2019-03-26 15:14:33,280] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.71666666666667, 84.16666666666667, 1.0, 2.0, 0.5362253578679649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749309.478857817, 749309.4788578164, 189466.5266259519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2239800.0000, 
sim time next is 2240400.0000, 
raw observation next is [27.63333333333333, 84.33333333333334, 1.0, 2.0, 0.533385824450514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745340.1854358703, 745340.1854358697, 188992.3759554533], 
processed observation next is [1.0, 0.9565217391304348, 0.5086887835703, 0.8433333333333334, 1.0, 1.0, 0.4378142463259204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20703894039885287, 0.2070389403988527, 0.2820781730678407], 
reward next is 0.7179, 
noisyNet noise sample is [array([0.3369194], dtype=float32), 0.16792321]. 
=============================================
[2019-03-26 15:14:39,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6338552e-09 3.3597864e-02 3.1342951e-13 9.6640211e-01 6.8837528e-18], sum to 1.0000
[2019-03-26 15:14:39,228] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8628
[2019-03-26 15:14:39,232] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333333, 65.0, 1.0, 2.0, 0.8287739555219521, 1.0, 2.0, 0.8287739555219521, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2317891.064677534, 2317891.064677533, 434123.6553560747], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2297400.0000, 
sim time next is 2298000.0000, 
raw observation next is [31.86666666666667, 65.0, 1.0, 2.0, 0.8399267555607008, 1.0, 2.0, 0.8399267555607008, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2349112.210428512, 2349112.210428512, 439778.2055111154], 
processed observation next is [1.0, 0.6086956521739131, 0.7093206951026858, 0.65, 1.0, 1.0, 0.807140669350242, 1.0, 1.0, 0.807140669350242, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6525311695634756, 0.6525311695634756, 0.6563853813598737], 
reward next is 0.3436, 
noisyNet noise sample is [array([-0.81225383], dtype=float32), -0.12597242]. 
=============================================
[2019-03-26 15:14:39,254] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[56.315125]
 [56.101868]
 [58.326546]
 [59.215195]
 [61.188934]], R is [[56.61434174]
 [56.4002533 ]
 [56.15139389]
 [55.5898819 ]
 [55.03398514]].
[2019-03-26 15:14:40,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9411859e-16 1.0000000e+00 5.1375122e-17 7.2253102e-12 1.1132665e-25], sum to 1.0000
[2019-03-26 15:14:40,523] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-26 15:14:40,529] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 79.66666666666667, 1.0, 2.0, 0.5618134814509129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 785078.9717929928, 785078.9717929922, 193847.6444563118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325000.0000, 
sim time next is 2325600.0000, 
raw observation next is [29.1, 80.0, 1.0, 2.0, 0.5613385714576048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784415.086834244, 784415.086834244, 193764.4831830124], 
processed observation next is [1.0, 0.9565217391304348, 0.5781990521327015, 0.8, 1.0, 1.0, 0.4714922547681985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21789307967617888, 0.21789307967617888, 0.28920072116867523], 
reward next is 0.7108, 
noisyNet noise sample is [array([-1.994849], dtype=float32), 0.7787664]. 
=============================================
[2019-03-26 15:14:44,502] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0971832e-18 1.0000000e+00 7.5070661e-18 2.3492316e-14 1.4248289e-26], sum to 1.0000
[2019-03-26 15:14:44,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1166
[2019-03-26 15:14:44,514] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666667, 82.0, 1.0, 2.0, 0.6655486001863871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 930102.0482365907, 930102.0482365907, 213582.6950682274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2349600.0000, 
sim time next is 2350200.0000, 
raw observation next is [27.13333333333333, 82.0, 1.0, 2.0, 0.6682611215593884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 933894.4548958407, 933894.4548958407, 214141.528037051], 
processed observation next is [1.0, 0.17391304347826086, 0.484992101105845, 0.82, 1.0, 1.0, 0.6003146042884198, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2594151263599558, 0.2594151263599558, 0.31961422095082237], 
reward next is 0.6804, 
noisyNet noise sample is [array([-1.0941195], dtype=float32), -1.7772158]. 
=============================================
[2019-03-26 15:14:54,333] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6509158e-18 1.0000000e+00 6.0039943e-19 2.7932119e-13 6.6953329e-27], sum to 1.0000
[2019-03-26 15:14:54,341] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8380
[2019-03-26 15:14:54,345] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 92.5, 1.0, 2.0, 0.4865391851448324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679856.8996106591, 679856.8996106591, 181513.3265422555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2593800.0000, 
sim time next is 2594400.0000, 
raw observation next is [24.86666666666667, 92.66666666666667, 1.0, 2.0, 0.4839522424962031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676240.9306145759, 676240.9306145759, 181119.3198428449], 
processed observation next is [0.0, 0.0, 0.3775671406003162, 0.9266666666666667, 1.0, 1.0, 0.37825571385084716, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1878447029484933, 0.1878447029484933, 0.27032734304902223], 
reward next is 0.7297, 
noisyNet noise sample is [array([1.0026078], dtype=float32), 0.50994056]. 
=============================================
[2019-03-26 15:14:57,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5496462e-22 1.0000000e+00 6.4502159e-21 5.1605837e-20 1.1742546e-29], sum to 1.0000
[2019-03-26 15:14:57,888] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-26 15:14:57,893] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4730146462875185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661537.8596975404, 661537.8596975404, 179551.5366612646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2620800.0000, 
sim time next is 2621400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4738631162323849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662292.3425520502, 662292.3425520497, 179621.9109307519], 
processed observation next is [0.0, 0.34782608695652173, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36610014003901803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18397009515334728, 0.18397009515334714, 0.2680924043742566], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.38350028], dtype=float32), 0.30090988]. 
=============================================
[2019-03-26 15:15:00,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3396482e-23 1.0000000e+00 1.2038133e-21 4.6326279e-20 1.0909777e-30], sum to 1.0000
[2019-03-26 15:15:00,765] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0448
[2019-03-26 15:15:00,769] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 87.33333333333334, 1.0, 2.0, 0.4936624669961582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689813.7229251548, 689813.7229251548, 182609.2640349944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649000.0000, 
sim time next is 2649600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4972700992341245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 694856.4561947358, 694856.4561947352, 183169.6039628165], 
processed observation next is [0.0, 0.6956521739130435, 0.4312796208530806, 0.89, 1.0, 1.0, 0.3943013243784633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19301568227631552, 0.19301568227631535, 0.27338746860121865], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.18506078], dtype=float32), -0.23050188]. 
=============================================
[2019-03-26 15:15:02,102] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.0501073e-21 1.0000000e+00 1.4793162e-20 3.5752473e-19 4.4709313e-30], sum to 1.0000
[2019-03-26 15:15:02,110] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7179
[2019-03-26 15:15:02,114] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4972700992341245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 694856.4561947358, 694856.4561947352, 183169.6039628165], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2649600.0000, 
sim time next is 2650200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4981254129902304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696052.0137000309, 696052.0137000309, 183302.9807375376], 
processed observation next is [0.0, 0.6956521739130435, 0.4312796208530806, 0.89, 1.0, 1.0, 0.3953318228797956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1933477815833419, 0.1933477815833419, 0.27358653841423525], 
reward next is 0.7264, 
noisyNet noise sample is [array([1.7985758], dtype=float32), 0.58881277]. 
=============================================
[2019-03-26 15:15:03,228] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7371643e-23 1.0000000e+00 1.3666252e-21 1.5534899e-19 9.6116976e-31], sum to 1.0000
[2019-03-26 15:15:03,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1411
[2019-03-26 15:15:03,246] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4018787071855204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 597938.4926027788, 597938.4926027788, 174297.4293140701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2663400.0000, 
sim time next is 2664000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3989862227200194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594915.4175127856, 594915.4175127856, 174057.6605508872], 
processed observation next is [0.0, 0.8695652173913043, 0.28909952606635075, 0.94, 1.0, 1.0, 0.27588701532532456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16525428264244046, 0.16525428264244046, 0.2597875530610257], 
reward next is 0.7402, 
noisyNet noise sample is [array([0.68353945], dtype=float32), 1.191988]. 
=============================================
[2019-03-26 15:15:03,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.36193]
 [75.37239]
 [75.37643]
 [75.38088]
 [75.3866 ]], R is [[75.35932159]
 [75.34558105]
 [75.33161163]
 [75.31738281]
 [75.30281067]].
[2019-03-26 15:15:04,111] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.0410963e-21 1.0000000e+00 7.0551042e-21 3.7552552e-19 1.9582570e-29], sum to 1.0000
[2019-03-26 15:15:04,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6695
[2019-03-26 15:15:04,126] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 99.00000000000001, 1.0, 2.0, 0.3738989849940827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564723.3143392728, 564723.3143392728, 171573.3725469798], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2758200.0000, 
sim time next is 2758800.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.3705931676615564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561826.8458285144, 561826.8458285144, 171388.3369283464], 
processed observation next is [0.0, 0.9565217391304348, 0.2417061611374408, 0.98, 1.0, 1.0, 0.24167851525488726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1560630127301429, 0.1560630127301429, 0.2558034879527558], 
reward next is 0.7442, 
noisyNet noise sample is [array([1.5736129], dtype=float32), 0.18487869]. 
=============================================
[2019-03-26 15:15:04,859] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.1335821e-21 1.0000000e+00 2.6835844e-20 1.2626617e-17 6.2727604e-29], sum to 1.0000
[2019-03-26 15:15:04,867] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4178
[2019-03-26 15:15:04,874] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3474518561810484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535240.9313666883, 535240.9313666878, 169426.6608317343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2771400.0000, 
sim time next is 2772000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3473481168878181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535081.3018466077, 535081.3018466084, 169413.6413674864], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.213672429985323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14863369495739104, 0.14863369495739123, 0.25285618114550207], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.19866599], dtype=float32), 0.44228268]. 
=============================================
[2019-03-26 15:15:04,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[71.4873 ]
 [71.36214]
 [71.45948]
 [71.51502]
 [71.54846]], R is [[71.65833282]
 [71.68887329]
 [71.71905518]
 [71.74884033]
 [71.77825928]].
[2019-03-26 15:15:08,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4605868e-21 1.0000000e+00 2.8725055e-20 5.1733414e-18 7.8564671e-29], sum to 1.0000
[2019-03-26 15:15:08,031] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0717
[2019-03-26 15:15:08,037] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3474518561810484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535240.9313666883, 535240.9313666878, 169426.6608317343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2771400.0000, 
sim time next is 2772000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3473481168878181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535081.3018466077, 535081.3018466084, 169413.6413674864], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.213672429985323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14863369495739104, 0.14863369495739123, 0.25285618114550207], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.11302874], dtype=float32), 0.092478335]. 
=============================================
[2019-03-26 15:15:08,047] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.983536]
 [71.85978 ]
 [71.95798 ]
 [72.01074 ]
 [72.04472 ]], R is [[72.14048767]
 [72.16620636]
 [72.19161224]
 [72.2166748 ]
 [72.24141693]].
[2019-03-26 15:15:08,960] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5525870e-22 1.0000000e+00 2.1770404e-21 9.0862792e-20 2.9966302e-30], sum to 1.0000
[2019-03-26 15:15:08,971] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6199
[2019-03-26 15:15:08,977] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 96.0, 1.0, 2.0, 0.3899526964879866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583306.3079049023, 583306.3079049016, 173051.4434765129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2748000.0000, 
sim time next is 2748600.0000, 
raw observation next is [22.5, 97.0, 1.0, 2.0, 0.3879939931931745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 581264.5881379509, 581264.5881379503, 172894.327902857], 
processed observation next is [0.0, 0.8260869565217391, 0.2654028436018958, 0.97, 1.0, 1.0, 0.2626433652929813, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16146238559387524, 0.16146238559387507, 0.258051235675906], 
reward next is 0.7419, 
noisyNet noise sample is [array([-1.3601393], dtype=float32), -1.1019785]. 
=============================================
[2019-03-26 15:15:12,904] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 15:15:12,911] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:15:12,912] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:15:12,913] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:15:12,913] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:15:12,914] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:15:12,915] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:15:12,914] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:15:12,916] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:15:12,917] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:15:12,917] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:15:12,924] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 15:15:12,924] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 15:15:12,925] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 15:15:12,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 15:15:13,001] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 15:15:18,661] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:15:18,663] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.2, 63.0, 1.0, 2.0, 0.2332129518491045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 386726.6478506207, 386726.64785062, 159112.2819488608]
[2019-03-26 15:15:18,665] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:15:18,667] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7874678e-23 1.0000000e+00 7.4832052e-22 2.4325768e-21 4.7467868e-31], sampled 0.42047923556244937
[2019-03-26 15:15:20,984] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:15:20,985] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.7, 75.0, 1.0, 2.0, 0.4802929978796964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772164.0973032619, 772164.0973032626, 191668.8623320326]
[2019-03-26 15:15:20,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:15:20,989] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2682368e-21 1.0000000e+00 1.6132177e-20 8.7671756e-19 2.6832649e-29], sampled 0.5787677340967893
[2019-03-26 15:15:22,578] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:15:22,580] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.6588082, 73.92496471, 1.0, 2.0, 0.2268567774113363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 378121.3596469257, 378121.3596469257, 158148.6756171009]
[2019-03-26 15:15:22,581] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:15:22,584] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.68874183e-21 1.00000000e+00 1.09377519e-20 2.42508366e-19
 1.00401015e-29], sampled 0.582898716395973
[2019-03-26 15:15:46,175] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:15:46,176] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.6824448, 96.55271745666668, 1.0, 2.0, 0.5538824618075129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773992.1155685564, 773992.115568557, 192469.512110887]
[2019-03-26 15:15:46,177] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:15:46,179] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2203980e-22 1.0000000e+00 1.0863232e-21 9.4309463e-21 1.0541094e-30], sampled 0.5158854028552963
[2019-03-26 15:16:03,148] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:16:03,149] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.53333333333333, 61.0, 1.0, 2.0, 0.5409538618613268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755919.3370638957, 755919.3370638957, 190260.5224907443]
[2019-03-26 15:16:03,150] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:16:03,152] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0203720e-22 1.0000000e+00 7.8172723e-22 1.1143237e-19 4.7474023e-31], sampled 0.8953131576715185
[2019-03-26 15:16:03,230] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:16:03,231] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.09771089, 79.102341475, 1.0, 2.0, 0.5401021728351716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754728.7791057866, 754728.779105786, 190116.4798064063]
[2019-03-26 15:16:03,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:16:03,235] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2686314e-21 1.0000000e+00 3.6317672e-21 1.1782547e-18 2.6401624e-30], sampled 0.6964646420366651
[2019-03-26 15:16:06,255] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:16:06,255] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.45, 84.0, 1.0, 2.0, 0.5417520308120863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757035.0816592631, 757035.0816592631, 190392.798201296]
[2019-03-26 15:16:06,256] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:16:06,257] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7229284e-22 1.0000000e+00 2.1134513e-21 5.0285931e-20 3.0100807e-30], sampled 0.47989850503051446
[2019-03-26 15:16:33,271] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04385505], dtype=float32), 0.0780496]
[2019-03-26 15:16:33,272] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.65, 75.16666666666667, 1.0, 2.0, 0.5628479471501088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786525.0708640441, 786525.0708640441, 194027.9998718791]
[2019-03-26 15:16:33,273] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:16:33,278] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.20543141e-21 1.00000000e+00 1.14035257e-20 1.07912634e-17
 9.59305781e-30], sampled 0.8865123497618517
[2019-03-26 15:17:10,038] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.8804 2926810074.7632 1323.0000
[2019-03-26 15:17:10,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9198 2779288578.9076 932.0000
[2019-03-26 15:17:10,094] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8004.1789 3006748162.3742 1746.0000
[2019-03-26 15:17:10,206] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7898.5355 3161784533.5244 1716.0000
[2019-03-26 15:17:10,280] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.0650 2842070106.6652 1121.0000
[2019-03-26 15:17:11,294] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 500000, evaluation results [500000.0, 7898.535482245334, 3161784533.524407, 1716.0, 8259.880410401822, 2926810074.763237, 1323.0, 8659.919825277942, 2779288578.9075637, 932.0, 8004.17891735144, 3006748162.3742332, 1746.0, 8499.06504875983, 2842070106.6651816, 1121.0]
[2019-03-26 15:17:15,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.62163486e-21 1.00000000e+00 1.14103135e-20 7.09259647e-18
 1.06760601e-29], sum to 1.0000
[2019-03-26 15:17:15,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4127
[2019-03-26 15:17:15,072] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 91.66666666666667, 1.0, 2.0, 0.6015080193165437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 924546.5356235106, 924546.5356235106, 211234.4279068697], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2887800.0000, 
sim time next is 2888400.0000, 
raw observation next is [22.43333333333334, 91.33333333333334, 1.0, 2.0, 0.5765178304463094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 885489.105802712, 885489.105802712, 206113.2114519725], 
processed observation next is [1.0, 0.43478260869565216, 0.2622432859399688, 0.9133333333333334, 1.0, 1.0, 0.4897805186100114, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2459691960563089, 0.2459691960563089, 0.30763165888354105], 
reward next is 0.6924, 
noisyNet noise sample is [array([-0.04577946], dtype=float32), -0.3513624]. 
=============================================
[2019-03-26 15:17:26,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7460890e-20 1.0000000e+00 5.8086006e-20 7.5176159e-17 2.1174130e-29], sum to 1.0000
[2019-03-26 15:17:26,259] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-26 15:17:26,263] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3966181482058797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591816.2734095218, 591816.2734095218, 173784.5850322915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3111600.0000, 
sim time next is 3112200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3930914692769988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586550.9406073227, 586550.9406073234, 173302.0483535628], 
processed observation next is [1.0, 0.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.268784902743372, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16293081683536742, 0.16293081683536761, 0.258659773662034], 
reward next is 0.7413, 
noisyNet noise sample is [array([-0.5809669], dtype=float32), 0.7001343]. 
=============================================
[2019-03-26 15:17:27,076] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.5289789e-18 1.0000000e+00 9.7489036e-19 1.0115947e-15 3.0331498e-27], sum to 1.0000
[2019-03-26 15:17:27,084] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9989
[2019-03-26 15:17:27,090] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333333, 87.0, 1.0, 2.0, 0.763298148418341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1122222.391580485, 1122222.391580485, 242598.9479915159], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3147600.0000, 
sim time next is 3148200.0000, 
raw observation next is [24.5, 86.0, 1.0, 2.0, 0.7817239004478149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1148029.477045031, 1148029.477045031, 247050.9659327327], 
processed observation next is [1.0, 0.43478260869565216, 0.3601895734597157, 0.86, 1.0, 1.0, 0.7370167475274878, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3188970769569531, 0.3188970769569531, 0.3687327849742279], 
reward next is 0.6313, 
noisyNet noise sample is [array([0.05038651], dtype=float32), 0.03639358]. 
=============================================
[2019-03-26 15:17:27,719] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7548675e-21 1.0000000e+00 1.0132142e-20 3.3046641e-16 1.4039628e-29], sum to 1.0000
[2019-03-26 15:17:27,728] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3991
[2019-03-26 15:17:27,733] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3849212062235661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579764.8643923954, 579764.8643923948, 172854.1836680601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3106200.0000, 
sim time next is 3106800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3857020380339127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580940.6695455962, 580940.6695455955, 172959.6041456942], 
processed observation next is [1.0, 1.0, 0.2417061611374408, 1.0, 1.0, 1.0, 0.25988197353483455, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16137240820711007, 0.16137240820710988, 0.2581486629040212], 
reward next is 0.7419, 
noisyNet noise sample is [array([2.1034245], dtype=float32), -0.6927287]. 
=============================================
[2019-03-26 15:17:30,729] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2390061e-22 1.0000000e+00 3.2342032e-22 1.6925671e-20 1.0001068e-30], sum to 1.0000
[2019-03-26 15:17:30,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9686
[2019-03-26 15:17:30,752] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.561792428769163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785049.5418733739, 785049.5418733739, 193844.4108438563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3241800.0000, 
sim time next is 3242400.0000, 
raw observation next is [32.0, 64.33333333333334, 1.0, 2.0, 0.5578858890686076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779588.5344063349, 779588.5344063349, 193163.0114004926], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.6433333333333334, 1.0, 1.0, 0.4673323964682019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21655237066842636, 0.21655237066842636, 0.2883030020902875], 
reward next is 0.7117, 
noisyNet noise sample is [array([-0.37828556], dtype=float32), -1.2755926]. 
=============================================
[2019-03-26 15:17:36,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7791096e-22 1.0000000e+00 2.2202676e-20 1.6091805e-19 8.3886911e-30], sum to 1.0000
[2019-03-26 15:17:36,150] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3364
[2019-03-26 15:17:36,154] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 65.66666666666667, 1.0, 2.0, 0.5659146935608056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790812.1449620173, 790812.1449620173, 194568.3191767216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3241200.0000, 
sim time next is 3241800.0000, 
raw observation next is [32.0, 65.0, 1.0, 2.0, 0.561792428769163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785049.5418733739, 785049.5418733739, 193844.4108438563], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.65, 1.0, 1.0, 0.4720390708062205, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2180693171870483, 0.2180693171870483, 0.28932001618486014], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.54479593], dtype=float32), 2.1049185]. 
=============================================
[2019-03-26 15:17:38,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8738742e-21 1.0000000e+00 1.5002122e-20 4.7670510e-18 9.5870588e-30], sum to 1.0000
[2019-03-26 15:17:38,783] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0730
[2019-03-26 15:17:38,790] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.4829951644860992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 674903.1520813071, 674903.1520813066, 180974.3376002834], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3284400.0000, 
sim time next is 3285000.0000, 
raw observation next is [26.5, 81.5, 1.0, 2.0, 0.4823792683383901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674042.2694951739, 674042.2694951739, 180880.9422085543], 
processed observation next is [0.0, 0.0, 0.4549763033175356, 0.815, 1.0, 1.0, 0.37636056426312064, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18723396374865942, 0.18723396374865942, 0.26997155553515567], 
reward next is 0.7300, 
noisyNet noise sample is [array([0.2545819], dtype=float32), 0.25404698]. 
=============================================
[2019-03-26 15:17:38,802] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.01825 ]
 [73.20301 ]
 [73.65145 ]
 [74.275406]
 [74.29106 ]], R is [[72.94345093]
 [72.94390869]
 [72.94406891]
 [72.9439621 ]
 [72.9437027 ]].
[2019-03-26 15:17:45,617] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3412401e-16 1.0000000e+00 1.5939512e-17 6.3223922e-14 5.7038230e-26], sum to 1.0000
[2019-03-26 15:17:45,624] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3017
[2019-03-26 15:17:45,632] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.83333333333334, 1.0, 2.0, 0.5197891354897839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726334.0120772389, 726334.0120772389, 186754.518086806], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3445800.0000, 
sim time next is 3446400.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5198032636949518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726353.76105566, 726353.76105566, 186756.7224078644], 
processed observation next is [1.0, 0.9130434782608695, 0.5102685624012641, 0.8066666666666668, 1.0, 1.0, 0.4214497152951226, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20176493362657222, 0.20176493362657222, 0.27874137672815585], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.2208635], dtype=float32), 0.5593301]. 
=============================================
[2019-03-26 15:17:58,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5921616e-19 1.0000000e+00 2.7527852e-19 9.9931306e-17 8.9269308e-28], sum to 1.0000
[2019-03-26 15:17:58,865] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3679
[2019-03-26 15:17:58,869] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5243107355649014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732654.5068667321, 732654.5068667321, 187492.39677599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621000.0000, 
sim time next is 3621600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5219144311735413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729304.8407424163, 729304.8407424163, 187100.5978990221], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42399329057053164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20258467798400454, 0.20258467798400454, 0.27925462372988374], 
reward next is 0.7207, 
noisyNet noise sample is [array([1.0741711], dtype=float32), 0.77942634]. 
=============================================
[2019-03-26 15:18:04,951] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2353590e-19 1.0000000e+00 5.6042003e-19 2.7821575e-17 1.2337447e-27], sum to 1.0000
[2019-03-26 15:18:04,961] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8788
[2019-03-26 15:18:04,966] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.00000000000001, 1.0, 2.0, 0.5126395231903313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738920.2227204571, 738920.2227204578, 188467.3204370738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3733800.0000, 
sim time next is 3734400.0000, 
raw observation next is [26.0, 79.0, 1.0, 2.0, 0.4853506647827253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 699630.447884891, 699630.447884891, 184058.717490553], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.79, 1.0, 1.0, 0.3799405599791872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19434179107913638, 0.19434179107913638, 0.2747145037172433], 
reward next is 0.7253, 
noisyNet noise sample is [array([-1.1256099], dtype=float32), -0.30310598]. 
=============================================
[2019-03-26 15:18:06,745] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 15:18:06,747] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:18:06,747] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:18:06,748] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:18:06,749] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:18:06,750] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:18:06,751] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:18:06,751] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:18:06,753] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:18:06,753] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:18:06,756] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:18:06,774] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 15:18:06,803] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 15:18:06,826] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 15:18:06,826] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 15:18:06,827] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 15:18:15,030] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:18:15,033] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.13333333333333, 79.0, 1.0, 2.0, 0.2404901571515648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 397739.4148161089, 397739.4148161095, 159893.8413064448]
[2019-03-26 15:18:15,033] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:18:15,036] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5629588e-22 1.0000000e+00 3.8039548e-21 2.1838027e-21 1.5234342e-30], sampled 0.5011719844378129
[2019-03-26 15:18:21,986] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:18:21,989] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.33333333333334, 93.0, 1.0, 2.0, 0.292187906589926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 469567.3387493861, 469567.3387493854, 164928.7835430392]
[2019-03-26 15:18:21,989] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:18:21,994] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8005275e-23 1.0000000e+00 8.7467514e-22 4.1138989e-23 4.0747581e-31], sampled 0.6550325331569332
[2019-03-26 15:18:25,572] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:18:25,574] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [17.93333333333333, 91.33333333333333, 1.0, 2.0, 0.2227845825318847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 370691.2137608488, 370691.2137608488, 157953.3963432347]
[2019-03-26 15:18:25,575] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:18:25,578] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.1025357e-23 1.0000000e+00 1.4949728e-21 1.2138561e-22 5.3413960e-31], sampled 0.9398006779663151
[2019-03-26 15:18:41,349] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:18:41,350] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.489474265, 61.85225497499999, 1.0, 2.0, 0.5621269431623763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104262, 785517.1656113504, 785517.1656113511, 193904.9900193216]
[2019-03-26 15:18:41,352] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:18:41,357] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6319569e-16 1.0000000e+00 4.8201167e-18 6.5819114e-11 1.3708621e-25], sampled 0.5692160327944006
[2019-03-26 15:18:51,400] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:18:51,400] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [16.98940792166667, 97.90379602333334, 1.0, 2.0, 0.2863147621110998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476533.5024417566, 476533.5024417572, 164287.6824540851]
[2019-03-26 15:18:51,402] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:18:51,405] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4761184e-22 1.0000000e+00 3.0954023e-21 4.1199630e-22 2.3581013e-30], sampled 0.6346232021078427
[2019-03-26 15:19:16,064] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:19:16,066] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.83333333333334, 68.33333333333333, 1.0, 2.0, 0.9377470910515561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1310733.350902429, 1310733.350902428, 280533.2166479763]
[2019-03-26 15:19:16,068] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:19:16,072] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4935607e-19 1.0000000e+00 2.3618144e-19 1.0402674e-16 1.8550752e-27], sampled 0.9017765989219728
[2019-03-26 15:19:26,170] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:19:26,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.6, 62.0, 1.0, 2.0, 0.954450473235549, 1.0, 2.0, 0.7978152761320373, 1.0, 2.0, 1.03, 7.005117803922168, 6.9112, 170.5573041426782, 3348339.2565074, 3281062.113225945, 613756.8546764432]
[2019-03-26 15:19:26,174] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:19:26,178] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1330976e-09 1.5661441e-04 2.3116378e-13 9.9984336e-01 8.1675450e-18], sampled 0.4370287340579768
[2019-03-26 15:19:26,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 0, 0, 1, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3348339.2565074 W.
[2019-03-26 15:19:39,634] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0473475], dtype=float32), 0.07415898]
[2019-03-26 15:19:39,636] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.2, 67.33333333333334, 1.0, 2.0, 0.5678469101671676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 793513.2430981904, 793513.2430981898, 194908.0296945478]
[2019-03-26 15:19:39,639] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:19:39,640] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5288801e-22 1.0000000e+00 2.1745338e-21 6.6779062e-21 7.8913014e-31], sampled 0.11797843446153522
[2019-03-26 15:20:01,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.0740 2842519327.9662 1124.0000
[2019-03-26 15:20:01,890] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.9643 3007554893.5799 1761.0000
[2019-03-26 15:20:02,009] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 15:20:02,171] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8260.7928 2927226737.6227 1328.0000
[2019-03-26 15:20:02,189] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7891.8062 3163169334.7914 1747.0000
[2019-03-26 15:20:03,203] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 525000, evaluation results [525000.0, 7891.806162485737, 3163169334.7913747, 1747.0, 8260.792755213028, 2927226737.6227155, 1328.0, 8661.172501768742, 2779322230.897455, 933.0, 7999.964297805008, 3007554893.5799108, 1761.0, 8497.074024876729, 2842519327.9661818, 1124.0]
[2019-03-26 15:20:05,317] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2336600e-24 1.0000000e+00 4.6692576e-23 4.4551819e-23 3.4054821e-32], sum to 1.0000
[2019-03-26 15:20:05,327] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5543
[2019-03-26 15:20:05,333] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666666, 76.5, 1.0, 2.0, 0.560968485190524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783897.7370774476, 783897.7370774476, 193699.8036357533], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3829800.0000, 
sim time next is 3830400.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.5629570964367421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 786677.6528210016, 786677.6528210023, 194047.9523203448], 
processed observation next is [0.0, 0.34782608695652173, 0.6208530805687204, 0.75, 1.0, 1.0, 0.47344228486354467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.218521570228056, 0.21852157022805618, 0.2896238094333505], 
reward next is 0.7104, 
noisyNet noise sample is [array([-2.5887585], dtype=float32), 0.8386609]. 
=============================================
[2019-03-26 15:20:07,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8601386e-23 1.0000000e+00 4.3632172e-22 1.2223455e-22 2.1934428e-31], sum to 1.0000
[2019-03-26 15:20:07,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9424
[2019-03-26 15:20:07,781] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 69.5, 1.0, 2.0, 0.5714166052600571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798503.4350052854, 798503.4350052854, 195542.0834691583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3834600.0000, 
sim time next is 3835200.0000, 
raw observation next is [31.66666666666667, 69.0, 1.0, 2.0, 0.5746693473168272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803050.5684547573, 803050.5684547573, 196122.4919113029], 
processed observation next is [0.0, 0.391304347826087, 0.6998420221169038, 0.69, 1.0, 1.0, 0.4875534305022014, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2230696023485437, 0.2230696023485437, 0.2927201371810491], 
reward next is 0.7073, 
noisyNet noise sample is [array([1.9090763], dtype=float32), -0.5624934]. 
=============================================
[2019-03-26 15:20:08,734] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.6994599e-23 1.0000000e+00 1.9815903e-21 6.0750628e-21 7.7359542e-31], sum to 1.0000
[2019-03-26 15:20:08,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7227
[2019-03-26 15:20:08,748] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 55.0, 1.0, 2.0, 0.5874360757035686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820897.8581129654, 820897.8581129654, 198429.3402831675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3859200.0000, 
sim time next is 3859800.0000, 
raw observation next is [35.0, 54.66666666666667, 1.0, 2.0, 0.603812365442395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843791.5849227291, 843791.5849227291, 201457.7535669962], 
processed observation next is [0.0, 0.6956521739130435, 0.8578199052132701, 0.5466666666666667, 1.0, 1.0, 0.5226655005330061, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23438655136742473, 0.23438655136742473, 0.3006832142790988], 
reward next is 0.6993, 
noisyNet noise sample is [array([0.73592657], dtype=float32), 0.27259034]. 
=============================================
[2019-03-26 15:20:09,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8171496e-23 1.0000000e+00 8.9655907e-22 2.0666679e-21 1.1449972e-31], sum to 1.0000
[2019-03-26 15:20:09,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1110
[2019-03-26 15:20:09,156] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 54.33333333333334, 1.0, 2.0, 0.5852473548498202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817838.1073454967, 817838.1073454967, 198030.1991720698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3860400.0000, 
sim time next is 3861000.0000, 
raw observation next is [35.0, 54.0, 1.0, 2.0, 0.5807997071608726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811620.4876002457, 811620.4876002457, 197224.0647753774], 
processed observation next is [0.0, 0.6956521739130435, 0.8578199052132701, 0.54, 1.0, 1.0, 0.49493940621791876, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2254501354445127, 0.2254501354445127, 0.29436427578414537], 
reward next is 0.7056, 
noisyNet noise sample is [array([-0.26119098], dtype=float32), -0.8857888]. 
=============================================
[2019-03-26 15:20:09,172] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.40809 ]
 [72.365585]
 [72.3687  ]
 [72.31584 ]
 [72.27117 ]], R is [[72.43440247]
 [72.41448975]
 [72.3896637 ]
 [72.36960602]
 [72.34942627]].
[2019-03-26 15:20:09,890] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9696967e-22 1.0000000e+00 2.3645166e-21 3.1468596e-21 1.4282979e-30], sum to 1.0000
[2019-03-26 15:20:09,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9089
[2019-03-26 15:20:09,908] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 90.66666666666667, 1.0, 2.0, 0.576724529448313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805923.5967779416, 805923.5967779416, 196489.2596508685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3903600.0000, 
sim time next is 3904200.0000, 
raw observation next is [27.5, 91.5, 1.0, 2.0, 0.5759854728022732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 804890.4365129758, 804890.4365129764, 196356.6652942462], 
processed observation next is [0.0, 0.17391304347826086, 0.5023696682464456, 0.915, 1.0, 1.0, 0.48913912385816044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22358067680915997, 0.2235806768091601, 0.2930696496929048], 
reward next is 0.7069, 
noisyNet noise sample is [array([-0.95010245], dtype=float32), -0.50009036]. 
=============================================
[2019-03-26 15:20:14,885] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.30127847e-22 1.00000000e+00 3.82754968e-21 4.14704092e-20
 1.03714615e-29], sum to 1.0000
[2019-03-26 15:20:14,892] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5995
[2019-03-26 15:20:14,898] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 73.66666666666667, 1.0, 2.0, 0.6309860994818122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 881781.0125658162, 881781.0125658168, 206660.805679261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [32.0, 73.0, 1.0, 2.0, 0.6216255229113851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868694.5845196096, 868694.5845196096, 204844.3145208912], 
processed observation next is [0.0, 0.8260869565217391, 0.7156398104265403, 0.73, 1.0, 1.0, 0.5441271360378133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2413040512554471, 0.2413040512554471, 0.3057377828670018], 
reward next is 0.6943, 
noisyNet noise sample is [array([0.09825788], dtype=float32), -0.22377452]. 
=============================================
[2019-03-26 15:20:15,230] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.6568625e-09 9.7762215e-01 5.3304691e-12 2.2377843e-02 5.5909277e-17], sum to 1.0000
[2019-03-26 15:20:15,240] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-26 15:20:15,248] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.3922938264700813, 1.0, 2.0, 0.3922938264700813, 1.0, 2.0, 0.6812846430276727, 6.9112, 6.9112, 170.5573041426782, 1645229.506294856, 1645229.506294856, 348664.1093321861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3992400.0000, 
sim time next is 3993000.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.9723174823350608, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1359084.947473181, 1359084.947473182, 290608.2202381611], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.9666475690783864, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.377523596520328, 0.37752359652032835, 0.43374361229576286], 
reward next is 0.5663, 
noisyNet noise sample is [array([0.5761048], dtype=float32), -0.396498]. 
=============================================
[2019-03-26 15:20:15,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[53.600067]
 [54.27192 ]
 [55.390526]
 [55.003117]
 [55.343357]], R is [[55.88491058]
 [55.80566788]
 [55.247612  ]
 [54.69513702]
 [54.14818573]].
[2019-03-26 15:20:18,327] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.0662211e-18 1.0000000e+00 9.8143565e-18 1.0546771e-14 4.1812101e-27], sum to 1.0000
[2019-03-26 15:20:18,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4332
[2019-03-26 15:20:18,339] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5399624295733059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754533.4351024448, 754533.4351024448, 190094.2155585692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4058400.0000, 
sim time next is 4059000.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.5396066146914613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754036.0495406995, 754036.0495406988, 190034.4154079187], 
processed observation next is [1.0, 1.0, 0.5023696682464456, 0.865, 1.0, 1.0, 0.4453091743270618, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20945445820574984, 0.20945445820574965, 0.2836334558327145], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.74445105], dtype=float32), 0.38626903]. 
=============================================
[2019-03-26 15:20:18,347] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[62.879593]
 [62.893856]
 [62.90314 ]
 [62.898136]
 [62.91732 ]], R is [[62.95135117]
 [63.03811646]
 [63.1238327 ]
 [63.20858002]
 [63.29247284]].
[2019-03-26 15:20:22,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4376541e-18 1.0000000e+00 7.8354963e-19 1.7073625e-16 4.5761428e-27], sum to 1.0000
[2019-03-26 15:20:22,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2445
[2019-03-26 15:20:22,018] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333334, 88.33333333333334, 1.0, 2.0, 0.7576638047186189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1058896.932026893, 1058896.932026892, 233784.456891426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4076400.0000, 
sim time next is 4077000.0000, 
raw observation next is [27.1, 88.5, 1.0, 2.0, 0.7727494187434324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1079991.028715407, 1079991.028715407, 237331.9339852326], 
processed observation next is [1.0, 0.17391304347826086, 0.4834123222748816, 0.885, 1.0, 1.0, 0.7262041189679909, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29999750797650193, 0.29999750797650193, 0.35422676714213824], 
reward next is 0.6458, 
noisyNet noise sample is [array([1.7680806], dtype=float32), -0.7558269]. 
=============================================
[2019-03-26 15:20:22,032] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.817165]
 [62.90502 ]
 [63.078255]
 [63.020233]
 [62.753918]], R is [[62.65140152]
 [62.67595673]
 [62.66885757]
 [62.68970108]
 [62.70522308]].
[2019-03-26 15:20:22,384] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4740556e-19 1.0000000e+00 4.5927756e-19 1.2621566e-16 7.2346841e-28], sum to 1.0000
[2019-03-26 15:20:22,393] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0506
[2019-03-26 15:20:22,399] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 87.5, 1.0, 2.0, 0.7967053986307002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1113489.350035161, 1113489.350035161, 243104.010936163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4073400.0000, 
sim time next is 4074000.0000, 
raw observation next is [27.26666666666667, 87.66666666666667, 1.0, 2.0, 0.7948406715529139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1110881.811720385, 1110881.811720385, 242648.6013289087], 
processed observation next is [1.0, 0.13043478260869565, 0.4913112164297, 0.8766666666666667, 1.0, 1.0, 0.7528200862083301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30857828103344026, 0.30857828103344026, 0.3621620915356846], 
reward next is 0.6378, 
noisyNet noise sample is [array([0.38137332], dtype=float32), -1.5989094]. 
=============================================
[2019-03-26 15:20:22,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.269608]
 [62.05454 ]
 [61.825962]
 [61.820255]
 [61.67246 ]], R is [[62.32883835]
 [62.34270859]
 [62.34953308]
 [62.29701996]
 [62.27425766]].
[2019-03-26 15:20:24,575] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.7206802e-19 1.0000000e+00 3.1698507e-19 4.1837366e-17 1.1162458e-28], sum to 1.0000
[2019-03-26 15:20:24,585] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8235
[2019-03-26 15:20:24,592] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5825627364649959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814085.1222146007, 814085.1222146007, 197542.2599234823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4141800.0000, 
sim time next is 4142400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5832246196768941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815010.4062550204, 815010.4062550204, 197662.1721715487], 
processed observation next is [1.0, 0.9565217391304348, 0.5734597156398105, 0.84, 1.0, 1.0, 0.497860987562523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22639177951528344, 0.22639177951528344, 0.29501816742022197], 
reward next is 0.7050, 
noisyNet noise sample is [array([0.5166321], dtype=float32), -0.59629697]. 
=============================================
[2019-03-26 15:20:32,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6643999e-08 3.3616713e-01 7.4139713e-12 6.6383278e-01 2.8538664e-17], sum to 1.0000
[2019-03-26 15:20:32,130] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3892
[2019-03-26 15:20:32,134] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.33333333333334, 56.00000000000001, 1.0, 2.0, 0.8744711770928167, 1.0, 2.0, 0.7578256280606708, 1.0, 1.0, 1.03, 7.00511149308065, 6.9112, 170.5573041426782, 3180293.572396673, 3113020.949827705, 582103.2242472343], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4278000.0000, 
sim time next is 4278600.0000, 
raw observation next is [37.5, 55.5, 1.0, 2.0, 0.9714439774406057, 1.0, 2.0, 0.9714439774406057, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2717340.340106608, 2717340.340106609, 511987.7944059112], 
processed observation next is [1.0, 0.5217391304347826, 0.976303317535545, 0.555, 1.0, 1.0, 0.9655951535428985, 1.0, 1.0, 0.9655951535428985, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7548167611407244, 0.7548167611407247, 0.7641608871730018], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.146982], dtype=float32), -0.46864966]. 
=============================================
[2019-03-26 15:20:33,497] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5621296e-20 1.0000000e+00 7.6894529e-20 1.7386120e-19 1.2074416e-29], sum to 1.0000
[2019-03-26 15:20:33,504] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3091
[2019-03-26 15:20:33,513] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.00000000000001, 1.0, 2.0, 0.6225927536582418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 870046.8009729541, 870046.8009729536, 205030.9167263089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4313400.0000, 
sim time next is 4314000.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6213418748053967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868298.0366210239, 868298.0366210239, 204789.8230371206], 
processed observation next is [1.0, 0.9565217391304348, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5437853913318033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24119389906139552, 0.24119389906139552, 0.30565645229420985], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.8515698], dtype=float32), -2.2031918]. 
=============================================
[2019-03-26 15:20:33,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.565643]
 [63.468616]
 [63.657856]
 [63.6623  ]
 [63.579933]], R is [[63.55449295]
 [63.61293411]
 [63.67163467]
 [63.73023987]
 [63.7888298 ]].
[2019-03-26 15:20:37,390] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3573865e-08 5.8671080e-02 1.1590362e-12 9.4132900e-01 7.9440921e-18], sum to 1.0000
[2019-03-26 15:20:37,398] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1197
[2019-03-26 15:20:37,402] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.072758105767218, 6.9112, 170.5573041426782, 3025195.195180189, 2909464.552255561, 552812.8753433654], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4370400.0000, 
sim time next is 4371000.0000, 
raw observation next is [32.33333333333334, 71.83333333333333, 1.0, 2.0, 0.9900814696707527, 1.0, 2.0, 0.9900814696707527, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2769531.251596689, 2769531.251596689, 523028.8277860263], 
processed observation next is [1.0, 0.6086956521739131, 0.7314375987361774, 0.7183333333333333, 1.0, 1.0, 0.9880499634587382, 1.0, 1.0, 0.9880499634587382, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7693142365546359, 0.7693142365546359, 0.780640041471681], 
reward next is 0.2194, 
noisyNet noise sample is [array([0.72568727], dtype=float32), 0.02620983]. 
=============================================
[2019-03-26 15:20:37,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[47.12425 ]
 [45.379486]
 [45.760464]
 [48.229828]
 [47.536804]], R is [[48.76148605]
 [48.27387238]
 [47.79113388]
 [47.31322479]
 [46.84009171]].
[2019-03-26 15:20:44,880] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.03874161e-26 1.00000000e+00 5.16204741e-25 1.21838134e-26
 3.80053556e-34], sum to 1.0000
[2019-03-26 15:20:44,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7187
[2019-03-26 15:20:44,894] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.83333333333333, 71.66666666666667, 1.0, 2.0, 0.6404039290390139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 894947.6451074779, 894947.6451074779, 208515.4691915082], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4449000.0000, 
sim time next is 4449600.0000, 
raw observation next is [33.0, 71.0, 1.0, 2.0, 0.6423674400303991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 897692.7597030667, 897692.7597030667, 208905.309976897], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.71, 1.0, 1.0, 0.5691173976269869, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2493590999175185, 0.2493590999175185, 0.31179897011477165], 
reward next is 0.6882, 
noisyNet noise sample is [array([-0.12507504], dtype=float32), -0.35777882]. 
=============================================
[2019-03-26 15:20:53,124] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0995499e-08 9.3449056e-01 2.4280163e-11 6.5509431e-02 3.5578329e-17], sum to 1.0000
[2019-03-26 15:20:53,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9299
[2019-03-26 15:20:53,142] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2893094.893867731 W.
[2019-03-26 15:20:53,149] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 60.0, 1.0, 2.0, 0.7377575492494542, 1.0, 2.0, 0.6894688141389897, 1.0, 1.0, 1.03, 7.005100709492496, 6.9112, 170.5573041426782, 2893094.893867731, 2825829.996021606, 533521.1202790103], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4629600.0000, 
sim time next is 4630200.0000, 
raw observation next is [35.0, 60.0, 1.0, 2.0, 0.7183680302975848, 1.0, 2.0, 0.6797740546630548, 1.0, 2.0, 1.03, 7.00509918050277, 6.9112, 170.5573041426782, 2852368.059483536, 2785104.256914947, 527194.6380565901], 
processed observation next is [1.0, 0.6086956521739131, 0.8578199052132701, 0.6, 1.0, 1.0, 0.6606843738525118, 1.0, 1.0, 0.6141856080277769, 1.0, 1.0, 1.0365853658536586, 0.009389918050276957, 0.0, 0.8375144448122397, 0.7923244609676489, 0.7736400713652631, 0.7868576687411792], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4050194], dtype=float32), 0.5101371]. 
=============================================
[2019-03-26 15:20:59,345] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6091635e-21 1.0000000e+00 2.5865041e-20 1.8226337e-19 7.6418365e-30], sum to 1.0000
[2019-03-26 15:20:59,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-26 15:20:59,363] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5176297980677346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723315.606932321, 723315.606932321, 186404.4491686033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4739400.0000, 
sim time next is 4740000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5172384432464104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722768.5569846696, 722768.5569846702, 186341.1345189717], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4183595701763981, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2007690436068527, 0.20076904360685285, 0.2781210962969727], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.9554134], dtype=float32), 1.9951769]. 
=============================================
[2019-03-26 15:20:59,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[59.9625  ]
 [59.620438]
 [59.114357]
 [59.02286 ]
 [59.01947 ]], R is [[60.57371521]
 [60.68976212]
 [60.80474472]
 [60.91888809]
 [61.03201294]].
[2019-03-26 15:20:59,577] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 15:20:59,579] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:20:59,580] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:20:59,580] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:59,581] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:20:59,580] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:20:59,581] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:59,583] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:20:59,585] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:59,585] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:59,587] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:20:59,608] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 15:20:59,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 15:20:59,631] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 15:20:59,671] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 15:20:59,689] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 15:21:19,923] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:19,925] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.06666666666667, 91.33333333333334, 1.0, 2.0, 0.5442468249622961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 843652.4958574866, 843652.4958574872, 200698.2711923694]
[2019-03-26 15:21:19,926] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:21:19,928] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1192903e-19 1.0000000e+00 6.6950536e-19 2.7617480e-18 2.6674186e-27], sampled 0.31218756853616725
[2019-03-26 15:21:27,091] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:27,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.51861458, 95.85073916, 1.0, 2.0, 0.2744594404763447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 450267.617944623, 450267.6179446236, 163421.8624915749]
[2019-03-26 15:21:27,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:21:27,095] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.6467668e-22 1.0000000e+00 4.3845928e-21 6.1784778e-22 3.3771543e-30], sampled 0.5939188992486909
[2019-03-26 15:21:32,333] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:32,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.1, 86.66666666666666, 1.0, 2.0, 0.4993681427436349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697789.1036556391, 697789.1036556397, 183496.6338693795]
[2019-03-26 15:21:32,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:21:32,338] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7113740e-22 1.0000000e+00 1.7549154e-21 1.0888950e-22 1.4831792e-30], sampled 0.16713381585931208
[2019-03-26 15:21:33,088] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:33,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.46666666666667, 84.66666666666667, 1.0, 2.0, 0.5300039202080183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740612.7484461255, 740612.7484461262, 188430.6489737317]
[2019-03-26 15:21:33,090] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:21:33,092] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2594071e-21 1.0000000e+00 7.6407352e-21 7.8849926e-21 5.7702099e-30], sampled 0.13162070340070475
[2019-03-26 15:21:41,974] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:41,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.96666666666667, 89.66666666666667, 1.0, 2.0, 0.8159832619677602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1140446.896630821, 1140446.896630821, 247872.148700697]
[2019-03-26 15:21:41,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:21:41,982] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2174977e-20 1.0000000e+00 4.2808862e-20 4.3595281e-20 1.0585752e-28], sampled 0.8042887793213421
[2019-03-26 15:21:45,629] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:45,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.84900788, 86.66738512, 1.0, 2.0, 0.5253028907023295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 783191.06041784, 783191.06041784, 193751.6315809892]
[2019-03-26 15:21:45,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:21:45,635] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.7236051e-22 1.0000000e+00 6.1581973e-21 5.9135184e-22 7.4530344e-30], sampled 0.8545626856196229
[2019-03-26 15:21:59,393] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05074177], dtype=float32), 0.07016136]
[2019-03-26 15:21:59,394] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.72777105, 80.841179915, 1.0, 2.0, 0.9152371434116938, 1.0, 1.0, 0.9152371434116938, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2559921.543432288, 2559921.543432288, 480368.3573496038]
[2019-03-26 15:21:59,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:21:59,398] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7680996e-10 9.9997175e-01 9.6251999e-13 2.8294078e-05 2.4859071e-18], sampled 0.9845102293282865
[2019-03-26 15:21:59,398] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2559921.543432288 W.
[2019-03-26 15:22:54,667] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.0120 3164049622.8549 1773.0000
[2019-03-26 15:22:54,967] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3918 2842504862.1440 1131.0000
[2019-03-26 15:22:55,156] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1132 2927534923.5977 1338.0000
[2019-03-26 15:22:55,214] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8775 2779222526.1705 933.0000
[2019-03-26 15:22:55,238] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.8649 3007754281.4365 1765.0000
[2019-03-26 15:22:56,252] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 550000, evaluation results [550000.0, 7884.011951717886, 3164049622.8549147, 1773.0, 8254.113199770398, 2927534923.5976505, 1338.0, 8659.87750936659, 2779222526.170501, 933.0, 7997.864901874412, 3007754281.436526, 1765.0, 8495.391844197313, 2842504862.143969, 1131.0]
[2019-03-26 15:22:56,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.7594897e-19 1.0000000e+00 2.4964867e-19 8.7255742e-18 3.6697596e-28], sum to 1.0000
[2019-03-26 15:22:56,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4109
[2019-03-26 15:22:56,778] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7835879753519386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1095146.756755355, 1095146.756755355, 239918.6676532144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4761600.0000, 
sim time next is 4762200.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7545645603778484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1054563.334669906, 1054563.334669906, 233060.318162231], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7042946510576487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29293425963052944, 0.29293425963052944, 0.3478512211376582], 
reward next is 0.6521, 
noisyNet noise sample is [array([0.3402821], dtype=float32), -0.7248892]. 
=============================================
[2019-03-26 15:23:06,573] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.7433313e-08 4.9428412e-01 9.9548937e-12 5.0571579e-01 4.8218360e-17], sum to 1.0000
[2019-03-26 15:23:06,582] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1293
[2019-03-26 15:23:06,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2673004.342968326 W.
[2019-03-26 15:23:06,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 65.33333333333334, 1.0, 2.0, 0.9556108811851587, 1.0, 2.0, 0.9556108811851587, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2673004.342968326, 2673004.342968326, 502734.379284092], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4893600.0000, 
sim time next is 4894200.0000, 
raw observation next is [31.25, 65.5, 1.0, 2.0, 0.9349004300089037, 1.0, 2.0, 0.9349004300089037, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2615013.101907265, 2615013.101907264, 490885.1986870602], 
processed observation next is [1.0, 0.6521739130434783, 0.6800947867298578, 0.655, 1.0, 1.0, 0.9215667831432575, 1.0, 1.0, 0.9215667831432575, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7263925283075736, 0.7263925283075733, 0.7326644756523287], 
reward next is 0.2673, 
noisyNet noise sample is [array([1.7403504], dtype=float32), -0.23130335]. 
=============================================
[2019-03-26 15:23:08,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7219313e-21 1.0000000e+00 4.3737845e-21 1.1955404e-19 1.5372580e-30], sum to 1.0000
[2019-03-26 15:23:08,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1242
[2019-03-26 15:23:08,247] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5093125521134234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711689.5198407974, 711689.5198407968, 185068.074878838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4920000.0000, 
sim time next is 4920600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5095323512195129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711996.7597552518, 711996.7597552518, 185103.113205666], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4090751219512203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19777687770979216, 0.19777687770979216, 0.2762733032920388], 
reward next is 0.7237, 
noisyNet noise sample is [array([-0.46961984], dtype=float32), 0.5580058]. 
=============================================
[2019-03-26 15:23:11,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2213266e-20 1.0000000e+00 8.3282434e-21 2.7753614e-18 4.0914730e-30], sum to 1.0000
[2019-03-26 15:23:11,602] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5559
[2019-03-26 15:23:11,606] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5207347086276652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727655.7733850864, 727655.773385087, 186908.6286438667], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4995000.0000, 
sim time next is 4995600.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5206245008709525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727501.7203321003, 727501.7203320996, 186890.6140350714], 
processed observation next is [1.0, 0.8260869565217391, 0.541864139020537, 0.7733333333333333, 1.0, 1.0, 0.42243915767584633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2020838112033612, 0.202083811203361, 0.2789412149777185], 
reward next is 0.7211, 
noisyNet noise sample is [array([0.46752426], dtype=float32), -1.089907]. 
=============================================
[2019-03-26 15:23:16,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4727654e-23 1.0000000e+00 4.6614447e-23 5.1966083e-23 9.5019558e-33], sum to 1.0000
[2019-03-26 15:23:16,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5160
[2019-03-26 15:23:16,099] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 88.16666666666667, 1.0, 2.0, 0.491929910150616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687391.9707137512, 687391.9707137519, 182341.4938957685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5021400.0000, 
sim time next is 5022000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4960570641905541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 693160.8782075542, 693160.8782075549, 182980.8162080559], 
processed observation next is [0.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.39283983637416164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1925446883909873, 0.19254468839098748, 0.27310569583291927], 
reward next is 0.7269, 
noisyNet noise sample is [array([1.6747015], dtype=float32), 1.4860044]. 
=============================================
[2019-03-26 15:23:16,108] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.10207 ]
 [73.220665]
 [73.40985 ]
 [73.590195]
 [73.55303 ]], R is [[73.14660645]
 [73.14299011]
 [73.14033508]
 [73.13856506]
 [73.13758087]].
[2019-03-26 15:23:25,431] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6985633e-17 1.0000000e+00 7.8648473e-18 6.7181177e-15 2.4691819e-26], sum to 1.0000
[2019-03-26 15:23:25,441] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7483
[2019-03-26 15:23:25,448] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 83.16666666666667, 1.0, 2.0, 0.7675019187544418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1072653.442791051, 1072653.442791051, 236088.4467856895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5206200.0000, 
sim time next is 5206800.0000, 
raw observation next is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.7551541827924095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1055387.78787028, 1055387.78787028, 233199.0512750815], 
processed observation next is [1.0, 0.2608695652173913, 0.4944707740916275, 0.8233333333333335, 1.0, 1.0, 0.7050050395089271, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2931632744084111, 0.2931632744084111, 0.34805828548519624], 
reward next is 0.6519, 
noisyNet noise sample is [array([1.4350327], dtype=float32), -0.9152155]. 
=============================================
[2019-03-26 15:23:33,140] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7061228e-19 1.0000000e+00 4.2557602e-21 1.6399997e-18 5.7369801e-30], sum to 1.0000
[2019-03-26 15:23:33,149] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5185
[2019-03-26 15:23:33,157] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.6245572213472688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872793.1887043887, 872793.1887043887, 205411.2944045779], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5341200.0000, 
sim time next is 5341800.0000, 
raw observation next is [31.75, 76.5, 1.0, 2.0, 0.6264332755560198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 875415.9782338598, 875415.9782338605, 205774.8840607514], 
processed observation next is [1.0, 0.8260869565217391, 0.7037914691943128, 0.765, 1.0, 1.0, 0.5499196091036382, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24317110506496104, 0.24317110506496123, 0.3071266926279872], 
reward next is 0.6929, 
noisyNet noise sample is [array([1.4704323], dtype=float32), 0.9134558]. 
=============================================
[2019-03-26 15:23:33,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.2728544e-09 2.2743347e-03 1.1494457e-13 9.9772567e-01 6.3683486e-18], sum to 1.0000
[2019-03-26 15:23:33,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4847
[2019-03-26 15:23:33,375] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.11666666666667, 52.83333333333334, 1.0, 2.0, 0.8810888877854811, 1.0, 2.0, 0.7611344834070031, 1.0, 1.0, 1.03, 7.005112015192923, 6.9112, 170.5573041426782, 3194197.28426699, 3126924.287687763, 584629.7798760312], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5320200.0000, 
sim time next is 5320800.0000, 
raw observation next is [36.1, 53.0, 1.0, 2.0, 1.004260486811423, 1.0, 2.0, 1.004260486811423, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2809238.473938189, 2809238.473938189, 531571.5622756977], 
processed observation next is [1.0, 0.6086956521739131, 0.9099526066350712, 0.53, 1.0, 1.0, 1.0051331166402688, 1.0, 1.0, 1.0051331166402688, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7803440205383858, 0.7803440205383858, 0.7933903914562652], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.38244072], dtype=float32), -0.6511901]. 
=============================================
[2019-03-26 15:23:36,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4969202e-08 2.8459987e-01 4.1496446e-12 7.1540004e-01 1.7948812e-17], sum to 1.0000
[2019-03-26 15:23:36,746] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9189
[2019-03-26 15:23:36,751] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.9, 71.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.041429389042327, 6.9112, 170.5573041426782, 3002727.023645668, 2909438.414881798, 552963.8255802877], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5418000.0000, 
sim time next is 5418600.0000, 
raw observation next is [30.9, 71.66666666666667, 1.0, 2.0, 0.4351985793139421, 1.0, 2.0, 0.4351985793139421, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1216534.520028472, 1216534.520028472, 281365.5860652915], 
processed observation next is [1.0, 0.7391304347826086, 0.6635071090047393, 0.7166666666666667, 1.0, 1.0, 0.31951636061920735, 1.0, 1.0, 0.31951636061920735, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.33792625556346445, 0.33792625556346445, 0.4199486359183455], 
reward next is 0.5801, 
noisyNet noise sample is [array([-0.45302805], dtype=float32), 1.0714806]. 
=============================================
[2019-03-26 15:23:41,297] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.6588222e-07 9.1766733e-01 2.5797131e-10 8.2332350e-02 1.3265503e-14], sum to 1.0000
[2019-03-26 15:23:41,306] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7491
[2019-03-26 15:23:41,313] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2373630.507036836 W.
[2019-03-26 15:23:41,321] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.08333333333333, 72.66666666666666, 1.0, 2.0, 0.8486849722920297, 1.0, 2.0, 0.8486849722920297, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2373630.507036836, 2373630.507036836, 444280.7637369231], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5475000.0000, 
sim time next is 5475600.0000, 
raw observation next is [32.3, 72.0, 1.0, 2.0, 0.8780888974968941, 1.0, 2.0, 0.8780888974968941, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2455949.202787359, 2455949.202787359, 459690.1951057177], 
processed observation next is [1.0, 0.391304347826087, 0.7298578199052131, 0.72, 1.0, 1.0, 0.8531191536107158, 1.0, 1.0, 0.8531191536107158, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6822081118853774, 0.6822081118853774, 0.686104768814504], 
reward next is 0.3139, 
noisyNet noise sample is [array([0.30938783], dtype=float32), -0.8627807]. 
=============================================
[2019-03-26 15:23:46,263] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8677101e-20 1.0000000e+00 8.3016315e-21 8.6055063e-20 2.1745830e-29], sum to 1.0000
[2019-03-26 15:23:46,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3512
[2019-03-26 15:23:46,275] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 91.83333333333333, 1.0, 2.0, 0.5207622642880092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727694.291853428, 727694.291853428, 186912.7021412179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5619000.0000, 
sim time next is 5619600.0000, 
raw observation next is [26.0, 92.0, 1.0, 2.0, 0.5186026217205423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724675.4562992429, 724675.4562992435, 186561.8068549785], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.92, 1.0, 1.0, 0.4200031586994485, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2012987378609008, 0.20129873786090097, 0.27845045799250523], 
reward next is 0.7215, 
noisyNet noise sample is [array([-0.21247678], dtype=float32), -0.01710684]. 
=============================================
[2019-03-26 15:23:52,383] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 15:23:52,384] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:23:52,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:23:52,386] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:23:52,387] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:23:52,387] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:23:52,388] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:23:52,389] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:23:52,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:23:52,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:23:52,395] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:23:52,417] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 15:23:52,417] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 15:23:52,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 15:23:52,418] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 15:23:52,458] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 15:24:08,638] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:24:08,639] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.4257886, 94.77080068333333, 1.0, 2.0, 0.3257976151721972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 510790.4059634676, 510790.405963467, 167747.5374120872]
[2019-03-26 15:24:08,641] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:24:08,645] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.0579686e-26 1.0000000e+00 1.2722539e-25 3.0617005e-27 7.2376393e-35], sampled 0.9974343686693512
[2019-03-26 15:24:46,820] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:24:46,821] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.08333333333334, 46.5, 1.0, 2.0, 0.7545462752306086, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000077248651796, 6.9112, 168.9123555446044, 1951461.087185114, 1888408.732403901, 397147.8366195175]
[2019-03-26 15:24:46,822] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:24:46,825] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.4678731e-14 1.0000000e+00 3.3267848e-17 4.0421835e-09 3.0323707e-22], sampled 0.9953597024951558
[2019-03-26 15:24:46,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1951461.087185114 W.
[2019-03-26 15:24:58,623] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:24:58,625] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.940281615, 81.69424152833334, 1.0, 2.0, 0.5099864194009863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712631.4662996423, 712631.4662996418, 185174.6277210092]
[2019-03-26 15:24:58,626] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:24:58,628] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.4800490e-26 1.0000000e+00 1.0804977e-25 1.1873053e-26 6.1125385e-35], sampled 0.24345987271275793
[2019-03-26 15:25:11,257] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:11,258] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.65, 56.33333333333333, 1.0, 2.0, 0.6066430929992214, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.93790891762463, 6.9112, 168.9126811979436, 1696175.059858534, 1677226.865329475, 365806.7825488208]
[2019-03-26 15:25:11,260] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:25:11,263] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.6468570e-14 1.0000000e+00 2.3837393e-17 3.9348031e-09 1.7901006e-22], sampled 0.43810666518621766
[2019-03-26 15:25:11,267] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1696175.059858534 W.
[2019-03-26 15:25:20,742] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:20,745] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.9087942, 72.40549792499999, 1.0, 2.0, 0.4449546422992127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 645882.8724602069, 645882.8724602063, 178504.3400228856]
[2019-03-26 15:25:20,745] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:25:20,750] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3334526e-25 1.0000000e+00 3.0793905e-25 1.4846151e-25 1.8373563e-34], sampled 0.4015958467136318
[2019-03-26 15:25:24,147] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:24,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.21472901, 87.63665974, 1.0, 2.0, 0.5101302199506593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712832.4739667538, 712832.4739667538, 185197.9116441183]
[2019-03-26 15:25:24,149] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:25:24,153] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.5951816e-26 1.0000000e+00 1.2927968e-25 2.1421784e-27 1.3383034e-34], sampled 0.7375257129092271
[2019-03-26 15:25:29,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:29,190] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.55, 76.5, 1.0, 2.0, 0.6802466394553881, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980116111180164, 6.9112, 168.9124908916374, 1847487.211778976, 1798595.885370548, 381348.0193864296]
[2019-03-26 15:25:29,192] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:25:29,194] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9284644e-16 1.0000000e+00 8.5501168e-18 1.6337409e-13 8.4680014e-24], sampled 0.4350232563882158
[2019-03-26 15:25:29,195] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1847487.211778976 W.
[2019-03-26 15:25:33,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:33,561] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 88.16666666666667, 1.0, 2.0, 0.5312467300386452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742350.02321021, 742350.0232102106, 188635.8934482311]
[2019-03-26 15:25:33,562] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:25:33,564] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2412896e-25 1.0000000e+00 1.7967271e-25 1.2285042e-26 1.1852008e-34], sampled 0.26111928095562287
[2019-03-26 15:25:36,550] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03700001], dtype=float32), 0.07721866]
[2019-03-26 15:25:36,551] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.05, 79.66666666666667, 1.0, 2.0, 0.83946407399747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1173282.636559313, 1173282.636559313, 253832.7109925358]
[2019-03-26 15:25:36,552] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:25:36,553] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3459291e-23 1.0000000e+00 1.0589293e-23 3.9061339e-24 3.4947626e-32], sampled 0.613138135150145
[2019-03-26 15:25:46,740] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1639 3007747783.1430 1766.0000
[2019-03-26 15:25:47,569] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.1371 2779404952.9849 933.0000
[2019-03-26 15:25:47,690] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 15:25:47,803] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3918 2842563638.9128 1131.0000
[2019-03-26 15:25:47,886] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1320 2927522702.9456 1338.0000
[2019-03-26 15:25:48,902] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 575000, evaluation results [575000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.132014516563, 2927522702.9455853, 1338.0, 8659.137118778835, 2779404952.9849343, 933.0, 7998.16386951494, 3007747783.142953, 1766.0, 8495.391845542033, 2842563638.9127707, 1131.0]
[2019-03-26 15:25:54,839] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1900135e-24 1.0000000e+00 1.5421436e-24 9.5086249e-26 3.0809760e-33], sum to 1.0000
[2019-03-26 15:25:54,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-26 15:25:54,855] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 84.0, 1.0, 2.0, 0.5458243591685282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 762727.7271971051, 762727.7271971044, 191086.9771636304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5778000.0000, 
sim time next is 5778600.0000, 
raw observation next is [27.83333333333333, 84.33333333333333, 1.0, 2.0, 0.5468479034284822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764158.5288643345, 764158.5288643345, 191261.2868749911], 
processed observation next is [0.0, 0.9130434782608695, 0.518167456556082, 0.8433333333333333, 1.0, 1.0, 0.45403361858853275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2122662580178707, 0.2122662580178707, 0.2854646072761061], 
reward next is 0.7145, 
noisyNet noise sample is [array([0.6407884], dtype=float32), -0.29284298]. 
=============================================
[2019-03-26 15:25:56,301] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5035243e-24 1.0000000e+00 1.8243890e-24 5.9836268e-25 2.0274647e-32], sum to 1.0000
[2019-03-26 15:25:56,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6205
[2019-03-26 15:25:56,316] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.08333333333334, 57.16666666666667, 1.0, 2.0, 0.5421806642376003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757634.2603337981, 757634.2603337975, 190469.5307139758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5759400.0000, 
sim time next is 5760000.0000, 
raw observation next is [32.9, 58.0, 1.0, 2.0, 0.543803572676141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759902.8968467354, 759902.8968467347, 190744.3764636886], 
processed observation next is [0.0, 0.6956521739130435, 0.7582938388625592, 0.58, 1.0, 1.0, 0.45036575021221803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21108413801298206, 0.21108413801298187, 0.2846930991995352], 
reward next is 0.7153, 
noisyNet noise sample is [array([1.2276058], dtype=float32), -0.19265361]. 
=============================================
[2019-03-26 15:25:56,328] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.7217  ]
 [70.69026 ]
 [70.655754]
 [70.618904]
 [70.58382 ]], R is [[70.7722702 ]
 [70.78025818]
 [70.78851318]
 [70.79682159]
 [70.80509186]].
[2019-03-26 15:25:58,293] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5575280e-16 1.0000000e+00 8.4657667e-18 1.5767656e-15 5.8011894e-25], sum to 1.0000
[2019-03-26 15:25:58,300] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-26 15:25:58,304] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 78.0, 1.0, 2.0, 0.9195888788130633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1285337.397135478, 1285337.397135478, 275384.3548494923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5817600.0000, 
sim time next is 5818200.0000, 
raw observation next is [29.35, 77.33333333333333, 1.0, 2.0, 0.9998214274603627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1397554.689650868, 1397554.689650869, 298873.049129988], 
processed observation next is [1.0, 0.34782608695652173, 0.590047393364929, 0.7733333333333333, 1.0, 1.0, 0.9997848523618829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38820963601413, 0.3882096360141303, 0.44607917780595224], 
reward next is 0.5539, 
noisyNet noise sample is [array([0.23855397], dtype=float32), -0.5728133]. 
=============================================
[2019-03-26 15:25:59,368] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9989104e-16 1.0000000e+00 1.3075673e-17 1.6082764e-14 1.8140902e-24], sum to 1.0000
[2019-03-26 15:25:59,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8880
[2019-03-26 15:25:59,384] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.65, 80.5, 1.0, 2.0, 1.030111933655643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128842521867, 1439923.60576418, 1439923.60576418, 308235.99370558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815800.0000, 
sim time next is 5816400.0000, 
raw observation next is [28.83333333333334, 79.66666666666667, 1.0, 2.0, 0.999202889045295, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1396689.525228156, 1396689.525228156, 298684.3226347532], 
processed observation next is [1.0, 0.30434782608695654, 0.5655608214849924, 0.7966666666666667, 1.0, 1.0, 0.9990396253557771, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3879693125633767, 0.3879693125633767, 0.4457974964697809], 
reward next is 0.5542, 
noisyNet noise sample is [array([-1.1669613], dtype=float32), 1.6162773]. 
=============================================
[2019-03-26 15:26:02,125] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.5386906e-19 1.0000000e+00 1.7950396e-20 1.7046989e-18 9.6808873e-29], sum to 1.0000
[2019-03-26 15:26:02,133] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4610
[2019-03-26 15:26:02,139] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.5250008546552274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733619.1895011489, 733619.1895011495, 187605.9281109089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5882400.0000, 
sim time next is 5883000.0000, 
raw observation next is [25.98333333333333, 94.16666666666667, 1.0, 2.0, 1.031517588784715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1441889.809772644, 1441889.809772644, 308675.2991374247], 
processed observation next is [1.0, 0.08695652173913043, 0.43048973143759867, 0.9416666666666668, 1.0, 1.0, 1.0379729985358013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4005249471590678, 0.4005249471590678, 0.4607094016976488], 
reward next is 0.5393, 
noisyNet noise sample is [array([0.82489896], dtype=float32), -1.057326]. 
=============================================
[2019-03-26 15:26:02,160] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[61.798267]
 [61.724537]
 [61.778526]
 [61.841606]
 [61.93435 ]], R is [[60.32056427]
 [60.43734741]
 [60.55291748]
 [60.66727066]
 [60.78039932]].
[2019-03-26 15:26:03,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5545341e-18 1.0000000e+00 4.8452042e-19 7.1338413e-18 7.3528230e-27], sum to 1.0000
[2019-03-26 15:26:03,864] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6657
[2019-03-26 15:26:03,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 95.0, 1.0, 2.0, 0.9649197290024352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1348737.95474605, 1348737.95474605, 288418.6792180605], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5887200.0000, 
sim time next is 5887800.0000, 
raw observation next is [25.8, 95.0, 1.0, 2.0, 0.9620627942517301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1344742.081665313, 1344742.081665313, 287578.9995235306], 
processed observation next is [1.0, 0.13043478260869565, 0.42180094786729866, 0.95, 1.0, 1.0, 0.9542925231948556, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3735394671292536, 0.3735394671292536, 0.4292223873485531], 
reward next is 0.5708, 
noisyNet noise sample is [array([0.24716783], dtype=float32), 0.18941683]. 
=============================================
[2019-03-26 15:26:15,516] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.2869659e-08 8.3880442e-01 6.2338551e-13 1.6119549e-01 4.1758585e-17], sum to 1.0000
[2019-03-26 15:26:15,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0918
[2019-03-26 15:26:15,539] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2251735.022326998 W.
[2019-03-26 15:26:15,545] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.85, 65.83333333333333, 1.0, 2.0, 0.8051408107358518, 1.0, 2.0, 0.8051408107358518, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2251735.022326998, 2251735.022326997, 422378.3029953829], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6101400.0000, 
sim time next is 6102000.0000, 
raw observation next is [30.8, 66.0, 1.0, 2.0, 0.5388351996339026, 1.0, 2.0, 0.5388351996339026, 1.0, 1.0, 0.9308319311854242, 6.9112, 6.9112, 170.5573041426782, 2260446.183179723, 2260446.183179723, 442069.3134730179], 
processed observation next is [1.0, 0.6521739130434783, 0.6587677725118484, 0.66, 1.0, 1.0, 0.44437975859506335, 1.0, 1.0, 0.44437975859506335, 1.0, 0.5, 0.9156486965675903, 0.0, 0.0, 0.8375144448122397, 0.6279017175499231, 0.6279017175499231, 0.6598049454821162], 
reward next is 0.3402, 
noisyNet noise sample is [array([-0.6311474], dtype=float32), 0.12144413]. 
=============================================
[2019-03-26 15:26:15,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[47.150005]
 [46.491364]
 [45.74786 ]
 [44.8099  ]
 [44.939335]], R is [[45.50922775]
 [45.4237175 ]
 [45.31933212]
 [45.14441681]
 [44.69297409]].
[2019-03-26 15:26:25,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.0079755e-25 1.0000000e+00 2.0262028e-26 2.0696914e-27 3.3892900e-35], sum to 1.0000
[2019-03-26 15:26:25,055] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5117
[2019-03-26 15:26:25,061] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.76666666666667, 62.0, 1.0, 2.0, 0.5078006300671732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709576.1251180142, 709576.1251180142, 184827.4236625128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6273600.0000, 
sim time next is 6274200.0000, 
raw observation next is [30.73333333333333, 62.0, 1.0, 2.0, 0.5066521727252193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707970.7914016352, 707970.7914016346, 184645.0240866598], 
processed observation next is [0.0, 0.6086956521739131, 0.6556082148499209, 0.62, 1.0, 1.0, 0.4056050273797823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1966585531671209, 0.19665855316712072, 0.2755895881890445], 
reward next is 0.7244, 
noisyNet noise sample is [array([-1.5527155], dtype=float32), 0.64834535]. 
=============================================
[2019-03-26 15:26:25,703] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5435502e-24 1.0000000e+00 6.7622044e-25 9.0216697e-25 3.0186656e-33], sum to 1.0000
[2019-03-26 15:26:25,718] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9449
[2019-03-26 15:26:25,723] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5277896534109376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737517.5194075225, 737517.5194075225, 188064.6001796792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5281840973461742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738068.8950873374, 738068.8950873368, 188129.6472705961], 
processed observation next is [0.0, 0.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4315471052363545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20501913752426038, 0.2050191375242602, 0.2807905183143225], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.568026], dtype=float32), 0.6277248]. 
=============================================
[2019-03-26 15:26:26,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2551094e-22 1.0000000e+00 3.3815990e-24 1.2025871e-22 1.8123121e-32], sum to 1.0000
[2019-03-26 15:26:26,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6158
[2019-03-26 15:26:26,587] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.16666666666667, 1.0, 2.0, 0.5289172763333795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739093.7742306674, 739093.7742306667, 188250.7419989714], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6307800.0000, 
sim time next is 6308400.0000, 
raw observation next is [27.3, 85.33333333333334, 1.0, 2.0, 0.5297373591888676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740240.133698212, 740240.1336982113, 188386.3710716541], 
processed observation next is [0.0, 0.0, 0.4928909952606636, 0.8533333333333334, 1.0, 1.0, 0.43341850504682833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20562225936061443, 0.20562225936061423, 0.28117368816664795], 
reward next is 0.7188, 
noisyNet noise sample is [array([-1.1366997], dtype=float32), -1.5408553]. 
=============================================
[2019-03-26 15:26:35,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3770037e-19 1.0000000e+00 2.2944874e-22 5.0658953e-17 2.8400762e-30], sum to 1.0000
[2019-03-26 15:26:35,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0788
[2019-03-26 15:26:35,566] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 71.0, 1.0, 2.0, 0.5080060797651659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709863.3065473617, 709863.3065473617, 184860.1133665758], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6459600.0000, 
sim time next is 6460200.0000, 
raw observation next is [29.0, 71.5, 1.0, 2.0, 0.5065285289715604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707797.9601494962, 707797.9601494956, 184625.4918272532], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.715, 1.0, 1.0, 0.40545605900188, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19661054448597118, 0.196610544485971, 0.2755604355630645], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.43943134], dtype=float32), 0.23334119]. 
=============================================
[2019-03-26 15:26:42,194] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4308386e-12 1.0000000e+00 9.5011990e-17 4.4762970e-08 3.3958461e-23], sum to 1.0000
[2019-03-26 15:26:42,202] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0547
[2019-03-26 15:26:42,215] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1789013.852189666 W.
[2019-03-26 15:26:42,221] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.383454980774662, 6.9112, 168.9106987851167, 1789013.852189666, 1453984.393198586, 311351.1275036303], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6613200.0000, 
sim time next is 6613800.0000, 
raw observation next is [31.08333333333334, 65.0, 1.0, 2.0, 0.5870236171316014, 1.0, 1.0, 0.5870236171316014, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1641264.319906969, 1641264.31990697, 329508.7985991806], 
processed observation next is [1.0, 0.5652173913043478, 0.6721958925750398, 0.65, 1.0, 1.0, 0.5024380929296403, 1.0, 0.5, 0.5024380929296403, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.45590675552971366, 0.4559067555297139, 0.4918041770137024], 
reward next is 0.5082, 
noisyNet noise sample is [array([-0.77893066], dtype=float32), -0.21564999]. 
=============================================
[2019-03-26 15:26:45,057] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 15:26:45,060] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:26:45,061] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:26:45,061] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:26:45,061] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:26:45,062] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:26:45,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:26:45,063] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:26:45,066] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:26:45,068] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:26:45,064] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:26:45,088] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 15:26:45,089] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 15:26:45,089] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 15:26:45,128] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 15:26:45,170] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 15:27:24,416] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03663727], dtype=float32), 0.075882345]
[2019-03-26 15:27:24,419] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.96666666666667, 77.0, 1.0, 2.0, 0.5781634356152654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807935.1108010804, 807935.1108010804, 196748.1160747145]
[2019-03-26 15:27:24,420] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:27:24,422] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1079096e-21 1.0000000e+00 7.5393040e-23 2.8444477e-21 3.6655864e-30], sampled 0.4923998476795165
[2019-03-26 15:27:27,280] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03663727], dtype=float32), 0.075882345]
[2019-03-26 15:27:27,282] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.5, 85.0, 1.0, 2.0, 0.5434068721498897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 759348.3553807295, 759348.3553807302, 190675.7386262366]
[2019-03-26 15:27:27,283] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:27:27,288] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.6854217e-22 1.0000000e+00 2.5938812e-23 3.5853505e-21 2.1909842e-31], sampled 0.7655163831642279
[2019-03-26 15:27:32,174] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03663727], dtype=float32), 0.075882345]
[2019-03-26 15:27:32,175] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.34999999999999, 58.5, 1.0, 2.0, 0.9480618098715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1325159.717976754, 1325159.717976754, 283505.2923584089]
[2019-03-26 15:27:32,177] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:27:32,180] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8684958e-21 1.0000000e+00 3.2367950e-22 2.5473465e-20 9.7700320e-30], sampled 0.23545315155648727
[2019-03-26 15:28:19,223] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03663727], dtype=float32), 0.075882345]
[2019-03-26 15:28:19,224] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.67452539333333, 62.15889290499999, 1.0, 2.0, 0.4417452667149879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 641897.8227124116, 641897.8227124116, 178120.2429026476]
[2019-03-26 15:28:19,225] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:28:19,228] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2148844e-22 1.0000000e+00 1.3311013e-23 1.4979233e-22 4.7878501e-31], sampled 0.797341939692469
[2019-03-26 15:28:39,651] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8021.3595 3004531733.4480 1690.0000
[2019-03-26 15:28:39,904] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9950 2778906579.1192 929.0000
[2019-03-26 15:28:39,999] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8272.1693 2926110011.1608 1307.0000
[2019-03-26 15:28:40,353] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7936.3034 3158006736.6362 1613.0000
[2019-03-26 15:28:40,441] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8506.5062 2841250568.9290 1097.0000
[2019-03-26 15:28:41,459] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 600000, evaluation results [600000.0, 7936.30340458735, 3158006736.6362314, 1613.0, 8272.16934936465, 2926110011.1607585, 1307.0, 8659.994998858274, 2778906579.11918, 929.0, 8021.359463394872, 3004531733.4479613, 1690.0, 8506.506155745901, 2841250568.9289765, 1097.0]
[2019-03-26 15:28:51,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2408519e-21 1.0000000e+00 7.4133065e-23 1.8235221e-21 3.5242727e-30], sum to 1.0000
[2019-03-26 15:28:51,595] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9323
[2019-03-26 15:28:51,602] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 77.0, 1.0, 2.0, 0.3747493844665999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 588698.4156158856, 588698.4156158856, 174175.6952414407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6766800.0000, 
sim time next is 6767400.0000, 
raw observation next is [23.66666666666667, 76.5, 1.0, 2.0, 0.3844108377844545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603003.0325276207, 603003.0325276207, 175421.6376671486], 
processed observation next is [1.0, 0.30434782608695654, 0.3206951026856243, 0.765, 1.0, 1.0, 0.2583263105836801, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16750084236878351, 0.16750084236878351, 0.26182333980171435], 
reward next is 0.7382, 
noisyNet noise sample is [array([-0.3895913], dtype=float32), -0.10949188]. 
=============================================
[2019-03-26 15:28:52,521] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0883265e-21 1.0000000e+00 1.4009022e-22 2.6524311e-20 4.3410521e-30], sum to 1.0000
[2019-03-26 15:28:52,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1594
[2019-03-26 15:28:52,535] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 83.5, 1.0, 2.0, 0.3659360682601785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 579438.8657669369, 579438.8657669376, 173408.5297280036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6748200.0000, 
sim time next is 6748800.0000, 
raw observation next is [22.2, 83.66666666666667, 1.0, 2.0, 0.3422726798846468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542331.6899244603, 542331.6899244603, 170328.2951468949], 
processed observation next is [1.0, 0.08695652173913043, 0.2511848341232228, 0.8366666666666667, 1.0, 1.0, 0.2075574456441528, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1506476916456834, 0.1506476916456834, 0.25422133604014163], 
reward next is 0.7458, 
noisyNet noise sample is [array([0.33514318], dtype=float32), -1.3930415]. 
=============================================
[2019-03-26 15:28:58,669] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.4879153e-26 1.0000000e+00 5.8326736e-26 5.2601436e-26 7.9205131e-34], sum to 1.0000
[2019-03-26 15:28:58,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-26 15:28:58,678] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 63.16666666666666, 1.0, 2.0, 0.3688237051575706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 562188.2769463515, 562188.2769463509, 171512.6995161288], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6897000.0000, 
sim time next is 6897600.0000, 
raw observation next is [26.8, 64.0, 1.0, 2.0, 0.3693110611153672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 562659.6548752574, 562659.6548752574, 171545.3113086715], 
processed observation next is [0.0, 0.8695652173913043, 0.4691943127962086, 0.64, 1.0, 1.0, 0.2401338085727316, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15629434857646038, 0.15629434857646038, 0.256037778072644], 
reward next is 0.7440, 
noisyNet noise sample is [array([-0.40941793], dtype=float32), -2.4842553]. 
=============================================
[2019-03-26 15:29:03,911] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2501957e-07 6.7195874e-01 7.5707989e-13 3.2804105e-01 1.0906051e-15], sum to 1.0000
[2019-03-26 15:29:03,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1097
[2019-03-26 15:29:03,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1838058.102467271 W.
[2019-03-26 15:29:03,936] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 55.66666666666667, 1.0, 2.0, 0.4382330989028158, 1.0, 1.0, 0.4382330989028158, 1.0, 2.0, 0.7313453667470046, 6.9112, 6.9112, 170.5573041426782, 1838058.102467271, 1838058.102467271, 370278.6822112069], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7036800.0000, 
sim time next is 7037400.0000, 
raw observation next is [30.43333333333334, 54.83333333333333, 1.0, 2.0, 0.664226314049674, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.950511308869091, 6.9112, 168.9127215012112, 1836375.405528954, 1808486.648828172, 380102.1738658469], 
processed observation next is [1.0, 0.43478260869565216, 0.6413902053712484, 0.5483333333333333, 1.0, 1.0, 0.595453390421294, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.003931130886909084, 0.0, 0.8294387911494457, 0.5101042793135984, 0.50235740245227, 0.5673166774117118], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5303814], dtype=float32), -1.4541209]. 
=============================================
[2019-03-26 15:29:05,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3635313e-22 1.0000000e+00 4.9995862e-24 6.8416613e-23 5.0714278e-31], sum to 1.0000
[2019-03-26 15:29:05,498] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0246
[2019-03-26 15:29:05,503] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.93333333333333, 58.83333333333334, 1.0, 2.0, 0.4581645755589372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649578.5978494558, 649578.5978494558, 178510.5750467127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6973800.0000, 
sim time next is 6974400.0000, 
raw observation next is [29.86666666666667, 58.66666666666667, 1.0, 2.0, 0.4558483970616229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 648770.5358751133, 648770.5358751127, 178488.3026248644], 
processed observation next is [0.0, 0.7391304347826086, 0.6145339652448659, 0.5866666666666667, 1.0, 1.0, 0.34439565911038905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18021403774308703, 0.18021403774308686, 0.2664004516789021], 
reward next is 0.7336, 
noisyNet noise sample is [array([-0.8566406], dtype=float32), 2.4161818]. 
=============================================
[2019-03-26 15:29:08,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0115169e-18 1.0000000e+00 4.0559076e-20 1.5493555e-16 1.0136170e-26], sum to 1.0000
[2019-03-26 15:29:08,270] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1843
[2019-03-26 15:29:08,275] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 78.0, 1.0, 2.0, 0.5977991114801654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 854855.0022633283, 854855.0022633277, 202843.5922504146], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7021800.0000, 
sim time next is 7022400.0000, 
raw observation next is [26.5, 77.0, 1.0, 2.0, 0.5928815583752316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 847976.1421943277, 847976.1421943277, 201930.7281508207], 
processed observation next is [1.0, 0.2608695652173913, 0.4549763033175356, 0.77, 1.0, 1.0, 0.5094958534641344, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23554892838731323, 0.23554892838731323, 0.30138914649376225], 
reward next is 0.6986, 
noisyNet noise sample is [array([-1.3192418], dtype=float32), -2.5207283]. 
=============================================
[2019-03-26 15:29:09,199] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8431409e-17 1.0000000e+00 5.1847755e-20 3.7384236e-16 5.4062664e-27], sum to 1.0000
[2019-03-26 15:29:09,209] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4725
[2019-03-26 15:29:09,214] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 88.0, 1.0, 2.0, 0.4750357433376128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664685.6372309809, 664685.6372309809, 179894.1851140492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7081200.0000, 
sim time next is 7081800.0000, 
raw observation next is [25.36666666666667, 88.16666666666667, 1.0, 2.0, 0.4745974721251046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664380.7659595414, 664380.7659595414, 179868.5737645611], 
processed observation next is [1.0, 1.0, 0.40126382306477115, 0.8816666666666667, 1.0, 1.0, 0.3669849061748248, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1845502127665393, 0.1845502127665393, 0.26846055785755385], 
reward next is 0.7315, 
noisyNet noise sample is [array([1.1944884], dtype=float32), -0.3214061]. 
=============================================
[2019-03-26 15:29:14,742] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.660614e-20 1.000000e+00 1.374457e-21 7.474548e-18 2.952504e-29], sum to 1.0000
[2019-03-26 15:29:14,750] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9862
[2019-03-26 15:29:14,758] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 86.66666666666667, 1.0, 2.0, 0.4781715024161082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668160.789432546, 668160.7894325453, 180246.6167092501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7177200.0000, 
sim time next is 7177800.0000, 
raw observation next is [25.8, 86.83333333333333, 1.0, 2.0, 0.4788232892238842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669071.8339672287, 669071.833967228, 180344.6030678092], 
processed observation next is [1.0, 0.043478260869565216, 0.42180094786729866, 0.8683333333333333, 1.0, 1.0, 0.37207625207696887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18585328721311908, 0.1858532872131189, 0.2691710493549391], 
reward next is 0.7308, 
noisyNet noise sample is [array([0.25273812], dtype=float32), -1.23409]. 
=============================================
[2019-03-26 15:29:15,109] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4709669e-18 1.0000000e+00 4.6912405e-21 7.2265286e-18 6.2652987e-29], sum to 1.0000
[2019-03-26 15:29:15,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4791
[2019-03-26 15:29:15,121] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 86.0, 1.0, 2.0, 0.4736779639699703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661879.9016697747, 661879.9016697753, 179574.5086698887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7172400.0000, 
sim time next is 7173000.0000, 
raw observation next is [25.75, 86.0, 1.0, 2.0, 0.4740798169992675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662441.5942000849, 662441.5942000843, 179634.3761610241], 
processed observation next is [1.0, 0.0, 0.41943127962085314, 0.86, 1.0, 1.0, 0.3663612253003222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18401155394446803, 0.18401155394446786, 0.26811100919555836], 
reward next is 0.7319, 
noisyNet noise sample is [array([0.2035941], dtype=float32), -1.0636445]. 
=============================================
[2019-03-26 15:29:15,145] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.4114  ]
 [69.509155]
 [69.90602 ]
 [70.54939 ]
 [70.546875]], R is [[69.4371109 ]
 [69.47471619]
 [69.51197815]
 [69.54904938]
 [69.58597565]].
[2019-03-26 15:29:15,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2468166e-20 1.0000000e+00 3.3956665e-22 8.3318698e-20 5.3407260e-30], sum to 1.0000
[2019-03-26 15:29:15,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5951
[2019-03-26 15:29:15,290] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 90.16666666666667, 1.0, 2.0, 0.531586835600501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742825.443834168, 742825.443834168, 188690.8426545402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [25.8, 90.33333333333334, 1.0, 2.0, 0.5001853017388527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 698931.3315636899, 698931.3315636904, 183625.0480110853], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9033333333333334, 1.0, 1.0, 0.39781361655283454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19414759210102497, 0.1941475921010251, 0.27406723583744075], 
reward next is 0.7259, 
noisyNet noise sample is [array([0.4252858], dtype=float32), 0.19511029]. 
=============================================
[2019-03-26 15:29:17,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.7799674e-08 9.3923199e-01 2.6846752e-12 6.0768016e-02 1.0182519e-15], sum to 1.0000
[2019-03-26 15:29:17,746] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-26 15:29:17,753] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 80.66666666666667, 1.0, 2.0, 0.4339613019109337, 1.0, 2.0, 0.4339613019109337, 1.0, 1.0, 0.7536472682237396, 6.9112, 6.9112, 170.5573041426782, 1820125.910665152, 1820125.910665152, 372484.5391311415], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7206000.0000, 
sim time next is 7206600.0000, 
raw observation next is [29.0, 79.83333333333334, 1.0, 2.0, 0.6343087676397492, 1.0, 2.0, 0.6343087676397492, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1773578.677883423, 1773578.677883423, 347273.1503418957], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.7983333333333335, 1.0, 1.0, 0.5594081537828304, 1.0, 1.0, 0.5594081537828304, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4926607438565064, 0.4926607438565064, 0.5183181348386503], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.0474744], dtype=float32), -0.9108877]. 
=============================================
[2019-03-26 15:29:18,325] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8951287e-21 1.0000000e+00 4.2077820e-22 4.0126766e-21 3.6926735e-30], sum to 1.0000
[2019-03-26 15:29:18,335] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7039
[2019-03-26 15:29:18,339] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 89.0, 1.0, 2.0, 0.3204884988383386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 505796.1216798144, 505796.1216798138, 167441.9681416478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7279200.0000, 
sim time next is 7279800.0000, 
raw observation next is [21.75, 88.66666666666667, 1.0, 2.0, 0.3514389348955866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 554537.0874032846, 554537.0874032853, 171297.7065912789], 
processed observation next is [1.0, 0.2608695652173913, 0.2298578199052133, 0.8866666666666667, 1.0, 1.0, 0.2186011263802248, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15403807983424572, 0.15403807983424592, 0.2556682187929536], 
reward next is 0.7443, 
noisyNet noise sample is [array([-1.5302596], dtype=float32), 0.87758434]. 
=============================================
[2019-03-26 15:29:24,648] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9036095e-18 1.0000000e+00 7.5771691e-21 4.1539843e-16 1.9970563e-28], sum to 1.0000
[2019-03-26 15:29:24,654] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8807
[2019-03-26 15:29:24,660] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 67.0, 1.0, 2.0, 0.3800291821125275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 568403.7290773244, 568403.729077325, 171715.604130279], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7322400.0000, 
sim time next is 7323000.0000, 
raw observation next is [26.8, 67.5, 1.0, 2.0, 0.3844436291327872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 575146.5214300234, 575146.5214300241, 172319.7016298247], 
processed observation next is [1.0, 0.782608695652174, 0.4691943127962086, 0.675, 1.0, 1.0, 0.2583658182322737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15976292261945094, 0.15976292261945113, 0.25719358452212643], 
reward next is 0.7428, 
noisyNet noise sample is [array([1.5954342], dtype=float32), -0.20132083]. 
=============================================
[2019-03-26 15:29:24,697] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.52642 ]
 [71.09165 ]
 [70.51635 ]
 [69.800095]
 [68.67358 ]], R is [[71.77751923]
 [71.80345154]
 [71.82985687]
 [71.85650635]
 [71.88420868]].
[2019-03-26 15:29:27,162] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7970231e-22 1.0000000e+00 9.1708441e-24 6.7022527e-21 1.7404860e-31], sum to 1.0000
[2019-03-26 15:29:27,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2490
[2019-03-26 15:29:27,178] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 94.33333333333334, 1.0, 2.0, 0.3181200173644202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501764.1874958618, 501764.1874958611, 167131.322666799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7429200.0000, 
sim time next is 7429800.0000, 
raw observation next is [21.08333333333334, 94.16666666666667, 1.0, 2.0, 0.3175944420231824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500974.5044515085, 500974.5044515085, 167072.7920034233], 
processed observation next is [1.0, 1.0, 0.1982622432859403, 0.9416666666666668, 1.0, 1.0, 0.17782462894359322, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13915958456986346, 0.13915958456986346, 0.24936237612451237], 
reward next is 0.7506, 
noisyNet noise sample is [array([1.353484], dtype=float32), 1.1761354]. 
=============================================
[2019-03-26 15:29:33,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0652411e-24 1.0000000e+00 9.9336087e-25 3.4631384e-24 8.0077394e-33], sum to 1.0000
[2019-03-26 15:29:33,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4700
[2019-03-26 15:29:33,991] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.78333333333333, 78.5, 1.0, 2.0, 0.4177501772966061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608701.117699015, 608701.117699015, 174927.5002061765], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7495800.0000, 
sim time next is 7496400.0000, 
raw observation next is [25.66666666666667, 79.0, 1.0, 2.0, 0.4158893333616966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606903.4914427524, 606903.4914427524, 174784.5962774617], 
processed observation next is [0.0, 0.782608695652174, 0.4154818325434442, 0.79, 1.0, 1.0, 0.296252208869514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16858430317854234, 0.16858430317854234, 0.26087253175740555], 
reward next is 0.7391, 
noisyNet noise sample is [array([-1.0968502], dtype=float32), -1.0780079]. 
=============================================
[2019-03-26 15:29:37,479] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 15:29:37,480] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:29:37,481] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:29:37,482] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:29:37,482] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:29:37,484] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:29:37,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:29:37,486] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:29:37,484] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:29:37,490] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:29:37,493] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:29:37,508] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 15:29:37,528] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 15:29:37,529] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 15:29:37,570] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 15:29:37,589] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 15:29:56,514] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.04100511], dtype=float32), 0.07891179]
[2019-03-26 15:29:56,514] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.8, 58.0, 1.0, 2.0, 0.2430332391539428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400024.6025281815, 400024.6025281809, 160222.5238485281]
[2019-03-26 15:29:56,516] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:29:56,520] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.7789965e-24 1.0000000e+00 3.2220702e-24 8.8921762e-25 5.9496013e-32], sampled 0.3124174272619372
[2019-03-26 15:30:10,112] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04100511], dtype=float32), 0.07891179]
[2019-03-26 15:30:10,114] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.95321741, 99.53620371, 1.0, 2.0, 0.5806730327735368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 811443.4028003498, 811443.4028003492, 197201.05662895]
[2019-03-26 15:30:10,115] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:30:10,119] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.6705275e-21 1.0000000e+00 1.7657527e-22 5.6945356e-20 4.0934087e-30], sampled 0.7659545177541978
[2019-03-26 15:30:10,675] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04100511], dtype=float32), 0.07891179]
[2019-03-26 15:30:10,677] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.50900497, 78.277031975, 1.0, 2.0, 0.6850851467454123, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005974352305542, 6.9112, 168.9123158746137, 1854257.842945654, 1787021.910545183, 381451.2821322505]
[2019-03-26 15:30:10,679] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:30:10,684] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.7877989e-16 1.0000000e+00 6.0778307e-18 1.8052194e-13 7.3479837e-24], sampled 0.056251949224962794
[2019-03-26 15:30:10,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1854257.842945654 W.
[2019-03-26 15:31:30,428] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7917.6654 3160248551.3293 1681.0000
[2019-03-26 15:31:31,059] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.9017 2779328963.8426 930.0000
[2019-03-26 15:31:31,074] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8010.7124 3006174248.4831 1726.0000
[2019-03-26 15:31:31,075] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8262.0345 2926997840.8543 1327.0000
[2019-03-26 15:31:31,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.9719 2841797813.9387 1114.0000
[2019-03-26 15:31:32,119] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 625000, evaluation results [625000.0, 7917.6653832050215, 3160248551.3293495, 1681.0, 8262.03453005647, 2926997840.85426, 1327.0, 8660.901728732832, 2779328963.8425546, 930.0, 8010.712353047739, 3006174248.48308, 1726.0, 8499.9719458247, 2841797813.9386554, 1114.0]
[2019-03-26 15:31:32,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.8051448e-22 1.0000000e+00 8.2931669e-24 8.2833071e-23 1.1831834e-31], sum to 1.0000
[2019-03-26 15:31:32,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4427
[2019-03-26 15:31:32,520] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 91.66666666666667, 1.0, 2.0, 0.4041958767938847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595491.0337763424, 595491.0337763424, 173894.3569860906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7512600.0000, 
sim time next is 7513200.0000, 
raw observation next is [23.6, 92.0, 1.0, 2.0, 0.403860478297237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595147.3893444547, 595147.3893444554, 173866.9479302722], 
processed observation next is [0.0, 1.0, 0.3175355450236968, 0.92, 1.0, 1.0, 0.2817596124063096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16531871926234853, 0.16531871926234873, 0.25950290735861525], 
reward next is 0.7405, 
noisyNet noise sample is [array([0.52343285], dtype=float32), -0.062078387]. 
=============================================
[2019-03-26 15:31:32,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8006555e-21 1.0000000e+00 1.1277669e-22 1.8081247e-20 4.0696625e-31], sum to 1.0000
[2019-03-26 15:31:32,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7859
[2019-03-26 15:31:32,833] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 92.0, 1.0, 2.0, 0.403860478297237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595147.3893444547, 595147.3893444554, 173866.9479302722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7513200.0000, 
sim time next is 7513800.0000, 
raw observation next is [23.6, 92.16666666666667, 1.0, 2.0, 0.4042794679116462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595490.0639916938, 595490.0639916938, 173890.4112398252], 
processed observation next is [0.0, 1.0, 0.3175355450236968, 0.9216666666666667, 1.0, 1.0, 0.2822644191706581, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16541390666435937, 0.16541390666435937, 0.2595379272236197], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.5942212], dtype=float32), -1.1725905]. 
=============================================
[2019-03-26 15:31:35,731] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8412222e-19 1.0000000e+00 3.0967606e-21 6.4596287e-19 2.7403256e-28], sum to 1.0000
[2019-03-26 15:31:35,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9246
[2019-03-26 15:31:35,745] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 95.0, 1.0, 2.0, 0.4782900439083911, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696882.8024645454, 696882.8024645454, 183875.4209380105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7616400.0000, 
sim time next is 7617000.0000, 
raw observation next is [23.45, 95.0, 1.0, 2.0, 0.4720473595915531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689128.3889712683, 689128.3889712683, 183064.7829018497], 
processed observation next is [1.0, 0.13043478260869565, 0.3104265402843602, 0.95, 1.0, 1.0, 0.3639124814356061, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19142455249201898, 0.19142455249201898, 0.2732310192564921], 
reward next is 0.7268, 
noisyNet noise sample is [array([-3.274216], dtype=float32), 2.1761262]. 
=============================================
[2019-03-26 15:31:35,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[67.51009 ]
 [67.67111 ]
 [67.80481 ]
 [67.83718 ]
 [67.797844]], R is [[67.43592834]
 [67.48712158]
 [67.53718567]
 [67.58554077]
 [67.62501526]].
[2019-03-26 15:31:40,127] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2019933e-18 1.0000000e+00 3.2988477e-22 2.4619605e-17 5.8404992e-30], sum to 1.0000
[2019-03-26 15:31:40,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6684
[2019-03-26 15:31:40,138] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 83.16666666666666, 1.0, 2.0, 0.5075454124171095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709219.3772228311, 709219.3772228304, 184786.9198064809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7671000.0000, 
sim time next is 7671600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5098492989891206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712439.7963159691, 712439.7963159684, 185153.6690967838], 
processed observation next is [1.0, 0.8260869565217391, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4094569867338802, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19789994342110254, 0.19789994342110234, 0.276348759845946], 
reward next is 0.7237, 
noisyNet noise sample is [array([-1.9315224], dtype=float32), 0.32836118]. 
=============================================
[2019-03-26 15:31:43,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2237058e-07 4.8052430e-01 2.0249466e-12 5.1947552e-01 7.9652040e-16], sum to 1.0000
[2019-03-26 15:31:43,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3117
[2019-03-26 15:31:43,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2111049.970227783 W.
[2019-03-26 15:31:43,675] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.7548843672127672, 1.0, 2.0, 0.7548843672127672, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2111049.970227783, 2111049.970227783, 398503.3574081864], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7729200.0000, 
sim time next is 7729800.0000, 
raw observation next is [31.16666666666667, 64.66666666666667, 1.0, 2.0, 0.5485411957535018, 1.0, 2.0, 0.5485411957535018, 1.0, 1.0, 0.9489433396604887, 6.9112, 6.9112, 170.5573041426782, 2301200.910049282, 2301200.910049282, 449597.912313896], 
processed observation next is [1.0, 0.4782608695652174, 0.6761453396524489, 0.6466666666666667, 1.0, 1.0, 0.45607372982349614, 1.0, 1.0, 0.45607372982349614, 1.0, 0.5, 0.9377357800737667, 0.0, 0.0, 0.8375144448122397, 0.6392224750136895, 0.6392224750136895, 0.671041660169994], 
reward next is 0.3290, 
noisyNet noise sample is [array([0.5917463], dtype=float32), -0.22754593]. 
=============================================
[2019-03-26 15:31:53,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0406521e-09 9.9977869e-01 7.9863694e-14 2.2135855e-04 1.3814034e-17], sum to 1.0000
[2019-03-26 15:31:53,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7206
[2019-03-26 15:31:53,520] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1864063.590375791 W.
[2019-03-26 15:31:53,526] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.56666666666667, 77.0, 1.0, 2.0, 0.6666419776366779, 1.0, 2.0, 0.6666419776366779, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1864063.590375791, 1864063.590375791, 360168.0081970775], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7897200.0000, 
sim time next is 7897800.0000, 
raw observation next is [28.68333333333333, 76.5, 1.0, 2.0, 0.711385355232493, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.984013006689379, 6.9112, 168.9125230830599, 1891061.05579308, 1839405.13536578, 387935.1794664545], 
processed observation next is [1.0, 0.391304347826087, 0.5584518167456555, 0.765, 1.0, 1.0, 0.6522715123283048, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007281300668937884, 0.0, 0.8294378168254867, 0.5252947377203, 0.5109458709349389, 0.579007730546947], 
reward next is 0.0569, 
noisyNet noise sample is [array([0.6014446], dtype=float32), 0.5910766]. 
=============================================
[2019-03-26 15:31:53,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:53,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:54,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 15:31:55,961] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:55,962] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:55,990] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 15:31:56,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,251] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 15:31:56,397] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,397] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 15:31:56,431] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,431] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 15:31:56,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,458] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,463] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 15:31:56,671] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,673] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 15:31:56,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,869] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 15:31:56,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,893] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 15:31:56,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,911] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,913] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 15:31:56,963] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:56,964] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:56,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 15:31:57,089] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:57,089] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:57,090] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 15:31:57,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:57,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:57,342] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 15:31:57,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:57,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:57,396] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 15:31:57,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:57,450] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:57,451] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 15:31:57,497] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:31:57,498] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:31:57,499] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 15:32:04,506] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5652884e-16 1.0000000e+00 1.0227057e-18 2.9233609e-13 4.7907878e-25], sum to 1.0000
[2019-03-26 15:32:04,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0035
[2019-03-26 15:32:04,524] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 96.0, 1.0, 2.0, 0.7330645965442325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1097865.417183944, 1097865.417183944, 237780.0226941984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142800.0000, 
sim time next is 143400.0000, 
raw observation next is [22.61666666666667, 96.0, 1.0, 2.0, 0.7387576761770659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1107018.206574379, 1107018.206574378, 239246.3671416086], 
processed observation next is [1.0, 0.6521739130434783, 0.2709320695102688, 0.96, 1.0, 1.0, 0.6852502122615252, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3075050573817719, 0.3075050573817717, 0.35708413006210243], 
reward next is 0.6429, 
noisyNet noise sample is [array([-0.4734587], dtype=float32), 0.484943]. 
=============================================
[2019-03-26 15:32:05,744] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4310896e-16 1.0000000e+00 4.3854836e-19 9.4531310e-14 1.4400476e-25], sum to 1.0000
[2019-03-26 15:32:05,751] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2266
[2019-03-26 15:32:05,756] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.8230485978416185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1225662.880009404, 1225662.880009404, 260037.5145147647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 136200.0000, 
sim time next is 136800.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.7678708023734497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1143481.316695742, 1143481.316695743, 245610.7743564423], 
processed observation next is [1.0, 0.6086956521739131, 0.2796208530805688, 0.96, 1.0, 1.0, 0.7203262679198189, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31763369908215056, 0.31763369908215083, 0.36658324530812286], 
reward next is 0.6334, 
noisyNet noise sample is [array([0.42172965], dtype=float32), -0.68597]. 
=============================================
[2019-03-26 15:32:07,062] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4543599e-21 1.0000000e+00 2.3268347e-23 1.9603363e-20 1.3074040e-30], sum to 1.0000
[2019-03-26 15:32:07,072] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2336
[2019-03-26 15:32:07,080] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 96.0, 1.0, 2.0, 0.357945376625525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551781.4168478603, 551781.4168478603, 170805.9791371891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 162600.0000, 
sim time next is 163200.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.3543341171355828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547783.4350458741, 547783.4350458735, 170514.375543383], 
processed observation next is [1.0, 0.9130434782608695, 0.22274881516587688, 0.96, 1.0, 1.0, 0.22208929775371425, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1521620652905206, 0.15216206529052043, 0.2544990679751985], 
reward next is 0.7455, 
noisyNet noise sample is [array([2.1715345], dtype=float32), 0.55200624]. 
=============================================
[2019-03-26 15:32:08,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.6889741e-26 1.0000000e+00 1.4008406e-26 2.9390334e-27 2.4161914e-34], sum to 1.0000
[2019-03-26 15:32:08,889] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2197
[2019-03-26 15:32:08,896] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 94.66666666666667, 1.0, 2.0, 0.2870589814165657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 462308.2144084498, 462308.2144084498, 164430.5828139944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 195600.0000, 
sim time next is 196200.0000, 
raw observation next is [20.1, 94.5, 1.0, 2.0, 0.288313258333764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464202.8945721302, 464202.8945721308, 164560.2537644077], 
processed observation next is [0.0, 0.2608695652173913, 0.15165876777251197, 0.945, 1.0, 1.0, 0.14254609437802887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12894524849225839, 0.12894524849225855, 0.24561231905135478], 
reward next is 0.7544, 
noisyNet noise sample is [array([-0.07377581], dtype=float32), 0.56846076]. 
=============================================
[2019-03-26 15:32:12,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9883860e-24 1.0000000e+00 1.0291365e-24 9.4631449e-25 2.5821702e-32], sum to 1.0000
[2019-03-26 15:32:12,869] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5247
[2019-03-26 15:32:12,875] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 76.5, 1.0, 2.0, 0.3147652218626529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 495543.5162170169, 495543.5162170163, 166643.9633841207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 304200.0000, 
sim time next is 304800.0000, 
raw observation next is [23.53333333333333, 76.33333333333333, 1.0, 2.0, 0.3164592760256142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498106.7996662029, 498106.7996662023, 166832.9639899812], 
processed observation next is [0.0, 0.5217391304347826, 0.3143759873617693, 0.7633333333333333, 1.0, 1.0, 0.17645695906700504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1383629999072786, 0.1383629999072784, 0.24900442386564356], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.24667645], dtype=float32), 0.24689522]. 
=============================================
[2019-03-26 15:32:18,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.3468241e-22 1.0000000e+00 6.3661888e-24 1.4968771e-23 4.9347265e-32], sum to 1.0000
[2019-03-26 15:32:18,876] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0258
[2019-03-26 15:32:18,882] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 87.0, 1.0, 2.0, 0.2569084511794936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418598.7393006994, 418598.7393006994, 161538.0374686603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367200.0000, 
sim time next is 367800.0000, 
raw observation next is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
processed observation next is [1.0, 0.2608695652173913, 0.1642969984202214, 0.865, 1.0, 1.0, 0.10959443173423335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11811343042746605, 0.11811343042746623, 0.24171376142103967], 
reward next is 0.7583, 
noisyNet noise sample is [array([0.44333845], dtype=float32), -0.028344622]. 
=============================================
[2019-03-26 15:32:21,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.76798899e-20 1.00000000e+00 1.03481814e-22 9.58406758e-21
 3.08269854e-29], sum to 1.0000
[2019-03-26 15:32:21,366] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9121
[2019-03-26 15:32:21,373] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 73.0, 1.0, 2.0, 0.3120328401531444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504413.3474573876, 504413.3474573876, 167408.9133559373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.3208786493000252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518560.6218782662, 518560.6218782662, 168467.3340876571], 
processed observation next is [1.0, 0.5652173913043478, 0.27488151658767773, 0.73, 1.0, 1.0, 0.18178150518075323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14404461718840728, 0.14404461718840728, 0.2514437822203837], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.5797108], dtype=float32), -1.6864061]. 
=============================================
[2019-03-26 15:32:24,108] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.4564904e-21 1.0000000e+00 4.9708350e-23 1.6694057e-20 1.0231444e-30], sum to 1.0000
[2019-03-26 15:32:24,120] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3346
[2019-03-26 15:32:24,130] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 85.5, 1.0, 2.0, 0.2416396750564468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398145.4098398074, 398145.4098398067, 160078.15637442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 433800.0000, 
sim time next is 434400.0000, 
raw observation next is [19.63333333333333, 85.33333333333334, 1.0, 2.0, 0.2408108809142203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 396950.562634402, 396950.5626344027, 159993.4607243839], 
processed observation next is [1.0, 0.0, 0.1295418641390204, 0.8533333333333334, 1.0, 1.0, 0.08531431435448227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11026404517622278, 0.11026404517622297, 0.2387962100363939], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.9848525], dtype=float32), 0.28645253]. 
=============================================
[2019-03-26 15:32:27,496] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9541333e-20 1.0000000e+00 3.6648463e-22 8.9256438e-19 3.5232126e-29], sum to 1.0000
[2019-03-26 15:32:27,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8623
[2019-03-26 15:32:27,511] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 55.0, 1.0, 2.0, 0.5787618109575396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 945408.8146812594, 945408.8146812594, 211038.9238447963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 480600.0000, 
sim time next is 481200.0000, 
raw observation next is [25.1, 54.33333333333333, 1.0, 2.0, 0.5884396747616139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 960885.5958692874, 960885.5958692874, 213052.9043557368], 
processed observation next is [1.0, 0.5652173913043478, 0.38862559241706174, 0.5433333333333333, 1.0, 1.0, 0.5041441864597757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2669126655192465, 0.2669126655192465, 0.3179894094861743], 
reward next is 0.6820, 
noisyNet noise sample is [array([-1.221403], dtype=float32), -0.32843837]. 
=============================================
[2019-03-26 15:32:28,195] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 15:32:28,196] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:32:28,197] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:32:28,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:32:28,198] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:32:28,199] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:32:28,199] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:32:28,201] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:32:28,204] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:32:28,197] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:32:28,207] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:32:28,223] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 15:32:28,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 15:32:28,244] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 15:32:28,301] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 15:32:28,303] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 15:33:01,332] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:33:01,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.6, 94.0, 1.0, 2.0, 0.3744191437823797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 566247.9169628611, 566247.9169628617, 171729.8121131507]
[2019-03-26 15:33:01,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:33:01,339] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7816805e-24 1.0000000e+00 4.1271613e-25 6.3563577e-25 7.2604879e-33], sampled 0.07928460353909839
[2019-03-26 15:33:08,035] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:33:08,036] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.593473885, 90.205951495, 1.0, 2.0, 0.4751396311260594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 671198.6850687942, 671198.6850687936, 180728.2582618146]
[2019-03-26 15:33:08,036] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:33:08,038] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.8783352e-23 1.0000000e+00 4.0422605e-24 2.2508978e-22 8.3693764e-32], sampled 0.7447724359830544
[2019-03-26 15:33:14,252] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:33:14,252] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 100.0, 1.0, 2.0, 0.8334669727279125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1209470.981654011, 1209470.981654011, 258589.5951404254]
[2019-03-26 15:33:14,254] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:33:14,256] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5805331e-19 1.0000000e+00 3.1082051e-21 1.0049742e-17 3.4669647e-28], sampled 0.5680316106980968
[2019-03-26 15:33:51,415] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:33:51,415] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.26666666666667, 93.0, 1.0, 2.0, 0.6134448896797856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857257.8924053382, 857257.8924053382, 203276.9224038848]
[2019-03-26 15:33:51,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:33:51,420] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4643114e-23 1.0000000e+00 1.4424124e-24 2.5874575e-23 3.9040175e-32], sampled 0.13176816764540078
[2019-03-26 15:34:00,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:34:00,092] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.44675029333333, 72.44125244666668, 1.0, 2.0, 0.533563580334853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 745588.664295931, 745588.6642959303, 189021.7143034851]
[2019-03-26 15:34:00,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:34:00,096] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2381390e-23 1.0000000e+00 1.0820616e-24 2.8454326e-23 2.4935577e-32], sampled 0.5337304070408108
[2019-03-26 15:34:07,351] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.03748361], dtype=float32), 0.085163295]
[2019-03-26 15:34:07,351] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.549329085, 57.26336711, 1.0, 2.0, 0.3426425602105331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539184.1155956398, 539184.1155956405, 170023.651321596]
[2019-03-26 15:34:07,352] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:34:07,353] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5215035e-23 1.0000000e+00 1.5833464e-24 6.8403044e-23 3.5119757e-32], sampled 0.8442182092856957
[2019-03-26 15:34:23,266] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.0837 2927444493.3066 1337.0000
[2019-03-26 15:34:23,408] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9664 2842251749.2311 1125.0000
[2019-03-26 15:34:23,581] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7897.3588 3162791178.8309 1748.0000
[2019-03-26 15:34:23,671] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.4070 3007234149.4795 1751.0000
[2019-03-26 15:34:23,692] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.0735 2779388539.9568 933.0000
[2019-03-26 15:34:24,709] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 650000, evaluation results [650000.0, 7897.358830101807, 3162791178.83095, 1748.0, 8257.083669951351, 2927444493.3065815, 1337.0, 8661.07353302349, 2779388539.9567747, 933.0, 8003.407044384182, 3007234149.479523, 1751.0, 8496.966403502282, 2842251749.2310796, 1125.0]
[2019-03-26 15:34:28,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9030638e-21 1.0000000e+00 8.0534557e-23 3.1145313e-21 1.4028752e-30], sum to 1.0000
[2019-03-26 15:34:28,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4075
[2019-03-26 15:34:28,079] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 75.0, 1.0, 2.0, 0.3653496452052277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600724.2853475936, 600724.2853475936, 174600.5831611978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 550200.0000, 
sim time next is 550800.0000, 
raw observation next is [21.2, 75.0, 1.0, 2.0, 0.4174778319579757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686437.3715234355, 686437.3715234349, 182086.0896672615], 
processed observation next is [1.0, 0.391304347826087, 0.20379146919431282, 0.75, 1.0, 1.0, 0.29816606259997075, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19067704764539875, 0.19067704764539858, 0.2717702830854649], 
reward next is 0.7282, 
noisyNet noise sample is [array([-1.0566282], dtype=float32), -0.67654115]. 
=============================================
[2019-03-26 15:34:39,946] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5908388e-20 1.0000000e+00 1.6044827e-22 3.6112420e-19 1.1264214e-29], sum to 1.0000
[2019-03-26 15:34:39,955] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9301
[2019-03-26 15:34:39,963] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.01666666666667, 50.0, 1.0, 2.0, 0.6101124164259905, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1006275.576645778, 1006275.576645778, 217768.6788588425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 749400.0000, 
sim time next is 750000.0000, 
raw observation next is [24.93333333333334, 50.0, 1.0, 2.0, 0.5761181493514851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950958.3910729398, 950958.3910729398, 210527.7958741349], 
processed observation next is [1.0, 0.6956521739130435, 0.3807266982622437, 0.5, 1.0, 1.0, 0.48929897512227116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2641551086313722, 0.2641551086313722, 0.3142205908569178], 
reward next is 0.6858, 
noisyNet noise sample is [array([0.756965], dtype=float32), -0.39643687]. 
=============================================
[2019-03-26 15:34:39,977] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.30618]
 [71.31395]
 [71.41784]
 [71.62867]
 [71.85026]], R is [[71.40943909]
 [71.37031555]
 [71.32674408]
 [71.28311157]
 [71.24494171]].
[2019-03-26 15:34:42,569] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3275406e-24 1.0000000e+00 3.9482279e-25 4.2721985e-24 1.8018617e-32], sum to 1.0000
[2019-03-26 15:34:42,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3023
[2019-03-26 15:34:42,589] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 66.33333333333333, 1.0, 2.0, 0.2938091098116378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469094.101236043, 469094.101236043, 164868.587597189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 831000.0000, 
sim time next is 831600.0000, 
raw observation next is [24.4, 67.0, 1.0, 2.0, 0.2960799492551895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 472020.0737030072, 472020.0737030066, 165063.6170354878], 
processed observation next is [0.0, 0.6521739130434783, 0.3554502369668246, 0.67, 1.0, 1.0, 0.1519035533195054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13111668713972421, 0.13111668713972405, 0.24636360751565345], 
reward next is 0.7536, 
noisyNet noise sample is [array([-0.35452133], dtype=float32), -1.3482366]. 
=============================================
[2019-03-26 15:34:44,199] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8351662e-24 1.0000000e+00 1.6700129e-25 1.0374529e-25 8.7550812e-33], sum to 1.0000
[2019-03-26 15:34:44,209] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7796
[2019-03-26 15:34:44,214] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 67.0, 1.0, 2.0, 0.2913297578531947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466062.1251034755, 466062.1251034748, 164669.3506602364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 813600.0000, 
sim time next is 814200.0000, 
raw observation next is [24.36666666666667, 66.0, 1.0, 2.0, 0.2917691551458272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466682.7730041854, 466682.7730041848, 164711.4541141483], 
processed observation next is [0.0, 0.43478260869565216, 0.3538704581358612, 0.66, 1.0, 1.0, 0.14670982547690023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12963410361227373, 0.12963410361227357, 0.2458379912151467], 
reward next is 0.7542, 
noisyNet noise sample is [array([-1.7640375], dtype=float32), 0.7698221]. 
=============================================
[2019-03-26 15:34:47,806] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2178628e-23 1.0000000e+00 1.6037346e-24 5.4621620e-24 3.8868690e-32], sum to 1.0000
[2019-03-26 15:34:47,817] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-26 15:34:47,821] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 74.0, 1.0, 2.0, 0.3174580353314876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498329.8766802831, 498329.8766802831, 166815.7604252182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 925200.0000, 
sim time next is 925800.0000, 
raw observation next is [23.93333333333333, 74.66666666666667, 1.0, 2.0, 0.3173503564230457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497794.5797429986, 497794.5797429986, 166765.8123437208], 
processed observation next is [0.0, 0.7391304347826086, 0.3333333333333332, 0.7466666666666667, 1.0, 1.0, 0.17753054990728398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13827627215083294, 0.13827627215083294, 0.24890419752794152], 
reward next is 0.7511, 
noisyNet noise sample is [array([-1.1259226], dtype=float32), 0.12288703]. 
=============================================
[2019-03-26 15:34:51,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4993639e-22 1.0000000e+00 1.1472053e-23 2.9802948e-22 3.1702062e-31], sum to 1.0000
[2019-03-26 15:34:51,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5818
[2019-03-26 15:34:51,157] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.55, 88.0, 1.0, 2.0, 0.3387289176552802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524766.1754814181, 524766.1754814174, 168672.0485317231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937800.0000, 
sim time next is 938400.0000, 
raw observation next is [22.5, 88.33333333333333, 1.0, 2.0, 0.3383860009893634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524331.8892428037, 524331.8892428043, 168640.3182976949], 
processed observation next is [0.0, 0.8695652173913043, 0.2654028436018958, 0.8833333333333333, 1.0, 1.0, 0.2028746999871848, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1456477470118899, 0.14564774701189007, 0.25170196760849983], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.42016244], dtype=float32), 0.86025876]. 
=============================================
[2019-03-26 15:34:51,531] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6244817e-20 1.0000000e+00 9.5959151e-22 6.5387402e-19 2.2683273e-29], sum to 1.0000
[2019-03-26 15:34:51,537] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2967
[2019-03-26 15:34:51,540] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.33333333333334, 1.0, 2.0, 0.340482990389693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526970.7987906242, 526970.7987906237, 168833.0523317622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 951600.0000, 
sim time next is 952200.0000, 
raw observation next is [21.8, 94.5, 1.0, 2.0, 0.3401548452683181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526165.6061189561, 526165.6061189554, 168759.6553157746], 
processed observation next is [1.0, 0.0, 0.23222748815165886, 0.945, 1.0, 1.0, 0.2050058376726724, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14615711281082114, 0.14615711281082094, 0.25188008256085764], 
reward next is 0.7481, 
noisyNet noise sample is [array([-0.6974638], dtype=float32), 0.8104354]. 
=============================================
[2019-03-26 15:34:54,360] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3858727e-19 1.0000000e+00 9.2747808e-22 8.1578899e-19 4.4688704e-29], sum to 1.0000
[2019-03-26 15:34:54,369] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-26 15:34:54,375] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.98333333333333, 94.16666666666667, 1.0, 2.0, 0.5779668196676535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 889981.6723193923, 889981.6723193923, 206641.2591889056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 990600.0000, 
sim time next is 991200.0000, 
raw observation next is [21.96666666666667, 94.33333333333334, 1.0, 2.0, 0.5010190771566627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771455.5556118315, 771455.5556118315, 192302.9672577543], 
processed observation next is [1.0, 0.4782608695652174, 0.24012638230647723, 0.9433333333333335, 1.0, 1.0, 0.3988181652489912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2142932098921754, 0.2142932098921754, 0.2870193541160512], 
reward next is 0.7130, 
noisyNet noise sample is [array([-3.555521], dtype=float32), 0.7468881]. 
=============================================
[2019-03-26 15:34:54,739] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0159360e-20 1.0000000e+00 7.2046588e-22 7.6658214e-19 1.7648507e-29], sum to 1.0000
[2019-03-26 15:34:54,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1648
[2019-03-26 15:34:54,757] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 95.0, 1.0, 2.0, 0.4102773023912795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634948.3089447392, 634948.3089447386, 178232.2694986775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 997200.0000, 
sim time next is 997800.0000, 
raw observation next is [21.68333333333333, 95.16666666666667, 1.0, 2.0, 0.3863456947753357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598072.0404958345, 598072.0404958345, 174882.9244018733], 
processed observation next is [1.0, 0.5652173913043478, 0.22669826224328585, 0.9516666666666667, 1.0, 1.0, 0.2606574635847418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16613112235995403, 0.16613112235995403, 0.26101929015204967], 
reward next is 0.7390, 
noisyNet noise sample is [array([1.41512], dtype=float32), -1.077891]. 
=============================================
[2019-03-26 15:34:57,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.4790265e-23 1.0000000e+00 1.6626847e-24 1.9941088e-22 2.0629623e-32], sum to 1.0000
[2019-03-26 15:34:57,848] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5409
[2019-03-26 15:34:57,854] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.43333333333333, 96.66666666666667, 1.0, 2.0, 0.3371600872445006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522255.1675875294, 522255.1675875288, 168469.7412859084], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1048800.0000, 
sim time next is 1049400.0000, 
raw observation next is [21.3, 96.5, 1.0, 2.0, 0.3325613554506282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517316.5723982737, 517316.5723982743, 168145.1584687701], 
processed observation next is [1.0, 0.13043478260869565, 0.2085308056872039, 0.965, 1.0, 1.0, 0.195857054759793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14369904788840934, 0.14369904788840954, 0.25096292308771656], 
reward next is 0.7490, 
noisyNet noise sample is [array([2.0823612], dtype=float32), -0.020028332]. 
=============================================
[2019-03-26 15:34:58,952] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6815375e-19 1.0000000e+00 9.9891793e-22 5.2567519e-19 1.6143616e-29], sum to 1.0000
[2019-03-26 15:34:58,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9816
[2019-03-26 15:34:58,967] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.81666666666667, 79.5, 1.0, 2.0, 0.3149041220441833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498399.0415846922, 498399.0415846922, 166914.0830814503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1111800.0000, 
sim time next is 1112400.0000, 
raw observation next is [22.7, 80.0, 1.0, 2.0, 0.3128860056454387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495717.4590429692, 495717.4590429692, 166724.3808079092], 
processed observation next is [1.0, 0.9130434782608695, 0.27488151658767773, 0.8, 1.0, 1.0, 0.17215181403064905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13769929417860255, 0.13769929417860255, 0.24884235941478988], 
reward next is 0.7512, 
noisyNet noise sample is [array([0.06347331], dtype=float32), -0.13379255]. 
=============================================
[2019-03-26 15:35:02,534] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2419506e-21 1.0000000e+00 4.4621043e-23 4.1454096e-21 1.8251073e-30], sum to 1.0000
[2019-03-26 15:35:02,542] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-26 15:35:02,549] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 82.16666666666667, 1.0, 2.0, 0.4185849907539139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663846.6084781395, 663846.6084781402, 180970.7405445914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1152600.0000, 
sim time next is 1153200.0000, 
raw observation next is [22.6, 81.33333333333334, 1.0, 2.0, 0.5714072732335134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 904402.9080629873, 904402.9080629867, 207712.5735169155], 
processed observation next is [1.0, 0.34782608695652173, 0.27014218009478685, 0.8133333333333335, 1.0, 1.0, 0.4836232207632691, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25122303001749646, 0.2512230300174963, 0.31001876644315746], 
reward next is 0.6900, 
noisyNet noise sample is [array([-0.6097727], dtype=float32), -0.7803107]. 
=============================================
[2019-03-26 15:35:05,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3279514e-16 1.0000000e+00 6.9583790e-20 3.6471284e-14 7.9600996e-27], sum to 1.0000
[2019-03-26 15:35:05,518] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3499
[2019-03-26 15:35:05,526] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 57.83333333333333, 1.0, 2.0, 0.4381659364294249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676160.7084975761, 676160.7084975761, 182190.6228728698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1185000.0000, 
sim time next is 1185600.0000, 
raw observation next is [27.3, 58.66666666666667, 1.0, 2.0, 0.3293212876343562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508207.406258325, 508207.4062583257, 167303.9016481442], 
processed observation next is [1.0, 0.7391304347826086, 0.4928909952606636, 0.5866666666666667, 1.0, 1.0, 0.19195335859560986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14116872396064584, 0.14116872396064603, 0.24970731589275255], 
reward next is 0.7503, 
noisyNet noise sample is [array([-0.16691369], dtype=float32), 0.62208927]. 
=============================================
[2019-03-26 15:35:06,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7846166e-20 1.0000000e+00 3.4478778e-22 2.2646309e-18 8.0172305e-29], sum to 1.0000
[2019-03-26 15:35:06,523] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-26 15:35:06,529] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.85, 87.16666666666667, 1.0, 2.0, 0.3557153872458308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 548072.2460944823, 548072.2460944816, 170488.2475067229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1206600.0000, 
sim time next is 1207200.0000, 
raw observation next is [22.8, 87.33333333333334, 1.0, 2.0, 0.3542790115204759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546283.1030205621, 546283.1030205615, 170351.1846066992], 
processed observation next is [1.0, 1.0, 0.2796208530805688, 0.8733333333333334, 1.0, 1.0, 0.22202290544635653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15174530639460057, 0.15174530639460043, 0.25425549941298387], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.65767235], dtype=float32), 0.38098145]. 
=============================================
[2019-03-26 15:35:09,799] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4856745e-08 3.1072539e-01 6.3191219e-12 6.8927449e-01 1.3258622e-15], sum to 1.0000
[2019-03-26 15:35:09,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5772
[2019-03-26 15:35:09,813] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 71.0, 1.0, 2.0, 0.4310440912846932, 1.0, 2.0, 0.4310440912846932, 1.0, 2.0, 0.7259139960238957, 6.9112, 6.9112, 170.5573041426782, 1807880.187398114, 1807880.187398114, 367196.449419296], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1249200.0000, 
sim time next is 1249800.0000, 
raw observation next is [28.11666666666667, 71.16666666666667, 1.0, 2.0, 0.5838105020891788, 1.0, 2.0, 0.5838105020891788, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1632273.902806917, 1632273.902806917, 328337.8770226866], 
processed observation next is [1.0, 0.4782608695652174, 0.5315955766192735, 0.7116666666666667, 1.0, 1.0, 0.4985668699869624, 1.0, 1.0, 0.4985668699869624, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4534094174463658, 0.4534094174463658, 0.4900565328696815], 
reward next is 0.5099, 
noisyNet noise sample is [array([-0.547041], dtype=float32), 1.9769199]. 
=============================================
[2019-03-26 15:35:20,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9720480e-24 1.0000000e+00 9.1061389e-25 4.3258592e-23 8.1173874e-32], sum to 1.0000
[2019-03-26 15:35:20,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7910
[2019-03-26 15:35:20,619] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 82.66666666666666, 1.0, 2.0, 0.4058292445935688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599728.062371842, 599728.062371842, 174341.8726408554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1450200.0000, 
sim time next is 1450800.0000, 
raw observation next is [24.5, 84.0, 1.0, 2.0, 0.4026097145536569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596571.4829347419, 596571.4829347419, 174099.046317623], 
processed observation next is [0.0, 0.8260869565217391, 0.3601895734597157, 0.84, 1.0, 1.0, 0.28025266813693606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16571430081520608, 0.16571430081520608, 0.25984932286212387], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.05252314], dtype=float32), -0.25832608]. 
=============================================
[2019-03-26 15:35:20,764] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 15:35:20,765] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:35:20,765] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:35:20,766] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:35:20,767] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:35:20,767] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:35:20,768] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:35:20,767] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:35:20,769] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:35:20,771] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:35:20,774] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:35:20,791] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 15:35:20,811] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 15:35:20,835] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 15:35:20,836] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 15:35:20,855] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 15:36:09,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:09,328] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.597699948860203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835246.4905922757, 835246.4905922757, 200318.4407519266]
[2019-03-26 15:36:09,330] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:36:09,335] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3167567e-22 1.0000000e+00 4.4039974e-24 2.4744498e-21 1.3658729e-31], sampled 0.01583838105844637
[2019-03-26 15:36:14,754] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:14,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.6271433952662702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 876408.7521644707, 876408.7521644714, 205901.485104607]
[2019-03-26 15:36:14,758] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:36:14,763] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6549503e-21 1.0000000e+00 7.7438095e-23 1.6805746e-20 6.9501192e-30], sampled 0.9433580363798053
[2019-03-26 15:36:25,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:25,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 84.0, 1.0, 2.0, 0.5809484113354244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811828.3690380023, 811828.3690380023, 197250.3394906312]
[2019-03-26 15:36:25,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:36:25,778] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.3013892e-23 1.0000000e+00 1.6234996e-24 5.6247922e-23 6.2708603e-32], sampled 0.035699024543632274
[2019-03-26 15:36:30,155] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:30,155] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.21199799166667, 98.89720789333334, 1.0, 2.0, 0.6275748101330508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 877011.8867467364, 877011.8867467357, 205990.7620490967]
[2019-03-26 15:36:30,157] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:36:30,161] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5989778e-22 1.0000000e+00 1.7707569e-23 2.0898969e-21 1.1750561e-30], sampled 0.6257740107440438
[2019-03-26 15:36:34,106] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:34,109] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.21121243666667, 72.36129881333333, 1.0, 2.0, 0.8192929570449398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1145075.137049399, 1145075.1370494, 248698.392115532]
[2019-03-26 15:36:34,109] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:36:34,112] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3745794e-19 1.0000000e+00 1.4821905e-21 2.2930231e-17 3.7766432e-28], sampled 0.506941292254087
[2019-03-26 15:36:36,255] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:36,258] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.53333333333333, 88.66666666666667, 1.0, 2.0, 0.6412914960123723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 896188.5199171418, 896188.5199171411, 208690.3278230931]
[2019-03-26 15:36:36,261] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:36:36,267] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4691142e-21 1.0000000e+00 1.7749973e-23 3.3406413e-20 6.4273896e-31], sampled 0.3639567416475744
[2019-03-26 15:36:42,617] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02876387], dtype=float32), 0.08483579]
[2019-03-26 15:36:42,618] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.39485614833333, 78.07445515, 1.0, 2.0, 0.8914121390029092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1245930.800604081, 1245930.80060408, 267590.8676019692]
[2019-03-26 15:36:42,618] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:36:42,624] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.8773393e-20 1.0000000e+00 9.2045351e-22 1.4562718e-18 1.3442939e-28], sampled 0.6745354309681886
[2019-03-26 15:37:15,766] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.8944 2927246357.3187 1332.0000
[2019-03-26 15:37:15,853] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8006.0348 3006827276.5911 1739.0000
[2019-03-26 15:37:15,862] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7908.4446 3161230172.6770 1706.0000
[2019-03-26 15:37:16,093] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.3750 2842155997.5095 1121.0000
[2019-03-26 15:37:16,179] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.7146 2779125634.1895 930.0000
[2019-03-26 15:37:17,195] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 675000, evaluation results [675000.0, 7908.4445788409985, 3161230172.677002, 1706.0, 8256.894418354625, 2927246357.3186846, 1332.0, 8661.714629811, 2779125634.1894827, 930.0, 8006.03478557658, 3006827276.591084, 1739.0, 8499.375033848206, 2842155997.5094786, 1121.0]
[2019-03-26 15:37:17,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7591832e-23 1.0000000e+00 9.6987608e-25 9.6128368e-23 3.2129499e-32], sum to 1.0000
[2019-03-26 15:37:17,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8211
[2019-03-26 15:37:17,239] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 69.0, 1.0, 2.0, 0.4307955358048171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 620818.23157765, 620818.2315776505, 175895.6247755926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1443600.0000, 
sim time next is 1444200.0000, 
raw observation next is [27.35, 70.16666666666667, 1.0, 2.0, 0.4278669607953643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 618079.2525293842, 618079.2525293849, 175671.8115075868], 
processed observation next is [0.0, 0.7391304347826086, 0.4952606635071091, 0.7016666666666667, 1.0, 1.0, 0.31068308529561967, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17168868125816228, 0.17168868125816247, 0.2621967335934131], 
reward next is 0.7378, 
noisyNet noise sample is [array([-0.21013945], dtype=float32), 0.74131066]. 
=============================================
[2019-03-26 15:37:36,773] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2946127e-17 1.0000000e+00 1.6601600e-19 4.9518468e-14 1.3277725e-26], sum to 1.0000
[2019-03-26 15:37:36,786] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5151
[2019-03-26 15:37:36,795] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.93333333333333, 86.66666666666667, 1.0, 2.0, 0.6317802615002365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 997703.614510872, 997703.614510872, 220280.7405242832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [21.7, 88.0, 1.0, 2.0, 0.6384595995319078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1009697.859320773, 1009697.859320773, 221894.1809250204], 
processed observation next is [1.0, 0.6086956521739131, 0.2274881516587678, 0.88, 1.0, 1.0, 0.5644091560625395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2804716275891036, 0.2804716275891036, 0.33118534466420957], 
reward next is 0.6688, 
noisyNet noise sample is [array([-2.0857275], dtype=float32), 0.9581709]. 
=============================================
[2019-03-26 15:37:37,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8537787e-17 1.0000000e+00 1.4414417e-20 2.3573816e-15 1.8951528e-26], sum to 1.0000
[2019-03-26 15:37:38,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1968
[2019-03-26 15:37:38,016] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.46666666666667, 89.33333333333333, 1.0, 2.0, 0.614719867487512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 973577.7416708786, 973577.741670878, 216801.584699802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1780800.0000, 
sim time next is 1781400.0000, 
raw observation next is [21.23333333333333, 90.66666666666667, 1.0, 2.0, 0.6036693233599966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 957533.1192305534, 957533.1192305528, 214559.1078550541], 
processed observation next is [1.0, 0.6086956521739131, 0.2053712480252764, 0.9066666666666667, 1.0, 1.0, 0.5224931606746946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26598142200848707, 0.2659814220084869, 0.3202374744105285], 
reward next is 0.6798, 
noisyNet noise sample is [array([-1.0087069], dtype=float32), 1.9261638]. 
=============================================
[2019-03-26 15:37:54,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7094752e-22 1.0000000e+00 5.6478629e-23 1.8550313e-21 3.5881662e-30], sum to 1.0000
[2019-03-26 15:37:54,854] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3043
[2019-03-26 15:37:54,859] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 97.16666666666667, 1.0, 2.0, 0.4599709408056562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650217.9598427864, 650217.9598427871, 178529.635563173], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2088600.0000, 
sim time next is 2089200.0000, 
raw observation next is [23.93333333333333, 97.33333333333334, 1.0, 2.0, 0.4583683932920895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 648304.8621784303, 648304.8621784303, 178340.272852537], 
processed observation next is [0.0, 0.17391304347826086, 0.3333333333333332, 0.9733333333333334, 1.0, 1.0, 0.3474317991470958, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18008468393845287, 0.18008468393845287, 0.2661795117202045], 
reward next is 0.7338, 
noisyNet noise sample is [array([1.3625612], dtype=float32), 1.7476811]. 
=============================================
[2019-03-26 15:37:58,065] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.9726202e-22 1.0000000e+00 1.9774878e-23 8.4509717e-22 8.1870472e-32], sum to 1.0000
[2019-03-26 15:37:58,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8661
[2019-03-26 15:37:58,074] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 77.0, 1.0, 2.0, 0.5688649918539387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794936.4499355687, 794936.4499355693, 195089.4460440906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2124000.0000, 
sim time next is 2124600.0000, 
raw observation next is [30.05, 76.83333333333334, 1.0, 2.0, 0.5691461926551131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795329.5492814106, 795329.5492814106, 195139.2908913219], 
processed observation next is [0.0, 0.6086956521739131, 0.6232227488151659, 0.7683333333333334, 1.0, 1.0, 0.48089902729531697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22092487480039186, 0.22092487480039186, 0.29125267297212226], 
reward next is 0.7087, 
noisyNet noise sample is [array([1.0373286], dtype=float32), 0.55931515]. 
=============================================
[2019-03-26 15:37:58,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4520714e-22 1.0000000e+00 1.4182749e-23 9.7997093e-22 3.8290492e-31], sum to 1.0000
[2019-03-26 15:37:58,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0133
[2019-03-26 15:37:58,406] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 75.66666666666667, 1.0, 2.0, 0.5775610225557228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807092.9690326591, 807092.9690326591, 196640.2359953894], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2128200.0000, 
sim time next is 2128800.0000, 
raw observation next is [30.36666666666667, 75.33333333333334, 1.0, 2.0, 0.5736805237774774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801668.2518703135, 801668.251870313, 195945.5078429384], 
processed observation next is [0.0, 0.6521739130434783, 0.6382306477093209, 0.7533333333333334, 1.0, 1.0, 0.48636207684033417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22268562551953153, 0.2226856255195314, 0.29245598185513194], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.15361543], dtype=float32), -1.5053973]. 
=============================================
[2019-03-26 15:38:02,693] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1009730e-09 3.2997586e-02 4.2661589e-15 9.6700245e-01 7.0464228e-19], sum to 1.0000
[2019-03-26 15:38:02,702] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4334
[2019-03-26 15:38:02,707] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.9, 65.66666666666666, 1.0, 2.0, 0.8737629845051712, 1.0, 2.0, 0.8737629845051712, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2443838.115003369, 2443838.115003369, 457380.8565835727], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [32.0, 65.33333333333334, 1.0, 2.0, 0.8706993164617335, 1.0, 2.0, 0.8706993164617335, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2435260.955561548, 2435260.955561548, 455759.6638480654], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.6533333333333334, 1.0, 1.0, 0.8442160439297993, 1.0, 1.0, 0.8442160439297993, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6764613765448745, 0.6764613765448745, 0.6802383042508439], 
reward next is 0.3198, 
noisyNet noise sample is [array([-0.9509007], dtype=float32), 1.4990327]. 
=============================================
[2019-03-26 15:38:06,483] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6521476e-17 1.0000000e+00 2.4592736e-19 1.5901488e-14 1.2566686e-26], sum to 1.0000
[2019-03-26 15:38:06,492] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1248
[2019-03-26 15:38:06,498] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 79.66666666666667, 1.0, 2.0, 0.6622450349849871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 925483.3148388439, 925483.3148388439, 212904.4483568755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2270400.0000, 
sim time next is 2271000.0000, 
raw observation next is [27.45, 78.83333333333333, 1.0, 2.0, 0.6725429737793114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 939880.9882351824, 939880.988235183, 215027.8458054866], 
processed observation next is [1.0, 0.2608695652173913, 0.5, 0.7883333333333333, 1.0, 1.0, 0.6054734623847124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26107805228755065, 0.2610780522875508, 0.32093708329177106], 
reward next is 0.6791, 
noisyNet noise sample is [array([-0.3724922], dtype=float32), 0.16771598]. 
=============================================
[2019-03-26 15:38:06,513] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[62.693142]
 [62.748062]
 [62.719273]
 [62.583786]
 [62.64221 ]], R is [[62.6821022 ]
 [62.7375145 ]
 [62.80060196]
 [62.86576843]
 [62.91765213]].
[2019-03-26 15:38:12,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3317359e-16 1.0000000e+00 8.5647371e-19 3.1452010e-15 1.9884315e-25], sum to 1.0000
[2019-03-26 15:38:12,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1389
[2019-03-26 15:38:12,483] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.56666666666667, 75.66666666666666, 1.0, 2.0, 0.7034871674576918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 983145.6160424062, 983145.6160424056, 221598.6202840613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2357400.0000, 
sim time next is 2358000.0000, 
raw observation next is [28.7, 75.0, 1.0, 2.0, 0.7020375815863508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981118.8380463118, 981118.8380463118, 221284.6010492296], 
processed observation next is [1.0, 0.30434782608695654, 0.5592417061611374, 0.75, 1.0, 1.0, 0.6410091344413864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27253301056841994, 0.27253301056841994, 0.330275523954074], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.12444414], dtype=float32), 1.1239252]. 
=============================================
[2019-03-26 15:38:12,498] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.309235]
 [62.28661 ]
 [62.26049 ]
 [62.319046]
 [62.327774]], R is [[62.44237518]
 [62.48720551]
 [62.5310173 ]
 [62.57066345]
 [62.61172867]].
[2019-03-26 15:38:13,452] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 15:38:13,455] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:38:13,456] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:38:13,456] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:38:13,457] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:38:13,458] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:38:13,458] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:38:13,459] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:38:13,457] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:38:13,459] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:38:13,460] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:38:13,481] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 15:38:13,482] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 15:38:13,503] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 15:38:13,522] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 15:38:13,568] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 15:38:33,914] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:38:33,916] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.05976678666667, 92.54144133333332, 1.0, 2.0, 0.3935177804040665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589472.2377250728, 589472.2377250728, 173637.4440377755]
[2019-03-26 15:38:33,919] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:38:33,923] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4622372e-21 1.0000000e+00 2.7437961e-22 1.4558752e-21 9.0047652e-30], sampled 0.06047614409851032
[2019-03-26 15:38:36,980] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:38:36,983] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.15, 56.5, 1.0, 2.0, 0.3618000962645297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 552033.1282474456, 552033.128247445, 170661.9828688587]
[2019-03-26 15:38:36,985] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:36,990] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.60423896e-22 1.00000000e+00 1.03297233e-22 4.99566401e-22
 2.27316834e-30], sampled 0.9436491426806268
[2019-03-26 15:38:55,124] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:38:55,125] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.26666666666667, 84.0, 1.0, 2.0, 0.6757635608304595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944383.7702033484, 944383.7702033484, 215699.7630741714]
[2019-03-26 15:38:55,126] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:55,128] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.86658511e-19 1.00000000e+00 1.04518164e-20 1.70026324e-18
 1.04313065e-27], sampled 0.7952244531382066
[2019-03-26 15:38:58,114] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:38:58,116] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3597844510134063, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558262.3869942317, 558262.3869942317, 171442.0311372862]
[2019-03-26 15:38:58,117] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:38:58,120] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9369943e-21 1.0000000e+00 3.1189404e-22 6.5245779e-22 9.7178453e-30], sampled 0.17585354266538367
[2019-03-26 15:39:03,133] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:39:03,135] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.86055850333334, 67.07851366833333, 1.0, 2.0, 0.5471868853194399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764632.3884799524, 764632.3884799524, 191319.3770451857]
[2019-03-26 15:39:03,135] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:39:03,138] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.6654355e-21 1.0000000e+00 5.9260741e-22 8.5374587e-21 2.2342679e-29], sampled 0.9894471857399073
[2019-03-26 15:39:20,520] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:39:20,520] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.51639364, 82.70176736, 1.0, 2.0, 0.5314971172107237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 742700.0298902056, 742700.0298902062, 188677.465623952]
[2019-03-26 15:39:20,521] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:39:20,523] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9723831e-20 1.0000000e+00 7.6947558e-22 1.0666344e-19 1.9786061e-29], sampled 0.964780543242214
[2019-03-26 15:39:53,112] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:39:53,113] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.9, 75.66666666666667, 1.0, 2.0, 0.5150048263430942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719646.3317479518, 719646.3317479518, 185979.2234235345]
[2019-03-26 15:39:53,113] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:39:53,116] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.6363994e-20 1.0000000e+00 1.0339939e-21 2.9978359e-19 2.6755582e-29], sampled 0.34889317872080206
[2019-03-26 15:39:59,642] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:39:59,643] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.35, 75.0, 1.0, 2.0, 0.6882301421210009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067253.913742923, 1067253.913742923, 231366.6282060146]
[2019-03-26 15:39:59,644] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:39:59,646] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6324360e-19 1.0000000e+00 2.9691997e-20 8.1754292e-19 2.5943212e-27], sampled 0.877431679140234
[2019-03-26 15:40:04,927] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02372819], dtype=float32), 0.078383125]
[2019-03-26 15:40:04,930] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.06666666666666, 89.0, 1.0, 2.0, 0.8843431493225697, 1.0, 1.0, 0.8843431493225697, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2473426.54851956, 2473426.54851956, 463508.636400746]
[2019-03-26 15:40:04,932] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:40:04,934] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8939326e-09 9.7614664e-01 2.6119266e-14 2.3853308e-02 4.3766821e-18], sampled 0.1545800541500224
[2019-03-26 15:40:04,936] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2473426.54851956 W.
[2019-03-26 15:40:08,404] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.7605 2926603664.2852 1314.0000
[2019-03-26 15:40:08,818] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.9664 2778903150.6419 922.0000
[2019-03-26 15:40:08,992] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8508.1458 2840986882.8509 1092.0000
[2019-03-26 15:40:09,011] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7942.4315 3158194563.9652 1622.0000
[2019-03-26 15:40:09,076] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8026.0129 3004611006.8576 1690.0000
[2019-03-26 15:40:10,090] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 700000, evaluation results [700000.0, 7942.431519996297, 3158194563.9652305, 1622.0, 8266.760468333736, 2926603664.2852254, 1314.0, 8664.96637682165, 2778903150.6418567, 922.0, 8026.0128716019335, 3004611006.8575506, 1690.0, 8508.14580617989, 2840986882.850858, 1092.0]
[2019-03-26 15:40:12,133] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1001666e-21 1.0000000e+00 8.8516787e-22 1.7136557e-20 1.7448354e-29], sum to 1.0000
[2019-03-26 15:40:12,147] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5610
[2019-03-26 15:40:12,153] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3960511450640312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590966.8437370453, 590966.8437370453, 173706.3800040062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2674200.0000, 
sim time next is 2674800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3959781094822624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590857.7785036261, 590857.7785036255, 173696.3566230513], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2722627825087499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1641271606954517, 0.16412716069545155, 0.25924829346724076], 
reward next is 0.7408, 
noisyNet noise sample is [array([0.20759566], dtype=float32), 0.20208369]. 
=============================================
[2019-03-26 15:40:12,203] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.8798961e-17 1.0000000e+00 5.3375965e-20 8.3452788e-16 2.9656007e-27], sum to 1.0000
[2019-03-26 15:40:12,215] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0250
[2019-03-26 15:40:12,219] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 80.0, 1.0, 2.0, 0.5704923211440605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797211.346178428, 797211.346178428, 195377.1786382939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416800.0000, 
sim time next is 2417400.0000, 
raw observation next is [29.2, 80.0, 1.0, 2.0, 0.5678562392396902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793526.2844790141, 793526.2844790141, 194910.2265544807], 
processed observation next is [1.0, 1.0, 0.5829383886255924, 0.8, 1.0, 1.0, 0.47934486655384356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22042396791083727, 0.22042396791083727, 0.29091078590221], 
reward next is 0.7091, 
noisyNet noise sample is [array([0.04030141], dtype=float32), 1.5595472]. 
=============================================
[2019-03-26 15:40:22,371] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5927749e-21 1.0000000e+00 9.7603764e-24 1.8845386e-21 3.5533466e-32], sum to 1.0000
[2019-03-26 15:40:22,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4966
[2019-03-26 15:40:22,385] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 84.33333333333334, 1.0, 2.0, 0.5410689179681824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756080.1716485576, 756080.1716485576, 190280.7610229312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2576400.0000, 
sim time next is 2577000.0000, 
raw observation next is [27.68333333333334, 84.66666666666667, 1.0, 2.0, 0.5394514929958127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753819.2085097961, 753819.2085097961, 190008.0673911301], 
processed observation next is [1.0, 0.8260869565217391, 0.511058451816746, 0.8466666666666667, 1.0, 1.0, 0.44512228071784665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20939422458605447, 0.20939422458605447, 0.28359413043452253], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.46073762], dtype=float32), -1.4893324]. 
=============================================
[2019-03-26 15:40:22,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.84728 ]
 [70.01487 ]
 [69.906815]
 [70.2332  ]
 [70.389275]], R is [[69.73712921]
 [69.75575256]
 [69.77418518]
 [69.7926712 ]
 [69.81136322]].
[2019-03-26 15:40:24,626] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.0208005e-23 1.0000000e+00 3.8405610e-24 3.3830442e-24 7.6672330e-32], sum to 1.0000
[2019-03-26 15:40:24,634] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8488
[2019-03-26 15:40:24,640] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4770567381362009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666730.5403852839, 666730.5403852839, 180095.5526592168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2629800.0000, 
sim time next is 2630400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.47695265418527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666584.9123931888, 666584.9123931894, 180079.941457943], 
processed observation next is [0.0, 0.43478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36982247492201203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18516247566477467, 0.18516247566477484, 0.2687760320267806], 
reward next is 0.7312, 
noisyNet noise sample is [array([0.13542335], dtype=float32), -1.1929095]. 
=============================================
[2019-03-26 15:40:32,207] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7339739e-23 1.0000000e+00 5.9855705e-24 1.9021159e-23 4.5254733e-33], sum to 1.0000
[2019-03-26 15:40:32,216] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1027
[2019-03-26 15:40:32,225] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3942585765178038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588293.0676393362, 588293.0676393369, 173461.2461105632], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2739000.0000, 
sim time next is 2739600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3940499015925438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587981.5821450595, 587981.5821450589, 173432.7497484515], 
processed observation next is [0.0, 0.7391304347826086, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2699396404729444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16332821726251653, 0.16332821726251637, 0.2588548503708231], 
reward next is 0.7411, 
noisyNet noise sample is [array([-1.6512707], dtype=float32), 0.90140533]. 
=============================================
[2019-03-26 15:40:32,686] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4613601e-23 1.0000000e+00 1.1914125e-24 3.3630982e-25 3.9261037e-33], sum to 1.0000
[2019-03-26 15:40:32,693] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-26 15:40:32,702] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.3911062162407326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584174.1603886123, 584174.1603886123, 173103.7404002603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2747400.0000, 
sim time next is 2748000.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.3899526964879866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583306.3079049023, 583306.3079049016, 173051.4434765129], 
processed observation next is [0.0, 0.8260869565217391, 0.27330173775671435, 0.96, 1.0, 1.0, 0.26500324878070675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16202952997358397, 0.16202952997358377, 0.25828573653210884], 
reward next is 0.7417, 
noisyNet noise sample is [array([-0.6538095], dtype=float32), -0.38090536]. 
=============================================
[2019-03-26 15:40:32,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[76.60336 ]
 [76.58033 ]
 [76.53422 ]
 [76.51281 ]
 [76.490295]], R is [[76.59109497]
 [76.56682587]
 [76.54265594]
 [76.51851654]
 [76.49451447]].
[2019-03-26 15:40:34,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.673246e-21 1.000000e+00 2.523272e-22 8.498434e-21 9.440472e-31], sum to 1.0000
[2019-03-26 15:40:34,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-26 15:40:34,775] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 90.0, 1.0, 2.0, 0.5349092040805988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834201.3221805632, 834201.3221805632, 199447.1048913579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2799600.0000, 
sim time next is 2800200.0000, 
raw observation next is [22.0, 89.0, 1.0, 2.0, 0.5312838730596943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 831257.8872264372, 831257.8872264365, 199032.555775022], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 0.89, 1.0, 1.0, 0.43528177477071595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23090496867401034, 0.23090496867401014, 0.2970635160821224], 
reward next is 0.7029, 
noisyNet noise sample is [array([-1.800822], dtype=float32), -0.07330984]. 
=============================================
[2019-03-26 15:40:39,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.4907690e-24 1.0000000e+00 3.7784954e-24 2.1611584e-24 5.8594620e-32], sum to 1.0000
[2019-03-26 15:40:39,616] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8430
[2019-03-26 15:40:39,622] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3496026625079432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538542.6937369745, 538542.6937369745, 169696.5313190107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2871600.0000, 
sim time next is 2872200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3426318834560549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527812.8876769763, 527812.8876769756, 168824.2942452934], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.20799022103139142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1466146910213823, 0.1466146910213821, 0.2519765585750648], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.37416133], dtype=float32), 0.48457316]. 
=============================================
[2019-03-26 15:40:45,809] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6801106e-23 1.0000000e+00 3.5863707e-24 4.3987275e-23 1.4792677e-32], sum to 1.0000
[2019-03-26 15:40:45,817] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7679
[2019-03-26 15:40:45,826] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333334, 98.0, 1.0, 2.0, 0.3012956036091493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478834.0511005365, 478834.0511005365, 165522.358767957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3036000.0000, 
sim time next is 3036600.0000, 
raw observation next is [20.5, 97.0, 1.0, 2.0, 0.3043958692060172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 483192.4815268922, 483192.4815268916, 165825.3701243311], 
processed observation next is [1.0, 0.13043478260869565, 0.1706161137440759, 0.97, 1.0, 1.0, 0.16192273398315324, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13422013375747005, 0.13422013375746988, 0.24750055242437477], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.58587456], dtype=float32), 0.5536756]. 
=============================================
[2019-03-26 15:40:48,376] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.6789075e-22 1.0000000e+00 5.3198803e-24 8.2152101e-23 9.9073434e-33], sum to 1.0000
[2019-03-26 15:40:48,388] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3747
[2019-03-26 15:40:48,394] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3039678834542239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484051.0362989192, 484051.0362989186, 165912.9389391483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3010800.0000, 
sim time next is 3011400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3041065107829917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484272.064722271, 484272.064722271, 165928.8890831842], 
processed observation next is [1.0, 0.8695652173913043, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16157410937709846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13452001797840862, 0.13452001797840862, 0.24765505833311077], 
reward next is 0.7523, 
noisyNet noise sample is [array([1.6446806], dtype=float32), -0.32063302]. 
=============================================
[2019-03-26 15:40:54,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1603123e-19 1.0000000e+00 1.8372843e-21 3.8245639e-18 8.8560037e-29], sum to 1.0000
[2019-03-26 15:40:54,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9396
[2019-03-26 15:40:54,853] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 85.0, 1.0, 2.0, 0.6745084869485554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 989521.3541769555, 989521.3541769562, 221548.375659918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3148800.0000, 
sim time next is 3149400.0000, 
raw observation next is [24.83333333333334, 84.0, 1.0, 2.0, 0.6496299206387757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 952143.2767183082, 952143.2767183089, 216070.7810334703], 
processed observation next is [1.0, 0.43478260869565216, 0.3759873617693526, 0.84, 1.0, 1.0, 0.5778673742635851, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2644842435328634, 0.2644842435328636, 0.3224937030350303], 
reward next is 0.6775, 
noisyNet noise sample is [array([0.9472307], dtype=float32), -0.18387]. 
=============================================
[2019-03-26 15:40:59,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.3794137e-23 1.0000000e+00 6.6020349e-24 9.8200940e-24 1.7203718e-32], sum to 1.0000
[2019-03-26 15:40:59,125] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5703
[2019-03-26 15:40:59,129] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.33333333333333, 1.0, 2.0, 0.4682276596196061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657270.9418419404, 657270.9418419404, 179156.5997873862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3207000.0000, 
sim time next is 3207600.0000, 
raw observation next is [25.0, 90.0, 1.0, 2.0, 0.4657045598329232, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655042.1432493017, 655042.1432493011, 178953.5943287883], 
processed observation next is [0.0, 0.13043478260869565, 0.38388625592417064, 0.9, 1.0, 1.0, 0.3562705540155702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1819561509025838, 0.18195615090258366, 0.2670949169086393], 
reward next is 0.7329, 
noisyNet noise sample is [array([0.35083506], dtype=float32), -1.3617574]. 
=============================================
[2019-03-26 15:41:06,139] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 15:41:06,141] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:41:06,143] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:41:06,143] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:41:06,143] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:41:06,143] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:41:06,144] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:41:06,145] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:41:06,145] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:41:06,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:41:06,150] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:41:06,171] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 15:41:06,173] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 15:41:06,193] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 15:41:06,216] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 15:41:06,255] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 15:41:13,310] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:41:13,313] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.42996794666667, 77.93960504500001, 1.0, 2.0, 0.3404845267136222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557490.5882839431, 557490.5882839431, 171238.71631842]
[2019-03-26 15:41:13,314] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:41:13,319] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2424731e-22 1.0000000e+00 6.3008144e-23 4.6008848e-23 5.3158652e-31], sampled 0.915169899088017
[2019-03-26 15:41:19,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:41:19,290] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.18333333333333, 95.16666666666667, 1.0, 2.0, 0.3782464466167446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577008.8621369342, 577008.8621369342, 172818.0809859047]
[2019-03-26 15:41:19,290] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:41:19,293] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0300318e-23 1.0000000e+00 1.3305987e-23 2.0269327e-23 7.1354235e-32], sampled 0.6140893089079608
[2019-03-26 15:41:24,706] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:41:24,707] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.4, 80.0, 1.0, 2.0, 0.2569638445175198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 423171.6452146507, 423171.64521465, 161590.0137483032]
[2019-03-26 15:41:24,708] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:41:24,711] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8328452e-22 1.0000000e+00 3.4540237e-23 6.0798791e-23 1.8127486e-31], sampled 0.981705065866074
[2019-03-26 15:41:47,708] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:41:47,709] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.56402266, 99.77017379333333, 1.0, 2.0, 0.2943034106171574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 473092.7565731378, 473092.7565731378, 165174.9366083041]
[2019-03-26 15:41:47,711] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:41:47,715] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7338341e-22 1.0000000e+00 4.5398648e-23 4.7370198e-23 2.1706357e-31], sampled 0.5559214801482837
[2019-03-26 15:42:02,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:02,389] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.03333333333333, 71.16666666666667, 1.0, 2.0, 0.5474144679844376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764950.5242778761, 764950.5242778761, 191358.0353269476]
[2019-03-26 15:42:02,391] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:42:02,393] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.26711146e-23 1.00000000e+00 3.86258485e-24 1.44821254e-24
 3.19949608e-32], sampled 0.35940329575053187
[2019-03-26 15:42:16,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:16,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.15, 73.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.326496659469697, 6.9112, 168.9104479771201, 1748578.084848885, 1453956.716712287, 311357.4814457147]
[2019-03-26 15:42:16,510] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:42:16,511] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1553815e-18 1.0000000e+00 3.1621557e-20 1.8617344e-17 1.8953905e-27], sampled 0.24854332219008346
[2019-03-26 15:42:16,512] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1748578.084848885 W.
[2019-03-26 15:42:43,177] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:43,179] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.46254969, 84.94661663666666, 1.0, 2.0, 0.9006297189671993, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564481519, 1258821.891673011, 1258821.891673011, 270108.2449447414]
[2019-03-26 15:42:43,181] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:42:43,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5135068e-18 1.0000000e+00 7.0846662e-20 2.7731298e-17 7.2628374e-27], sampled 0.49097250362433165
[2019-03-26 15:42:48,828] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:48,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.19121020333333, 86.80367163833334, 1.0, 2.0, 0.5243598726436193, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732723.1930793262, 732723.1930793256, 187501.3554712089]
[2019-03-26 15:42:48,831] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:42:48,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.1089317e-22 1.0000000e+00 6.7119681e-23 1.1786035e-21 4.0342355e-31], sampled 0.026156921584106874
[2019-03-26 15:42:53,920] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:53,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.76666666666667, 94.0, 1.0, 2.0, 0.707887377428188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 989297.9132368182, 989297.9132368187, 222558.3363235512]
[2019-03-26 15:42:53,923] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:42:53,925] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2858112e-20 1.0000000e+00 4.9579411e-22 5.8122356e-20 6.4833656e-30], sampled 0.14355510196150922
[2019-03-26 15:42:53,947] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:53,948] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.98097988166667, 72.13735340833333, 1.0, 2.0, 0.2611674265396981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 431069.2504952628, 431069.2504952634, 161985.3562839376]
[2019-03-26 15:42:53,950] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:42:53,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0447569e-22 1.0000000e+00 3.1370165e-23 7.9176871e-23 1.6419356e-31], sampled 0.5961482336910618
[2019-03-26 15:42:54,696] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02780668], dtype=float32), 0.081043035]
[2019-03-26 15:42:54,697] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.73333333333333, 75.33333333333334, 1.0, 2.0, 0.4659669663162758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665474.4254368199, 665474.4254368205, 180278.3304316765]
[2019-03-26 15:42:54,699] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:42:54,703] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5556097e-23 1.0000000e+00 5.0670177e-24 1.5587275e-24 3.9228271e-32], sampled 0.30457143683633936
[2019-03-26 15:43:01,092] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7893.3322 3163252346.1807 1755.0000
[2019-03-26 15:43:01,565] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.6953 3007662122.8610 1765.0000
[2019-03-26 15:43:01,572] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.0492 2842483512.1056 1130.0000
[2019-03-26 15:43:01,649] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 15:43:01,673] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.4801 2779500575.0272 934.0000
[2019-03-26 15:43:02,688] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 725000, evaluation results [725000.0, 7893.332241713986, 3163252346.1806755, 1755.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8659.480134114692, 2779500575.027156, 934.0, 7996.695303887766, 3007662122.8610134, 1765.0, 8497.049151457732, 2842483512.10558, 1130.0]
[2019-03-26 15:43:05,959] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0968862e-21 1.0000000e+00 1.9802744e-22 2.6285675e-21 4.3771173e-31], sum to 1.0000
[2019-03-26 15:43:05,975] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-26 15:43:05,980] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5368056235281804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750120.615587785, 750120.6155877844, 189563.6615732112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3363000.0000, 
sim time next is 3363600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5380746063124562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751894.4923981369, 751894.4923981369, 189776.4799464616], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44346338109934474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2088595812217047, 0.2088595812217047, 0.28324847753203225], 
reward next is 0.7168, 
noisyNet noise sample is [array([-1.5470296], dtype=float32), 0.33394513]. 
=============================================
[2019-03-26 15:43:08,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5484601e-20 1.0000000e+00 4.5306632e-22 1.4218423e-19 2.2998936e-30], sum to 1.0000
[2019-03-26 15:43:08,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-26 15:43:08,260] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5163185270364803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721482.6658881874, 721482.665888188, 186192.4860737829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3443400.0000, 
sim time next is 3444000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5163119925786053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721473.5317996818, 721473.5317996818, 186191.4310685439], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41724336455253647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2004093143888005, 0.2004093143888005, 0.27789765831125957], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.48645163], dtype=float32), -0.009298168]. 
=============================================
[2019-03-26 15:43:08,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.96756]
 [65.3308 ]
 [65.61755]
 [65.83815]
 [66.15217]], R is [[65.14499664]
 [65.21564484]
 [65.28553009]
 [65.35463715]
 [65.42310333]].
[2019-03-26 15:43:09,094] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.8505736e-20 1.0000000e+00 3.9382610e-22 1.1242845e-20 1.0206495e-30], sum to 1.0000
[2019-03-26 15:43:09,101] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-26 15:43:09,110] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5157695029439897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720715.2215249649, 720715.2215249649, 186104.0597786985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3440400.0000, 
sim time next is 3441000.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.516028016286732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721076.5801110404, 721076.5801110397, 186145.6822240083], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.41690122444184574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20029905003084456, 0.20029905003084436, 0.2778293764537437], 
reward next is 0.7222, 
noisyNet noise sample is [array([-0.2895056], dtype=float32), 1.5266968]. 
=============================================
[2019-03-26 15:43:09,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[65.92288]
 [66.20746]
 [66.52183]
 [66.87754]
 [67.03868]], R is [[65.89588165]
 [65.95915222]
 [66.02157593]
 [66.08309937]
 [66.14365387]].
[2019-03-26 15:43:09,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6802943e-17 1.0000000e+00 2.8965608e-19 1.8273844e-16 1.7888478e-26], sum to 1.0000
[2019-03-26 15:43:09,922] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4726
[2019-03-26 15:43:09,930] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5068390298243134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708231.9833506766, 708231.983350676, 184674.5551597565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460800.0000, 
sim time next is 3461400.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5054346614254485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706268.9355070761, 706268.9355070768, 184451.9452195093], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.865, 1.0, 1.0, 0.40413814629572103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19618581541863225, 0.19618581541863245, 0.275301410775387], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.814545], dtype=float32), -1.4534016]. 
=============================================
[2019-03-26 15:43:18,007] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2147100e-08 9.9968147e-01 2.0610824e-13 3.1860103e-04 9.8294689e-19], sum to 1.0000
[2019-03-26 15:43:18,015] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-26 15:43:18,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2525645.147884337 W.
[2019-03-26 15:43:18,030] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 62.33333333333333, 1.0, 2.0, 0.9029825098987283, 1.0, 2.0, 0.9029825098987283, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2525645.147884337, 2525645.147884337, 473124.5490912736], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3593400.0000, 
sim time next is 3594000.0000, 
raw observation next is [33.0, 61.66666666666667, 1.0, 2.0, 0.6570543655356385, 1.0, 2.0, 0.6491172222820817, 1.0, 1.0, 1.03, 7.005094346177025, 6.9112, 170.5573041426782, 2723590.132453174, 2656329.792908764, 508106.6198462152], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.6166666666666667, 1.0, 1.0, 0.5868124885971547, 1.0, 1.0, 0.5772496654000984, 1.0, 0.5, 1.0365853658536586, 0.00938943461770254, 0.0, 0.8375144448122397, 0.7565528145703261, 0.7378693869191011, 0.7583680893227093], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6471941], dtype=float32), 0.20670679]. 
=============================================
[2019-03-26 15:43:18,046] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[48.299007]
 [48.28508 ]
 [47.994923]
 [48.775063]
 [49.19376 ]], R is [[45.74358368]
 [45.57999039]
 [45.40408325]
 [45.19435883]
 [45.00546646]].
[2019-03-26 15:43:21,758] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1532485e-18 1.0000000e+00 6.3032011e-21 1.7107248e-18 5.4889495e-28], sum to 1.0000
[2019-03-26 15:43:21,768] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9524
[2019-03-26 15:43:21,777] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8955024469003753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564978379, 1251651.21244208, 1251651.21244208, 268699.9941978502], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3638400.0000, 
sim time next is 3639000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.8621373551190564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104278, 1204990.083021733, 1204990.083021734, 259731.3493923704], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.8339004278542849, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451522869, 0.3347194675060369, 0.3347194675060372, 0.3876587304363737], 
reward next is 0.6123, 
noisyNet noise sample is [array([-0.21307477], dtype=float32), -0.6953423]. 
=============================================
[2019-03-26 15:43:21,799] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[61.517673]
 [61.940205]
 [62.52199 ]
 [64.06411 ]
 [66.24216 ]], R is [[61.28422165]
 [61.27033615]
 [61.23840714]
 [60.85163498]
 [60.77860641]].
[2019-03-26 15:43:21,825] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1043706e-18 1.0000000e+00 1.8529389e-20 2.6132745e-18 8.3048959e-28], sum to 1.0000
[2019-03-26 15:43:21,839] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9590
[2019-03-26 15:43:21,846] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.759871013071652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1061983.228120634, 1061983.228120635, 234295.6190430396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3640800.0000, 
sim time next is 3641400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7736879900000767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1081303.439445454, 1081303.439445454, 237551.2278678445], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7273349277109358, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3003620665126261, 0.3003620665126261, 0.35455407144454404], 
reward next is 0.6454, 
noisyNet noise sample is [array([0.30010664], dtype=float32), -1.5414206]. 
=============================================
[2019-03-26 15:43:31,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.26133392e-23 1.00000000e+00 1.61854023e-24 1.12446659e-24
 1.06467205e-32], sum to 1.0000
[2019-03-26 15:43:31,893] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9605
[2019-03-26 15:43:31,899] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 80.66666666666667, 1.0, 2.0, 0.5187210980084552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724841.0670143329, 724841.0670143323, 186581.4908043624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3809400.0000, 
sim time next is 3810000.0000, 
raw observation next is [27.66666666666667, 82.33333333333334, 1.0, 2.0, 0.5215890895221579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728850.0638113872, 728850.0638113866, 187048.0319483735], 
processed observation next is [0.0, 0.08695652173913043, 0.5102685624012641, 0.8233333333333335, 1.0, 1.0, 0.4236013126772986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20245835105871865, 0.20245835105871848, 0.2791761670871246], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.9601426], dtype=float32), 0.8270316]. 
=============================================
[2019-03-26 15:43:31,920] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.86148 ]
 [68.79399 ]
 [68.783295]
 [68.969666]
 [68.97912 ]], R is [[68.9190979 ]
 [68.95142365]
 [68.98392487]
 [69.01604462]
 [69.04776001]].
[2019-03-26 15:43:34,740] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7574844e-25 1.0000000e+00 3.8356229e-26 4.3776917e-28 1.2604659e-34], sum to 1.0000
[2019-03-26 15:43:34,748] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4052
[2019-03-26 15:43:34,751] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666667, 60.66666666666667, 1.0, 2.0, 0.6211640916239537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868049.490890921, 868049.4908909217, 204755.9348768251], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3849600.0000, 
sim time next is 3850200.0000, 
raw observation next is [34.75, 60.5, 1.0, 2.0, 0.6203133274136174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866860.1001569517, 866860.1001569517, 204592.3819506234], 
processed observation next is [0.0, 0.5652173913043478, 0.8459715639810427, 0.605, 1.0, 1.0, 0.5425461776067679, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2407944722658199, 0.2407944722658199, 0.3053617641054081], 
reward next is 0.6946, 
noisyNet noise sample is [array([0.06843497], dtype=float32), 0.031592946]. 
=============================================
[2019-03-26 15:43:40,829] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6852112e-24 1.0000000e+00 7.4633805e-25 3.2205219e-24 5.6750024e-33], sum to 1.0000
[2019-03-26 15:43:40,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.22585174e-23 1.00000000e+00 1.89465615e-24 8.86464101e-25
 3.69980440e-32], sum to 1.0000
[2019-03-26 15:43:40,838] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4311
[2019-03-26 15:43:40,839] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6187
[2019-03-26 15:43:40,842] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6120671115098942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 855331.7425388523, 855331.7425388523, 203015.3604700686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3961200.0000, 
sim time next is 3961800.0000, 
raw observation next is [31.5, 73.0, 1.0, 2.0, 0.6058632231405846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846658.677897004, 846658.677897004, 201843.3974250862], 
processed observation next is [0.0, 0.8695652173913043, 0.6919431279620853, 0.73, 1.0, 1.0, 0.525136413422391, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23518296608250108, 0.23518296608250108, 0.30125880212699435], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.12216735], dtype=float32), -1.9554578]. 
=============================================
[2019-03-26 15:43:40,845] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 62.00000000000001, 1.0, 2.0, 0.6138143539392955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 857774.4083206037, 857774.4083206031, 203348.1752246291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3950400.0000, 
sim time next is 3951000.0000, 
raw observation next is [34.0, 61.5, 1.0, 2.0, 0.6090855167490602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851163.4504296836, 851163.4504296836, 202451.2057352744], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.615, 1.0, 1.0, 0.5290186948783857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2364342917860232, 0.2364342917860232, 0.30216597870936474], 
reward next is 0.6978, 
noisyNet noise sample is [array([-0.36068287], dtype=float32), 1.0870622]. 
=============================================
[2019-03-26 15:43:40,859] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.56854 ]
 [73.564896]
 [73.62209 ]
 [73.59928 ]
 [73.57918 ]], R is [[73.54602051]
 [73.50705719]
 [73.46492004]
 [73.42672729]
 [73.3899231 ]].
[2019-03-26 15:43:43,122] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7154526e-10 9.9999940e-01 1.1158577e-13 6.1999350e-07 2.5626105e-18], sum to 1.0000
[2019-03-26 15:43:43,131] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3371
[2019-03-26 15:43:43,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2021194.113452649 W.
[2019-03-26 15:43:43,144] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.7227833499516411, 1.0, 1.0, 0.7227833499516411, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2021194.113452649, 2021194.113452649, 384038.535526401], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3984600.0000, 
sim time next is 3985200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.754091164364954, 1.0, 2.0, 0.754091164364954, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2108829.578382466, 2108829.578382467, 398147.6043802978], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.79, 1.0, 1.0, 0.7037242944156072, 1.0, 1.0, 0.7037242944156072, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5857859939951294, 0.5857859939951297, 0.5942501557914893], 
reward next is 0.4057, 
noisyNet noise sample is [array([-0.02540388], dtype=float32), -0.048596412]. 
=============================================
[2019-03-26 15:43:45,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6786846e-07 2.5780527e-03 2.5808882e-13 9.9742186e-01 4.3965483e-17], sum to 1.0000
[2019-03-26 15:43:46,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4658
[2019-03-26 15:43:46,014] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.343556489596962, 6.9112, 170.5573041426782, 3219405.03807151, 2909690.497435661, 551335.5541055423], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4030800.0000, 
sim time next is 4031400.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.457484022126653, 6.9112, 170.5573041426782, 3301111.03174892, 2909785.565286327, 550682.2878071393], 
processed observation next is [1.0, 0.6521739130434783, 0.8104265402843602, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.054628402212665336, 0.0, 0.8375144448122397, 0.9169752865969223, 0.8082737681350909, 0.8219138623987154], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43177095], dtype=float32), -0.64231575]. 
=============================================
[2019-03-26 15:43:47,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1268232e-18 1.0000000e+00 4.4904542e-21 8.3596630e-20 3.5402300e-28], sum to 1.0000
[2019-03-26 15:43:47,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7562
[2019-03-26 15:43:47,363] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.83333333333334, 1.0, 2.0, 0.7336170904601088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1025273.464897259, 1025273.464897259, 228269.2253772327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4083000.0000, 
sim time next is 4083600.0000, 
raw observation next is [27.0, 90.66666666666667, 1.0, 2.0, 0.8263011242058245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1154875.345869785, 1154875.345869785, 250469.8526333685], 
processed observation next is [1.0, 0.2608695652173913, 0.4786729857819906, 0.9066666666666667, 1.0, 1.0, 0.7907242460311138, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32079870718605136, 0.32079870718605136, 0.3738356009453261], 
reward next is 0.6262, 
noisyNet noise sample is [array([1.1460085], dtype=float32), 0.5212013]. 
=============================================
[2019-03-26 15:43:58,924] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 15:43:58,925] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:43:58,926] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:43:58,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:43:58,927] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:43:58,930] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:43:58,930] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:43:58,931] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:43:58,932] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:43:58,932] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:43:58,934] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:43:58,955] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 15:43:58,956] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 15:43:58,956] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 15:43:59,014] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 15:43:59,015] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 15:45:14,004] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02492525], dtype=float32), 0.07484374]
[2019-03-26 15:45:14,004] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 63.00000000000001, 1.0, 2.0, 0.5535319987922865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773502.2022834525, 773502.2022834532, 192408.6116957248]
[2019-03-26 15:45:14,005] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:45:14,007] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1996422e-23 1.0000000e+00 3.5401695e-24 9.9014517e-25 6.6630341e-32], sampled 0.5674893058799828
[2019-03-26 15:45:18,363] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02492525], dtype=float32), 0.07484374]
[2019-03-26 15:45:18,364] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.26666666666667, 77.33333333333334, 1.0, 2.0, 0.5599001246990367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 782404.2595657681, 782404.2595657675, 193512.6765720828]
[2019-03-26 15:45:18,365] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:45:18,368] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2798570e-21 1.0000000e+00 6.4307758e-23 2.6612459e-22 1.2627690e-30], sampled 0.6726747268098757
[2019-03-26 15:45:21,392] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.02492525], dtype=float32), 0.07484374]
[2019-03-26 15:45:21,393] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.22566769333334, 81.43447277333334, 1.0, 2.0, 0.4910920095892518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687371.8362965642, 687371.8362965642, 182359.3236969564]
[2019-03-26 15:45:21,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:45:21,399] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0969701e-23 1.0000000e+00 4.3919014e-24 1.8923654e-25 1.1119050e-31], sampled 0.38140132382553515
[2019-03-26 15:45:31,960] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02492525], dtype=float32), 0.07484374]
[2019-03-26 15:45:31,963] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.2, 73.0, 1.0, 2.0, 0.8768153279119024, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981653996770504, 6.9112, 168.9124799839553, 2122584.876056859, 2072602.526915852, 428578.6718323579]
[2019-03-26 15:45:31,964] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:45:31,966] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7538970e-10 9.9999762e-01 2.6539206e-14 2.3456694e-06 2.3943312e-18], sampled 0.22835525753208785
[2019-03-26 15:45:31,967] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2122584.876056859 W.
[2019-03-26 15:45:54,038] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.2811 2842592176.0619 1131.0000
[2019-03-26 15:45:54,257] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.7183 3163826075.0863 1774.0000
[2019-03-26 15:45:54,337] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6295 2779256357.0602 933.0000
[2019-03-26 15:45:54,351] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5883 2927327297.4404 1338.0000
[2019-03-26 15:45:54,491] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 15:45:55,508] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 750000, evaluation results [750000.0, 7885.718304796248, 3163826075.0862875, 1774.0, 8253.588267098503, 2927327297.440425, 1338.0, 8660.629516213334, 2779256357.0601926, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8495.28112461888, 2842592176.061937, 1131.0]
[2019-03-26 15:46:04,683] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2014622e-26 1.0000000e+00 2.9680016e-26 9.1498199e-29 6.7098279e-35], sum to 1.0000
[2019-03-26 15:46:04,696] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6196
[2019-03-26 15:46:04,701] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.606296123057291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 847263.8716847828, 847263.8716847834, 201925.1362408009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4467600.0000, 
sim time next is 4468200.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6465546392236101, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 903546.7570592399, 903546.7570592399, 209737.4679518104], 
processed observation next is [0.0, 0.7391304347826086, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5741622159320604, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2509852102942333, 0.2509852102942333, 0.3130409969430006], 
reward next is 0.6870, 
noisyNet noise sample is [array([-0.58213913], dtype=float32), 0.82721704]. 
=============================================
[2019-03-26 15:46:15,965] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2912022e-19 1.0000000e+00 2.5956259e-21 1.1843363e-21 1.9234894e-29], sum to 1.0000
[2019-03-26 15:46:15,976] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1851
[2019-03-26 15:46:15,984] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.001329001628105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1399663.372522734, 1399663.372522734, 299336.5388062986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4604400.0000, 
sim time next is 4605000.0000, 
raw observation next is [29.16666666666667, 88.16666666666667, 1.0, 2.0, 1.000461134521655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1398449.463905272, 1398449.463905272, 299071.9936719646], 
processed observation next is [1.0, 0.30434782608695654, 0.581358609794629, 0.8816666666666667, 1.0, 1.0, 1.00055558376103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3884581844181311, 0.3884581844181311, 0.44637610995815613], 
reward next is 0.5536, 
noisyNet noise sample is [array([0.5993304], dtype=float32), -0.81693006]. 
=============================================
[2019-03-26 15:46:16,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.434353]
 [50.212048]
 [50.245136]
 [49.98781 ]
 [50.18373 ]], R is [[50.67446899]
 [50.7209549 ]
 [50.77713394]
 [50.83347702]
 [50.88113022]].
[2019-03-26 15:46:22,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2088135e-08 9.9374676e-01 1.2695235e-12 6.2531768e-03 3.4308794e-16], sum to 1.0000
[2019-03-26 15:46:22,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5794
[2019-03-26 15:46:22,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2581968.243251234 W.
[2019-03-26 15:46:22,601] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 72.5, 1.0, 2.0, 0.6153991115420675, 1.0, 1.0, 0.6153991115420675, 1.0, 2.0, 1.03, 6.954756081465903, 6.9112, 170.5573041426782, 2581968.243251234, 2550767.250349092, 493629.3369601003], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4703400.0000, 
sim time next is 4704000.0000, 
raw observation next is [30.66666666666666, 71.66666666666667, 1.0, 2.0, 0.8948508668677018, 1.0, 2.0, 0.8948508668677018, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2502878.135207367, 2502878.135207367, 468690.1487723109], 
processed observation next is [1.0, 0.43478260869565216, 0.6524486571879934, 0.7166666666666667, 1.0, 1.0, 0.873314297430966, 1.0, 1.0, 0.873314297430966, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6952439264464909, 0.6952439264464909, 0.699537535481061], 
reward next is 0.3005, 
noisyNet noise sample is [array([1.3482894], dtype=float32), -0.168596]. 
=============================================
[2019-03-26 15:46:22,618] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[42.047062]
 [45.15547 ]
 [46.175316]
 [46.515167]
 [45.597363]], R is [[41.13946915]
 [40.77353287]
 [40.36579895]
 [39.96214294]
 [39.56252289]].
[2019-03-26 15:46:23,764] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.82863261e-07 9.88629818e-01 1.21579385e-12 1.13699585e-02
 1.30229277e-16], sum to 1.0000
[2019-03-26 15:46:23,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6019
[2019-03-26 15:46:23,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2459996.455236797 W.
[2019-03-26 15:46:23,785] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 71.0, 1.0, 2.0, 0.8795345107286952, 1.0, 2.0, 0.8795345107286952, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2459996.455236797, 2459996.455236797, 460450.9975760902], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4721400.0000, 
sim time next is 4722000.0000, 
raw observation next is [31.33333333333334, 69.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.39090285769537, 6.9112, 168.9045268770723, 3334346.317984594, 2284646.571374304, 472404.1536282152], 
processed observation next is [1.0, 0.6521739130434783, 0.6840442338072673, 0.6966666666666668, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.14797028576953694, 0.0, 0.8293985517934086, 0.9262073105512761, 0.6346240476039734, 0.705080826310769], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08529428], dtype=float32), 0.1489034]. 
=============================================
[2019-03-26 15:46:23,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[38.628014]
 [38.121628]
 [39.698982]
 [39.258953]
 [38.75992 ]], R is [[36.92917633]
 [36.55988312]
 [36.47559357]
 [36.3988533 ]
 [36.03486633]].
[2019-03-26 15:46:27,484] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1568001e-13 1.0000000e+00 2.5948603e-16 2.3465279e-13 6.2882837e-22], sum to 1.0000
[2019-03-26 15:46:27,494] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9430
[2019-03-26 15:46:27,505] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2263189.026515787 W.
[2019-03-26 15:46:27,510] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 71.66666666666667, 1.0, 2.0, 0.5394884350666602, 1.0, 2.0, 0.5394884350666602, 1.0, 2.0, 0.9367258808181022, 6.9112, 6.9112, 170.5573041426782, 2263189.026515787, 2263189.026515787, 443490.0291685914], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4783200.0000, 
sim time next is 4783800.0000, 
raw observation next is [30.0, 70.83333333333333, 1.0, 2.0, 0.956152770570734, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.992314470240206, 6.9112, 168.9124111251693, 2233631.382335827, 2176086.171205088, 450616.9488529103], 
processed observation next is [1.0, 0.34782608695652173, 0.6208530805687204, 0.7083333333333333, 1.0, 1.0, 0.9471720127358241, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008111447024020623, 0.0, 0.8294372670609893, 0.620453161759952, 0.6044683808903022, 0.6725626102282244], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29483587], dtype=float32), 0.81051534]. 
=============================================
[2019-03-26 15:46:27,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8869586e-11 9.9999988e-01 1.0872928e-14 6.8212820e-08 8.7443234e-20], sum to 1.0000
[2019-03-26 15:46:27,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6330
[2019-03-26 15:46:27,606] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2132484.002378404 W.
[2019-03-26 15:46:27,610] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666666, 67.33333333333334, 1.0, 2.0, 0.8838877141281185, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.991534662238564, 6.9112, 168.9124781654354, 2132484.002378404, 2075491.989476948, 430165.748386874], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4786800.0000, 
sim time next is 4787400.0000, 
raw observation next is [30.83333333333334, 66.66666666666666, 1.0, 2.0, 0.5034132707886498, 1.0, 1.0, 0.5034132707886498, 1.0, 2.0, 0.8703169028708642, 6.9112, 6.9112, 170.5573041426782, 2111709.309151141, 2111709.309151141, 416796.9119132911], 
processed observation next is [1.0, 0.391304347826087, 0.6603475513428123, 0.6666666666666665, 1.0, 1.0, 0.40170273588993954, 1.0, 0.5, 0.40170273588993954, 1.0, 1.0, 0.8418498815498343, 0.0, 0.0, 0.8375144448122397, 0.5865859192086502, 0.5865859192086502, 0.6220849431541658], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68405473], dtype=float32), 0.57754165]. 
=============================================
[2019-03-26 15:46:29,592] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7615823e-21 1.0000000e+00 1.0080999e-24 1.0902286e-23 1.1283335e-32], sum to 1.0000
[2019-03-26 15:46:29,602] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7525
[2019-03-26 15:46:29,607] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 70.0, 1.0, 2.0, 0.5105331950420744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713395.7618843167, 713395.7618843167, 185264.1819900355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4817400.0000, 
sim time next is 4818000.0000, 
raw observation next is [29.66666666666667, 70.0, 1.0, 2.0, 0.5098914425048809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712498.7054627757, 712498.7054627764, 185161.3104872901], 
processed observation next is [1.0, 0.782608695652174, 0.6050552922590839, 0.7, 1.0, 1.0, 0.4095077620540734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19791630707299324, 0.19791630707299343, 0.27636016490640314], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.48971027], dtype=float32), 0.2950567]. 
=============================================
[2019-03-26 15:46:29,627] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.722157]
 [62.207592]
 [61.19174 ]
 [59.70369 ]
 [56.742523]], R is [[62.56498718]
 [62.66282654]
 [62.76017761]
 [62.85772705]
 [62.95560837]].
[2019-03-26 15:46:30,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0286675e-21 1.0000000e+00 1.7918966e-23 6.4929394e-24 7.0681294e-32], sum to 1.0000
[2019-03-26 15:46:30,941] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9592
[2019-03-26 15:46:30,947] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4874479715313773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681127.1832627802, 681127.1832627802, 181652.4226032182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4838400.0000, 
sim time next is 4839000.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.4864589666265494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679744.7718240013, 679744.7718240013, 181501.3452180053], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.3812758634054812, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1888179921733337, 0.1888179921733337, 0.27089753017612733], 
reward next is 0.7291, 
noisyNet noise sample is [array([-0.396477], dtype=float32), -0.8825412]. 
=============================================
[2019-03-26 15:46:30,957] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.350586]
 [70.06338 ]
 [70.05947 ]
 [70.05361 ]
 [70.05589 ]], R is [[69.00328064]
 [69.04212189]
 [69.08039093]
 [69.11811829]
 [69.15526581]].
[2019-03-26 15:46:34,386] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1476137e-25 1.0000000e+00 4.9518260e-26 1.8356805e-28 1.5575946e-36], sum to 1.0000
[2019-03-26 15:46:34,393] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0403
[2019-03-26 15:46:34,399] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 73.33333333333334, 1.0, 2.0, 0.491514018420261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686810.6418548356, 686810.6418548356, 182277.1349528615], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4909800.0000, 
sim time next is 4910400.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4896975195386722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684271.5635466398, 684271.5635466403, 181997.5674451162], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.3851777343839424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19007543431851104, 0.1900754343185112, 0.2716381603658451], 
reward next is 0.7284, 
noisyNet noise sample is [array([-0.89338076], dtype=float32), -1.0280237]. 
=============================================
[2019-03-26 15:46:38,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.9167011e-13 1.0000000e+00 1.5896468e-16 4.8213961e-10 1.2147460e-21], sum to 1.0000
[2019-03-26 15:46:38,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3057
[2019-03-26 15:46:38,992] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.43333333333333, 64.83333333333334, 1.0, 2.0, 0.58544197724369, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9934223927742278, 6.911200000000001, 6.9112, 168.9129564976907, 1636850.991403351, 1636850.991403351, 353296.622984576], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4972200.0000, 
sim time next is 4972800.0000, 
raw observation next is [30.46666666666667, 64.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 9.13991174924539, 6.9112, 168.900169019924, 3035760.869539293, 1454755.746733497, 308906.0567752926], 
processed observation next is [1.0, 0.5652173913043478, 0.6429699842022119, 0.6466666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.22287117492453906, 0.0, 0.8293771527197747, 0.8432669082053592, 0.40409881853708246, 0.46105381608252627], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0384953], dtype=float32), -0.15243788]. 
=============================================
[2019-03-26 15:46:40,164] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7503535e-24 1.0000000e+00 2.8524939e-25 2.0155941e-27 9.6076873e-34], sum to 1.0000
[2019-03-26 15:46:40,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9933
[2019-03-26 15:46:40,174] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 87.33333333333333, 1.0, 2.0, 0.4878876570466119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681741.7675323692, 681741.7675323692, 181720.2063402289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5020800.0000, 
sim time next is 5021400.0000, 
raw observation next is [26.0, 88.16666666666667, 1.0, 2.0, 0.491929910150616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 687391.9707137512, 687391.9707137519, 182341.4938957685], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.8816666666666667, 1.0, 1.0, 0.3878673616272482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1909422140871531, 0.19094221408715328, 0.2721514834265202], 
reward next is 0.7278, 
noisyNet noise sample is [array([-0.4372714], dtype=float32), 1.336057]. 
=============================================
[2019-03-26 15:46:49,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6790394e-26 1.0000000e+00 1.2806283e-26 3.7176217e-29 5.1845580e-35], sum to 1.0000
[2019-03-26 15:46:49,537] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3780
[2019-03-26 15:46:49,547] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5508516237762893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769755.305596947, 769755.3055969476, 191947.3824051682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5151600.0000, 
sim time next is 5152200.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5736702554996205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801653.8974371125, 801653.8974371132, 195941.9700258927], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.63, 1.0, 1.0, 0.48634970542122946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2226816381769757, 0.2226816381769759, 0.29245070153118313], 
reward next is 0.7075, 
noisyNet noise sample is [array([-0.2342372], dtype=float32), -1.7487798]. 
=============================================
[2019-03-26 15:46:51,659] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 15:46:51,660] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:46:51,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:46:51,662] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:46:51,663] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:46:51,663] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:46:51,663] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:46:51,665] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:46:51,666] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:46:51,667] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:46:51,668] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:46:51,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 15:46:51,708] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 15:46:51,732] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 15:46:51,732] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 15:46:51,778] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 15:46:54,713] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:46:54,715] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.45, 96.0, 1.0, 2.0, 0.3851173570638002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 580498.9012723201, 580498.9012723208, 172932.974181683]
[2019-03-26 15:46:54,717] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:46:54,720] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9566320e-22 1.0000000e+00 2.6050169e-23 6.3649988e-24 1.6060308e-31], sampled 0.9996168901788449
[2019-03-26 15:47:03,178] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:03,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.7, 63.0, 1.0, 2.0, 0.5568258796781738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 907625.8797148681, 907625.8797148687, 206510.8893043553]
[2019-03-26 15:47:03,182] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:47:03,186] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5229407e-22 1.0000000e+00 4.9517957e-23 4.0946528e-25 6.3832611e-31], sampled 0.8188017362423423
[2019-03-26 15:47:13,175] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:13,176] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.35, 94.0, 1.0, 2.0, 0.3267571076837635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 512502.2542531469, 512502.2542531464, 167884.1542484799]
[2019-03-26 15:47:13,177] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:47:13,180] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.5161263e-25 1.0000000e+00 1.7582287e-25 6.9130250e-29 7.4529620e-34], sampled 0.01241845959273391
[2019-03-26 15:47:15,187] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:15,188] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.43333333333334, 84.0, 1.0, 2.0, 0.3581823112842414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549437.9069466967, 549437.9069466974, 170532.5589414631]
[2019-03-26 15:47:15,190] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:47:15,193] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9762350e-24 1.0000000e+00 4.5049948e-25 3.8078050e-27 1.2628296e-33], sampled 0.26667113247511187
[2019-03-26 15:47:25,743] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:25,745] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.53333333333333, 83.83333333333334, 1.0, 2.0, 0.7371720842473377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1030244.189916009, 1030244.189916009, 229070.5233628539]
[2019-03-26 15:47:25,746] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:47:25,748] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.6573328e-22 1.0000000e+00 5.0827204e-23 2.4924932e-24 7.7695508e-31], sampled 0.9210235896762115
[2019-03-26 15:47:34,497] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:34,498] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 73.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.94161929988082, 6.9112, 168.9126032237802, 1475350.159931757, 1453769.706781077, 311349.8943307376]
[2019-03-26 15:47:34,499] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:47:34,502] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.5621124e-20 1.0000000e+00 3.8408597e-21 1.4538053e-21 6.2691716e-29], sampled 0.4533214028279974
[2019-03-26 15:47:37,332] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:47:37,333] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.89109796833333, 100.0, 1.0, 2.0, 0.3269109727869801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510914.0265559638, 510914.0265559638, 167714.9001041839]
[2019-03-26 15:47:37,335] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:47:37,340] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.3575217e-25 1.0000000e+00 3.2372347e-25 2.1868708e-28 1.5934581e-33], sampled 0.35350589302325985
[2019-03-26 15:48:24,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.02330597], dtype=float32), 0.0758533]
[2019-03-26 15:48:24,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.33056243166667, 81.90788748666668, 1.0, 2.0, 0.6511797683795929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 910013.0486409329, 910013.0486409329, 210656.4926580415]
[2019-03-26 15:48:24,873] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:48:24,876] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.0080389e-22 1.0000000e+00 4.1045096e-23 3.6471028e-24 4.7408872e-31], sampled 0.883578249999153
[2019-03-26 15:48:46,984] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1717 3164262583.6598 1776.0000
[2019-03-26 15:48:47,100] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.6679 3007840824.3263 1766.0000
[2019-03-26 15:48:47,198] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4937 2779347358.0729 933.0000
[2019-03-26 15:48:47,214] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.9227 2842411389.6399 1131.0000
[2019-03-26 15:48:47,245] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3138 2927336198.9341 1338.0000
[2019-03-26 15:48:48,263] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 775000, evaluation results [775000.0, 7884.171662029637, 3164262583.659771, 1776.0, 8254.313777885838, 2927336198.934145, 1338.0, 8660.493697224767, 2779347358.072928, 933.0, 7998.667917709291, 3007840824.32627, 1766.0, 8496.922729686416, 2842411389.6398726, 1131.0]
[2019-03-26 15:48:48,529] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.5290778e-17 1.0000000e+00 2.5254039e-19 1.9875154e-16 3.6684756e-26], sum to 1.0000
[2019-03-26 15:48:48,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3637
[2019-03-26 15:48:48,543] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.9637879934077177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565103994, 1347155.042523194, 1347155.042523194, 288084.2143038111], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5195400.0000, 
sim time next is 5196000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.9514258394251024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1329864.757766333, 1329864.757766333, 284472.7960258182], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.9414769149700029, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3694068771573147, 0.3694068771573147, 0.4245862627251018], 
reward next is 0.5754, 
noisyNet noise sample is [array([-0.7085125], dtype=float32), -0.10056054]. 
=============================================
[2019-03-26 15:48:48,552] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[56.223095]
 [55.05789 ]
 [52.978107]
 [53.686234]
 [53.830776]], R is [[56.53097916]
 [56.53569412]
 [55.97033691]
 [55.41063309]
 [54.85652542]].
[2019-03-26 15:49:02,419] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4933046e-09 9.9997604e-01 5.4816381e-14 2.4015631e-05 6.2417550e-19], sum to 1.0000
[2019-03-26 15:49:02,428] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5239
[2019-03-26 15:49:02,434] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2269747.591707538 W.
[2019-03-26 15:49:02,440] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [36.41666666666666, 51.0, 1.0, 2.0, 0.541050416814534, 1.0, 2.0, 0.541050416814534, 1.0, 2.0, 0.9396256458998233, 6.9112, 6.9112, 170.5573041426782, 2269747.591707538, 2269747.591707538, 444695.3804308461], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5490600.0000, 
sim time next is 5491200.0000, 
raw observation next is [36.53333333333333, 50.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.784008788319332, 6.9112, 168.9024338802983, 3613456.378880709, 2284904.13621461, 471168.6822126576], 
processed observation next is [1.0, 0.5652173913043478, 0.9304897314375986, 0.5, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.18728087883193317, 0.0, 0.8293882742210702, 1.003737883022419, 0.6346955933929472, 0.7032368391233695], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43786484], dtype=float32), 1.2293397]. 
=============================================
[2019-03-26 15:49:04,405] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.1754963e-17 1.0000000e+00 1.9928961e-18 1.9149646e-17 9.2826199e-26], sum to 1.0000
[2019-03-26 15:49:04,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1690
[2019-03-26 15:49:04,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2192403.960545827 W.
[2019-03-26 15:49:04,426] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.96666666666667, 92.66666666666667, 1.0, 2.0, 0.7839457689848791, 1.0, 1.0, 0.7839457689848791, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2192403.960545827, 2192403.960545827, 412138.4189210661], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5451600.0000, 
sim time next is 5452200.0000, 
raw observation next is [27.95, 92.5, 1.0, 2.0, 0.582919643914375, 0.0, 1.0, 0.0, 1.0, 1.0, 1.01233864700726, 6.9112, 6.9112, 168.9129560509762, 1629793.325586533, 1629793.325586533, 356817.7379594459], 
processed observation next is [1.0, 0.08695652173913043, 0.523696682464455, 0.925, 1.0, 1.0, 0.49749354688478914, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0150471304966584, 0.0, 0.0, 0.8294399428961692, 0.4527203682184814, 0.4527203682184814, 0.532563787999173], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.96899146], dtype=float32), -1.6151323]. 
=============================================
[2019-03-26 15:49:05,265] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2443005e-17 1.0000000e+00 7.5905712e-19 1.1353009e-19 4.3307730e-26], sum to 1.0000
[2019-03-26 15:49:05,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8589
[2019-03-26 15:49:05,283] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 82.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.151427281635259, 6.9112, 168.9114775842434, 1624295.654549244, 1453871.645141601, 311354.6066453936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5467200.0000, 
sim time next is 5467800.0000, 
raw observation next is [29.7, 81.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.398970201970895, 6.9112, 168.9098758912226, 1800026.595570599, 1453991.937601569, 311354.7977091381], 
processed observation next is [1.0, 0.2608695652173913, 0.6066350710900474, 0.8183333333333332, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.048777020197089536, 0.0, 0.8294248179016759, 0.5000073876584997, 0.4038866493337692, 0.464708653297221], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.35815516], dtype=float32), -1.3887097]. 
=============================================
[2019-03-26 15:49:15,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5623444e-09 9.9996483e-01 2.0968031e-13 3.5148591e-05 6.9683945e-18], sum to 1.0000
[2019-03-26 15:49:15,832] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9570
[2019-03-26 15:49:15,838] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2485545.884192687 W.
[2019-03-26 15:49:15,843] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 74.0, 1.0, 2.0, 0.8886602461785816, 1.0, 2.0, 0.8886602461785816, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2485545.884192687, 2485545.884192687, 465348.5230930832], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5911200.0000, 
sim time next is 5911800.0000, 
raw observation next is [31.26666666666667, 73.33333333333334, 1.0, 2.0, 0.9020984764408413, 1.0, 2.0, 0.9020984764408413, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2523170.00672327, 2523170.00672327, 472643.5442027816], 
processed observation next is [1.0, 0.43478260869565216, 0.6808846761453398, 0.7333333333333334, 1.0, 1.0, 0.8820463571576401, 1.0, 1.0, 0.8820463571576401, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7008805574231305, 0.7008805574231305, 0.7054381256757934], 
reward next is 0.2946, 
noisyNet noise sample is [array([-1.1132911], dtype=float32), 0.69038963]. 
=============================================
[2019-03-26 15:49:21,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5471930e-26 1.0000000e+00 3.8690531e-27 1.6732673e-30 3.0595498e-36], sum to 1.0000
[2019-03-26 15:49:21,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6121
[2019-03-26 15:49:21,067] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 69.16666666666667, 1.0, 2.0, 0.5586665312572577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780679.8029916028, 780679.8029916034, 193298.3522883099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5766600.0000, 
sim time next is 5767200.0000, 
raw observation next is [30.7, 70.0, 1.0, 2.0, 0.558050477635908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779818.614541369, 779818.614541369, 193191.1023807659], 
processed observation next is [0.0, 0.782608695652174, 0.6540284360189573, 0.7, 1.0, 1.0, 0.4675306959468771, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21661628181704695, 0.21661628181704695, 0.28834492892651625], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.6454948], dtype=float32), -0.047000907]. 
=============================================
[2019-03-26 15:49:26,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.7057954e-07 8.9874994e-03 1.9875510e-12 9.9101186e-01 1.3162925e-15], sum to 1.0000
[2019-03-26 15:49:26,933] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4004
[2019-03-26 15:49:26,939] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.85, 61.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.065530172337604, 6.9112, 170.5573041426782, 3020011.502184722, 2909458.52198926, 552839.094875504], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5838600.0000, 
sim time next is 5839200.0000, 
raw observation next is [32.9, 61.0, 1.0, 2.0, 1.026139206744832, 1.0, 2.0, 1.026139206744832, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2870510.584797803, 2870510.584797804, 544979.3064140857], 
processed observation next is [1.0, 0.6086956521739131, 0.7582938388625592, 0.61, 1.0, 1.0, 1.0314930201744965, 1.0, 1.0, 1.0314930201744965, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.797364051332723, 0.7973640513327233, 0.8134019498717696], 
reward next is 0.1866, 
noisyNet noise sample is [array([1.3184048], dtype=float32), -1.0223005]. 
=============================================
[2019-03-26 15:49:32,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6860858e-07 9.9136955e-01 1.6075926e-12 8.6303437e-03 5.2300099e-17], sum to 1.0000
[2019-03-26 15:49:32,843] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3895
[2019-03-26 15:49:32,856] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2243760.628386287 W.
[2019-03-26 15:49:32,863] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.36666666666666, 78.83333333333334, 1.0, 2.0, 0.5348613378444601, 1.0, 2.0, 0.5348613378444601, 1.0, 1.0, 0.9288772624884967, 6.9112, 6.9112, 170.5573041426782, 2243760.628386287, 2243760.628386287, 440091.5853784123], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5935800.0000, 
sim time next is 5936400.0000, 
raw observation next is [30.4, 79.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.130289311783413, 6.9112, 168.9117986806073, 2439249.429297417, 2283820.99645228, 475609.3017079463], 
processed observation next is [1.0, 0.7391304347826086, 0.6398104265402843, 0.79, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.021908931178341272, 0.0, 0.8294342596778115, 0.6775692859159491, 0.6343947212367445, 0.7098646294148452], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7209207], dtype=float32), 0.27199596]. 
=============================================
[2019-03-26 15:49:33,714] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1001411e-21 1.0000000e+00 6.8051944e-23 2.3802246e-23 3.0962016e-31], sum to 1.0000
[2019-03-26 15:49:33,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3313914e-21 1.0000000e+00 1.9478262e-22 2.2974389e-22 3.6199367e-31], sum to 1.0000
[2019-03-26 15:49:33,722] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2816
[2019-03-26 15:49:33,728] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.0, 1.0, 2.0, 0.5240565623480476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732299.2111800533, 732299.2111800539, 187451.1534132516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5968800.0000, 
sim time next is 5969400.0000, 
raw observation next is [26.36666666666667, 91.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.974264896367111, 6.9112, 168.9602238291896, 1498538.21340181, 1453785.285576813, 311358.1659200625], 
processed observation next is [1.0, 0.08695652173913043, 0.4486571879936811, 0.9116666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.006306489636711099, 0.0, 0.8296720493264795, 0.41626061483383614, 0.4038292459935591, 0.4647136804777052], 
reward next is 0.2200, 
noisyNet noise sample is [array([0.9867652], dtype=float32), 0.11031938]. 
=============================================
[2019-03-26 15:49:33,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8693
[2019-03-26 15:49:33,738] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 91.5, 1.0, 2.0, 0.5514018941620689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770524.5275837607, 770524.5275837613, 192041.4645244369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.9133333333333334, 1.0, 1.0, 0.45622280791289466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21297181571720755, 0.21297181571720772, 0.28592843147275776], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.08115616], dtype=float32), -0.8033723]. 
=============================================
[2019-03-26 15:49:39,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.4671024e-10 9.9996531e-01 1.4977032e-14 3.4744848e-05 3.3097692e-18], sum to 1.0000
[2019-03-26 15:49:39,831] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2580
[2019-03-26 15:49:39,840] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1990757.232482346 W.
[2019-03-26 15:49:39,843] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.86666666666667, 65.83333333333334, 1.0, 2.0, 0.7826253700974042, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.990183271793105, 6.9112, 168.9124863273192, 1990757.232482346, 1934723.93705162, 404180.7795598186], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6087000.0000, 
sim time next is 6087600.0000, 
raw observation next is [31.0, 65.0, 1.0, 2.0, 0.6787809051244653, 1.0, 1.0, 0.6787809051244653, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1898036.511286278, 1898036.511286277, 365171.9979848497], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.65, 1.0, 1.0, 0.6129890423186329, 1.0, 0.5, 0.6129890423186329, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5272323642461884, 0.5272323642461881, 0.5450328328132085], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03802649], dtype=float32), 1.9976265]. 
=============================================
[2019-03-26 15:49:40,235] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1288040e-20 1.0000000e+00 1.1117326e-21 2.3215164e-22 2.6844117e-29], sum to 1.0000
[2019-03-26 15:49:40,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6516
[2019-03-26 15:49:40,251] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 89.0, 1.0, 2.0, 0.6834732248677882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 955162.9186698908, 955162.9186698901, 217318.3066567561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6069600.0000, 
sim time next is 6070200.0000, 
raw observation next is [27.05, 88.33333333333334, 1.0, 2.0, 0.7015539126984572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 980442.5840683912, 980442.5840683912, 221181.0475966941], 
processed observation next is [1.0, 0.2608695652173913, 0.4810426540284361, 0.8833333333333334, 1.0, 1.0, 0.6404264008415147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2723451622412198, 0.2723451622412198, 0.33012096656223], 
reward next is 0.6699, 
noisyNet noise sample is [array([2.0590427], dtype=float32), -0.7135336]. 
=============================================
[2019-03-26 15:49:40,475] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1154037e-21 1.0000000e+00 1.1099099e-22 2.0582485e-22 2.2210866e-30], sum to 1.0000
[2019-03-26 15:49:40,482] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7644
[2019-03-26 15:49:40,487] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.7299022786947874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020079.30127493, 1020079.30127493, 227431.2087076436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6064200.0000, 
sim time next is 6064800.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.7133067839727418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 996875.2823695963, 996875.2823695963, 223742.9300283698], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6545864867141468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2769098006582212, 0.2769098006582212, 0.333944671684134], 
reward next is 0.6661, 
noisyNet noise sample is [array([-2.47008], dtype=float32), 1.2840785]. 
=============================================
[2019-03-26 15:49:43,811] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 15:49:43,813] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:49:43,814] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:49:43,815] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:49:43,816] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:49:43,816] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:49:43,817] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:49:43,817] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:49:43,818] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:49:43,819] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:49:43,820] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:49:43,844] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 15:49:43,845] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 15:49:43,845] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 15:49:43,888] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 15:49:43,927] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 15:50:04,556] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:50:04,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.63162403, 91.69130913, 1.0, 2.0, 0.4819221915226564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709512.6391475224, 709512.639147523, 185342.9018136197]
[2019-03-26 15:50:04,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:50:04,560] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.11548245e-23 1.00000000e+00 2.52036405e-24 1.00767598e-26
 8.39908420e-33], sampled 0.7156150938564689
[2019-03-26 15:50:21,399] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:50:21,401] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.38333333333333, 94.33333333333334, 1.0, 2.0, 0.6745944939554251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 942749.2668443718, 942749.2668443718, 215457.5680809156]
[2019-03-26 15:50:21,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:50:21,406] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4871215e-23 1.0000000e+00 5.9421405e-24 3.5868599e-26 2.8440413e-32], sampled 0.6503231292697039
[2019-03-26 15:50:25,646] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:50:25,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.65944674, 79.00250277, 1.0, 2.0, 0.4408972452711016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661896.6099014947, 661896.6099014954, 180560.2854188081]
[2019-03-26 15:50:25,648] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:50:25,650] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9861544e-24 1.0000000e+00 8.0441749e-25 4.0622569e-27 2.1668279e-33], sampled 0.3144528539057845
[2019-03-26 15:50:56,083] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:50:56,084] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.218214745, 75.07206311, 1.0, 2.0, 0.5228040241020357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730548.3540262933, 730548.3540262926, 187244.8720592195]
[2019-03-26 15:50:56,084] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:50:56,087] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.8768504e-26 1.0000000e+00 1.9142912e-26 3.6071482e-29 8.7255603e-36], sampled 0.269333055623997
[2019-03-26 15:51:26,564] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:51:26,566] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.03333333333333, 90.66666666666667, 1.0, 2.0, 0.4733658023761965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662661.4765737271, 662661.4765737278, 179685.4985024148]
[2019-03-26 15:51:26,568] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:51:26,571] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6486516e-23 1.0000000e+00 2.3192657e-24 4.5756040e-26 5.0515353e-33], sampled 0.907716723962225
[2019-03-26 15:51:26,903] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01595031], dtype=float32), 0.07585523]
[2019-03-26 15:51:26,905] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.16666666666667, 80.16666666666667, 1.0, 2.0, 0.50004453226819, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711263.0992687366, 711263.0992687372, 185205.4327044014]
[2019-03-26 15:51:26,907] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:51:26,911] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9334920e-24 1.0000000e+00 6.6439453e-25 7.3543065e-28 2.8947507e-33], sampled 0.9364120085791776
[2019-03-26 15:51:37,626] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.8339 3007658724.9324 1766.0000
[2019-03-26 15:51:38,358] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0227 2842637028.6680 1131.0000
[2019-03-26 15:51:38,468] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4820 2779364512.3506 933.0000
[2019-03-26 15:51:38,542] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 15:51:38,615] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.4977 3164153558.8360 1773.0000
[2019-03-26 15:51:39,634] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 800000, evaluation results [800000.0, 7885.497661230149, 3164153558.835973, 1773.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8660.481997960702, 2779364512.3506083, 933.0, 7996.833916076684, 3007658724.9323688, 1766.0, 8496.022712917786, 2842637028.668048, 1131.0]
[2019-03-26 15:51:43,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.65846747e-22 1.00000000e+00 2.72002364e-23 2.50235357e-24
 1.09155105e-32], sum to 1.0000
[2019-03-26 15:51:43,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4321
[2019-03-26 15:51:43,611] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 83.0, 1.0, 2.0, 0.5297764642891541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740294.797110556, 740294.7971105553, 188393.3284024545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6204000.0000, 
sim time next is 6204600.0000, 
raw observation next is [27.75, 83.5, 1.0, 2.0, 0.5296092229843834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740061.0173844877, 740061.0173844884, 188365.6451705839], 
processed observation next is [1.0, 0.8260869565217391, 0.514218009478673, 0.835, 1.0, 1.0, 0.4332641240775703, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20557250482902437, 0.20557250482902456, 0.2811427539859461], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.3937748], dtype=float32), 1.1805633]. 
=============================================
[2019-03-26 15:51:54,041] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.3223538e-25 1.0000000e+00 3.8186877e-26 4.0982094e-28 6.8134132e-35], sum to 1.0000
[2019-03-26 15:51:54,051] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6364
[2019-03-26 15:51:54,057] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.63333333333333, 82.0, 1.0, 2.0, 0.5276148445948841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737273.162009482, 737273.1620094826, 188035.4726312438], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6380400.0000, 
sim time next is 6381000.0000, 
raw observation next is [27.6, 82.0, 1.0, 2.0, 0.5264462443910909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735639.6296786687, 735639.6296786681, 187843.0045480424], 
processed observation next is [0.0, 0.8695652173913043, 0.5071090047393366, 0.82, 1.0, 1.0, 0.4294533064952902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20434434157740797, 0.2043443415774078, 0.2803626933552872], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.18668671], dtype=float32), -0.072279155]. 
=============================================
[2019-03-26 15:51:54,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.84495 ]
 [72.88854 ]
 [72.92809 ]
 [72.942856]
 [72.99242 ]], R is [[72.80347443]
 [72.79479218]
 [72.78591156]
 [72.77688599]
 [72.76797485]].
[2019-03-26 15:51:55,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0916260e-19 1.0000000e+00 3.0000083e-20 5.8845183e-20 6.1456906e-28], sum to 1.0000
[2019-03-26 15:51:55,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1117
[2019-03-26 15:51:55,809] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 86.66666666666667, 1.0, 2.0, 0.7883020372163694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1101738.572785358, 1101738.572785359, 241057.998678459], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6412200.0000, 
sim time next is 6412800.0000, 
raw observation next is [26.73333333333334, 86.33333333333334, 1.0, 2.0, 0.7501327455663231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1048366.467428835, 1048366.467428835, 232036.8900300064], 
processed observation next is [1.0, 0.21739130434782608, 0.4660347551342816, 0.8633333333333334, 1.0, 1.0, 0.6989551151401483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29121290761912083, 0.29121290761912083, 0.34632371646269616], 
reward next is 0.6537, 
noisyNet noise sample is [array([-1.325883], dtype=float32), 0.638834]. 
=============================================
[2019-03-26 15:51:56,457] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.7371438e-19 1.0000000e+00 2.1237647e-20 2.9184981e-20 2.8653911e-28], sum to 1.0000
[2019-03-26 15:51:56,470] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7143
[2019-03-26 15:51:56,475] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 80.0, 1.0, 2.0, 0.7369009601951348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1029865.093325775, 1029865.093325775, 229010.8452252608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6422400.0000, 
sim time next is 6423000.0000, 
raw observation next is [28.0, 79.5, 1.0, 2.0, 0.8306915036831023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161014.891009867, 1161014.891009867, 251582.8259627409], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.795, 1.0, 1.0, 0.7960138598591594, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3225041363916297, 0.3225041363916297, 0.37549675516827], 
reward next is 0.6245, 
noisyNet noise sample is [array([1.7773933], dtype=float32), 1.843156]. 
=============================================
[2019-03-26 15:51:56,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[56.632   ]
 [56.454792]
 [56.18617 ]
 [55.802376]
 [55.94298 ]], R is [[56.30089188]
 [56.3960762 ]
 [56.49360275]
 [56.58671188]
 [56.66638947]].
[2019-03-26 15:52:01,119] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.5873675e-21 1.0000000e+00 4.9246128e-23 2.5484435e-21 1.2331782e-30], sum to 1.0000
[2019-03-26 15:52:01,131] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6364
[2019-03-26 15:52:01,138] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 88.0, 1.0, 2.0, 0.5286159030669341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738672.4974779445, 738672.4974779452, 188201.0023743313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480000.0000, 
sim time next is 6480600.0000, 
raw observation next is [26.86666666666667, 88.33333333333334, 1.0, 2.0, 0.52873246730019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738835.4375962825, 738835.4375962825, 188220.286648948], 
processed observation next is [1.0, 0.0, 0.4723538704581361, 0.8833333333333334, 1.0, 1.0, 0.4322077919279397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20523206599896734, 0.20523206599896734, 0.2809258009685791], 
reward next is 0.7191, 
noisyNet noise sample is [array([0.5347437], dtype=float32), 0.044415895]. 
=============================================
[2019-03-26 15:52:08,384] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5199985e-08 9.9978536e-01 1.2246111e-13 2.1464180e-04 2.0640925e-18], sum to 1.0000
[2019-03-26 15:52:08,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8006
[2019-03-26 15:52:08,401] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2116018.218269332 W.
[2019-03-26 15:52:08,406] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.7566591959577292, 1.0, 2.0, 0.7566591959577292, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2116018.218269332, 2116018.218269332, 399318.0199967035], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6620400.0000, 
sim time next is 6621000.0000, 
raw observation next is [30.5, 66.5, 1.0, 2.0, 0.7569480344184526, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.984358253138049, 6.9112, 168.9125205499539, 1954822.243742333, 1902921.395008699, 398271.0169877176], 
processed observation next is [1.0, 0.6521739130434783, 0.6445497630331753, 0.665, 1.0, 1.0, 0.7071663065282561, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007315825313804858, 0.0, 0.8294378043867766, 0.5430061788173147, 0.5285892763913053, 0.5944343537130113], 
reward next is 0.0398, 
noisyNet noise sample is [array([-0.08774823], dtype=float32), 0.29302114]. 
=============================================
[2019-03-26 15:52:08,431] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[43.356064]
 [41.97864 ]
 [42.11827 ]
 [42.333088]
 [41.88137 ]], R is [[43.31740952]
 [43.28823853]
 [42.85535812]
 [42.42680359]
 [42.35683441]].
[2019-03-26 15:52:09,240] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7851910e-08 9.3508154e-01 7.6101067e-13 6.4918354e-02 1.0082785e-17], sum to 1.0000
[2019-03-26 15:52:09,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0004
[2019-03-26 15:52:09,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1917008.789771986 W.
[2019-03-26 15:52:09,263] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.5, 66.5, 1.0, 2.0, 0.6855597577046275, 1.0, 2.0, 0.6855597577046275, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1917008.789771986, 1917008.789771986, 368001.3063709278], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6621000.0000, 
sim time next is 6621600.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.7772640616283758, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.986692304166349, 6.9112, 168.912507470448, 1983254.072992293, 1929697.376548163, 403010.2507896426], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.7, 1.0, 1.0, 0.7316434477450311, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007549230416634867, 0.0, 0.8294377401604147, 0.5509039091645258, 0.5360270490411564, 0.6015078369994666], 
reward next is 0.0210, 
noisyNet noise sample is [array([-0.6772945], dtype=float32), 1.4836669]. 
=============================================
[2019-03-26 15:52:10,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9082892e-20 1.0000000e+00 2.3416709e-22 4.3117138e-20 8.4638422e-30], sum to 1.0000
[2019-03-26 15:52:10,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7905
[2019-03-26 15:52:10,759] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 92.0, 1.0, 2.0, 0.4950779244460796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 691792.2405812937, 691792.2405812931, 182828.5435305255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6656400.0000, 
sim time next is 6657000.0000, 
raw observation next is [25.43333333333333, 92.33333333333334, 1.0, 2.0, 0.4948652071567946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691494.9054366194, 691494.9054366194, 182795.4937304375], 
processed observation next is [1.0, 0.043478260869565216, 0.40442338072669815, 0.9233333333333335, 1.0, 1.0, 0.3914038640443308, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19208191817683873, 0.19208191817683873, 0.272829095120056], 
reward next is 0.7272, 
noisyNet noise sample is [array([-0.21305265], dtype=float32), 0.9399555]. 
=============================================
[2019-03-26 15:52:10,774] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[65.40363 ]
 [65.47326 ]
 [65.56482 ]
 [65.655754]
 [65.71867 ]], R is [[65.37345886]
 [65.44684601]
 [65.51937866]
 [65.59104919]
 [65.66186523]].
[2019-03-26 15:52:13,059] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.34755609e-07 1.11098528e-01 1.00113304e-13 8.88901412e-01
 4.39660577e-16], sum to 1.0000
[2019-03-26 15:52:13,068] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8102
[2019-03-26 15:52:13,074] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.56666666666667, 67.33333333333334, 1.0, 2.0, 0.7974214535900547, 1.0, 2.0, 0.7974214535900547, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2230127.056402405, 2230127.056402405, 418608.092304984], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6696600.0000, 
sim time next is 6697200.0000, 
raw observation next is [29.63333333333333, 66.66666666666667, 1.0, 2.0, 0.6461555232251407, 1.0, 2.0, 0.6461555232251407, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1806731.091914239, 1806731.091914239, 351917.9741205429], 
processed observation next is [1.0, 0.5217391304347826, 0.6034755134281199, 0.6666666666666667, 1.0, 1.0, 0.573681353283302, 1.0, 1.0, 0.573681353283302, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5018697477539553, 0.5018697477539553, 0.5252507076426013], 
reward next is 0.4747, 
noisyNet noise sample is [array([-0.19676447], dtype=float32), 0.7058775]. 
=============================================
[2019-03-26 15:52:13,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0698681e-23 1.0000000e+00 5.3358757e-24 1.6891314e-25 3.4526133e-31], sum to 1.0000
[2019-03-26 15:52:13,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5292
[2019-03-26 15:52:13,399] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 60.0, 1.0, 2.0, 0.4541582517543982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644943.6896082959, 644943.6896082959, 178059.7220311403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6950400.0000, 
sim time next is 6951000.0000, 
raw observation next is [29.85, 59.5, 1.0, 2.0, 0.4562591219867195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646686.5410719265, 646686.5410719265, 178207.5732842541], 
processed observation next is [0.0, 0.43478260869565216, 0.613744075829384, 0.595, 1.0, 1.0, 0.3448905084177343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17963515029775737, 0.17963515029775737, 0.26598145266306583], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.6584706], dtype=float32), 0.022603083]. 
=============================================
[2019-03-26 15:52:13,408] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.87726]
 [68.83436]
 [68.79827]
 [68.75925]
 [68.70769]], R is [[68.96129608]
 [69.00592041]
 [69.05031586]
 [69.09464264]
 [69.13858032]].
[2019-03-26 15:52:19,144] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.8575683e-15 1.0000000e+00 2.0174505e-17 2.6738353e-13 3.5315102e-24], sum to 1.0000
[2019-03-26 15:52:19,155] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5582
[2019-03-26 15:52:19,162] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333333, 48.5, 1.0, 2.0, 0.8216444717619065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1284039.651333688, 1284039.651333689, 266935.6243135613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6785400.0000, 
sim time next is 6786000.0000, 
raw observation next is [28.9, 48.0, 1.0, 2.0, 0.7420385108998799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1160778.082419593, 1160778.082419593, 245626.6319962632], 
processed observation next is [1.0, 0.5652173913043478, 0.5687203791469194, 0.48, 1.0, 1.0, 0.6892030251805782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3224383562276647, 0.3224383562276647, 0.3666069134272585], 
reward next is 0.6334, 
noisyNet noise sample is [array([1.7322192], dtype=float32), 1.2401131]. 
=============================================
[2019-03-26 15:52:19,176] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[56.492176]
 [56.508965]
 [56.481518]
 [56.066616]
 [55.75437 ]], R is [[57.03178024]
 [57.06305313]
 [57.09632111]
 [57.14320374]
 [57.17502213]].
[2019-03-26 15:52:20,022] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3479796e-15 1.0000000e+00 2.0642522e-18 5.1583754e-14 5.6338272e-25], sum to 1.0000
[2019-03-26 15:52:20,031] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8581
[2019-03-26 15:52:20,039] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.31666666666667, 46.66666666666667, 1.0, 2.0, 0.985090117182746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1538419.695313547, 1538419.695313547, 317393.348743286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6792600.0000, 
sim time next is 6793200.0000, 
raw observation next is [29.3, 47.0, 1.0, 2.0, 0.9482753016335264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1478974.296279009, 1478974.296279009, 305009.4952735879], 
processed observation next is [1.0, 0.6521739130434783, 0.5876777251184835, 0.47, 1.0, 1.0, 0.9376810863054534, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4108261934108358, 0.4108261934108358, 0.45523805264714606], 
reward next is 0.5448, 
noisyNet noise sample is [array([0.74568665], dtype=float32), -2.3275032]. 
=============================================
[2019-03-26 15:52:29,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1999529e-26 1.0000000e+00 5.3445049e-27 4.3445523e-28 2.1288678e-34], sum to 1.0000
[2019-03-26 15:52:29,652] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9050
[2019-03-26 15:52:29,657] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 52.0, 1.0, 2.0, 0.4366154791352491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 629839.3270420604, 629839.3270420597, 176800.3774165596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6962400.0000, 
sim time next is 6963000.0000, 
raw observation next is [31.08333333333333, 52.0, 1.0, 2.0, 0.4351438101654626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626252.4519089366, 626252.4519089366, 176405.8876938332], 
processed observation next is [0.0, 0.6086956521739131, 0.6721958925750393, 0.52, 1.0, 1.0, 0.31945037369332846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17395901441914904, 0.17395901441914904, 0.26329236969228836], 
reward next is 0.7367, 
noisyNet noise sample is [array([-0.4516623], dtype=float32), 0.64685345]. 
=============================================
[2019-03-26 15:52:29,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[78.15433 ]
 [77.99465 ]
 [77.871956]
 [77.75948 ]
 [77.66361 ]], R is [[78.22116089]
 [78.17507172]
 [78.12858582]
 [78.08175659]
 [78.03488159]].
[2019-03-26 15:52:33,130] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9360204e-19 1.0000000e+00 4.1276894e-21 2.3536122e-19 5.9402956e-27], sum to 1.0000
[2019-03-26 15:52:33,139] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0101
[2019-03-26 15:52:33,145] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 87.66666666666667, 1.0, 2.0, 0.5912425696324287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841688.2798063053, 841688.2798063053, 201117.7585156127], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7015800.0000, 
sim time next is 7016400.0000, 
raw observation next is [25.0, 88.0, 1.0, 2.0, 0.5832156894620328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 830408.377166842, 830408.3771668413, 199641.8364603053], 
processed observation next is [1.0, 0.21739130434782608, 0.38388625592417064, 0.88, 1.0, 1.0, 0.4978502282675094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2306689936574561, 0.2306689936574559, 0.2979728902392616], 
reward next is 0.7020, 
noisyNet noise sample is [array([-0.23220092], dtype=float32), -0.83633286]. 
=============================================
[2019-03-26 15:52:35,768] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 15:52:35,769] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:52:35,770] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:52:35,771] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:52:35,771] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:52:35,772] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:52:35,772] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:52:35,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:52:35,774] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:52:35,776] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:52:35,780] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:52:35,799] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 15:52:35,823] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 15:52:35,824] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 15:52:35,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 15:52:35,873] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 15:52:57,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:52:57,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.81890172833333, 97.93591019833335, 1.0, 2.0, 0.2544911960074759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 420047.5660965089, 420047.5660965089, 161309.0072709279]
[2019-03-26 15:52:57,540] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:52:57,543] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.5834812e-22 1.0000000e+00 2.1367064e-23 4.9817314e-23 3.1143253e-31], sampled 0.5296251599558097
[2019-03-26 15:53:08,283] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:53:08,285] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.9, 94.0, 1.0, 2.0, 0.3939585781457351, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 589925.0083531912, 589925.0083531918, 173672.779075377]
[2019-03-26 15:53:08,287] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:53:08,289] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7989284e-21 1.0000000e+00 8.6691169e-23 4.4892703e-22 1.6425692e-30], sampled 0.6034528087408573
[2019-03-26 15:53:35,564] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:53:35,566] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.5, 69.0, 1.0, 2.0, 0.6099288036292395, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104269, 852342.3702305679, 852342.3702305679, 202613.2304679008]
[2019-03-26 15:53:35,567] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:53:35,569] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3060215e-15 1.0000000e+00 2.2314929e-20 2.1297599e-09 1.2341555e-25], sampled 0.003096567980412024
[2019-03-26 15:53:36,786] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:53:36,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.90874015333333, 84.89546202666668, 1.0, 2.0, 0.6390171040255053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 893008.7788582112, 893008.7788582119, 208239.1704126186]
[2019-03-26 15:53:36,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:53:36,789] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.147784e-20 1.000000e+00 5.829305e-22 4.750563e-20 1.783680e-29], sampled 0.567246665519804
[2019-03-26 15:53:59,307] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:53:59,308] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.073331765, 89.53828537000001, 1.0, 2.0, 0.4479586504339627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642194.7920791992, 642194.7920791992, 177935.1046863721]
[2019-03-26 15:53:59,309] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:53:59,315] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3173323e-21 1.0000000e+00 6.1515468e-23 3.9640043e-22 1.3206170e-30], sampled 0.5788386384476698
[2019-03-26 15:54:08,082] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:54:08,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.6724173, 88.66845923, 1.0, 2.0, 0.77434777694318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1104142.379697579, 1104142.379697579, 240744.9871442847]
[2019-03-26 15:54:08,086] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:54:08,095] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5685938e-18 1.0000000e+00 2.7748081e-20 2.4825007e-17 1.3772878e-26], sampled 0.2973107326359714
[2019-03-26 15:54:26,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01117133], dtype=float32), 0.0799987]
[2019-03-26 15:54:26,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.05114677666667, 90.18666501000001, 1.0, 2.0, 0.7718834035041889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078780.075009008, 1078780.075009008, 237124.3765827123]
[2019-03-26 15:54:26,172] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:54:26,178] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.6411642e-20 1.0000000e+00 2.2676359e-21 2.1308817e-20 2.5847280e-28], sampled 0.19511201252585553
[2019-03-26 15:54:29,517] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7978.3739 3154953884.3783 1547.0000
[2019-03-26 15:54:29,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.1488 2778192750.4382 902.0000
[2019-03-26 15:54:29,715] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8046.4138 3002756100.0798 1645.0000
[2019-03-26 15:54:29,967] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8283.5684 2925311259.2501 1275.0000
[2019-03-26 15:54:30,116] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.8607 2839988395.2071 1067.0000
[2019-03-26 15:54:31,131] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 825000, evaluation results [825000.0, 7978.373859834038, 3154953884.378267, 1547.0, 8283.568400270817, 2925311259.2500534, 1275.0, 8671.148845815069, 2778192750.4381957, 902.0, 8046.4137722325, 3002756100.079781, 1645.0, 8519.860655521972, 2839988395.207094, 1067.0]
[2019-03-26 15:54:31,970] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.2351366e-20 1.0000000e+00 3.2358814e-22 3.6387168e-20 1.7483666e-29], sum to 1.0000
[2019-03-26 15:54:31,980] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5657
[2019-03-26 15:54:31,989] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 73.83333333333334, 1.0, 2.0, 0.3854389143278537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581655.8441599511, 581655.8441599518, 173056.399844698], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7332600.0000, 
sim time next is 7333200.0000, 
raw observation next is [25.4, 74.0, 1.0, 2.0, 0.3807836591491494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575343.7028946707, 575343.7028946707, 172514.4012383298], 
processed observation next is [1.0, 0.9130434782608695, 0.4028436018957346, 0.74, 1.0, 1.0, 0.2539562158423487, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15981769524851963, 0.15981769524851963, 0.257484180952731], 
reward next is 0.7425, 
noisyNet noise sample is [array([0.26668712], dtype=float32), -0.68477595]. 
=============================================
[2019-03-26 15:54:35,958] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3171091e-08 2.9962964e-02 8.0219211e-14 9.7003704e-01 1.2680936e-17], sum to 1.0000
[2019-03-26 15:54:35,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1320
[2019-03-26 15:54:35,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.11666666666667, 85.66666666666667, 1.0, 2.0, 0.4032198806702673, 1.0, 2.0, 0.4032198806702673, 1.0, 1.0, 0.6812054348064129, 6.9112, 6.9112, 170.5573041426782, 1691088.117243168, 1691088.117243168, 351931.6166297586], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7145400.0000, 
sim time next is 7146000.0000, 
raw observation next is [26.1, 86.0, 1.0, 2.0, 0.535232489976926, 1.0, 2.0, 0.535232489976926, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1496359.980998039, 1496359.980998039, 311552.1640001168], 
processed observation next is [1.0, 0.7391304347826086, 0.4360189573459717, 0.86, 1.0, 1.0, 0.4400391445505132, 1.0, 1.0, 0.4400391445505132, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.41565555027723305, 0.41565555027723305, 0.46500322985092063], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1031684], dtype=float32), -0.21534671]. 
=============================================
[2019-03-26 15:54:35,991] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[51.034115]
 [52.007683]
 [51.748627]
 [53.45427 ]
 [54.82694 ]], R is [[52.21211243]
 [51.689991  ]
 [51.66695786]
 [51.59933853]
 [51.08334732]].
[2019-03-26 15:54:39,729] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5125155e-21 1.0000000e+00 1.7806806e-23 8.4707889e-22 1.0339025e-30], sum to 1.0000
[2019-03-26 15:54:39,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2127
[2019-03-26 15:54:39,743] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.61666666666667, 89.83333333333333, 1.0, 2.0, 0.3282927001426869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517834.9143904585, 517834.9143904591, 168359.0085167426], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7271400.0000, 
sim time next is 7272000.0000, 
raw observation next is [21.6, 90.0, 1.0, 2.0, 0.3282137759430772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517660.6663926761, 517660.6663926768, 168344.5824127825], 
processed observation next is [1.0, 0.17391304347826086, 0.22274881516587688, 0.9, 1.0, 1.0, 0.19061900716033398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14379462955352115, 0.14379462955352135, 0.251260570765347], 
reward next is 0.7487, 
noisyNet noise sample is [array([-1.7757711], dtype=float32), 0.2904501]. 
=============================================
[2019-03-26 15:54:39,752] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.78375 ]
 [69.78387 ]
 [69.79866 ]
 [69.87518 ]
 [69.888664]], R is [[69.81298828]
 [69.8635788 ]
 [69.91314697]
 [69.96128082]
 [70.00919342]].
[2019-03-26 15:54:47,524] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.943516e-23 1.000000e+00 7.498850e-26 1.047647e-23 8.500647e-34], sum to 1.0000
[2019-03-26 15:54:47,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0178
[2019-03-26 15:54:47,543] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 73.5, 1.0, 2.0, 0.3878582133267932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 583848.2853143984, 583848.285314399, 173211.2121714892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7331400.0000, 
sim time next is 7332000.0000, 
raw observation next is [25.53333333333333, 73.66666666666666, 1.0, 2.0, 0.3868699793266774, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583089.1592438482, 583089.1592438476, 173164.1113373199], 
processed observation next is [1.0, 0.8695652173913043, 0.4091627172195892, 0.7366666666666666, 1.0, 1.0, 0.2612891317188884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16196921090106894, 0.16196921090106878, 0.2584538975183879], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.45596495], dtype=float32), -0.6192274]. 
=============================================
[2019-03-26 15:54:47,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.74808 ]
 [79.696976]
 [79.63587 ]
 [79.56743 ]
 [79.30412 ]], R is [[79.71897125]
 [79.66326141]
 [79.60800934]
 [79.55318451]
 [79.49888611]].
[2019-03-26 15:54:47,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0440076e-23 1.0000000e+00 3.2386058e-25 1.0519159e-23 4.2949085e-33], sum to 1.0000
[2019-03-26 15:54:47,874] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8412
[2019-03-26 15:54:47,882] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 74.5, 1.0, 2.0, 0.4143424388512938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636987.9260370054, 636987.9260370047, 178372.5192024837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7353000.0000, 
sim time next is 7353600.0000, 
raw observation next is [24.66666666666666, 75.33333333333333, 1.0, 2.0, 0.4143900331792998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636312.9102827344, 636312.9102827339, 178298.6179107785], 
processed observation next is [1.0, 0.08695652173913043, 0.36808846761453373, 0.7533333333333333, 1.0, 1.0, 0.2944458231075901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17675358618964845, 0.1767535861896483, 0.26611734016534105], 
reward next is 0.7339, 
noisyNet noise sample is [array([0.07508083], dtype=float32), 0.28002664]. 
=============================================
[2019-03-26 15:54:52,238] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3628924e-21 1.0000000e+00 1.3315431e-23 1.7496815e-21 2.0062543e-31], sum to 1.0000
[2019-03-26 15:54:52,244] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5450
[2019-03-26 15:54:52,250] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.01666666666667, 94.83333333333334, 1.0, 2.0, 0.3180759226206301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501596.6726288902, 501596.6726288902, 167116.5945697944], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7427400.0000, 
sim time next is 7428000.0000, 
raw observation next is [21.03333333333333, 94.66666666666667, 1.0, 2.0, 0.3187621316488384, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 502701.3248446704, 502701.3248446711, 167200.2811768486], 
processed observation next is [1.0, 1.0, 0.19589257503949445, 0.9466666666666668, 1.0, 1.0, 0.1792314839142631, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13963925690129733, 0.13963925690129753, 0.24955265847290836], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.2830659], dtype=float32), 0.68755066]. 
=============================================
[2019-03-26 15:54:52,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.182175]
 [78.169716]
 [78.124886]
 [78.109825]
 [78.090805]], R is [[78.1541214 ]
 [78.12315369]
 [78.09264374]
 [78.06263733]
 [78.03308105]].
[2019-03-26 15:54:55,385] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2208244e-22 1.0000000e+00 1.8756854e-24 3.5366755e-23 2.2112270e-32], sum to 1.0000
[2019-03-26 15:54:55,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3620
[2019-03-26 15:54:55,398] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 86.33333333333334, 1.0, 2.0, 0.4027598588474285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594720.212489671, 594720.2124896715, 173864.3419595282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7504800.0000, 
sim time next is 7505400.0000, 
raw observation next is [24.25, 86.66666666666666, 1.0, 2.0, 0.4034057216550294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 595765.460110381, 595765.4601103804, 173964.466860212], 
processed observation next is [0.0, 0.8695652173913043, 0.3483412322274882, 0.8666666666666666, 1.0, 1.0, 0.28121171283738483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16549040558621694, 0.16549040558621678, 0.25964845800031644], 
reward next is 0.7404, 
noisyNet noise sample is [array([-0.21445271], dtype=float32), 0.629354]. 
=============================================
[2019-03-26 15:54:55,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8858983e-24 1.0000000e+00 1.1861522e-24 3.7473587e-25 1.0970111e-32], sum to 1.0000
[2019-03-26 15:54:55,512] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5273
[2019-03-26 15:54:55,519] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 77.66666666666667, 1.0, 2.0, 0.4154238338477537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 606714.721921772, 606714.7219217714, 174781.5986146753], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7485000.0000, 
sim time next is 7485600.0000, 
raw observation next is [25.93333333333334, 77.33333333333334, 1.0, 2.0, 0.4157669626163324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 606869.831827706, 606869.8318277065, 174785.830363647], 
processed observation next is [0.0, 0.6521739130434783, 0.42812006319115364, 0.7733333333333334, 1.0, 1.0, 0.2961047742365451, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16857495328547387, 0.16857495328547403, 0.26087437367708505], 
reward next is 0.7391, 
noisyNet noise sample is [array([-1.1970325], dtype=float32), 1.4006866]. 
=============================================
[2019-03-26 15:55:09,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.6256662e-08 5.2953184e-01 4.1850291e-12 4.7046810e-01 7.5763444e-16], sum to 1.0000
[2019-03-26 15:55:09,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3160
[2019-03-26 15:55:09,729] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1963888.287781478 W.
[2019-03-26 15:55:09,738] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.81666666666667, 76.83333333333333, 1.0, 2.0, 0.7023094296092415, 1.0, 2.0, 0.7023094296092415, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1963888.287781478, 1963888.287781478, 375112.898500872], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7722600.0000, 
sim time next is 7723200.0000, 
raw observation next is [29.03333333333333, 75.66666666666667, 1.0, 2.0, 0.7016633908505452, 1.0, 2.0, 0.7016633908505452, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1962080.096556378, 1962080.096556378, 374835.7127806216], 
processed observation next is [1.0, 0.391304347826087, 0.5750394944707741, 0.7566666666666667, 1.0, 1.0, 0.6405583022295726, 1.0, 1.0, 0.6405583022295726, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5450222490434383, 0.5450222490434383, 0.5594562877322711], 
reward next is 0.4405, 
noisyNet noise sample is [array([-0.7631533], dtype=float32), 0.03488987]. 
=============================================
[2019-03-26 15:55:10,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:10,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:10,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 15:55:11,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.9120513e-21 1.0000000e+00 1.5280900e-23 9.3453541e-21 3.2430342e-31], sum to 1.0000
[2019-03-26 15:55:11,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9322
[2019-03-26 15:55:11,385] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 79.66666666666667, 1.0, 2.0, 0.5096494993358043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712160.5119462757, 712160.5119462751, 185122.2775402692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7759200.0000, 
sim time next is 7759800.0000, 
raw observation next is [27.7, 81.0, 1.0, 2.0, 0.5111447883724254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714250.6617795123, 714250.6617795129, 185361.1814248074], 
processed observation next is [1.0, 0.8260869565217391, 0.5118483412322274, 0.81, 1.0, 1.0, 0.41101781731617515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1984029616054201, 0.19840296160542026, 0.27665847973851854], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.49193645], dtype=float32), 1.4396027]. 
=============================================
[2019-03-26 15:55:12,716] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8174071e-18 1.0000000e+00 5.4963056e-20 5.5958719e-18 1.4228022e-27], sum to 1.0000
[2019-03-26 15:55:12,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7882
[2019-03-26 15:55:12,733] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.03333333333333, 84.50000000000001, 1.0, 2.0, 0.7565199476128736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1057297.502628378, 1057297.502628377, 233516.4975966799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7801800.0000, 
sim time next is 7802400.0000, 
raw observation next is [27.16666666666666, 84.0, 1.0, 2.0, 0.6687241109450456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 934541.766919579, 934541.766919579, 214237.9198633613], 
processed observation next is [1.0, 0.30434782608695654, 0.4865718799368086, 0.84, 1.0, 1.0, 0.6008724228253561, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2595949352554386, 0.2595949352554386, 0.31975808934830047], 
reward next is 0.6802, 
noisyNet noise sample is [array([-0.10562276], dtype=float32), 0.3280174]. 
=============================================
[2019-03-26 15:55:14,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2750948e-19 1.0000000e+00 1.3717655e-20 1.2928810e-17 5.9579938e-28], sum to 1.0000
[2019-03-26 15:55:14,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2580
[2019-03-26 15:55:14,141] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 85.0, 1.0, 2.0, 0.616453280075016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861463.6692218971, 861463.6692218971, 203843.7886059519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7801200.0000, 
sim time next is 7801800.0000, 
raw observation next is [27.03333333333333, 84.50000000000001, 1.0, 2.0, 0.7565199476128736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1057297.502628378, 1057297.502628377, 233516.4975966799], 
processed observation next is [1.0, 0.30434782608695654, 0.48025276461295413, 0.8450000000000002, 1.0, 1.0, 0.7066505392926187, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.293693750730105, 0.29369375073010473, 0.34853208596519386], 
reward next is 0.6515, 
noisyNet noise sample is [array([-0.33235347], dtype=float32), 1.2238662]. 
=============================================
[2019-03-26 15:55:16,563] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.57646679e-18 1.00000000e+00 3.29893578e-22 1.22631575e-14
 3.09046967e-29], sum to 1.0000
[2019-03-26 15:55:16,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9870
[2019-03-26 15:55:16,579] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 74.0, 1.0, 2.0, 0.4928451999166115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688671.3537416244, 688671.3537416244, 182485.4856955149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7839600.0000, 
sim time next is 7840200.0000, 
raw observation next is [29.15, 75.0, 1.0, 2.0, 0.5050928964992552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705791.2117622566, 705791.2117622559, 184400.0357896447], 
processed observation next is [1.0, 0.7391304347826086, 0.5805687203791469, 0.75, 1.0, 1.0, 0.40372638132440375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1960531143784046, 0.19605311437840442, 0.27522393401439504], 
reward next is 0.7248, 
noisyNet noise sample is [array([0.01052324], dtype=float32), 1.3268223]. 
=============================================
[2019-03-26 15:55:16,911] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.9805797e-09 9.5430344e-01 5.7273745e-14 4.5696564e-02 9.6742764e-19], sum to 1.0000
[2019-03-26 15:55:16,921] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3536
[2019-03-26 15:55:16,932] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2215678.946027534 W.
[2019-03-26 15:55:16,937] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.08333333333333, 68.83333333333333, 1.0, 2.0, 0.9433259579276713, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984111241960394, 6.9112, 168.9124638871091, 2215678.946027534, 2163953.352424216, 447149.4681224205], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7836600.0000, 
sim time next is 7837200.0000, 
raw observation next is [29.9, 70.0, 1.0, 2.0, 0.7334528859944893, 1.0, 1.0, 0.7334528859944893, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2051059.006855995, 2051059.006855995, 388771.467341709], 
processed observation next is [1.0, 0.7391304347826086, 0.6161137440758293, 0.7, 1.0, 1.0, 0.6788588987885413, 1.0, 0.5, 0.6788588987885413, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5697386130155542, 0.5697386130155542, 0.5802559214055358], 
reward next is 0.4197, 
noisyNet noise sample is [array([-0.1631522], dtype=float32), 1.6533486]. 
=============================================
[2019-03-26 15:55:20,456] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2537397e-08 1.4185405e-01 6.1703735e-14 8.5814583e-01 2.8297660e-17], sum to 1.0000
[2019-03-26 15:55:20,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1704
[2019-03-26 15:55:20,470] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.76666666666667, 72.0, 1.0, 2.0, 0.7024006909744915, 1.0, 2.0, 0.7024006909744915, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1964143.718522347, 1964143.718522347, 375152.9423951945], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7905000.0000, 
sim time next is 7905600.0000, 
raw observation next is [29.8, 72.0, 1.0, 2.0, 0.7639320949303093, 1.0, 2.0, 0.7639320949303093, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2136377.361850934, 2136377.361850934, 402692.1403711784], 
processed observation next is [1.0, 0.5217391304347826, 0.6113744075829385, 0.72, 1.0, 1.0, 0.7155808372654329, 1.0, 1.0, 0.7155808372654329, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.593438156069704, 0.593438156069704, 0.601033045330117], 
reward next is 0.3990, 
noisyNet noise sample is [array([-0.61637926], dtype=float32), -0.6366341]. 
=============================================
[2019-03-26 15:55:21,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:21,068] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:21,106] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 15:55:22,407] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6672229e-20 1.0000000e+00 6.2381575e-22 3.2002481e-20 1.1221450e-30], sum to 1.0000
[2019-03-26 15:55:22,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3624
[2019-03-26 15:55:22,416] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.8, 82.33333333333334, 1.0, 2.0, 0.5236551086158481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731738.0398667025, 731738.0398667025, 187385.8173370538], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7935600.0000, 
sim time next is 7936200.0000, 
raw observation next is [27.7, 83.0, 1.0, 2.0, 0.5248873486146212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733460.5250773531, 733460.5250773531, 187587.6723508576], 
processed observation next is [1.0, 0.8695652173913043, 0.5118483412322274, 0.83, 1.0, 1.0, 0.42757511881279653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2037390347437092, 0.2037390347437092, 0.27998160052366805], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.45072204], dtype=float32), 2.4075048]. 
=============================================
[2019-03-26 15:55:22,488] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:22,489] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:22,524] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 15:55:22,556] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:22,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:22,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 15:55:22,979] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:22,980] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:22,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 15:55:23,116] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,118] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 15:55:23,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 15:55:23,351] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,351] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,354] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 15:55:23,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,387] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 15:55:23,651] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,664] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 15:55:23,692] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,693] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,700] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 15:55:23,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,723] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,726] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 15:55:23,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 15:55:23,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,818] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,821] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 15:55:23,843] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,843] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,850] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 15:55:23,850] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:23,851] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 15:55:23,893] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 15:55:26,556] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 15:55:26,559] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:55:26,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:26,561] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:55:26,564] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:55:26,564] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:26,566] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:55:26,566] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:26,569] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:26,568] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:55:26,573] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:55:26,589] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 15:55:26,589] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 15:55:26,626] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 15:55:26,628] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 15:55:26,667] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 15:55:57,170] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:55:57,171] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.7, 91.0, 1.0, 2.0, 0.46136816560868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654541.0360528758, 654541.0360528758, 179035.4703364913]
[2019-03-26 15:55:57,172] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:55:57,175] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9596479e-24 1.0000000e+00 4.1020321e-25 1.4671173e-25 3.8334006e-33], sampled 0.7401695132423093
[2019-03-26 15:55:57,324] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:55:57,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.66666666666666, 87.33333333333333, 1.0, 2.0, 0.5121627211644103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715673.554291611, 715673.5542916103, 185523.8814697156]
[2019-03-26 15:55:57,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:55:57,328] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3342787e-23 1.0000000e+00 8.3360450e-25 1.2108164e-24 8.0375477e-33], sampled 0.8896047597763004
[2019-03-26 15:56:01,608] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:56:01,611] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.54616265666667, 56.94111688333334, 1.0, 2.0, 0.585061969052813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 821909.2696598896, 821909.2696598902, 198550.7728654713]
[2019-03-26 15:56:01,612] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:56:01,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3267339e-23 1.0000000e+00 1.7541229e-24 3.2101699e-24 2.1283341e-32], sampled 0.09628419426429247
[2019-03-26 15:56:02,523] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:56:02,524] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.58333333333334, 91.50000000000001, 1.0, 2.0, 0.3760839017020343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574905.8748471204, 574905.8748471204, 172664.8151896879]
[2019-03-26 15:56:02,524] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 15:56:02,527] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5649932e-22 1.0000000e+00 1.1412037e-23 1.0086241e-22 1.0075619e-31], sampled 0.7417137799882229
[2019-03-26 15:56:36,678] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:56:36,680] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.58574683, 89.22399589, 1.0, 2.0, 0.4062916223178236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 607765.4094609423, 607765.409460943, 175294.1977390009]
[2019-03-26 15:56:36,681] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:56:36,683] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8750435e-22 1.0000000e+00 6.8823886e-24 9.6388718e-23 5.8848639e-32], sampled 0.16158453187601662
[2019-03-26 15:56:47,547] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00623593], dtype=float32), 0.08973625]
[2019-03-26 15:56:47,548] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.48333333333333, 94.83333333333334, 1.0, 2.0, 0.6297414286600045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880040.9079865068, 880040.9079865068, 206417.4029140671]
[2019-03-26 15:56:47,552] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:56:47,554] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9294671e-22 1.0000000e+00 8.4123015e-24 4.2754635e-22 9.2690745e-32], sampled 0.6624153754974808
[2019-03-26 15:57:21,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8012.4531 3005985659.5396 1725.0000
[2019-03-26 15:57:21,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.9038 2778970320.6669 923.0000
[2019-03-26 15:57:21,767] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.8934 2841398738.1087 1105.0000
[2019-03-26 15:57:21,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.8486 2926911648.3612 1326.0000
[2019-03-26 15:57:21,986] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7930.3590 3159547674.7303 1662.0000
[2019-03-26 15:57:23,001] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 850000, evaluation results [850000.0, 7930.3590306085425, 3159547674.730279, 1662.0, 8261.84862378438, 2926911648.3612404, 1326.0, 8664.903771108935, 2778970320.6669455, 923.0, 8012.453064281452, 3005985659.5395894, 1725.0, 8502.893387952981, 2841398738.1086974, 1105.0]
[2019-03-26 15:57:38,300] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.95913432e-24 1.00000000e+00 4.31183482e-25 1.23457394e-26
 2.79466509e-33], sum to 1.0000
[2019-03-26 15:57:38,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-26 15:57:38,318] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 90.66666666666667, 1.0, 2.0, 0.2773877877685151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 448052.7956005751, 448052.7956005757, 163469.7129210312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 282000.0000, 
sim time next is 282600.0000, 
raw observation next is [20.55, 90.0, 1.0, 2.0, 0.2790752241858487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 450205.4066099429, 450205.4066099423, 163613.9061713835], 
processed observation next is [0.0, 0.2608695652173913, 0.17298578199052142, 0.9, 1.0, 1.0, 0.13141593275403454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1250570573916508, 0.12505705739165066, 0.24419985995728882], 
reward next is 0.7558, 
noisyNet noise sample is [array([0.11643864], dtype=float32), -0.096150964]. 
=============================================
[2019-03-26 15:57:43,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.0252585e-20 1.0000000e+00 4.6933680e-22 7.6685412e-19 2.5052030e-29], sum to 1.0000
[2019-03-26 15:57:43,646] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8699
[2019-03-26 15:57:43,651] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 75.0, 1.0, 2.0, 0.4802929978796964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772164.0973032619, 772164.0973032626, 191668.8623320326], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 398400.0000, 
sim time next is 399000.0000, 
raw observation next is [22.65, 75.5, 1.0, 2.0, 0.500781793906928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 804724.0981767258, 804724.0981767265, 195251.5084414976], 
processed observation next is [1.0, 0.6086956521739131, 0.2725118483412322, 0.755, 1.0, 1.0, 0.3985322818155759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22353447171575716, 0.22353447171575735, 0.2914201618529815], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.93260175], dtype=float32), 1.2208002]. 
=============================================
[2019-03-26 15:57:43,667] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.66885 ]
 [70.8825  ]
 [70.451065]
 [69.96653 ]
 [70.04246 ]], R is [[70.41804504]
 [70.42779541]
 [70.45791626]
 [70.48291779]
 [70.48306274]].
[2019-03-26 15:57:55,596] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8091081e-16 1.0000000e+00 1.8717161e-19 8.6607230e-15 6.4852095e-26], sum to 1.0000
[2019-03-26 15:57:55,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7386
[2019-03-26 15:57:55,611] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333334, 60.33333333333333, 1.0, 2.0, 0.7576476266142503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1239955.634815671, 1239955.63481567, 253664.6309543703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 571200.0000, 
sim time next is 571800.0000, 
raw observation next is [23.81666666666667, 60.66666666666666, 1.0, 2.0, 0.7596594214233054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1242601.624228484, 1242601.624228484, 254190.4673776444], 
processed observation next is [1.0, 0.6086956521739131, 0.3278041074249607, 0.6066666666666666, 1.0, 1.0, 0.7104330378594041, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34516711784124554, 0.34516711784124554, 0.37938875728006627], 
reward next is 0.6206, 
noisyNet noise sample is [array([0.27775806], dtype=float32), -1.3865813]. 
=============================================
[2019-03-26 15:57:56,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.1832526e-21 1.0000000e+00 1.1754420e-22 1.0731441e-19 3.6945614e-30], sum to 1.0000
[2019-03-26 15:57:56,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-26 15:57:56,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 68.5, 1.0, 2.0, 0.2563244028885566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420623.2616607983, 420623.2616607989, 161540.6153842802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 585000.0000, 
sim time next is 585600.0000, 
raw observation next is [22.16666666666666, 69.0, 1.0, 2.0, 0.2550291931835963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418790.1225689863, 418790.1225689856, 161410.4931594187], 
processed observation next is [1.0, 0.782608695652174, 0.24960505529225885, 0.69, 1.0, 1.0, 0.10244481106457384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1163305896024962, 0.11633058960249601, 0.2409111838200279], 
reward next is 0.7591, 
noisyNet noise sample is [array([1.055912], dtype=float32), 1.8344661]. 
=============================================
[2019-03-26 15:58:02,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6578935e-20 1.0000000e+00 2.4200619e-22 5.8813285e-21 1.8672626e-30], sum to 1.0000
[2019-03-26 15:58:02,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7102
[2019-03-26 15:58:02,278] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.38333333333333, 84.66666666666667, 1.0, 2.0, 0.2412925513793596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 399165.0872869539, 399165.0872869533, 159963.1122620658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 684600.0000, 
sim time next is 685200.0000, 
raw observation next is [19.26666666666667, 85.33333333333334, 1.0, 2.0, 0.2412295990922571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 399198.2861125637, 399198.2861125631, 159946.3948381975], 
processed observation next is [1.0, 0.9565217391304348, 0.1121642969984204, 0.8533333333333334, 1.0, 1.0, 0.08581879408705674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11088841280904546, 0.11088841280904531, 0.2387259624450709], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.40188265], dtype=float32), -1.7613437]. 
=============================================
[2019-03-26 15:58:02,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1839348e-22 1.0000000e+00 3.6545117e-24 2.1477385e-23 6.6428320e-32], sum to 1.0000
[2019-03-26 15:58:02,461] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1142
[2019-03-26 15:58:02,469] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.56666666666667, 92.0, 1.0, 2.0, 0.2219362550021812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 370005.9444047123, 370005.9444047123, 157681.2467350347], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 706800.0000, 
sim time next is 707400.0000, 
raw observation next is [17.55, 92.0, 1.0, 2.0, 0.2250363663102666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 375212.4245053321, 375212.4245053321, 157944.9050268299], 
processed observation next is [1.0, 0.17391304347826086, 0.03080568720379157, 0.92, 1.0, 1.0, 0.06630887507261035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10422567347370336, 0.10422567347370336, 0.23573866421914907], 
reward next is 0.7643, 
noisyNet noise sample is [array([-1.86035], dtype=float32), -1.4760406]. 
=============================================
[2019-03-26 15:58:02,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7738880e-22 1.0000000e+00 2.6815133e-23 7.5697034e-24 7.2961449e-31], sum to 1.0000
[2019-03-26 15:58:02,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-26 15:58:02,901] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.71666666666667, 91.0, 1.0, 2.0, 0.2173594940760535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 362380.1638334922, 362380.1638334916, 157278.1722491333], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 709800.0000, 
sim time next is 710400.0000, 
raw observation next is [17.93333333333333, 90.0, 1.0, 2.0, 0.2147865918908541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 357865.0006242922, 357865.0006242922, 157127.2389302956], 
processed observation next is [1.0, 0.21739130434782608, 0.04897314375987352, 0.9, 1.0, 1.0, 0.05395974926608928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.09940694461785894, 0.09940694461785894, 0.2345182670601427], 
reward next is 0.7655, 
noisyNet noise sample is [array([-1.1460712], dtype=float32), 1.2875098]. 
=============================================
[2019-03-26 15:58:07,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0326149e-24 1.0000000e+00 4.6149600e-25 1.0623223e-26 2.5080858e-33], sum to 1.0000
[2019-03-26 15:58:07,617] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6454
[2019-03-26 15:58:07,623] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 76.5, 1.0, 2.0, 0.287851958334223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461785.5987357184, 461785.5987357184, 164387.0768557938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 808200.0000, 
sim time next is 808800.0000, 
raw observation next is [22.76666666666667, 75.33333333333334, 1.0, 2.0, 0.287771708005965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461659.387396554, 461659.3873965534, 164378.4425637016], 
processed observation next is [0.0, 0.34782608695652173, 0.2780410742496052, 0.7533333333333334, 1.0, 1.0, 0.1418936241035723, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.128238718721265, 0.12823871872126483, 0.2453409590503009], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.03193381], dtype=float32), 0.32878485]. 
=============================================
[2019-03-26 15:58:10,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3828696e-24 1.0000000e+00 1.0949455e-25 1.4139672e-26 1.9057377e-33], sum to 1.0000
[2019-03-26 15:58:10,579] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3513
[2019-03-26 15:58:10,587] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 62.16666666666667, 1.0, 2.0, 0.28930423503913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463132.4665881591, 463132.4665881597, 164470.3522888233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 821400.0000, 
sim time next is 822000.0000, 
raw observation next is [24.93333333333333, 62.33333333333334, 1.0, 2.0, 0.2889146941406687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462546.0055829607, 462546.0055829613, 164430.3787668172], 
processed observation next is [0.0, 0.5217391304347826, 0.38072669826224315, 0.6233333333333334, 1.0, 1.0, 0.143270715832131, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1284850015508224, 0.1284850015508226, 0.24541847577136894], 
reward next is 0.7546, 
noisyNet noise sample is [array([0.6207616], dtype=float32), -1.5007312]. 
=============================================
[2019-03-26 15:58:10,609] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.82502 ]
 [77.76983 ]
 [77.67826 ]
 [77.613266]
 [77.54482 ]], R is [[77.84319305]
 [77.81928253]
 [77.795578  ]
 [77.77212524]
 [77.74890137]].
[2019-03-26 15:58:12,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7079549e-24 1.0000000e+00 1.0050051e-24 6.7960786e-26 1.5925777e-32], sum to 1.0000
[2019-03-26 15:58:12,068] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-26 15:58:12,075] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 79.0, 1.0, 2.0, 0.2936542726538034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 468752.1887341646, 468752.1887341653, 164843.3139199838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 897600.0000, 
sim time next is 898200.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.2936097048136517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 468681.2068542926, 468681.2068542932, 164838.3568301626], 
processed observation next is [0.0, 0.391304347826087, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14892735519717068, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13018922412619238, 0.13018922412619255, 0.24602739825397404], 
reward next is 0.7540, 
noisyNet noise sample is [array([0.15811683], dtype=float32), -1.1237849]. 
=============================================
[2019-03-26 15:58:14,998] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1958320e-20 1.0000000e+00 1.0816547e-21 5.6347440e-20 9.7862955e-30], sum to 1.0000
[2019-03-26 15:58:15,008] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9949
[2019-03-26 15:58:15,017] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 95.0, 1.0, 2.0, 0.3426359610186044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528995.1205086668, 528995.1205086668, 168956.2888355418], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 955200.0000, 
sim time next is 955800.0000, 
raw observation next is [21.8, 95.0, 1.0, 2.0, 0.3420284472118769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 528057.0774867306, 528057.0774867313, 168880.7716853372], 
processed observation next is [1.0, 0.043478260869565216, 0.23222748815165886, 0.95, 1.0, 1.0, 0.2072631894118999, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14668252152409184, 0.14668252152409203, 0.2520608532616973], 
reward next is 0.7479, 
noisyNet noise sample is [array([-0.9572395], dtype=float32), -0.9713083]. 
=============================================
[2019-03-26 15:58:17,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4044084e-20 1.0000000e+00 4.4142788e-22 7.8157892e-20 5.7289133e-29], sum to 1.0000
[2019-03-26 15:58:17,755] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1389
[2019-03-26 15:58:17,758] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 92.0, 1.0, 2.0, 0.3410723180482942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 527645.53783535, 527645.5378353494, 168880.0675782755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 943200.0000, 
sim time next is 943800.0000, 
raw observation next is [22.05, 92.33333333333334, 1.0, 2.0, 0.3412681066332428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527977.0730229522, 527977.0730229522, 168907.5150377784], 
processed observation next is [0.0, 0.9565217391304348, 0.24407582938388633, 0.9233333333333335, 1.0, 1.0, 0.20634711642559375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14666029806193115, 0.14666029806193115, 0.25210076871310205], 
reward next is 0.7479, 
noisyNet noise sample is [array([0.1737179], dtype=float32), -0.8373581]. 
=============================================
[2019-03-26 15:58:18,908] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 15:58:18,910] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 15:58:18,911] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:58:18,912] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 15:58:18,913] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 15:58:18,913] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:58:18,915] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:58:18,917] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 15:58:18,919] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 15:58:18,920] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:58:18,923] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 15:58:18,940] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 15:58:18,965] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 15:58:18,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 15:58:18,986] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 15:58:19,005] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 15:58:33,921] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:58:33,923] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.36666666666667, 78.33333333333334, 1.0, 2.0, 0.2998962843576135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 480436.3376791002, 480436.3376791002, 165685.4571042296]
[2019-03-26 15:58:33,924] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:58:33,926] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2793773e-20 1.0000000e+00 4.7475149e-22 1.7070790e-20 8.6167625e-30], sampled 0.2825203043892385
[2019-03-26 15:58:49,819] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:58:49,820] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.25722288, 94.34720397333334, 1.0, 2.0, 0.5676007555823077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793169.1365286225, 793169.136528623, 194865.5992915053]
[2019-03-26 15:58:49,823] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 15:58:49,825] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2399241e-22 1.0000000e+00 4.3001928e-23 1.6253602e-22 1.1161510e-30], sampled 0.02875940075842287
[2019-03-26 15:59:24,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:59:24,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [38.46666666666667, 42.33333333333334, 1.0, 2.0, 0.6276171426526571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 877071.0692563248, 877071.0692563248, 206002.0570223913]
[2019-03-26 15:59:24,878] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:59:24,882] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7128232e-22 1.0000000e+00 6.7354853e-24 2.7798799e-22 1.1632500e-31], sampled 0.6145353746814819
[2019-03-26 15:59:48,385] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:59:48,386] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.8, 72.0, 1.0, 2.0, 0.5440831293522681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760293.6849292712, 760293.6849292712, 190790.9279182795]
[2019-03-26 15:59:48,387] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 15:59:48,391] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0367084e-19 1.0000000e+00 1.2312989e-21 1.0709526e-18 2.8221392e-29], sampled 0.47486380324637956
[2019-03-26 15:59:51,844] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:59:51,845] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.15878563, 70.88910702, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.150811771545366, 6.9112, 168.911694244987, 1623858.912037763, 1453871.344808126, 311353.7356746802]
[2019-03-26 15:59:51,846] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 15:59:51,850] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.7373752e-16 1.0000000e+00 2.0245181e-19 8.2061685e-13 8.7561145e-26], sampled 0.7384487186072358
[2019-03-26 15:59:53,101] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01133325], dtype=float32), 0.08714259]
[2019-03-26 15:59:53,102] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.23333333333333, 91.66666666666666, 1.0, 2.0, 0.7544219088537768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1054363.868967868, 1054363.868967868, 233029.7328824497]
[2019-03-26 15:59:53,102] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 15:59:53,104] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0963407e-19 1.0000000e+00 1.8335874e-21 2.4279995e-19 9.8575258e-29], sampled 0.590480251957841
[2019-03-26 16:00:13,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8673.2751 2778056371.4799 900.0000
[2019-03-26 16:00:13,633] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8038.4692 3003670184.7621 1662.0000
[2019-03-26 16:00:13,848] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8520.0726 2839995412.8207 1069.0000
[2019-03-26 16:00:14,007] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7975.6271 3155239339.9224 1539.0000
[2019-03-26 16:00:14,039] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8275.2320 2925995329.9235 1294.0000
[2019-03-26 16:00:15,056] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 875000, evaluation results [875000.0, 7975.627053287826, 3155239339.9223986, 1539.0, 8275.231952227437, 2925995329.9234657, 1294.0, 8673.275131741702, 2778056371.4798884, 900.0, 8038.469172676635, 3003670184.762062, 1662.0, 8520.072577301995, 2839995412.820672, 1069.0]
[2019-03-26 16:00:19,799] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3415352e-19 1.0000000e+00 2.1502164e-21 4.8521430e-18 7.4432925e-29], sum to 1.0000
[2019-03-26 16:00:19,812] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4180
[2019-03-26 16:00:19,818] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 96.83333333333334, 1.0, 2.0, 0.3810266070358634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 572905.3294677648, 572905.3294677654, 172212.0456711038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1041000.0000, 
sim time next is 1041600.0000, 
raw observation next is [22.46666666666667, 96.66666666666667, 1.0, 2.0, 0.3810725633409504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572713.346781979, 572713.346781979, 172186.7688893835], 
processed observation next is [1.0, 0.043478260869565216, 0.2638230647709322, 0.9666666666666667, 1.0, 1.0, 0.254304293181868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15908704077277194, 0.15908704077277194, 0.256995177446841], 
reward next is 0.7430, 
noisyNet noise sample is [array([0.86093634], dtype=float32), -0.73269325]. 
=============================================
[2019-03-26 16:00:30,264] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1072643e-09 9.3441659e-01 1.4209559e-15 6.5583445e-02 2.2494334e-19], sum to 1.0000
[2019-03-26 16:00:30,273] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0717
[2019-03-26 16:00:30,277] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.65, 76.66666666666667, 1.0, 2.0, 0.2932843814225452, 1.0, 1.0, 0.2932843814225452, 1.0, 1.0, 0.4959943159898429, 6.911199999999999, 6.9112, 170.5573041426782, 1229758.518390524, 1229758.518390525, 300389.7744619663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1271400.0000, 
sim time next is 1272000.0000, 
raw observation next is [27.5, 77.33333333333334, 1.0, 2.0, 0.4753063719108577, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129560957153, 664156.0206692404, 664156.0206692404, 179818.2840966122], 
processed observation next is [1.0, 0.7391304347826086, 0.5023696682464456, 0.7733333333333334, 1.0, 1.0, 0.36783900230223815, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399431158587, 0.18448778351923345, 0.18448778351923345, 0.26838549865166], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8421072], dtype=float32), 0.2130552]. 
=============================================
[2019-03-26 16:00:30,291] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.24872 ]
 [62.120426]
 [62.354008]
 [61.184006]
 [59.36314 ]], R is [[67.79293823]
 [67.11501312]
 [66.44386292]
 [66.29141998]
 [66.12757111]].
[2019-03-26 16:00:30,447] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1044350e-19 1.0000000e+00 3.0928174e-21 1.5124769e-17 2.5159978e-28], sum to 1.0000
[2019-03-26 16:00:30,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7004
[2019-03-26 16:00:30,462] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 88.83333333333334, 1.0, 2.0, 0.3455641444637538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535479.6854406107, 535479.6854406114, 169537.7444667488], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1212600.0000, 
sim time next is 1213200.0000, 
raw observation next is [22.4, 89.0, 1.0, 2.0, 0.3453616369211296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535339.9796372101, 535339.9796372101, 169531.1868940349], 
processed observation next is [1.0, 0.043478260869565216, 0.2606635071090047, 0.89, 1.0, 1.0, 0.21127908062786696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14870554989922505, 0.14870554989922505, 0.25303162222990283], 
reward next is 0.7470, 
noisyNet noise sample is [array([-1.0480196], dtype=float32), -0.14321007]. 
=============================================
[2019-03-26 16:00:33,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.5885166e-09 8.2071418e-01 2.7529669e-13 1.7928584e-01 1.9731047e-17], sum to 1.0000
[2019-03-26 16:00:33,310] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5483
[2019-03-26 16:00:33,318] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2067517.86106342 W.
[2019-03-26 16:00:33,323] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.05, 74.83333333333333, 1.0, 2.0, 0.7393328514452391, 1.0, 2.0, 0.7393328514452391, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2067517.86106342, 2067517.86106342, 391407.2726964892], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1266600.0000, 
sim time next is 1267200.0000, 
raw observation next is [28.0, 75.0, 1.0, 2.0, 0.4696956107940843, 1.0, 2.0, 0.4696956107940843, 1.0, 1.0, 0.7973984949365372, 6.9112, 6.9112, 170.5573041426782, 1970140.993329912, 1970140.993329912, 391694.0440696525], 
processed observation next is [1.0, 0.6956521739130435, 0.5260663507109005, 0.75, 1.0, 1.0, 0.3610790491494991, 1.0, 1.0, 0.3610790491494991, 1.0, 0.5, 0.7529249938250453, 0.0, 0.0, 0.8375144448122397, 0.5472613870360866, 0.5472613870360866, 0.584617976223362], 
reward next is 0.4154, 
noisyNet noise sample is [array([0.24941438], dtype=float32), -1.1937563]. 
=============================================
[2019-03-26 16:00:34,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2433095e-16 1.0000000e+00 8.9109469e-19 1.9596842e-14 6.9592070e-26], sum to 1.0000
[2019-03-26 16:00:34,670] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3864
[2019-03-26 16:00:34,675] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 88.5, 1.0, 2.0, 0.5589917482240518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 889170.9920185768, 889170.9920185768, 205604.6929953521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1348200.0000, 
sim time next is 1348800.0000, 
raw observation next is [21.36666666666667, 88.66666666666666, 1.0, 2.0, 0.5136073376258888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817199.162105594, 817199.162105594, 196986.9948725727], 
processed observation next is [1.0, 0.6086956521739131, 0.21169036334913136, 0.8866666666666666, 1.0, 1.0, 0.4139847441275769, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22699976725155388, 0.22699976725155388, 0.29401044010831745], 
reward next is 0.7060, 
noisyNet noise sample is [array([-0.4752152], dtype=float32), 0.2684749]. 
=============================================
[2019-03-26 16:00:37,127] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.2278884e-17 1.0000000e+00 2.7537185e-20 4.7176533e-15 6.3269345e-27], sum to 1.0000
[2019-03-26 16:00:37,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-26 16:00:37,142] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.48333333333333, 93.33333333333333, 1.0, 2.0, 0.7187401081279726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1092218.434412109, 1092218.434412109, 236227.0199749477], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1338600.0000, 
sim time next is 1339200.0000, 
raw observation next is [22.4, 93.0, 1.0, 2.0, 0.77006259614506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1174780.441420588, 1174780.441420588, 249615.5148186972], 
processed observation next is [1.0, 0.5217391304347826, 0.2606635071090047, 0.93, 1.0, 1.0, 0.7229669833073012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32632790039460774, 0.32632790039460774, 0.37256046987865254], 
reward next is 0.6274, 
noisyNet noise sample is [array([-0.9108759], dtype=float32), 1.2302653]. 
=============================================
[2019-03-26 16:00:41,647] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3178528e-22 1.0000000e+00 2.4352576e-23 1.0968499e-21 4.2360114e-31], sum to 1.0000
[2019-03-26 16:00:41,659] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1494
[2019-03-26 16:00:41,664] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.75, 93.66666666666667, 1.0, 2.0, 0.3812725536995554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574517.8006273448, 574517.800627344, 172393.7785899106], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1457400.0000, 
sim time next is 1458000.0000, 
raw observation next is [22.7, 94.0, 1.0, 2.0, 0.3812029617447436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574572.6535373455, 574572.6535373455, 172403.5456470895], 
processed observation next is [0.0, 0.9130434782608695, 0.27488151658767773, 0.94, 1.0, 1.0, 0.2544613996924622, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15960351487148486, 0.15960351487148486, 0.2573187248464022], 
reward next is 0.7427, 
noisyNet noise sample is [array([0.04516703], dtype=float32), -0.3973366]. 
=============================================
[2019-03-26 16:00:41,676] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.12413 ]
 [77.19506 ]
 [77.25982 ]
 [77.327774]
 [77.394356]], R is [[77.04984283]
 [77.02204132]
 [76.99445343]
 [76.96699524]
 [76.93972015]].
[2019-03-26 16:00:43,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0235967e-23 1.0000000e+00 2.1441123e-23 1.1377877e-22 8.9573789e-31], sum to 1.0000
[2019-03-26 16:00:43,052] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4048
[2019-03-26 16:00:43,058] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 75.0, 1.0, 2.0, 0.4296274430356196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619811.9741891421, 619811.9741891414, 175817.0072538997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1431000.0000, 
sim time next is 1431600.0000, 
raw observation next is [26.8, 73.66666666666666, 1.0, 2.0, 0.4287836549573449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 618914.8134678683, 618914.8134678683, 175738.8934382945], 
processed observation next is [0.0, 0.5652173913043478, 0.4691943127962086, 0.7366666666666666, 1.0, 1.0, 0.31178753609318666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1719207815188523, 0.1719207815188523, 0.2622968558780515], 
reward next is 0.7377, 
noisyNet noise sample is [array([-1.4709008], dtype=float32), -1.9662232]. 
=============================================
[2019-03-26 16:00:43,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4768281e-22 1.0000000e+00 1.3091954e-23 4.0808254e-23 1.4908989e-31], sum to 1.0000
[2019-03-26 16:00:43,494] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-26 16:00:43,499] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 69.66666666666667, 1.0, 2.0, 0.4425385865042282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 629922.9750266817, 629922.9750266817, 176577.7746709021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1438800.0000, 
sim time next is 1439400.0000, 
raw observation next is [27.93333333333334, 69.83333333333333, 1.0, 2.0, 0.4476488768239278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 634772.7633866058, 634772.7633866058, 176999.4665341146], 
processed observation next is [0.0, 0.6521739130434783, 0.5229067930489735, 0.6983333333333333, 1.0, 1.0, 0.33451671906497327, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1763257676073905, 0.1763257676073905, 0.26417830825987254], 
reward next is 0.7358, 
noisyNet noise sample is [array([2.073994], dtype=float32), 0.86656666]. 
=============================================
[2019-03-26 16:00:44,756] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1971911e-21 1.0000000e+00 1.1974464e-22 1.0382751e-20 1.0453797e-30], sum to 1.0000
[2019-03-26 16:00:44,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0040
[2019-03-26 16:00:44,774] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.63333333333333, 94.16666666666667, 1.0, 2.0, 0.3798966029423203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573246.6561010603, 573246.6561010603, 172305.686990211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1458600.0000, 
sim time next is 1459200.0000, 
raw observation next is [22.56666666666667, 94.33333333333334, 1.0, 2.0, 0.3779315394398082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571128.6884031432, 571128.6884031432, 172144.6344543866], 
processed observation next is [0.0, 0.9130434782608695, 0.26856240126382325, 0.9433333333333335, 1.0, 1.0, 0.25051992703591347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.158646857889762, 0.158646857889762, 0.25693229023042774], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.48341826], dtype=float32), 0.78354126]. 
=============================================
[2019-03-26 16:00:47,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.5897376e-22 1.0000000e+00 1.3698652e-23 2.9430250e-21 4.0277157e-31], sum to 1.0000
[2019-03-26 16:00:47,612] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5051
[2019-03-26 16:00:47,618] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 90.66666666666666, 1.0, 2.0, 0.4370288705946396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639250.9888726175, 639250.9888726175, 177959.2335691631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1921800.0000, 
sim time next is 1922400.0000, 
raw observation next is [24.1, 90.0, 1.0, 2.0, 0.4325131596338797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 631949.131524256, 631949.1315242565, 177221.2355602652], 
processed observation next is [1.0, 0.2608695652173913, 0.3412322274881518, 0.9, 1.0, 1.0, 0.3162809152215418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17554142542340442, 0.1755414254234046, 0.264509306806366], 
reward next is 0.7355, 
noisyNet noise sample is [array([0.67367136], dtype=float32), 0.040376313]. 
=============================================
[2019-03-26 16:00:54,124] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2266495e-19 1.0000000e+00 8.1933376e-22 1.7077254e-18 5.7083826e-30], sum to 1.0000
[2019-03-26 16:00:54,132] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6687
[2019-03-26 16:00:54,138] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 99.0, 1.0, 2.0, 0.4300133032605817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622147.4625190102, 622147.4625190095, 176095.591419972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1648800.0000, 
sim time next is 1649400.0000, 
raw observation next is [23.21666666666667, 99.0, 1.0, 2.0, 0.6278438088402513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 907952.4709085738, 907952.4709085738, 209994.7039322603], 
processed observation next is [1.0, 0.08695652173913043, 0.29936808846761465, 0.99, 1.0, 1.0, 0.5516190467954835, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2522090196968261, 0.2522090196968261, 0.31342493124217957], 
reward next is 0.6866, 
noisyNet noise sample is [array([0.30900142], dtype=float32), -1.407184]. 
=============================================
[2019-03-26 16:01:00,921] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.8538006e-17 1.0000000e+00 1.2551393e-20 1.0920644e-15 2.6241414e-27], sum to 1.0000
[2019-03-26 16:01:00,929] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-26 16:01:00,934] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 94.00000000000001, 1.0, 2.0, 0.5088553574614962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 711050.4436148852, 711050.4436148852, 184995.3250477609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1725000.0000, 
sim time next is 1725600.0000, 
raw observation next is [25.56666666666667, 94.0, 1.0, 2.0, 0.5065683184638683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707853.5785466613, 707853.5785466619, 184631.7498514981], 
processed observation next is [1.0, 1.0, 0.41074249605055313, 0.94, 1.0, 1.0, 0.4055039981492389, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19662599404073924, 0.1966259940407394, 0.2755697758977584], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.8035194], dtype=float32), -1.5016953]. 
=============================================
[2019-03-26 16:01:08,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.1685356e-10 9.9989998e-01 7.8546327e-14 9.9989789e-05 9.5091949e-19], sum to 1.0000
[2019-03-26 16:01:08,773] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4344
[2019-03-26 16:01:08,784] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1680062.971846892 W.
[2019-03-26 16:01:08,791] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.9, 86.0, 1.0, 2.0, 0.600885104170205, 0.0, 2.0, 0.0, 1.0, 1.0, 1.004424044825259, 6.911200000000001, 6.9112, 168.9125445288132, 1680062.971846892, 1680062.971846892, 359395.7880270624], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1857600.0000, 
sim time next is 1858200.0000, 
raw observation next is [26.0, 85.83333333333334, 1.0, 2.0, 0.554190505859246, 1.0, 1.0, 0.554190505859246, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1549399.587984747, 1549399.587984747, 317938.0900949306], 
processed observation next is [1.0, 0.5217391304347826, 0.4312796208530806, 0.8583333333333334, 1.0, 1.0, 0.46288012754126023, 1.0, 0.5, 0.46288012754126023, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4303887744402075, 0.4303887744402075, 0.4745344628282546], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1526154], dtype=float32), 0.39886776]. 
=============================================
[2019-03-26 16:01:11,292] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 16:01:11,294] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:01:11,295] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:01:11,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:01:11,296] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:01:11,299] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:01:11,300] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:01:11,300] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:01:11,301] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:01:11,301] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:01:11,304] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:01:11,322] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 16:01:11,343] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 16:01:11,369] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 16:01:11,388] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 16:01:11,389] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 16:02:20,050] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01110746], dtype=float32), 0.08662134]
[2019-03-26 16:02:20,052] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.9, 71.0, 1.0, 2.0, 0.759462565089403, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005978996567684, 6.9112, 168.9123160206219, 1958341.234473278, 1891102.007227774, 398093.9949580166]
[2019-03-26 16:02:20,056] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:02:20,058] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.6066953e-13 1.0000000e+00 3.5924925e-16 9.4427577e-09 1.6651245e-21], sampled 0.9415071450354181
[2019-03-26 16:02:20,059] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1958341.234473278 W.
[2019-03-26 16:02:25,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.01110746], dtype=float32), 0.08662134]
[2019-03-26 16:02:25,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.06666666666667, 77.66666666666667, 1.0, 2.0, 0.584440526020428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 816710.1927194071, 816710.1927194077, 197882.9194759923]
[2019-03-26 16:02:25,093] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:02:25,096] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1149566e-20 1.0000000e+00 1.6365966e-22 8.6151623e-20 1.8563821e-30], sampled 0.500329804015777
[2019-03-26 16:02:55,526] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01110746], dtype=float32), 0.08662134]
[2019-03-26 16:02:55,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 84.0, 1.0, 2.0, 0.7754967333639282, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979997910175, 6.9112, 168.9123160158943, 1980780.708155748, 1913540.770527993, 401865.8563479488]
[2019-03-26 16:02:55,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:02:55,531] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7332868e-13 1.0000000e+00 8.0515183e-16 3.9378665e-09 3.4872315e-21], sampled 0.13666844605973794
[2019-03-26 16:02:55,532] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1980780.708155748 W.
[2019-03-26 16:02:58,129] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.01110746], dtype=float32), 0.08662134]
[2019-03-26 16:02:58,130] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.85, 65.0, 1.0, 2.0, 0.7182174859639058, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005976420980948, 6.9112, 168.9123160393931, 1900621.813594217, 1833384.413544188, 388665.4842425705]
[2019-03-26 16:02:58,133] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:02:58,137] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.7745290e-11 9.9891615e-01 2.1560114e-15 1.0839177e-03 2.0081020e-19], sampled 0.6235300539531782
[2019-03-26 16:02:58,139] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1900621.813594217 W.
[2019-03-26 16:03:00,043] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01110746], dtype=float32), 0.08662134]
[2019-03-26 16:03:00,044] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.8, 90.66666666666667, 1.0, 2.0, 0.4049397626363604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 596156.6687155137, 596156.6687155131, 173942.5359921775]
[2019-03-26 16:03:00,046] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:03:00,048] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.2505439e-21 1.0000000e+00 1.1546520e-22 4.9684325e-21 1.1411039e-30], sampled 0.20059049965698417
[2019-03-26 16:03:06,383] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8015.6104 3005659575.9519 1713.0000
[2019-03-26 16:03:06,511] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8511.0299 2841289542.6596 1098.0000
[2019-03-26 16:03:06,530] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7936.5525 3158209888.6315 1628.0000
[2019-03-26 16:03:06,746] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.9274 2778735283.2728 913.0000
[2019-03-26 16:03:06,805] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.0449 2926530389.5646 1312.0000
[2019-03-26 16:03:07,822] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 900000, evaluation results [900000.0, 7936.552475779255, 3158209888.6315436, 1628.0, 8265.04494520497, 2926530389.5646367, 1312.0, 8669.92742257593, 2778735283.272776, 913.0, 8015.610383119398, 3005659575.951881, 1713.0, 8511.029917994965, 2841289542.659584, 1098.0]
[2019-03-26 16:03:09,219] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7856397e-22 1.0000000e+00 3.1468204e-23 4.8421115e-22 7.5871375e-31], sum to 1.0000
[2019-03-26 16:03:09,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9544
[2019-03-26 16:03:09,233] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.38333333333333, 83.66666666666667, 1.0, 2.0, 0.4781189451026186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687416.3430143271, 687416.3430143271, 182702.9621575311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929000.0000, 
sim time next is 1929600.0000, 
raw observation next is [25.5, 83.0, 1.0, 2.0, 0.4865390156703512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698938.4954897553, 698938.4954897553, 183945.1048319371], 
processed observation next is [1.0, 0.34782608695652173, 0.40758293838862564, 0.83, 1.0, 1.0, 0.3813723080365677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19414958208048758, 0.19414958208048758, 0.27454493258498075], 
reward next is 0.7255, 
noisyNet noise sample is [array([-1.7394627], dtype=float32), -0.24838604]. 
=============================================
[2019-03-26 16:03:13,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.02632707e-21 1.00000000e+00 1.35592732e-22 1.16639365e-20
 1.40480311e-30], sum to 1.0000
[2019-03-26 16:03:13,698] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1562
[2019-03-26 16:03:13,706] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 94.83333333333333, 1.0, 2.0, 0.471409588423889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660603.3525919177, 660603.3525919183, 179482.4667023973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1997400.0000, 
sim time next is 1998000.0000, 
raw observation next is [24.4, 95.0, 1.0, 2.0, 0.4695653630414371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 658875.7304304363, 658875.7304304363, 179319.5416612722], 
processed observation next is [0.0, 0.13043478260869565, 0.3554502369668246, 0.95, 1.0, 1.0, 0.3609221241463098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18302103623067675, 0.18302103623067675, 0.2676411069571227], 
reward next is 0.7324, 
noisyNet noise sample is [array([-0.74671984], dtype=float32), 0.6578269]. 
=============================================
[2019-03-26 16:03:13,726] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.92033 ]
 [74.079475]
 [74.29849 ]
 [74.51944 ]
 [74.4297  ]], R is [[73.94416046]
 [73.93683624]
 [73.92944336]
 [73.92211914]
 [73.91482544]].
[2019-03-26 16:03:16,654] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.0472679e-22 1.0000000e+00 1.7161388e-23 6.3364428e-22 1.3421961e-31], sum to 1.0000
[2019-03-26 16:03:16,664] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-26 16:03:16,673] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 87.5, 1.0, 2.0, 0.4892734497685287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683678.8052585904, 683678.8052585904, 181932.5021534578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2053800.0000, 
sim time next is 2054400.0000, 
raw observation next is [25.9, 87.66666666666667, 1.0, 2.0, 0.4880166059696301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681922.010016076, 681922.010016076, 181739.8203442827], 
processed observation next is [0.0, 0.782608695652174, 0.42654028436018954, 0.8766666666666667, 1.0, 1.0, 0.38315253731280735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18942278056002113, 0.18942278056002113, 0.27125346320042193], 
reward next is 0.7287, 
noisyNet noise sample is [array([-0.5774133], dtype=float32), 0.3550258]. 
=============================================
[2019-03-26 16:03:19,042] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.07821657e-09 5.19417487e-02 1.20367244e-14 9.48058248e-01
 1.35759870e-18], sum to 1.0000
[2019-03-26 16:03:19,049] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4330
[2019-03-26 16:03:19,057] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.03333333333333, 64.83333333333334, 1.0, 2.0, 0.5906806154188133, 1.0, 1.0, 0.5906806154188133, 1.0, 2.0, 1.025816887917973, 6.9112, 6.9112, 170.5573041426782, 2478156.486685463, 2478156.486685463, 483515.357674201], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2301000.0000, 
sim time next is 2301600.0000, 
raw observation next is [32.06666666666667, 64.66666666666667, 1.0, 2.0, 0.8164971931477979, 1.0, 2.0, 0.8164971931477979, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2283524.400877242, 2283524.400877242, 427985.0623887872], 
processed observation next is [1.0, 0.6521739130434783, 0.7187993680884678, 0.6466666666666667, 1.0, 1.0, 0.7789122809009613, 1.0, 1.0, 0.7789122809009613, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6343123335770117, 0.6343123335770117, 0.6387836752071451], 
reward next is 0.3612, 
noisyNet noise sample is [array([-0.55875945], dtype=float32), 1.2112371]. 
=============================================
[2019-03-26 16:03:20,283] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9643683e-20 1.0000000e+00 5.0129215e-22 1.6416709e-18 2.3027654e-29], sum to 1.0000
[2019-03-26 16:03:20,291] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2133
[2019-03-26 16:03:20,300] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 93.0, 1.0, 2.0, 0.5151240273938602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719812.954775663, 719812.954775663, 185999.4616185058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2160000.0000, 
sim time next is 2160600.0000, 
raw observation next is [25.76666666666667, 93.16666666666667, 1.0, 2.0, 0.5136989195474245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717820.895321216, 717820.8953212154, 185770.1529917105], 
processed observation next is [1.0, 0.0, 0.42022116903633505, 0.9316666666666668, 1.0, 1.0, 0.4140950837920777, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19939469314478223, 0.19939469314478206, 0.27726888506225444], 
reward next is 0.7227, 
noisyNet noise sample is [array([-1.539801], dtype=float32), 0.24585436]. 
=============================================
[2019-03-26 16:03:21,855] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0222676e-22 1.0000000e+00 4.0700363e-23 1.2909176e-20 3.6179091e-30], sum to 1.0000
[2019-03-26 16:03:21,861] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-26 16:03:21,874] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 73.66666666666667, 1.0, 2.0, 0.5692102775244059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795419.1355337119, 795419.1355337119, 195150.646355685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2132400.0000, 
sim time next is 2133000.0000, 
raw observation next is [30.65, 73.5, 1.0, 2.0, 0.5695801170196924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795936.1459319879, 795936.1459319879, 195216.2238433336], 
processed observation next is [0.0, 0.6956521739130435, 0.6516587677725119, 0.735, 1.0, 1.0, 0.4814218277345691, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22109337386999664, 0.22109337386999664, 0.29136749827363223], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.5724482], dtype=float32), -0.18469721]. 
=============================================
[2019-03-26 16:03:21,895] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.38123]
 [72.37559]
 [72.35613]
 [72.28637]
 [72.24239]], R is [[72.37828827]
 [72.36323547]
 [72.34855652]
 [72.3344574 ]
 [72.31998444]].
[2019-03-26 16:03:23,032] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6781695e-12 1.0000000e+00 1.2213944e-15 2.5012383e-08 3.6953817e-21], sum to 1.0000
[2019-03-26 16:03:23,040] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6452
[2019-03-26 16:03:23,047] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2016273.342881346 W.
[2019-03-26 16:03:23,054] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 80.0, 1.0, 2.0, 0.721025326219026, 1.0, 1.0, 0.721025326219026, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2016273.342881346, 2016273.342881346, 383255.7845636384], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2191200.0000, 
sim time next is 2191800.0000, 
raw observation next is [28.8, 79.5, 1.0, 2.0, 0.7635487909516709, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.994503095839113, 6.9112, 168.9124605290826, 1964059.773076009, 1904961.863346935, 399470.4210303837], 
processed observation next is [1.0, 0.34782608695652173, 0.5639810426540285, 0.795, 1.0, 1.0, 0.715119025242977, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008330309583911255, 0.0, 0.8294375096568208, 0.5455721591877802, 0.5291560731519264, 0.5962245090005727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49855903], dtype=float32), 0.66868687]. 
=============================================
[2019-03-26 16:03:23,166] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0153146e-09 2.3368370e-02 2.6374283e-15 9.7663158e-01 4.5824048e-19], sum to 1.0000
[2019-03-26 16:03:23,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9850
[2019-03-26 16:03:23,179] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.03333333333333, 65.66666666666667, 1.0, 2.0, 0.8154237729867092, 1.0, 2.0, 0.8154237729867092, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2280519.592516574, 2280519.592516574, 427453.5550115935], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2212800.0000, 
sim time next is 2213400.0000, 
raw observation next is [32.01666666666667, 65.83333333333333, 1.0, 2.0, 0.8185302511692888, 1.0, 2.0, 0.8185302511692888, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2289215.528374152, 2289215.528374152, 428996.8992488772], 
processed observation next is [1.0, 0.6086956521739131, 0.7164296998420224, 0.6583333333333333, 1.0, 1.0, 0.7813617483967334, 1.0, 1.0, 0.7813617483967334, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6358932023261533, 0.6358932023261533, 0.6402938794759361], 
reward next is 0.3597, 
noisyNet noise sample is [array([0.93355477], dtype=float32), 1.3313473]. 
=============================================
[2019-03-26 16:03:25,954] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1054976e-16 1.0000000e+00 3.6501167e-20 1.8692144e-16 1.1026869e-26], sum to 1.0000
[2019-03-26 16:03:25,963] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4390
[2019-03-26 16:03:25,967] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 86.0, 1.0, 2.0, 0.913705205082607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1277108.660853028, 1277108.660853029, 273733.0476552404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2254200.0000, 
sim time next is 2254800.0000, 
raw observation next is [26.4, 86.0, 1.0, 2.0, 0.8730304101673947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1220223.810903348, 1220223.810903349, 262624.1888260762], 
processed observation next is [1.0, 0.08695652173913043, 0.45023696682464454, 0.86, 1.0, 1.0, 0.8470245905631261, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33895105858426333, 0.3389510585842636, 0.3919764012329496], 
reward next is 0.6080, 
noisyNet noise sample is [array([-1.1492517], dtype=float32), 1.7100565]. 
=============================================
[2019-03-26 16:03:32,593] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1040909e-21 1.0000000e+00 2.0590407e-23 1.1085612e-20 4.3416625e-31], sum to 1.0000
[2019-03-26 16:03:32,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7043
[2019-03-26 16:03:32,609] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 72.0, 1.0, 2.0, 0.5681566927240682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793946.2971972033, 793946.2971972033, 194964.1955819265], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2314800.0000, 
sim time next is 2315400.0000, 
raw observation next is [30.78333333333333, 72.83333333333333, 1.0, 2.0, 0.5694616676642078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795770.5617816582, 795770.5617816582, 195195.2572018267], 
processed observation next is [1.0, 0.8260869565217391, 0.6579778830963664, 0.7283333333333333, 1.0, 1.0, 0.48127911766772025, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22104737827268284, 0.22104737827268284, 0.2913362047788458], 
reward next is 0.7087, 
noisyNet noise sample is [array([-0.46250403], dtype=float32), -1.7116055]. 
=============================================
[2019-03-26 16:03:38,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.3607324e-20 1.0000000e+00 2.3174815e-22 5.4182398e-20 1.1133614e-30], sum to 1.0000
[2019-03-26 16:03:38,867] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7516
[2019-03-26 16:03:38,876] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.2, 80.0, 1.0, 2.0, 0.5678562392396902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793526.2844790141, 793526.2844790141, 194910.2265544807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2417400.0000, 
sim time next is 2418000.0000, 
raw observation next is [29.16666666666666, 80.0, 1.0, 2.0, 0.5650714471557491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789633.350035203, 789633.350035203, 194419.1723215128], 
processed observation next is [1.0, 1.0, 0.5813586097946285, 0.8, 1.0, 1.0, 0.4759896953683724, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21934259723200084, 0.21934259723200084, 0.2901778691365863], 
reward next is 0.7098, 
noisyNet noise sample is [array([-0.65920424], dtype=float32), 0.7293182]. 
=============================================
[2019-03-26 16:03:38,896] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.87993]
 [68.89585]
 [68.9322 ]
 [68.9674 ]
 [68.97339]], R is [[68.9026947 ]
 [68.92276001]
 [68.94192505]
 [68.96051788]
 [68.97872925]].
[2019-03-26 16:03:40,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2042806e-23 1.0000000e+00 5.3788920e-25 1.2066297e-24 2.9792307e-34], sum to 1.0000
[2019-03-26 16:03:40,194] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3954
[2019-03-26 16:03:40,197] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 91.0, 1.0, 2.0, 0.5519825497080537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771336.2255356542, 771336.2255356548, 192141.6382926534], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2489400.0000, 
sim time next is 2490000.0000, 
raw observation next is [27.16666666666667, 91.66666666666667, 1.0, 2.0, 0.5531454007898564, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772961.776055016, 772961.776055016, 192341.8934636629], 
processed observation next is [1.0, 0.8260869565217391, 0.4865718799368091, 0.9166666666666667, 1.0, 1.0, 0.4616209648070559, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21471160445972665, 0.21471160445972665, 0.2870774529308402], 
reward next is 0.7129, 
noisyNet noise sample is [array([1.9908814], dtype=float32), -1.4355625]. 
=============================================
[2019-03-26 16:03:40,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.00379 ]
 [69.304825]
 [69.75668 ]
 [69.79994 ]
 [69.98808 ]], R is [[69.10349274]
 [69.12567902]
 [69.14813232]
 [69.17105103]
 [69.19425201]].
[2019-03-26 16:03:47,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.9351429e-10 9.9948990e-01 2.3921256e-14 5.1011058e-04 3.0813297e-19], sum to 1.0000
[2019-03-26 16:03:47,023] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8886
[2019-03-26 16:03:47,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1854740.883924271 W.
[2019-03-26 16:03:47,034] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.41666666666667, 68.33333333333334, 1.0, 2.0, 0.663310796770533, 1.0, 2.0, 0.663310796770533, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1854740.883924271, 1854740.883924271, 358812.8118292911], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2556600.0000, 
sim time next is 2557200.0000, 
raw observation next is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.690197465155042, 1.0, 2.0, 0.690197465155042, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1929988.742983908, 1929988.742983908, 369955.1351118401], 
processed observation next is [1.0, 0.6086956521739131, 0.6366508688783573, 0.6866666666666668, 1.0, 1.0, 0.6267439339217373, 1.0, 1.0, 0.6267439339217373, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5361079841621966, 0.5361079841621966, 0.5521718434505076], 
reward next is 0.4478, 
noisyNet noise sample is [array([0.4447002], dtype=float32), 1.4464598]. 
=============================================
[2019-03-26 16:03:48,722] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1106381e-22 1.0000000e+00 4.4653882e-24 1.3918248e-23 4.4854620e-33], sum to 1.0000
[2019-03-26 16:03:48,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1177
[2019-03-26 16:03:48,738] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.75, 88.0, 1.0, 2.0, 0.527408824582229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736985.1759527229, 736985.1759527235, 188001.5331280662], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2583000.0000, 
sim time next is 2583600.0000, 
raw observation next is [26.63333333333333, 88.33333333333333, 1.0, 2.0, 0.524319538201854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732666.811622995, 732666.8116229944, 187493.8411431129], 
processed observation next is [1.0, 0.9130434782608695, 0.46129541864139006, 0.8833333333333333, 1.0, 1.0, 0.4268910098817517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20351855878416528, 0.2035185587841651, 0.2798415539449446], 
reward next is 0.7202, 
noisyNet noise sample is [array([-0.8751637], dtype=float32), 1.5462172]. 
=============================================
[2019-03-26 16:03:49,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1098602e-20 1.0000000e+00 3.1776532e-23 7.4859462e-22 9.8973380e-32], sum to 1.0000
[2019-03-26 16:03:49,096] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4506
[2019-03-26 16:03:49,105] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 89.33333333333334, 1.0, 2.0, 0.5197959559566341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726343.5460024896, 726343.546002489, 186755.3305043713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [26.2, 89.66666666666667, 1.0, 2.0, 0.5173097320172007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722868.206990218, 722868.206990218, 186352.1543742471], 
processed observation next is [1.0, 0.9565217391304348, 0.44075829383886256, 0.8966666666666667, 1.0, 1.0, 0.4184454602616875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20079672416394945, 0.20079672416394945, 0.27813754384215983], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.100154], dtype=float32), -0.24718231]. 
=============================================
[2019-03-26 16:03:49,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.61184 ]
 [72.46165 ]
 [72.28337 ]
 [71.99649 ]
 [71.541954]], R is [[72.59438324]
 [72.58969879]
 [72.58461761]
 [72.57935333]
 [72.57372284]].
[2019-03-26 16:03:49,438] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3446981e-22 1.0000000e+00 5.0853358e-24 3.3840268e-23 1.5927408e-33], sum to 1.0000
[2019-03-26 16:03:49,447] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7149
[2019-03-26 16:03:49,453] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 93.0, 1.0, 2.0, 0.4776870419611109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668719.214149378, 668719.214149378, 180333.1098262739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2595600.0000, 
sim time next is 2596200.0000, 
raw observation next is [24.63333333333333, 92.83333333333333, 1.0, 2.0, 0.473072286715056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 664660.3296078828, 664660.3296078828, 179952.5281528739], 
processed observation next is [0.0, 0.043478260869565216, 0.3665086887835701, 0.9283333333333332, 1.0, 1.0, 0.3651473333916338, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.184627869335523, 0.184627869335523, 0.2685858629147372], 
reward next is 0.7314, 
noisyNet noise sample is [array([-2.1313703], dtype=float32), 1.2124231]. 
=============================================
[2019-03-26 16:03:49,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5190021e-22 1.0000000e+00 1.6979894e-24 3.3095851e-23 6.7596237e-33], sum to 1.0000
[2019-03-26 16:03:49,601] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1134
[2019-03-26 16:03:49,606] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.95, 92.5, 1.0, 2.0, 0.4865391851448324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679856.8996106591, 679856.8996106591, 181513.3265422555], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2593800.0000, 
sim time next is 2594400.0000, 
raw observation next is [24.86666666666667, 92.66666666666667, 1.0, 2.0, 0.4839522424962031, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676240.9306145759, 676240.9306145759, 181119.3198428449], 
processed observation next is [0.0, 0.0, 0.3775671406003162, 0.9266666666666667, 1.0, 1.0, 0.37825571385084716, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1878447029484933, 0.1878447029484933, 0.27032734304902223], 
reward next is 0.7297, 
noisyNet noise sample is [array([-0.56222236], dtype=float32), 0.6729901]. 
=============================================
[2019-03-26 16:03:51,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5104614e-25 1.0000000e+00 1.0784882e-25 3.7788952e-26 2.5198898e-34], sum to 1.0000
[2019-03-26 16:03:51,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-26 16:03:51,860] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 84.0, 1.0, 2.0, 0.4886596575628824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 682820.8564156874, 682820.856415688, 181838.4814686216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2647800.0000, 
sim time next is 2648400.0000, 
raw observation next is [26.33333333333334, 85.66666666666666, 1.0, 2.0, 0.490508351975817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685404.9337410438, 685404.9337410444, 182122.4945417789], 
processed observation next is [0.0, 0.6521739130434783, 0.44707740916271754, 0.8566666666666666, 1.0, 1.0, 0.38615464093471924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19039025937251217, 0.19039025937251233, 0.271824618719073], 
reward next is 0.7282, 
noisyNet noise sample is [array([-0.42276573], dtype=float32), 0.24500382]. 
=============================================
[2019-03-26 16:04:00,246] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.1140717e-23 1.0000000e+00 4.7574809e-24 2.2082435e-24 1.2804924e-32], sum to 1.0000
[2019-03-26 16:04:00,255] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3423
[2019-03-26 16:04:00,260] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3474518561810484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535240.9313666883, 535240.9313666878, 169426.6608317343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2771400.0000, 
sim time next is 2772000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3473481168878181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 535081.3018466077, 535081.3018466084, 169413.6413674864], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 1.0, 1.0, 0.213672429985323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14863369495739104, 0.14863369495739123, 0.25285618114550207], 
reward next is 0.7471, 
noisyNet noise sample is [array([-1.9853319], dtype=float32), 0.94675267]. 
=============================================
[2019-03-26 16:04:00,283] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.12598 ]
 [73.06012 ]
 [73.16142 ]
 [73.198204]
 [73.21309 ]], R is [[73.32038879]
 [73.33431244]
 [73.34803772]
 [73.36153412]
 [73.37483215]].
[2019-03-26 16:04:04,004] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 16:04:04,005] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:04:04,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:04:04,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:04:04,007] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:04:04,008] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:04:04,008] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:04:04,012] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:04:04,014] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:04:04,014] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:04:04,016] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:04:04,033] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 16:04:04,033] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 16:04:04,083] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 16:04:04,107] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 16:04:04,107] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 16:04:22,705] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01259901], dtype=float32), 0.08735603]
[2019-03-26 16:04:22,706] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.05678162, 91.34032245833333, 1.0, 2.0, 0.3844333100511276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580399.6275299594, 580399.6275299594, 172951.6375722544]
[2019-03-26 16:04:22,708] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:04:22,711] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.7150208e-24 1.0000000e+00 1.5173027e-24 2.6592933e-25 2.4331280e-33], sampled 0.39953387507381133
[2019-03-26 16:04:39,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01259901], dtype=float32), 0.08735603]
[2019-03-26 16:04:39,063] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.77149693, 70.66947462, 1.0, 2.0, 0.4303315642890675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104055, 606943.6261604563, 606943.6261604563, 174137.3055505385]
[2019-03-26 16:04:39,064] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:04:39,067] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0378254e-23 1.0000000e+00 1.6403254e-25 3.6163075e-23 2.5465913e-33], sampled 0.8328318491866595
[2019-03-26 16:04:50,725] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01259901], dtype=float32), 0.08735603]
[2019-03-26 16:04:50,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.539440045, 81.67313114, 1.0, 2.0, 0.53749708294277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751087.1876878421, 751087.1876878414, 189680.7473308299]
[2019-03-26 16:04:50,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:04:50,731] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.2819900e-24 1.0000000e+00 6.2030519e-25 2.7662088e-25 1.1631602e-33], sampled 0.6155267906054072
[2019-03-26 16:05:42,969] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01259901], dtype=float32), 0.08735603]
[2019-03-26 16:05:42,970] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.25, 54.5, 1.0, 2.0, 0.322858277554824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508053.5868684333, 508053.5868684333, 167581.9541114929]
[2019-03-26 16:05:42,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:42,976] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5043760e-25 1.0000000e+00 5.1751562e-26 1.2154847e-26 8.8034993e-35], sampled 0.8615327222230009
[2019-03-26 16:05:48,051] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01259901], dtype=float32), 0.08735603]
[2019-03-26 16:05:48,052] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.1, 83.83333333333333, 1.0, 2.0, 0.4762583401505951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665486.6434327345, 665486.643432734, 179959.6477878545]
[2019-03-26 16:05:48,053] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:05:48,057] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5586070e-26 1.0000000e+00 1.7969446e-27 1.1477058e-28 9.4891860e-37], sampled 0.35271195320022763
[2019-03-26 16:05:59,847] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.6679 3007840824.3263 1766.0000
[2019-03-26 16:05:59,876] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.1065 3164240751.7849 1776.0000
[2019-03-26 16:05:59,888] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:05:59,995] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 16:06:00,008] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2118 2927459259.5787 1338.0000
[2019-03-26 16:06:01,023] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 925000, evaluation results [925000.0, 7883.106511887976, 3164240751.784855, 1776.0, 8254.211789258557, 2927459259.5787225, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.667917709291, 3007840824.32627, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 16:06:01,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.1728013e-21 1.0000000e+00 6.3179750e-23 1.1650546e-21 8.1563462e-31], sum to 1.0000
[2019-03-26 16:06:01,389] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4722
[2019-03-26 16:06:01,395] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 91.5, 1.0, 2.0, 0.527734823461151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 796695.6009873647, 796695.6009873652, 195321.1992612997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2896200.0000, 
sim time next is 2896800.0000, 
raw observation next is [23.0, 92.33333333333334, 1.0, 2.0, 0.516654771935371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777291.1511361116, 777291.1511361116, 193052.4794744494], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.9233333333333335, 1.0, 1.0, 0.41765635172936266, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2159142086489199, 0.2159142086489199, 0.2881380290663424], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.71892726], dtype=float32), 0.1724219]. 
=============================================
[2019-03-26 16:06:02,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0590806e-20 1.0000000e+00 6.9154463e-23 1.5385498e-21 6.6000726e-31], sum to 1.0000
[2019-03-26 16:06:02,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8180
[2019-03-26 16:06:02,520] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 94.0, 1.0, 2.0, 0.6903514935496612, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1039737.312066003, 1039737.312066004, 228390.7154094192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2899200.0000, 
sim time next is 2899800.0000, 
raw observation next is [22.5, 94.0, 1.0, 2.0, 0.7305418848079579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1106169.369365209, 1106169.369365209, 238633.0476941622], 
processed observation next is [1.0, 0.5652173913043478, 0.2654028436018958, 0.94, 1.0, 1.0, 0.6753516684433227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3072692692681136, 0.3072692692681136, 0.35616872790173465], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.21495844], dtype=float32), -0.7315367]. 
=============================================
[2019-03-26 16:06:09,926] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.2975939e-22 1.0000000e+00 2.3367349e-23 3.8703472e-22 4.9298343e-32], sum to 1.0000
[2019-03-26 16:06:09,929] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1756
[2019-03-26 16:06:09,934] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.5808879828875657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912708.653975482, 912708.653975482, 209038.4272906284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2980800.0000, 
sim time next is 2981400.0000, 
raw observation next is [21.66666666666667, 90.0, 1.0, 2.0, 0.6884180546139048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1083074.385866981, 1083074.385866981, 232968.1364439665], 
processed observation next is [1.0, 0.5217391304347826, 0.22590837282780438, 0.9, 1.0, 1.0, 0.6246000657998853, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3008539960741614, 0.3008539960741614, 0.3477136364835321], 
reward next is 0.6523, 
noisyNet noise sample is [array([1.089016], dtype=float32), 0.20022525]. 
=============================================
[2019-03-26 16:06:14,019] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5487783e-21 1.0000000e+00 4.6430769e-23 2.2113733e-22 2.0100845e-31], sum to 1.0000
[2019-03-26 16:06:14,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5288
[2019-03-26 16:06:14,036] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.6208827562282309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 934995.076949588, 934995.0769495873, 213121.615267202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3059400.0000, 
sim time next is 3060000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.594342783005197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 895015.1927884435, 895015.1927884435, 207700.950212236], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 1.0, 1.0, 1.0, 0.5112563650665024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2486153313301232, 0.2486153313301232, 0.3100014182272179], 
reward next is 0.6900, 
noisyNet noise sample is [array([1.6973388], dtype=float32), 1.3371112]. 
=============================================
[2019-03-26 16:06:14,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[67.87696 ]
 [68.075195]
 [68.25592 ]
 [68.28485 ]
 [68.23218 ]], R is [[67.96702576]
 [67.96926117]
 [67.97611237]
 [67.99160767]
 [68.00852203]].
[2019-03-26 16:06:21,925] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0377021e-22 1.0000000e+00 4.8826349e-24 2.7514881e-23 2.0745947e-32], sum to 1.0000
[2019-03-26 16:06:21,932] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0875
[2019-03-26 16:06:21,938] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 92.0, 1.0, 2.0, 0.4772328137999958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666848.7250758626, 666848.7250758626, 180105.6427070112], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3204000.0000, 
sim time next is 3204600.0000, 
raw observation next is [25.0, 91.66666666666667, 1.0, 2.0, 0.4755660274847455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664518.9565794333, 664518.956579434, 179856.1365504404], 
processed observation next is [0.0, 0.08695652173913043, 0.38388625592417064, 0.9166666666666667, 1.0, 1.0, 0.36815184034306686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18458859904984257, 0.18458859904984276, 0.2684419948514036], 
reward next is 0.7316, 
noisyNet noise sample is [array([0.0117734], dtype=float32), -0.79084176]. 
=============================================
[2019-03-26 16:06:23,081] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8830832e-25 1.0000000e+00 2.2238623e-27 2.1269933e-26 4.2904643e-36], sum to 1.0000
[2019-03-26 16:06:23,092] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6299
[2019-03-26 16:06:23,096] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 66.16666666666666, 1.0, 2.0, 0.5461988551441728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763251.2309266883, 763251.2309266883, 191151.2970614113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3610200.0000, 
sim time next is 3610800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5413068819972214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756412.8167876226, 756412.8167876233, 190321.2363310945], 
processed observation next is [1.0, 0.8260869565217391, 0.6682464454976303, 0.66, 1.0, 1.0, 0.44735768915327884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21011467132989517, 0.21011467132989536, 0.2840615467628276], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.8673737], dtype=float32), -0.5749664]. 
=============================================
[2019-03-26 16:06:26,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3381255e-22 1.0000000e+00 4.5115861e-23 6.3176134e-23 1.2612615e-31], sum to 1.0000
[2019-03-26 16:06:26,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7689
[2019-03-26 16:06:26,989] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.00000000000001, 1.0, 2.0, 0.5146523632729149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719153.6477883166, 719153.647788316, 185923.4973853219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3276600.0000, 
sim time next is 3277200.0000, 
raw observation next is [27.66666666666667, 79.0, 1.0, 2.0, 0.5115656084541126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714838.8946300927, 714838.8946300927, 185427.6951711184], 
processed observation next is [0.0, 0.9565217391304348, 0.5102685624012641, 0.79, 1.0, 1.0, 0.41152482946278623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1985663596194702, 0.1985663596194702, 0.27675775398674385], 
reward next is 0.7232, 
noisyNet noise sample is [array([1.0137811], dtype=float32), 0.56333953]. 
=============================================
[2019-03-26 16:06:31,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8970311e-21 1.0000000e+00 9.1041333e-23 1.8802651e-22 1.1631131e-30], sum to 1.0000
[2019-03-26 16:06:31,750] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1731
[2019-03-26 16:06:31,757] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 83.16666666666667, 1.0, 2.0, 0.5461071983525783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763123.1049005303, 763123.1049005303, 191135.0438016164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3355800.0000, 
sim time next is 3356400.0000, 
raw observation next is [28.0, 82.33333333333334, 1.0, 2.0, 0.541350303648928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756473.5150540927, 756473.5150540927, 190328.0800522262], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.8233333333333335, 1.0, 1.0, 0.44741000439629874, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2101315319594702, 0.2101315319594702, 0.2840717612719794], 
reward next is 0.7159, 
noisyNet noise sample is [array([-1.3840258], dtype=float32), -0.6505019]. 
=============================================
[2019-03-26 16:06:33,611] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.21643827e-24 1.00000000e+00 1.10999655e-26 1.45982642e-25
 1.13509671e-35], sum to 1.0000
[2019-03-26 16:06:33,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0935
[2019-03-26 16:06:33,624] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 66.66666666666667, 1.0, 2.0, 0.5576751982178993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779294.0074643632, 779294.0074643632, 193126.7232788616], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3781200.0000, 
sim time next is 3781800.0000, 
raw observation next is [31.5, 66.5, 1.0, 2.0, 0.5525429257997592, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772119.5754417912, 772119.5754417912, 192238.6510454855], 
processed observation next is [1.0, 0.782608695652174, 0.6919431279620853, 0.665, 1.0, 1.0, 0.460895091325011, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.214477659844942, 0.214477659844942, 0.2869233597693813], 
reward next is 0.7131, 
noisyNet noise sample is [array([-0.09679617], dtype=float32), 1.2219572]. 
=============================================
[2019-03-26 16:06:37,942] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.3043257e-24 1.0000000e+00 2.2248244e-24 1.6215808e-24 2.3089104e-32], sum to 1.0000
[2019-03-26 16:06:37,952] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8537
[2019-03-26 16:06:37,959] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.66666666666667, 1.0, 2.0, 0.6045622374870508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844839.9029176588, 844839.9029176594, 201599.4660853402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3855000.0000, 
sim time next is 3855600.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5995248817101846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837797.7203946159, 837797.7203946159, 200657.9150921838], 
processed observation next is [0.0, 0.6521739130434783, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5174998574821501, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23272158899850443, 0.23272158899850443, 0.2994894255107221], 
reward next is 0.7005, 
noisyNet noise sample is [array([1.5514638], dtype=float32), -0.5901993]. 
=============================================
[2019-03-26 16:06:43,460] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3806411e-20 1.0000000e+00 1.0193584e-21 2.1096746e-20 6.1058455e-29], sum to 1.0000
[2019-03-26 16:06:43,469] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8572
[2019-03-26 16:06:43,472] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8997118816485835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1257538.258746913, 1257538.258746913, 269854.9234964281], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3550800.0000, 
sim time next is 3551400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7947494250403578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1110754.217460622, 1110754.217460622, 242622.5759142873], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7527101506510335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30854283818350614, 0.30854283818350614, 0.36212324763326464], 
reward next is 0.6379, 
noisyNet noise sample is [array([0.91070336], dtype=float32), -0.18462493]. 
=============================================
[2019-03-26 16:06:44,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.4245985e-23 1.0000000e+00 1.0610158e-23 1.4995862e-23 1.3208776e-32], sum to 1.0000
[2019-03-26 16:06:44,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4596
[2019-03-26 16:06:44,103] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.610584911719432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853259.6139355367, 853259.6139355374, 202733.9930727872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3964200.0000, 
sim time next is 3964800.0000, 
raw observation next is [31.33333333333334, 73.66666666666667, 1.0, 2.0, 0.6046563939403528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 844971.5333202941, 844971.5333202948, 201616.6447879491], 
processed observation next is [0.0, 0.9130434782608695, 0.6840442338072673, 0.7366666666666667, 1.0, 1.0, 0.5236824023377744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23471431481119281, 0.234714314811193, 0.30092036535514793], 
reward next is 0.6991, 
noisyNet noise sample is [array([0.4227993], dtype=float32), -0.18462794]. 
=============================================
[2019-03-26 16:06:49,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1725851e-09 9.9964774e-01 9.2795530e-13 3.5228141e-04 3.2158026e-17], sum to 1.0000
[2019-03-26 16:06:49,350] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2699
[2019-03-26 16:06:49,358] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2009061.487888991 W.
[2019-03-26 16:06:49,367] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.66666666666667, 72.66666666666667, 1.0, 2.0, 0.4789658409753284, 1.0, 2.0, 0.4789658409753284, 1.0, 2.0, 0.8273089804545347, 6.9112, 6.9112, 170.5573041426782, 2009061.487888991, 2009061.487888991, 400131.62685101], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3662400.0000, 
sim time next is 3663000.0000, 
raw observation next is [30.0, 72.0, 1.0, 2.0, 0.7480664146488265, 1.0, 2.0, 0.7480664146488265, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2091964.805381394, 2091964.805381394, 395379.7187866943], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.72, 1.0, 1.0, 0.6964655598178633, 1.0, 1.0, 0.6964655598178633, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.581101334828165, 0.581101334828165, 0.5901189832637228], 
reward next is 0.4099, 
noisyNet noise sample is [array([0.6792406], dtype=float32), -0.004708359]. 
=============================================
[2019-03-26 16:06:49,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[47.650517]
 [46.695927]
 [45.903126]
 [45.775787]
 [45.832874]], R is [[48.42609024]
 [48.34461975]
 [47.86117554]
 [47.38256454]
 [47.32694244]].
[2019-03-26 16:06:54,392] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9933443e-26 1.0000000e+00 1.7733963e-27 1.8702221e-29 2.9837187e-37], sum to 1.0000
[2019-03-26 16:06:54,399] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5846
[2019-03-26 16:06:54,404] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 76.5, 1.0, 2.0, 0.5952074269520723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831761.9908162386, 831761.9908162386, 199856.6772586214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4133400.0000, 
sim time next is 4134000.0000, 
raw observation next is [30.33333333333334, 78.0, 1.0, 2.0, 0.5921317202988599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827462.2252508991, 827462.2252508991, 199289.4378216687], 
processed observation next is [1.0, 0.8695652173913043, 0.6366508688783573, 0.78, 1.0, 1.0, 0.5085924340950119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22985061812524976, 0.22985061812524976, 0.29744692212189355], 
reward next is 0.7026, 
noisyNet noise sample is [array([0.8933542], dtype=float32), 1.462596]. 
=============================================
[2019-03-26 16:06:54,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[68.93618 ]
 [69.11695 ]
 [69.21741 ]
 [69.476494]
 [69.75976 ]], R is [[68.74626923]
 [68.76051331]
 [68.77380371]
 [68.78607941]
 [68.79728699]].
[2019-03-26 16:06:57,143] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 16:06:57,145] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:06:57,148] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:06:57,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:06:57,151] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:06:57,156] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:06:57,158] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:06:57,158] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:06:57,159] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:06:57,159] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:06:57,160] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:06:57,175] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 16:06:57,196] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 16:06:57,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 16:06:57,232] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 16:06:57,232] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 16:06:58,658] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:06:58,660] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.63333333333333, 63.66666666666666, 1.0, 2.0, 0.5751566638488416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 828433.0859573588, 828433.0859573588, 199364.3856512075]
[2019-03-26 16:06:58,662] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:06:58,665] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.5228956e-25 1.0000000e+00 2.8428257e-25 1.7817631e-28 1.1551214e-33], sampled 0.5932015105103934
[2019-03-26 16:07:22,993] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:07:22,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.81065057333333, 85.29054010666667, 1.0, 2.0, 0.5512678090133339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770337.0901431429, 770337.0901431429, 192018.0560407895]
[2019-03-26 16:07:22,995] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:07:22,998] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9898552e-24 1.0000000e+00 7.9439393e-25 2.9499078e-26 1.5872579e-33], sampled 0.19601953831579488
[2019-03-26 16:07:24,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:07:24,322] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.01666666666667, 91.66666666666667, 1.0, 2.0, 0.8180472116404325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1189346.0457431, 1189346.0457431, 254830.9724059374]
[2019-03-26 16:07:24,323] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:07:24,327] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.5597078e-22 1.0000000e+00 1.4842097e-22 2.3018141e-24 1.6588529e-30], sampled 0.7530065316893486
[2019-03-26 16:07:34,094] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:07:34,095] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.23358952, 88.23744587, 1.0, 2.0, 0.44864012923108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654126.7688656411, 654126.7688656411, 179404.2330975339]
[2019-03-26 16:07:34,096] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:07:34,101] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3362613e-24 1.0000000e+00 2.9843515e-25 3.2431520e-27 4.9203227e-34], sampled 0.01771142168108264
[2019-03-26 16:07:44,379] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:07:44,383] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.55666197, 68.68181741, 1.0, 2.0, 0.6099179997844225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 852327.2663864809, 852327.2663864803, 202608.6437657593]
[2019-03-26 16:07:44,383] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:07:44,385] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2227271e-25 1.0000000e+00 2.4359892e-25 1.9696081e-28 8.4225337e-34], sampled 0.6951371842778367
[2019-03-26 16:07:59,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:07:59,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.74163870833333, 91.75715433833334, 1.0, 2.0, 0.9280475473343212, 1.0, 2.0, 0.9280475473343212, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 172.86236624, 2595789.01175386, 2595789.01175386, 487510.5380191064]
[2019-03-26 16:07:59,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:07:59,678] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9107707e-10 9.9996686e-01 7.9209617e-15 3.3188615e-05 3.7005390e-19], sampled 0.8802678869914807
[2019-03-26 16:07:59,679] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2595789.01175386 W.
[2019-03-26 16:08:00,905] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:08:00,906] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.41666666666666, 47.66666666666666, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.931153695653192, 6.9112, 168.9072651024568, 3007911.286595725, 2284345.411687244, 473731.3319189785]
[2019-03-26 16:08:00,907] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:08:00,909] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9764395e-14 1.0000000e+00 1.0080112e-17 5.1561233e-10 1.9419714e-23], sampled 0.7014554772551252
[2019-03-26 16:08:00,911] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3007911.286595725 W.
[2019-03-26 16:08:21,713] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00987788], dtype=float32), 0.081054315]
[2019-03-26 16:08:21,715] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.35, 55.0, 1.0, 2.0, 0.7973964629394293, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00598136563001, 6.9112, 168.9123160068359, 2011429.675523199, 1944188.767595205, 407215.8390667252]
[2019-03-26 16:08:21,716] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:08:21,720] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00900765e-17 1.00000000e+00 1.96619943e-21 6.30969157e-15
 2.21277679e-27], sampled 0.1181551000929636
[2019-03-26 16:08:21,722] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2011429.675523199 W.
[2019-03-26 16:08:52,142] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.7507 3164307242.1410 1777.0000
[2019-03-26 16:08:52,677] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2899 2927407109.7953 1338.0000
[2019-03-26 16:08:52,736] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:08:52,977] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6390 2842649219.4474 1131.0000
[2019-03-26 16:08:53,059] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.3673 3007785402.7744 1766.0000
[2019-03-26 16:08:54,077] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 950000, evaluation results [950000.0, 7882.750654250539, 3164307242.141041, 1777.0, 8254.289933546808, 2927407109.795325, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7997.367263813297, 3007785402.77445, 1766.0, 8496.6390034736, 2842649219.4473543, 1131.0]
[2019-03-26 16:09:12,237] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.9378048e-08 9.1054839e-01 1.2828661e-13 8.9451484e-02 3.7728621e-17], sum to 1.0000
[2019-03-26 16:09:12,249] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1581
[2019-03-26 16:09:12,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2802150.614324703 W.
[2019-03-26 16:09:12,268] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333333, 72.33333333333334, 1.0, 2.0, 1.001729522293417, 1.0, 2.0, 1.001729522293417, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2802150.614324703, 2802150.614324703, 530036.6639319637], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4099800.0000, 
sim time next is 4100400.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 1.000389288514533, 1.0, 2.0, 1.000389288514533, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2798397.362318611, 2798397.362318611, 529225.4931960028], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.71, 1.0, 1.0, 1.0004690223066661, 1.0, 1.0, 1.0004690223066661, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7773326006440585, 0.7773326006440585, 0.7898887958149295], 
reward next is 0.2101, 
noisyNet noise sample is [array([0.25084013], dtype=float32), -0.63036877]. 
=============================================
[2019-03-26 16:09:17,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3649070e-08 3.3572018e-02 4.9374011e-14 9.6642792e-01 7.2766855e-18], sum to 1.0000
[2019-03-26 16:09:17,538] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2411
[2019-03-26 16:09:17,543] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.33333333333334, 52.0, 1.0, 2.0, 0.8676060855951158, 1.0, 2.0, 0.7543930823118207, 1.0, 1.0, 1.03, 7.00511095146325, 6.9112, 170.5573041426782, 3165870.2807101, 3098598.046123708, 579495.6216764896], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4203600.0000, 
sim time next is 4204200.0000, 
raw observation next is [36.16666666666666, 52.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.59123620170763, 6.9112, 170.5573041426782, 3397034.777316046, 2909897.183928791, 549891.8138731275], 
processed observation next is [1.0, 0.6521739130434783, 0.9131121642969979, 0.525, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.06800362017076296, 0.0, 0.8375144448122397, 0.9436207714766794, 0.808304773313553, 0.8207340505569066], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9520616], dtype=float32), -0.8356164]. 
=============================================
[2019-03-26 16:09:29,048] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9274344e-24 1.0000000e+00 1.5862474e-25 1.9283530e-29 5.5737735e-35], sum to 1.0000
[2019-03-26 16:09:29,056] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3396
[2019-03-26 16:09:29,061] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6172120494033209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 862524.4432381731, 862524.4432381738, 203997.1329587804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4396800.0000, 
sim time next is 4397400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.616364673260863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 861339.7952720759, 861339.7952720753, 203835.1097823063], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5377887629648951, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2392610542422433, 0.23926105424224314, 0.3042315071377706], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.27212623], dtype=float32), 1.9490099]. 
=============================================
[2019-03-26 16:09:32,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4628238e-14 1.0000000e+00 9.1380069e-19 4.7105597e-11 4.3128895e-24], sum to 1.0000
[2019-03-26 16:09:32,701] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7874
[2019-03-26 16:09:32,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2596245.768278526 W.
[2019-03-26 16:09:32,718] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666666, 69.0, 1.0, 2.0, 0.618798555704056, 1.0, 2.0, 0.618798555704056, 1.0, 1.0, 1.03, 6.961393203791299, 6.9112, 170.5573041426782, 2596245.768278526, 2560290.334673828, 494895.5725998296], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4639200.0000, 
sim time next is 4639800.0000, 
raw observation next is [31.33333333333334, 69.5, 1.0, 2.0, 0.9161135093344275, 1.0, 2.0, 0.9161135093344275, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2562410.258135497, 2562410.258135497, 480360.0765640668], 
processed observation next is [1.0, 0.6956521739130435, 0.6840442338072673, 0.695, 1.0, 1.0, 0.8989319389571415, 1.0, 1.0, 0.8989319389571415, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7117806272598604, 0.7117806272598604, 0.7169553381553236], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1570348], dtype=float32), 0.3852233]. 
=============================================
[2019-03-26 16:09:33,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5444709e-29 1.0000000e+00 3.5752019e-29 1.3706467e-34 4.6753712e-38], sum to 1.0000
[2019-03-26 16:09:33,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0889
[2019-03-26 16:09:33,281] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 83.16666666666667, 1.0, 2.0, 0.5815724154656606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 812700.6978889741, 812700.6978889747, 197363.1852121624], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4432200.0000, 
sim time next is 4432800.0000, 
raw observation next is [29.33333333333334, 82.33333333333334, 1.0, 2.0, 0.5826276356725464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814175.8484580095, 814175.8484580095, 197554.2035287762], 
processed observation next is [0.0, 0.30434782608695654, 0.5892575039494474, 0.8233333333333335, 1.0, 1.0, 0.4971417297259595, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22615995790500265, 0.22615995790500265, 0.2948570201922033], 
reward next is 0.7051, 
noisyNet noise sample is [array([-1.8116373], dtype=float32), 1.2382383]. 
=============================================
[2019-03-26 16:09:48,430] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.9055520e-20 1.0000000e+00 5.9835445e-22 6.4313154e-23 8.1811864e-30], sum to 1.0000
[2019-03-26 16:09:48,439] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6675
[2019-03-26 16:09:48,444] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 83.16666666666667, 1.0, 2.0, 0.8018281900160361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1120652.830650528, 1120652.830650527, 244360.9320847051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4691400.0000, 
sim time next is 4692000.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.8620881488115991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1204921.269443467, 1204921.269443467, 259722.8437797384], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.8233333333333335, 1.0, 1.0, 0.8338411431465049, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33470035262318526, 0.33470035262318526, 0.3876460354921469], 
reward next is 0.6124, 
noisyNet noise sample is [array([0.2664052], dtype=float32), -0.19451481]. 
=============================================
[2019-03-26 16:09:48,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[54.88388 ]
 [54.696938]
 [54.523674]
 [54.220497]
 [54.06176 ]], R is [[54.6022644 ]
 [54.69152451]
 [54.77733231]
 [54.86771011]
 [54.94342422]].
[2019-03-26 16:09:50,282] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 16:09:50,283] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:09:50,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:09:50,285] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:09:50,286] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:09:50,285] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:09:50,286] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:09:50,288] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:09:50,289] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:09:50,290] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:09:50,292] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:09:50,306] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 16:09:50,323] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 16:09:50,354] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 16:09:50,354] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 16:09:50,395] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 16:09:51,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:09:51,750] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.96950897, 74.58479374, 1.0, 2.0, 0.3639212578500496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581117.3137601841, 581117.3137601847, 173553.6789464121]
[2019-03-26 16:09:51,752] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:09:51,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9140064e-26 1.0000000e+00 1.5086783e-26 2.8646327e-31 1.8202843e-35], sampled 0.9212246510447312
[2019-03-26 16:10:08,625] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:10:08,627] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.050247365, 88.49816996, 1.0, 2.0, 0.3553686196213038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 554377.8352507958, 554377.8352507952, 171180.3356009816]
[2019-03-26 16:10:08,628] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:10:08,632] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2428065e-24 1.0000000e+00 3.8862897e-25 1.9055609e-28 4.4183963e-34], sampled 0.19811926300783833
[2019-03-26 16:10:14,562] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:10:14,562] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.1, 96.0, 1.0, 2.0, 0.4184945992397313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 616663.8918163064, 616663.8918163057, 175882.3832728108]
[2019-03-26 16:10:14,563] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:10:14,567] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.1271935e-24 1.0000000e+00 6.7167256e-25 9.5663906e-28 5.7448085e-34], sampled 0.7527059460904805
[2019-03-26 16:10:20,550] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:10:20,553] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.56361647666667, 79.669928485, 1.0, 2.0, 0.5100490209757639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712718.9721948553, 712718.9721948553, 185185.3191785355]
[2019-03-26 16:10:20,554] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:10:20,557] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4974171e-26 1.0000000e+00 3.6016542e-26 1.9531307e-30 3.4664631e-35], sampled 0.1859068118648205
[2019-03-26 16:10:57,028] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:10:57,029] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.34445551833333, 92.05821619333335, 1.0, 2.0, 0.9898042856562512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1383543.56142553, 1383543.561425531, 295842.3669515183]
[2019-03-26 16:10:57,030] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:10:57,032] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.0998138e-22 1.0000000e+00 9.7104688e-23 5.7170924e-25 8.9034171e-31], sampled 0.46032444834101327
[2019-03-26 16:11:10,740] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00584021], dtype=float32), 0.08003969]
[2019-03-26 16:11:10,741] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.176970475, 82.20453696333333, 1.0, 2.0, 0.5284666632482309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738463.88160335, 738463.88160335, 188174.9505482067]
[2019-03-26 16:11:10,742] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:11:10,744] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.3213155e-25 1.0000000e+00 7.9189740e-26 2.0050103e-28 5.1611153e-35], sampled 0.9570724476875712
[2019-03-26 16:11:45,739] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5043 3164246279.9728 1777.0000
[2019-03-26 16:11:45,936] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.0250 3007848960.6402 1766.0000
[2019-03-26 16:11:46,067] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 16:11:46,105] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:11:46,161] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3928 2842574156.6246 1131.0000
[2019-03-26 16:11:47,177] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 975000, evaluation results [975000.0, 7883.50430590148, 3164246279.9727592, 1777.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.024995752096, 3007848960.6401815, 1766.0, 8497.392829644317, 2842574156.6245975, 1131.0]
[2019-03-26 16:11:50,176] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3180152e-24 1.0000000e+00 1.0986866e-24 3.3519246e-28 2.4851714e-33], sum to 1.0000
[2019-03-26 16:11:50,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9247
[2019-03-26 16:11:50,190] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6414176210425633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 896364.8508104136, 896364.8508104136, 208705.0979931641], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4773600.0000, 
sim time next is 4774200.0000, 
raw observation next is [27.16666666666666, 79.83333333333334, 1.0, 2.0, 0.5919076776101134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827149.0195213107, 827149.0195213107, 199241.0098672827], 
processed observation next is [1.0, 0.2608695652173913, 0.4865718799368086, 0.7983333333333335, 1.0, 1.0, 0.5083225031447149, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22976361653369742, 0.22976361653369742, 0.29737464159295923], 
reward next is 0.7026, 
noisyNet noise sample is [array([-0.80598605], dtype=float32), -0.98014677]. 
=============================================
[2019-03-26 16:11:52,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5103032e-08 9.9954140e-01 2.1239719e-14 4.5859805e-04 3.2252374e-18], sum to 1.0000
[2019-03-26 16:11:52,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7548
[2019-03-26 16:11:52,179] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2617164.754386599 W.
[2019-03-26 16:11:52,185] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.365285103584306, 6.9112, 168.9103546248103, 2617164.754386599, 2295026.115706271, 475656.4657676927], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4793400.0000, 
sim time next is 4794000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8463618294588081, 1.0, 1.0, 0.8463618294588081, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2367126.909631631, 2367126.909631631, 443069.8479007386], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.8148937704322989, 1.0, 0.5, 0.8148937704322989, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.657535252675453, 0.657535252675453, 0.6612982804488635], 
reward next is 0.3387, 
noisyNet noise sample is [array([-0.1236334], dtype=float32), -0.50686157]. 
=============================================
[2019-03-26 16:11:52,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[49.936237]
 [49.887745]
 [49.90484 ]
 [49.602562]
 [49.04644 ]], R is [[48.83688354]
 [48.34851456]
 [47.86502838]
 [47.78003311]
 [47.69494247]].
[2019-03-26 16:12:08,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5647780e-27 1.0000000e+00 2.2468172e-27 2.2135659e-31 2.2295346e-36], sum to 1.0000
[2019-03-26 16:12:08,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7422
[2019-03-26 16:12:08,159] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 60.33333333333333, 1.0, 2.0, 0.5212675674919582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728400.6263068545, 728400.6263068538, 186995.8504322216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5064000.0000, 
sim time next is 5064600.0000, 
raw observation next is [31.83333333333333, 59.66666666666667, 1.0, 2.0, 0.5220691881744673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729521.1669824453, 729521.1669824459, 187126.6090841035], 
processed observation next is [0.0, 0.6086956521739131, 0.7077409162717218, 0.5966666666666667, 1.0, 1.0, 0.42417974478851483, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2026447686062348, 0.20264476860623495, 0.2792934463941843], 
reward next is 0.7207, 
noisyNet noise sample is [array([-1.1107173], dtype=float32), -0.08904892]. 
=============================================
[2019-03-26 16:12:08,972] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3011179e-26 1.0000000e+00 2.0594843e-27 1.2256503e-31 1.0468051e-36], sum to 1.0000
[2019-03-26 16:12:08,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7135
[2019-03-26 16:12:08,992] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 67.66666666666667, 1.0, 2.0, 0.5266637652255756, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735943.6918311836, 735943.6918311842, 187879.5799000853], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071200.0000, 
sim time next is 5071800.0000, 
raw observation next is [30.16666666666666, 68.83333333333333, 1.0, 2.0, 0.5281310652742466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737994.7638898012, 737994.7638898012, 188121.4172582703], 
processed observation next is [0.0, 0.6956521739130435, 0.6287519747235385, 0.6883333333333332, 1.0, 1.0, 0.431483211173791, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2049985455249448, 0.2049985455249448, 0.28077823471383623], 
reward next is 0.7192, 
noisyNet noise sample is [array([-1.531797], dtype=float32), 0.0016660563]. 
=============================================
[2019-03-26 16:12:11,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1269094e-25 1.0000000e+00 1.1015013e-26 4.7643106e-31 3.6357613e-35], sum to 1.0000
[2019-03-26 16:12:11,259] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.5446206e-26 1.0000000e+00 1.3192753e-26 1.0091049e-30 3.5028589e-35], sum to 1.0000
[2019-03-26 16:12:11,261] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5958
[2019-03-26 16:12:11,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3450
[2019-03-26 16:12:11,270] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.5122393071937514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715780.6082808475, 715780.6082808468, 185535.990862769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5123400.0000, 
sim time next is 5124000.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5150709156731073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719738.71351649, 719738.71351649, 185991.1029217095], 
processed observation next is [0.0, 0.30434782608695654, 0.5102685624012641, 0.8066666666666668, 1.0, 1.0, 0.41574809117241834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1999274204212472, 0.1999274204212472, 0.27759866107717834], 
reward next is 0.7224, 
noisyNet noise sample is [array([1.3977053], dtype=float32), 0.344]. 
=============================================
[2019-03-26 16:12:11,271] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5103689724725529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713166.2077364186, 713166.2077364192, 185236.5954961804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5132400.0000, 
sim time next is 5133000.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5102681719364942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713025.3064145406, 713025.3064145413, 185220.5000598621], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.40996165293553516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19806258511515018, 0.19806258511515037, 0.276448507552033], 
reward next is 0.7236, 
noisyNet noise sample is [array([-1.4598819], dtype=float32), 0.90573835]. 
=============================================
[2019-03-26 16:12:11,286] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.93837 ]
 [69.987755]
 [70.00742 ]
 [70.05654 ]
 [70.09973 ]], R is [[69.91996765]
 [69.94385529]
 [69.96847534]
 [69.99412537]
 [70.02075195]].
[2019-03-26 16:12:11,299] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.158134]
 [71.051   ]
 [70.940956]
 [70.82969 ]
 [70.79183 ]], R is [[71.27000427]
 [71.28083038]
 [71.29152679]
 [71.30171967]
 [71.30916595]].
[2019-03-26 16:12:18,017] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3299824e-23 1.0000000e+00 3.0062799e-24 2.7888829e-25 3.8033656e-33], sum to 1.0000
[2019-03-26 16:12:18,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6446
[2019-03-26 16:12:18,034] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 82.33333333333333, 1.0, 2.0, 0.5520011049038989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771362.1638402259, 771362.1638402259, 192144.7478012505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5265600.0000, 
sim time next is 5266200.0000, 
raw observation next is [28.5, 82.66666666666667, 1.0, 2.0, 0.5529708411243391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772717.758790971, 772717.758790971, 192311.8374464314], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8266666666666667, 1.0, 1.0, 0.46141065195703507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21464382188638084, 0.21464382188638084, 0.28703259320362895], 
reward next is 0.7130, 
noisyNet noise sample is [array([0.74649435], dtype=float32), 0.43305388]. 
=============================================
[2019-03-26 16:12:18,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8966393e-22 1.0000000e+00 7.6910799e-24 3.8514598e-25 8.8090173e-33], sum to 1.0000
[2019-03-26 16:12:18,061] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0158
[2019-03-26 16:12:18,065] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 86.66666666666667, 1.0, 2.0, 0.5773297826347883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806769.7079644799, 806769.7079644799, 196598.8073998505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5276400.0000, 
sim time next is 5277000.0000, 
raw observation next is [28.6, 86.83333333333333, 1.0, 2.0, 0.5786719237302794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808645.950957457, 808645.950957457, 196840.0829238772], 
processed observation next is [1.0, 0.043478260869565216, 0.5545023696682465, 0.8683333333333333, 1.0, 1.0, 0.4923758117232282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22462387526596025, 0.22462387526596025, 0.2937911685431003], 
reward next is 0.7062, 
noisyNet noise sample is [array([0.8336693], dtype=float32), -0.46072164]. 
=============================================
[2019-03-26 16:12:18,084] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[62.16103 ]
 [62.221382]
 [62.299625]
 [62.371197]
 [62.460873]], R is [[62.19916916]
 [62.28374863]
 [62.36768341]
 [62.45106506]
 [62.5340004 ]].
[2019-03-26 16:12:20,804] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.0810426e-09 9.9974090e-01 1.8773214e-13 2.5913253e-04 3.1665537e-18], sum to 1.0000
[2019-03-26 16:12:20,814] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1027
[2019-03-26 16:12:20,822] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3284307.794441003 W.
[2019-03-26 16:12:20,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.11666666666667, 52.83333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.434054268433384, 6.9112, 170.5573041426782, 3284307.794441003, 2909766.013610345, 550821.0792587537], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5320200.0000, 
sim time next is 5320800.0000, 
raw observation next is [36.1, 53.0, 1.0, 2.0, 0.7455030586740549, 1.0, 2.0, 0.6933415688512901, 1.0, 1.0, 1.03, 7.005101320304163, 6.9112, 170.5573041426782, 2909364.367970282, 2842099.032574914, 536086.9158591079], 
processed observation next is [1.0, 0.6086956521739131, 0.9099526066350712, 0.53, 1.0, 1.0, 0.6933771791253673, 1.0, 1.0, 0.6305320106642048, 1.0, 0.5, 1.0365853658536586, 0.009390132030416342, 0.0, 0.8375144448122397, 0.8081567688806339, 0.7894719534930317, 0.8001297251628475], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26624772], dtype=float32), -0.63519895]. 
=============================================
[2019-03-26 16:12:21,603] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0460916e-14 1.0000000e+00 5.4905693e-18 1.9686036e-11 2.4386495e-24], sum to 1.0000
[2019-03-26 16:12:21,610] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9151
[2019-03-26 16:12:21,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2554540.48390455 W.
[2019-03-26 16:12:21,627] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.18333333333334, 52.16666666666667, 1.0, 2.0, 0.6088685194157466, 1.0, 1.0, 0.6088685194157466, 1.0, 2.0, 1.03, 6.94200587464997, 6.9112, 170.5573041426782, 2554540.48390455, 2532472.982789914, 491217.5857724019], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5317800.0000, 
sim time next is 5318400.0000, 
raw observation next is [36.16666666666667, 52.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.022539964670163, 6.9112, 170.5573041426782, 2989180.001480951, 2909422.655767518, 553069.0782755243], 
processed observation next is [1.0, 0.5652173913043478, 0.9131121642969986, 0.5233333333333334, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.011133996467016339, 0.0, 0.8375144448122397, 0.830327778189153, 0.8081729599354217, 0.8254762362321258], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12136554], dtype=float32), -0.8274021]. 
=============================================
[2019-03-26 16:12:23,478] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3233777e-09 9.9999106e-01 1.1668052e-14 8.9394407e-06 1.5580101e-19], sum to 1.0000
[2019-03-26 16:12:23,487] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9312
[2019-03-26 16:12:23,490] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.65, 55.16666666666666, 1.0, 2.0, 0.3165800653924424, 1.0, 2.0, 0.3165800653924424, 1.0, 2.0, 0.5497948789592195, 6.911199999999999, 6.9112, 170.5573041426782, 1327499.158622647, 1327499.158622647, 311521.0363748539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5332200.0000, 
sim time next is 5332800.0000, 
raw observation next is [35.4, 56.33333333333334, 1.0, 2.0, 0.5837040216029895, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564927791, 815680.5898710499, 815680.5898710499, 197751.9939053988], 
processed observation next is [1.0, 0.7391304347826086, 0.8767772511848341, 0.5633333333333335, 1.0, 1.0, 0.49843858024456567, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399450656238, 0.22657794163084718, 0.22657794163084718, 0.2951522297095504], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.819154], dtype=float32), -0.12570171]. 
=============================================
[2019-03-26 16:12:24,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.5223817e-07 6.1918849e-01 7.4296957e-12 3.8081053e-01 1.6561181e-15], sum to 1.0000
[2019-03-26 16:12:24,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4675
[2019-03-26 16:12:24,092] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3375732.220021084 W.
[2019-03-26 16:12:24,095] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.3, 52.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.561532781006598, 6.9112, 170.5573041426782, 3375732.220021084, 2909872.395139881, 550070.5069853985], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5313600.0000, 
sim time next is 5314200.0000, 
raw observation next is [36.28333333333333, 52.0, 1.0, 2.0, 0.7782137763380453, 1.0, 2.0, 0.7096969276832852, 1.0, 1.0, 1.03, 7.005103900050114, 6.9112, 170.5573041426782, 2978075.701003708, 2910808.517631379, 547171.0772768718], 
processed observation next is [1.0, 0.5217391304347826, 0.9186413902053712, 0.52, 1.0, 1.0, 0.7327876823349944, 1.0, 1.0, 0.6502372622690182, 1.0, 0.5, 1.0365853658536586, 0.009390390005011361, 0.0, 0.8375144448122397, 0.8272432502788077, 0.808557921564272, 0.8166732496669727], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.57544637], dtype=float32), 0.98595357]. 
=============================================
[2019-03-26 16:12:38,384] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1669836e-23 1.0000000e+00 1.0711047e-24 1.8277227e-27 2.9826422e-34], sum to 1.0000
[2019-03-26 16:12:38,394] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5546
[2019-03-26 16:12:38,400] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 90.0, 1.0, 2.0, 0.5340010684298273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746200.2141612999, 746200.2141613004, 189094.3196509706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5612400.0000, 
sim time next is 5613000.0000, 
raw observation next is [26.55, 90.16666666666667, 1.0, 2.0, 0.5314635425979242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742653.097212558, 742653.0972125573, 188672.2222992554], 
processed observation next is [1.0, 1.0, 0.4573459715639811, 0.9016666666666667, 1.0, 1.0, 0.4354982440938845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20629252700348835, 0.20629252700348816, 0.28160033178993343], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.09851034], dtype=float32), 1.8684202]. 
=============================================
[2019-03-26 16:12:38,415] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[61.279537]
 [61.25309 ]
 [61.26217 ]
 [61.27491 ]
 [61.31044 ]], R is [[61.383255  ]
 [61.48719406]
 [61.58956146]
 [61.69032288]
 [61.78933334]].
[2019-03-26 16:12:43,718] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 16:12:43,720] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:12:43,721] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:12:43,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:12:43,722] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:12:43,724] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:12:43,722] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:12:43,725] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:12:43,728] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:12:43,728] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:12:43,730] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:12:44,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 16:12:44,178] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 16:12:44,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 16:12:44,351] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 16:12:44,583] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 16:13:06,684] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:13:06,685] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.6, 89.66666666666667, 1.0, 2.0, 0.3063452297009812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483532.9459328792, 483532.9459328799, 165790.6940724863]
[2019-03-26 16:13:06,686] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:13:06,692] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1449410e-30 1.0000000e+00 2.7133712e-30 5.7307889e-38 0.0000000e+00], sampled 0.8260392255078246
[2019-03-26 16:13:09,966] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:13:09,968] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.4, 93.16666666666667, 1.0, 2.0, 0.3280013532986883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515005.1491886139, 515005.1491886139, 168090.5317381071]
[2019-03-26 16:13:09,970] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:13:09,973] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7767420e-29 1.0000000e+00 2.3023087e-29 2.6387360e-35 0.0000000e+00], sampled 0.44065613495716294
[2019-03-26 16:13:25,035] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:13:25,036] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.81206468, 98.25532914333334, 1.0, 2.0, 0.393743255246723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 584866.4338237664, 584866.4338237664, 173065.7354696603]
[2019-03-26 16:13:25,039] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:13:25,041] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5642036e-29 1.0000000e+00 1.1157642e-29 9.0520591e-36 0.0000000e+00], sampled 0.039319528736162956
[2019-03-26 16:13:50,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:13:50,211] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.21350223333333, 99.85306706, 1.0, 2.0, 0.5986035198747228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836509.6690719789, 836509.6690719789, 200486.1441862782]
[2019-03-26 16:13:50,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:13:50,214] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.4109047e-30 1.0000000e+00 1.2710677e-29 9.5255265e-37 0.0000000e+00], sampled 0.23211654044782914
[2019-03-26 16:14:32,128] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:14:32,129] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.30095701, 73.00313313333334, 1.0, 2.0, 0.3419288721499346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546168.6873431272, 546168.6873431278, 170660.799492335]
[2019-03-26 16:14:32,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:14:32,134] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.4790638e-30 1.0000000e+00 6.5825502e-30 2.0882791e-36 0.0000000e+00], sampled 0.3261196671384776
[2019-03-26 16:14:33,321] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.01477676], dtype=float32), 0.08300622]
[2019-03-26 16:14:33,322] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 93.0, 1.0, 2.0, 0.4059162739980898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 597606.4208987879, 597606.4208987873, 174076.9876780622]
[2019-03-26 16:14:33,323] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:14:33,326] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9426275e-29 1.0000000e+00 3.7949387e-29 4.3046801e-35 0.0000000e+00], sampled 0.9696816477255638
[2019-03-26 16:14:39,744] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7881.9141 3164264062.0750 1778.0000
[2019-03-26 16:14:39,759] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 16:14:40,033] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2118 2927459259.5787 1338.0000
[2019-03-26 16:14:40,128] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 16:14:40,201] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6656 2842565299.5504 1131.0000
[2019-03-26 16:14:41,217] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1000000, evaluation results [1000000.0, 7881.914118866076, 3164264062.0749626, 1778.0, 8254.211789258557, 2927459259.5787225, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8496.665578540826, 2842565299.55038, 1131.0]
[2019-03-26 16:14:41,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6546048e-30 1.0000000e+00 3.3194990e-30 2.2164414e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 16:14:41,472] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4686
[2019-03-26 16:14:41,482] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666666, 71.66666666666666, 1.0, 2.0, 0.5329130095245321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744679.2539343757, 744679.2539343757, 188913.6345181573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5683200.0000, 
sim time next is 5683800.0000, 
raw observation next is [29.43333333333333, 72.83333333333334, 1.0, 2.0, 0.5322740261263339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743786.0419720585, 743786.0419720579, 188807.3144585471], 
processed observation next is [0.0, 0.782608695652174, 0.5939968404423379, 0.7283333333333334, 1.0, 1.0, 0.4364747302726914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20660723388112737, 0.2066072338811272, 0.2818019618784285], 
reward next is 0.7182, 
noisyNet noise sample is [array([0.4020032], dtype=float32), 0.8178341]. 
=============================================
[2019-03-26 16:14:50,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4584296e-17 1.0000000e+00 2.2159186e-20 2.8356953e-20 5.7517994e-28], sum to 1.0000
[2019-03-26 16:14:50,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4203
[2019-03-26 16:14:50,080] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 93.16666666666667, 1.0, 2.0, 0.9362284174262068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104306, 1308609.320883164, 1308609.320883163, 280096.8934140843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5803800.0000, 
sim time next is 5804400.0000, 
raw observation next is [26.1, 93.33333333333334, 1.0, 2.0, 0.8847047730548059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1236550.425415989, 1236550.425415989, 265764.2286500966], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.9333333333333335, 1.0, 1.0, 0.8610900880178384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34348622928221917, 0.34348622928221917, 0.396663027835965], 
reward next is 0.6033, 
noisyNet noise sample is [array([1.8324455], dtype=float32), 1.3114073]. 
=============================================
[2019-03-26 16:15:14,825] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0788328e-27 1.0000000e+00 3.2404544e-28 1.7931456e-33 8.7715777e-37], sum to 1.0000
[2019-03-26 16:15:14,832] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-26 16:15:14,841] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 89.5, 1.0, 2.0, 0.5272986350211235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736831.1469815219, 736831.1469815212, 187984.0942567497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6240600.0000, 
sim time next is 6241200.0000, 
raw observation next is [26.86666666666667, 89.33333333333333, 1.0, 2.0, 0.52786251708802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737619.3722879834, 737619.3722879834, 188077.1312553247], 
processed observation next is [0.0, 0.21739130434782608, 0.4723538704581361, 0.8933333333333333, 1.0, 1.0, 0.43115965914219273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2048942700799954, 0.2048942700799954, 0.28071213620197716], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.5374204], dtype=float32), 2.0343978]. 
=============================================
[2019-03-26 16:15:16,405] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8588799e-29 1.0000000e+00 4.0206890e-29 1.7819412e-34 1.2270782e-37], sum to 1.0000
[2019-03-26 16:15:16,414] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5728
[2019-03-26 16:15:16,421] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 90.66666666666667, 1.0, 2.0, 0.5251425489204847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733817.2568692582, 733817.2568692588, 187629.3871789379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6236400.0000, 
sim time next is 6237000.0000, 
raw observation next is [26.55, 90.5, 1.0, 2.0, 0.5249050761389132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733485.3054963945, 733485.3054963939, 187590.4168267733], 
processed observation next is [0.0, 0.17391304347826086, 0.4573459715639811, 0.905, 1.0, 1.0, 0.4275964772757991, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20374591819344293, 0.20374591819344276, 0.279985696756378], 
reward next is 0.7200, 
noisyNet noise sample is [array([1.3642322], dtype=float32), 0.108441986]. 
=============================================
[2019-03-26 16:15:16,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[76.06952 ]
 [76.112045]
 [76.005745]
 [75.88866 ]
 [75.76001 ]], R is [[76.0968399 ]
 [76.05582428]
 [76.01522827]
 [75.97502899]
 [75.93523407]].
[2019-03-26 16:15:19,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2140220e-26 1.0000000e+00 4.5930717e-27 1.9260657e-30 4.9844358e-36], sum to 1.0000
[2019-03-26 16:15:19,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4550
[2019-03-26 16:15:19,963] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 80.66666666666666, 1.0, 2.0, 0.5301681045499398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740842.2550885848, 740842.2550885843, 188457.8951091644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6291600.0000, 
sim time next is 6292200.0000, 
raw observation next is [27.95, 81.83333333333334, 1.0, 2.0, 0.5317184949596887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743009.485499889, 743009.4854998883, 188715.0068130046], 
processed observation next is [0.0, 0.8260869565217391, 0.523696682464455, 0.8183333333333335, 1.0, 1.0, 0.43580541561408276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20639152374996916, 0.20639152374996897, 0.2816641892731412], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.4849143], dtype=float32), 0.022708226]. 
=============================================
[2019-03-26 16:15:29,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.2601988e-22 1.0000000e+00 4.0997657e-24 1.4744118e-24 2.3214083e-31], sum to 1.0000
[2019-03-26 16:15:29,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4487
[2019-03-26 16:15:29,856] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 92.66666666666667, 1.0, 2.0, 0.7344736857797572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1026471.186321585, 1026471.186321584, 228461.5663768529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6498600.0000, 
sim time next is 6499200.0000, 
raw observation next is [26.23333333333333, 92.33333333333334, 1.0, 2.0, 0.6725292212962413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 939861.7605912875, 939861.7605912869, 215026.8114320446], 
processed observation next is [1.0, 0.21739130434782608, 0.44233807266982617, 0.9233333333333335, 1.0, 1.0, 0.6054568931280015, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26107271127535764, 0.26107271127535747, 0.3209355394508128], 
reward next is 0.6791, 
noisyNet noise sample is [array([-0.4027172], dtype=float32), 0.049099833]. 
=============================================
[2019-03-26 16:15:37,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1155644e-21 1.0000000e+00 4.1388779e-24 5.7081766e-26 4.6349683e-32], sum to 1.0000
[2019-03-26 16:15:37,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5300
[2019-03-26 16:15:37,152] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.76666666666667, 92.66666666666667, 1.0, 2.0, 0.5516146446212815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770821.9312190055, 770821.9312190055, 192075.0497460303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6583200.0000, 
sim time next is 6583800.0000, 
raw observation next is [25.73333333333333, 92.83333333333333, 1.0, 2.0, 0.5478756560373194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765595.215277056, 765595.2152770566, 191434.3419718563], 
processed observation next is [1.0, 0.17391304347826086, 0.41864139020537117, 0.9283333333333332, 1.0, 1.0, 0.45527187474375824, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21266533757696, 0.21266533757696016, 0.2857228984654572], 
reward next is 0.7143, 
noisyNet noise sample is [array([1.5206782], dtype=float32), -0.21015371]. 
=============================================
[2019-03-26 16:15:37,580] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 16:15:37,581] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:15:37,582] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:15:37,583] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:15:37,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:15:37,583] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:15:37,585] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:15:37,586] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:15:37,586] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:15:37,589] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:15:37,590] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:15:37,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 16:15:37,634] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 16:15:37,658] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 16:15:37,659] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 16:15:37,714] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 16:15:52,363] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:15:52,363] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.96666666666667, 92.66666666666667, 1.0, 2.0, 0.3071251603714302, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487783.1145219677, 487783.1145219677, 166162.9203836971]
[2019-03-26 16:15:52,366] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:15:52,369] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.1925184e-27 1.0000000e+00 7.8960711e-28 1.6332079e-32 5.2380104e-36], sampled 0.8382755846523796
[2019-03-26 16:15:55,814] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:15:55,815] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [19.7, 83.0, 1.0, 2.0, 0.2498543682224275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412823.2203445097, 412823.2203445103, 160826.7850597729]
[2019-03-26 16:15:55,816] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:15:55,818] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6304445e-24 1.0000000e+00 8.0465649e-26 5.3191797e-28 4.8251550e-34], sampled 0.8426659059925588
[2019-03-26 16:16:00,532] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:00,533] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.75, 64.0, 1.0, 2.0, 0.3033463950820128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 484796.8365217254, 484796.8365217248, 165987.9767628706]
[2019-03-26 16:16:00,535] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:16:00,536] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6380798e-26 1.0000000e+00 1.5208004e-27 8.9740004e-31 7.9739829e-36], sampled 0.41734036500491556
[2019-03-26 16:16:03,295] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:03,296] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.93990291, 81.38880693499999, 1.0, 2.0, 0.5417536772064909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757037.3831226616, 757037.3831226609, 190395.6790543715]
[2019-03-26 16:16:03,297] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:16:03,301] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.79543685e-23 1.00000000e+00 8.65555935e-25 8.85064711e-26
 1.12241784e-32], sampled 0.0628313943780231
[2019-03-26 16:16:03,893] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:03,895] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.86760506, 100.0, 1.0, 2.0, 0.6549029073108233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953212.7838584037, 953212.7838584037, 216351.9890869256]
[2019-03-26 16:16:03,895] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:16:03,899] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.2551572e-23 1.0000000e+00 2.5213545e-24 3.1692348e-26 8.9446380e-32], sampled 0.0036011056524473117
[2019-03-26 16:16:18,226] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:18,227] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.28333333333333, 84.5, 1.0, 2.0, 0.568514761034251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794446.8515833181, 794446.8515833188, 195026.1174034298]
[2019-03-26 16:16:18,229] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:16:18,232] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9729500e-24 1.0000000e+00 1.4461691e-25 1.8342964e-26 1.0699032e-33], sampled 0.7461664303765686
[2019-03-26 16:16:29,119] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:29,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 63.0, 1.0, 2.0, 1.017287377965562, 1.0, 2.0, 1.017287377965562, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2845720.370565129, 2845720.370565129, 539520.6116974272]
[2019-03-26 16:16:29,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:16:29,123] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0733893e-07 5.2385819e-01 2.3353394e-12 4.7614115e-01 7.6332650e-16], sampled 0.329498708583679
[2019-03-26 16:16:29,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2845720.370565129 W.
[2019-03-26 16:16:53,461] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:16:53,462] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.12451681, 85.41275743, 1.0, 2.0, 0.5030165093602273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702888.8136940146, 702888.8136940146, 184068.9778797468]
[2019-03-26 16:16:53,462] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:16:53,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9477509e-24 1.0000000e+00 1.1758932e-25 1.2058134e-27 9.1612869e-34], sampled 0.836680580010474
[2019-03-26 16:17:21,885] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:17:21,886] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.6, 85.0, 1.0, 2.0, 0.8811643816804982, 1.0, 1.0, 0.8811643816804982, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2464527.176839711, 2464527.176839711, 461806.2410353005]
[2019-03-26 16:17:21,887] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:17:21,889] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.8461826e-08 9.9720973e-01 1.9412529e-12 2.7903055e-03 4.5559726e-16], sampled 0.872718759257439
[2019-03-26 16:17:21,892] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2464527.176839711 W.
[2019-03-26 16:17:31,470] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00721352], dtype=float32), 0.08214993]
[2019-03-26 16:17:31,471] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.45, 66.5, 1.0, 2.0, 0.8378698371252536, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.984441048452579, 6.9112, 168.9125204663522, 2068075.037316132, 2016115.450914094, 418192.3208615569]
[2019-03-26 16:17:31,473] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:17:31,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4867411e-10 9.9993551e-01 6.3058439e-15 6.4521410e-05 7.4981927e-19], sampled 0.21331218503694194
[2019-03-26 16:17:31,478] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2068075.037316132 W.
[2019-03-26 16:17:33,127] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7905.3661 3162259414.4007 1729.0000
[2019-03-26 16:17:33,193] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.2462 2927403314.1200 1334.0000
[2019-03-26 16:17:33,360] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.8726 3007499083.9274 1761.0000
[2019-03-26 16:17:33,541] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2064 2779239362.3351 930.0000
[2019-03-26 16:17:33,623] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.1852 2842359378.4156 1126.0000
[2019-03-26 16:17:34,640] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1025000, evaluation results [1025000.0, 7905.366111549917, 3162259414.4006886, 1729.0, 8256.24615076707, 2927403314.1200204, 1334.0, 8661.206404648341, 2779239362.3350706, 930.0, 8000.872641729905, 3007499083.9274006, 1761.0, 8498.185204260877, 2842359378.415611, 1126.0]
[2019-03-26 16:17:38,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.4987507e-22 1.0000000e+00 7.4112670e-24 6.8909004e-24 4.1482972e-32], sum to 1.0000
[2019-03-26 16:17:38,621] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-26 16:17:38,627] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 87.0, 1.0, 2.0, 0.5100081957000538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712661.9057015249, 712661.9057015249, 185179.027469198], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6646200.0000, 
sim time next is 6646800.0000, 
raw observation next is [26.53333333333334, 87.0, 1.0, 2.0, 0.5086050263659883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710700.5257481782, 710700.5257481782, 184955.3193013815], 
processed observation next is [1.0, 0.9565217391304348, 0.4565560821484995, 0.87, 1.0, 1.0, 0.4079578630915521, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1974168127078273, 0.1974168127078273, 0.27605271537519627], 
reward next is 0.7239, 
noisyNet noise sample is [array([1.2555304], dtype=float32), 1.3337399]. 
=============================================
[2019-03-26 16:17:41,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6861782e-23 1.0000000e+00 1.7296555e-26 1.8505819e-25 1.6625113e-34], sum to 1.0000
[2019-03-26 16:17:41,919] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0665
[2019-03-26 16:17:41,924] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 67.0, 1.0, 2.0, 0.4582745650168862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648585.6294542779, 648585.6294542785, 178379.5010822732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6719400.0000, 
sim time next is 6720000.0000, 
raw observation next is [28.26666666666667, 67.0, 1.0, 2.0, 0.4522053941820711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643380.8895357632, 643380.8895357632, 177930.5097588635], 
processed observation next is [1.0, 0.782608695652174, 0.53870458135861, 0.67, 1.0, 1.0, 0.34000649901454355, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17871691375993423, 0.17871691375993423, 0.2655679250132291], 
reward next is 0.7344, 
noisyNet noise sample is [array([0.02189207], dtype=float32), -0.9615881]. 
=============================================
[2019-03-26 16:17:41,938] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[68.91179]
 [68.66871]
 [68.65946]
 [68.12942]
 [67.41859]], R is [[68.54051208]
 [68.58887482]
 [68.63620758]
 [68.68279266]
 [68.72900391]].
[2019-03-26 16:17:47,671] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8794037e-28 1.0000000e+00 1.2991525e-28 6.6258473e-33 1.1342781e-36], sum to 1.0000
[2019-03-26 16:17:47,679] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5400
[2019-03-26 16:17:47,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 74.66666666666667, 1.0, 2.0, 0.3817480512519722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576521.8400158354, 576521.8400158347, 172610.7202726799], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6855600.0000, 
sim time next is 6856200.0000, 
raw observation next is [25.5, 73.0, 1.0, 2.0, 0.3798776059042748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574733.5999963228, 574733.5999963222, 172482.9083867958], 
processed observation next is [0.0, 0.34782608695652173, 0.40758293838862564, 0.73, 1.0, 1.0, 0.2528645854268371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15964822222120076, 0.15964822222120062, 0.2574371766967102], 
reward next is 0.7426, 
noisyNet noise sample is [array([-1.1406415], dtype=float32), -1.2957234]. 
=============================================
[2019-03-26 16:17:51,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0896894e-29 1.0000000e+00 7.0049503e-30 1.3211844e-33 6.5754966e-38], sum to 1.0000
[2019-03-26 16:17:51,157] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1050
[2019-03-26 16:17:51,160] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.81666666666667, 31.16666666666666, 1.0, 2.0, 0.2536829169178785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 417426.2472565491, 417426.2472565497, 161267.5597546505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6875400.0000, 
sim time next is 6876000.0000, 
raw observation next is [29.9, 30.0, 1.0, 2.0, 0.2544687688644385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419707.3587315264, 419707.3587315264, 161319.5096549368], 
processed observation next is [0.0, 0.6086956521739131, 0.6161137440758293, 0.3, 1.0, 1.0, 0.10176960104149213, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.116585377425424, 0.116585377425424, 0.24077538754468178], 
reward next is 0.7592, 
noisyNet noise sample is [array([-0.08331941], dtype=float32), 0.40374225]. 
=============================================
[2019-03-26 16:17:51,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[80.73457 ]
 [80.59659 ]
 [80.423615]
 [80.26926 ]
 [80.11348 ]], R is [[80.82324219]
 [80.77430725]
 [80.72570801]
 [80.67667389]
 [80.62755585]].
[2019-03-26 16:17:51,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2767191e-26 1.0000000e+00 5.3083579e-27 5.6458453e-28 1.2509473e-35], sum to 1.0000
[2019-03-26 16:17:51,531] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0419
[2019-03-26 16:17:51,537] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 80.0, 1.0, 2.0, 0.4167240385449648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612002.4918850659, 612002.4918850666, 175381.8049249348], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6910200.0000, 
sim time next is 6910800.0000, 
raw observation next is [25.3, 80.33333333333334, 1.0, 2.0, 0.4170237444848601, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612460.5297119211, 612460.5297119211, 175425.7835641209], 
processed observation next is [0.0, 1.0, 0.39810426540284366, 0.8033333333333335, 1.0, 1.0, 0.2976189692588676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17012792491997808, 0.17012792491997808, 0.2618295277076432], 
reward next is 0.7382, 
noisyNet noise sample is [array([0.36605847], dtype=float32), -0.09461551]. 
=============================================
[2019-03-26 16:18:05,692] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.7398720e-24 1.0000000e+00 3.2982136e-25 1.8215915e-26 4.5785733e-33], sum to 1.0000
[2019-03-26 16:18:05,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-26 16:18:05,714] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5065954625839889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721175.2415038793, 721175.2415038793, 186333.5788862473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [25.5, 84.5, 1.0, 2.0, 0.5052259938965823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719182.4200182089, 719182.4200182089, 186106.7225950922], 
processed observation next is [1.0, 0.2608695652173913, 0.40758293838862564, 0.845, 1.0, 1.0, 0.40388673963443644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19977289444950247, 0.19977289444950247, 0.277771227753869], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.44525757], dtype=float32), 0.34700423]. 
=============================================
[2019-03-26 16:18:13,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0417365e-19 1.0000000e+00 4.9295209e-22 1.1383755e-19 4.4770754e-30], sum to 1.0000
[2019-03-26 16:18:13,564] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0428
[2019-03-26 16:18:13,569] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 82.5, 1.0, 2.0, 0.3666782519916248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 554770.5921117193, 554770.5921117193, 170744.521931935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7234200.0000, 
sim time next is 7234800.0000, 
raw observation next is [24.0, 83.0, 1.0, 2.0, 0.3693732107040272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 559374.6693396844, 559374.6693396838, 171157.4053747089], 
processed observation next is [1.0, 0.7391304347826086, 0.3364928909952607, 0.83, 1.0, 1.0, 0.24020868759521347, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15538185259435677, 0.15538185259435663, 0.25545881399210285], 
reward next is 0.7445, 
noisyNet noise sample is [array([-1.5653285], dtype=float32), 0.11040292]. 
=============================================
[2019-03-26 16:18:15,401] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1971471e-18 1.0000000e+00 1.3962195e-20 4.8473120e-19 2.0783536e-28], sum to 1.0000
[2019-03-26 16:18:15,409] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2632
[2019-03-26 16:18:15,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 63.0, 1.0, 2.0, 0.8548144265830148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1304457.208512261, 1304457.208512261, 272824.3850225583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7300800.0000, 
sim time next is 7301400.0000, 
raw observation next is [27.0, 62.5, 1.0, 2.0, 0.8977900800573273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1370208.005544685, 1370208.005544685, 285484.8455427904], 
processed observation next is [1.0, 0.5217391304347826, 0.4786729857819906, 0.625, 1.0, 1.0, 0.8768555181413582, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3806133348735236, 0.3806133348735236, 0.42609678439222454], 
reward next is 0.5739, 
noisyNet noise sample is [array([-0.5739104], dtype=float32), -1.268475]. 
=============================================
[2019-03-26 16:18:16,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0173210e-25 1.0000000e+00 4.6052501e-26 6.5347207e-28 2.0385839e-34], sum to 1.0000
[2019-03-26 16:18:16,504] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7886
[2019-03-26 16:18:16,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.83333333333334, 93.0, 1.0, 2.0, 0.495363730226292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692191.7385777482, 692191.7385777482, 182871.6693297447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7708800.0000, 
sim time next is 7709400.0000, 
raw observation next is [25.0, 92.5, 1.0, 2.0, 0.4969029648518459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 694343.2761949665, 694343.2761949671, 183111.2153675945], 
processed observation next is [1.0, 0.21739130434782608, 0.38388625592417064, 0.925, 1.0, 1.0, 0.3938589937974047, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1928731322763796, 0.19287313227637976, 0.2733003214441709], 
reward next is 0.7267, 
noisyNet noise sample is [array([-0.7467722], dtype=float32), 0.95179886]. 
=============================================
[2019-03-26 16:18:24,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.9736403e-25 1.0000000e+00 6.8813841e-26 3.6263019e-27 6.6524836e-35], sum to 1.0000
[2019-03-26 16:18:24,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6783
[2019-03-26 16:18:24,198] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666666, 82.66666666666667, 1.0, 2.0, 0.2898212026336421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465893.8763467673, 465893.8763467673, 164675.0138125497], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7416600.0000, 
sim time next is 7417200.0000, 
raw observation next is [21.63333333333333, 83.33333333333334, 1.0, 2.0, 0.2928300893170977, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 470243.2167977881, 470243.2167977875, 164974.4481674853], 
processed observation next is [1.0, 0.8695652173913043, 0.2243285939968403, 0.8333333333333335, 1.0, 1.0, 0.14798805941819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13062311577716337, 0.1306231157771632, 0.24623051965296314], 
reward next is 0.7538, 
noisyNet noise sample is [array([-0.08684211], dtype=float32), -2.0573947]. 
=============================================
[2019-03-26 16:18:30,936] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 16:18:30,938] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:18:30,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:30,939] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:18:30,940] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:18:30,940] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:30,941] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:30,943] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:18:30,944] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:18:30,945] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:30,947] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:18:30,966] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 16:18:30,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 16:18:30,989] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 16:18:31,012] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 16:18:31,056] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 16:18:36,284] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:18:36,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [18.9, 89.66666666666667, 1.0, 2.0, 0.2574914712982059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 425394.127644886, 425394.127644886, 161592.1824968913]
[2019-03-26 16:18:36,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:18:36,288] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0236136e-23 1.0000000e+00 2.5258888e-24 1.5274357e-25 1.3601580e-32], sampled 0.10612775362212967
[2019-03-26 16:18:39,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:18:39,766] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.05, 61.5, 1.0, 2.0, 0.4410394949101237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726687.4437295337, 726687.4437295337, 185761.3217983033]
[2019-03-26 16:18:39,767] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:18:39,769] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2772304e-22 1.0000000e+00 1.6881926e-23 4.3596832e-25 2.3045381e-31], sampled 0.31163180527259227
[2019-03-26 16:19:09,314] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:19:09,315] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.91126535333333, 82.60998995666667, 1.0, 2.0, 0.4210073077929422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622521.0608243099, 622521.0608243092, 176499.1958116686]
[2019-03-26 16:19:09,317] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:19:09,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5144881e-23 1.0000000e+00 2.4817343e-24 6.9578265e-26 1.9100401e-32], sampled 0.5380053151998095
[2019-03-26 16:19:34,513] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:19:34,513] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.75, 46.5, 1.0, 2.0, 0.5279506574816974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737742.579821443, 737742.5798214423, 188090.8456898249]
[2019-03-26 16:19:34,515] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:19:34,519] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6737902e-23 1.0000000e+00 3.0979122e-25 2.6643195e-25 1.2183026e-33], sampled 0.22254313883025467
[2019-03-26 16:19:55,403] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:19:55,404] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.15, 77.66666666666666, 1.0, 2.0, 0.804146202153365, 1.0, 2.0, 0.804146202153365, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2248950.900566093, 2248950.900566093, 421900.7083270685]
[2019-03-26 16:19:55,406] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:19:55,409] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4280576e-09 5.4135221e-01 2.1862325e-14 4.5864773e-01 3.3662436e-18], sampled 0.31372970106794995
[2019-03-26 16:19:55,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2248950.900566093 W.
[2019-03-26 16:20:20,961] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00488547], dtype=float32), 0.08421891]
[2019-03-26 16:20:20,964] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.43333333333333, 60.33333333333333, 1.0, 2.0, 1.008520122387019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1409721.836244503, 1409721.836244502, 301529.4237653191]
[2019-03-26 16:20:20,967] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:20:20,970] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.5195949e-14 1.0000000e+00 1.7412155e-17 7.3988199e-10 7.3002949e-23], sampled 0.4966460157676704
[2019-03-26 16:20:23,243] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8289.7337 2924428973.3034 1259.0000
[2019-03-26 16:20:23,512] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.0536 2840258830.3636 1070.0000
[2019-03-26 16:20:23,810] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8678.9353 2777664056.8260 890.0000
[2019-03-26 16:20:23,994] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8043.6841 3003083673.9174 1656.0000
[2019-03-26 16:20:24,149] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7995.8558 3153703877.3101 1506.0000
[2019-03-26 16:20:25,164] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1050000, evaluation results [1050000.0, 7995.855751389451, 3153703877.3101277, 1506.0, 8289.733728888592, 2924428973.303389, 1259.0, 8678.935347572307, 2777664056.8260436, 890.0, 8043.684051048073, 3003083673.917384, 1656.0, 8519.053643397692, 2840258830.3635535, 1070.0]
[2019-03-26 16:20:26,854] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:26,855] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:26,945] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 16:20:27,645] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4861513e-23 1.0000000e+00 6.9165737e-25 4.8742366e-26 2.9181225e-33], sum to 1.0000
[2019-03-26 16:20:27,654] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2607
[2019-03-26 16:20:27,657] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 62.0, 1.0, 2.0, 0.4513166777827046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 638710.9203464325, 638710.9203464318, 177365.3130854174], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7573200.0000, 
sim time next is 7573800.0000, 
raw observation next is [29.16666666666667, 62.0, 1.0, 2.0, 0.4445139563660606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633156.6034245412, 633156.6034245412, 176913.5538732694], 
processed observation next is [0.0, 0.6521739130434783, 0.581358609794629, 0.62, 1.0, 1.0, 0.33073970646513323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17587683428459477, 0.17587683428459477, 0.2640500804078648], 
reward next is 0.7359, 
noisyNet noise sample is [array([0.36832646], dtype=float32), 0.8625444]. 
=============================================
[2019-03-26 16:20:31,443] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0274551e-13 1.0000000e+00 1.2664871e-17 1.3877545e-10 6.1407148e-23], sum to 1.0000
[2019-03-26 16:20:31,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7644
[2019-03-26 16:20:31,459] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.58333333333334, 59.66666666666666, 1.0, 2.0, 0.9860550426682898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1378299.485932651, 1378299.48593265, 294702.6286466139], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7650600.0000, 
sim time next is 7651200.0000, 
raw observation next is [30.66666666666667, 59.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.584305587778196, 6.9112, 168.9037514645026, 2641418.123513499, 1454524.119951271, 310281.3035789554], 
processed observation next is [1.0, 0.5652173913043478, 0.6524486571879939, 0.5933333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.16731055877781964, 0.0, 0.829394744162706, 0.7337272565315275, 0.40403447776424195, 0.4631064232521723], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.50895673], dtype=float32), 1.0496572]. 
=============================================
[2019-03-26 16:20:32,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7945363e-20 1.0000000e+00 5.3492706e-22 2.8548058e-22 5.5864528e-30], sum to 1.0000
[2019-03-26 16:20:32,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8522
[2019-03-26 16:20:32,233] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 86.5, 1.0, 2.0, 0.6148752916851967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859257.6147002022, 859257.6147002022, 203543.1267455017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716600.0000, 
sim time next is 7717200.0000, 
raw observation next is [27.06666666666667, 86.0, 1.0, 2.0, 0.6720123608028685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 939139.1270139074, 939139.1270139068, 214919.337831165], 
processed observation next is [1.0, 0.30434782608695654, 0.48183254344391807, 0.86, 1.0, 1.0, 0.6048341696420102, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2608719797260854, 0.2608719797260852, 0.320775131091291], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.10008203], dtype=float32), -1.0797887]. 
=============================================
[2019-03-26 16:20:34,245] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2783779e-19 1.0000000e+00 7.8427506e-22 2.2720876e-20 5.9994279e-30], sum to 1.0000
[2019-03-26 16:20:34,252] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7694
[2019-03-26 16:20:34,256] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 88.66666666666667, 1.0, 2.0, 0.4791948013832009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669591.1208661617, 669591.1208661622, 180400.1578883383], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7687200.0000, 
sim time next is 7687800.0000, 
raw observation next is [25.35, 89.0, 1.0, 2.0, 0.4800516621168904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670788.812251617, 670788.812251617, 180529.1795795794], 
processed observation next is [1.0, 1.0, 0.4004739336492892, 0.89, 1.0, 1.0, 0.37355621941794026, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18633022562544915, 0.18633022562544915, 0.2694465366859394], 
reward next is 0.7306, 
noisyNet noise sample is [array([0.4320279], dtype=float32), -0.7446865]. 
=============================================
[2019-03-26 16:20:34,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7149469e-08 4.9449373e-03 5.9185865e-14 9.9505508e-01 1.3021988e-17], sum to 1.0000
[2019-03-26 16:20:34,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6081
[2019-03-26 16:20:34,410] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.6332467811159816, 1.0, 2.0, 0.6332467811159816, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1770606.824263737, 1770606.824263737, 346852.4893101086], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7664400.0000, 
sim time next is 7665000.0000, 
raw observation next is [28.55, 75.66666666666667, 1.0, 2.0, 0.3205711242151021, 1.0, 2.0, 0.3205711242151021, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 895976.2186316467, 895976.2186316467, 253969.5376337034], 
processed observation next is [1.0, 0.7391304347826086, 0.552132701421801, 0.7566666666666667, 1.0, 1.0, 0.18141099303024347, 1.0, 1.0, 0.18141099303024347, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2488822829532352, 0.2488822829532352, 0.37905901139358716], 
reward next is 0.6209, 
noisyNet noise sample is [array([0.72006315], dtype=float32), 0.6552258]. 
=============================================
[2019-03-26 16:20:34,425] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[47.53213 ]
 [46.994312]
 [47.98776 ]
 [46.83169 ]
 [46.144615]], R is [[52.09743881]
 [52.05877686]
 [52.01287079]
 [51.59395981]
 [51.078022  ]].
[2019-03-26 16:20:37,059] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1055407: loss 0.9799
[2019-03-26 16:20:37,061] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1055407: learning rate 0.0000
[2019-03-26 16:20:38,374] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:38,374] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:38,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 16:20:42,001] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5127859e-08 9.9728560e-01 1.9658546e-13 2.7144020e-03 1.9829817e-17], sum to 1.0000
[2019-03-26 16:20:42,008] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-26 16:20:42,018] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1918378.657152839 W.
[2019-03-26 16:20:42,025] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.1, 74.5, 1.0, 2.0, 0.6860492108233546, 1.0, 2.0, 0.6860492108233546, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1918378.657152839, 1918378.657152839, 368207.0185483948], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7812600.0000, 
sim time next is 7813200.0000, 
raw observation next is [29.2, 74.0, 1.0, 2.0, 0.4623730765704486, 1.0, 2.0, 0.4623730765704486, 1.0, 1.0, 0.7957843371704468, 6.9112, 6.9112, 170.5573041426782, 1939398.780654077, 1939398.780654077, 388907.5302341981], 
processed observation next is [1.0, 0.43478260869565216, 0.5829383886255924, 0.74, 1.0, 1.0, 0.3522567187595767, 1.0, 1.0, 0.3522567187595767, 1.0, 0.5, 0.7509565087444472, 0.0, 0.0, 0.8375144448122397, 0.5387218835150214, 0.5387218835150214, 0.5804590003495493], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.18118712], dtype=float32), -2.24583]. 
=============================================
[2019-03-26 16:20:43,573] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0499684e-21 1.0000000e+00 3.6295891e-23 1.0947259e-22 1.5166036e-30], sum to 1.0000
[2019-03-26 16:20:43,583] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5814
[2019-03-26 16:20:43,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 86.5, 1.0, 2.0, 0.6033662351347145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 843167.8971018008, 843167.8971018002, 201368.0948255169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7884600.0000, 
sim time next is 7885200.0000, 
raw observation next is [26.73333333333334, 86.0, 1.0, 2.0, 0.6243938726880052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872564.8218607658, 872564.8218607658, 205370.5781021543], 
processed observation next is [1.0, 0.2608695652173913, 0.4660347551342816, 0.86, 1.0, 1.0, 0.547462497214464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24237911718354604, 0.24237911718354604, 0.3065232508987378], 
reward next is 0.6935, 
noisyNet noise sample is [array([-0.03705164], dtype=float32), 0.87701225]. 
=============================================
[2019-03-26 16:20:46,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8512306e-22 1.0000000e+00 1.5233516e-24 2.7395395e-22 1.0309083e-32], sum to 1.0000
[2019-03-26 16:20:46,372] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1736
[2019-03-26 16:20:46,376] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.15, 72.5, 1.0, 2.0, 0.5063250630001301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707513.5521628319, 707513.5521628319, 184594.0074733687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7929000.0000, 
sim time next is 7929600.0000, 
raw observation next is [28.93333333333334, 74.0, 1.0, 2.0, 0.5090072894533362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711262.8172811767, 711262.8172811773, 185020.289979625], 
processed observation next is [1.0, 0.782608695652174, 0.5703001579778835, 0.74, 1.0, 1.0, 0.408442517413658, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19757300480032686, 0.19757300480032702, 0.2761496865367537], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.6254495], dtype=float32), -1.7324709]. 
=============================================
[2019-03-26 16:20:47,021] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:47,022] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:47,086] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 16:20:47,580] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:47,581] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:47,642] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 16:20:47,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.235657e-22 1.000000e+00 3.425417e-24 7.871971e-23 2.595344e-32], sum to 1.0000
[2019-03-26 16:20:47,998] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8321
[2019-03-26 16:20:48,001] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 78.33333333333334, 1.0, 2.0, 0.520807005037641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727756.832369921, 727756.832369921, 186920.7514987606], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7932000.0000, 
sim time next is 7932600.0000, 
raw observation next is [28.25, 79.0, 1.0, 2.0, 0.5223759645920587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729949.9928753187, 729949.9928753187, 187176.5749648716], 
processed observation next is [1.0, 0.8260869565217391, 0.537914691943128, 0.79, 1.0, 1.0, 0.4245493549301912, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20276388690981076, 0.20276388690981076, 0.27936802233562924], 
reward next is 0.7206, 
noisyNet noise sample is [array([1.086656], dtype=float32), -0.44668233]. 
=============================================
[2019-03-26 16:20:48,018] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1060450: loss 0.7568
[2019-03-26 16:20:48,019] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1060450: learning rate 0.0000
[2019-03-26 16:20:48,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:48,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:48,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 16:20:48,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:48,447] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:48,518] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 16:20:48,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:48,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:48,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 16:20:48,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:48,989] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,024] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 16:20:49,147] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,148] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,175] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 16:20:49,286] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,286] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,307] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 16:20:49,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 16:20:49,386] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1061237: loss 0.0196
[2019-03-26 16:20:49,388] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1061237: learning rate 0.0000
[2019-03-26 16:20:49,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 16:20:49,428] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,429] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 16:20:49,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9155516e-22 1.0000000e+00 8.7849633e-24 2.9295123e-24 5.1783394e-32], sum to 1.0000
[2019-03-26 16:20:49,551] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0291
[2019-03-26 16:20:49,557] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 75.83333333333333, 1.0, 2.0, 0.4052513659093974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666519.4414477205, 666519.4414477205, 180246.454953312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [21.2, 75.0, 1.0, 2.0, 0.4228065751600374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695236.5461233738, 695236.5461233745, 182903.5054878025], 
processed observation next is [1.0, 0.391304347826087, 0.20379146919431282, 0.75, 1.0, 1.0, 0.30458623513257516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19312126281204828, 0.19312126281204847, 0.27299030669821267], 
reward next is 0.7270, 
noisyNet noise sample is [array([-0.5117807], dtype=float32), 0.47709635]. 
=============================================
[2019-03-26 16:20:49,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,605] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 16:20:49,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,724] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 16:20:49,767] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8595666e-20 1.0000000e+00 5.6993080e-23 6.3570494e-21 1.8964570e-31], sum to 1.0000
[2019-03-26 16:20:49,768] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9692
[2019-03-26 16:20:49,772] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.51666666666667, 83.33333333333334, 1.0, 2.0, 0.3641451087769509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558594.5174224947, 558594.5174224947, 171307.190417166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 72600.0000, 
sim time next is 73200.0000, 
raw observation next is [23.43333333333334, 83.66666666666667, 1.0, 2.0, 0.3627457052283415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 557055.4001379946, 557055.400137994, 171193.2174820227], 
processed observation next is [1.0, 0.8695652173913043, 0.30963665086887876, 0.8366666666666667, 1.0, 1.0, 0.23222374123896564, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15473761114944293, 0.15473761114944276, 0.25551226489854134], 
reward next is 0.7445, 
noisyNet noise sample is [array([0.4896808], dtype=float32), -0.6808047]. 
=============================================
[2019-03-26 16:20:49,810] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:20:49,810] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:20:49,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 16:20:51,271] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1062238: loss 0.5264
[2019-03-26 16:20:51,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1062241: learning rate 0.0000
[2019-03-26 16:20:52,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8873136e-23 1.0000000e+00 3.5235020e-25 3.6269973e-25 3.9666899e-33], sum to 1.0000
[2019-03-26 16:20:52,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1511
[2019-03-26 16:20:52,305] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.73333333333333, 82.0, 1.0, 2.0, 0.542318566617543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 854020.5062737424, 854020.5062737431, 201616.6798820528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 30000.0000, 
sim time next is 30600.0000, 
raw observation next is [22.95, 81.0, 1.0, 2.0, 0.6087727765698281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 956732.6883268057, 956732.6883268063, 214858.5586430603], 
processed observation next is [1.0, 0.34782608695652173, 0.28672985781990523, 0.81, 1.0, 1.0, 0.5286418994817206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26575908009077936, 0.26575908009077953, 0.3206844158851646], 
reward next is 0.6793, 
noisyNet noise sample is [array([0.1360585], dtype=float32), -0.78038144]. 
=============================================
[2019-03-26 16:20:52,840] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1062938: loss 0.3975
[2019-03-26 16:20:52,844] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1062939: learning rate 0.0000
[2019-03-26 16:20:53,784] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.4551006e-17 1.0000000e+00 3.5789861e-19 3.4242459e-14 2.7707803e-26], sum to 1.0000
[2019-03-26 16:20:53,792] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8626
[2019-03-26 16:20:53,801] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.2, 63.66666666666667, 1.0, 2.0, 0.6924300270297054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1044727.012058795, 1044727.012058795, 229092.3450298621], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 45600.0000, 
sim time next is 46200.0000, 
raw observation next is [27.3, 63.33333333333333, 1.0, 2.0, 0.6532585512819375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 984577.2517540853, 984577.2517540853, 220135.292964243], 
processed observation next is [1.0, 0.5217391304347826, 0.4928909952606636, 0.6333333333333333, 1.0, 1.0, 0.5822392184119729, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2734936810428015, 0.2734936810428015, 0.3285601387526015], 
reward next is 0.6714, 
noisyNet noise sample is [array([-2.6419916], dtype=float32), 0.23637493]. 
=============================================
[2019-03-26 16:20:54,123] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.2853442e-24 1.0000000e+00 1.7067361e-25 2.2992316e-26 1.7935972e-33], sum to 1.0000
[2019-03-26 16:20:54,134] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0640
[2019-03-26 16:20:54,141] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 87.0, 1.0, 2.0, 0.2569084511794936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 418598.7393006994, 418598.7393006994, 161538.0374686603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367200.0000, 
sim time next is 367800.0000, 
raw observation next is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
processed observation next is [1.0, 0.2608695652173913, 0.1642969984202214, 0.865, 1.0, 1.0, 0.10959443173423335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11811343042746605, 0.11811343042746623, 0.24171376142103967], 
reward next is 0.7583, 
noisyNet noise sample is [array([1.1271652], dtype=float32), 0.8441241]. 
=============================================
[2019-03-26 16:20:56,443] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1064544: loss 0.5598
[2019-03-26 16:20:56,445] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1064544: learning rate 0.0000
[2019-03-26 16:20:56,848] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064722: loss 0.5288
[2019-03-26 16:20:56,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064723: learning rate 0.0000
[2019-03-26 16:20:57,226] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1064887: loss 0.4725
[2019-03-26 16:20:57,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1064888: learning rate 0.0000
[2019-03-26 16:20:57,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9084968e-19 1.0000000e+00 3.5642950e-21 2.0359337e-19 4.6654180e-28], sum to 1.0000
[2019-03-26 16:20:57,934] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6377
[2019-03-26 16:20:57,941] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 93.33333333333334, 1.0, 2.0, 0.6944983242685399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1042988.007843672, 1042988.007843671, 228991.4354119874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 121200.0000, 
sim time next is 121800.0000, 
raw observation next is [22.9, 93.66666666666667, 1.0, 2.0, 0.6772672177176389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1015721.395939352, 1015721.395939352, 224885.0827546244], 
processed observation next is [1.0, 0.391304347826087, 0.2843601895734597, 0.9366666666666668, 1.0, 1.0, 0.6111653225513721, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28214483220537556, 0.28214483220537556, 0.33564937724570804], 
reward next is 0.6644, 
noisyNet noise sample is [array([1.4151989], dtype=float32), 1.3208603]. 
=============================================
[2019-03-26 16:20:58,437] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1065424: loss 0.4556
[2019-03-26 16:20:58,440] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1065425: learning rate 0.0000
[2019-03-26 16:20:59,075] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065705: loss 0.4884
[2019-03-26 16:20:59,080] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065705: learning rate 0.0000
[2019-03-26 16:20:59,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1065856: loss 0.0082
[2019-03-26 16:20:59,415] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1065856: learning rate 0.0000
[2019-03-26 16:20:59,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3638545e-18 1.0000000e+00 2.6917134e-21 4.4085492e-18 7.4349490e-29], sum to 1.0000
[2019-03-26 16:20:59,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-26 16:20:59,589] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 96.0, 1.0, 2.0, 0.3757333794794568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 565510.5378395348, 565510.5378395341, 171578.450878132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 149400.0000, 
sim time next is 150000.0000, 
raw observation next is [22.5, 96.0, 1.0, 2.0, 0.3819982060870853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574951.4300596942, 574951.4300596935, 172412.015864021], 
processed observation next is [1.0, 0.7391304347826086, 0.2654028436018958, 0.96, 1.0, 1.0, 0.25541952540612683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15970873057213728, 0.15970873057213708, 0.2573313669612254], 
reward next is 0.7427, 
noisyNet noise sample is [array([1.011856], dtype=float32), -1.706944]. 
=============================================
[2019-03-26 16:20:59,604] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.97563 ]
 [68.75511 ]
 [66.945984]
 [64.81588 ]
 [64.85672 ]], R is [[70.79873657]
 [70.83466339]
 [70.86952209]
 [70.88827515]
 [70.81642151]].
[2019-03-26 16:20:59,707] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1065982: loss 0.3465
[2019-03-26 16:20:59,708] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1065983: learning rate 0.0000
[2019-03-26 16:20:59,959] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066097: loss 0.3097
[2019-03-26 16:20:59,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066098: learning rate 0.0000
[2019-03-26 16:20:59,977] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1066104: loss 0.2956
[2019-03-26 16:20:59,978] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1066104: learning rate 0.0000
[2019-03-26 16:20:59,988] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066108: loss 0.2895
[2019-03-26 16:20:59,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066108: learning rate 0.0000
[2019-03-26 16:21:00,224] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1066211: loss 0.2741
[2019-03-26 16:21:00,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1066211: learning rate 0.0000
[2019-03-26 16:21:00,376] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066280: loss 0.2372
[2019-03-26 16:21:00,379] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066280: learning rate 0.0000
[2019-03-26 16:21:00,429] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1066303: loss 0.2291
[2019-03-26 16:21:00,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1066303: learning rate 0.0000
[2019-03-26 16:21:05,234] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1068448: loss 8.0192
[2019-03-26 16:21:05,240] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1068451: learning rate 0.0000
[2019-03-26 16:21:05,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9661183e-26 1.0000000e+00 1.1859021e-26 1.9726975e-29 3.0708718e-34], sum to 1.0000
[2019-03-26 16:21:05,823] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8932
[2019-03-26 16:21:05,827] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.2, 96.0, 1.0, 2.0, 0.2614105203169333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 426112.745323793, 426112.745323793, 162000.0584266495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 277200.0000, 
sim time next is 277800.0000, 
raw observation next is [19.35, 95.33333333333333, 1.0, 2.0, 0.2623846589048661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 427461.9519288958, 427461.9519288958, 162091.0591451025], 
processed observation next is [0.0, 0.21739130434782608, 0.11611374407582951, 0.9533333333333333, 1.0, 1.0, 0.11130681795767002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11873943109135994, 0.11873943109135994, 0.2419269539479142], 
reward next is 0.7581, 
noisyNet noise sample is [array([2.5642245], dtype=float32), -1.4485483]. 
=============================================
[2019-03-26 16:21:06,843] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1386501e-25 1.0000000e+00 2.1548997e-26 1.9601339e-28 1.9875350e-34], sum to 1.0000
[2019-03-26 16:21:06,854] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2750
[2019-03-26 16:21:06,860] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 95.5, 1.0, 2.0, 0.2650526154486161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 431053.1406491161, 431053.1406491161, 162334.7419220064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 275400.0000, 
sim time next is 276000.0000, 
raw observation next is [19.33333333333333, 95.66666666666667, 1.0, 2.0, 0.26342732567264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 428744.169440457, 428744.1694404576, 162181.6441650866], 
processed observation next is [0.0, 0.17391304347826086, 0.11532385466034739, 0.9566666666666667, 1.0, 1.0, 0.11256304297908432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11909560262234917, 0.11909560262234933, 0.24206215547027848], 
reward next is 0.7579, 
noisyNet noise sample is [array([0.810329], dtype=float32), 0.06897761]. 
=============================================
[2019-03-26 16:21:06,872] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.77229 ]
 [75.82497 ]
 [75.881294]
 [75.87591 ]
 [75.92311 ]], R is [[75.66188049]
 [75.6629715 ]
 [75.66379547]
 [75.66434479]
 [75.66464996]].
[2019-03-26 16:21:08,121] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00104985e-22 1.00000000e+00 2.17189421e-24 1.97031856e-24
 1.03433533e-32], sum to 1.0000
[2019-03-26 16:21:08,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1886
[2019-03-26 16:21:08,136] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 86.0, 1.0, 2.0, 0.2767291524129772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 446506.1808600551, 446506.1808600551, 163368.3651714692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 336600.0000, 
sim time next is 337200.0000, 
raw observation next is [20.96666666666667, 86.0, 1.0, 2.0, 0.275679208189076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 445079.7360947166, 445079.736094716, 163273.9126578792], 
processed observation next is [0.0, 0.9130434782608695, 0.1927330173775673, 0.86, 1.0, 1.0, 0.1273243472157542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12363326002631016, 0.12363326002631, 0.24369240695205852], 
reward next is 0.7563, 
noisyNet noise sample is [array([-0.22522917], dtype=float32), 1.3985617]. 
=============================================
[2019-03-26 16:21:09,315] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1070268: loss 0.0037
[2019-03-26 16:21:09,320] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1070268: learning rate 0.0000
[2019-03-26 16:21:10,903] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1070894: loss 0.0317
[2019-03-26 16:21:10,906] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1070895: learning rate 0.0000
[2019-03-26 16:21:11,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9435229e-22 1.0000000e+00 7.8795080e-24 6.8648467e-24 5.8703153e-31], sum to 1.0000
[2019-03-26 16:21:11,390] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8854
[2019-03-26 16:21:11,395] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 75.83333333333333, 1.0, 2.0, 0.4052513659093974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666519.4414477205, 666519.4414477205, 180246.454953312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [21.2, 75.0, 1.0, 2.0, 0.4228065751600374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695236.5461233738, 695236.5461233745, 182903.5054878025], 
processed observation next is [1.0, 0.391304347826087, 0.20379146919431282, 0.75, 1.0, 1.0, 0.30458623513257516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19312126281204828, 0.19312126281204847, 0.27299030669821267], 
reward next is 0.7270, 
noisyNet noise sample is [array([1.6051004], dtype=float32), 1.5763484]. 
=============================================
[2019-03-26 16:21:13,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9901695e-21 1.0000000e+00 1.1748413e-22 1.3652339e-21 3.5449679e-31], sum to 1.0000
[2019-03-26 16:21:13,471] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-26 16:21:13,475] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2397853028395814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 395649.4862059378, 395649.4862059372, 159880.4258597444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 436800.0000, 
sim time next is 437400.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2393795938962013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 394980.12064865, 394980.1206486494, 159841.9166773104], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08358987216409795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10971670018018055, 0.10971670018018038, 0.23857002489150805], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.35686833], dtype=float32), -1.515036]. 
=============================================
[2019-03-26 16:21:14,558] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1072570: loss 0.0098
[2019-03-26 16:21:14,560] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1072570: learning rate 0.0000
[2019-03-26 16:21:14,839] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072699: loss 0.0031
[2019-03-26 16:21:14,840] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072699: learning rate 0.0000
[2019-03-26 16:21:15,262] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1072891: loss 0.0040
[2019-03-26 16:21:15,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1072891: learning rate 0.0000
[2019-03-26 16:21:16,525] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1073467: loss 0.0038
[2019-03-26 16:21:16,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1073468: learning rate 0.0000
[2019-03-26 16:21:17,017] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073692: loss 0.0085
[2019-03-26 16:21:17,020] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073693: learning rate 0.0000
[2019-03-26 16:21:17,237] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1073796: loss 7.9677
[2019-03-26 16:21:17,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1073802: learning rate 0.0000
[2019-03-26 16:21:17,651] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1073983: loss 0.0051
[2019-03-26 16:21:17,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1073984: learning rate 0.0000
[2019-03-26 16:21:17,850] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1074072: loss 0.0026
[2019-03-26 16:21:17,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1074072: learning rate 0.0000
[2019-03-26 16:21:17,878] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1074084: loss 0.0030
[2019-03-26 16:21:17,880] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1074084: learning rate 0.0000
[2019-03-26 16:21:17,991] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074134: loss 0.0047
[2019-03-26 16:21:17,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074134: learning rate 0.0000
[2019-03-26 16:21:18,184] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074224: loss 0.0028
[2019-03-26 16:21:18,189] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074224: learning rate 0.0000
[2019-03-26 16:21:18,240] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1074248: loss 0.0025
[2019-03-26 16:21:18,241] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1074248: learning rate 0.0000
[2019-03-26 16:21:18,353] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1074299: loss 0.0031
[2019-03-26 16:21:18,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1074300: learning rate 0.0000
[2019-03-26 16:21:19,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9511420e-22 1.0000000e+00 2.4817545e-23 5.3566394e-23 6.8318015e-31], sum to 1.0000
[2019-03-26 16:21:19,720] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1740
[2019-03-26 16:21:19,725] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 57.0, 1.0, 2.0, 0.3635119540660886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594544.1725442765, 594544.1725442759, 174315.8896779703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [24.65, 56.33333333333333, 1.0, 2.0, 0.4835530432168294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790551.8589840526, 790551.8589840526, 192854.9999312984], 
processed observation next is [1.0, 0.5652173913043478, 0.3672985781990521, 0.5633333333333332, 1.0, 1.0, 0.3777747508636499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21959773860668128, 0.21959773860668128, 0.28784328347954985], 
reward next is 0.7122, 
noisyNet noise sample is [array([0.04225359], dtype=float32), 1.0437785]. 
=============================================
[2019-03-26 16:21:19,893] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 16:21:19,897] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:21:19,898] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:21:19,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:21:19,899] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:21:19,900] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:21:19,899] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:21:19,903] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:21:19,903] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:21:19,904] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:21:19,905] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:21:19,928] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 16:21:19,930] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 16:21:19,973] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 16:21:19,999] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 16:21:20,001] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 16:21:24,260] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:21:24,261] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.06666666666667, 39.66666666666666, 1.0, 2.0, 0.2204049074756917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 368425.4934470653, 368425.4934470653, 157074.8691434313]
[2019-03-26 16:21:24,262] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:21:24,264] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3764795e-25 1.0000000e+00 5.8155220e-26 1.9359615e-27 3.1150453e-34], sampled 0.05983547642760012
[2019-03-26 16:21:30,280] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:21:30,281] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.03333333333333, 86.66666666666667, 1.0, 2.0, 0.2377911770333683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 393784.5974520952, 393784.5974520946, 159595.9677909474]
[2019-03-26 16:21:30,282] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:21:30,287] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.1807470e-23 1.0000000e+00 3.6987187e-24 3.4596659e-24 2.3872974e-32], sampled 0.24550296723488252
[2019-03-26 16:21:50,788] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:21:50,789] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.243632695, 91.73946760000001, 1.0, 2.0, 0.5876339581178253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821174.4908406144, 821174.4908406144, 198462.6604259464]
[2019-03-26 16:21:50,790] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:21:50,794] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8728569e-21 1.0000000e+00 3.8098031e-23 5.3189521e-22 4.2532719e-31], sampled 0.25233740381470815
[2019-03-26 16:21:56,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:21:56,448] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.38333333333333, 95.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.359698216321023, 6.9112, 169.6265963146485, 1773492.994362928, 1453968.645634479, 311482.866855632]
[2019-03-26 16:21:56,449] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:21:56,451] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1273939e-20 1.0000000e+00 1.8923033e-22 4.9233217e-21 3.5913158e-30], sampled 0.15035355983302345
[2019-03-26 16:21:56,452] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1773492.994362928 W.
[2019-03-26 16:22:38,314] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:22:38,316] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.1, 78.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.919618037800538, 6.9112, 168.912424833948, 1459731.04665739, 1453759.019713013, 311351.4678912819]
[2019-03-26 16:22:38,317] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:22:38,324] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.1923813e-20 1.0000000e+00 8.3492973e-22 4.9570763e-20 3.1344230e-29], sampled 0.7192370936676775
[2019-03-26 16:23:05,965] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00260205], dtype=float32), 0.092055164]
[2019-03-26 16:23:05,967] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.78549857, 94.92608637, 1.0, 2.0, 0.3922543231548282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 589376.1812556365, 589376.1812556359, 173681.2950976524]
[2019-03-26 16:23:05,967] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:23:05,970] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4041605e-22 1.0000000e+00 3.8351001e-24 1.0610927e-23 2.8316569e-32], sampled 0.06187487053655871
[2019-03-26 16:23:15,704] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7958.1691 3156647519.0275 1591.0000
[2019-03-26 16:23:16,235] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8513.8694 2840814347.9467 1087.0000
[2019-03-26 16:23:16,291] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8021.2520 3005320230.3845 1706.0000
[2019-03-26 16:23:16,316] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8272.6260 2926093187.3303 1297.0000
[2019-03-26 16:23:16,536] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.9855 2778251670.3909 904.0000
[2019-03-26 16:23:17,556] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1075000, evaluation results [1075000.0, 7958.169071351307, 3156647519.0274653, 1591.0, 8272.626037075155, 2926093187.3302994, 1297.0, 8671.985471559872, 2778251670.3909273, 904.0, 8021.25202719422, 3005320230.384522, 1706.0, 8513.869405860043, 2840814347.946731, 1087.0]
[2019-03-26 16:23:20,873] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1076472: loss 0.0141
[2019-03-26 16:23:20,875] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1076472: learning rate 0.0000
[2019-03-26 16:23:22,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2059996e-16 1.0000000e+00 1.9626794e-19 2.8028887e-16 1.3386970e-26], sum to 1.0000
[2019-03-26 16:23:22,639] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4131
[2019-03-26 16:23:22,649] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 61.0, 1.0, 2.0, 0.7461307550320919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1219838.501201951, 1219838.501201951, 250563.1228964446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 572400.0000, 
sim time next is 573000.0000, 
raw observation next is [23.76666666666667, 61.16666666666667, 1.0, 2.0, 0.6206558011641495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1014574.779839985, 1014574.779839985, 220047.3637728094], 
processed observation next is [1.0, 0.6521739130434783, 0.32543443917851517, 0.6116666666666667, 1.0, 1.0, 0.5429587965833127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28182632773332916, 0.28182632773332916, 0.32842890115344686], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.09070935], dtype=float32), -1.1047626]. 
=============================================
[2019-03-26 16:23:22,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.671413]
 [62.8315  ]
 [63.226254]
 [63.72558 ]
 [64.30771 ]], R is [[63.50219345]
 [63.49319839]
 [63.47888184]
 [63.46548843]
 [63.45737457]].
[2019-03-26 16:23:24,806] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1078223: loss 7.7614
[2019-03-26 16:23:24,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1078223: learning rate 0.0000
[2019-03-26 16:23:26,239] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1078857: loss 7.6202
[2019-03-26 16:23:26,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1078858: learning rate 0.0000
[2019-03-26 16:23:27,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.3036700e-24 1.0000000e+00 2.3382039e-25 9.3101695e-27 1.8681647e-33], sum to 1.0000
[2019-03-26 16:23:27,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0069
[2019-03-26 16:23:27,725] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.16666666666667, 1.0, 2.0, 0.3322008264389752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516494.7689646671, 516494.7689646671, 168073.3060268565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 969000.0000, 
sim time next is 969600.0000, 
raw observation next is [21.9, 92.33333333333334, 1.0, 2.0, 0.3238541162463477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 503245.2882189518, 503245.2882189525, 167039.1819228981], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.9233333333333335, 1.0, 1.0, 0.18536640511608155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13979035783859772, 0.13979035783859792, 0.24931221182522106], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.85494155], dtype=float32), -1.472788]. 
=============================================
[2019-03-26 16:23:30,101] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1080569: loss 7.6633
[2019-03-26 16:23:30,104] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1080569: learning rate 0.0000
[2019-03-26 16:23:30,331] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080671: loss 7.5410
[2019-03-26 16:23:30,334] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080671: learning rate 0.0000
[2019-03-26 16:23:30,804] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1080872: loss 7.2799
[2019-03-26 16:23:30,809] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1080874: learning rate 0.0000
[2019-03-26 16:23:32,145] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1081469: loss 7.1840
[2019-03-26 16:23:32,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1081469: learning rate 0.0000
[2019-03-26 16:23:32,690] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081715: loss 7.0695
[2019-03-26 16:23:32,696] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081716: learning rate 0.0000
[2019-03-26 16:23:32,907] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1081812: loss 0.0049
[2019-03-26 16:23:32,910] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1081813: learning rate 0.0000
[2019-03-26 16:23:33,315] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1081993: loss 6.7558
[2019-03-26 16:23:33,316] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1081993: learning rate 0.0000
[2019-03-26 16:23:33,484] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1082066: loss 6.7628
[2019-03-26 16:23:33,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1082066: learning rate 0.0000
[2019-03-26 16:23:33,637] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082132: loss 6.6611
[2019-03-26 16:23:33,639] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082133: loss 6.6574
[2019-03-26 16:23:33,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082132: learning rate 0.0000
[2019-03-26 16:23:33,642] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082135: learning rate 0.0000
[2019-03-26 16:23:33,830] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1082220: loss 6.6662
[2019-03-26 16:23:33,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1082220: learning rate 0.0000
[2019-03-26 16:23:33,918] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082263: loss 6.6472
[2019-03-26 16:23:33,921] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082263: learning rate 0.0000
[2019-03-26 16:23:34,083] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1082334: loss 6.5570
[2019-03-26 16:23:34,084] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1082334: learning rate 0.0000
[2019-03-26 16:23:39,092] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1084561: loss 0.8790
[2019-03-26 16:23:39,094] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1084561: learning rate 0.0000
[2019-03-26 16:23:42,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4306641e-23 1.0000000e+00 9.5652382e-25 2.8677778e-26 8.3813533e-33], sum to 1.0000
[2019-03-26 16:23:42,483] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8256
[2019-03-26 16:23:42,489] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 72.66666666666667, 1.0, 2.0, 0.2990771172722378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475818.0563652861, 475818.0563652861, 165316.3083429248], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 908400.0000, 
sim time next is 909000.0000, 
raw observation next is [23.75, 72.0, 1.0, 2.0, 0.3003861962009937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 477419.4241391998, 477419.4241391998, 165421.8145714712], 
processed observation next is [0.0, 0.5217391304347826, 0.3246445497630332, 0.72, 1.0, 1.0, 0.15709180265179964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13261650670533326, 0.13261650670533326, 0.24689823070368833], 
reward next is 0.7531, 
noisyNet noise sample is [array([-1.7932758], dtype=float32), -0.01183613]. 
=============================================
[2019-03-26 16:23:42,506] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.282684]
 [76.29977 ]
 [76.30265 ]
 [76.258545]
 [76.25281 ]], R is [[76.2664566 ]
 [76.25704956]
 [76.2479248 ]
 [76.23901367]
 [76.2301712 ]].
[2019-03-26 16:23:42,692] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1086155: loss 0.0096
[2019-03-26 16:23:42,694] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1086155: learning rate 0.0000
[2019-03-26 16:23:43,533] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6603579e-24 1.0000000e+00 1.9991946e-24 1.4189499e-25 5.8243155e-33], sum to 1.0000
[2019-03-26 16:23:43,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8442
[2019-03-26 16:23:43,554] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 70.66666666666667, 1.0, 2.0, 0.3135463153491793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493711.9461238421, 493711.9461238421, 166509.8329997223], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 921000.0000, 
sim time next is 921600.0000, 
raw observation next is [24.3, 71.0, 1.0, 2.0, 0.3134652038833068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493740.0374303367, 493740.0374303367, 166515.7331143028], 
processed observation next is [0.0, 0.6956521739130435, 0.3507109004739337, 0.71, 1.0, 1.0, 0.17284964323289972, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13715001039731575, 0.13715001039731575, 0.2485309449467206], 
reward next is 0.7515, 
noisyNet noise sample is [array([1.9693655], dtype=float32), -0.37557417]. 
=============================================
[2019-03-26 16:23:43,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1941159e-23 1.0000000e+00 3.2075486e-25 1.8550772e-25 2.3307584e-33], sum to 1.0000
[2019-03-26 16:23:43,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1515
[2019-03-26 16:23:43,994] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.63333333333333, 69.33333333333333, 1.0, 2.0, 0.3155173422487395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496224.8312151646, 496224.8312151639, 166682.3374941126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 918600.0000, 
sim time next is 919200.0000, 
raw observation next is [24.56666666666667, 69.66666666666667, 1.0, 2.0, 0.314944250029077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495460.0831677268, 495460.0831677268, 166628.6931227838], 
processed observation next is [0.0, 0.6521739130434783, 0.3633491311216432, 0.6966666666666668, 1.0, 1.0, 0.17463162654105663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13762780087992413, 0.13762780087992413, 0.24869954197430416], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.39562213], dtype=float32), -1.2776235]. 
=============================================
[2019-03-26 16:23:44,342] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1086888: loss 0.0332
[2019-03-26 16:23:44,345] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1086889: learning rate 0.0000
[2019-03-26 16:23:45,017] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8366951e-21 1.0000000e+00 7.0060176e-23 1.0739041e-22 1.4333194e-30], sum to 1.0000
[2019-03-26 16:23:45,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3850
[2019-03-26 16:23:45,031] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.0, 1.0, 2.0, 0.3433815576369807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531856.691001625, 531856.6910016245, 169237.5690268535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 961200.0000, 
sim time next is 961800.0000, 
raw observation next is [21.81666666666667, 93.83333333333334, 1.0, 2.0, 0.3383488663541128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 524192.5131478327, 524192.5131478327, 168626.7849811791], 
processed observation next is [1.0, 0.13043478260869565, 0.2330173775671408, 0.9383333333333335, 1.0, 1.0, 0.20282995946278654, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14560903142995352, 0.14560903142995352, 0.2516817686286255], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.2639356], dtype=float32), -0.30324468]. 
=============================================
[2019-03-26 16:23:46,926] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.4256100e-21 1.0000000e+00 6.2920268e-22 1.3689477e-20 4.7376899e-30], sum to 1.0000
[2019-03-26 16:23:46,934] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7792
[2019-03-26 16:23:46,940] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 89.66666666666667, 1.0, 2.0, 0.292297394789205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 468788.9812294227, 468788.9812294221, 164869.7039335522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1125600.0000, 
sim time next is 1126200.0000, 
raw observation next is [20.83333333333334, 89.83333333333333, 1.0, 2.0, 0.2925687654486595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 469344.0314759809, 469344.0314759803, 164909.1301145324], 
processed observation next is [1.0, 0.0, 0.1864139020537128, 0.8983333333333333, 1.0, 1.0, 0.1476732113839271, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13037334207666135, 0.1303733420766612, 0.24613303002169015], 
reward next is 0.7539, 
noisyNet noise sample is [array([1.5399917], dtype=float32), 0.8164216]. 
=============================================
[2019-03-26 16:23:48,083] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1088538: loss 0.0223
[2019-03-26 16:23:48,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1088538: learning rate 0.0000
[2019-03-26 16:23:48,282] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6055200e-19 1.0000000e+00 4.3893766e-22 2.6104324e-20 1.2627069e-29], sum to 1.0000
[2019-03-26 16:23:48,295] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-26 16:23:48,301] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 97.16666666666667, 1.0, 2.0, 0.3576113633991529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549453.8984225335, 549453.8984225335, 170560.0307967989], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1014600.0000, 
sim time next is 1015200.0000, 
raw observation next is [21.7, 97.0, 1.0, 2.0, 0.3573041311786649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549303.5648226578, 549303.5648226573, 170556.7196522344], 
processed observation next is [1.0, 0.782608695652174, 0.2274881516587678, 0.97, 1.0, 1.0, 0.22566762792610226, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1525843235618494, 0.15258432356184923, 0.2545622681376633], 
reward next is 0.7454, 
noisyNet noise sample is [array([0.7952896], dtype=float32), 0.15198897]. 
=============================================
[2019-03-26 16:23:48,357] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088660: loss 0.0206
[2019-03-26 16:23:48,360] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088660: learning rate 0.0000
[2019-03-26 16:23:48,746] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1088831: loss 0.0267
[2019-03-26 16:23:48,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1088833: learning rate 0.0000
[2019-03-26 16:23:50,106] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1089430: loss 0.0236
[2019-03-26 16:23:50,108] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1089430: learning rate 0.0000
[2019-03-26 16:23:50,763] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089726: loss 0.0226
[2019-03-26 16:23:50,768] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089728: learning rate 0.0000
[2019-03-26 16:23:51,183] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1089910: loss 0.7485
[2019-03-26 16:23:51,186] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1089911: learning rate 0.0000
[2019-03-26 16:23:51,261] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1089945: loss 0.0116
[2019-03-26 16:23:51,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1089945: learning rate 0.0000
[2019-03-26 16:23:51,565] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1090079: loss 0.0091
[2019-03-26 16:23:51,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1090079: learning rate 0.0000
[2019-03-26 16:23:51,582] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090085: loss 0.0077
[2019-03-26 16:23:51,584] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090085: learning rate 0.0000
[2019-03-26 16:23:51,690] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090136: loss 0.0047
[2019-03-26 16:23:51,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090136: learning rate 0.0000
[2019-03-26 16:23:51,907] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1090231: loss 0.0047
[2019-03-26 16:23:51,909] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1090231: learning rate 0.0000
[2019-03-26 16:23:51,935] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090240: loss 0.0059
[2019-03-26 16:23:51,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090240: learning rate 0.0000
[2019-03-26 16:23:52,181] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1090351: loss 0.0052
[2019-03-26 16:23:52,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1090351: learning rate 0.0000
[2019-03-26 16:23:55,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6072840e-20 1.0000000e+00 1.5933029e-22 8.9787030e-21 7.8160439e-31], sum to 1.0000
[2019-03-26 16:23:55,875] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5318
[2019-03-26 16:23:55,883] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 85.33333333333334, 1.0, 2.0, 0.3049440339954287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485473.150321774, 485473.150321774, 166013.7063149755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1117200.0000, 
sim time next is 1117800.0000, 
raw observation next is [21.65, 86.0, 1.0, 2.0, 0.3038511470227199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 484043.942535425, 484043.942535425, 165914.981291909], 
processed observation next is [1.0, 0.9565217391304348, 0.22511848341232227, 0.86, 1.0, 1.0, 0.1612664421960481, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13445665070428472, 0.13445665070428472, 0.24763430043568507], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.43698305], dtype=float32), -1.3068827]. 
=============================================
[2019-03-26 16:23:57,201] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1092580: loss 0.1342
[2019-03-26 16:23:57,208] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1092584: learning rate 0.0000
[2019-03-26 16:23:59,820] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2178879e-21 1.0000000e+00 4.6360680e-23 1.7182631e-21 8.0851592e-31], sum to 1.0000
[2019-03-26 16:23:59,831] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5469
[2019-03-26 16:23:59,836] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 73.0, 1.0, 2.0, 0.3514016201417813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542729.9341087812, 542729.9341087817, 170081.8251625188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195200.0000, 
sim time next is 1195800.0000, 
raw observation next is [24.7, 73.83333333333334, 1.0, 2.0, 0.3517874959090655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 543006.3234376422, 543006.3234376422, 170095.7090169036], 
processed observation next is [1.0, 0.8695652173913043, 0.3696682464454976, 0.7383333333333334, 1.0, 1.0, 0.21902107940851265, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1508350898437895, 0.1508350898437895, 0.2538741925625427], 
reward next is 0.7461, 
noisyNet noise sample is [array([0.3115621], dtype=float32), -0.5293469]. 
=============================================
[2019-03-26 16:24:01,027] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1094220: loss 0.8738
[2019-03-26 16:24:01,029] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1094220: learning rate 0.0000
[2019-03-26 16:24:02,571] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1094902: loss 0.9058
[2019-03-26 16:24:02,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1094903: learning rate 0.0000
[2019-03-26 16:24:04,898] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4697659e-19 1.0000000e+00 9.4637411e-21 2.5527675e-18 1.5960720e-28], sum to 1.0000
[2019-03-26 16:24:04,908] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4029
[2019-03-26 16:24:04,913] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.8223431819794218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1221404.104168523, 1221404.104168523, 259426.428015832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1329000.0000, 
sim time next is 1329600.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.7450749485453285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1106612.822111481, 1106612.82211148, 239564.1965244612], 
processed observation next is [1.0, 0.391304347826087, 0.28909952606635075, 0.95, 1.0, 1.0, 0.6928613837895524, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30739245058652254, 0.3073924505865222, 0.3575585022753152], 
reward next is 0.6424, 
noisyNet noise sample is [array([0.6227249], dtype=float32), 0.58017945]. 
=============================================
[2019-03-26 16:24:06,205] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8219719e-18 1.0000000e+00 9.5824593e-21 1.1890240e-17 3.2865516e-29], sum to 1.0000
[2019-03-26 16:24:06,206] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1096593: loss 0.8443
[2019-03-26 16:24:06,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1096593: learning rate 0.0000
[2019-03-26 16:24:06,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9304
[2019-03-26 16:24:06,218] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 94.0, 1.0, 2.0, 0.4597026772879609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651966.8511016708, 651966.8511016708, 178762.9624516959], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1299000.0000, 
sim time next is 1299600.0000, 
raw observation next is [24.3, 94.0, 1.0, 2.0, 0.45971656316523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 651988.9023952944, 651988.902395295, 178765.3062099393], 
processed observation next is [1.0, 0.043478260869565216, 0.3507109004739337, 0.94, 1.0, 1.0, 0.3490561001990723, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18110802844313734, 0.1811080284431375, 0.266813889865581], 
reward next is 0.7332, 
noisyNet noise sample is [array([-0.82973343], dtype=float32), -0.17997031]. 
=============================================
[2019-03-26 16:24:06,344] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096655: loss 0.8492
[2019-03-26 16:24:06,347] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096657: learning rate 0.0000
[2019-03-26 16:24:06,856] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1096890: loss 0.8349
[2019-03-26 16:24:06,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1096891: learning rate 0.0000
[2019-03-26 16:24:08,095] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1097458: loss 0.6683
[2019-03-26 16:24:08,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1097460: learning rate 0.0000
[2019-03-26 16:24:08,832] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097796: loss 0.6507
[2019-03-26 16:24:08,834] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097796: learning rate 0.0000
[2019-03-26 16:24:08,873] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1097819: loss 0.0341
[2019-03-26 16:24:08,876] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1097819: learning rate 0.0000
[2019-03-26 16:24:09,002] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1097875: loss 0.6610
[2019-03-26 16:24:09,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1097875: learning rate 0.0000
[2019-03-26 16:24:09,377] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1098047: loss 0.6399
[2019-03-26 16:24:09,381] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1098048: learning rate 0.0000
[2019-03-26 16:24:09,464] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098088: loss 0.6753
[2019-03-26 16:24:09,468] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098090: learning rate 0.0000
[2019-03-26 16:24:09,477] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098092: loss 0.6692
[2019-03-26 16:24:09,478] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098092: learning rate 0.0000
[2019-03-26 16:24:09,670] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1098180: loss 0.6226
[2019-03-26 16:24:09,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1098181: learning rate 0.0000
[2019-03-26 16:24:09,803] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098242: loss 0.6101
[2019-03-26 16:24:09,808] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098243: learning rate 0.0000
[2019-03-26 16:24:10,119] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1098385: loss 0.6048
[2019-03-26 16:24:10,121] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1098385: learning rate 0.0000
[2019-03-26 16:24:11,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0594656e-10 9.9923027e-01 6.4616908e-15 7.6976634e-04 9.8473913e-20], sum to 1.0000
[2019-03-26 16:24:11,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4337
[2019-03-26 16:24:11,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2571123.879634012 W.
[2019-03-26 16:24:11,311] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.25, 78.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 8.485271066786687, 6.9112, 168.9040088907554, 2571123.879634012, 1454482.843105291, 310503.6981774229], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1696200.0000, 
sim time next is 1696800.0000, 
raw observation next is [28.3, 78.33333333333334, 1.0, 2.0, 0.6874142952681517, 1.0, 1.0, 0.6874142952681517, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1922199.225683545, 1922199.225683545, 368779.7061159805], 
processed observation next is [1.0, 0.6521739130434783, 0.5402843601895735, 0.7833333333333334, 1.0, 1.0, 0.6233907171905442, 1.0, 0.5, 0.6233907171905442, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5339442293565403, 0.5339442293565403, 0.5504174718148963], 
reward next is 0.4496, 
noisyNet noise sample is [array([-0.80772585], dtype=float32), -0.015160048]. 
=============================================
[2019-03-26 16:24:12,360] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8773405e-21 1.0000000e+00 4.0539366e-23 2.4101870e-21 8.0748027e-31], sum to 1.0000
[2019-03-26 16:24:12,371] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6238
[2019-03-26 16:24:12,376] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 94.83333333333333, 1.0, 2.0, 0.3716634034496848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 564164.5981793643, 564164.5981793636, 171613.0683750689], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1461000.0000, 
sim time next is 1461600.0000, 
raw observation next is [22.3, 95.0, 1.0, 2.0, 0.3696442427333634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561922.6241534292, 561922.6241534292, 171444.2038619962], 
processed observation next is [0.0, 0.9565217391304348, 0.25592417061611383, 0.95, 1.0, 1.0, 0.24053523220887155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.156089617820397, 0.156089617820397, 0.25588687143581523], 
reward next is 0.7441, 
noisyNet noise sample is [array([-0.54721576], dtype=float32), 0.13973813]. 
=============================================
[2019-03-26 16:24:13,676] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 16:24:13,679] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:24:13,680] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:24:13,681] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:13,682] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:24:13,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:13,683] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:24:13,684] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:13,685] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:13,684] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:24:13,688] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:24:13,708] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 16:24:13,708] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 16:24:13,709] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 16:24:13,777] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 16:24:13,797] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 16:24:17,510] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:24:17,511] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.3, 50.0, 1.0, 2.0, 0.300698599477958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481664.4559738073, 481664.4559738073, 165772.7214566341]
[2019-03-26 16:24:17,513] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:24:17,517] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4761507e-24 1.0000000e+00 3.0142363e-25 5.2317841e-27 2.7447545e-33], sampled 0.2238298516655448
[2019-03-26 16:24:33,259] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:24:33,262] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.3, 93.0, 1.0, 2.0, 0.5285086589159383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753666.2896072889, 753666.2896072895, 190117.0290542869]
[2019-03-26 16:24:33,263] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:24:33,265] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.0904676e-22 1.0000000e+00 2.1102107e-23 7.2921400e-23 2.7760312e-31], sampled 0.3196446384934448
[2019-03-26 16:24:57,795] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:24:57,797] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.6, 55.5, 1.0, 2.0, 0.919322689155755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1284965.11058528, 1284965.11058528, 275312.0686079464]
[2019-03-26 16:24:57,798] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:24:57,801] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.5756839e-19 1.0000000e+00 2.6604047e-21 2.1727295e-18 1.3805687e-28], sampled 0.8436126970440567
[2019-03-26 16:25:23,833] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:25:23,835] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.304194055, 74.891492285, 1.0, 2.0, 0.6391975731984201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 893261.0856072002, 893261.0856072002, 208276.752318849]
[2019-03-26 16:25:23,836] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:25:23,840] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.35199156e-20 1.00000000e+00 1.01142135e-22 3.57241357e-18
 2.27963902e-29], sampled 0.5238739027307726
[2019-03-26 16:25:35,572] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:25:35,574] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.99645866, 63.51306797666666, 1.0, 2.0, 0.6953324513062177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 971743.9277148304, 971743.9277148297, 219840.4894275318]
[2019-03-26 16:25:35,576] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:25:35,578] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2041030e-24 1.0000000e+00 1.6815964e-25 1.0942476e-26 3.4582364e-34], sampled 0.23615916822811256
[2019-03-26 16:25:41,776] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:25:41,777] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.8, 82.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.629527730856751, 6.9112, 168.9086314931762, 1963697.359267698, 1454103.992540726, 311352.7398815391]
[2019-03-26 16:25:41,777] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:25:41,779] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0534082e-16 1.0000000e+00 5.0720973e-19 1.7263009e-14 8.8160747e-26], sampled 0.18671652257487104
[2019-03-26 16:25:41,779] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1963697.359267698 W.
[2019-03-26 16:25:46,295] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:25:46,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 63.0, 1.0, 2.0, 0.5250897365125621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733743.4330258347, 733743.433025834, 187620.4260151756]
[2019-03-26 16:25:46,298] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:25:46,301] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3666454e-22 1.0000000e+00 4.2521677e-24 1.9572472e-23 4.5705660e-32], sampled 0.43322578430714553
[2019-03-26 16:26:05,180] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0055313], dtype=float32), 0.09132588]
[2019-03-26 16:26:05,182] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.28218230333334, 63.80691346, 1.0, 2.0, 0.4362597083724521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632806.6493587167, 632806.6493587167, 177186.612185333]
[2019-03-26 16:26:05,183] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:26:05,185] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0626018e-23 1.0000000e+00 1.7621038e-24 3.6339218e-25 1.8386903e-32], sampled 0.9562362005127997
[2019-03-26 16:26:09,523] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7982.4545 3154356865.7174 1533.0000
[2019-03-26 16:26:09,924] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8281.2476 2925420854.1498 1283.0000
[2019-03-26 16:26:10,269] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8038.1077 3003881255.0045 1669.0000
[2019-03-26 16:26:10,343] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8516.6491 2840233957.7033 1069.0000
[2019-03-26 16:26:10,359] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8676.2051 2777845150.5531 895.0000
[2019-03-26 16:26:11,373] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1100000, evaluation results [1100000.0, 7982.454461137724, 3154356865.717417, 1533.0, 8281.247616348634, 2925420854.14977, 1283.0, 8676.205138278045, 2777845150.5531187, 895.0, 8038.107681931352, 3003881255.0044937, 1669.0, 8516.649108892814, 2840233957.7033477, 1069.0]
[2019-03-26 16:26:12,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4676962e-22 1.0000000e+00 3.9379116e-24 1.0225237e-23 4.1544733e-32], sum to 1.0000
[2019-03-26 16:26:12,064] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4054
[2019-03-26 16:26:12,070] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 73.66666666666667, 1.0, 2.0, 0.4220774919393711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613484.5792079386, 613484.5792079386, 175339.262532732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1446000.0000, 
sim time next is 1446600.0000, 
raw observation next is [26.35, 74.83333333333333, 1.0, 2.0, 0.4201252165336955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 612031.5313201292, 612031.5313201298, 175240.9820735452], 
processed observation next is [0.0, 0.7391304347826086, 0.4478672985781992, 0.7483333333333333, 1.0, 1.0, 0.30135568257071743, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17000875870003587, 0.17000875870003604, 0.26155370458738086], 
reward next is 0.7384, 
noisyNet noise sample is [array([0.19554801], dtype=float32), -0.633977]. 
=============================================
[2019-03-26 16:26:12,953] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1100710: loss 0.4055
[2019-03-26 16:26:12,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1100710: learning rate 0.0000
[2019-03-26 16:26:16,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9722209e-24 1.0000000e+00 1.8516552e-25 2.9720562e-27 2.9306167e-33], sum to 1.0000
[2019-03-26 16:26:16,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0529
[2019-03-26 16:26:16,027] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 97.33333333333334, 1.0, 2.0, 0.4669774741565006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 656237.0641911187, 656237.064191118, 179064.9579631308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2006400.0000, 
sim time next is 2007000.0000, 
raw observation next is [24.2, 97.0, 1.0, 2.0, 0.4695583185565638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658112.1932833813, 658112.1932833806, 179221.2954939674], 
processed observation next is [0.0, 0.21739130434782608, 0.3459715639810427, 0.97, 1.0, 1.0, 0.3609136368151371, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18280894257871702, 0.18280894257871683, 0.2674944708865185], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.3497718], dtype=float32), 1.8474851]. 
=============================================
[2019-03-26 16:26:16,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.99146 ]
 [73.02405 ]
 [73.03645 ]
 [72.991554]
 [72.98092 ]], R is [[72.96173859]
 [72.96486664]
 [72.96813965]
 [72.97145081]
 [72.9745636 ]].
[2019-03-26 16:26:16,225] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1102167: loss 0.0790
[2019-03-26 16:26:16,228] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1102169: learning rate 0.0000
[2019-03-26 16:26:17,878] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1102910: loss 0.1516
[2019-03-26 16:26:17,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1102911: learning rate 0.0000
[2019-03-26 16:26:19,877] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3751108e-20 1.0000000e+00 1.1703242e-21 1.8748675e-19 2.9338217e-29], sum to 1.0000
[2019-03-26 16:26:19,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2332
[2019-03-26 16:26:19,893] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 91.0, 1.0, 2.0, 0.3298331534031852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516317.0468404786, 516317.0468404786, 168154.9518577245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1557600.0000, 
sim time next is 1558200.0000, 
raw observation next is [21.73333333333333, 91.0, 1.0, 2.0, 0.3285881520650155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 514803.0287488053, 514803.0287488059, 168048.1391282832], 
processed observation next is [1.0, 0.0, 0.22906793048973137, 0.91, 1.0, 1.0, 0.19107006272893434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1430008413191126, 0.14300084131911275, 0.25081811810191523], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.00471865], dtype=float32), -1.4154621]. 
=============================================
[2019-03-26 16:26:21,748] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1104594: loss 0.1581
[2019-03-26 16:26:21,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1104594: learning rate 0.0000
[2019-03-26 16:26:21,804] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104619: loss 0.1694
[2019-03-26 16:26:21,806] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104619: learning rate 0.0000
[2019-03-26 16:26:22,332] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1104855: loss 0.1727
[2019-03-26 16:26:22,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1104855: learning rate 0.0000
[2019-03-26 16:26:23,717] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1105465: loss 0.0896
[2019-03-26 16:26:23,719] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1105465: learning rate 0.0000
[2019-03-26 16:26:24,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105769: loss 0.0649
[2019-03-26 16:26:24,399] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105769: learning rate 0.0000
[2019-03-26 16:26:24,575] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1105848: loss 0.0624
[2019-03-26 16:26:24,578] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1105849: learning rate 0.0000
[2019-03-26 16:26:24,770] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1105935: loss 16.2585
[2019-03-26 16:26:24,772] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1105935: learning rate 0.0000
[2019-03-26 16:26:24,905] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1105993: loss 0.0610
[2019-03-26 16:26:24,908] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1105993: learning rate 0.0000
[2019-03-26 16:26:24,959] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106016: loss 0.0539
[2019-03-26 16:26:24,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106016: learning rate 0.0000
[2019-03-26 16:26:24,981] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1106024: loss 0.0581
[2019-03-26 16:26:24,983] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1106024: learning rate 0.0000
[2019-03-26 16:26:25,259] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1106153: loss 0.0431
[2019-03-26 16:26:25,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1106154: learning rate 0.0000
[2019-03-26 16:26:25,386] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106206: loss 0.0557
[2019-03-26 16:26:25,388] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106206: learning rate 0.0000
[2019-03-26 16:26:25,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1106372: loss 0.0682
[2019-03-26 16:26:25,767] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1106373: learning rate 0.0000
[2019-03-26 16:26:31,014] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1108708: loss 7.7594
[2019-03-26 16:26:31,016] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1108708: learning rate 0.0000
[2019-03-26 16:26:33,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6125657e-20 1.0000000e+00 6.4345548e-23 1.0393094e-20 3.6482448e-31], sum to 1.0000
[2019-03-26 16:26:33,825] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0237
[2019-03-26 16:26:33,830] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 93.16666666666667, 1.0, 2.0, 0.3280013532986883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515005.1491886139, 515005.1491886139, 168090.5317381071], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1804200.0000, 
sim time next is 1804800.0000, 
raw observation next is [21.4, 93.33333333333334, 1.0, 2.0, 0.3293026980380409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 516778.268878669, 516778.2688786697, 168221.8515881677], 
processed observation next is [1.0, 0.9130434782608695, 0.21327014218009477, 0.9333333333333335, 1.0, 1.0, 0.19193096149161554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14354951913296363, 0.14354951913296382, 0.251077390430101], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.22067265], dtype=float32), 0.07117885]. 
=============================================
[2019-03-26 16:26:34,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1110306: loss 16.6526
[2019-03-26 16:26:34,625] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1110306: learning rate 0.0000
[2019-03-26 16:26:36,325] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1111056: loss -35.0848
[2019-03-26 16:26:36,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1111056: learning rate 0.0000
[2019-03-26 16:26:37,177] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.05593037e-19 1.00000000e+00 4.21515619e-22 2.69965337e-20
 1.42596784e-30], sum to 1.0000
[2019-03-26 16:26:37,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2114
[2019-03-26 16:26:37,191] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 93.33333333333333, 1.0, 2.0, 0.4040301460663349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599988.9851594074, 599988.9851594067, 174452.5545965302], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1969800.0000, 
sim time next is 1970400.0000, 
raw observation next is [23.1, 93.66666666666667, 1.0, 2.0, 0.4020499205968325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598273.8111152219, 598273.8111152214, 174330.5577556562], 
processed observation next is [1.0, 0.8260869565217391, 0.2938388625592418, 0.9366666666666668, 1.0, 1.0, 0.27957821758654516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16618716975422831, 0.16618716975422815, 0.2601948623218749], 
reward next is 0.7398, 
noisyNet noise sample is [array([0.49851677], dtype=float32), 0.3269117]. 
=============================================
[2019-03-26 16:26:37,737] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3650131e-16 1.0000000e+00 8.5162592e-19 7.8582618e-15 1.5906466e-25], sum to 1.0000
[2019-03-26 16:26:37,745] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0284
[2019-03-26 16:26:37,754] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2100558.197830642 W.
[2019-03-26 16:26:37,760] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 71.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.822318600183165, 6.9112, 168.9081488063479, 2100558.197830642, 1454197.70221077, 311350.5057129195], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2362800.0000, 
sim time next is 2363400.0000, 
raw observation next is [29.95, 70.5, 1.0, 2.0, 0.7174053327423677, 1.0, 1.0, 0.7174053327423677, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2006140.924365637, 2006140.924365638, 381662.7991430498], 
processed observation next is [1.0, 0.34782608695652173, 0.6184834123222749, 0.705, 1.0, 1.0, 0.6595244972799611, 1.0, 0.5, 0.6595244972799611, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5572613678793435, 0.5572613678793439, 0.5696459688702236], 
reward next is 0.4304, 
noisyNet noise sample is [array([1.82719], dtype=float32), 0.01376799]. 
=============================================
[2019-03-26 16:26:39,853] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1112624: loss -42.7242
[2019-03-26 16:26:39,856] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1112624: learning rate 0.0000
[2019-03-26 16:26:40,007] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112695: loss -30.1823
[2019-03-26 16:26:40,011] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112695: learning rate 0.0000
[2019-03-26 16:26:40,363] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1112852: loss -35.9481
[2019-03-26 16:26:40,366] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1112852: learning rate 0.0000
[2019-03-26 16:26:40,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.13938671e-08 9.93884742e-01 3.50869534e-13 6.11529080e-03
 1.24409635e-17], sum to 1.0000
[2019-03-26 16:26:40,928] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0152
[2019-03-26 16:26:40,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1766325.785011644 W.
[2019-03-26 16:26:40,942] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.53333333333333, 78.33333333333334, 1.0, 2.0, 0.6317169542934786, 1.0, 1.0, 0.6317169542934786, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1766325.785011644, 1766325.785011644, 346248.3372342645], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1941600.0000, 
sim time next is 1942200.0000, 
raw observation next is [26.6, 78.0, 1.0, 2.0, 0.42098427728899, 1.0, 2.0, 0.42098427728899, 1.0, 1.0, 0.7055438746642646, 6.911199999999999, 6.9112, 170.5573041426782, 1765652.668443705, 1765652.668443706, 360898.2439183804], 
processed observation next is [1.0, 0.4782608695652174, 0.4597156398104266, 0.78, 1.0, 1.0, 0.3023906955289036, 1.0, 1.0, 0.3023906955289036, 1.0, 0.5, 0.6409071642247129, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.49045907456769583, 0.4904590745676961, 0.5386540954005677], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39186057], dtype=float32), -1.3619903]. 
=============================================
[2019-03-26 16:26:41,849] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1113513: loss 8.4029
[2019-03-26 16:26:41,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1113514: learning rate 0.0000
[2019-03-26 16:26:42,494] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1113799: loss -51.9002
[2019-03-26 16:26:42,497] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1113799: learning rate 0.0000
[2019-03-26 16:26:42,543] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113817: loss -28.1455
[2019-03-26 16:26:42,547] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113817: learning rate 0.0000
[2019-03-26 16:26:42,756] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1113909: loss 8.3002
[2019-03-26 16:26:42,759] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1113910: learning rate 0.0000
[2019-03-26 16:26:42,896] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1113972: loss -10.7451
[2019-03-26 16:26:42,898] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1113972: learning rate 0.0000
[2019-03-26 16:26:42,916] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1113980: loss -2.7704
[2019-03-26 16:26:42,919] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1113981: learning rate 0.0000
[2019-03-26 16:26:42,970] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1113999: loss -7.7354
[2019-03-26 16:26:42,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1113999: learning rate 0.0000
[2019-03-26 16:26:43,253] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1114124: loss -39.2614
[2019-03-26 16:26:43,258] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1114126: learning rate 0.0000
[2019-03-26 16:26:43,470] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114223: loss -34.9999
[2019-03-26 16:26:43,471] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114224: learning rate 0.0000
[2019-03-26 16:26:43,746] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1114342: loss 40.6710
[2019-03-26 16:26:43,754] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1114346: learning rate 0.0000
[2019-03-26 16:26:47,440] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1015106e-23 1.0000000e+00 1.1227307e-24 3.4780443e-25 6.1152967e-33], sum to 1.0000
[2019-03-26 16:26:47,448] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7004
[2019-03-26 16:26:47,454] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 96.0, 1.0, 2.0, 0.4602961970323435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649894.0932472008, 649894.0932472001, 178476.709614409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2083800.0000, 
sim time next is 2084400.0000, 
raw observation next is [24.1, 96.0, 1.0, 2.0, 0.4586687352505378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648556.0202974015, 648556.020297402, 178361.9085017403], 
processed observation next is [0.0, 0.13043478260869565, 0.3412322274881518, 0.96, 1.0, 1.0, 0.34779365692835884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18015445008261152, 0.1801544500826117, 0.26621180373394077], 
reward next is 0.7338, 
noisyNet noise sample is [array([1.1252679], dtype=float32), -1.8922203]. 
=============================================
[2019-03-26 16:26:49,737] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1117014: loss -328.0530
[2019-03-26 16:26:49,739] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1117014: learning rate 0.0000
[2019-03-26 16:26:50,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8418224e-21 1.0000000e+00 1.4800187e-24 6.0875465e-20 1.4393732e-31], sum to 1.0000
[2019-03-26 16:26:50,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1460
[2019-03-26 16:26:50,816] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 80.33333333333334, 1.0, 2.0, 0.5381180489597529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751955.2197556107, 751955.2197556107, 189784.2991302836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571600.0000, 
sim time next is 2572200.0000, 
raw observation next is [28.4, 81.0, 1.0, 2.0, 0.5394234672671486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753780.0319965587, 753780.0319965587, 190003.7560932164], 
processed observation next is [1.0, 0.782608695652174, 0.5450236966824644, 0.81, 1.0, 1.0, 0.44508851477969713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20938334222126628, 0.20938334222126628, 0.283587695661517], 
reward next is 0.7164, 
noisyNet noise sample is [array([1.0304948], dtype=float32), -0.61855334]. 
=============================================
[2019-03-26 16:26:52,702] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2859159e-24 1.0000000e+00 1.9535241e-24 2.6871630e-25 3.6309851e-32], sum to 1.0000
[2019-03-26 16:26:52,712] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8091
[2019-03-26 16:26:52,721] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666667, 1.0, 2.0, 0.5612681575784264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784316.6540803378, 784316.6540803378, 193752.661080726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119200.0000, 
sim time next is 2119800.0000, 
raw observation next is [30.0, 75.83333333333333, 1.0, 2.0, 0.5619807788988245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785312.8399107563, 785312.8399107563, 193877.3503473001], 
processed observation next is [0.0, 0.5217391304347826, 0.6208530805687204, 0.7583333333333333, 1.0, 1.0, 0.47226599867328245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21814245553076564, 0.21814245553076564, 0.289369179622836], 
reward next is 0.7106, 
noisyNet noise sample is [array([0.24572794], dtype=float32), 0.22884825]. 
=============================================
[2019-03-26 16:26:52,806] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1118309: loss 8.2727
[2019-03-26 16:26:52,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1118309: learning rate 0.0000
[2019-03-26 16:26:54,335] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1119007: loss 7.3234
[2019-03-26 16:26:54,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1119007: learning rate 0.0000
[2019-03-26 16:26:57,771] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1120575: loss 6.7234
[2019-03-26 16:26:57,773] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1120576: learning rate 0.0000
[2019-03-26 16:26:57,848] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120606: loss 6.6985
[2019-03-26 16:26:57,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120606: learning rate 0.0000
[2019-03-26 16:26:58,167] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1120755: loss 6.8373
[2019-03-26 16:26:58,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1120755: learning rate 0.0000
[2019-03-26 16:26:59,774] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1121488: loss 6.6589
[2019-03-26 16:26:59,777] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121489: learning rate 0.0000
[2019-03-26 16:26:59,998] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6788242e-10 9.9999988e-01 4.3024517e-14 1.3323033e-07 5.4971018e-20], sum to 1.0000
[2019-03-26 16:27:00,007] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4969
[2019-03-26 16:27:00,012] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1891346.805386348 W.
[2019-03-26 16:27:00,020] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 90.33333333333333, 1.0, 2.0, 0.4509270828763028, 1.0, 1.0, 0.4509270828763028, 1.0, 2.0, 0.775656478547832, 6.9112, 6.9112, 170.5573041426782, 1891346.805386348, 1891346.805386348, 381669.6559979172], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [27.0, 89.66666666666667, 1.0, 2.0, 0.6701289264168173, 1.0, 2.0, 0.6701289264168173, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1873822.318785183, 1873822.318785182, 361598.2966289518], 
processed observation next is [1.0, 0.34782608695652173, 0.4786729857819906, 0.8966666666666667, 1.0, 1.0, 0.6025649715865269, 1.0, 1.0, 0.6025649715865269, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5205061996625509, 0.5205061996625505, 0.5396989501924654], 
reward next is 0.4603, 
noisyNet noise sample is [array([-0.02659247], dtype=float32), -0.80844]. 
=============================================
[2019-03-26 16:27:00,403] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121772: loss 6.8911
[2019-03-26 16:27:00,407] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121772: learning rate 0.0000
[2019-03-26 16:27:00,442] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1121797: loss 6.8091
[2019-03-26 16:27:00,446] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1121798: learning rate 0.0000
[2019-03-26 16:27:00,482] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1121812: loss 6.9247
[2019-03-26 16:27:00,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1121812: learning rate 0.0000
[2019-03-26 16:27:00,731] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1121921: loss 6.8294
[2019-03-26 16:27:00,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1121922: learning rate 0.0000
[2019-03-26 16:27:00,845] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1121976: loss 6.9052
[2019-03-26 16:27:00,850] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1121976: learning rate 0.0000
[2019-03-26 16:27:01,058] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1122069: loss 6.9118
[2019-03-26 16:27:01,061] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1122069: learning rate 0.0000
[2019-03-26 16:27:01,271] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1122163: loss -267.7922
[2019-03-26 16:27:01,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1122163: learning rate 0.0000
[2019-03-26 16:27:01,333] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122191: loss 6.8711
[2019-03-26 16:27:01,335] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122191: learning rate 0.0000
[2019-03-26 16:27:01,566] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1122295: loss 6.8276
[2019-03-26 16:27:01,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1122296: learning rate 0.0000
[2019-03-26 16:27:03,160] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.4462360e-20 1.0000000e+00 3.5937423e-22 2.1824700e-21 3.0053893e-29], sum to 1.0000
[2019-03-26 16:27:03,169] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5897
[2019-03-26 16:27:03,182] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 82.0, 1.0, 2.0, 0.670485267407717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 937004.0683421745, 937004.0683421738, 214601.8070888437], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [27.26666666666667, 82.00000000000001, 1.0, 2.0, 0.6952553961221722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 971636.1919683645, 971636.1919683645, 219822.6598649816], 
processed observation next is [1.0, 0.17391304347826086, 0.4913112164297, 0.8200000000000002, 1.0, 1.0, 0.6328378266532195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2698989422134346, 0.2698989422134346, 0.3280935221865397], 
reward next is 0.6719, 
noisyNet noise sample is [array([0.14441751], dtype=float32), 1.9310371]. 
=============================================
[2019-03-26 16:27:03,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9708295e-21 1.0000000e+00 6.0812240e-23 3.4984085e-22 2.6894723e-31], sum to 1.0000
[2019-03-26 16:27:03,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8843
[2019-03-26 16:27:03,480] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.1, 77.0, 1.0, 2.0, 0.5793113965352257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809539.9016293401, 809539.9016293401, 196955.0082168444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2410200.0000, 
sim time next is 2410800.0000, 
raw observation next is [30.0, 77.33333333333334, 1.0, 2.0, 0.5780193806038082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 807733.7294120664, 807733.729412067, 196722.4401446359], 
processed observation next is [1.0, 0.9130434782608695, 0.6208530805687204, 0.7733333333333334, 1.0, 1.0, 0.4915896151853111, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22437048039224067, 0.22437048039224083, 0.2936155823054267], 
reward next is 0.7064, 
noisyNet noise sample is [array([2.2532694], dtype=float32), 0.83092713]. 
=============================================
[2019-03-26 16:27:06,913] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.1149148e-21 1.0000000e+00 6.9128126e-22 5.3144117e-21 5.0367845e-30], sum to 1.0000
[2019-03-26 16:27:06,922] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-26 16:27:06,929] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.65, 71.5, 1.0, 2.0, 0.8092741896984313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1131065.067225003, 1131065.067225003, 246199.7353304236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2362200.0000, 
sim time next is 2362800.0000, 
raw observation next is [29.8, 71.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.822318600183165, 6.9112, 168.9081488063479, 2100558.197830642, 1454197.70221077, 311350.5057129195], 
processed observation next is [1.0, 0.34782608695652173, 0.6113744075829385, 0.71, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09111186001831646, 0.0, 0.8294163371242782, 0.5834883882862895, 0.4039438061696583, 0.4647022473327157], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04404074], dtype=float32), -0.11122681]. 
=============================================
[2019-03-26 16:27:07,127] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1124842: loss 0.0554
[2019-03-26 16:27:07,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1124842: learning rate 0.0000
[2019-03-26 16:27:07,478] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 16:27:07,479] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:27:07,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:07,480] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:27:07,482] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:27:07,483] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:07,484] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:27:07,484] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:27:07,486] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:07,486] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:07,487] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:27:07,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 16:27:07,535] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 16:27:07,558] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 16:27:07,558] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 16:27:07,603] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 16:27:49,906] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00733638], dtype=float32), 0.08695]
[2019-03-26 16:27:49,907] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.5, 97.0, 1.0, 2.0, 0.3105448129433591, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492558.611368616, 492558.611368616, 166501.105965699]
[2019-03-26 16:27:49,909] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:27:49,912] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.1154214e-23 1.0000000e+00 2.9860955e-24 3.0062212e-25 1.1858623e-32], sampled 0.25849712713398754
[2019-03-26 16:29:03,803] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.3165 2842229687.5323 1126.0000
[2019-03-26 16:29:04,138] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.1054 3007461336.2312 1762.0000
[2019-03-26 16:29:04,171] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7901.4388 3162560186.3859 1739.0000
[2019-03-26 16:29:04,299] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.2285 2927400483.4225 1335.0000
[2019-03-26 16:29:04,304] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.8247 2779095224.6348 925.0000
[2019-03-26 16:29:05,320] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1125000, evaluation results [1125000.0, 7901.438780759239, 3162560186.385865, 1739.0, 8256.228471155222, 2927400483.4225326, 1335.0, 8663.824684964738, 2779095224.6348305, 925.0, 8001.105375786951, 3007461336.231233, 1762.0, 8499.31649361952, 2842229687.5322976, 1126.0]
[2019-03-26 16:29:08,291] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1126331: loss -472.5569
[2019-03-26 16:29:08,295] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1126332: learning rate 0.0000
[2019-03-26 16:29:10,112] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1127154: loss -350.2831
[2019-03-26 16:29:10,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1127154: learning rate 0.0000
[2019-03-26 16:29:13,481] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128646: loss -241.6573
[2019-03-26 16:29:13,485] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128647: learning rate 0.0000
[2019-03-26 16:29:13,589] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1128694: loss -435.4404
[2019-03-26 16:29:13,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1128695: learning rate 0.0000
[2019-03-26 16:29:13,849] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1128809: loss -351.1614
[2019-03-26 16:29:13,853] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1128809: learning rate 0.0000
[2019-03-26 16:29:15,629] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129601: loss -428.7576
[2019-03-26 16:29:15,631] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129601: learning rate 0.0000
[2019-03-26 16:29:16,147] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1129830: loss 0.0046
[2019-03-26 16:29:16,149] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1129830: learning rate 0.0000
[2019-03-26 16:29:16,286] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1129889: loss -300.0509
[2019-03-26 16:29:16,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1129890: learning rate 0.0000
[2019-03-26 16:29:16,321] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129905: loss -348.5095
[2019-03-26 16:29:16,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129906: learning rate 0.0000
[2019-03-26 16:29:16,375] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1129930: loss -389.9713
[2019-03-26 16:29:16,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1129930: learning rate 0.0000
[2019-03-26 16:29:16,450] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1129962: loss -225.2339
[2019-03-26 16:29:16,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1129962: learning rate 0.0000
[2019-03-26 16:29:16,743] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1130093: loss -396.1628
[2019-03-26 16:29:16,747] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1130094: learning rate 0.0000
[2019-03-26 16:29:16,969] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1130192: loss -382.5765
[2019-03-26 16:29:16,981] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1130192: learning rate 0.0000
[2019-03-26 16:29:17,020] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130210: loss -365.5439
[2019-03-26 16:29:17,025] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130210: learning rate 0.0000
[2019-03-26 16:29:17,399] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1130381: loss -324.1166
[2019-03-26 16:29:17,401] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1130381: learning rate 0.0000
[2019-03-26 16:29:18,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.7457696e-28 1.0000000e+00 2.0061513e-27 1.2686056e-31 8.7207974e-37], sum to 1.0000
[2019-03-26 16:29:18,650] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1829
[2019-03-26 16:29:18,654] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.475867988442044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664941.0253757458, 664941.0253757464, 179901.4110463232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2703600.0000, 
sim time next is 2704200.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4770851508227688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666642.3273552274, 666642.3273552274, 180083.5644885299], 
processed observation next is [0.0, 0.30434782608695654, 0.3364928909952607, 1.0, 1.0, 1.0, 0.36998210942502263, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18517842426534095, 0.18517842426534095, 0.26878143953511924], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.298448], dtype=float32), -0.39662924]. 
=============================================
[2019-03-26 16:29:22,175] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1132510: loss 9.4723
[2019-03-26 16:29:22,178] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1132512: learning rate 0.0000
[2019-03-26 16:29:25,886] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1134155: loss 0.0143
[2019-03-26 16:29:25,888] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1134156: learning rate 0.0000
[2019-03-26 16:29:26,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4386858e-28 1.0000000e+00 3.7039918e-28 2.1382623e-32 2.5248414e-37], sum to 1.0000
[2019-03-26 16:29:26,304] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9538
[2019-03-26 16:29:26,310] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3852189403496105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580207.7230043663, 580207.7230043663, 172893.702197987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2719200.0000, 
sim time next is 2719800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3849806790613923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579853.4706101741, 579853.4706101741, 172862.0925145509], 
processed observation next is [0.0, 0.4782608695652174, 0.2417061611374408, 1.0, 1.0, 1.0, 0.2590128663390268, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16107040850282614, 0.16107040850282614, 0.2580031231560461], 
reward next is 0.7420, 
noisyNet noise sample is [array([-0.84574926], dtype=float32), -1.6021672]. 
=============================================
[2019-03-26 16:29:26,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.900788e-24 1.000000e+00 8.996680e-26 7.687548e-27 6.067192e-35], sum to 1.0000
[2019-03-26 16:29:26,458] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1583
[2019-03-26 16:29:26,462] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2834400.0000, 
sim time next is 2835000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4093354669916394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 603119.3580655652, 603119.3580655647, 174603.8807527346], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.2883559843272764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16753315501821256, 0.1675331550182124, 0.26060280709363376], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.5128532], dtype=float32), 2.260461]. 
=============================================
[2019-03-26 16:29:26,477] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.85094 ]
 [73.8073  ]
 [73.751434]
 [73.67946 ]
 [73.67738 ]], R is [[73.94343567]
 [73.94343567]
 [73.94338226]
 [73.94242859]
 [73.94134521]].
[2019-03-26 16:29:27,734] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1134969: loss 0.0259
[2019-03-26 16:29:27,737] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1134969: learning rate 0.0000
[2019-03-26 16:29:31,332] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1136581: loss 0.0140
[2019-03-26 16:29:31,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1136582: learning rate 0.0000
[2019-03-26 16:29:31,525] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136668: loss 0.0131
[2019-03-26 16:29:31,531] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136669: learning rate 0.0000
[2019-03-26 16:29:31,798] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1136788: loss 0.0070
[2019-03-26 16:29:31,799] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1136788: learning rate 0.0000
[2019-03-26 16:29:33,650] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137606: loss 0.0213
[2019-03-26 16:29:33,654] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137607: learning rate 0.0000
[2019-03-26 16:29:33,914] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1137729: loss 9.6132
[2019-03-26 16:29:33,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1137729: learning rate 0.0000
[2019-03-26 16:29:34,305] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1137905: loss 0.0424
[2019-03-26 16:29:34,308] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1137905: learning rate 0.0000
[2019-03-26 16:29:34,338] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137918: loss 0.0313
[2019-03-26 16:29:34,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137919: learning rate 0.0000
[2019-03-26 16:29:34,420] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1137954: loss 0.0294
[2019-03-26 16:29:34,426] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1137957: learning rate 0.0000
[2019-03-26 16:29:34,473] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1137974: loss 0.0295
[2019-03-26 16:29:34,474] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1137974: learning rate 0.0000
[2019-03-26 16:29:34,864] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1138151: loss 0.0188
[2019-03-26 16:29:34,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1138152: learning rate 0.0000
[2019-03-26 16:29:34,976] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1138197: loss 0.0146
[2019-03-26 16:29:34,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1138197: learning rate 0.0000
[2019-03-26 16:29:35,082] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138246: loss 0.0142
[2019-03-26 16:29:35,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138247: learning rate 0.0000
[2019-03-26 16:29:35,636] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1138491: loss 0.0159
[2019-03-26 16:29:35,640] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1138492: learning rate 0.0000
[2019-03-26 16:29:38,875] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1621233e-24 1.0000000e+00 1.5902453e-26 1.0281612e-28 2.2788321e-35], sum to 1.0000
[2019-03-26 16:29:38,884] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2651
[2019-03-26 16:29:38,888] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3170575583172149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501368.4287978841, 501368.4287978835, 167127.8055310481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2931600.0000, 
sim time next is 2932200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3177529425547354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 502467.2599172965, 502467.2599172965, 167210.3012784686], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17801559343944023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1395742388659157, 0.1395742388659157, 0.2495676138484606], 
reward next is 0.7504, 
noisyNet noise sample is [array([-0.88475853], dtype=float32), -0.66931885]. 
=============================================
[2019-03-26 16:29:40,564] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1140660: loss 1.2144
[2019-03-26 16:29:40,569] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1140661: learning rate 0.0000
[2019-03-26 16:29:42,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.84412874e-24 1.00000000e+00 3.68440937e-25 1.60220881e-28
 1.44841585e-33], sum to 1.0000
[2019-03-26 16:29:42,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5222
[2019-03-26 16:29:42,146] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.5432639263750915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837069.2685101344, 837069.2685101344, 199991.506046124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2970000.0000, 
sim time next is 2970600.0000, 
raw observation next is [22.0, 93.00000000000001, 1.0, 2.0, 0.540854919852412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835031.0591947987, 835031.0591947987, 199714.5929616853], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 0.9300000000000002, 1.0, 1.0, 0.4468131564486891, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2319530719985552, 0.2319530719985552, 0.2980814820323661], 
reward next is 0.7019, 
noisyNet noise sample is [array([-0.3819403], dtype=float32), -0.62630457]. 
=============================================
[2019-03-26 16:29:42,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5738994e-22 1.0000000e+00 4.8918069e-24 1.3994314e-25 6.8265321e-33], sum to 1.0000
[2019-03-26 16:29:42,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8819
[2019-03-26 16:29:42,798] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 90.0, 1.0, 2.0, 0.6884180546139048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1083074.385866981, 1083074.385866981, 232968.1364439665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2981400.0000, 
sim time next is 2982000.0000, 
raw observation next is [21.33333333333334, 92.0, 1.0, 2.0, 0.527824670655018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 832003.0330721037, 832003.0330721043, 198957.6325639436], 
processed observation next is [1.0, 0.5217391304347826, 0.2101105845181678, 0.92, 1.0, 1.0, 0.43111406103014216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23111195363113993, 0.2311119536311401, 0.29695169039394564], 
reward next is 0.7030, 
noisyNet noise sample is [array([-0.95806223], dtype=float32), -0.8050134]. 
=============================================
[2019-03-26 16:29:42,823] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[67.064514]
 [68.102264]
 [68.336945]
 [68.43823 ]
 [68.54089 ]], R is [[67.66199493]
 [67.63765717]
 [67.64928436]
 [67.66898346]
 [67.69133759]].
[2019-03-26 16:29:43,214] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4905117e-08 9.4804722e-01 3.6856878e-13 5.1952738e-02 2.5456636e-17], sum to 1.0000
[2019-03-26 16:29:43,227] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3937
[2019-03-26 16:29:43,233] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2267006.41813015 W.
[2019-03-26 16:29:43,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.83333333333334, 66.0, 1.0, 2.0, 0.5403975824778723, 1.0, 1.0, 0.5403975824778723, 1.0, 2.0, 0.9328755122566447, 6.911199999999999, 6.9112, 170.5573041426782, 2267006.41813015, 2267006.418130151, 443099.5225410712], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3495000.0000, 
sim time next is 3495600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 1.025596689155635, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.992825068473157, 6.9112, 168.9124710142131, 2330829.766882854, 2272922.300430332, 471775.6705768716], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 1.0308393845248613, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008162506847315676, 0.0, 0.8294375611436117, 0.647452713023015, 0.6313673056750921, 0.7041427919057786], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5948217], dtype=float32), 0.1023631]. 
=============================================
[2019-03-26 16:29:43,911] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1142096: loss 9.9301
[2019-03-26 16:29:43,914] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1142098: learning rate 0.0000
[2019-03-26 16:29:44,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2811941e-20 1.0000000e+00 5.5784021e-23 1.2450096e-22 3.8302470e-31], sum to 1.0000
[2019-03-26 16:29:44,882] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7512
[2019-03-26 16:29:44,886] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.792185365789055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1146047.146729372, 1146047.146729373, 247390.1156672415], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3079200.0000, 
sim time next is 3079800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.8129721434911567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1174031.285721376, 1174031.285721376, 252419.0025796037], 
processed observation next is [1.0, 0.6521739130434783, 0.31279620853080575, 0.97, 1.0, 1.0, 0.7746652331218755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3261198015892711, 0.3261198015892711, 0.37674477996955774], 
reward next is 0.6233, 
noisyNet noise sample is [array([2.0266418], dtype=float32), -1.273547]. 
=============================================
[2019-03-26 16:29:45,935] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1143018: loss 10.0991
[2019-03-26 16:29:45,938] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1143019: learning rate 0.0000
[2019-03-26 16:29:46,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4541065e-26 1.0000000e+00 3.5239018e-27 4.5806896e-32 6.2566548e-36], sum to 1.0000
[2019-03-26 16:29:46,111] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6416
[2019-03-26 16:29:46,119] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3379539573354989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524904.8674610177, 524904.8674610184, 168721.9697361065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3049200.0000, 
sim time next is 3049800.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 1.0, 2.0, 0.3446697329484064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534811.0765066483, 534811.0765066483, 169503.1329633374], 
processed observation next is [1.0, 0.30434782608695654, 0.2022116903633494, 0.9900000000000001, 1.0, 1.0, 0.2104454613836222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14855863236295788, 0.14855863236295788, 0.2529897506915484], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.25052476], dtype=float32), -0.118561715]. 
=============================================
[2019-03-26 16:29:47,722] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6684635e-20 1.0000000e+00 1.5691755e-22 1.5164883e-22 4.4580900e-30], sum to 1.0000
[2019-03-26 16:29:47,736] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2514
[2019-03-26 16:29:47,743] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7835795559862044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1168877.876111318, 1168877.876111319, 249875.5060570021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3066600.0000, 
sim time next is 3067200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7623258149977394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1137172.003097404, 1137172.003097404, 244461.0870257267], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 1.0, 1.0, 0.7136455602382402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3158811119715011, 0.3158811119715011, 0.3648672940682488], 
reward next is 0.6351, 
noisyNet noise sample is [array([0.21211398], dtype=float32), -0.08534141]. 
=============================================
[2019-03-26 16:29:49,254] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144535: loss 10.4829
[2019-03-26 16:29:49,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144535: learning rate 0.0000
[2019-03-26 16:29:49,315] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1144562: loss 10.5132
[2019-03-26 16:29:49,319] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1144562: learning rate 0.0000
[2019-03-26 16:29:49,633] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1144707: loss 10.3607
[2019-03-26 16:29:49,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1144707: learning rate 0.0000
[2019-03-26 16:29:51,447] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145540: loss 10.6334
[2019-03-26 16:29:51,448] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145540: learning rate 0.0000
[2019-03-26 16:29:52,131] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1145853: loss 10.8738
[2019-03-26 16:29:52,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1145853: learning rate 0.0000
[2019-03-26 16:29:52,214] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1145888: loss 10.7711
[2019-03-26 16:29:52,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1145888: learning rate 0.0000
[2019-03-26 16:29:52,261] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1145910: loss 10.9440
[2019-03-26 16:29:52,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1145912: learning rate 0.0000
[2019-03-26 16:29:52,278] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1145922: loss 0.9085
[2019-03-26 16:29:52,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1145922: learning rate 0.0000
[2019-03-26 16:29:52,320] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145938: loss 10.9433
[2019-03-26 16:29:52,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145940: learning rate 0.0000
[2019-03-26 16:29:52,702] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146109: loss 11.0801
[2019-03-26 16:29:52,705] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146109: learning rate 0.0000
[2019-03-26 16:29:52,753] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1146130: loss 11.0798
[2019-03-26 16:29:52,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1146130: learning rate 0.0000
[2019-03-26 16:29:52,796] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1146151: loss 11.0858
[2019-03-26 16:29:52,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1146152: learning rate 0.0000
[2019-03-26 16:29:53,422] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1146435: loss 11.2913
[2019-03-26 16:29:53,432] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1146436: learning rate 0.0000
[2019-03-26 16:29:54,246] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2995771e-23 1.0000000e+00 1.1029405e-24 3.3078762e-26 8.5987504e-34], sum to 1.0000
[2019-03-26 16:29:54,252] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7214
[2019-03-26 16:29:54,257] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 92.66666666666666, 1.0, 2.0, 0.4810841055832136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672231.9291245964, 672231.9291245958, 180685.2682598107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3202800.0000, 
sim time next is 3203400.0000, 
raw observation next is [25.0, 92.33333333333333, 1.0, 2.0, 0.4791888750308868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669582.8372130482, 669582.8372130488, 180399.4825859996], 
processed observation next is [0.0, 0.043478260869565216, 0.38388625592417064, 0.9233333333333333, 1.0, 1.0, 0.37251671690468285, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18599523255918007, 0.18599523255918024, 0.2692529590835815], 
reward next is 0.7307, 
noisyNet noise sample is [array([-2.7030172], dtype=float32), 0.39372557]. 
=============================================
[2019-03-26 16:29:57,088] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0477834e-22 1.0000000e+00 4.5548651e-25 7.6658236e-26 6.1531316e-34], sum to 1.0000
[2019-03-26 16:29:57,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4400
[2019-03-26 16:29:57,099] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4579791345538589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653507.9042580575, 653507.9042580575, 179018.0397899096], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3718800.0000, 
sim time next is 3719400.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.4547525033161577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650008.1057268956, 650008.1057268963, 178683.9311878362], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.74, 1.0, 1.0, 0.34307530520019, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18055780714635988, 0.18055780714636008, 0.2666924346087107], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.69490266], dtype=float32), -0.38117096]. 
=============================================
[2019-03-26 16:29:59,310] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1149059: loss -188.5698
[2019-03-26 16:29:59,315] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1149061: learning rate 0.0000
[2019-03-26 16:30:01,359] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 16:30:01,363] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:30:01,365] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:30:01,366] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:01,367] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:01,369] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:30:01,371] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:30:01,367] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:30:01,375] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:01,377] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:01,379] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:30:01,398] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 16:30:01,398] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 16:30:01,444] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 16:30:01,467] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 16:30:01,490] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 16:30:24,296] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:30:24,297] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.43333333333334, 84.0, 1.0, 2.0, 0.3581823112842414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 549437.9069466967, 549437.9069466974, 170532.5589414631]
[2019-03-26 16:30:24,298] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:30:24,301] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2949833e-25 1.0000000e+00 1.8535341e-26 2.7935196e-29 3.5580208e-35], sampled 0.1482833522500434
[2019-03-26 16:30:56,379] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:30:56,382] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.4, 82.66666666666667, 1.0, 2.0, 0.5275665519278024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564801312, 737205.6558676376, 737205.6558676382, 188029.8027293411]
[2019-03-26 16:30:56,384] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:30:56,390] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4044491e-23 1.0000000e+00 8.8158010e-27 4.3632648e-23 2.8622580e-34], sampled 0.7431993303254666
[2019-03-26 16:31:03,793] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:03,794] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.5, 79.0, 1.0, 2.0, 0.9834529039382823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1374659.88324726, 1374659.883247259, 293927.35968535]
[2019-03-26 16:31:03,797] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:31:03,800] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8104482e-23 1.0000000e+00 3.1291146e-24 1.9044002e-26 2.5961757e-32], sampled 0.34220668806930044
[2019-03-26 16:31:08,762] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:08,763] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [38.4, 43.0, 1.0, 2.0, 0.9938166435607438, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005993029534438, 6.9112, 168.9123159449773, 2286347.329403932, 2219098.146756701, 461407.7904445207]
[2019-03-26 16:31:08,764] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:31:08,767] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1419580e-14 1.0000000e+00 1.6887959e-18 1.5690026e-10 1.0784523e-23], sampled 0.06488713814075453
[2019-03-26 16:31:08,768] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2286347.329403932 W.
[2019-03-26 16:31:14,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:14,915] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.9, 55.0, 1.0, 2.0, 0.9811654655272595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1371460.461144785, 1371460.461144786, 293244.0947435876]
[2019-03-26 16:31:14,918] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:31:14,921] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0321161e-25 1.0000000e+00 4.8940954e-27 1.0660803e-28 1.2848600e-35], sampled 0.6801741558256318
[2019-03-26 16:31:24,097] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:24,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.46666666666667, 83.33333333333334, 1.0, 2.0, 0.605497473499935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846147.3604180234, 846147.3604180234, 201773.9047813638]
[2019-03-26 16:31:24,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:31:24,104] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2420286e-25 1.0000000e+00 1.4559439e-26 2.0691523e-29 4.0334273e-35], sampled 0.3986594635919001
[2019-03-26 16:31:26,355] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:26,356] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.23333333333333, 62.66666666666666, 1.0, 2.0, 0.5545847629796474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774973.8651334906, 774973.8651334906, 192590.779138714]
[2019-03-26 16:31:26,356] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:31:26,358] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.8772921e-26 1.0000000e+00 9.7942651e-27 2.2718432e-29 2.2418253e-35], sampled 0.3948303525810921
[2019-03-26 16:31:27,030] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:27,030] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.27638465666666, 88.99826432333334, 1.0, 2.0, 0.5007342311534361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 704045.2873063687, 704045.2873063694, 184269.3524309361]
[2019-03-26 16:31:27,031] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:31:27,034] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9206192e-25 1.0000000e+00 1.3428346e-26 5.1341501e-29 1.5369901e-35], sampled 0.015484485166710416
[2019-03-26 16:31:35,101] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:35,103] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.17200962, 84.67553229, 1.0, 2.0, 0.5701462529423377, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9681104851746047, 6.9112, 6.9112, 168.9129565004731, 1594053.201062701, 1594053.201062701, 344127.2397286296]
[2019-03-26 16:31:35,104] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:31:35,106] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.3318913e-15 1.0000000e+00 1.1939139e-18 3.5312576e-11 2.5899854e-23], sampled 0.2510573767871319
[2019-03-26 16:31:52,303] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00503661], dtype=float32), 0.08650572]
[2019-03-26 16:31:52,305] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.31666666666667, 80.5, 1.0, 2.0, 0.4102745150565296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601467.1663904247, 601467.1663904247, 174357.7980464165]
[2019-03-26 16:31:52,305] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:31:52,309] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2501045e-25 1.0000000e+00 1.7178195e-26 2.4574042e-29 3.3391889e-35], sampled 0.6989917314555276
[2019-03-26 16:31:57,820] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.5730 3007694416.7045 1764.0000
[2019-03-26 16:31:58,008] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3575 2779379874.1781 932.0000
[2019-03-26 16:31:58,118] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 16:31:58,361] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.7532 3163628777.5705 1768.0000
[2019-03-26 16:31:58,502] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.1320 2927522702.9456 1338.0000
[2019-03-26 16:31:59,519] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1150000, evaluation results [1150000.0, 7884.753227199008, 3163628777.570462, 1768.0, 8254.132014516563, 2927522702.9455853, 1338.0, 8661.357502156397, 2779379874.178105, 932.0, 7999.573036247873, 3007694416.704453, 1764.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 16:32:00,018] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1150227: loss 0.9386
[2019-03-26 16:32:00,023] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1150227: learning rate 0.0000
[2019-03-26 16:32:01,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9852050e-25 1.0000000e+00 1.5763960e-26 3.2472464e-29 1.7400575e-35], sum to 1.0000
[2019-03-26 16:32:01,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1250
[2019-03-26 16:32:01,929] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.5, 77.0, 1.0, 2.0, 0.5900030291869829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 824486.3753322603, 824486.3753322603, 198898.6271320656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3342600.0000, 
sim time next is 3343200.0000, 
raw observation next is [30.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5886233678286997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822557.652259809, 822557.652259809, 198645.9138852008], 
processed observation next is [0.0, 0.6956521739130435, 0.6366508688783573, 0.7766666666666667, 1.0, 1.0, 0.504365503408072, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22848823673883584, 0.22848823673883584, 0.2964864386346281], 
reward next is 0.7035, 
noisyNet noise sample is [array([1.5262758], dtype=float32), -0.6043662]. 
=============================================
[2019-03-26 16:32:02,011] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1151110: loss 0.9467
[2019-03-26 16:32:02,014] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1151111: learning rate 0.0000
[2019-03-26 16:32:05,251] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1152550: loss 0.6744
[2019-03-26 16:32:05,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1152550: learning rate 0.0000
[2019-03-26 16:32:05,307] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152580: loss 0.6825
[2019-03-26 16:32:05,311] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152580: learning rate 0.0000
[2019-03-26 16:32:05,657] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1152732: loss 0.6390
[2019-03-26 16:32:05,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1152732: learning rate 0.0000
[2019-03-26 16:32:07,436] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153526: loss 0.7121
[2019-03-26 16:32:07,439] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153526: learning rate 0.0000
[2019-03-26 16:32:07,933] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1153749: loss 0.7222
[2019-03-26 16:32:07,935] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1153749: learning rate 0.0000
[2019-03-26 16:32:08,132] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153835: loss 0.7431
[2019-03-26 16:32:08,135] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153836: learning rate 0.0000
[2019-03-26 16:32:08,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1153863: loss 0.7769
[2019-03-26 16:32:08,212] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1153866: learning rate 0.0000
[2019-03-26 16:32:08,319] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1153917: loss 0.7963
[2019-03-26 16:32:08,321] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1153917: learning rate 0.0000
[2019-03-26 16:32:08,521] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154006: loss 0.7975
[2019-03-26 16:32:08,523] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154007: learning rate 0.0000
[2019-03-26 16:32:08,612] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1154047: loss 0.7655
[2019-03-26 16:32:08,614] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1154047: learning rate 0.0000
[2019-03-26 16:32:08,676] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1154074: loss 0.7925
[2019-03-26 16:32:08,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1154075: learning rate 0.0000
[2019-03-26 16:32:08,913] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1154178: loss -0.3163
[2019-03-26 16:32:08,919] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1154178: learning rate 0.0000
[2019-03-26 16:32:09,255] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1154329: loss 0.7916
[2019-03-26 16:32:09,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1154329: learning rate 0.0000
[2019-03-26 16:32:15,145] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1156938: loss 0.0054
[2019-03-26 16:32:15,149] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1156939: learning rate 0.0000
[2019-03-26 16:32:18,234] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1158301: loss -102.1568
[2019-03-26 16:32:18,238] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1158302: learning rate 0.0000
[2019-03-26 16:32:20,041] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1159113: loss -9.8098
[2019-03-26 16:32:20,045] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1159115: learning rate 0.0000
[2019-03-26 16:32:23,245] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160536: loss 5.9879
[2019-03-26 16:32:23,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160536: learning rate 0.0000
[2019-03-26 16:32:23,376] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1160597: loss 12.0735
[2019-03-26 16:32:23,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1160598: learning rate 0.0000
[2019-03-26 16:32:23,761] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1160772: loss -4.4498
[2019-03-26 16:32:23,763] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1160772: learning rate 0.0000
[2019-03-26 16:32:25,548] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161566: loss 6.5662
[2019-03-26 16:32:25,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161566: learning rate 0.0000
[2019-03-26 16:32:26,221] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1161864: loss -167.9460
[2019-03-26 16:32:26,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1161864: learning rate 0.0000
[2019-03-26 16:32:26,246] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161876: loss -24.1963
[2019-03-26 16:32:26,250] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161876: learning rate 0.0000
[2019-03-26 16:32:26,260] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1161880: loss -66.6659
[2019-03-26 16:32:26,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1161880: learning rate 0.0000
[2019-03-26 16:32:26,397] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1161940: loss -35.1227
[2019-03-26 16:32:26,400] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1161941: learning rate 0.0000
[2019-03-26 16:32:26,505] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1161985: loss 0.0073
[2019-03-26 16:32:26,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1161985: learning rate 0.0000
[2019-03-26 16:32:26,634] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.8698464e-26 1.0000000e+00 1.7315757e-27 3.4523269e-29 5.6217949e-36], sum to 1.0000
[2019-03-26 16:32:26,645] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9750
[2019-03-26 16:32:26,652] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 63.33333333333333, 1.0, 2.0, 0.5572060011874463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778638.1123257191, 778638.1123257191, 193045.2620676647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3868800.0000, 
sim time next is 3869400.0000, 
raw observation next is [32.16666666666666, 65.16666666666667, 1.0, 2.0, 0.5640217650058872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 788165.9753220618, 788165.9753220612, 194235.5952034292], 
processed observation next is [0.0, 0.782608695652174, 0.7235387045813582, 0.6516666666666667, 1.0, 1.0, 0.4747250180793821, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21893499314501716, 0.218934993145017, 0.28990387343795404], 
reward next is 0.7101, 
noisyNet noise sample is [array([-0.78457814], dtype=float32), -0.34394056]. 
=============================================
[2019-03-26 16:32:26,657] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1162054: loss -68.1675
[2019-03-26 16:32:26,661] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1162055: learning rate 0.0000
[2019-03-26 16:32:26,697] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1162067: loss -37.2805
[2019-03-26 16:32:26,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1162067: learning rate 0.0000
[2019-03-26 16:32:26,875] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162146: loss -169.5119
[2019-03-26 16:32:26,876] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162146: learning rate 0.0000
[2019-03-26 16:32:27,414] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1162386: loss -128.0913
[2019-03-26 16:32:27,422] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1162386: learning rate 0.0000
[2019-03-26 16:32:33,378] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8840688e-24 1.0000000e+00 2.4628053e-25 1.2107274e-26 2.8358605e-33], sum to 1.0000
[2019-03-26 16:32:33,387] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2935
[2019-03-26 16:32:33,393] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.8130366652437334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1136326.4258456, 1136326.4258456, 247138.7285865187], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4165200.0000, 
sim time next is 4165800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.047930190324083, 6.9112, 168.9123488711764, 1550822.109832841, 1453821.355874017, 311353.1849116097], 
processed observation next is [1.0, 0.21739130434782608, 0.5260663507109005, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.013673019032408274, 0.0, 0.8294369613653841, 0.43078391939801136, 0.4038392655205603, 0.4647062461367309], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0227382], dtype=float32), 0.44046476]. 
=============================================
[2019-03-26 16:32:33,701] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1165122: loss -84.1633
[2019-03-26 16:32:33,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1165122: learning rate 0.0000
[2019-03-26 16:32:36,219] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1166270: loss 0.0307
[2019-03-26 16:32:36,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1166271: learning rate 0.0000
[2019-03-26 16:32:37,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3002029e-28 1.0000000e+00 4.4243612e-29 4.7033424e-33 2.1662191e-38], sum to 1.0000
[2019-03-26 16:32:37,875] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-26 16:32:37,885] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5975809756937643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835080.1680343803, 835080.1680343803, 200296.7262030568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3939600.0000, 
sim time next is 3940200.0000, 
raw observation next is [35.0, 56.0, 1.0, 2.0, 0.5945621299909731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830859.8793981312, 830859.8793981312, 199738.0260890798], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.56, 1.0, 1.0, 0.5115206385433411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23079441094392533, 0.23079441094392533, 0.2981164568493728], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.32092717], dtype=float32), -0.36028317]. 
=============================================
[2019-03-26 16:32:38,123] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1167138: loss 0.0042
[2019-03-26 16:32:38,127] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1167139: learning rate 0.0000
[2019-03-26 16:32:38,735] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.13957121e-25 1.00000000e+00 7.58880339e-27 4.57411371e-29
 1.14230744e-35], sum to 1.0000
[2019-03-26 16:32:38,743] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3005
[2019-03-26 16:32:38,751] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 71.66666666666667, 1.0, 2.0, 0.6070122641293909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 848265.0371713643, 848265.037171365, 202059.8077364328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3966600.0000, 
sim time next is 3967200.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.6084379794734014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850258.1905649487, 850258.1905649487, 202328.6956724103], 
processed observation next is [0.0, 0.9565217391304348, 0.7156398104265403, 0.71, 1.0, 1.0, 0.5282385294860258, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23618283071248575, 0.23618283071248575, 0.3019831278692691], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.82736963], dtype=float32), 0.41981286]. 
=============================================
[2019-03-26 16:32:39,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.8149395e-13 1.0000000e+00 7.4522594e-17 4.2420536e-11 3.2975014e-22], sum to 1.0000
[2019-03-26 16:32:39,833] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2007
[2019-03-26 16:32:39,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2107857.638927806 W.
[2019-03-26 16:32:39,846] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.7537439525456872, 1.0, 2.0, 0.7537439525456872, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2107857.638927806, 2107857.638927807, 397987.9733255368], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3985200.0000, 
sim time next is 3985800.0000, 
raw observation next is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.4627914408725608, 1.0, 2.0, 0.4627914408725608, 1.0, 1.0, 0.8037156853274392, 6.9112, 6.9112, 170.5573041426782, 1941155.176729104, 1941155.176729104, 390369.9631962605], 
processed observation next is [1.0, 0.13043478260869565, 0.6129541864139019, 0.7983333333333335, 1.0, 1.0, 0.35276077213561546, 1.0, 1.0, 0.35276077213561546, 1.0, 0.5, 0.7606288845456576, 0.0, 0.0, 0.8375144448122397, 0.53920977131364, 0.53920977131364, 0.5826417361138216], 
reward next is 0.4174, 
noisyNet noise sample is [array([-0.36930782], dtype=float32), 0.8670852]. 
=============================================
[2019-03-26 16:32:41,195] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168535: loss 0.0502
[2019-03-26 16:32:41,197] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168535: learning rate 0.0000
[2019-03-26 16:32:41,378] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1168617: loss 0.0471
[2019-03-26 16:32:41,382] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1168617: learning rate 0.0000
[2019-03-26 16:32:41,566] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1168700: loss 0.0440
[2019-03-26 16:32:41,567] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1168701: learning rate 0.0000
[2019-03-26 16:32:43,428] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169548: loss 0.0372
[2019-03-26 16:32:43,431] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169548: learning rate 0.0000
[2019-03-26 16:32:43,926] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169782: loss 0.0367
[2019-03-26 16:32:43,929] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169783: learning rate 0.0000
[2019-03-26 16:32:43,969] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1169800: loss 0.0346
[2019-03-26 16:32:43,970] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1169800: learning rate 0.0000
[2019-03-26 16:32:44,062] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1169845: loss 0.0352
[2019-03-26 16:32:44,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1169845: learning rate 0.0000
[2019-03-26 16:32:44,155] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1169887: loss 0.0145
[2019-03-26 16:32:44,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1169887: learning rate 0.0000
[2019-03-26 16:32:44,502] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1170040: loss 0.0193
[2019-03-26 16:32:44,506] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1170040: learning rate 0.0000
[2019-03-26 16:32:44,519] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1170050: loss 0.0122
[2019-03-26 16:32:44,521] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1170051: learning rate 0.0000
[2019-03-26 16:32:44,702] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1170136: loss 44.3722
[2019-03-26 16:32:44,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1170137: learning rate 0.0000
[2019-03-26 16:32:44,743] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170154: loss 0.0141
[2019-03-26 16:32:44,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170155: learning rate 0.0000
[2019-03-26 16:32:44,797] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9059253e-24 1.0000000e+00 7.3952713e-27 2.5861681e-28 7.2598399e-36], sum to 1.0000
[2019-03-26 16:32:44,806] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0229
[2019-03-26 16:32:44,814] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 87.33333333333333, 1.0, 2.0, 0.5401544423213469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754801.8454693147, 754801.8454693141, 190126.5668811943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4056000.0000, 
sim time next is 4056600.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.5411499810021114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756193.4880246483, 756193.4880246476, 190294.3499238946], 
processed observation next is [1.0, 0.9565217391304348, 0.4865718799368086, 0.8816666666666667, 1.0, 1.0, 0.4471686518097728, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2100537466735134, 0.2100537466735132, 0.2840214177968576], 
reward next is 0.7160, 
noisyNet noise sample is [array([-1.2901884], dtype=float32), -2.1339011]. 
=============================================
[2019-03-26 16:32:44,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3841117e-29 1.0000000e+00 7.3809986e-30 1.3997292e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 16:32:44,893] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-26 16:32:44,897] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5455810744206206, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762387.6423113113, 762387.6423113113, 191045.8341374866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4048200.0000, 
sim time next is 4048800.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5445282443353512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760915.9047814367, 760915.9047814367, 190866.8922560311], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.84, 1.0, 1.0, 0.45123884859680863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21136552910595463, 0.21136552910595463, 0.2848759585910912], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.6275013], dtype=float32), -0.7707573]. 
=============================================
[2019-03-26 16:32:45,290] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1170399: loss 0.0124
[2019-03-26 16:32:45,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1170399: learning rate 0.0000
[2019-03-26 16:32:50,950] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1172951: loss 0.8590
[2019-03-26 16:32:50,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1172951: learning rate 0.0000
[2019-03-26 16:32:53,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2357775e-27 1.0000000e+00 1.8038185e-28 1.6936871e-32 1.7954143e-37], sum to 1.0000
[2019-03-26 16:32:53,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7011
[2019-03-26 16:32:53,599] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.33333333333334, 73.66666666666667, 1.0, 2.0, 0.635418770645873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 887978.1050642777, 887978.1050642777, 207530.7629131568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4220400.0000, 
sim time next is 4221000.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.6333670517561034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 885109.6965596054, 885109.696559606, 207127.5277510237], 
processed observation next is [1.0, 0.8695652173913043, 0.7156398104265403, 0.75, 1.0, 1.0, 0.5582735563326547, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2458638045998904, 0.24586380459989055, 0.3091455638074981], 
reward next is 0.6909, 
noisyNet noise sample is [array([-0.6456531], dtype=float32), 0.38955826]. 
=============================================
[2019-03-26 16:32:53,610] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.90105 ]
 [63.81078 ]
 [63.90279 ]
 [63.90471 ]
 [63.900013]], R is [[64.03796387]
 [64.08783722]
 [64.13697815]
 [64.18684387]
 [64.23838806]].
[2019-03-26 16:32:54,028] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1174359: loss -47.0062
[2019-03-26 16:32:54,033] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1174359: learning rate 0.0000
[2019-03-26 16:32:55,416] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 16:32:55,419] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:32:55,420] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:32:55,420] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:32:55,421] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:32:55,421] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:32:55,422] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:32:55,423] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:32:55,424] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:32:55,424] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:32:55,425] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:32:55,448] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 16:32:55,471] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 16:32:55,472] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 16:32:55,472] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 16:32:55,532] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 16:33:01,643] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:01,644] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.13985865, 88.41528083333333, 1.0, 2.0, 0.2425014190700462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400449.6168414525, 400449.6168414518, 160124.3490139479]
[2019-03-26 16:33:01,645] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:33:01,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8183049e-29 1.0000000e+00 9.3028781e-30 2.6475774e-36 2.2241638e-38], sampled 0.4542049207437371
[2019-03-26 16:33:14,998] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:14,999] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.8, 72.0, 1.0, 2.0, 0.2599119475439303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 426699.5252664073, 426699.5252664073, 161904.0394487744]
[2019-03-26 16:33:14,999] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:33:15,002] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0722798e-28 1.0000000e+00 5.7951617e-29 2.3356691e-35 1.8371222e-37], sampled 0.1413915704852885
[2019-03-26 16:33:20,416] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:20,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.4, 94.0, 1.0, 2.0, 0.9075780463729445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1281737.819993569, 1281737.819993569, 273997.0819213995]
[2019-03-26 16:33:20,418] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:33:20,422] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3295490e-24 1.0000000e+00 4.1924422e-25 1.4164493e-28 4.8921206e-33], sampled 0.05461425583833068
[2019-03-26 16:33:46,223] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:46,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.03131168, 79.94634813, 1.0, 2.0, 0.295677718511609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480158.0754420788, 480158.0754420793, 165625.2814155047]
[2019-03-26 16:33:46,226] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:33:46,229] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9110142e-27 1.0000000e+00 1.4721214e-28 1.7112478e-32 2.9032380e-37], sampled 0.8836064639060703
[2019-03-26 16:33:53,207] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:53,208] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.88333333333333, 72.0, 1.0, 2.0, 0.5805454079821489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811264.9894104144, 811264.9894104144, 197177.2934192971]
[2019-03-26 16:33:53,210] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:33:53,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.3466951e-26 1.0000000e+00 1.2656258e-27 2.6615396e-30 3.7382432e-36], sampled 0.784010510159227
[2019-03-26 16:33:55,207] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:33:55,210] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666666, 85.66666666666666, 1.0, 2.0, 0.5398106426584461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754321.2555846643, 754321.255584665, 190068.885851162]
[2019-03-26 16:33:55,213] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:33:55,216] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.0358211e-26 1.0000000e+00 4.6716713e-27 3.3267246e-30 1.4469123e-35], sampled 0.16166928301678607
[2019-03-26 16:34:49,703] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00715212], dtype=float32), 0.085254036]
[2019-03-26 16:34:49,704] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.2, 59.0, 1.0, 2.0, 0.8749652334617783, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.986907581105665, 6.9112, 168.9124442314169, 2119995.338792744, 2066285.937992838, 427909.5585122285]
[2019-03-26 16:34:49,706] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:34:49,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.9041515e-17 1.0000000e+00 3.5352629e-21 3.1131984e-15 2.2010423e-26], sampled 0.4680892314594314
[2019-03-26 16:34:49,712] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2119995.338792744 W.
[2019-03-26 16:34:51,869] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.0250 3007848960.6402 1766.0000
[2019-03-26 16:34:52,085] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 16:34:52,268] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2118 2927459259.5787 1338.0000
[2019-03-26 16:34:52,285] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:34:52,325] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 16:34:53,337] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1175000, evaluation results [1175000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8254.211789258557, 2927459259.5787225, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.024995752096, 3007848960.6401815, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 16:34:53,739] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1175181: loss 57.6248
[2019-03-26 16:34:53,743] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1175182: learning rate 0.0000
[2019-03-26 16:34:55,272] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4664086e-09 9.9969733e-01 2.3496575e-15 3.0270519e-04 8.5016040e-20], sum to 1.0000
[2019-03-26 16:34:55,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4257
[2019-03-26 16:34:55,288] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3167285.224107368 W.
[2019-03-26 16:34:55,297] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.0, 59.00000000000001, 1.0, 2.0, 0.8682795633759154, 1.0, 2.0, 0.7547298212022204, 1.0, 2.0, 1.03, 7.005111004596334, 6.9112, 170.5573041426782, 3167285.224107368, 3100012.951459586, 579750.8031110248], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4378800.0000, 
sim time next is 4379400.0000, 
raw observation next is [34.5, 60.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.719386241126118, 6.9112, 170.5573041426782, 3488940.814958252, 2910004.135525216, 549106.5032347196], 
processed observation next is [1.0, 0.6956521739130435, 0.8341232227488152, 0.6, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.08081862411261183, 0.0, 0.8375144448122397, 0.9691502263772922, 0.8083344820903378, 0.8195619451264472], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41629502], dtype=float32), 0.7315989]. 
=============================================
[2019-03-26 16:34:56,752] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5919146e-11 9.9995923e-01 3.9636265e-17 4.0800081e-05 4.3941252e-21], sum to 1.0000
[2019-03-26 16:34:56,761] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5172
[2019-03-26 16:34:56,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3065016.220778313 W.
[2019-03-26 16:34:56,775] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.33333333333333, 47.0, 1.0, 2.0, 0.8196001019467677, 1.0, 2.0, 0.7303900904876464, 1.0, 2.0, 1.03, 7.005107164408447, 6.9112, 170.5573041426782, 3065016.220778313, 2997746.699013323, 561765.8139730338], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4293600.0000, 
sim time next is 4294200.0000, 
raw observation next is [37.16666666666667, 47.5, 1.0, 2.0, 0.8156749751211476, 1.0, 2.0, 0.7284275270748364, 1.0, 2.0, 1.03, 7.005106854793445, 6.9112, 170.5573041426782, 3056770.421899666, 2989501.121924497, 560354.1803275421], 
processed observation next is [1.0, 0.6956521739130435, 0.9605055292259086, 0.475, 1.0, 1.0, 0.777921656772467, 1.0, 1.0, 0.6728042494877546, 1.0, 1.0, 1.0365853658536586, 0.00939068547934454, 0.0, 0.8375144448122397, 0.8491028949721294, 0.8304169783123603, 0.8363495228769285], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12599799], dtype=float32), -0.17402013]. 
=============================================
[2019-03-26 16:34:56,942] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176593: loss 10.5667
[2019-03-26 16:34:56,945] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176594: learning rate 0.0000
[2019-03-26 16:34:57,031] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1176634: loss 69.9907
[2019-03-26 16:34:57,033] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1176634: learning rate 0.0000
[2019-03-26 16:34:57,086] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1176659: loss -8.6301
[2019-03-26 16:34:57,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1176660: learning rate 0.0000
[2019-03-26 16:34:59,176] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177585: loss 94.1277
[2019-03-26 16:34:59,178] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177585: learning rate 0.0000
[2019-03-26 16:34:59,639] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1177788: loss -87.4291
[2019-03-26 16:34:59,642] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1177789: learning rate 0.0000
[2019-03-26 16:34:59,655] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177797: loss -60.0778
[2019-03-26 16:34:59,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177798: learning rate 0.0000
[2019-03-26 16:34:59,767] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1177843: loss -78.9910
[2019-03-26 16:34:59,768] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1177844: learning rate 0.0000
[2019-03-26 16:34:59,838] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1177875: loss 0.8615
[2019-03-26 16:34:59,839] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1177875: learning rate 0.0000
[2019-03-26 16:34:59,901] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1177902: loss -108.7125
[2019-03-26 16:34:59,904] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1177902: learning rate 0.0000
[2019-03-26 16:35:00,423] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1178136: loss 92.3588
[2019-03-26 16:35:00,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1178136: learning rate 0.0000
[2019-03-26 16:35:00,513] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178170: loss -70.5370
[2019-03-26 16:35:00,514] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1178170: loss -79.9226
[2019-03-26 16:35:00,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178170: learning rate 0.0000
[2019-03-26 16:35:00,516] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1178170: learning rate 0.0000
[2019-03-26 16:35:01,067] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1178415: loss -52.9696
[2019-03-26 16:35:01,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1178416: learning rate 0.0000
[2019-03-26 16:35:06,891] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1181000: loss 26.2793
[2019-03-26 16:35:06,897] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1181000: learning rate 0.0000
[2019-03-26 16:35:09,713] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1182252: loss 0.3226
[2019-03-26 16:35:09,714] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1182253: learning rate 0.0000
[2019-03-26 16:35:10,481] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7613156e-30 1.0000000e+00 3.3667610e-30 1.8146112e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 16:35:10,494] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8966
[2019-03-26 16:35:10,497] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5130121937667768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716860.9702976157, 716860.9702976157, 185659.7436488764], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4519800.0000, 
sim time next is 4520400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5134090715666738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717415.7373815287, 717415.7373815293, 185723.4554471353], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4137458693574383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19928214927264687, 0.19928214927264704, 0.2771991872345303], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.9014562], dtype=float32), -0.935758]. 
=============================================
[2019-03-26 16:35:11,159] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2391102e-30 1.0000000e+00 1.2288861e-30 3.7323847e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 16:35:11,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0888
[2019-03-26 16:35:11,177] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 52.5, 1.0, 2.0, 0.5339334248901505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 746105.6575136452, 746105.657513646, 189084.4687387619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4546200.0000, 
sim time next is 4546800.0000, 
raw observation next is [34.0, 53.0, 1.0, 2.0, 0.5366912403143218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749960.7225235285, 749960.7225235285, 189545.519842363], 
processed observation next is [0.0, 0.6521739130434783, 0.8104265402843602, 0.53, 1.0, 1.0, 0.44179667507749615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20832242292320235, 0.20832242292320235, 0.28290376095875075], 
reward next is 0.7171, 
noisyNet noise sample is [array([0.56156075], dtype=float32), 0.51114243]. 
=============================================
[2019-03-26 16:35:11,569] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1183070: loss 0.6736
[2019-03-26 16:35:11,574] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1183072: learning rate 0.0000
[2019-03-26 16:35:12,747] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4793279e-27 1.0000000e+00 4.8928794e-28 6.6581771e-33 5.1556398e-37], sum to 1.0000
[2019-03-26 16:35:12,758] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9773
[2019-03-26 16:35:12,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 87.33333333333334, 1.0, 2.0, 0.7132153483236026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 996747.4373574523, 996747.4373574523, 223723.5666201256], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4864200.0000, 
sim time next is 4864800.0000, 
raw observation next is [27.33333333333334, 85.66666666666667, 1.0, 2.0, 0.6910342311826162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965734.3298855813, 965734.3298855813, 218921.6578950011], 
processed observation next is [1.0, 0.30434782608695654, 0.4944707740916275, 0.8566666666666667, 1.0, 1.0, 0.6277520857621882, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2682595360793281, 0.2682595360793281, 0.3267487431268673], 
reward next is 0.6733, 
noisyNet noise sample is [array([0.5189203], dtype=float32), -0.32904822]. 
=============================================
[2019-03-26 16:35:15,020] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1184610: loss 0.7051
[2019-03-26 16:35:15,023] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1184610: learning rate 0.0000
[2019-03-26 16:35:15,039] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184618: loss 0.8224
[2019-03-26 16:35:15,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184619: learning rate 0.0000
[2019-03-26 16:35:15,084] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1184634: loss 1.4315
[2019-03-26 16:35:15,087] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1184635: learning rate 0.0000
[2019-03-26 16:35:17,130] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185544: loss 0.4408
[2019-03-26 16:35:17,132] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185544: learning rate 0.0000
[2019-03-26 16:35:17,608] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1185755: loss 0.9767
[2019-03-26 16:35:17,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1185755: learning rate 0.0000
[2019-03-26 16:35:17,684] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1185784: loss 0.3319
[2019-03-26 16:35:17,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1185784: learning rate 0.0000
[2019-03-26 16:35:17,814] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1185845: loss 0.0035
[2019-03-26 16:35:17,815] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185845: loss 0.3633
[2019-03-26 16:35:17,816] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1185845: learning rate 0.0000
[2019-03-26 16:35:17,819] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185845: learning rate 0.0000
[2019-03-26 16:35:18,118] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1185986: loss 27.1451
[2019-03-26 16:35:18,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1185986: learning rate 0.0000
[2019-03-26 16:35:18,494] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186139: loss 0.7622
[2019-03-26 16:35:18,496] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186139: learning rate 0.0000
[2019-03-26 16:35:18,646] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1186207: loss 0.2121
[2019-03-26 16:35:18,647] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1186207: learning rate 0.0000
[2019-03-26 16:35:18,722] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1186238: loss 0.6247
[2019-03-26 16:35:18,726] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1186240: learning rate 0.0000
[2019-03-26 16:35:19,228] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1186457: loss 0.1577
[2019-03-26 16:35:19,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1186461: learning rate 0.0000
[2019-03-26 16:35:24,619] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.8608135e-26 1.0000000e+00 1.8318550e-27 1.5026839e-31 4.7516116e-36], sum to 1.0000
[2019-03-26 16:35:24,628] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0683
[2019-03-26 16:35:24,633] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6311768945550326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 882047.7527259204, 882047.7527259204, 206687.8484651671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4769400.0000, 
sim time next is 4770000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.5970820639323688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 834382.6977638899, 834382.6977638893, 200195.5653108609], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5145567035329744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23177297160108054, 0.23177297160108037, 0.29879935121024015], 
reward next is 0.7012, 
noisyNet noise sample is [array([0.16952185], dtype=float32), 0.42598358]. 
=============================================
[2019-03-26 16:35:24,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.64575 ]
 [63.605217]
 [63.586655]
 [63.469646]
 [63.20756 ]], R is [[63.9854393 ]
 [64.03709412]
 [64.08836365]
 [64.14191437]
 [64.19585419]].
[2019-03-26 16:35:24,788] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1188871: loss 0.1723
[2019-03-26 16:35:24,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1188871: learning rate 0.0000
[2019-03-26 16:35:25,662] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.3600112e-26 1.0000000e+00 9.5830461e-28 2.8551944e-32 4.5827778e-36], sum to 1.0000
[2019-03-26 16:35:25,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2723
[2019-03-26 16:35:25,673] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6311768945550326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 882047.7527259204, 882047.7527259204, 206687.8484651671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4769400.0000, 
sim time next is 4770000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.5970820639323688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 834382.6977638899, 834382.6977638893, 200195.5653108609], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5145567035329744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23177297160108054, 0.23177297160108037, 0.29879935121024015], 
reward next is 0.7012, 
noisyNet noise sample is [array([-0.4297758], dtype=float32), -0.3497914]. 
=============================================
[2019-03-26 16:35:25,686] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[64.94575 ]
 [64.90308 ]
 [64.884155]
 [64.770744]
 [64.509605]], R is [[65.27637482]
 [65.31512451]
 [65.35360718]
 [65.39450836]
 [65.43592072]].
[2019-03-26 16:35:27,841] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1190266: loss 26.5823
[2019-03-26 16:35:27,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1190266: learning rate 0.0000
[2019-03-26 16:35:29,564] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1191044: loss 10.5104
[2019-03-26 16:35:29,567] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1191045: learning rate 0.0000
[2019-03-26 16:35:29,589] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.2484100e-25 1.0000000e+00 1.0673348e-26 1.6385515e-30 3.9300257e-35], sum to 1.0000
[2019-03-26 16:35:29,597] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3221
[2019-03-26 16:35:29,600] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.6130519277822909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 856708.5267574344, 856708.5267574337, 203195.3615805125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4852800.0000, 
sim time next is 4853400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.7134894593213367, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 997130.6984637955, 997130.6984637949, 223782.1395880468], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.84, 1.0, 1.0, 0.6548065774955864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2769807495732765, 0.27698074957327634, 0.33400319341499524], 
reward next is 0.6660, 
noisyNet noise sample is [array([0.06214389], dtype=float32), 0.45727092]. 
=============================================
[2019-03-26 16:35:29,640] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3280826e-12 9.9999952e-01 1.3144782e-17 4.1918750e-07 5.7368506e-21], sum to 1.0000
[2019-03-26 16:35:29,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1717
[2019-03-26 16:35:29,659] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2184498.325077253 W.
[2019-03-26 16:35:29,664] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333334, 66.0, 1.0, 2.0, 0.7811218021343552, 1.0, 1.0, 0.7811218021343552, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2184498.325077253, 2184498.325077253, 410779.4533048488], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4898400.0000, 
sim time next is 4899000.0000, 
raw observation next is [30.16666666666666, 66.0, 1.0, 2.0, 0.8936925261282233, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.979297059993887, 6.9112, 168.9125518063334, 2146207.821092651, 2097897.53876153, 433252.7326393028], 
processed observation next is [1.0, 0.6956521739130435, 0.6287519747235385, 0.66, 1.0, 1.0, 0.8719187061785822, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006809705999388705, 0.0, 0.8294379578699091, 0.5961688391924032, 0.5827493163226473, 0.6466458696108996], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.40635827], dtype=float32), 0.7919757]. 
=============================================
[2019-03-26 16:35:29,675] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[51.54895 ]
 [52.350624]
 [51.21073 ]
 [48.735397]
 [45.04518 ]], R is [[50.61226273]
 [50.49303818]
 [49.98810959]
 [49.48822784]
 [48.99334717]].
[2019-03-26 16:35:32,272] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1135146e-11 1.0000000e+00 2.7116741e-15 9.2708632e-09 9.2191981e-20], sum to 1.0000
[2019-03-26 16:35:32,282] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-26 16:35:32,293] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2143110.573074852 W.
[2019-03-26 16:35:32,299] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.5108915801710848, 1.0, 1.0, 0.5108915801710848, 1.0, 2.0, 0.880283355290114, 6.9112, 6.9112, 170.5573041426782, 2143110.573074852, 2143110.573074852, 421468.3428202086], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4873800.0000, 
sim time next is 4874400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.7296121061800869, 1.0, 2.0, 0.7296121061800869, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2040308.257939558, 2040308.257939558, 387056.539951413], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.7, 1.0, 1.0, 0.6742314532290203, 1.0, 1.0, 0.6742314532290203, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5667522938720995, 0.5667522938720995, 0.5776963282856911], 
reward next is 0.4223, 
noisyNet noise sample is [array([-0.21392803], dtype=float32), -0.030847695]. 
=============================================
[2019-03-26 16:35:32,767] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1192504: loss 11.3345
[2019-03-26 16:35:32,769] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1192505: learning rate 0.0000
[2019-03-26 16:35:32,920] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192572: loss 27.0476
[2019-03-26 16:35:32,921] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192572: learning rate 0.0000
[2019-03-26 16:35:33,022] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1192624: loss 24.4049
[2019-03-26 16:35:33,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1192624: learning rate 0.0000
[2019-03-26 16:35:34,926] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193452: loss 29.1713
[2019-03-26 16:35:34,927] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193453: learning rate 0.0000
[2019-03-26 16:35:35,578] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1193757: loss 12.6149
[2019-03-26 16:35:35,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1193757: learning rate 0.0000
[2019-03-26 16:35:35,604] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1193768: loss 0.4305
[2019-03-26 16:35:35,606] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1193768: learning rate 0.0000
[2019-03-26 16:35:35,650] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1193784: loss 28.2654
[2019-03-26 16:35:35,653] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1193784: learning rate 0.0000
[2019-03-26 16:35:35,734] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1193825: loss 25.7059
[2019-03-26 16:35:35,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1193829: learning rate 0.0000
[2019-03-26 16:35:35,787] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193849: loss 29.3772
[2019-03-26 16:35:35,793] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193850: learning rate 0.0000
[2019-03-26 16:35:36,320] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8771368e-11 1.0000000e+00 3.1636464e-16 6.9690431e-09 2.5624908e-21], sum to 1.0000
[2019-03-26 16:35:36,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9209
[2019-03-26 16:35:36,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2182124.942272616 W.
[2019-03-26 16:35:36,343] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 63.66666666666667, 1.0, 2.0, 0.520182669036315, 1.0, 2.0, 0.520182669036315, 1.0, 2.0, 0.8917052631503006, 6.911199999999999, 6.9112, 170.5573041426782, 2182124.942272616, 2182124.942272616, 427165.0736184552], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4976400.0000, 
sim time next is 4977000.0000, 
raw observation next is [30.7, 63.5, 1.0, 2.0, 0.5283470983165621, 1.0, 2.0, 0.5283470983165621, 1.0, 2.0, 0.9058596902303077, 6.9112, 6.9112, 170.5573041426782, 2216408.951004464, 2216408.951004464, 433040.7714571866], 
processed observation next is [1.0, 0.6086956521739131, 0.6540284360189573, 0.635, 1.0, 1.0, 0.4317434919476652, 1.0, 1.0, 0.4317434919476652, 1.0, 1.0, 0.8851947441833019, 0.0, 0.0, 0.8375144448122397, 0.6156691530567956, 0.6156691530567956, 0.646329509637592], 
reward next is 0.3537, 
noisyNet noise sample is [array([-1.8086975], dtype=float32), 0.32182845]. 
=============================================
[2019-03-26 16:35:36,353] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[44.32943 ]
 [44.509487]
 [46.05854 ]
 [47.403614]
 [47.173542]], R is [[43.28019333]
 [43.20983505]
 [42.77773666]
 [42.34996033]
 [41.92646027]].
[2019-03-26 16:35:36,376] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194114: loss 28.6737
[2019-03-26 16:35:36,378] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194115: learning rate 0.0000
[2019-03-26 16:35:36,426] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1194135: loss 28.8493
[2019-03-26 16:35:36,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1194135: learning rate 0.0000
[2019-03-26 16:35:36,725] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1194268: loss 25.5112
[2019-03-26 16:35:36,731] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1194270: learning rate 0.0000
[2019-03-26 16:35:37,136] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1194456: loss 13.1871
[2019-03-26 16:35:37,138] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1194456: learning rate 0.0000
[2019-03-26 16:35:38,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1913671e-25 1.0000000e+00 1.0624069e-27 1.5490091e-28 5.5559600e-36], sum to 1.0000
[2019-03-26 16:35:38,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4481
[2019-03-26 16:35:38,783] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.5169787342217955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722405.5264565716, 722405.5264565722, 186299.7380690597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4992600.0000, 
sim time next is 4993200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5172741435004169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722818.4600814283, 722818.4600814289, 186347.3689148637], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.74, 1.0, 1.0, 0.41840258253062274, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20078290557817452, 0.2007829055781747, 0.27813040136546824], 
reward next is 0.7219, 
noisyNet noise sample is [array([0.09310781], dtype=float32), -0.80825144]. 
=============================================
[2019-03-26 16:35:41,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5482491e-29 1.0000000e+00 6.0902799e-30 2.1703995e-35 1.2566225e-38], sum to 1.0000
[2019-03-26 16:35:41,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0892
[2019-03-26 16:35:41,436] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5169274923730585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722333.8987893036, 722333.8987893036, 186291.2622685379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5051400.0000, 
sim time next is 5052000.0000, 
raw observation next is [31.0, 63.00000000000001, 1.0, 2.0, 0.517809345509258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723566.5849451869, 723566.5849451869, 186433.9142561213], 
processed observation next is [0.0, 0.4782608695652174, 0.6682464454976303, 0.6300000000000001, 1.0, 1.0, 0.4190474042280216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20099071804032967, 0.20099071804032967, 0.27825957351659897], 
reward next is 0.7217, 
noisyNet noise sample is [array([-1.9412917], dtype=float32), -1.909734]. 
=============================================
[2019-03-26 16:35:41,445] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.880516]
 [74.84614 ]
 [74.76899 ]
 [74.739555]
 [74.70309 ]], R is [[74.87802124]
 [74.85119629]
 [74.82487488]
 [74.79920197]
 [74.77424622]].
[2019-03-26 16:35:41,841] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5705841e-28 1.0000000e+00 1.2615707e-29 4.8420287e-33 2.9538758e-38], sum to 1.0000
[2019-03-26 16:35:41,850] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2062
[2019-03-26 16:35:41,857] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 68.83333333333333, 1.0, 2.0, 0.5281310652742466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737994.7638898012, 737994.7638898012, 188121.4172582703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5071800.0000, 
sim time next is 5072400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5299414630530386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740525.4421315795, 740525.4421315801, 188420.6451424913], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4336644133169139, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20570151170321652, 0.20570151170321668, 0.28122484349625565], 
reward next is 0.7188, 
noisyNet noise sample is [array([-1.7613661], dtype=float32), -0.3191371]. 
=============================================
[2019-03-26 16:35:42,626] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1196959: loss 1.5064
[2019-03-26 16:35:42,628] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1196959: learning rate 0.0000
[2019-03-26 16:35:45,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1198228: loss 1.5364
[2019-03-26 16:35:45,403] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1198228: learning rate 0.0000
[2019-03-26 16:35:47,158] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1199026: loss 0.4761
[2019-03-26 16:35:47,162] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1199026: learning rate 0.0000
[2019-03-26 16:35:49,349] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 16:35:49,351] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:35:49,352] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:35:49,353] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:35:49,354] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:35:49,355] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:35:49,355] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:35:49,356] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:35:49,356] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:35:49,360] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:35:49,360] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:35:49,383] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 16:35:49,407] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 16:35:49,433] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 16:35:49,433] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 16:35:49,472] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 16:35:54,967] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:35:54,969] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.6, 63.0, 1.0, 2.0, 0.221939724693287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 369514.5688693083, 369514.5688693083, 157824.2633673721]
[2019-03-26 16:35:54,970] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:35:54,973] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4149191e-27 1.0000000e+00 3.0979192e-28 1.5184777e-32 1.1700607e-36], sampled 0.6687764153523549
[2019-03-26 16:36:08,456] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:36:08,458] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.5, 44.33333333333334, 1.0, 2.0, 0.3949230430835866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649491.9321445978, 649491.9321445978, 178732.832939588]
[2019-03-26 16:36:08,458] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:36:08,461] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7543516e-27 1.0000000e+00 8.3067333e-28 8.0776284e-33 5.3579325e-36], sampled 0.6828057169377121
[2019-03-26 16:36:42,740] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:36:42,741] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.82817204, 66.40159285499999, 1.0, 2.0, 0.6032421781387498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 842994.4661397742, 842994.4661397736, 201351.9263051613]
[2019-03-26 16:36:42,742] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:36:42,746] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3256666e-28 1.0000000e+00 9.4716798e-30 1.6588006e-32 2.1282789e-38], sampled 0.16524235153378297
[2019-03-26 16:36:55,041] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:36:55,043] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.2, 47.0, 1.0, 2.0, 0.7347120250026035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1026804.440768213, 1026804.440768213, 228521.1695111221]
[2019-03-26 16:36:55,044] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:36:55,049] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.8668861e-26 1.0000000e+00 1.3478634e-27 1.3975872e-30 9.2322848e-36], sampled 0.8716949936654154
[2019-03-26 16:36:57,024] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:36:57,026] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.56666666666667, 70.0, 1.0, 2.0, 0.9175838810966926, 1.0, 1.0, 0.9175838810966926, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2566492.02836383, 2566492.02836383, 481651.2351972527]
[2019-03-26 16:36:57,027] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:36:57,030] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.34480241e-10 9.99999046e-01 1.27397414e-14 9.50017863e-07
 1.67992100e-18], sampled 0.9616287465528955
[2019-03-26 16:36:57,031] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2566492.02836383 W.
[2019-03-26 16:37:29,519] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:37:29,520] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.63333333333334, 71.66666666666667, 1.0, 2.0, 0.8064229357647522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1127077.957155467, 1127077.957155467, 245495.8418255757]
[2019-03-26 16:37:29,523] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:37:29,525] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4376557e-25 1.0000000e+00 2.6495712e-26 8.7801453e-30 2.2915693e-34], sampled 0.31294341848271
[2019-03-26 16:37:44,717] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00591524], dtype=float32), 0.08561966]
[2019-03-26 16:37:44,717] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.21666666666667, 89.83333333333333, 1.0, 2.0, 0.6508600437936357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 909566.0474464631, 909566.0474464631, 210594.4513989143]
[2019-03-26 16:37:44,718] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:37:44,720] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9076075e-25 1.0000000e+00 1.2556240e-26 1.7860826e-30 1.1593367e-34], sampled 0.4324312324883154
[2019-03-26 16:37:45,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.8172 3163751910.5183 1771.0000
[2019-03-26 16:37:45,874] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:37:46,366] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1803 3007736924.2222 1766.0000
[2019-03-26 16:37:46,408] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.4906 2927457840.3776 1338.0000
[2019-03-26 16:37:46,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.5779 2842695196.5357 1131.0000
[2019-03-26 16:37:47,486] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1200000, evaluation results [1200000.0, 7886.817245309394, 3163751910.518321, 1771.0, 8253.490594747309, 2927457840.3775544, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.180259296095, 3007736924.2222114, 1766.0, 8496.577922422102, 2842695196.535731, 1131.0]
[2019-03-26 16:37:48,034] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3666493e-21 1.0000000e+00 7.1629698e-24 5.2355628e-25 2.4320727e-31], sum to 1.0000
[2019-03-26 16:37:48,044] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4438
[2019-03-26 16:37:48,049] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8040646589605409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1123780.223190856, 1123780.223190856, 244908.5317874186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5199000.0000, 
sim time next is 5199600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.7720453625760281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1079006.543133964, 1079006.543133964, 237162.2853708779], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.725355858525335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29972403975943446, 0.29972403975943446, 0.3539735602550416], 
reward next is 0.6460, 
noisyNet noise sample is [array([0.93291193], dtype=float32), -0.34790587]. 
=============================================
[2019-03-26 16:37:48,783] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1200580: loss 0.7954
[2019-03-26 16:37:48,784] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1200580: learning rate 0.0000
[2019-03-26 16:37:48,866] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200619: loss 2.3031
[2019-03-26 16:37:48,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200619: learning rate 0.0000
[2019-03-26 16:37:48,997] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1200673: loss 0.9334
[2019-03-26 16:37:49,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1200675: learning rate 0.0000
[2019-03-26 16:37:50,810] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201470: loss 0.3634
[2019-03-26 16:37:50,811] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201470: learning rate 0.0000
[2019-03-26 16:37:51,581] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1201809: loss 0.6353
[2019-03-26 16:37:51,583] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1201810: learning rate 0.0000
[2019-03-26 16:37:51,589] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1201813: loss 0.9795
[2019-03-26 16:37:51,592] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1201813: learning rate 0.0000
[2019-03-26 16:37:51,696] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1201859: loss 1.0358
[2019-03-26 16:37:51,700] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1201860: learning rate 0.0000
[2019-03-26 16:37:51,704] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201864: loss 1.1471
[2019-03-26 16:37:51,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201866: learning rate 0.0000
[2019-03-26 16:37:52,134] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1202051: loss 1.3966
[2019-03-26 16:37:52,136] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1202051: learning rate 0.0000
[2019-03-26 16:37:52,250] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1202103: loss 1.2219
[2019-03-26 16:37:52,253] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1202103: learning rate 0.0000
[2019-03-26 16:37:52,417] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202178: loss 1.1603
[2019-03-26 16:37:52,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202178: learning rate 0.0000
[2019-03-26 16:37:52,574] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1202243: loss 0.8503
[2019-03-26 16:37:52,576] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1202244: learning rate 0.0000
[2019-03-26 16:37:53,153] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1202499: loss 0.4964
[2019-03-26 16:37:53,156] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1202499: learning rate 0.0000
[2019-03-26 16:37:54,626] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3579194e-23 1.0000000e+00 3.3624423e-26 9.1533549e-27 3.0217173e-34], sum to 1.0000
[2019-03-26 16:37:54,638] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0441
[2019-03-26 16:37:54,645] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.86666666666667, 84.0, 1.0, 2.0, 0.6128122521157372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856373.4573172141, 856373.4573172141, 203157.3513647149], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5353800.0000, 
sim time next is 5354400.0000, 
raw observation next is [29.83333333333333, 84.0, 1.0, 2.0, 0.6110621381928617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 853926.7803851445, 853926.7803851451, 202825.1450226855], 
processed observation next is [1.0, 1.0, 0.6129541864139019, 0.84, 1.0, 1.0, 0.5314001664974237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23720188344031792, 0.2372018834403181, 0.30272409704878434], 
reward next is 0.6973, 
noisyNet noise sample is [array([1.5981672], dtype=float32), -1.0197184]. 
=============================================
[2019-03-26 16:37:58,539] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1204880: loss 1.3971
[2019-03-26 16:37:58,541] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1204880: learning rate 0.0000
[2019-03-26 16:37:58,985] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5583078e-06 9.6049172e-01 9.9078835e-12 3.9506696e-02 1.3983871e-15], sum to 1.0000
[2019-03-26 16:37:58,995] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5200
[2019-03-26 16:37:59,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3155965.55916294 W.
[2019-03-26 16:37:59,008] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.78333333333333, 65.5, 1.0, 2.0, 0.8628916637098697, 1.0, 2.0, 0.7520358713691976, 1.0, 1.0, 1.03, 7.005110579528917, 6.9112, 170.5573041426782, 3155965.55916294, 3088693.591008239, 577717.9535634747], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5482200.0000, 
sim time next is 5482800.0000, 
raw observation next is [35.0, 65.0, 1.0, 2.0, 0.860330472804852, 1.0, 2.0, 0.7507552759166886, 1.0, 2.0, 1.03, 7.005110377471655, 6.9112, 170.5573041426782, 3150584.681482862, 3083312.858069997, 576754.9611576373], 
processed observation next is [1.0, 0.4782608695652174, 0.8578199052132701, 0.65, 1.0, 1.0, 0.831723461210665, 1.0, 1.0, 0.6997051517068537, 1.0, 1.0, 1.0365853658536586, 0.009391037747165498, 0.0, 0.8375144448122397, 0.8751624115230173, 0.8564757939083324, 0.8608283002352796], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5760808], dtype=float32), -0.5170578]. 
=============================================
[2019-03-26 16:38:00,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8023992e-23 1.0000000e+00 1.5953013e-25 4.6559592e-28 3.0824910e-34], sum to 1.0000
[2019-03-26 16:38:00,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1361
[2019-03-26 16:38:00,258] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 87.66666666666666, 1.0, 2.0, 0.5892268612011002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823401.3165328501, 823401.3165328501, 198756.2059069471], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5445600.0000, 
sim time next is 5446200.0000, 
raw observation next is [28.6, 88.33333333333334, 1.0, 2.0, 0.58828882238829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822089.9688113108, 822089.9688113108, 198584.6308239584], 
processed observation next is [1.0, 0.0, 0.5545023696682465, 0.8833333333333334, 1.0, 1.0, 0.5039624366123975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22835832466980857, 0.22835832466980857, 0.2963949713790424], 
reward next is 0.7036, 
noisyNet noise sample is [array([1.0542488], dtype=float32), -0.92126065]. 
=============================================
[2019-03-26 16:38:01,707] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1206279: loss 1.3147
[2019-03-26 16:38:01,711] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1206279: learning rate 0.0000
[2019-03-26 16:38:03,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1206993: loss 1.1672
[2019-03-26 16:38:03,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1206993: learning rate 0.0000
[2019-03-26 16:38:06,790] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1208525: loss 1.4493
[2019-03-26 16:38:06,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1208525: learning rate 0.0000
[2019-03-26 16:38:06,957] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208594: loss 1.2218
[2019-03-26 16:38:06,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208595: learning rate 0.0000
[2019-03-26 16:38:06,991] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1208610: loss 1.2350
[2019-03-26 16:38:06,995] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1208611: learning rate 0.0000
[2019-03-26 16:38:08,840] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209428: loss 1.4036
[2019-03-26 16:38:08,845] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209429: learning rate 0.0000
[2019-03-26 16:38:09,718] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1209810: loss 1.2764
[2019-03-26 16:38:09,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1209812: learning rate 0.0000
[2019-03-26 16:38:09,737] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1209815: loss 1.4873
[2019-03-26 16:38:09,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1209815: learning rate 0.0000
[2019-03-26 16:38:09,798] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1209848: loss 1.5617
[2019-03-26 16:38:09,800] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1209848: learning rate 0.0000
[2019-03-26 16:38:09,804] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209850: loss 1.4571
[2019-03-26 16:38:09,806] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209850: learning rate 0.0000
[2019-03-26 16:38:09,846] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1209866: loss 0.0463
[2019-03-26 16:38:09,848] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1209867: learning rate 0.0000
[2019-03-26 16:38:10,453] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210136: loss 2.0856
[2019-03-26 16:38:10,455] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210137: learning rate 0.0000
[2019-03-26 16:38:10,553] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1210179: loss 1.5394
[2019-03-26 16:38:10,557] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1210180: learning rate 0.0000
[2019-03-26 16:38:10,689] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1210239: loss 1.3531
[2019-03-26 16:38:10,692] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1210239: learning rate 0.0000
[2019-03-26 16:38:11,210] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1210472: loss 1.3162
[2019-03-26 16:38:11,212] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1210472: learning rate 0.0000
[2019-03-26 16:38:11,863] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.1100454e-13 1.0000000e+00 5.3195919e-18 3.0528909e-11 3.4066800e-23], sum to 1.0000
[2019-03-26 16:38:11,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7485
[2019-03-26 16:38:11,880] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2187712.310659321 W.
[2019-03-26 16:38:11,885] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.51666666666667, 52.83333333333334, 1.0, 2.0, 0.9233441192701012, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.989045550666814, 6.9112, 168.9124929704647, 2187712.310659321, 2132486.149334202, 441237.7047025191], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5575800.0000, 
sim time next is 5576400.0000, 
raw observation next is [33.6, 52.0, 1.0, 2.0, 0.5047509633833203, 1.0, 1.0, 0.5047509633833203, 1.0, 2.0, 0.8691039089485966, 6.911199999999999, 6.9112, 170.5573041426782, 2117326.184640131, 2117326.184640132, 417078.1408977082], 
processed observation next is [1.0, 0.5652173913043478, 0.7914691943127963, 0.52, 1.0, 1.0, 0.40331441371484367, 1.0, 0.5, 0.40331441371484367, 1.0, 1.0, 0.8403706206690202, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5881461624000364, 0.5881461624000366, 0.6225046879070272], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6786159], dtype=float32), -0.8974131]. 
=============================================
[2019-03-26 16:38:13,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3178274e-25 1.0000000e+00 1.3692459e-27 6.9349935e-31 1.2096180e-36], sum to 1.0000
[2019-03-26 16:38:13,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6105
[2019-03-26 16:38:13,276] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 90.0, 1.0, 2.0, 0.5440535270929651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760252.3043683963, 760252.3043683963, 190785.8175681132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5610000.0000, 
sim time next is 5610600.0000, 
raw observation next is [26.85, 90.0, 1.0, 2.0, 0.5414135592833833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756561.938858219, 756561.9388582197, 190338.7116191654], 
processed observation next is [1.0, 0.9565217391304348, 0.4715639810426541, 0.9, 1.0, 1.0, 0.44748621600407623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21015609412728303, 0.21015609412728323, 0.28408762928233644], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.81379867], dtype=float32), 0.30584612]. 
=============================================
[2019-03-26 16:38:16,874] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1212927: loss 1.5287
[2019-03-26 16:38:16,876] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1212927: learning rate 0.0000
[2019-03-26 16:38:18,244] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1570655e-31 1.0000000e+00 7.9992861e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 16:38:18,251] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6787
[2019-03-26 16:38:18,255] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.45, 60.66666666666666, 1.0, 2.0, 0.5198684069498711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726444.820945256, 726444.8209452567, 186767.8669291593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5741400.0000, 
sim time next is 5742000.0000, 
raw observation next is [31.6, 60.0, 1.0, 2.0, 0.5201989665103799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726906.8906554563, 726906.8906554563, 186821.6285277968], 
processed observation next is [0.0, 0.4782608695652174, 0.6966824644549764, 0.6, 1.0, 1.0, 0.42192646567515646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20191858073762675, 0.20191858073762675, 0.2788382515340251], 
reward next is 0.7212, 
noisyNet noise sample is [array([0.9987207], dtype=float32), -1.2531012]. 
=============================================
[2019-03-26 16:38:18,278] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[75.74522]
 [75.67271]
 [75.59452]
 [75.52598]
 [75.47268]], R is [[75.82228088]
 [75.78530121]
 [75.74873352]
 [75.71250153]
 [75.67649078]].
[2019-03-26 16:38:19,574] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1214130: loss 0.7270
[2019-03-26 16:38:19,576] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1214131: learning rate 0.0000
[2019-03-26 16:38:20,041] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1841887e-11 1.0000000e+00 1.0396807e-15 7.3063928e-09 1.5203824e-20], sum to 1.0000
[2019-03-26 16:38:20,050] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5868
[2019-03-26 16:38:20,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2321673.579661145 W.
[2019-03-26 16:38:20,064] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 75.0, 1.0, 2.0, 1.019055232304579, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005994381141813, 6.9112, 168.9123159406803, 2321673.579661145, 2254423.438142471, 469213.1501203388], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6017400.0000, 
sim time next is 6018000.0000, 
raw observation next is [31.0, 73.66666666666666, 1.0, 2.0, 0.8424211233483012, 1.0, 1.0, 0.8424211233483012, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2356095.049750295, 2356095.049750296, 441057.9418326034], 
processed observation next is [1.0, 0.6521739130434783, 0.6682464454976303, 0.7366666666666666, 1.0, 1.0, 0.8101459317449412, 1.0, 0.5, 0.8101459317449412, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6544708471528597, 0.65447084715286, 0.6582954355710499], 
reward next is 0.3417, 
noisyNet noise sample is [array([0.9078427], dtype=float32), 0.57198423]. 
=============================================
[2019-03-26 16:38:20,082] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[38.375458]
 [38.799606]
 [39.14049 ]
 [39.939   ]
 [40.19277 ]], R is [[36.87914658]
 [36.5103569 ]
 [36.14525223]
 [36.17577744]
 [35.81401825]].
[2019-03-26 16:38:21,394] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1214955: loss 1.9263
[2019-03-26 16:38:21,396] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1214956: learning rate 0.0000
[2019-03-26 16:38:24,981] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1216599: loss 2.1947
[2019-03-26 16:38:24,983] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1216599: learning rate 0.0000
[2019-03-26 16:38:25,005] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1216609: loss 1.0652
[2019-03-26 16:38:25,008] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1216610: learning rate 0.0000
[2019-03-26 16:38:25,074] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216637: loss 2.5787
[2019-03-26 16:38:25,075] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216638: learning rate 0.0000
[2019-03-26 16:38:26,902] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217471: loss 3.4362
[2019-03-26 16:38:26,906] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217472: learning rate 0.0000
[2019-03-26 16:38:27,743] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1217854: loss 0.1878
[2019-03-26 16:38:27,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1217855: learning rate 0.0000
[2019-03-26 16:38:27,775] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1217867: loss 1.2087
[2019-03-26 16:38:27,778] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1217869: learning rate 0.0000
[2019-03-26 16:38:27,791] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1217871: loss 0.8737
[2019-03-26 16:38:27,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1217871: learning rate 0.0000
[2019-03-26 16:38:27,941] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217941: loss 0.8414
[2019-03-26 16:38:27,943] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217942: learning rate 0.0000
[2019-03-26 16:38:28,253] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1218087: loss 2.3039
[2019-03-26 16:38:28,255] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1218088: learning rate 0.0000
[2019-03-26 16:38:28,409] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218160: loss 0.4953
[2019-03-26 16:38:28,413] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218161: learning rate 0.0000
[2019-03-26 16:38:28,471] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1218184: loss 2.2322
[2019-03-26 16:38:28,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1218184: learning rate 0.0000
[2019-03-26 16:38:28,656] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1218267: loss 0.4279
[2019-03-26 16:38:28,658] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1218268: learning rate 0.0000
[2019-03-26 16:38:29,183] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1218508: loss 2.6688
[2019-03-26 16:38:29,188] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1218508: learning rate 0.0000
[2019-03-26 16:38:29,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1551101e-08 9.9958462e-01 1.6079763e-14 4.1541771e-04 2.7335122e-18], sum to 1.0000
[2019-03-26 16:38:29,606] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0034
[2019-03-26 16:38:29,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2185425.542521132 W.
[2019-03-26 16:38:29,618] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.921710438748115, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.993381198352425, 6.9112, 168.912467911766, 2185425.542521132, 2127123.540596583, 440620.3464723915], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6022800.0000, 
sim time next is 6023400.0000, 
raw observation next is [30.83333333333334, 67.0, 1.0, 2.0, 0.2401317497514152, 1.0, 1.0, 0.2401317497514152, 1.0, 2.0, 0.4141342086642629, 6.911199999999999, 6.9112, 170.5573041426782, 1006781.796109092, 1006781.796109093, 281858.8857483001], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.67, 1.0, 1.0, 0.08449608403784964, 1.0, 0.5, 0.08449608403784964, 1.0, 1.0, 0.28552952276129623, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2796616100303033, 0.2796616100303036, 0.4206849041019405], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11778759], dtype=float32), 1.2527853]. 
=============================================
[2019-03-26 16:38:33,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.3459363e-08 9.9945885e-01 1.0237861e-13 5.4108247e-04 7.8870573e-17], sum to 1.0000
[2019-03-26 16:38:33,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3842
[2019-03-26 16:38:33,539] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2209629.630646077 W.
[2019-03-26 16:38:33,546] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.76666666666667, 74.33333333333333, 1.0, 2.0, 0.790098867097114, 1.0, 2.0, 0.790098867097114, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2209629.630646077, 2209629.630646078, 415086.3747661895], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5998200.0000, 
sim time next is 5998800.0000, 
raw observation next is [30.93333333333334, 73.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.340575420914226, 6.9112, 168.9109063392562, 2588568.671492947, 2283958.667165976, 475156.4958990374], 
processed observation next is [1.0, 0.43478260869565216, 0.6650868878357034, 0.7366666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.04293754209142264, 0.0, 0.829429877873262, 0.7190468531924852, 0.63443296310166, 0.7091887998493096], 
reward next is 0.0000, 
noisyNet noise sample is [array([-3.2515037], dtype=float32), 0.43005136]. 
=============================================
[2019-03-26 16:38:34,702] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1220913: loss 897.0868
[2019-03-26 16:38:34,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1220913: learning rate 0.0000
[2019-03-26 16:38:37,534] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1222205: loss 2.2258
[2019-03-26 16:38:37,536] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1222205: learning rate 0.0000
[2019-03-26 16:38:39,161] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1222943: loss 1.6976
[2019-03-26 16:38:39,166] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1222943: learning rate 0.0000
[2019-03-26 16:38:42,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1224511: loss 2.3510
[2019-03-26 16:38:42,605] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1224511: learning rate 0.0000
[2019-03-26 16:38:42,724] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224565: loss 1.7094
[2019-03-26 16:38:42,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224566: learning rate 0.0000
[2019-03-26 16:38:42,735] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1224571: loss 2.2769
[2019-03-26 16:38:42,736] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1224571: learning rate 0.0000
[2019-03-26 16:38:43,684] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 16:38:43,686] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:38:43,687] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:38:43,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:38:43,688] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:38:43,690] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:38:43,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:38:43,691] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:38:43,693] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:38:43,696] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:38:43,693] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:38:43,713] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 16:38:43,738] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 16:38:43,740] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 16:38:43,761] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 16:38:43,801] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 16:39:41,986] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00132514], dtype=float32), 0.086177245]
[2019-03-26 16:39:41,987] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.9, 68.0, 1.0, 2.0, 0.6118836591150354, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.9208420064183, 6.9112, 168.9128240869592, 1710839.500558977, 1703999.134716262, 367756.896762743]
[2019-03-26 16:39:41,988] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:39:41,994] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9261770e-14 1.0000000e+00 1.6562129e-19 6.5148401e-11 1.1256136e-22], sampled 0.8383968139750304
[2019-03-26 16:39:41,994] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1710839.500558977 W.
[2019-03-26 16:39:45,549] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00132514], dtype=float32), 0.086177245]
[2019-03-26 16:39:45,552] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.61398100666667, 60.04928623333333, 1.0, 2.0, 0.6483861307629136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 906107.3204828603, 906107.3204828609, 210105.4820904313]
[2019-03-26 16:39:45,554] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:39:45,556] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1651061e-24 1.0000000e+00 7.3000261e-28 5.7201406e-27 1.4905497e-34], sampled 0.013339333280984578
[2019-03-26 16:39:54,502] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00132514], dtype=float32), 0.086177245]
[2019-03-26 16:39:54,503] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.05, 59.0, 1.0, 2.0, 0.8160608652098953, 1.0, 1.0, 0.8160608652098953, 0.0, 1.0, 0.0, 6.9112, 6.9112, 169.0403247858759, 2282321.696317496, 2282321.696317496, 427492.5786508727]
[2019-03-26 16:39:54,504] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:39:54,507] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1325471e-08 9.4659472e-01 3.0700982e-15 5.3405307e-02 3.0401319e-17], sampled 0.09386687889583278
[2019-03-26 16:39:54,510] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2282321.696317496 W.
[2019-03-26 16:40:03,499] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00132514], dtype=float32), 0.086177245]
[2019-03-26 16:40:03,501] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.9, 62.33333333333334, 1.0, 2.0, 0.6805148034863121, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005974066849536, 6.9112, 168.9123160528044, 1847862.460130014, 1780626.73017016, 380473.7484900396]
[2019-03-26 16:40:03,501] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:40:03,505] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5950717e-15 1.0000000e+00 4.4913669e-19 4.6918564e-14 1.0374421e-23], sampled 0.12542247223534608
[2019-03-26 16:40:03,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1847862.460130014 W.
[2019-03-26 16:40:21,902] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00132514], dtype=float32), 0.086177245]
[2019-03-26 16:40:21,903] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.41298964333333, 60.01714489333334, 1.0, 2.0, 0.6599379449205842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 943168.228585662, 943168.228585662, 215186.7247724855]
[2019-03-26 16:40:21,903] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:40:21,904] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2552036e-22 1.0000000e+00 6.1611220e-25 3.1400663e-25 9.8459736e-32], sampled 0.17526446816777064
[2019-03-26 16:40:40,045] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.7737 2927512725.0370 1338.0000
[2019-03-26 16:40:40,289] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.7580 2842589120.1342 1130.0000
[2019-03-26 16:40:40,516] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.8400 2779333513.9148 932.0000
[2019-03-26 16:40:40,656] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7889.6207 3163505058.8236 1764.0000
[2019-03-26 16:40:40,745] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.0101 3007850793.6778 1766.0000
[2019-03-26 16:40:41,761] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1225000, evaluation results [1225000.0, 7889.620653979787, 3163505058.823573, 1764.0, 8254.773707254759, 2927512725.037018, 1338.0, 8660.840000299144, 2779333513.914762, 932.0, 7998.01012790131, 3007850793.677805, 1766.0, 8497.757950184647, 2842589120.134199, 1130.0]
[2019-03-26 16:40:41,804] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0245323e-27 1.0000000e+00 3.4782891e-29 2.1250635e-33 5.1451088e-37], sum to 1.0000
[2019-03-26 16:40:41,812] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9191
[2019-03-26 16:40:41,819] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666666, 67.66666666666667, 1.0, 2.0, 0.5385036327451984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752494.2175479198, 752494.2175479204, 189849.0417139439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6262800.0000, 
sim time next is 6263400.0000, 
raw observation next is [30.68333333333333, 67.33333333333333, 1.0, 2.0, 0.5371825052149364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750647.4480241525, 750647.448024152, 189627.2052148219], 
processed observation next is [0.0, 0.4782608695652174, 0.6532385466034754, 0.6733333333333333, 1.0, 1.0, 0.4423885604999233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20851318000670904, 0.20851318000670888, 0.2830256794251073], 
reward next is 0.7170, 
noisyNet noise sample is [array([1.9191784], dtype=float32), -2.8530443]. 
=============================================
[2019-03-26 16:40:42,822] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225473: loss 2.1458
[2019-03-26 16:40:42,824] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225473: learning rate 0.0000
[2019-03-26 16:40:43,382] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1225718: loss 2.0490
[2019-03-26 16:40:43,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1225719: learning rate 0.0000
[2019-03-26 16:40:43,634] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1225830: loss 2.1648
[2019-03-26 16:40:43,638] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1225831: learning rate 0.0000
[2019-03-26 16:40:43,667] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1225845: loss 2.0546
[2019-03-26 16:40:43,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1225846: learning rate 0.0000
[2019-03-26 16:40:43,920] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1225962: loss 610.5474
[2019-03-26 16:40:43,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1225962: learning rate 0.0000
[2019-03-26 16:40:43,938] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225967: loss 1.4181
[2019-03-26 16:40:43,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225969: learning rate 0.0000
[2019-03-26 16:40:44,297] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1226127: loss 2.1416
[2019-03-26 16:40:44,300] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1226129: learning rate 0.0000
[2019-03-26 16:40:44,381] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.4869094e-24 1.0000000e+00 2.2501366e-27 7.7198329e-30 1.3924484e-35], sum to 1.0000
[2019-03-26 16:40:44,389] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9897
[2019-03-26 16:40:44,396] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 86.5, 1.0, 2.0, 0.5278203877085342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737560.481508499, 737560.4815084997, 188069.856583729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6211800.0000, 
sim time next is 6212400.0000, 
raw observation next is [27.1, 86.66666666666667, 1.0, 2.0, 0.5273128409002699, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736851.004732017, 736851.0047320178, 187986.1524361397], 
processed observation next is [1.0, 0.9130434782608695, 0.4834123222748816, 0.8666666666666667, 1.0, 1.0, 0.4304973986750239, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20468083464778253, 0.20468083464778272, 0.2805763469196115], 
reward next is 0.7194, 
noisyNet noise sample is [array([-1.1142144], dtype=float32), 0.40807483]. 
=============================================
[2019-03-26 16:40:44,401] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226169: loss 2.1411
[2019-03-26 16:40:44,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226170: learning rate 0.0000
[2019-03-26 16:40:44,537] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1226230: loss 2.1191
[2019-03-26 16:40:44,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1226230: learning rate 0.0000
[2019-03-26 16:40:45,059] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1226459: loss 2.0770
[2019-03-26 16:40:45,061] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1226459: learning rate 0.0000
[2019-03-26 16:40:47,746] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3497527e-28 1.0000000e+00 3.2315385e-30 2.5956187e-34 3.7681622e-38], sum to 1.0000
[2019-03-26 16:40:47,754] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7288
[2019-03-26 16:40:47,761] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5251428749602071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733817.7126240182, 733817.7126240176, 187629.4753346363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6234600.0000, 
sim time next is 6235200.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.5251337541611616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733804.9631114175, 733804.9631114168, 187627.9789351105], 
processed observation next is [0.0, 0.17391304347826086, 0.4549763033175356, 0.91, 1.0, 1.0, 0.4278719929652549, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20383471197539374, 0.20383471197539355, 0.28004175960464256], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.14984415], dtype=float32), 0.62533194]. 
=============================================
[2019-03-26 16:40:50,871] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1229045: loss 0.0195
[2019-03-26 16:40:50,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1229045: learning rate 0.0000
[2019-03-26 16:40:53,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1230120: loss 668.7532
[2019-03-26 16:40:53,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1230120: learning rate 0.0000
[2019-03-26 16:40:53,891] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.3030158e-10 9.9999988e-01 5.0261866e-16 1.0738262e-07 6.3724695e-20], sum to 1.0000
[2019-03-26 16:40:53,900] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1945
[2019-03-26 16:40:53,908] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2187343.845938495 W.
[2019-03-26 16:40:53,914] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 62.0, 1.0, 2.0, 0.5214255007814401, 1.0, 2.0, 0.5214255007814401, 1.0, 2.0, 0.8984969804823563, 6.911200000000001, 6.9112, 170.5573041426782, 2187343.845938495, 2187343.845938494, 428942.243901082], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6615600.0000, 
sim time next is 6616200.0000, 
raw observation next is [31.41666666666666, 61.0, 1.0, 2.0, 0.7726097678364364, 1.0, 2.0, 0.7726097678364364, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2160669.418090144, 2160669.418090144, 406751.7101128771], 
processed observation next is [1.0, 0.5652173913043478, 0.6879936808846759, 0.61, 1.0, 1.0, 0.7260358648631764, 1.0, 1.0, 0.7260358648631764, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6001859494694844, 0.6001859494694844, 0.6070921046460852], 
reward next is 0.3929, 
noisyNet noise sample is [array([0.06270335], dtype=float32), 1.5515535]. 
=============================================
[2019-03-26 16:40:55,324] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1230993: loss 756.8566
[2019-03-26 16:40:55,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1230993: learning rate 0.0000
[2019-03-26 16:40:57,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6356496e-26 1.0000000e+00 7.2446774e-29 1.9513946e-31 1.9088124e-36], sum to 1.0000
[2019-03-26 16:40:57,738] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3975
[2019-03-26 16:40:57,748] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.18333333333333, 82.16666666666667, 1.0, 2.0, 0.5121313591848884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715629.715685423, 715629.715685423, 185518.3057289357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6390600.0000, 
sim time next is 6391200.0000, 
raw observation next is [27.16666666666667, 82.33333333333334, 1.0, 2.0, 0.5122766213681439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715832.7670303946, 715832.767030394, 185541.6009069304], 
processed observation next is [0.0, 1.0, 0.4865718799368091, 0.8233333333333335, 1.0, 1.0, 0.4123814715278842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19884243528622073, 0.19884243528622056, 0.27692776254765733], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.10228894], dtype=float32), 0.83990216]. 
=============================================
[2019-03-26 16:40:58,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6413718e-26 1.0000000e+00 2.4663647e-28 3.5965805e-30 7.3330421e-36], sum to 1.0000
[2019-03-26 16:40:58,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9298
[2019-03-26 16:40:58,212] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.45, 82.0, 1.0, 2.0, 0.5227449343679943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730465.7556748218, 730465.7556748218, 187235.9598224992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6384600.0000, 
sim time next is 6385200.0000, 
raw observation next is [27.43333333333333, 82.0, 1.0, 2.0, 0.5214930887779144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728715.8697678195, 728715.8697678202, 187031.657905314], 
processed observation next is [0.0, 0.9130434782608695, 0.49921011058451803, 0.82, 1.0, 1.0, 0.4234856491300174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20242107493550543, 0.20242107493550562, 0.27915172821688655], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.688347], dtype=float32), -0.36595026]. 
=============================================
[2019-03-26 16:40:58,741] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1232521: loss 806.2211
[2019-03-26 16:40:58,741] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1232521: learning rate 0.0000
[2019-03-26 16:40:58,883] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1232587: loss 879.9725
[2019-03-26 16:40:58,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1232587: learning rate 0.0000
[2019-03-26 16:40:58,946] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232613: loss 516.6763
[2019-03-26 16:40:58,948] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232614: learning rate 0.0000
[2019-03-26 16:41:00,142] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.0353793e-22 1.0000000e+00 2.6859639e-25 1.5269872e-25 5.5885543e-33], sum to 1.0000
[2019-03-26 16:41:00,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1556
[2019-03-26 16:41:00,155] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 88.0, 1.0, 2.0, 0.5286159030669341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738672.4974779445, 738672.4974779452, 188201.0023743313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6480000.0000, 
sim time next is 6480600.0000, 
raw observation next is [26.86666666666667, 88.33333333333334, 1.0, 2.0, 0.52873246730019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738835.4375962825, 738835.4375962825, 188220.286648948], 
processed observation next is [1.0, 0.0, 0.4723538704581361, 0.8833333333333334, 1.0, 1.0, 0.4322077919279397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20523206599896734, 0.20523206599896734, 0.2809258009685791], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.28776413], dtype=float32), -1.9555032]. 
=============================================
[2019-03-26 16:41:01,113] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233570: loss 738.7758
[2019-03-26 16:41:01,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233570: learning rate 0.0000
[2019-03-26 16:41:01,589] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1233779: loss 627.3580
[2019-03-26 16:41:01,590] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1233779: learning rate 0.0000
[2019-03-26 16:41:01,761] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1233858: loss 596.5820
[2019-03-26 16:41:01,763] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1233859: learning rate 0.0000
[2019-03-26 16:41:01,870] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1233908: loss 764.7792
[2019-03-26 16:41:01,871] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1233909: learning rate 0.0000
[2019-03-26 16:41:02,126] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234020: loss 1052.1921
[2019-03-26 16:41:02,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234020: learning rate 0.0000
[2019-03-26 16:41:02,491] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1234179: loss 0.0516
[2019-03-26 16:41:02,493] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1234179: learning rate 0.0000
[2019-03-26 16:41:02,517] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234192: loss 773.3663
[2019-03-26 16:41:02,522] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234193: learning rate 0.0000
[2019-03-26 16:41:02,524] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1234195: loss 793.8132
[2019-03-26 16:41:02,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1234197: learning rate 0.0000
[2019-03-26 16:41:02,787] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1234307: loss 834.0306
[2019-03-26 16:41:02,793] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1234309: learning rate 0.0000
[2019-03-26 16:41:03,137] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1234462: loss 496.0354
[2019-03-26 16:41:03,139] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1234462: learning rate 0.0000
[2019-03-26 16:41:05,650] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8548444e-22 1.0000000e+00 3.5348258e-24 3.8207879e-25 8.9707446e-32], sum to 1.0000
[2019-03-26 16:41:05,661] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1500
[2019-03-26 16:41:05,670] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666667, 85.16666666666667, 1.0, 2.0, 0.9250014301611457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1292907.291572742, 1292907.291572741, 276907.1900368137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [27.63333333333334, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.631521474754371, 6.9112, 168.9093597728707, 1965114.921603189, 1454104.957251263, 311350.1458003531], 
processed observation next is [1.0, 0.34782608695652173, 0.5086887835703005, 0.8333333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07203214747543711, 0.0, 0.8294222835242879, 0.5458652560008859, 0.4039180436809064, 0.46470171014978073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.2478688], dtype=float32), -0.27817714]. 
=============================================
[2019-03-26 16:41:05,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.93437 ]
 [57.638985]
 [58.40132 ]
 [58.132942]
 [57.81089 ]], R is [[52.10613632]
 [52.17177963]
 [52.29284668]
 [52.45309448]
 [52.60890579]].
[2019-03-26 16:41:07,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0757927e-25 1.0000000e+00 5.4508902e-28 1.1747782e-30 1.4567149e-35], sum to 1.0000
[2019-03-26 16:41:07,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7825
[2019-03-26 16:41:07,902] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 77.66666666666667, 1.0, 2.0, 0.4962764284963369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693467.5050002947, 693467.5050002947, 183014.8726285548], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6556200.0000, 
sim time next is 6556800.0000, 
raw observation next is [27.63333333333333, 78.33333333333334, 1.0, 2.0, 0.4979545386699867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695813.1654802216, 695813.1654802216, 183276.4264311119], 
processed observation next is [1.0, 0.9130434782608695, 0.5086887835703, 0.7833333333333334, 1.0, 1.0, 0.3951259502048033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1932814348556171, 0.1932814348556171, 0.27354690512106256], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.03300531], dtype=float32), 0.27188438]. 
=============================================
[2019-03-26 16:41:08,719] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1236875: loss -66.7744
[2019-03-26 16:41:08,723] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1236875: learning rate 0.0000
[2019-03-26 16:41:09,455] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.8351271e-11 9.9999964e-01 6.4281263e-15 3.5679039e-07 8.4763260e-19], sum to 1.0000
[2019-03-26 16:41:09,466] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1351
[2019-03-26 16:41:09,476] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1899049.4716249 W.
[2019-03-26 16:41:09,484] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.03333333333333, 79.0, 1.0, 2.0, 0.4527618946371259, 1.0, 1.0, 0.4527618946371259, 1.0, 2.0, 0.7748905399560487, 6.9112, 6.9112, 170.5573041426782, 1899049.4716249, 1899049.4716249, 382162.5267486269], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6688200.0000, 
sim time next is 6688800.0000, 
raw observation next is [28.2, 78.0, 1.0, 2.0, 0.7289475893375867, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.981268743026266, 6.9112, 168.9125391294075, 1915637.490823842, 1865928.435771517, 391933.977734317], 
processed observation next is [1.0, 0.43478260869565216, 0.5355450236966824, 0.78, 1.0, 1.0, 0.673430830527213, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007006874302626631, 0.0, 0.8294378956203994, 0.5321215252288449, 0.518313454380977, 0.5849760861706224], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5876811], dtype=float32), 0.36160493]. 
=============================================
[2019-03-26 16:41:11,591] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1238191: loss 0.0062
[2019-03-26 16:41:11,597] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1238192: learning rate 0.0000
[2019-03-26 16:41:13,425] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1239025: loss 0.0032
[2019-03-26 16:41:13,426] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1239025: learning rate 0.0000
[2019-03-26 16:41:16,715] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1240531: loss 0.0020
[2019-03-26 16:41:16,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1240532: learning rate 0.0000
[2019-03-26 16:41:16,753] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.3384181e-09 9.9793869e-01 5.8560957e-15 2.0613237e-03 1.0203529e-17], sum to 1.0000
[2019-03-26 16:41:16,761] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4580
[2019-03-26 16:41:16,767] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1997171.860309788 W.
[2019-03-26 16:41:16,775] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.25, 71.33333333333333, 1.0, 2.0, 0.7142009405454322, 1.0, 2.0, 0.7142009405454322, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1997171.860309788, 1997171.860309788, 380257.6233159745], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6693000.0000, 
sim time next is 6693600.0000, 
raw observation next is [29.3, 70.66666666666667, 1.0, 2.0, 0.8285126884616228, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.978281483138889, 6.9112, 168.9125570154538, 2054978.773416619, 2007388.973066028, 415976.9466956251], 
processed observation next is [1.0, 0.4782608695652174, 0.5876777251184835, 0.7066666666666667, 1.0, 1.0, 0.7933887812790636, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006708148313888884, 0.0, 0.8294379834490752, 0.5708274370601719, 0.5576080480738966, 0.6208611144710822], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.67430085], dtype=float32), 0.78057855]. 
=============================================
[2019-03-26 16:41:16,860] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240597: loss 0.0023
[2019-03-26 16:41:16,862] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240597: learning rate 0.0000
[2019-03-26 16:41:16,867] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1240600: loss 0.0022
[2019-03-26 16:41:16,870] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1240600: learning rate 0.0000
[2019-03-26 16:41:19,026] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241588: loss 0.0071
[2019-03-26 16:41:19,028] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241588: learning rate 0.0000
[2019-03-26 16:41:19,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.3020155e-25 1.0000000e+00 1.9430790e-27 6.3325299e-29 1.0332572e-35], sum to 1.0000
[2019-03-26 16:41:19,213] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8911
[2019-03-26 16:41:19,218] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 84.0, 1.0, 2.0, 0.3710920051502805, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563026.1201074978, 563026.1201074984, 171506.0276666304], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7236000.0000, 
sim time next is 7236600.0000, 
raw observation next is [23.7, 84.66666666666667, 1.0, 2.0, 0.3761233759742084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 570926.7520654108, 570926.7520654103, 172202.9189744716], 
processed observation next is [1.0, 0.782608695652174, 0.3222748815165877, 0.8466666666666667, 1.0, 1.0, 0.24834141683639568, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1585907644626141, 0.15859076446261397, 0.25701928205145014], 
reward next is 0.7430, 
noisyNet noise sample is [array([-0.12263275], dtype=float32), 0.8283387]. 
=============================================
[2019-03-26 16:41:19,487] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1241796: loss 0.0115
[2019-03-26 16:41:19,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1241797: learning rate 0.0000
[2019-03-26 16:41:19,587] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1241840: loss -113.7894
[2019-03-26 16:41:19,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1241840: learning rate 0.0000
[2019-03-26 16:41:19,684] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1241885: loss 0.0261
[2019-03-26 16:41:19,687] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1241886: learning rate 0.0000
[2019-03-26 16:41:19,709] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1241896: loss 0.0307
[2019-03-26 16:41:19,712] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1241896: learning rate 0.0000
[2019-03-26 16:41:20,126] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242087: loss 0.0276
[2019-03-26 16:41:20,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242087: learning rate 0.0000
[2019-03-26 16:41:20,329] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1242183: loss 0.0392
[2019-03-26 16:41:20,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1242183: learning rate 0.0000
[2019-03-26 16:41:20,516] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242267: loss 0.0517
[2019-03-26 16:41:20,518] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242267: learning rate 0.0000
[2019-03-26 16:41:20,661] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1242330: loss 0.0462
[2019-03-26 16:41:20,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1242330: learning rate 0.0000
[2019-03-26 16:41:21,093] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1242526: loss 0.0289
[2019-03-26 16:41:21,098] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1242528: learning rate 0.0000
[2019-03-26 16:41:26,178] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1244846: loss 0.0612
[2019-03-26 16:41:26,182] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1244848: learning rate 0.0000
[2019-03-26 16:41:28,697] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1246072: loss -138.8221
[2019-03-26 16:41:28,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1246073: learning rate 0.0000
[2019-03-26 16:41:30,780] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1247029: loss -85.5685
[2019-03-26 16:41:30,784] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1247030: learning rate 0.0000
[2019-03-26 16:41:33,206] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8470223e-25 1.0000000e+00 2.3253836e-27 2.2933341e-28 2.8379478e-34], sum to 1.0000
[2019-03-26 16:41:33,218] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1393
[2019-03-26 16:41:33,227] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 93.0, 1.0, 2.0, 0.5546667040639084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783786.618631694, 783786.6186316933, 193719.7034768443], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7095600.0000, 
sim time next is 7096200.0000, 
raw observation next is [24.46666666666667, 93.16666666666667, 1.0, 2.0, 0.5610581789113944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793405.3547818691, 793405.3547818697, 194919.1804359521], 
processed observation next is [1.0, 0.13043478260869565, 0.3586097946287521, 0.9316666666666668, 1.0, 1.0, 0.47115443242336674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22039037632829697, 0.22039037632829714, 0.2909241499044061], 
reward next is 0.7091, 
noisyNet noise sample is [array([-0.82620686], dtype=float32), -0.82039285]. 
=============================================
[2019-03-26 16:41:34,252] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1248609: loss -58.2426
[2019-03-26 16:41:34,254] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1248610: learning rate 0.0000
[2019-03-26 16:41:34,287] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1248621: loss -204.8941
[2019-03-26 16:41:34,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1248622: learning rate 0.0000
[2019-03-26 16:41:34,320] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248634: loss -283.3388
[2019-03-26 16:41:34,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248635: learning rate 0.0000
[2019-03-26 16:41:36,476] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249622: loss -207.5164
[2019-03-26 16:41:36,481] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249623: learning rate 0.0000
[2019-03-26 16:41:36,966] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1249842: loss -25.3663
[2019-03-26 16:41:36,968] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1249842: learning rate 0.0000
[2019-03-26 16:41:37,081] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1249895: loss -121.4557
[2019-03-26 16:41:37,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1249895: learning rate 0.0000
[2019-03-26 16:41:37,181] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1249940: loss -159.9317
[2019-03-26 16:41:37,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1249940: learning rate 0.0000
[2019-03-26 16:41:37,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1249968: loss 0.2671
[2019-03-26 16:41:37,252] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1249968: learning rate 0.0000
[2019-03-26 16:41:37,314] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 16:41:37,316] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:41:37,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:37,318] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:41:37,319] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:37,320] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:41:37,320] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:37,321] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:41:37,322] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:37,322] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:41:37,323] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:41:37,349] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 16:41:37,373] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 16:41:37,374] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 16:41:37,417] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 16:41:37,438] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 16:41:46,195] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:41:46,197] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.46666666666667, 90.33333333333334, 1.0, 2.0, 0.2941708847964143, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474553.4666318129, 474553.4666318129, 165275.0677948915]
[2019-03-26 16:41:46,198] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:41:46,202] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.9360791e-28 1.0000000e+00 1.5744884e-29 8.9983597e-34 4.3431405e-37], sampled 0.7818404154300492
[2019-03-26 16:42:00,480] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:42:00,482] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.7, 90.0, 1.0, 2.0, 0.399558797126052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 592355.4035692798, 592355.4035692798, 173718.0696726892]
[2019-03-26 16:42:00,484] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:42:00,489] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9324789e-27 1.0000000e+00 3.1031101e-29 4.1940727e-33 9.3202141e-37], sampled 0.8415291322659414
[2019-03-26 16:42:05,366] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:42:05,369] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.5, 92.0, 1.0, 2.0, 0.4897628184162399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 684362.8373559648, 684362.8373559642, 182008.0208962008]
[2019-03-26 16:42:05,371] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:42:05,376] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.1758294e-28 1.0000000e+00 2.8502472e-29 1.1699242e-33 7.8319580e-37], sampled 0.25971341621510313
[2019-03-26 16:42:14,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:42:14,586] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.58219532166667, 99.36162347166668, 1.0, 2.0, 0.3818824357594956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583083.5259935156, 583083.5259935156, 173370.1294029953]
[2019-03-26 16:42:14,587] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:42:14,593] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8755260e-26 1.0000000e+00 2.3129966e-28 3.8128991e-31 7.1493589e-36], sampled 0.2401482211609718
[2019-03-26 16:42:23,730] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:42:23,731] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 75.0, 1.0, 2.0, 0.5964550567010019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833506.1528253664, 833506.1528253664, 200087.6766423961]
[2019-03-26 16:42:23,734] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:42:23,738] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8320511e-26 1.0000000e+00 3.1871507e-28 2.8057679e-30 1.5201155e-35], sampled 0.1924086047742063
[2019-03-26 16:42:45,435] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:42:45,436] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.2, 58.0, 1.0, 2.0, 0.981684507975525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104007, 1372186.440886367, 1372186.440886367, 293401.7799025718]
[2019-03-26 16:42:45,438] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:42:45,442] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1002524e-23 1.0000000e+00 8.9309593e-26 6.8906530e-27 5.6705881e-33], sampled 0.24570508005984326
[2019-03-26 16:43:24,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:43:24,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.5, 87.0, 1.0, 2.0, 0.5563811769863231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777485.0834530379, 777485.0834530379, 192900.2740255911]
[2019-03-26 16:43:24,422] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:43:24,425] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.4152452e-24 1.0000000e+00 4.0445060e-27 1.0404203e-27 1.9997795e-34], sampled 0.925037771763791
[2019-03-26 16:43:30,673] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00281135], dtype=float32), 0.08668875]
[2019-03-26 16:43:30,673] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.13333333333333, 62.66666666666667, 1.0, 2.0, 0.3219806676785508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 512923.9423055947, 512923.9423055941, 168054.2011367952]
[2019-03-26 16:43:30,674] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:43:30,679] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.4177615e-28 1.0000000e+00 1.0081781e-29 3.3299427e-34 2.9773971e-37], sampled 0.2953801310137244
[2019-03-26 16:43:31,577] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7917.0382 3161261453.4339 1708.0000
[2019-03-26 16:43:31,706] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.6693 2779025362.5069 924.0000
[2019-03-26 16:43:31,939] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.9044 2927079578.2911 1328.0000
[2019-03-26 16:43:32,198] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.4633 2842245442.8325 1123.0000
[2019-03-26 16:43:32,213] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8002.2513 3007279888.9140 1759.0000
[2019-03-26 16:43:33,229] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1250000, evaluation results [1250000.0, 7917.038175416618, 3161261453.4339027, 1708.0, 8258.904368393834, 2927079578.291114, 1328.0, 8663.669252491494, 2779025362.5069103, 924.0, 8002.251303381733, 3007279888.9139743, 1759.0, 8499.463279485526, 2842245442.8325047, 1123.0]
[2019-03-26 16:43:33,385] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250073: loss -145.0003
[2019-03-26 16:43:33,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250074: learning rate 0.0000
[2019-03-26 16:43:33,619] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1250174: loss -4.0288
[2019-03-26 16:43:33,620] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1250174: learning rate 0.0000
[2019-03-26 16:43:33,684] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250202: loss -79.3402
[2019-03-26 16:43:33,686] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250202: learning rate 0.0000
[2019-03-26 16:43:33,776] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1250244: loss -339.4450
[2019-03-26 16:43:33,777] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1250244: learning rate 0.0000
[2019-03-26 16:43:34,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5489401e-10 9.9999976e-01 3.1267537e-15 2.2460040e-07 9.1411419e-19], sum to 1.0000
[2019-03-26 16:43:34,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6387
[2019-03-26 16:43:34,043] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1717433.766390419 W.
[2019-03-26 16:43:34,048] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.26666666666667, 69.0, 1.0, 2.0, 0.6142449871174143, 1.0, 1.0, 0.6142449871174143, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1717433.766390419, 1717433.766390419, 339560.4262029286], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7122000.0000, 
sim time next is 7122600.0000, 
raw observation next is [28.35, 68.5, 1.0, 2.0, 0.3979176524096324, 1.0, 2.0, 0.3979176524096324, 1.0, 1.0, 0.6681151880385822, 6.9112, 6.9112, 170.5573041426782, 1668833.468276062, 1668833.468276062, 348459.6817372458], 
processed observation next is [1.0, 0.43478260869565216, 0.5426540284360191, 0.685, 1.0, 1.0, 0.2745995812164246, 1.0, 1.0, 0.2745995812164246, 1.0, 0.5, 0.5952624244372953, 0.0, 0.0, 0.8375144448122397, 0.46356485229890615, 0.46356485229890615, 0.5200890772197698], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6643363], dtype=float32), -0.70628035]. 
=============================================
[2019-03-26 16:43:34,322] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1250486: loss -173.9926
[2019-03-26 16:43:34,325] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1250488: learning rate 0.0000
[2019-03-26 16:43:34,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6673700e-23 1.0000000e+00 8.4341754e-26 7.7188178e-26 6.1997622e-33], sum to 1.0000
[2019-03-26 16:43:34,969] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3881
[2019-03-26 16:43:34,975] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 91.16666666666667, 1.0, 2.0, 0.4740211407467417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663354.1910249898, 663354.1910249904, 179754.1539608379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7089000.0000, 
sim time next is 7089600.0000, 
raw observation next is [24.93333333333333, 91.33333333333334, 1.0, 2.0, 0.4742863803956965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664048.6545583527, 664048.6545583534, 179835.4786827572], 
processed observation next is [1.0, 0.043478260869565216, 0.38072669826224315, 0.9133333333333334, 1.0, 1.0, 0.3666100968622849, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1844579595995424, 0.1844579595995426, 0.2684111622130705], 
reward next is 0.7316, 
noisyNet noise sample is [array([0.09596414], dtype=float32), -0.43299377]. 
=============================================
[2019-03-26 16:43:39,133] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1252615: loss -125.2922
[2019-03-26 16:43:39,137] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1252616: learning rate 0.0000
[2019-03-26 16:43:39,674] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1770833e-24 1.0000000e+00 5.8627411e-27 8.2356555e-26 4.7578924e-34], sum to 1.0000
[2019-03-26 16:43:39,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6243
[2019-03-26 16:43:39,688] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 83.83333333333333, 1.0, 2.0, 0.4762583401505951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665486.6434327345, 665486.643432734, 179959.6477878545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7153800.0000, 
sim time next is 7154400.0000, 
raw observation next is [26.1, 83.66666666666667, 1.0, 2.0, 0.4759774167766197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665093.9799112281, 665093.9799112281, 179917.5814764027], 
processed observation next is [1.0, 0.8260869565217391, 0.4360189573459717, 0.8366666666666667, 1.0, 1.0, 0.3686474900923129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18474832775311892, 0.18474832775311892, 0.26853370369612345], 
reward next is 0.7315, 
noisyNet noise sample is [array([-0.7665031], dtype=float32), 0.109741956]. 
=============================================
[2019-03-26 16:43:42,360] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1254031: loss 0.0686
[2019-03-26 16:43:42,364] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1254033: learning rate 0.0000
[2019-03-26 16:43:44,469] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1254959: loss 0.0839
[2019-03-26 16:43:44,473] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1254959: learning rate 0.0000
[2019-03-26 16:43:46,153] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2681174e-28 1.0000000e+00 1.0978244e-30 1.9521222e-33 1.2416983e-38], sum to 1.0000
[2019-03-26 16:43:46,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9953
[2019-03-26 16:43:46,171] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.23333333333333, 67.0, 1.0, 2.0, 0.4388319086265688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626804.18747406, 626804.18747406, 176327.478970654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7579200.0000, 
sim time next is 7579800.0000, 
raw observation next is [28.1, 68.0, 1.0, 2.0, 0.4437078962263412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632638.4604049121, 632638.4604049115, 176878.8515653623], 
processed observation next is [0.0, 0.7391304347826086, 0.5308056872037916, 0.68, 1.0, 1.0, 0.32976854967029057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17573290566803115, 0.175732905668031, 0.2639982859184512], 
reward next is 0.7360, 
noisyNet noise sample is [array([0.39932477], dtype=float32), -0.73755145]. 
=============================================
[2019-03-26 16:43:48,021] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1256543: loss 0.0229
[2019-03-26 16:43:48,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1256543: learning rate 0.0000
[2019-03-26 16:43:48,047] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1256553: loss 0.0191
[2019-03-26 16:43:48,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1256554: learning rate 0.0000
[2019-03-26 16:43:48,094] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256572: loss 0.0161
[2019-03-26 16:43:48,095] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256572: learning rate 0.0000
[2019-03-26 16:43:50,161] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.7350035e-25 1.0000000e+00 5.1214579e-28 8.2438781e-29 4.6282295e-35], sum to 1.0000
[2019-03-26 16:43:50,167] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9111
[2019-03-26 16:43:50,172] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.0, 1.0, 2.0, 0.4834909667026012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768347.1244336583, 768347.1244336583, 191563.4716844815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7390800.0000, 
sim time next is 7391400.0000, 
raw observation next is [20.98333333333333, 92.0, 1.0, 2.0, 0.6234993951955499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991406.5545155546, 991406.5545155553, 219040.6241461265], 
processed observation next is [1.0, 0.5652173913043478, 0.1935229067930489, 0.92, 1.0, 1.0, 0.5463848134886142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27539070958765405, 0.2753907095876542, 0.3269263046957112], 
reward next is 0.6731, 
noisyNet noise sample is [array([-0.47610766], dtype=float32), 0.0695659]. 
=============================================
[2019-03-26 16:43:50,436] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257617: loss 0.0053
[2019-03-26 16:43:50,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257617: learning rate 0.0000
[2019-03-26 16:43:50,767] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1257765: loss -82.7617
[2019-03-26 16:43:50,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1257766: learning rate 0.0000
[2019-03-26 16:43:50,867] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1257806: loss 0.0075
[2019-03-26 16:43:50,871] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1257807: learning rate 0.0000
[2019-03-26 16:43:51,171] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1257942: loss 0.0140
[2019-03-26 16:43:51,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1257944: learning rate 0.0000
[2019-03-26 16:43:51,189] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1257948: loss 0.0137
[2019-03-26 16:43:51,191] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1257949: learning rate 0.0000
[2019-03-26 16:43:51,348] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258020: loss 0.0124
[2019-03-26 16:43:51,350] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258020: learning rate 0.0000
[2019-03-26 16:43:51,620] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1258141: loss 0.0059
[2019-03-26 16:43:51,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1258141: learning rate 0.0000
[2019-03-26 16:43:51,648] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3637522e-26 1.0000000e+00 1.6215651e-28 3.7188946e-31 1.6539266e-35], sum to 1.0000
[2019-03-26 16:43:51,658] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0357
[2019-03-26 16:43:51,665] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 89.33333333333334, 1.0, 2.0, 0.411619710444492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 621164.9836193005, 621164.9836193, 176674.533196675], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7363200.0000, 
sim time next is 7363800.0000, 
raw observation next is [23.0, 89.5, 1.0, 2.0, 0.4182794883963654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634819.724282945, 634819.7242829445, 178037.3241111551], 
processed observation next is [1.0, 0.21739130434782608, 0.28909952606635075, 0.895, 1.0, 1.0, 0.29913191373056075, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17633881230081808, 0.1763388123008179, 0.26572734941963444], 
reward next is 0.7343, 
noisyNet noise sample is [array([-0.52133876], dtype=float32), 1.5071379]. 
=============================================
[2019-03-26 16:43:51,880] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258259: loss 0.0108
[2019-03-26 16:43:51,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258261: learning rate 0.0000
[2019-03-26 16:43:51,941] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1258284: loss 0.0095
[2019-03-26 16:43:51,945] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1258284: learning rate 0.0000
[2019-03-26 16:43:52,611] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1258580: loss 0.0202
[2019-03-26 16:43:52,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1258580: learning rate 0.0000
[2019-03-26 16:43:53,925] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7585784e-24 1.0000000e+00 7.3235990e-27 8.1566080e-28 5.8707769e-34], sum to 1.0000
[2019-03-26 16:43:53,935] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2129
[2019-03-26 16:43:53,940] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 92.16666666666667, 1.0, 2.0, 0.5690211435355871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912923.0050732447, 912923.0050732447, 208190.4419254536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7377000.0000, 
sim time next is 7377600.0000, 
raw observation next is [20.63333333333333, 92.33333333333334, 1.0, 2.0, 0.5817624780692395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 931735.4583651241, 931735.4583651234, 210682.2938787546], 
processed observation next is [1.0, 0.391304347826087, 0.17693522906793036, 0.9233333333333335, 1.0, 1.0, 0.49609937116775843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25881540510142337, 0.25881540510142315, 0.3144511848936636], 
reward next is 0.6855, 
noisyNet noise sample is [array([-1.0688276], dtype=float32), -0.9304759]. 
=============================================
[2019-03-26 16:43:58,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:43:58,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:43:58,842] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 16:43:59,949] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1261933: loss -107.3678
[2019-03-26 16:43:59,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1261935: learning rate 0.0000
[2019-03-26 16:44:00,379] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1432101e-15 1.0000000e+00 2.6217846e-16 1.2745269e-18 3.7813579e-20], sum to 1.0000
[2019-03-26 16:44:00,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-26 16:44:00,392] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 85.0, 1.0, 2.0, 0.3190807446338743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518586.0455341383, 518586.0455341383, 168404.7934616398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 8400.0000, 
sim time next is 9000.0000, 
raw observation next is [20.8, 85.0, 1.0, 2.0, 0.2933257951983452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476224.7608408195, 476224.7608408201, 165353.8095584711], 
processed observation next is [1.0, 0.08695652173913043, 0.1848341232227489, 0.85, 1.0, 1.0, 0.14858529541969298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13228465578911652, 0.1322846557891167, 0.24679673068428523], 
reward next is 0.7532, 
noisyNet noise sample is [array([1.264838], dtype=float32), 0.49351665]. 
=============================================
[2019-03-26 16:44:00,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[40.230286]
 [37.95305 ]
 [35.895775]
 [32.674187]
 [29.864029]], R is [[44.29244232]
 [44.59816742]
 [44.88974762]
 [45.19776535]
 [45.50297546]].
[2019-03-26 16:44:02,055] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1262897: loss -63.6479
[2019-03-26 16:44:02,057] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1262897: learning rate 0.0000
[2019-03-26 16:44:04,248] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7924789e-25 1.0000000e+00 9.7686633e-28 3.0489132e-28 8.7622221e-35], sum to 1.0000
[2019-03-26 16:44:04,257] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6323
[2019-03-26 16:44:04,262] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 63.5, 1.0, 2.0, 0.4357637878818251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625157.9579594301, 625157.9579594308, 176242.0069399577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7576200.0000, 
sim time next is 7576800.0000, 
raw observation next is [28.66666666666667, 64.0, 1.0, 2.0, 0.4366183348891791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 626130.4426361421, 626130.4426361421, 176330.9720670191], 
processed observation next is [0.0, 0.6956521739130435, 0.5576619273301741, 0.64, 1.0, 1.0, 0.3212269095050351, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17392512295448392, 0.17392512295448392, 0.2631805553239091], 
reward next is 0.7368, 
noisyNet noise sample is [array([-2.6577249], dtype=float32), 0.066184565]. 
=============================================
[2019-03-26 16:44:05,455] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1264458: loss 11.2259
[2019-03-26 16:44:05,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1264458: learning rate 0.0000
[2019-03-26 16:44:05,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264483: loss -184.5703
[2019-03-26 16:44:05,499] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264483: learning rate 0.0000
[2019-03-26 16:44:05,520] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1264492: loss 40.7626
[2019-03-26 16:44:05,522] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1264493: learning rate 0.0000
[2019-03-26 16:44:06,939] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2620683e-24 1.0000000e+00 1.6900457e-26 2.2909742e-27 2.7533536e-33], sum to 1.0000
[2019-03-26 16:44:06,948] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9120
[2019-03-26 16:44:06,956] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 94.5, 1.0, 2.0, 0.4154186491944362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608823.8065641823, 608823.8065641823, 175044.1358627848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7623000.0000, 
sim time next is 7623600.0000, 
raw observation next is [23.53333333333333, 94.33333333333334, 1.0, 2.0, 0.4169726614628092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 609649.1494993184, 609649.1494993191, 175079.6372785865], 
processed observation next is [1.0, 0.21739130434782608, 0.3143759873617693, 0.9433333333333335, 1.0, 1.0, 0.2975574234491677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1693469859720329, 0.1693469859720331, 0.2613128914605769], 
reward next is 0.7387, 
noisyNet noise sample is [array([-0.5589435], dtype=float32), -1.3815924]. 
=============================================
[2019-03-26 16:44:07,675] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1265471: loss 77.1013
[2019-03-26 16:44:07,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1265471: learning rate 0.0000
[2019-03-26 16:44:08,127] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1265680: loss -176.6924
[2019-03-26 16:44:08,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1265683: learning rate 0.0000
[2019-03-26 16:44:08,206] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6856090e-11 1.0000000e+00 1.0746702e-15 1.3704975e-08 2.6902775e-20], sum to 1.0000
[2019-03-26 16:44:08,215] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1994
[2019-03-26 16:44:08,222] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333333, 69.33333333333334, 1.0, 2.0, 1.001186683993268, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510396, 1399464.308997178, 1399464.308997178, 299284.0403970168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7640400.0000, 
sim time next is 7641000.0000, 
raw observation next is [28.8, 68.0, 1.0, 2.0, 1.002293515819617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1401012.465596366, 1401012.465596366, 299621.9176068075], 
processed observation next is [1.0, 0.43478260869565216, 0.5639810426540285, 0.68, 1.0, 1.0, 1.0027632720718276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.38917012933232387, 0.38917012933232387, 0.4471968919504589], 
reward next is 0.5528, 
noisyNet noise sample is [array([-1.310963], dtype=float32), 0.9610523]. 
=============================================
[2019-03-26 16:44:08,238] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[46.02854 ]
 [43.634926]
 [43.14828 ]
 [45.762344]
 [46.7044  ]], R is [[47.9046936 ]
 [47.97895432]
 [47.49916458]
 [47.02417374]
 [46.55393219]].
[2019-03-26 16:44:08,502] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1265850: loss 3.5448
[2019-03-26 16:44:08,506] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1265850: learning rate 0.0000
[2019-03-26 16:44:08,586] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1265891: loss -11.9502
[2019-03-26 16:44:08,589] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1265891: learning rate 0.0000
[2019-03-26 16:44:08,644] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265919: loss -49.2727
[2019-03-26 16:44:08,646] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265920: learning rate 0.0000
[2019-03-26 16:44:08,847] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1266014: loss 43.1109
[2019-03-26 16:44:08,850] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1266014: learning rate 0.0000
[2019-03-26 16:44:08,965] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266068: loss 23.0525
[2019-03-26 16:44:08,967] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266069: learning rate 0.0000
[2019-03-26 16:44:09,131] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1266145: loss 11.1170
[2019-03-26 16:44:09,137] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1266146: learning rate 0.0000
[2019-03-26 16:44:09,553] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:09,554] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:09,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 16:44:09,723] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1266399: loss 26.4656
[2019-03-26 16:44:09,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1266400: learning rate 0.0000
[2019-03-26 16:44:13,591] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.2595521e-25 1.0000000e+00 3.8900087e-27 2.6854987e-28 7.4077490e-35], sum to 1.0000
[2019-03-26 16:44:13,604] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6800
[2019-03-26 16:44:13,610] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 89.0, 1.0, 2.0, 0.2985970192955962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476385.0334150187, 476385.0334150187, 165377.1718629935], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 243000.0000, 
sim time next is 243600.0000, 
raw observation next is [21.16666666666667, 89.0, 1.0, 2.0, 0.2972226638213607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474524.5789758748, 474524.5789758748, 165249.8959981345], 
processed observation next is [0.0, 0.8260869565217391, 0.2022116903633494, 0.89, 1.0, 1.0, 0.1532803178570611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13181238304885412, 0.13181238304885412, 0.24664163581811122], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.59441346], dtype=float32), -0.14781319]. 
=============================================
[2019-03-26 16:44:16,415] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8230349e-24 1.0000000e+00 3.7516010e-28 9.2253967e-26 1.3987257e-34], sum to 1.0000
[2019-03-26 16:44:16,426] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8219
[2019-03-26 16:44:16,431] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 80.0, 1.0, 2.0, 0.5262272140191933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735333.4575026871, 735333.4575026877, 187808.4575748914], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7843200.0000, 
sim time next is 7843800.0000, 
raw observation next is [28.33333333333333, 81.0, 1.0, 2.0, 0.527755072407867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737469.1801709644, 737469.1801709644, 188060.026803519], 
processed observation next is [1.0, 0.782608695652174, 0.541864139020537, 0.81, 1.0, 1.0, 0.4310302077203217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20485255004749012, 0.20485255004749012, 0.28068660716943133], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.25379997], dtype=float32), 0.65589505]. 
=============================================
[2019-03-26 16:44:18,091] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:18,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:18,150] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 16:44:19,826] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:19,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:19,895] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 16:44:22,479] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:22,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:22,557] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 16:44:22,686] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:22,686] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:22,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 16:44:22,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:22,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:22,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6035844e-08 2.3846839e-01 9.7252156e-15 7.6153147e-01 3.2075953e-17], sum to 1.0000
[2019-03-26 16:44:22,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9266
[2019-03-26 16:44:22,800] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.23333333333333, 69.5, 1.0, 2.0, 0.70253160055412, 1.0, 2.0, 0.70253160055412, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1964510.120455123, 1964510.120455123, 375209.3077030235], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7913400.0000, 
sim time next is 7914000.0000, 
raw observation next is [30.26666666666667, 69.0, 1.0, 2.0, 0.7797654877391573, 1.0, 2.0, 0.7797654877391573, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2180701.372356977, 2180701.372356977, 410137.7872001316], 
processed observation next is [1.0, 0.6086956521739131, 0.6334913112164299, 0.69, 1.0, 1.0, 0.734657214143563, 1.0, 1.0, 0.734657214143563, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6057503812102714, 0.6057503812102714, 0.6121459510449726], 
reward next is 0.3879, 
noisyNet noise sample is [array([1.0480868], dtype=float32), 0.90252805]. 
=============================================
[2019-03-26 16:44:22,814] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.013565]
 [45.38228 ]
 [46.110794]
 [45.05654 ]
 [43.860947]], R is [[47.22753906]
 [47.19525146]
 [46.72330093]
 [46.25606918]
 [46.16488266]].
[2019-03-26 16:44:22,844] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 16:44:24,237] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 16:44:24,490] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,491] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,555] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 16:44:24,745] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,746] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,762] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,762] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,798] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 16:44:24,821] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,823] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,842] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 16:44:24,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 16:44:24,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,939] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:24,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:24,971] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 16:44:25,019] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 16:44:25,129] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:25,129] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:25,138] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 16:44:25,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 16:44:25,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:25,409] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 16:44:27,057] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 16:44:27,058] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:44:27,059] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:44:27,059] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:44:27,060] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:27,061] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:44:27,060] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:27,061] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:27,064] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:27,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:44:27,069] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:44:27,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 16:44:27,124] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 16:44:27,125] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 16:44:27,146] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 16:44:27,147] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 16:45:09,810] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0067922], dtype=float32), 0.09720166]
[2019-03-26 16:45:09,811] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.921223815, 89.03968836, 1.0, 2.0, 0.3320741720577519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522442.7216927646, 522442.7216927646, 168692.0317189643]
[2019-03-26 16:45:09,812] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:45:09,815] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.6908623e-27 1.0000000e+00 2.9173716e-29 7.0753362e-31 1.3717019e-36], sampled 0.6380254095142233
[2019-03-26 16:45:34,169] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0067922], dtype=float32), 0.09720166]
[2019-03-26 16:45:34,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5256229792935879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734488.8268748581, 734488.8268748581, 187707.9301477585]
[2019-03-26 16:45:34,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:45:34,176] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.7311045e-25 1.0000000e+00 3.4477093e-28 4.0241897e-28 3.2330962e-35], sampled 0.24236163569512192
[2019-03-26 16:46:08,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0067922], dtype=float32), 0.09720166]
[2019-03-26 16:46:08,561] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.2, 68.5, 1.0, 2.0, 0.6421588304166365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 897401.1097151244, 897401.1097151238, 208863.1365224729]
[2019-03-26 16:46:08,562] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:46:08,565] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.7795101e-25 1.0000000e+00 6.5160763e-28 1.6911670e-27 8.2846471e-35], sampled 0.15414765262610752
[2019-03-26 16:46:12,559] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0067922], dtype=float32), 0.09720166]
[2019-03-26 16:46:12,562] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.05, 83.5, 1.0, 2.0, 0.4759218724960754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665866.1073400227, 665866.1073400221, 180019.0258235217]
[2019-03-26 16:46:12,562] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:46:12,565] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2751431e-27 1.0000000e+00 1.1763170e-29 3.4971248e-31 1.5266225e-37], sampled 0.32810376466203917
[2019-03-26 16:46:22,905] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0067922], dtype=float32), 0.09720166]
[2019-03-26 16:46:22,906] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.03333333333333, 63.0, 1.0, 2.0, 0.3076586472988589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490687.340140153, 490687.340140153, 166404.1403548379]
[2019-03-26 16:46:22,907] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:46:22,909] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.37935852e-26 1.00000000e+00 1.69279913e-28 2.52720287e-29
 1.06487756e-35], sampled 0.14861295952439058
[2019-03-26 16:46:23,998] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.7036 2841741778.0504 1110.0000
[2019-03-26 16:46:24,088] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7925.3440 3160281436.8926 1677.0000
[2019-03-26 16:46:24,187] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.0899 2778883850.5504 921.0000
[2019-03-26 16:46:24,206] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8007.4233 3006475294.8223 1738.0000
[2019-03-26 16:46:24,206] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8262.2263 2926867718.0772 1322.0000
[2019-03-26 16:46:25,222] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1275000, evaluation results [1275000.0, 7925.344025175199, 3160281436.892563, 1677.0, 8262.226279205495, 2926867718.077202, 1322.0, 8667.089880259433, 2778883850.5504317, 921.0, 8007.423287140944, 3006475294.822292, 1738.0, 8502.703635875016, 2841741778.050392, 1110.0]
[2019-03-26 16:46:28,560] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.3477786e-24 1.0000000e+00 1.5179487e-27 3.1198623e-26 1.3025428e-34], sum to 1.0000
[2019-03-26 16:46:28,569] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-26 16:46:28,576] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.26666666666667, 84.33333333333334, 1.0, 2.0, 0.358997254768441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 552483.769309904, 552483.7693099045, 170839.8730776006], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 74400.0000, 
sim time next is 75000.0000, 
raw observation next is [23.18333333333334, 84.66666666666667, 1.0, 2.0, 0.3561662911640412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548715.2445120797, 548715.2445120803, 170540.4556415872], 
processed observation next is [1.0, 0.8695652173913043, 0.29778830963665126, 0.8466666666666667, 1.0, 1.0, 0.2242967363422183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15242090125335547, 0.15242090125335564, 0.2545379934949063], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.6164742], dtype=float32), -0.24683256]. 
=============================================
[2019-03-26 16:46:28,589] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.80465 ]
 [75.64051 ]
 [75.523705]
 [75.790955]
 [75.678734]], R is [[75.97091675]
 [75.95622253]
 [75.94140625]
 [75.92648315]
 [75.91153717]].
[2019-03-26 16:46:39,624] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6108777e-25 1.0000000e+00 1.0094260e-27 7.5016459e-28 7.7676977e-35], sum to 1.0000
[2019-03-26 16:46:39,633] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0105
[2019-03-26 16:46:39,644] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 91.0, 1.0, 2.0, 0.2866933853602713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460693.7622599908, 460693.7622599914, 164317.3227020783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 253800.0000, 
sim time next is 254400.0000, 
raw observation next is [20.56666666666667, 91.0, 1.0, 2.0, 0.2856054866037849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459242.3688511135, 459242.3688511135, 164219.7473754493], 
processed observation next is [0.0, 0.9565217391304348, 0.17377567140600336, 0.91, 1.0, 1.0, 0.1392837187997408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12756732468086485, 0.12756732468086485, 0.2451041005603721], 
reward next is 0.7549, 
noisyNet noise sample is [array([-1.396391], dtype=float32), 1.3189178]. 
=============================================
[2019-03-26 16:46:46,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0669589e-21 1.0000000e+00 1.1632004e-25 1.7430445e-23 2.2653232e-32], sum to 1.0000
[2019-03-26 16:46:46,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2298
[2019-03-26 16:46:46,905] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333333, 66.5, 1.0, 2.0, 0.2553916522124396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417912.0570407765, 417912.0570407765, 161435.166928166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 582600.0000, 
sim time next is 583200.0000, 
raw observation next is [22.7, 67.0, 1.0, 2.0, 0.255544752789682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 418460.2671677591, 418460.2671677597, 161455.1958298487], 
processed observation next is [1.0, 0.782608695652174, 0.27488151658767773, 0.67, 1.0, 1.0, 0.1030659672164843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11623896310215531, 0.11623896310215548, 0.24097790422365478], 
reward next is 0.7590, 
noisyNet noise sample is [array([-1.1004494], dtype=float32), 0.8911048]. 
=============================================
[2019-03-26 16:46:50,660] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2425423e-22 1.0000000e+00 1.5284966e-25 4.9406206e-25 1.1786644e-32], sum to 1.0000
[2019-03-26 16:46:50,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5295
[2019-03-26 16:46:50,677] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2393795938962013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 394980.12064865, 394980.1206486494, 159841.9166773104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 437400.0000, 
sim time next is 438000.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2382350530745168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 393091.6959793719, 393091.6959793713, 159733.593356395], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08221090731869495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10919213777204775, 0.10919213777204759, 0.23840834829312685], 
reward next is 0.7616, 
noisyNet noise sample is [array([-2.037385], dtype=float32), -1.2204063]. 
=============================================
[2019-03-26 16:46:50,697] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.84604 ]
 [72.907455]
 [72.978806]
 [73.07781 ]
 [73.12039 ]], R is [[72.83654022]
 [72.86960602]
 [72.90228271]
 [72.93475342]
 [72.9669342 ]].
[2019-03-26 16:46:53,164] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2268635e-23 1.0000000e+00 4.2492586e-27 2.0405838e-26 1.6884158e-33], sum to 1.0000
[2019-03-26 16:46:53,172] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6585
[2019-03-26 16:46:53,178] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 70.0, 1.0, 2.0, 0.2508041021938299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412422.978333547, 412422.9783335476, 160985.8883752157], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 586800.0000, 
sim time next is 587400.0000, 
raw observation next is [21.75, 70.5, 1.0, 2.0, 0.2499026127298319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411276.6103205053, 411276.6103205059, 160891.6280815469], 
processed observation next is [1.0, 0.8260869565217391, 0.2298578199052133, 0.705, 1.0, 1.0, 0.09626820810823121, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11424350286680703, 0.1142435028668072, 0.240136758330667], 
reward next is 0.7599, 
noisyNet noise sample is [array([0.23891309], dtype=float32), -0.15897824]. 
=============================================
[2019-03-26 16:46:58,051] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.4529236e-22 1.0000000e+00 2.2734949e-25 3.4382731e-24 1.3866250e-32], sum to 1.0000
[2019-03-26 16:46:58,060] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8570
[2019-03-26 16:46:58,069] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 49.33333333333334, 1.0, 2.0, 0.6256760036857524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1024025.362968306, 1024025.362968305, 221193.4819674156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 740400.0000, 
sim time next is 741000.0000, 
raw observation next is [25.93333333333333, 48.66666666666666, 1.0, 2.0, 0.6237115175825323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021657.733317938, 1021657.733317938, 220771.0262853622], 
processed observation next is [1.0, 0.5652173913043478, 0.42812006319115314, 0.4866666666666666, 1.0, 1.0, 0.5466403826295569, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28379381481053834, 0.28379381481053834, 0.3295089944557645], 
reward next is 0.6705, 
noisyNet noise sample is [array([-0.03349992], dtype=float32), 1.8178806]. 
=============================================
[2019-03-26 16:46:58,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.61923 ]
 [69.14755 ]
 [70.061   ]
 [71.31722 ]
 [72.375786]], R is [[68.26589203]
 [68.25309753]
 [68.23947144]
 [68.23339081]
 [68.24957275]].
[2019-03-26 16:47:10,019] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0077157e-23 1.0000000e+00 9.9762499e-26 7.4260358e-25 9.9328813e-34], sum to 1.0000
[2019-03-26 16:47:10,025] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7054
[2019-03-26 16:47:10,031] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 87.0, 1.0, 2.0, 0.2569188624737023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 421992.8074784896, 421992.807478489, 161600.1278023405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772800.0000, 
sim time next is 773400.0000, 
raw observation next is [19.66666666666667, 87.5, 1.0, 2.0, 0.2563921792308387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421159.7838542316, 421159.7838542322, 161546.9231726904], 
processed observation next is [1.0, 0.9565217391304348, 0.1311216429699845, 0.875, 1.0, 1.0, 0.10408696292872129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11698882884839766, 0.11698882884839784, 0.24111481070550808], 
reward next is 0.7589, 
noisyNet noise sample is [array([-1.7221875], dtype=float32), -0.61811715]. 
=============================================
[2019-03-26 16:47:12,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1939865e-26 1.0000000e+00 5.8585543e-29 2.2396342e-30 2.1955552e-36], sum to 1.0000
[2019-03-26 16:47:12,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-26 16:47:12,775] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 68.0, 1.0, 2.0, 0.3132407388071468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 493350.3158975887, 493350.3158975881, 166485.9569494055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 916800.0000, 
sim time next is 917400.0000, 
raw observation next is [24.75, 68.5, 1.0, 2.0, 0.3146142390191519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495163.9308618236, 495163.9308618236, 166612.2068282489], 
processed observation next is [0.0, 0.6086956521739131, 0.3720379146919432, 0.685, 1.0, 1.0, 0.17423402291464085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13754553635050656, 0.13754553635050656, 0.2486749355645506], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.3916247], dtype=float32), -1.5951742]. 
=============================================
[2019-03-26 16:47:16,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0549603e-26 1.0000000e+00 1.9108310e-28 8.8356136e-31 2.5760172e-35], sum to 1.0000
[2019-03-26 16:47:16,050] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3844
[2019-03-26 16:47:16,056] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 88.66666666666667, 1.0, 2.0, 0.2878154077582552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461737.2882740874, 461737.2882740867, 164383.8237235454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 876000.0000, 
sim time next is 876600.0000, 
raw observation next is [20.95, 88.5, 1.0, 2.0, 0.2873202962730949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 164354.9904660491], 
processed observation next is [0.0, 0.13043478260869565, 0.19194312796208532, 0.885, 1.0, 1.0, 0.1413497545458975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12813353795418456, 0.1281335379541844, 0.24530595591947624], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.00453624], dtype=float32), -0.71895367]. 
=============================================
[2019-03-26 16:47:17,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5879834e-27 1.0000000e+00 1.3472349e-29 5.9729979e-33 7.5855519e-37], sum to 1.0000
[2019-03-26 16:47:17,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5014
[2019-03-26 16:47:17,345] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 87.66666666666667, 1.0, 2.0, 0.2817372280340162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 453932.0935879869, 453932.0935879875, 163863.0852093133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 879600.0000, 
sim time next is 880200.0000, 
raw observation next is [20.85, 87.5, 1.0, 2.0, 0.2801559704741876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 451697.7751915869, 451697.7751915863, 163713.5292860979], 
processed observation next is [0.0, 0.17391304347826086, 0.18720379146919444, 0.875, 1.0, 1.0, 0.13271803671588867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12547160421988524, 0.12547160421988507, 0.24434855117328047], 
reward next is 0.7557, 
noisyNet noise sample is [array([-0.35796294], dtype=float32), -0.8886723]. 
=============================================
[2019-03-26 16:47:20,813] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 16:47:20,818] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:47:20,818] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:20,819] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:47:20,820] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:20,820] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:47:20,821] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:20,821] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:47:20,823] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:47:20,823] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:20,825] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:47:20,845] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 16:47:20,846] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 16:47:20,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 16:47:20,915] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 16:47:20,944] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 16:47:24,890] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:47:24,891] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.35, 54.16666666666667, 1.0, 2.0, 0.2730321447827717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 444709.1922632132, 444709.1922632132, 163196.7015763128]
[2019-03-26 16:47:24,893] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:47:24,895] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.8776276e-27 1.0000000e+00 1.4259366e-28 1.1430769e-31 1.1494236e-35], sampled 0.9531677445740415
[2019-03-26 16:47:41,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:47:41,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.83333333333334, 77.33333333333334, 1.0, 2.0, 0.4147932769288407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607054.8536704936, 607054.8536704936, 174851.578997805]
[2019-03-26 16:47:41,769] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:47:41,772] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0566846e-24 1.0000000e+00 3.7279640e-27 3.7281347e-27 5.0657548e-34], sampled 0.14703618796139883
[2019-03-26 16:47:44,045] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:47:44,046] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.21666666666667, 85.66666666666667, 1.0, 2.0, 0.4293062316776254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 637860.5258803039, 637860.5258803039, 178055.2953609847]
[2019-03-26 16:47:44,047] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:47:44,049] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9311985e-25 1.0000000e+00 1.0688092e-27 2.8397419e-29 1.1028591e-34], sampled 0.7171597079499398
[2019-03-26 16:47:47,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:47:47,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.14360310166667, 98.43295793833333, 1.0, 2.0, 0.3541784508979315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550993.7308366561, 550993.7308366561, 170866.1997189819]
[2019-03-26 16:47:47,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 16:47:47,529] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5987910e-22 1.0000000e+00 3.0128797e-25 6.4893489e-24 5.0950239e-32], sampled 0.9556179786005613
[2019-03-26 16:47:56,016] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:47:56,017] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.664261615, 60.41037913666666, 1.0, 2.0, 0.5528217545511732, 0.0, 2.0, 0.0, 1.0, 2.0, 0.94212835523286, 6.911200000000001, 6.9112, 168.9129104499568, 1545580.938372232, 1545580.938372231, 334594.793755024]
[2019-03-26 16:47:56,018] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:47:56,020] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.6028021e-13 1.0000000e+00 3.9157237e-18 1.7522211e-08 5.4767515e-22], sampled 0.26949302218125604
[2019-03-26 16:48:05,036] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:48:05,039] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 100.0, 1.0, 2.0, 0.3338099701619507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518466.0327573584, 518466.0327573584, 168212.4646880443]
[2019-03-26 16:48:05,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:48:05,043] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5186793e-26 1.0000000e+00 2.0455386e-28 2.7777895e-31 1.3591550e-35], sampled 0.23929370628521096
[2019-03-26 16:48:09,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:48:09,658] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.33333333333333, 57.66666666666667, 1.0, 2.0, 0.568539845456947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794481.9178559047, 794481.9178559047, 195030.8973803966]
[2019-03-26 16:48:09,659] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:48:09,663] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.3640772e-25 1.0000000e+00 1.3051089e-27 4.4713964e-28 1.9183479e-34], sampled 0.7009227993071749
[2019-03-26 16:48:51,766] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:48:51,767] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.83333333333333, 85.33333333333334, 1.0, 2.0, 0.541440628432529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756599.7782903083, 756599.7782903077, 190344.1061927358]
[2019-03-26 16:48:51,768] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:48:51,770] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6405632e-25 1.0000000e+00 8.5229478e-28 2.5352171e-29 9.3031734e-35], sampled 0.669645549710388
[2019-03-26 16:48:55,063] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00590181], dtype=float32), 0.09511997]
[2019-03-26 16:48:55,067] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.43333333333334, 91.66666666666667, 1.0, 2.0, 0.5119765409746666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715413.3067144138, 715413.3067144138, 185492.6052715452]
[2019-03-26 16:48:55,070] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 16:48:55,072] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7987814e-21 1.0000000e+00 9.0799497e-25 1.1587601e-22 2.2904103e-31], sampled 0.999167896152747
[2019-03-26 16:49:16,595] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7943.4865 3158603484.2907 1634.0000
[2019-03-26 16:49:17,721] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.2966 2926602642.6446 1312.0000
[2019-03-26 16:49:17,837] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.0308 2778473588.5341 910.0000
[2019-03-26 16:49:17,984] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8508.2568 2841578914.3309 1104.0000
[2019-03-26 16:49:18,022] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8011.2627 3005983286.1728 1726.0000
[2019-03-26 16:49:19,038] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1300000, evaluation results [1300000.0, 7943.486473508794, 3158603484.290694, 1634.0, 8266.296635173643, 2926602642.6446285, 1312.0, 8671.030754246229, 2778473588.534067, 910.0, 8011.262670654944, 3005983286.172834, 1726.0, 8508.256822698584, 2841578914.3308616, 1104.0]
[2019-03-26 16:49:24,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0872928e-22 1.0000000e+00 2.1791618e-26 1.0928096e-24 5.3637690e-33], sum to 1.0000
[2019-03-26 16:49:24,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6122
[2019-03-26 16:49:24,359] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 96.83333333333334, 1.0, 2.0, 0.3595768559803624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 550032.7604994213, 550032.7604994206, 170536.1960255997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1029000.0000, 
sim time next is 1029600.0000, 
raw observation next is [21.9, 97.0, 1.0, 2.0, 0.3607928405584966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 551556.2841985874, 551556.2841985868, 170654.4179159135], 
processed observation next is [1.0, 0.9565217391304348, 0.23696682464454974, 0.97, 1.0, 1.0, 0.2298708922391525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15321007894405206, 0.1532100789440519, 0.25470808644166193], 
reward next is 0.7453, 
noisyNet noise sample is [array([-0.76421857], dtype=float32), 0.15779978]. 
=============================================
[2019-03-26 16:49:25,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1470542e-25 1.0000000e+00 1.1610713e-27 2.8125648e-28 1.8654790e-34], sum to 1.0000
[2019-03-26 16:49:25,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0088
[2019-03-26 16:49:25,540] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 96.5, 1.0, 2.0, 0.3325613554506282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517316.5723982737, 517316.5723982743, 168145.1584687701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [21.16666666666666, 96.33333333333334, 1.0, 2.0, 0.3280387250889422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512374.4978643529, 512374.4978643529, 167819.2174377652], 
processed observation next is [1.0, 0.13043478260869565, 0.2022116903633489, 0.9633333333333334, 1.0, 1.0, 0.19040810251679785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1423262494067647, 0.1423262494067647, 0.250476443936963], 
reward next is 0.7495, 
noisyNet noise sample is [array([0.2754815], dtype=float32), 1.4059979]. 
=============================================
[2019-03-26 16:49:25,554] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.59162 ]
 [74.53045 ]
 [74.434654]
 [74.363014]
 [74.262856]], R is [[74.66218567]
 [74.66460419]
 [74.66651154]
 [74.66552734]
 [74.66584015]].
[2019-03-26 16:49:31,886] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8663706e-16 1.0000000e+00 8.1080559e-21 1.7151577e-15 1.0423316e-26], sum to 1.0000
[2019-03-26 16:49:31,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-26 16:49:31,904] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 59.33333333333334, 1.0, 2.0, 0.9917971786540183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1512080.254822638, 1512080.254822638, 315012.3284870182], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1176600.0000, 
sim time next is 1177200.0000, 
raw observation next is [27.6, 59.0, 1.0, 2.0, 0.99189320344214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1514832.984715675, 1514832.984715675, 315390.8894443341], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.59, 1.0, 1.0, 0.990232775231494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4207869401987986, 0.4207869401987986, 0.4707326708124389], 
reward next is 0.5293, 
noisyNet noise sample is [array([0.8079392], dtype=float32), -0.048490405]. 
=============================================
[2019-03-26 16:49:34,101] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5532272e-24 1.0000000e+00 2.9820498e-27 2.5157374e-29 2.8623017e-34], sum to 1.0000
[2019-03-26 16:49:34,116] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0043
[2019-03-26 16:49:34,125] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.75, 94.33333333333334, 1.0, 2.0, 0.3727137809671536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 577912.448543163, 577912.448543163, 173118.2213656409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1228200.0000, 
sim time next is 1228800.0000, 
raw observation next is [21.9, 93.66666666666667, 1.0, 2.0, 0.3507683142374582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 542852.3509460131, 542852.3509460137, 170122.107738015], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.9366666666666668, 1.0, 1.0, 0.21779314968368457, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15079231970722587, 0.15079231970722604, 0.25391359363882837], 
reward next is 0.7461, 
noisyNet noise sample is [array([-1.0510702], dtype=float32), -0.24808726]. 
=============================================
[2019-03-26 16:49:42,410] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6519096e-24 1.0000000e+00 1.9085456e-26 2.2934164e-25 1.8267553e-33], sum to 1.0000
[2019-03-26 16:49:42,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6870
[2019-03-26 16:49:42,423] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 69.16666666666666, 1.0, 2.0, 0.4350579333445968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 624688.8363887838, 624688.8363887845, 176211.0381997831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1443000.0000, 
sim time next is 1443600.0000, 
raw observation next is [27.6, 69.0, 1.0, 2.0, 0.4307955358048171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 620818.23157765, 620818.2315776505, 175895.6247755926], 
processed observation next is [0.0, 0.7391304347826086, 0.5071090047393366, 0.69, 1.0, 1.0, 0.3142114889214664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17244950877156942, 0.1724495087715696, 0.2625307832471531], 
reward next is 0.7375, 
noisyNet noise sample is [array([-0.28371096], dtype=float32), -0.35992256]. 
=============================================
[2019-03-26 16:49:47,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0776666e-18 1.0000000e+00 1.5819955e-22 1.2467467e-18 1.8216105e-28], sum to 1.0000
[2019-03-26 16:49:47,764] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9560
[2019-03-26 16:49:47,770] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 91.5, 1.0, 2.0, 0.767624055597594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1139953.630798365, 1139953.630798365, 245145.2787010064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1612200.0000, 
sim time next is 1612800.0000, 
raw observation next is [23.4, 92.0, 1.0, 2.0, 0.7373990066418296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1094497.444836996, 1094497.444836996, 237604.2578892988], 
processed observation next is [1.0, 0.6956521739130435, 0.30805687203791465, 0.92, 1.0, 1.0, 0.6836132610142525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3040270680102767, 0.3040270680102767, 0.35463322073029674], 
reward next is 0.6454, 
noisyNet noise sample is [array([0.5481722], dtype=float32), -2.1674619]. 
=============================================
[2019-03-26 16:49:48,896] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4677089e-20 1.0000000e+00 1.3439685e-24 1.1178867e-20 6.7757111e-32], sum to 1.0000
[2019-03-26 16:49:48,905] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4591
[2019-03-26 16:49:48,910] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333333, 96.16666666666666, 1.0, 2.0, 0.4160070435122561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610601.1554898728, 610601.1554898728, 175238.9585569047], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1631400.0000, 
sim time next is 1632000.0000, 
raw observation next is [23.16666666666667, 96.33333333333333, 1.0, 2.0, 0.4164400034122114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611138.6189723732, 611138.6189723732, 175287.062005289], 
processed observation next is [1.0, 0.9130434782608695, 0.2969984202211693, 0.9633333333333333, 1.0, 1.0, 0.29691566676170045, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16976072749232587, 0.16976072749232587, 0.26162248060490895], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.6931579], dtype=float32), 0.5309822]. 
=============================================
[2019-03-26 16:49:48,925] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.264786]
 [72.23274 ]
 [72.11486 ]
 [72.08588 ]
 [72.095024]], R is [[72.34062195]
 [72.35566711]
 [72.37049866]
 [72.38503265]
 [72.39944458]].
[2019-03-26 16:49:59,723] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0057326e-19 1.0000000e+00 2.8907141e-24 2.5532128e-20 8.0056704e-31], sum to 1.0000
[2019-03-26 16:49:59,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7524
[2019-03-26 16:49:59,743] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 98.0, 1.0, 2.0, 0.4212329881296998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614862.2907928545, 614862.2907928539, 175547.2019075247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1640400.0000, 
sim time next is 1641000.0000, 
raw observation next is [23.1, 98.0, 1.0, 2.0, 0.4211168896421672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614692.7642501778, 614692.7642501778, 175530.9628274303], 
processed observation next is [1.0, 1.0, 0.2938388625592418, 0.98, 1.0, 1.0, 0.3025504694483942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17074799006949382, 0.17074799006949382, 0.2619865116827318], 
reward next is 0.7380, 
noisyNet noise sample is [array([0.05768286], dtype=float32), 1.4914665]. 
=============================================
[2019-03-26 16:49:59,759] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.23726 ]
 [73.2204  ]
 [73.21533 ]
 [73.22261 ]
 [73.222626]], R is [[73.25809479]
 [73.26350403]
 [73.26887512]
 [73.27424622]
 [73.27964783]].
[2019-03-26 16:50:00,008] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0242533e-21 1.0000000e+00 4.9215277e-25 3.2868643e-22 8.4323159e-32], sum to 1.0000
[2019-03-26 16:50:00,011] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2799
[2019-03-26 16:50:00,017] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 97.5, 1.0, 2.0, 0.4176619970886177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 611261.2224872009, 611261.2224872014, 175250.4030838056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1636200.0000, 
sim time next is 1636800.0000, 
raw observation next is [23.1, 97.66666666666666, 1.0, 2.0, 0.4186766743579723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612263.0367881114, 612263.0367881114, 175331.7074861569], 
processed observation next is [1.0, 0.9565217391304348, 0.2938388625592418, 0.9766666666666666, 1.0, 1.0, 0.29961045103370154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1700730657744754, 0.1700730657744754, 0.26168911565098046], 
reward next is 0.7383, 
noisyNet noise sample is [array([0.9656964], dtype=float32), 0.9753993]. 
=============================================
[2019-03-26 16:50:09,152] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8299075e-21 1.0000000e+00 3.0737102e-25 1.0591850e-21 1.9420376e-31], sum to 1.0000
[2019-03-26 16:50:09,159] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3769
[2019-03-26 16:50:09,164] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 91.0, 1.0, 2.0, 0.4523888417178131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645432.5521447347, 645432.5521447347, 178185.5127609934], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1895400.0000, 
sim time next is 1896000.0000, 
raw observation next is [24.5, 91.33333333333333, 1.0, 2.0, 0.4519204511806106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644920.737521176, 644920.7375211767, 178137.1501138371], 
processed observation next is [1.0, 0.9565217391304348, 0.3601895734597157, 0.9133333333333333, 1.0, 1.0, 0.33966319419350677, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17914464931143778, 0.17914464931143798, 0.2658763434534882], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.56484807], dtype=float32), -0.45279416]. 
=============================================
[2019-03-26 16:50:09,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.11675 ]
 [74.129234]
 [74.15289 ]
 [74.13048 ]
 [73.85408 ]], R is [[74.10990143]
 [74.1028595 ]
 [74.09585571]
 [74.08892822]
 [74.08194733]].
[2019-03-26 16:50:13,376] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1809741e-19 1.0000000e+00 2.6021069e-23 1.7358362e-18 3.7300779e-30], sum to 1.0000
[2019-03-26 16:50:13,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-26 16:50:13,392] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.95, 80.0, 1.0, 2.0, 0.5566361447008397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777841.5048890228, 777841.5048890234, 192945.4512849399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421000.0000, 
sim time next is 2421600.0000, 
raw observation next is [28.9, 80.0, 1.0, 2.0, 0.5547100137790519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775148.9538129104, 775148.9538129104, 192611.8932705215], 
processed observation next is [1.0, 0.0, 0.5687203791469194, 0.8, 1.0, 1.0, 0.4635060406976529, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21531915383691955, 0.21531915383691955, 0.2874804377171963], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.62710816], dtype=float32), -0.9155842]. 
=============================================
[2019-03-26 16:50:14,538] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 16:50:14,539] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:50:14,540] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:50:14,541] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:14,542] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:50:14,543] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:50:14,542] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:14,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:50:14,546] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:14,545] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:14,549] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:50:14,574] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 16:50:14,600] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 16:50:14,621] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 16:50:14,643] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 16:50:14,664] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 16:51:14,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00842573], dtype=float32), 0.09496191]
[2019-03-26 16:51:14,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.174585855, 89.05717415000001, 1.0, 2.0, 0.5577660611318962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779421.0256713616, 779421.0256713616, 193140.496176701]
[2019-03-26 16:51:14,929] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:51:14,932] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3406282e-20 1.0000000e+00 3.3568449e-24 3.2328251e-20 1.5513020e-30], sampled 0.8222151741276058
[2019-03-26 16:51:56,915] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00842573], dtype=float32), 0.09496191]
[2019-03-26 16:51:56,915] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.05, 87.16666666666667, 1.0, 2.0, 0.5348182300538361, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747342.4978015766, 747342.4978015766, 189230.7525836706]
[2019-03-26 16:51:56,916] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:51:56,918] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.1152881e-23 1.0000000e+00 5.5312461e-26 6.8546608e-26 1.4025207e-32], sampled 0.5836503735505916
[2019-03-26 16:52:06,826] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00842573], dtype=float32), 0.09496191]
[2019-03-26 16:52:06,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 85.0, 1.0, 2.0, 0.8198144228671497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1145804.350837255, 1145804.350837254, 248833.0148487082]
[2019-03-26 16:52:06,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:52:06,833] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8822907e-20 1.0000000e+00 1.8469870e-23 2.2650260e-20 3.4254608e-29], sampled 0.3156446626203572
[2019-03-26 16:52:11,484] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8057.3404 3147636289.2588 1341.0000
[2019-03-26 16:52:11,506] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8317.4817 2922632335.7542 1208.0000
[2019-03-26 16:52:11,603] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8107.5800 2997215672.8388 1506.0000
[2019-03-26 16:52:11,610] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8690.2333 2776479579.9107 862.0000
[2019-03-26 16:52:11,934] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8544.7913 2837784644.9214 1003.0000
[2019-03-26 16:52:12,950] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1325000, evaluation results [1325000.0, 8057.34043185418, 3147636289.2587633, 1341.0, 8317.48166412616, 2922632335.7542343, 1208.0, 8690.233346603041, 2776479579.9106526, 862.0, 8107.580047243065, 2997215672.838832, 1506.0, 8544.791303035385, 2837784644.9214497, 1003.0]
[2019-03-26 16:52:23,403] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.6340495e-20 1.0000000e+00 2.4677155e-24 5.3604470e-21 8.5609608e-31], sum to 1.0000
[2019-03-26 16:52:23,413] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0448
[2019-03-26 16:52:23,420] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 79.0, 1.0, 2.0, 0.5718864987981999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799160.316084342, 799160.316084342, 195625.3288737926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2413800.0000, 
sim time next is 2414400.0000, 
raw observation next is [29.46666666666667, 79.33333333333333, 1.0, 2.0, 0.5719913985712006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799306.9593057355, 799306.9593057355, 195643.918306955], 
processed observation next is [1.0, 0.9565217391304348, 0.5955766192733019, 0.7933333333333333, 1.0, 1.0, 0.4843269862303622, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22202971091825988, 0.22202971091825988, 0.2920058482193358], 
reward next is 0.7080, 
noisyNet noise sample is [array([2.2609468], dtype=float32), 0.46968013]. 
=============================================
[2019-03-26 16:52:25,487] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2622485e-25 1.0000000e+00 4.4005311e-27 9.5785458e-29 9.2149133e-34], sum to 1.0000
[2019-03-26 16:52:25,497] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1058
[2019-03-26 16:52:25,503] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.05, 93.5, 1.0, 2.0, 0.4820010316194018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673513.5810254433, 673513.5810254439, 180824.2370530177], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2097000.0000, 
sim time next is 2097600.0000, 
raw observation next is [25.2, 93.0, 1.0, 2.0, 0.4845962434595739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677141.0992138005, 677141.0992138005, 181218.0594613316], 
processed observation next is [0.0, 0.2608695652173913, 0.3933649289099526, 0.93, 1.0, 1.0, 0.3790316186259927, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18809474978161125, 0.18809474978161125, 0.2704747156139278], 
reward next is 0.7295, 
noisyNet noise sample is [array([2.1227508], dtype=float32), 0.37151223]. 
=============================================
[2019-03-26 16:52:26,236] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1676791e-22 1.0000000e+00 6.8024585e-26 7.9794134e-25 1.5313450e-32], sum to 1.0000
[2019-03-26 16:52:26,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5363
[2019-03-26 16:52:26,257] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 73.16666666666667, 1.0, 2.0, 0.5706753174267406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797467.1629048804, 797467.1629048804, 195410.6037167161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2134200.0000, 
sim time next is 2134800.0000, 
raw observation next is [30.8, 73.0, 1.0, 2.0, 0.5711457773894059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798124.835167758, 798124.835167758, 195494.2186136233], 
processed observation next is [0.0, 0.7391304347826086, 0.6587677725118484, 0.73, 1.0, 1.0, 0.48330816552940464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.221701343102155, 0.221701343102155, 0.29178241584122877], 
reward next is 0.7082, 
noisyNet noise sample is [array([0.13070633], dtype=float32), -0.21820559]. 
=============================================
[2019-03-26 16:52:28,247] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8339333e-23 1.0000000e+00 6.2898268e-27 8.1287886e-25 1.3890650e-33], sum to 1.0000
[2019-03-26 16:52:28,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3822
[2019-03-26 16:52:28,260] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.43333333333333, 75.33333333333333, 1.0, 2.0, 0.5727263156361257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800334.3272621585, 800334.3272621585, 195775.5309704226], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2317200.0000, 
sim time next is 2317800.0000, 
raw observation next is [30.31666666666667, 76.16666666666667, 1.0, 2.0, 0.5746440475595012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803015.200874075, 803015.200874075, 196117.8030041755], 
processed observation next is [1.0, 0.8260869565217391, 0.6358609794628753, 0.7616666666666667, 1.0, 1.0, 0.48752294886686887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22305977802057636, 0.22305977802057636, 0.29271313881220223], 
reward next is 0.7073, 
noisyNet noise sample is [array([-0.08525429], dtype=float32), -2.0031662]. 
=============================================
[2019-03-26 16:52:34,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.3704888e-08 9.4265050e-01 6.8563429e-15 5.7349421e-02 2.5000998e-17], sum to 1.0000
[2019-03-26 16:52:34,843] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4532
[2019-03-26 16:52:34,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2381644.363490299 W.
[2019-03-26 16:52:34,855] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.5676983843073065, 1.0, 2.0, 0.5676983843073065, 1.0, 1.0, 0.9859043528172545, 6.9112, 6.9112, 170.5573041426782, 2381644.363490299, 2381644.363490299, 465117.1681743577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2300400.0000, 
sim time next is 2301000.0000, 
raw observation next is [32.03333333333333, 64.83333333333334, 1.0, 2.0, 0.8606082588388819, 1.0, 2.0, 0.8606082588388819, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2407010.070184238, 2407010.070184239, 450457.5987577176], 
processed observation next is [1.0, 0.6521739130434783, 0.7172195892575038, 0.6483333333333334, 1.0, 1.0, 0.8320581431793758, 1.0, 1.0, 0.8320581431793758, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6686139083845105, 0.6686139083845108, 0.6723247742652502], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5927995], dtype=float32), 0.96217114]. 
=============================================
[2019-03-26 16:52:34,869] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[52.380856]
 [53.473473]
 [53.20672 ]
 [52.223003]
 [51.89111 ]], R is [[52.32138443]
 [52.10396576]
 [51.92933273]
 [51.75576019]
 [51.57579422]].
[2019-03-26 16:52:40,425] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.6310356e-09 8.3813113e-01 5.8047009e-16 1.6186884e-01 4.8566116e-19], sum to 1.0000
[2019-03-26 16:52:40,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7202
[2019-03-26 16:52:40,442] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2367443.165800272 W.
[2019-03-26 16:52:40,448] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.18333333333334, 60.16666666666666, 1.0, 2.0, 0.8464747992545589, 1.0, 2.0, 0.8464747992545589, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2367443.165800272, 2367443.165800272, 443133.9754924031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2393400.0000, 
sim time next is 2394000.0000, 
raw observation next is [33.2, 60.0, 1.0, 2.0, 0.58706099967536, 1.0, 2.0, 0.58706099967536, 1.0, 1.0, 1.019530812396813, 6.9112, 6.9112, 170.5573041426782, 2462955.692428224, 2462955.692428224, 480569.6534157917], 
processed observation next is [1.0, 0.7391304347826086, 0.7725118483412324, 0.6, 1.0, 1.0, 0.5024831321389879, 1.0, 1.0, 0.5024831321389879, 1.0, 0.5, 1.0238180638985523, 0.0, 0.0, 0.8375144448122397, 0.6841543590078399, 0.6841543590078399, 0.7172681394265548], 
reward next is 0.2827, 
noisyNet noise sample is [array([-1.236947], dtype=float32), 0.68659765]. 
=============================================
[2019-03-26 16:52:40,464] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[55.968872]
 [55.45401 ]
 [54.62531 ]
 [54.11488 ]
 [51.743828]], R is [[53.89725494]
 [53.69689178]
 [53.15992355]
 [52.98570251]
 [52.81978607]].
[2019-03-26 16:52:41,832] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3965910e-09 8.9467406e-01 1.2413882e-15 1.0532597e-01 1.5202243e-18], sum to 1.0000
[2019-03-26 16:52:41,839] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6656
[2019-03-26 16:52:41,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2066861.60157446 W.
[2019-03-26 16:52:41,851] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.4, 82.0, 1.0, 2.0, 0.7390984028857088, 1.0, 2.0, 0.7390984028857088, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2066861.60157446, 2066861.60157446, 391311.5771916897], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2480400.0000, 
sim time next is 2481000.0000, 
raw observation next is [28.31666666666667, 82.50000000000001, 1.0, 2.0, 0.2353416238021939, 1.0, 2.0, 0.2353416238021939, 1.0, 1.0, 0.4066564580667051, 6.9112, 6.9112, 170.5573041426782, 986689.3661595529, 986689.3661595529, 280347.2483421256], 
processed observation next is [1.0, 0.7391304347826086, 0.5410742496050555, 0.8250000000000002, 1.0, 1.0, 0.07872484795445046, 1.0, 1.0, 0.07872484795445046, 1.0, 0.5, 0.276410314715494, 0.0, 0.0, 0.8375144448122397, 0.2740803794887647, 0.2740803794887647, 0.4184287288688442], 
reward next is 0.5816, 
noisyNet noise sample is [array([-0.15146638], dtype=float32), 0.89975744]. 
=============================================
[2019-03-26 16:52:41,867] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.06289 ]
 [52.999706]
 [53.69064 ]
 [55.221012]
 [54.435005]], R is [[58.83547592]
 [58.66307449]
 [58.07644272]
 [57.49567795]
 [57.36681747]].
[2019-03-26 16:52:42,394] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8675164e-13 1.0000000e+00 7.0286788e-19 8.2281387e-10 4.8610420e-23], sum to 1.0000
[2019-03-26 16:52:42,402] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0291
[2019-03-26 16:52:42,413] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2257603.493840312 W.
[2019-03-26 16:52:42,422] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.73333333333333, 63.0, 1.0, 2.0, 0.9732802827213519, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005991929796357, 6.9112, 168.91231596093, 2257603.493840312, 2190355.091375816, 455180.1659278012], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2382000.0000, 
sim time next is 2382600.0000, 
raw observation next is [32.76666666666667, 63.0, 1.0, 2.0, 0.5423623164030882, 1.0, 1.0, 0.5423623164030882, 1.0, 2.0, 0.9419039816333182, 6.9112, 6.9112, 170.5573041426782, 2275256.119913943, 2275256.119913943, 445677.0796657467], 
processed observation next is [1.0, 0.5652173913043478, 0.7519747235387049, 0.63, 1.0, 1.0, 0.4486292968711906, 1.0, 0.5, 0.4486292968711906, 1.0, 1.0, 0.9291511971138026, 0.0, 0.0, 0.8375144448122397, 0.6320155888649842, 0.6320155888649842, 0.6651896711429055], 
reward next is 0.3348, 
noisyNet noise sample is [array([2.2686524], dtype=float32), -1.5418909]. 
=============================================
[2019-03-26 16:52:46,944] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.5331031e-26 1.0000000e+00 1.6860580e-28 3.8617483e-30 2.7707145e-35], sum to 1.0000
[2019-03-26 16:52:46,952] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2295
[2019-03-26 16:52:46,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.4782925138206723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668329.9348324661, 668329.9348324666, 180264.7621281692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2634000.0000, 
sim time next is 2634600.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.4792904809376818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669724.8584926792, 669724.8584926798, 180414.8840751948], 
processed observation next is [0.0, 0.4782608695652174, 0.470774091627172, 0.7983333333333335, 1.0, 1.0, 0.37263913365985757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1860346829146331, 0.18603468291463326, 0.26927594638088775], 
reward next is 0.7307, 
noisyNet noise sample is [array([-0.19812132], dtype=float32), -0.5260384]. 
=============================================
[2019-03-26 16:52:51,742] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2613452e-10 9.9996686e-01 6.5721644e-17 3.3165135e-05 1.0622949e-19], sum to 1.0000
[2019-03-26 16:52:51,748] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1403
[2019-03-26 16:52:51,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1866566.033000579 W.
[2019-03-26 16:52:51,759] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.63333333333333, 78.66666666666667, 1.0, 2.0, 0.6938808931775224, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.989010735324269, 6.9112, 168.9124933631203, 1866566.033000579, 1811364.570681611, 383960.4120699452], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2546400.0000, 
sim time next is 2547000.0000, 
raw observation next is [28.75, 78.0, 1.0, 2.0, 0.6634585274173566, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987772237512536, 6.9112, 168.9124373515798, 1823995.573474811, 1769672.759733644, 377605.4689149771], 
processed observation next is [1.0, 0.4782608695652174, 0.561611374407583, 0.78, 1.0, 1.0, 0.5945283462859717, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007657223751253639, 0.0, 0.8294373958446714, 0.5066654370763364, 0.49157576659267893, 0.5635902521119062], 
reward next is 0.0535, 
noisyNet noise sample is [array([-0.74099517], dtype=float32), -0.80261385]. 
=============================================
[2019-03-26 16:52:51,773] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[56.45701 ]
 [56.126926]
 [54.712242]
 [54.689   ]
 [54.718086]], R is [[57.29947281]
 [56.72647858]
 [56.6255188 ]
 [56.05926514]
 [55.49867249]].
[2019-03-26 16:53:03,116] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6827213e-26 1.0000000e+00 5.1503923e-29 3.0478373e-32 1.1609553e-36], sum to 1.0000
[2019-03-26 16:53:03,124] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2700
[2019-03-26 16:53:03,129] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.3334649213971987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516223.059063176, 516223.059063176, 167983.766123318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2778000.0000, 
sim time next is 2778600.0000, 
raw observation next is [21.16666666666666, 99.0, 1.0, 2.0, 0.332306189633539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 515151.0291003835, 515151.0291003842, 167922.4051474607], 
processed observation next is [1.0, 0.13043478260869565, 0.2022116903633489, 0.99, 1.0, 1.0, 0.1955496260645048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14309750808343988, 0.14309750808344007, 0.25063045544397117], 
reward next is 0.7494, 
noisyNet noise sample is [array([0.7027267], dtype=float32), -1.4031218]. 
=============================================
[2019-03-26 16:53:08,536] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 16:53:08,539] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:53:08,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:08,540] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:53:08,540] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:53:08,543] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:08,543] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:53:08,545] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:08,547] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:08,542] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:53:08,550] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:53:08,567] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 16:53:08,567] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 16:53:08,612] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 16:53:08,613] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 16:53:08,613] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 16:53:48,710] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00669007], dtype=float32), 0.09436152]
[2019-03-26 16:53:48,714] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.43333333333333, 78.00000000000001, 1.0, 2.0, 0.5309270504310828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741903.1554445546, 741903.1554445546, 188583.3866110861]
[2019-03-26 16:53:48,715] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:53:48,717] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0277888e-27 1.0000000e+00 5.2765545e-29 5.3477746e-32 2.4043281e-36], sampled 0.4898414790690421
[2019-03-26 16:54:06,715] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00669007], dtype=float32), 0.09436152]
[2019-03-26 16:54:06,716] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.23333333333333, 61.0, 1.0, 2.0, 0.554961401283726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775500.3696708041, 775500.3696708041, 192655.0398071097]
[2019-03-26 16:54:06,718] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:54:06,721] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.5314119e-27 1.0000000e+00 4.1512957e-29 6.4373732e-32 2.1119280e-36], sampled 0.8546250781732092
[2019-03-26 16:54:56,587] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00669007], dtype=float32), 0.09436152]
[2019-03-26 16:54:56,588] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.1, 66.0, 1.0, 2.0, 0.6126673642660114, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.949780665864388, 6.9112, 168.9123124091955, 1713032.529247622, 1685662.181408772, 366927.0040824851]
[2019-03-26 16:54:56,588] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:54:56,595] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2490307e-20 1.0000000e+00 4.4768011e-23 8.1077422e-22 2.7895795e-29], sampled 0.11534187217602676
[2019-03-26 16:54:56,597] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1713032.529247622 W.
[2019-03-26 16:55:05,153] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4759 2927525220.0087 1338.0000
[2019-03-26 16:55:05,548] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.6077 2779207088.6539 927.0000
[2019-03-26 16:55:05,790] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7894.8536 3162913685.2285 1753.0000
[2019-03-26 16:55:05,905] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.7197 3007696255.6314 1766.0000
[2019-03-26 16:55:05,985] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5395 2842696210.7487 1131.0000
[2019-03-26 16:55:07,002] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1350000, evaluation results [1350000.0, 7894.853589830554, 3162913685.2285123, 1753.0, 8254.475934687374, 2927525220.008676, 1338.0, 8662.607691249637, 2779207088.6538587, 927.0, 7997.719706947194, 3007696255.6313787, 1766.0, 8497.539521690112, 2842696210.7487397, 1131.0]
[2019-03-26 16:55:07,666] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.4642960e-25 1.0000000e+00 1.6203408e-28 9.8786063e-29 4.1107972e-36], sum to 1.0000
[2019-03-26 16:55:07,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2868
[2019-03-26 16:55:07,681] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3949750711954993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589360.0767836894, 589360.0767836894, 173558.8936211923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2842200.0000, 
sim time next is 2842800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3917735633968783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 584584.2275499951, 584584.2275499958, 173122.8745327543], 
processed observation next is [1.0, 0.9130434782608695, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2671970643335883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1623845076527764, 0.1623845076527766, 0.258392350048887], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.51049304], dtype=float32), 1.2986712]. 
=============================================
[2019-03-26 16:55:27,707] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3185183e-22 1.0000000e+00 5.0874068e-26 1.9329969e-25 1.4199087e-32], sum to 1.0000
[2019-03-26 16:55:27,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7634
[2019-03-26 16:55:27,725] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.834292388302565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1192657.540661651, 1192657.540661651, 256294.6185008968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3723000.0000, 
sim time next is 3723600.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.7511585591953072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1073596.744355148, 1073596.744355148, 235529.3833489165], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.7001910351750689, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29822131787642997, 0.29822131787642997, 0.3515363930580844], 
reward next is 0.6485, 
noisyNet noise sample is [array([2.4175048], dtype=float32), 1.5239865]. 
=============================================
[2019-03-26 16:55:30,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.4798979e-27 1.0000000e+00 4.2615916e-29 2.5140437e-33 5.8863082e-37], sum to 1.0000
[2019-03-26 16:55:30,744] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7050
[2019-03-26 16:55:30,748] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4559155698054902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645525.3728558918, 645525.3728558918, 178071.0172771911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3218400.0000, 
sim time next is 3219000.0000, 
raw observation next is [25.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4575084408629382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646776.5353416, 646776.5353416, 178174.6390386999], 
processed observation next is [0.0, 0.2608695652173913, 0.39178515007898923, 0.8816666666666667, 1.0, 1.0, 0.346395711883058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.179660148706, 0.179660148706, 0.26593229707268645], 
reward next is 0.7341, 
noisyNet noise sample is [array([1.706999], dtype=float32), 0.045594547]. 
=============================================
[2019-03-26 16:55:30,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[74.013405]
 [73.93866 ]
 [73.91734 ]
 [73.89541 ]
 [73.88467 ]], R is [[74.01597595]
 [74.01004028]
 [74.00408173]
 [73.99810028]
 [73.99217224]].
[2019-03-26 16:55:46,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1530640e-08 9.5343965e-01 1.1362448e-14 4.6560377e-02 5.2777382e-17], sum to 1.0000
[2019-03-26 16:55:46,523] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0404
[2019-03-26 16:55:46,532] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2320187.86876874 W.
[2019-03-26 16:55:46,541] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.5, 66.5, 1.0, 2.0, 1.017993791624062, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.999630384363284, 6.9112, 168.9123604124292, 2320187.86876874, 2257452.531957821, 469133.5274672708], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3497400.0000, 
sim time next is 3498000.0000, 
raw observation next is [31.66666666666666, 66.66666666666667, 1.0, 2.0, 0.5663861606936587, 1.0, 1.0, 0.5663861606936587, 1.0, 2.0, 0.9836254543593286, 6.9112, 6.9112, 170.5573041426782, 2376134.005654679, 2376134.005654679, 464088.6340337603], 
processed observation next is [1.0, 0.4782608695652174, 0.6998420221169034, 0.6666666666666667, 1.0, 1.0, 0.47757368758272123, 1.0, 0.5, 0.47757368758272123, 1.0, 1.0, 0.9800310419016203, 0.0, 0.0, 0.8375144448122397, 0.6600372237929665, 0.6600372237929665, 0.6926696030354631], 
reward next is 0.3073, 
noisyNet noise sample is [array([0.620642], dtype=float32), -0.22925498]. 
=============================================
[2019-03-26 16:55:46,557] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[48.2269  ]
 [47.634575]
 [48.11724 ]
 [47.171814]
 [47.732826]], R is [[47.19592667]
 [46.72396851]
 [46.25672913]
 [45.79416275]
 [45.66845703]].
[2019-03-26 16:55:53,377] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3323367e-29 1.0000000e+00 2.7040922e-30 4.4107505e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 16:55:53,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5294
[2019-03-26 16:55:53,391] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5230039235708138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730827.7827572296, 730827.7827572296, 187278.7301356065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3702600.0000, 
sim time next is 3703200.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5229436336385986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730743.5066913774, 730743.5066913768, 187268.7983859703], 
processed observation next is [1.0, 0.8695652173913043, 0.541864139020537, 0.7733333333333333, 1.0, 1.0, 0.4252332935404803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20298430741427148, 0.20298430741427134, 0.27950566923279146], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.2975454], dtype=float32), 1.2865163]. 
=============================================
[2019-03-26 16:55:59,674] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9910011e-26 1.0000000e+00 5.0897285e-29 7.5470715e-31 5.0331965e-36], sum to 1.0000
[2019-03-26 16:55:59,684] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6047
[2019-03-26 16:55:59,691] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.4506987407720722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644277.5792512562, 644277.5792512568, 178099.2523405596], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3722400.0000, 
sim time next is 3723000.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.834292388302565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1192657.540661651, 1192657.540661651, 256294.6185008968], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.8003522750633314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33129376129490307, 0.33129376129490307, 0.38252928134462205], 
reward next is 0.6175, 
noisyNet noise sample is [array([-0.5542569], dtype=float32), 1.5194844]. 
=============================================
[2019-03-26 16:55:59,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[70.34714 ]
 [70.201096]
 [70.26219 ]
 [70.33845 ]
 [70.4032  ]], R is [[67.4053421 ]
 [67.46546936]
 [67.52494049]
 [67.58369446]
 [67.64163208]].
[2019-03-26 16:56:02,496] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 16:56:02,499] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:56:02,499] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:56:02,500] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:56:02,500] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:02,501] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:02,501] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:56:02,503] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:56:02,501] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:02,506] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:02,507] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:56:02,534] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 16:56:02,557] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 16:56:02,583] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 16:56:02,614] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 16:56:02,615] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 16:56:03,966] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:56:03,968] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.1, 79.0, 1.0, 2.0, 0.3966604834615329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591116.8206663651, 591116.8206663651, 173697.4086328887]
[2019-03-26 16:56:03,968] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:56:03,972] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.5385826e-30 1.0000000e+00 3.2676966e-31 1.3054210e-37 0.0000000e+00], sampled 0.3095940155129767
[2019-03-26 16:56:05,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:56:05,333] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.5, 96.0, 1.0, 2.0, 0.3826110538410947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575872.5079116046, 575872.5079116046, 172493.9529415882]
[2019-03-26 16:56:05,334] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:56:05,336] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8248038e-27 1.0000000e+00 1.0519207e-29 5.3655289e-33 1.1318785e-37], sampled 0.4698591192601752
[2019-03-26 16:57:04,911] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:57:04,912] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [37.13252636, 51.20530343999999, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.141448439401314, 6.9112, 168.9116249930555, 2447173.183116525, 2283828.303300683, 475602.9276223177]
[2019-03-26 16:57:04,913] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:57:04,916] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.2378016e-17 1.0000000e+00 1.7592176e-22 1.5784876e-14 9.5969890e-27], sampled 0.12373430669174001
[2019-03-26 16:57:04,917] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2447173.183116525 W.
[2019-03-26 16:57:29,467] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:57:29,468] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.88333333333333, 57.66666666666666, 1.0, 2.0, 0.8948705363866362, 1.0, 1.0, 0.8948705363866362, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 169.0403247858759, 2502955.702529471, 2502955.702529471, 468428.4313355088]
[2019-03-26 16:57:29,470] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:57:29,474] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7140107e-13 1.0000000e+00 1.9606888e-19 8.9708498e-09 8.5814643e-23], sampled 0.8321579459345578
[2019-03-26 16:57:29,476] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2502955.702529471 W.
[2019-03-26 16:57:39,207] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:57:39,207] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.57526614333334, 61.34575113, 1.0, 2.0, 0.3964099439068314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586815.6531237978, 586815.6531237973, 173180.4099344026]
[2019-03-26 16:57:39,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:57:39,212] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9260932e-25 1.0000000e+00 1.0317602e-28 5.1946327e-28 1.7608106e-35], sampled 0.4080366159404414
[2019-03-26 16:57:40,756] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00801208], dtype=float32), 0.092007376]
[2019-03-26 16:57:40,759] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.87018186833333, 89.10965925333333, 1.0, 2.0, 0.5017814116100544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701162.3834698363, 701162.3834698363, 183875.2704727926]
[2019-03-26 16:57:40,760] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:57:40,764] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0891175e-27 1.0000000e+00 1.4830386e-29 1.1047887e-32 1.6266814e-37], sampled 0.37515144031509706
[2019-03-26 16:57:59,156] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.9283 2927272965.6207 1338.0000
[2019-03-26 16:57:59,744] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 16:57:59,758] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.1720 3164276105.0808 1776.0000
[2019-03-26 16:57:59,952] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 16:58:00,019] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 16:58:01,033] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1375000, evaluation results [1375000.0, 7883.172041318002, 3164276105.0808067, 1776.0, 8252.928342174982, 2927272965.6207337, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 16:58:01,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6683950e-11 9.9999928e-01 2.6252241e-17 6.7657317e-07 8.0795828e-21], sum to 1.0000
[2019-03-26 16:58:01,133] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4608
[2019-03-26 16:58:01,146] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2861880.754077509 W.
[2019-03-26 16:58:01,150] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 62.5, 1.0, 2.0, 0.7228969577091457, 1.0, 2.0, 0.6820385183688354, 1.0, 1.0, 1.03, 7.005099537629245, 6.9112, 170.5573041426782, 2861880.754077509, 2794616.6956847, 528658.5930005197], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3772200.0000, 
sim time next is 3772800.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 1.023940378106357, 1.0, 2.0, 1.023940378106357, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2864352.553401501, 2864352.553401501, 543621.3522813837], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 1.0288438290438036, 1.0, 1.0, 1.0288438290438036, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7956534870559725, 0.7956534870559725, 0.8113751526587817], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.92356807], dtype=float32), 0.17184521]. 
=============================================
[2019-03-26 16:58:05,689] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2293696e-30 1.0000000e+00 1.2810941e-31 6.3356661e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 16:58:05,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3812
[2019-03-26 16:58:05,704] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.5, 1.0, 2.0, 0.554695264193918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775128.335297235, 775128.335297235, 192609.4052649781], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3828600.0000, 
sim time next is 3829200.0000, 
raw observation next is [29.33333333333334, 78.0, 1.0, 2.0, 0.5578162038926401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779491.1207615853, 779491.1207615853, 193150.4323246857], 
processed observation next is [0.0, 0.30434782608695654, 0.5892575039494474, 0.78, 1.0, 1.0, 0.4672484384248675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2165253113226626, 0.2165253113226626, 0.2882842273502772], 
reward next is 0.7117, 
noisyNet noise sample is [array([1.0651251], dtype=float32), 0.62955767]. 
=============================================
[2019-03-26 16:58:06,341] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.2933307e-28 1.0000000e+00 9.1133735e-31 1.9358669e-33 2.4157441e-38], sum to 1.0000
[2019-03-26 16:58:06,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0521
[2019-03-26 16:58:06,354] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 83.16666666666666, 1.0, 2.0, 0.6205568352776938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867200.5304170754, 867200.5304170754, 204638.3574451312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6196818803016998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 865977.3213539168, 865977.3213539174, 204470.1066768142], 
processed observation next is [1.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5417853979538552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24054925593164356, 0.24054925593164372, 0.30517926369673765], 
reward next is 0.6948, 
noisyNet noise sample is [array([1.4070171], dtype=float32), -0.354371]. 
=============================================
[2019-03-26 16:58:09,444] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5068363e-28 1.0000000e+00 2.9037912e-30 6.5741990e-36 1.5394062e-37], sum to 1.0000
[2019-03-26 16:58:09,454] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6224
[2019-03-26 16:58:09,459] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 91.5, 1.0, 2.0, 0.5759854728022732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 804890.4365129758, 804890.4365129764, 196356.6652942462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3904200.0000, 
sim time next is 3904800.0000, 
raw observation next is [27.33333333333334, 92.33333333333334, 1.0, 2.0, 0.5751620359736044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 803739.3186089606, 803739.3186089612, 196209.1342637642], 
processed observation next is [0.0, 0.17391304347826086, 0.4944707740916275, 0.9233333333333335, 1.0, 1.0, 0.48814703129349923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22326092183582238, 0.22326092183582255, 0.29284945412502117], 
reward next is 0.7072, 
noisyNet noise sample is [array([1.648943], dtype=float32), 2.6734078]. 
=============================================
[2019-03-26 16:58:19,492] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6755535e-25 1.0000000e+00 6.5722737e-27 2.9593016e-30 7.7423155e-35], sum to 1.0000
[2019-03-26 16:58:19,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1912
[2019-03-26 16:58:19,509] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.23333333333333, 87.83333333333334, 1.0, 2.0, 0.7821619180971322, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1093152.665600299, 1093152.665600299, 239579.602343137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4074600.0000, 
sim time next is 4075200.0000, 
raw observation next is [27.2, 88.0, 1.0, 2.0, 0.7677713513770087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1073030.189535858, 1073030.189535858, 236153.9268283316], 
processed observation next is [1.0, 0.17391304347826086, 0.4881516587677725, 0.88, 1.0, 1.0, 0.7202064474421791, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29806394153773835, 0.29806394153773835, 0.35246854750497253], 
reward next is 0.6475, 
noisyNet noise sample is [array([-1.0882044], dtype=float32), 0.32158855]. 
=============================================
[2019-03-26 16:58:21,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3853708e-09 9.9603975e-01 1.1716847e-15 3.9602043e-03 1.9847388e-18], sum to 1.0000
[2019-03-26 16:58:21,399] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4193
[2019-03-26 16:58:21,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3183392.448377947 W.
[2019-03-26 16:58:21,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.0, 50.0, 1.0, 2.0, 0.8759461467716211, 1.0, 2.0, 0.7585631129000729, 1.0, 2.0, 1.03, 7.005111609449156, 6.9112, 170.5573041426782, 3183392.448377947, 3116119.742449485, 582663.5774637426], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4201200.0000, 
sim time next is 4201800.0000, 
raw observation next is [36.83333333333334, 50.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.501239465055189, 6.9112, 170.5573041426782, 3332491.349150859, 2909822.079060934, 550429.3178226735], 
processed observation next is [1.0, 0.6521739130434783, 0.9447077409162722, 0.505, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.0590039465055189, 0.0, 0.8375144448122397, 0.9256920414307941, 0.8082839108502594, 0.8215362952577216], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.831178], dtype=float32), 0.43329898]. 
=============================================
[2019-03-26 16:58:26,627] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.7453072e-08 9.6652055e-01 4.5135201e-15 3.3479378e-02 8.4115029e-18], sum to 1.0000
[2019-03-26 16:58:26,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9533
[2019-03-26 16:58:26,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3085981.870389807 W.
[2019-03-26 16:58:26,654] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.16666666666666, 55.83333333333333, 1.0, 2.0, 0.8295799562406068, 1.0, 2.0, 0.7353800176345661, 1.0, 2.0, 1.03, 7.005107951640293, 6.9112, 170.5573041426782, 3085981.870389807, 3018711.784698624, 565381.8356030573], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4198200.0000, 
sim time next is 4198800.0000, 
raw observation next is [36.33333333333334, 54.66666666666667, 1.0, 2.0, 0.8738663159913534, 1.0, 2.0, 0.7575231975099391, 1.0, 2.0, 1.03, 7.005111445359983, 6.9112, 170.5573041426782, 3179022.775927411, 3111750.187542699, 581871.6505583874], 
processed observation next is [1.0, 0.6086956521739131, 0.9210110584518172, 0.5466666666666667, 1.0, 1.0, 0.8480317060136788, 1.0, 1.0, 0.7078592741083604, 1.0, 1.0, 1.0365853658536586, 0.009391144535998297, 0.0, 0.8375144448122397, 0.8830618822020586, 0.8643750520951942, 0.8684651500871454], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7767385], dtype=float32), -0.19885707]. 
=============================================
[2019-03-26 16:58:28,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.1888690e-18 1.0000000e+00 7.2763606e-22 1.9459650e-19 1.0278167e-27], sum to 1.0000
[2019-03-26 16:58:28,694] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9628
[2019-03-26 16:58:28,701] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.66666666666666, 1.0, 2.0, 0.5685495654897653, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9861907414439958, 6.911200000000001, 6.9112, 168.9129565104293, 1589585.732118708, 1589585.732118707, 347588.6809246272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4243800.0000, 
sim time next is 4244400.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.440011452030399, 6.9112, 168.9099495112963, 1829162.24713929, 1454011.8813528, 311352.6768372117], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0528811452030399, 0.0, 0.8294251794099412, 0.5081006242053583, 0.40389218926466663, 0.4647054878167339], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46467677], dtype=float32), 1.0706655]. 
=============================================
[2019-03-26 16:58:29,936] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8214523e-20 1.0000000e+00 7.6402567e-24 2.3557012e-22 1.5753535e-29], sum to 1.0000
[2019-03-26 16:58:29,946] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4123
[2019-03-26 16:58:29,953] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 0.963582914012748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104125, 1346868.206625655, 1346868.206625656, 288032.0469775307], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4342800.0000, 
sim time next is 4343400.0000, 
raw observation next is [29.5, 86.5, 1.0, 2.0, 0.9740883625806938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1361561.83401807, 1361561.83401807, 291136.0962348416], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.865, 1.0, 1.0, 0.9687811597357756, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.378211620560575, 0.378211620560575, 0.43453148691767407], 
reward next is 0.5655, 
noisyNet noise sample is [array([1.6796209], dtype=float32), -0.27809304]. 
=============================================
[2019-03-26 16:58:32,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3781926e-33 1.0000000e+00 2.6566854e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 16:58:32,711] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8714
[2019-03-26 16:58:32,716] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 82.0, 1.0, 2.0, 0.4678879828999695, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661753.5244685997, 661753.5244685997, 179743.7983843949], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4653000.0000, 
sim time next is 4653600.0000, 
raw observation next is [25.33333333333334, 86.0, 1.0, 2.0, 0.462441118112689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 656257.5409933337, 656257.5409933343, 179218.7617788287], 
processed observation next is [1.0, 0.8695652173913043, 0.3996840442338076, 0.86, 1.0, 1.0, 0.3523386965213121, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18229376138703712, 0.1822937613870373, 0.26749068922213237], 
reward next is 0.7325, 
noisyNet noise sample is [array([-0.993519], dtype=float32), 0.086251155]. 
=============================================
[2019-03-26 16:58:46,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1964547e-31 1.0000000e+00 1.5554720e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 16:58:46,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4382
[2019-03-26 16:58:46,064] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 75.66666666666667, 1.0, 2.0, 0.5013865127069486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 700610.3909894257, 700610.3909894257, 183813.1069169299], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4524600.0000, 
sim time next is 4525200.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.497565174219769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695268.9118359083, 695268.9118359083, 183214.9644337025], 
processed observation next is [0.0, 0.391304347826087, 0.5260663507109005, 0.74, 1.0, 1.0, 0.39465683640936017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1931302532877523, 0.1931302532877523, 0.2734551707965709], 
reward next is 0.7265, 
noisyNet noise sample is [array([0.29557332], dtype=float32), 0.013917966]. 
=============================================
[2019-03-26 16:58:49,643] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0941220e-17 1.0000000e+00 1.1281338e-20 8.2872705e-20 1.8567824e-26], sum to 1.0000
[2019-03-26 16:58:49,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9198
[2019-03-26 16:58:49,660] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2552178.866442685 W.
[2019-03-26 16:58:49,668] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 87.33333333333334, 1.0, 2.0, 0.6083062079246087, 1.0, 1.0, 0.6083062079246087, 1.0, 1.0, 1.03, 6.940908041209208, 6.9112, 170.5573041426782, 2552178.866442685, 2530897.788078676, 491009.4283904542], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4587600.0000, 
sim time next is 4588200.0000, 
raw observation next is [28.0, 86.5, 1.0, 2.0, 0.6967097299423636, 1.0, 2.0, 0.6967097299423636, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1948215.447494898, 1948215.447494898, 372722.1456067696], 
processed observation next is [1.0, 0.08695652173913043, 0.5260663507109005, 0.865, 1.0, 1.0, 0.6345900360751369, 1.0, 1.0, 0.6345900360751369, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5411709576374717, 0.5411709576374717, 0.5563017098608501], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1898765], dtype=float32), 1.5327234]. 
=============================================
[2019-03-26 16:58:51,106] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9619041e-07 9.8713708e-01 6.0834524e-13 1.2862434e-02 9.2784963e-16], sum to 1.0000
[2019-03-26 16:58:51,112] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6425
[2019-03-26 16:58:51,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2750653.207903025 W.
[2019-03-26 16:58:51,124] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.6699401443891493, 1.0, 2.0, 0.6555601117088371, 1.0, 2.0, 1.03, 7.00509536208406, 6.9112, 170.5573041426782, 2750653.207903025, 2683392.140623081, 512003.6039258493], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4612800.0000, 
sim time next is 4613400.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.9664399978072987, 1.0, 2.0, 0.9664399978072987, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2703327.975398209, 2703327.975398208, 509046.2935448462], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.9595662624184322, 1.0, 1.0, 0.9595662624184322, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7509244376106136, 0.7509244376106133, 0.7597705873803674], 
reward next is 0.2402, 
noisyNet noise sample is [array([0.99469537], dtype=float32), -0.74599206]. 
=============================================
[2019-03-26 16:58:53,027] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9219662e-25 1.0000000e+00 1.1042986e-27 3.9155783e-31 8.3997085e-37], sum to 1.0000
[2019-03-26 16:58:53,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9388
[2019-03-26 16:58:53,046] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.58333333333334, 94.00000000000001, 1.0, 2.0, 0.4767004995338715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668384.50316243, 668384.50316243, 180320.1372688563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4659000.0000, 
sim time next is 4659600.0000, 
raw observation next is [24.66666666666667, 94.0, 1.0, 2.0, 0.4810413142265207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672172.116678605, 672172.1166786043, 180678.4378513148], 
processed observation next is [1.0, 0.9565217391304348, 0.36808846761453423, 0.94, 1.0, 1.0, 0.37474857135725387, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18671447685516804, 0.18671447685516784, 0.269669310225843], 
reward next is 0.7303, 
noisyNet noise sample is [array([-0.03950189], dtype=float32), -1.5806009]. 
=============================================
[2019-03-26 16:58:56,523] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 16:58:56,524] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 16:58:56,527] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 16:58:56,527] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:58:56,528] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:58:56,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 16:58:56,531] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 16:58:56,531] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:58:56,532] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:58:56,534] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 16:58:56,536] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 16:58:56,557] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 16:58:56,581] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 16:58:56,606] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 16:58:56,606] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 16:58:56,607] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 16:59:06,456] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 16:59:06,458] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [18.2, 90.66666666666667, 1.0, 2.0, 0.2260716568205668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 375605.6039571176, 375605.603957117, 158354.8183598971]
[2019-03-26 16:59:06,459] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:59:06,462] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.0158077e-28 1.0000000e+00 1.3364854e-29 4.0813320e-34 1.3597448e-37], sampled 0.06981423640545659
[2019-03-26 16:59:07,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 16:59:07,894] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.4897163, 56.725278215, 1.0, 2.0, 0.4263749626773569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687119.0417952575, 687119.0417952575, 182959.850897034]
[2019-03-26 16:59:07,894] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 16:59:07,896] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.3232547e-29 1.0000000e+00 3.4282697e-30 5.0018447e-36 5.2422032e-38], sampled 0.6991720292852952
[2019-03-26 16:59:36,474] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 16:59:36,475] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653]
[2019-03-26 16:59:36,477] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 16:59:36,479] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9732070e-30 1.0000000e+00 1.9344811e-31 6.9257955e-38 0.0000000e+00], sampled 0.29611571380072166
[2019-03-26 16:59:43,204] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 16:59:43,206] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.5, 58.0, 1.0, 2.0, 0.7140589501122218, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005976161314181, 6.9112, 168.9123160390242, 1894802.426179916, 1827565.210345877, 387728.7906420308]
[2019-03-26 16:59:43,207] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 16:59:43,210] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.5707310e-16 1.0000000e+00 2.5264515e-21 2.1134398e-13 4.7208878e-25], sampled 0.28321641485126425
[2019-03-26 16:59:43,211] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1894802.426179916 W.
[2019-03-26 17:00:35,238] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 17:00:35,241] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.43333333333333, 62.66666666666667, 1.0, 2.0, 0.60102659191635, 0.0, 2.0, 0.0, 1.0, 2.0, 1.026652581549631, 6.9112, 6.9112, 168.9129329335637, 1680458.878950362, 1680458.878950362, 364594.5207955799]
[2019-03-26 17:00:35,242] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:00:35,246] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.317851e-18 1.000000e+00 9.317334e-22 8.002640e-18 8.533427e-27], sampled 0.985412868143102
[2019-03-26 17:00:35,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1680458.878950362 W.
[2019-03-26 17:00:53,042] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00838344], dtype=float32), 0.09017793]
[2019-03-26 17:00:53,042] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.63333333333333, 72.0, 1.0, 2.0, 0.7541127519156722, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.985740584840847, 6.9112, 168.9124531324098, 1950854.390116262, 1897972.891334016, 397565.0118882139]
[2019-03-26 17:00:53,043] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:00:53,046] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1843581e-15 1.0000000e+00 5.8568798e-21 3.4661911e-13 1.1744234e-24], sampled 0.8736403601900434
[2019-03-26 17:00:53,048] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1950854.390116262 W.
[2019-03-26 17:00:53,755] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.1057 3163988777.9475 1774.0000
[2019-03-26 17:00:53,761] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8371 2842761137.4341 1131.0000
[2019-03-26 17:00:53,767] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:00:53,883] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2115 2927394889.7897 1338.0000
[2019-03-26 17:00:53,892] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.0735 2779388539.9568 933.0000
[2019-03-26 17:00:54,909] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1400000, evaluation results [1400000.0, 7885.105714684413, 3163988777.947488, 1774.0, 8254.211531080065, 2927394889.7897344, 1338.0, 8661.07353302349, 2779388539.9567747, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8495.837115965189, 2842761137.4341326, 1131.0]
[2019-03-26 17:00:56,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3638754e-21 1.0000000e+00 1.6404748e-26 4.4280555e-23 1.0533847e-32], sum to 1.0000
[2019-03-26 17:00:56,097] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4607
[2019-03-26 17:00:56,105] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 68.66666666666667, 1.0, 2.0, 0.4715642422453523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 658925.4390865909, 658925.4390865916, 179262.4210117463], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4902000.0000, 
sim time next is 4902600.0000, 
raw observation next is [29.16666666666667, 69.33333333333333, 1.0, 2.0, 0.4777860276189966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 667621.9867698877, 667621.9867698883, 180190.1178104766], 
processed observation next is [1.0, 0.7391304347826086, 0.581358609794629, 0.6933333333333332, 1.0, 1.0, 0.37082653929999587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18545055188052437, 0.18545055188052453, 0.26894047434399493], 
reward next is 0.7311, 
noisyNet noise sample is [array([-0.02008003], dtype=float32), -1.6488725]. 
=============================================
[2019-03-26 17:00:58,880] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6538655e-27 1.0000000e+00 4.2006142e-29 1.1089641e-33 6.4975295e-37], sum to 1.0000
[2019-03-26 17:00:58,887] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7424
[2019-03-26 17:00:58,892] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.6163231255190609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861281.7107726893, 861281.7107726893, 203821.3754249572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [28.33333333333334, 82.5, 1.0, 2.0, 0.7697310751617751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1075770.468842834, 1075770.468842834, 236617.6538215202], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.825, 1.0, 1.0, 0.7225675604358736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29882513023412055, 0.29882513023412055, 0.3531606773455525], 
reward next is 0.6468, 
noisyNet noise sample is [array([0.2786681], dtype=float32), -0.59614885]. 
=============================================
[2019-03-26 17:01:00,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4929501e-08 9.9695230e-01 9.9845237e-15 3.0476451e-03 1.1489381e-17], sum to 1.0000
[2019-03-26 17:01:00,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4034
[2019-03-26 17:01:00,141] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2306136.864607786 W.
[2019-03-26 17:01:00,145] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5497167030798824, 1.0, 2.0, 0.5497167030798824, 1.0, 2.0, 0.9529605198726879, 6.9112, 6.9112, 170.5573041426782, 2306136.864607786, 2306136.864607786, 450884.9255395699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4791000.0000, 
sim time next is 4791600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.7327581869837119, 1.0, 2.0, 0.7327581869837119, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2049114.462858325, 2049114.462858325, 388462.6418205633], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.6780219120285685, 1.0, 1.0, 0.6780219120285685, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5691984619050903, 0.5691984619050903, 0.5797949877918855], 
reward next is 0.4202, 
noisyNet noise sample is [array([0.6698185], dtype=float32), -1.3860294]. 
=============================================
[2019-03-26 17:01:11,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5966253e-29 1.0000000e+00 1.5777576e-31 1.0286593e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:01:11,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4337
[2019-03-26 17:01:11,450] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.5, 63.0, 1.0, 2.0, 0.5358912381692663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748842.4227913615, 748842.4227913608, 189410.9069302468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5059800.0000, 
sim time next is 5060400.0000, 
raw observation next is [31.33333333333333, 63.0, 1.0, 2.0, 0.531511780117165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742720.5266115637, 742720.5266115637, 188680.8784446958], 
processed observation next is [0.0, 0.5652173913043478, 0.6840442338072668, 0.63, 1.0, 1.0, 0.43555636158694583, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20631125739210104, 0.20631125739210104, 0.2816132514099937], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.3681645], dtype=float32), -0.26680312]. 
=============================================
[2019-03-26 17:01:13,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3657469e-25 1.0000000e+00 8.2468976e-29 2.3233928e-31 9.5161555e-37], sum to 1.0000
[2019-03-26 17:01:13,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6596
[2019-03-26 17:01:13,545] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.511770668521239, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715125.5328461556, 715125.5328461563, 185460.7396174659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5007000.0000, 
sim time next is 5007600.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5125830964631871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 716261.1662004346, 716261.1662004339, 185590.9120291731], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4127507186303459, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19896143505567626, 0.19896143505567607, 0.2770013612375718], 
reward next is 0.7230, 
noisyNet noise sample is [array([-1.0571884], dtype=float32), -0.1880915]. 
=============================================
[2019-03-26 17:01:28,712] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1764136e-07 9.9634039e-01 8.5235622e-13 3.6594267e-03 5.3202446e-16], sum to 1.0000
[2019-03-26 17:01:28,721] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0721
[2019-03-26 17:01:28,729] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2685097.974073776 W.
[2019-03-26 17:01:28,735] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.76666666666667, 70.66666666666667, 1.0, 2.0, 0.9599297667087607, 1.0, 2.0, 0.9599297667087607, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2685097.974073776, 2685097.974073776, 505252.9721877006], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5476800.0000, 
sim time next is 5477400.0000, 
raw observation next is [33.0, 70.0, 1.0, 2.0, 0.6972321340977841, 1.0, 2.0, 0.6692061065631547, 1.0, 1.0, 1.03, 7.005097513913341, 6.9112, 170.5573041426782, 2807974.548816431, 2740711.940093643, 520457.6252320357], 
processed observation next is [1.0, 0.391304347826087, 0.7630331753554502, 0.7, 1.0, 1.0, 0.635219438672029, 1.0, 1.0, 0.6014531404375357, 1.0, 0.5, 1.0365853658536586, 0.009389751391334134, 0.0, 0.8375144448122397, 0.7799929302267864, 0.7613088722482342, 0.7768024257194562], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7400269], dtype=float32), -0.0079499725]. 
=============================================
[2019-03-26 17:01:29,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7798886e-20 1.0000000e+00 1.6978025e-23 1.9942970e-24 3.1069817e-30], sum to 1.0000
[2019-03-26 17:01:29,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-26 17:01:29,110] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.36666666666667, 81.5, 1.0, 2.0, 0.568882382530602, 0.0, 2.0, 0.0, 1.0, 1.0, 0.987960566176923, 6.9112, 6.9112, 168.9126783838104, 1590516.941572226, 1590516.941572226, 348065.8842743232], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5298600.0000, 
sim time next is 5299200.0000, 
raw observation next is [30.5, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.041530434500843, 6.9112, 168.911945167853, 1546278.591307777, 1453818.24904212, 311356.4894337737], 
processed observation next is [1.0, 0.34782608695652173, 0.6445497630331753, 0.81, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.013033043450084315, 0.0, 0.82943497899725, 0.42952183091882695, 0.4038384025117, 0.4647111782593637], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0128253], dtype=float32), -0.5478803]. 
=============================================
[2019-03-26 17:01:32,459] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.2828773e-17 1.0000000e+00 4.8786765e-21 3.7758557e-18 1.2480741e-26], sum to 1.0000
[2019-03-26 17:01:32,467] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6533
[2019-03-26 17:01:32,473] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.91666666666666, 92.16666666666667, 1.0, 2.0, 0.3721865496740245, 1.0, 1.0, 0.3721865496740245, 1.0, 1.0, 0.64636495281097, 6.9112, 6.9112, 170.5573041426782, 1560840.784156675, 1560840.784156675, 338026.9998115039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5453400.0000, 
sim time next is 5454000.0000, 
raw observation next is [27.9, 92.0, 1.0, 2.0, 1.013365492973044, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129416416607, 1416499.273721447, 1416499.273721447, 303028.3157490129], 
processed observation next is [1.0, 0.13043478260869565, 0.5213270142180094, 0.92, 1.0, 1.0, 1.0161030035819807, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294398721398335, 0.3934720204781797, 0.3934720204781797, 0.45228106828210884], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3233931], dtype=float32), -0.68762016]. 
=============================================
[2019-03-26 17:01:32,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.51234]
 [49.84476]
 [49.21678]
 [48.82636]
 [53.98748]], R is [[50.372715  ]
 [49.86898804]
 [49.37030029]
 [49.35876465]
 [49.22167206]].
[2019-03-26 17:01:39,856] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5513371e-23 1.0000000e+00 1.8462568e-28 1.2669548e-26 5.0544989e-35], sum to 1.0000
[2019-03-26 17:01:39,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4285
[2019-03-26 17:01:39,869] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.95, 55.0, 1.0, 2.0, 0.5206231340394863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104266, 727499.8097175373, 727499.8097175378, 186893.5971046896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5506200.0000, 
sim time next is 5506800.0000, 
raw observation next is [33.7, 56.33333333333333, 1.0, 2.0, 0.5287573612843565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738870.2358271822, 738870.2358271822, 188227.1951197323], 
processed observation next is [1.0, 0.7391304347826086, 0.7962085308056873, 0.5633333333333332, 1.0, 1.0, 0.4322377846799475, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20524173217421726, 0.20524173217421726, 0.28093611211900343], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.4286754], dtype=float32), -1.0332305]. 
=============================================
[2019-03-26 17:01:43,262] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4032283e-28 1.0000000e+00 8.2335885e-32 8.3139277e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:01:43,264] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1387
[2019-03-26 17:01:43,271] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 59.0, 1.0, 2.0, 0.5421744223301029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757625.53488525, 757625.5348852506, 190469.7265458026], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5508000.0000, 
sim time next is 5508600.0000, 
raw observation next is [32.93333333333334, 60.5, 1.0, 2.0, 0.5506815927695967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769517.6196698534, 769517.6196698528, 191919.2281587607], 
processed observation next is [1.0, 0.782608695652174, 0.7598736176935231, 0.605, 1.0, 1.0, 0.45865252140915264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21375489435273703, 0.2137548943527369, 0.2864466091921801], 
reward next is 0.7136, 
noisyNet noise sample is [array([1.5192282], dtype=float32), -0.8106639]. 
=============================================
[2019-03-26 17:01:49,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7886380e-27 1.0000000e+00 7.9208308e-30 1.5894755e-33 3.0283349e-38], sum to 1.0000
[2019-03-26 17:01:49,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2215
[2019-03-26 17:01:49,356] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 91.0, 1.0, 2.0, 0.5255056797706216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734324.8595977512, 734324.8595977512, 187688.4802586822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5616000.0000, 
sim time next is 5616600.0000, 
raw observation next is [26.25, 91.16666666666667, 1.0, 2.0, 0.5242929619366326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732629.6620206813, 732629.6620206819, 187489.5288003953], 
processed observation next is [0.0, 0.0, 0.4431279620853081, 0.9116666666666667, 1.0, 1.0, 0.42685899028509944, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20350823945018925, 0.20350823945018942, 0.27983511761253027], 
reward next is 0.7202, 
noisyNet noise sample is [array([-1.1201608], dtype=float32), -0.6786658]. 
=============================================
[2019-03-26 17:01:50,531] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:01:50,535] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:01:50,537] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:50,538] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:01:50,539] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:01:50,541] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:50,541] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:50,542] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:01:50,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:01:50,545] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:50,546] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:01:50,568] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-26 17:01:50,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-26 17:01:50,617] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-26 17:01:50,617] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-26 17:01:50,655] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-26 17:02:01,286] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00040425], dtype=float32), 0.09255518]
[2019-03-26 17:02:01,288] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.98333333333333, 74.83333333333333, 1.0, 2.0, 0.3469373038205161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555208.6808009441, 555208.6808009441, 171390.6435245506]
[2019-03-26 17:02:01,290] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:02:01,293] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2381288e-32 1.0000000e+00 4.0724539e-33 0.0000000e+00 0.0000000e+00], sampled 0.9956087838882245
[2019-03-26 17:02:19,158] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00040425], dtype=float32), 0.09255518]
[2019-03-26 17:02:19,159] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.91666666666666, 94.83333333333333, 1.0, 2.0, 0.3878601054404716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578342.9004447154, 578342.9004447154, 172545.0793678732]
[2019-03-26 17:02:19,160] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:02:19,163] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3480458e-31 1.0000000e+00 6.1482777e-33 0.0000000e+00 0.0000000e+00], sampled 0.8388551300005936
[2019-03-26 17:02:44,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00040425], dtype=float32), 0.09255518]
[2019-03-26 17:02:44,981] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.33333333333334, 71.33333333333333, 1.0, 2.0, 0.8415090909836798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1176142.451396595, 1176142.451396594, 254356.2409730892]
[2019-03-26 17:02:44,984] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:02:44,986] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1853633e-27 1.0000000e+00 2.3958311e-29 1.4229871e-34 3.9970915e-37], sampled 0.207729140391255
[2019-03-26 17:03:12,741] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00040425], dtype=float32), 0.09255518]
[2019-03-26 17:03:12,741] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.9, 72.66666666666667, 1.0, 2.0, 0.5885741326758132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 822488.8231333845, 822488.8231333838, 198636.123374763]
[2019-03-26 17:03:12,743] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:03:12,747] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8860021e-29 1.0000000e+00 1.3369634e-31 4.1432911e-36 0.0000000e+00], sampled 0.36907519199295713
[2019-03-26 17:03:21,622] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00040425], dtype=float32), 0.09255518]
[2019-03-26 17:03:21,624] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 87.0, 1.0, 2.0, 0.536514041933107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749713.0219583681, 749713.0219583681, 189514.8672336705]
[2019-03-26 17:03:21,625] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:03:21,629] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7532288e-29 1.0000000e+00 1.2218597e-31 1.1151602e-36 0.0000000e+00], sampled 0.8410881485617037
[2019-03-26 17:03:47,414] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2118 2927459259.5787 1338.0000
[2019-03-26 17:03:48,306] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1026 3007788747.8483 1766.0000
[2019-03-26 17:03:48,314] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6674 3164200272.3547 1778.0000
[2019-03-26 17:03:48,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7906 2779397493.2499 933.0000
[2019-03-26 17:03:48,356] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6656 2842565299.5504 1131.0000
[2019-03-26 17:03:49,371] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1425000, evaluation results [1425000.0, 7882.667391253242, 3164200272.354699, 1778.0, 8254.211789258557, 2927459259.5787225, 1338.0, 8659.790577032569, 2779397493.2499228, 933.0, 7998.102600828673, 3007788747.848251, 1766.0, 8496.665578540826, 2842565299.55038, 1131.0]
[2019-03-26 17:03:55,273] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.2993296e-30 1.0000000e+00 5.1076340e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:03:55,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2277
[2019-03-26 17:03:55,289] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 54.66666666666667, 1.0, 2.0, 0.5363100960623538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749427.9319116526, 749427.9319116526, 189480.3181243428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5746200.0000, 
sim time next is 5746800.0000, 
raw observation next is [33.2, 54.33333333333334, 1.0, 2.0, 0.5292446802138429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739551.4382507083, 739551.438250709, 188305.4382985118], 
processed observation next is [0.0, 0.5217391304347826, 0.7725118483412324, 0.5433333333333334, 1.0, 1.0, 0.4328249159202926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20543095506964118, 0.20543095506964137, 0.28105289298285346], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.21930173], dtype=float32), 0.9261445]. 
=============================================
[2019-03-26 17:03:56,948] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.7436532e-28 1.0000000e+00 8.3082737e-31 1.1699459e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 17:03:56,958] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1586
[2019-03-26 17:03:56,963] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 82.83333333333334, 1.0, 2.0, 0.5585933127316969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780577.4499351569, 780577.4499351569, 193285.6528329755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5946600.0000, 
sim time next is 5947200.0000, 
raw observation next is [28.5, 83.0, 1.0, 2.0, 0.5555106039364517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776268.1032273677, 776268.1032273677, 192750.558847794], 
processed observation next is [1.0, 0.8695652173913043, 0.5497630331753555, 0.83, 1.0, 1.0, 0.4644706071523514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2156300286742688, 0.2156300286742688, 0.2876874012653642], 
reward next is 0.7123, 
noisyNet noise sample is [array([-1.9568411], dtype=float32), -0.25967026]. 
=============================================
[2019-03-26 17:04:03,989] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3610128e-08 9.9875903e-01 6.1047824e-15 1.2409840e-03 6.5698593e-18], sum to 1.0000
[2019-03-26 17:04:03,996] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4271
[2019-03-26 17:04:04,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2367781.198055334 W.
[2019-03-26 17:04:04,010] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.23333333333333, 78.16666666666667, 1.0, 2.0, 0.8465955476496925, 1.0, 1.0, 0.8465955476496925, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2367781.198055334, 2367781.198055334, 443199.3128800839], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5933400.0000, 
sim time next is 5934000.0000, 
raw observation next is [30.26666666666667, 78.33333333333334, 1.0, 2.0, 0.8226355743623578, 1.0, 2.0, 0.8226355743623578, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2300707.614720678, 2300707.614720678, 431048.5172734374], 
processed observation next is [1.0, 0.6956521739130435, 0.6334913112164299, 0.7833333333333334, 1.0, 1.0, 0.7863079209185033, 1.0, 1.0, 0.7863079209185033, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6390854485335217, 0.6390854485335217, 0.6433559959305036], 
reward next is 0.3566, 
noisyNet noise sample is [array([1.3117625], dtype=float32), -0.81932825]. 
=============================================
[2019-03-26 17:04:04,026] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[40.759567]
 [42.027042]
 [43.575607]
 [42.397396]
 [42.723106]], R is [[41.52439499]
 [41.10914993]
 [40.69805908]
 [40.65985107]
 [40.25325394]].
[2019-03-26 17:04:08,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.1111357e-27 1.0000000e+00 4.7655517e-29 4.5544642e-33 1.8656763e-36], sum to 1.0000
[2019-03-26 17:04:08,071] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1380
[2019-03-26 17:04:08,075] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333333, 93.83333333333334, 1.0, 2.0, 0.6643650645838307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 928447.3380341934, 928447.3380341934, 213340.6206680305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5979000.0000, 
sim time next is 5979600.0000, 
raw observation next is [25.9, 94.0, 1.0, 2.0, 0.6603204725723009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 922792.5823845468, 922792.5823845468, 212512.677932431], 
processed observation next is [1.0, 0.21739130434782608, 0.42654028436018954, 0.94, 1.0, 1.0, 0.5907475573160251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.25633127288459634, 0.25633127288459634, 0.31718310139168804], 
reward next is 0.6828, 
noisyNet noise sample is [array([-0.7874973], dtype=float32), -0.7577135]. 
=============================================
[2019-03-26 17:04:11,311] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9954592e-26 1.0000000e+00 7.2558508e-29 2.2196540e-31 1.3621596e-36], sum to 1.0000
[2019-03-26 17:04:11,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0064
[2019-03-26 17:04:11,327] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 84.33333333333334, 1.0, 2.0, 0.5178707242791181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723652.3824592204, 723652.3824592197, 186443.6304068216], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6562200.0000, 
sim time next is 6562800.0000, 
raw observation next is [27.2, 85.0, 1.0, 2.0, 0.5191763705832839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725477.46478193, 725477.4647819294, 186655.4129660442], 
processed observation next is [1.0, 1.0, 0.4881516587677725, 0.85, 1.0, 1.0, 0.42069442238949867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20152151799498055, 0.2015215179949804, 0.27859016860603614], 
reward next is 0.7214, 
noisyNet noise sample is [array([0.9209314], dtype=float32), 0.6366675]. 
=============================================
[2019-03-26 17:04:13,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.9211934e-30 1.0000000e+00 5.3274133e-32 1.5763262e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:04:13,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3984
[2019-03-26 17:04:13,985] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5251428749602071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733817.7126240182, 733817.7126240176, 187629.4753346363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6234600.0000, 
sim time next is 6235200.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.5251337541611616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733804.9631114175, 733804.9631114168, 187627.9789351105], 
processed observation next is [0.0, 0.17391304347826086, 0.4549763033175356, 0.91, 1.0, 1.0, 0.4278719929652549, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20383471197539374, 0.20383471197539355, 0.28004175960464256], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.23564708], dtype=float32), 0.44946018]. 
=============================================
[2019-03-26 17:04:17,074] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.775847e-19 1.000000e+00 2.962935e-25 5.405564e-20 4.963693e-30], sum to 1.0000
[2019-03-26 17:04:17,079] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0222
[2019-03-26 17:04:17,085] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 71.5, 1.0, 2.0, 0.4871464070672719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 680705.6622458267, 680705.6622458261, 181609.9749335546], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6111000.0000, 
sim time next is 6111600.0000, 
raw observation next is [29.63333333333333, 72.33333333333333, 1.0, 2.0, 0.500363813360927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699180.8559419446, 699180.8559419439, 183655.5954063713], 
processed observation next is [1.0, 0.7391304347826086, 0.6034755134281199, 0.7233333333333333, 1.0, 1.0, 0.3980286907962975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19421690442831796, 0.19421690442831777, 0.2741128289647333], 
reward next is 0.7259, 
noisyNet noise sample is [array([2.8346312], dtype=float32), -0.45661366]. 
=============================================
[2019-03-26 17:04:21,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.8236397e-10 9.9994576e-01 6.7288303e-16 5.4280208e-05 4.1194789e-19], sum to 1.0000
[2019-03-26 17:04:21,310] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1793
[2019-03-26 17:04:21,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2004583.937654396 W.
[2019-03-26 17:04:21,325] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.55, 75.5, 1.0, 2.0, 0.477899378317125, 1.0, 2.0, 0.477899378317125, 1.0, 1.0, 0.8298420783365293, 6.911199999999999, 6.9112, 170.5573041426782, 2004583.937654396, 2004583.937654396, 400179.9165969827], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6175800.0000, 
sim time next is 6176400.0000, 
raw observation next is [29.63333333333333, 75.0, 1.0, 2.0, 0.8228724746138986, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.997380818122162, 6.9112, 168.912443552995, 2047084.810622758, 1985945.357801834, 413892.5624414475], 
processed observation next is [1.0, 0.4782608695652174, 0.6034755134281199, 0.75, 1.0, 1.0, 0.7865933429083115, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008618081812216172, 0.0, 0.829437426296459, 0.5686346696174328, 0.5516514882782871, 0.6177500931961903], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81921494], dtype=float32), -1.1179335]. 
=============================================
[2019-03-26 17:04:24,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0953986e-29 1.0000000e+00 2.3829222e-31 9.3051212e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:04:24,178] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5723
[2019-03-26 17:04:24,184] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 91.0, 1.0, 2.0, 0.5218648377209403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729235.516811192, 729235.5168111913, 187092.9816656346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6228000.0000, 
sim time next is 6228600.0000, 
raw observation next is [26.41666666666666, 91.00000000000001, 1.0, 2.0, 0.5217229452310012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729037.1732101989, 729037.1732101989, 187069.8875459699], 
processed observation next is [0.0, 0.08695652173913043, 0.4510268562401261, 0.9100000000000001, 1.0, 1.0, 0.423762584615664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2025103258917219, 0.2025103258917219, 0.27920878738204463], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.05032381], dtype=float32), -0.7667349]. 
=============================================
[2019-03-26 17:04:25,332] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7022979e-30 1.0000000e+00 9.2074027e-32 1.2016602e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:04:25,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7049
[2019-03-26 17:04:25,343] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 85.66666666666667, 1.0, 2.0, 0.5409758123877733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 755950.0212551511, 755950.0212551504, 190265.5886259529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6248400.0000, 
sim time next is 6249000.0000, 
raw observation next is [27.83333333333333, 85.33333333333334, 1.0, 2.0, 0.541440628432529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756599.7782903083, 756599.7782903077, 190344.1061927358], 
processed observation next is [0.0, 0.30434782608695654, 0.518167456556082, 0.8533333333333334, 1.0, 1.0, 0.44751882943678195, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2101666050806412, 0.21016660508064103, 0.2840956808846803], 
reward next is 0.7159, 
noisyNet noise sample is [array([0.2738944], dtype=float32), 0.7971087]. 
=============================================
[2019-03-26 17:04:25,352] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.347244]
 [75.32779 ]
 [75.316246]
 [75.3096  ]
 [75.29303 ]], R is [[75.33028412]
 [75.29299927]
 [75.25642395]
 [75.22052002]
 [75.18515015]].
[2019-03-26 17:04:35,498] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3531790e-21 1.0000000e+00 2.5106914e-24 2.7149918e-26 4.4480147e-31], sum to 1.0000
[2019-03-26 17:04:35,509] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8832
[2019-03-26 17:04:35,514] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 85.33333333333334, 1.0, 2.0, 0.8740163116194288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1221602.585899711, 1221602.585899711, 262888.4289950902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6405600.0000, 
sim time next is 6406200.0000, 
raw observation next is [26.8, 85.5, 1.0, 2.0, 0.8555036380411135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1195713.064414432, 1195713.064414432, 257989.2224765994], 
processed observation next is [1.0, 0.13043478260869565, 0.4691943127962086, 0.855, 1.0, 1.0, 0.8259079976398958, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3321425178928978, 0.3321425178928978, 0.3850585410098498], 
reward next is 0.6149, 
noisyNet noise sample is [array([0.6559204], dtype=float32), 1.6419909]. 
=============================================
[2019-03-26 17:04:37,859] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.7757590e-27 1.0000000e+00 3.6628067e-29 8.0128032e-35 1.9690205e-37], sum to 1.0000
[2019-03-26 17:04:37,864] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5442
[2019-03-26 17:04:37,868] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 93.0, 1.0, 2.0, 0.5747600634431401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 803177.384302047, 803177.3843020463, 196133.1431390801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6584400.0000, 
sim time next is 6585000.0000, 
raw observation next is [25.76666666666667, 92.5, 1.0, 2.0, 0.8252243814053289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1153369.624721331, 1153369.624721331, 250194.7616065977], 
processed observation next is [1.0, 0.21739130434782608, 0.42022116903633505, 0.925, 1.0, 1.0, 0.789426965548589, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32038045131148085, 0.32038045131148085, 0.37342501732328015], 
reward next is 0.6266, 
noisyNet noise sample is [array([-0.5032878], dtype=float32), 2.4308815]. 
=============================================
[2019-03-26 17:04:37,869] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6506303e-26 1.0000000e+00 1.5519598e-29 6.8597735e-30 2.9942901e-36], sum to 1.0000
[2019-03-26 17:04:37,870] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3292
[2019-03-26 17:04:37,878] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.41666666666667, 69.5, 1.0, 2.0, 0.4914043035871946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 686657.2837281837, 686657.2837281843, 182261.4946087566], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6457800.0000, 
sim time next is 6458400.0000, 
raw observation next is [29.3, 70.0, 1.0, 2.0, 0.5023734663010554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 701989.9622427048, 701989.9622427048, 183969.3246355474], 
processed observation next is [1.0, 0.782608695652174, 0.5876777251184835, 0.7, 1.0, 1.0, 0.4004499593988619, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19499721173408466, 0.19499721173408466, 0.27458108154559313], 
reward next is 0.7254, 
noisyNet noise sample is [array([-1.7884068], dtype=float32), -0.1609814]. 
=============================================
[2019-03-26 17:04:37,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.15139 ]
 [63.221   ]
 [62.970486]
 [62.700054]
 [62.354557]], R is [[60.79584122]
 [60.89514923]
 [61.00047302]
 [61.10379028]
 [61.20371628]].
[2019-03-26 17:04:44,695] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:04:44,699] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:04:44,700] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:04:44,701] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:44,702] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:04:44,704] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:44,705] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:04:44,703] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:04:44,706] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:44,708] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:44,711] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:04:44,733] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run59
[2019-03-26 17:04:44,754] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run59
[2019-03-26 17:04:44,777] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run59
[2019-03-26 17:04:44,799] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run59
[2019-03-26 17:04:44,820] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run59
[2019-03-26 17:04:53,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:04:53,789] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.61666666666667, 55.16666666666667, 1.0, 2.0, 0.4833536202975814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781938.7024852431, 781938.7024852431, 192488.0500278124]
[2019-03-26 17:04:53,791] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:04:53,793] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0188722e-27 1.0000000e+00 2.2722245e-29 8.4170740e-34 1.0921987e-36], sampled 0.38165518785342833
[2019-03-26 17:05:07,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:07,985] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.6, 65.0, 1.0, 2.0, 0.3072877611378939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490914.7059256292, 490914.7059256285, 166429.1760770232]
[2019-03-26 17:05:07,987] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:05:07,989] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.4681804e-29 1.0000000e+00 7.2586123e-31 3.2862159e-35 2.2552283e-38], sampled 0.7207229582677755
[2019-03-26 17:05:16,621] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:16,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.81666666666667, 94.0, 1.0, 2.0, 0.487248108528277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680847.8185763434, 680847.8185763434, 181621.7536575945]
[2019-03-26 17:05:16,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:05:16,628] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.12246665e-29 1.00000000e+00 3.28524481e-31 1.50757115e-37
 0.00000000e+00], sampled 0.6447575771074952
[2019-03-26 17:05:26,680] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:26,681] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.45, 83.5, 1.0, 2.0, 0.5672289583428313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 792649.3906920834, 792649.390692084, 194798.9276302756]
[2019-03-26 17:05:26,682] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:05:26,687] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.0003172e-26 1.0000000e+00 7.2580102e-29 1.1805735e-30 3.3110409e-36], sampled 0.48718838142793475
[2019-03-26 17:05:43,301] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:43,302] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.202830455, 77.45220954500002, 1.0, 2.0, 0.5276146822684804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737272.9351007142, 737272.9351007142, 188035.0604738925]
[2019-03-26 17:05:43,303] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:05:43,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5754065e-29 1.0000000e+00 7.8945533e-31 3.0242742e-36 1.8692792e-38], sampled 0.22303427716872215
[2019-03-26 17:05:44,706] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:44,707] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.58333333333334, 72.0, 1.0, 2.0, 0.5792969286547167, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 809519.6762550612, 809519.6762550612, 196951.4408250098]
[2019-03-26 17:05:44,707] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:05:44,709] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7475313e-25 1.0000000e+00 4.1368012e-28 5.4910802e-30 2.4790711e-35], sampled 0.9451409856078258
[2019-03-26 17:05:52,383] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:05:52,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.3, 50.0, 1.0, 2.0, 0.5733254362013952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801171.8609656424, 801171.8609656424, 195878.9499278]
[2019-03-26 17:05:52,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:05:52,386] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.1068131e-26 1.0000000e+00 2.3153437e-29 2.6440213e-31 1.2587925e-36], sampled 0.011736597242775315
[2019-03-26 17:06:28,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:06:28,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.18333333333334, 94.83333333333334, 1.0, 2.0, 0.4743727582903961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 673590.9750156048, 673590.9750156048, 181057.2359501767]
[2019-03-26 17:06:28,546] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:06:28,547] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6376336e-29 1.0000000e+00 4.7216119e-31 2.7037213e-37 0.0000000e+00], sampled 0.09876772238865184
[2019-03-26 17:06:30,768] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00768364], dtype=float32), 0.09152049]
[2019-03-26 17:06:30,769] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.41666666666666, 81.0, 1.0, 2.0, 0.5865919453128061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 819717.7940166333, 819717.7940166339, 198274.0965862309]
[2019-03-26 17:06:30,770] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:06:30,777] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.8009977e-26 1.0000000e+00 1.0131945e-28 1.1352599e-30 4.0576388e-36], sampled 0.5410511372230778
[2019-03-26 17:06:42,008] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.9756 2842572409.3181 1129.0000
[2019-03-26 17:06:42,212] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7905.4673 3162122209.7744 1738.0000
[2019-03-26 17:06:42,307] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.1865 2927081462.6250 1330.0000
[2019-03-26 17:06:42,563] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.0443 2779168306.3500 927.0000
[2019-03-26 17:06:42,608] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.5158 3007444247.5232 1766.0000
[2019-03-26 17:06:43,627] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1450000, evaluation results [1450000.0, 7905.467333762889, 3162122209.7743597, 1738.0, 8258.186531745867, 2927081462.624999, 1330.0, 8663.044316407175, 2779168306.349981, 927.0, 7999.51583043124, 3007444247.5232444, 1766.0, 8498.975558885928, 2842572409.3181376, 1129.0]
[2019-03-26 17:06:45,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.7668852e-07 9.8359966e-01 2.6215195e-13 1.6399544e-02 4.1860392e-16], sum to 1.0000
[2019-03-26 17:06:45,050] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8532
[2019-03-26 17:06:45,060] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2233189.735582661 W.
[2019-03-26 17:06:45,068] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.43333333333334, 72.33333333333334, 1.0, 2.0, 0.9558372220334687, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.98612166163354, 6.9112, 168.9125108890011, 2233189.735582661, 2180037.870439372, 450738.9432217393], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6603600.0000, 
sim time next is 6604200.0000, 
raw observation next is [29.6, 71.5, 1.0, 2.0, 0.544568840963628, 1.0, 1.0, 0.544568840963628, 1.0, 2.0, 0.937627248393784, 6.9112, 6.9112, 170.5573041426782, 2284521.138920193, 2284521.138920193, 445720.183720376], 
processed observation next is [1.0, 0.43478260869565216, 0.6018957345971565, 0.715, 1.0, 1.0, 0.4512877601971422, 1.0, 0.5, 0.4512877601971422, 1.0, 1.0, 0.9239356687729073, 0.0, 0.0, 0.8375144448122397, 0.6345892052556091, 0.6345892052556091, 0.6652540055528], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5629558], dtype=float32), -0.8578114]. 
=============================================
[2019-03-26 17:06:46,024] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4774330e-27 1.0000000e+00 9.1646610e-30 2.6486421e-33 2.2428325e-37], sum to 1.0000
[2019-03-26 17:06:46,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8927
[2019-03-26 17:06:46,036] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 77.0, 1.0, 2.0, 0.3320947521374722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520553.3023742306, 520553.3023742313, 168502.3308668552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6829200.0000, 
sim time next is 6829800.0000, 
raw observation next is [23.53333333333333, 77.5, 1.0, 2.0, 0.3318878576358087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 520250.3229531174, 520250.3229531174, 168479.1237519993], 
processed observation next is [0.0, 0.043478260869565216, 0.3143759873617693, 0.775, 1.0, 1.0, 0.19504561160940806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14451397859808815, 0.14451397859808815, 0.2514613787343273], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.41747648], dtype=float32), 0.7586379]. 
=============================================
[2019-03-26 17:06:51,961] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.8210629e-25 1.0000000e+00 3.6349960e-29 4.6545896e-29 3.4272394e-36], sum to 1.0000
[2019-03-26 17:06:51,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1512
[2019-03-26 17:06:51,973] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666666, 67.0, 1.0, 2.0, 0.4681830515766664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655446.089847496, 655446.0898474953, 178922.3800704158], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6718200.0000, 
sim time next is 6718800.0000, 
raw observation next is [28.53333333333333, 67.0, 1.0, 2.0, 0.4637931155155485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 652873.4973243435, 652873.497324343, 178739.0999957512], 
processed observation next is [1.0, 0.782608695652174, 0.5513428120063191, 0.67, 1.0, 1.0, 0.3539676090548778, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1813537492567621, 0.18135374925676193, 0.2667747761130615], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.5046646], dtype=float32), -0.280716]. 
=============================================
[2019-03-26 17:07:01,909] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6816059e-29 1.0000000e+00 6.1097071e-31 9.7804430e-36 3.8592878e-38], sum to 1.0000
[2019-03-26 17:07:01,919] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9948
[2019-03-26 17:07:01,924] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 53.33333333333334, 1.0, 2.0, 0.4607192371704784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 649184.6980748904, 649184.6980748904, 178370.7886708213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6956400.0000, 
sim time next is 6957000.0000, 
raw observation next is [31.5, 53.0, 1.0, 2.0, 0.4649460234275004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652843.7966502925, 652843.7966502925, 178696.0271175403], 
processed observation next is [0.0, 0.5217391304347826, 0.6919431279620853, 0.53, 1.0, 1.0, 0.35535665473192823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18134549906952568, 0.18134549906952568, 0.26671048823513477], 
reward next is 0.7333, 
noisyNet noise sample is [array([-1.1583437], dtype=float32), 1.8422195]. 
=============================================
[2019-03-26 17:07:01,937] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[76.352165]
 [76.32578 ]
 [76.257675]
 [76.12782 ]
 [76.07141 ]], R is [[76.34104919]
 [76.311409  ]
 [76.28251648]
 [76.253685  ]
 [76.22492218]].
[2019-03-26 17:07:02,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.6058980e-08 3.9820436e-01 9.3660084e-15 6.0179555e-01 4.4565629e-17], sum to 1.0000
[2019-03-26 17:07:02,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2463
[2019-03-26 17:07:02,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1971030.270436768 W.
[2019-03-26 17:07:02,698] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 51.0, 1.0, 2.0, 0.7007987968631674, 1.0, 2.0, 0.7007987968631674, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1971030.270436768, 1971030.270436768, 375888.3271070769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7041600.0000, 
sim time next is 7042200.0000, 
raw observation next is [31.2, 50.33333333333334, 1.0, 2.0, 0.7122795370759769, 1.0, 2.0, 0.7122795370759769, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2006233.838853625, 2006233.838853625, 381242.7234610731], 
processed observation next is [1.0, 0.5217391304347826, 0.6777251184834123, 0.5033333333333334, 1.0, 1.0, 0.6533488398505746, 1.0, 1.0, 0.6533488398505746, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5572871774593403, 0.5572871774593403, 0.5690189902404077], 
reward next is 0.4310, 
noisyNet noise sample is [array([0.12896769], dtype=float32), -0.03181376]. 
=============================================
[2019-03-26 17:07:08,319] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2902449e-07 1.2465738e-01 1.3559490e-14 8.7534243e-01 3.0340707e-16], sum to 1.0000
[2019-03-26 17:07:08,326] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7020
[2019-03-26 17:07:08,329] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.2, 50.33333333333334, 1.0, 2.0, 0.7122744213066009, 1.0, 2.0, 0.7122744213066009, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2006233.838853625, 2006233.838853625, 381242.3041753495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7042200.0000, 
sim time next is 7042800.0000, 
raw observation next is [31.3, 49.66666666666667, 1.0, 2.0, 0.5545393625324689, 1.0, 2.0, 0.5545393625324689, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1569731.576734437, 1569731.576734437, 320386.5491489079], 
processed observation next is [1.0, 0.5217391304347826, 0.6824644549763034, 0.4966666666666667, 1.0, 1.0, 0.4633004367861071, 1.0, 1.0, 0.4633004367861071, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.43603654909289913, 0.43603654909289913, 0.4781888793267282], 
reward next is 0.5218, 
noisyNet noise sample is [array([-0.09016836], dtype=float32), 0.045322385]. 
=============================================
[2019-03-26 17:07:09,212] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6155666e-27 1.0000000e+00 3.7909580e-30 3.6738261e-33 3.4384454e-38], sum to 1.0000
[2019-03-26 17:07:09,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4304
[2019-03-26 17:07:09,225] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 83.83333333333333, 1.0, 2.0, 0.4758985212935705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665387.7399736088, 665387.7399736088, 179957.9294025557], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7159800.0000, 
sim time next is 7160400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.47720091044263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666986.696240317, 666986.696240317, 180124.2261184937], 
processed observation next is [1.0, 0.9130434782608695, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3701215788465422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18527408228897693, 0.18527408228897693, 0.26884212853506523], 
reward next is 0.7312, 
noisyNet noise sample is [array([-2.964927], dtype=float32), 0.02880873]. 
=============================================
[2019-03-26 17:07:23,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.8258557e-26 1.0000000e+00 2.1382085e-29 4.6325842e-31 1.3246999e-36], sum to 1.0000
[2019-03-26 17:07:23,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2122
[2019-03-26 17:07:23,463] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 71.0, 1.0, 2.0, 0.3909919033648926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586428.3507421846, 586428.3507421846, 173382.0461499523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7327200.0000, 
sim time next is 7327800.0000, 
raw observation next is [26.05, 71.5, 1.0, 2.0, 0.391417254083236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 587086.5493565543, 587086.549356555, 173442.4740356298], 
processed observation next is [1.0, 0.8260869565217391, 0.43364928909952616, 0.715, 1.0, 1.0, 0.26676777600389884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1630795970434873, 0.16307959704348748, 0.2588693642322833], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.03908066], dtype=float32), 1.6670754]. 
=============================================
[2019-03-26 17:07:27,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.5564685e-23 1.0000000e+00 2.2001944e-26 3.0675473e-26 1.5916719e-33], sum to 1.0000
[2019-03-26 17:07:27,790] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9405
[2019-03-26 17:07:27,795] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.53333333333333, 89.66666666666667, 1.0, 2.0, 0.5466142941974074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 881804.8437253291, 881804.8437253286, 204049.5315351732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7402800.0000, 
sim time next is 7403400.0000, 
raw observation next is [20.5, 89.5, 1.0, 2.0, 0.5140196600526521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 830045.3471967152, 830045.3471967159, 197907.1468202413], 
processed observation next is [1.0, 0.6956521739130435, 0.1706161137440759, 0.895, 1.0, 1.0, 0.41448151813572537, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23056815199908756, 0.23056815199908776, 0.29538380122424074], 
reward next is 0.7046, 
noisyNet noise sample is [array([0.5108638], dtype=float32), -0.009061656]. 
=============================================
[2019-03-26 17:07:29,719] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:07:29,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:29,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run8
[2019-03-26 17:07:29,886] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0165188e-29 1.0000000e+00 7.2392556e-31 1.3282781e-35 8.4324183e-38], sum to 1.0000
[2019-03-26 17:07:29,891] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1216
[2019-03-26 17:07:29,894] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 91.0, 1.0, 2.0, 0.3575150991065352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546297.0502730453, 546297.050273046, 170204.3564429357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7465200.0000, 
sim time next is 7465800.0000, 
raw observation next is [22.78333333333333, 90.5, 1.0, 2.0, 0.3589739889621958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547644.7454565306, 547644.7454565306, 170289.4345128814], 
processed observation next is [0.0, 0.391304347826087, 0.27883096366508686, 0.905, 1.0, 1.0, 0.22767950477372986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15212354040459183, 0.15212354040459183, 0.2541633350938528], 
reward next is 0.7458, 
noisyNet noise sample is [array([-0.51152235], dtype=float32), -0.2247036]. 
=============================================
[2019-03-26 17:07:30,393] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2383798e-27 1.0000000e+00 7.5573025e-30 1.0523933e-31 2.7196932e-37], sum to 1.0000
[2019-03-26 17:07:30,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7458
[2019-03-26 17:07:30,405] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 88.5, 1.0, 2.0, 0.4036417151594379, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 595228.1077983001, 595228.1077982995, 173887.0774089706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7507800.0000, 
sim time next is 7508400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4040069532945039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 595397.4831866066, 595397.4831866072, 173891.3984539635], 
processed observation next is [0.0, 0.9130434782608695, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28193608830663125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16538818977405736, 0.16538818977405756, 0.2595394006775575], 
reward next is 0.7405, 
noisyNet noise sample is [array([-1.0753536], dtype=float32), 0.23134674]. 
=============================================
[2019-03-26 17:07:32,589] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.10619895e-10 9.99999881e-01 5.67617358e-17 6.42410569e-08
 1.45730952e-20], sum to 1.0000
[2019-03-26 17:07:32,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8970
[2019-03-26 17:07:32,608] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2102551.393364024 W.
[2019-03-26 17:07:32,618] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.8625022947048071, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.976943004604136, 6.9112, 168.9125065419725, 2102551.393364024, 2055911.167443827, 424878.6797377446], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7659600.0000, 
sim time next is 7660200.0000, 
raw observation next is [29.61666666666667, 68.16666666666666, 1.0, 2.0, 0.5060809378233606, 1.0, 1.0, 0.5060809378233606, 1.0, 2.0, 0.8610672654605928, 6.911199999999999, 6.9112, 170.5573041426782, 2122910.681348187, 2122910.681348188, 416071.1349106064], 
processed observation next is [1.0, 0.6521739130434783, 0.6026856240126385, 0.6816666666666665, 1.0, 1.0, 0.4049167925582658, 1.0, 0.5, 0.4049167925582658, 1.0, 1.0, 0.8305698359275521, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5896974114856075, 0.5896974114856077, 0.6210016938964275], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4609716], dtype=float32), 0.0044322205]. 
=============================================
[2019-03-26 17:07:33,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7899845e-27 1.0000000e+00 5.3453734e-30 9.3023311e-33 1.0399786e-37], sum to 1.0000
[2019-03-26 17:07:33,738] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3260
[2019-03-26 17:07:33,743] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 75.0, 1.0, 2.0, 0.425838547850772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614799.5149246486, 614799.5149246479, 175343.7455768385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7491600.0000, 
sim time next is 7492200.0000, 
raw observation next is [26.48333333333333, 75.5, 1.0, 2.0, 0.4253355507484468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 614370.1557356397, 614370.1557356397, 175311.0352889171], 
processed observation next is [0.0, 0.7391304347826086, 0.4541864139020536, 0.755, 1.0, 1.0, 0.30763319367282754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17065837659323327, 0.17065837659323327, 0.2616582616252494], 
reward next is 0.7383, 
noisyNet noise sample is [array([0.04205539], dtype=float32), -1.6668503]. 
=============================================
[2019-03-26 17:07:35,539] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 17:07:35,541] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:07:35,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,544] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:07:35,545] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:07:35,546] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,547] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,547] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:07:35,548] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:07:35,550] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,552] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:07:35,570] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run60
[2019-03-26 17:07:35,599] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run60
[2019-03-26 17:07:35,621] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run60
[2019-03-26 17:07:35,621] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run60
[2019-03-26 17:07:35,654] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run60
[2019-03-26 17:08:05,382] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:05,384] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.5, 78.0, 1.0, 2.0, 0.4991100589024285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 697428.3533497361, 697428.3533497361, 183456.4858070427]
[2019-03-26 17:08:05,385] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:08:05,389] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4576943e-26 1.0000000e+00 3.7571418e-29 1.3158943e-31 3.3982599e-36], sampled 0.4365466936864816
[2019-03-26 17:08:17,617] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:17,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.11666666666667, 80.33333333333334, 1.0, 2.0, 0.5743683529543177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802629.7960207575, 802629.7960207575, 196067.2328255726]
[2019-03-26 17:08:17,621] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:08:17,624] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2685085e-24 1.0000000e+00 5.5389052e-28 4.6043674e-28 8.4292473e-35], sampled 0.8786228218738381
[2019-03-26 17:08:19,235] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:19,236] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.95, 56.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.93714380525664, 6.9112, 168.9124641490435, 1472172.908128025, 1453767.533411757, 311352.9815682416]
[2019-03-26 17:08:19,237] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:08:19,240] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.9674434e-15 1.0000000e+00 6.3449361e-21 1.0230879e-11 5.8690155e-24], sampled 0.7677398445060997
[2019-03-26 17:08:37,200] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:37,201] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.45946378333333, 80.55666439666666, 1.0, 2.0, 0.6054160803375235, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846033.5729258755, 846033.5729258755, 201757.4327131685]
[2019-03-26 17:08:37,203] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:08:37,206] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.8615535e-24 1.0000000e+00 2.4574816e-27 5.3504206e-27 4.2755682e-34], sampled 0.7852593775086268
[2019-03-26 17:08:49,003] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:49,004] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666667, 62.33333333333333, 1.0, 2.0, 0.5346691542317358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747134.109469819, 747134.109469819, 189205.5921577475]
[2019-03-26 17:08:49,006] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:08:49,009] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0979355e-26 1.0000000e+00 2.4421342e-29 1.2423802e-31 2.6730698e-36], sampled 0.6593307950382206
[2019-03-26 17:08:55,168] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:08:55,168] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.69280269, 74.55624389, 1.0, 2.0, 1.010448941162913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1412419.756485478, 1412419.756485478, 302132.1197914669]
[2019-03-26 17:08:55,170] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:08:55,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.0293141e-23 1.0000000e+00 1.0346350e-25 1.3630606e-26 3.4106825e-32], sampled 0.4501866641708784
[2019-03-26 17:09:01,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:09:01,084] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.08333333333333, 87.83333333333334, 1.0, 2.0, 0.5359402213410656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 748910.894908808, 748910.8949088088, 189418.5853816767]
[2019-03-26 17:09:01,085] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:09:01,086] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8898125e-24 1.0000000e+00 6.2915995e-28 7.6001847e-28 8.0360065e-35], sampled 0.9404396634128168
[2019-03-26 17:09:06,451] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:09:06,451] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.91666666666667, 55.5, 1.0, 2.0, 0.5819749986038276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565103975, 813263.4908362825, 813263.4908362825, 197430.1780011703]
[2019-03-26 17:09:06,453] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:09:06,455] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.09204462e-21 1.00000000e+00 1.07533674e-26 5.63251216e-19
 3.51781026e-31], sampled 0.33495891791144883
[2019-03-26 17:09:16,611] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00195282], dtype=float32), 0.09329992]
[2019-03-26 17:09:16,613] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.43361458666666, 73.94415866, 1.0, 2.0, 0.276678719431833, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 448949.4460285124, 448949.4460285124, 163510.2368759944]
[2019-03-26 17:09:16,615] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:09:16,617] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1932704e-29 1.0000000e+00 5.2472836e-31 3.4044362e-36 2.4427659e-38], sampled 0.04617026278570002
[2019-03-26 17:09:31,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7937.9264 3160120249.8449 1664.0000
[2019-03-26 17:09:32,389] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8014.2959 3006367612.9712 1732.0000
[2019-03-26 17:09:33,126] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8508.1246 2841611537.5583 1105.0000
[2019-03-26 17:09:33,287] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8268.2001 2926456475.1789 1306.0000
[2019-03-26 17:09:33,404] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.1705 2778444903.1626 914.0000
[2019-03-26 17:09:34,421] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1475000, evaluation results [1475000.0, 7937.92636746572, 3160120249.844868, 1664.0, 8268.200069570496, 2926456475.1788964, 1306.0, 8669.17047169503, 2778444903.1626086, 914.0, 8014.295893250324, 3006367612.9712114, 1732.0, 8508.124645044576, 2841611537.5582986, 1105.0]
[2019-03-26 17:09:35,964] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.0709763e-26 1.0000000e+00 4.1182495e-30 7.0325585e-29 4.9946378e-36], sum to 1.0000
[2019-03-26 17:09:35,971] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8426
[2019-03-26 17:09:35,979] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 80.66666666666667, 1.0, 2.0, 0.5100794505965144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712761.5074086621, 712761.5074086614, 185190.4575802608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7669200.0000, 
sim time next is 7669800.0000, 
raw observation next is [27.4, 81.5, 1.0, 2.0, 0.5092657754887085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711624.1344809077, 711624.1344809083, 185060.6776], 
processed observation next is [1.0, 0.782608695652174, 0.4976303317535545, 0.815, 1.0, 1.0, 0.40875394637193796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19767337068914104, 0.19767337068914118, 0.2762099665671642], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.3943962], dtype=float32), 0.073414385]. 
=============================================
[2019-03-26 17:09:36,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2429380e-26 1.0000000e+00 8.2546317e-31 1.4353376e-31 0.0000000e+00], sum to 1.0000
[2019-03-26 17:09:36,546] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3539
[2019-03-26 17:09:36,553] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 79.66666666666667, 1.0, 2.0, 0.5096494993358043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712160.5119462757, 712160.5119462751, 185122.2775402692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7759200.0000, 
sim time next is 7759800.0000, 
raw observation next is [27.7, 81.0, 1.0, 2.0, 0.5111447883724254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714250.6617795123, 714250.6617795129, 185361.1814248074], 
processed observation next is [1.0, 0.8260869565217391, 0.5118483412322274, 0.81, 1.0, 1.0, 0.41101781731617515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1984029616054201, 0.19840296160542026, 0.27665847973851854], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.19656128], dtype=float32), -3.1508656]. 
=============================================
[2019-03-26 17:09:39,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:39,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:39,952] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run8
[2019-03-26 17:09:40,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.0199289e-28 1.0000000e+00 2.1309360e-30 1.8008901e-35 2.4844543e-38], sum to 1.0000
[2019-03-26 17:09:40,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8656
[2019-03-26 17:09:40,405] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.9, 96.0, 1.0, 2.0, 0.2864132040095518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461340.351837531, 461340.3518375317, 164364.5285493706], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187200.0000, 
sim time next is 187800.0000, 
raw observation next is [19.88333333333333, 96.0, 1.0, 2.0, 0.2862261540114023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461138.5560566716, 461138.5560566716, 164350.7811383822], 
processed observation next is [0.0, 0.17391304347826086, 0.14139020537124788, 0.96, 1.0, 1.0, 0.14003151085711116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12809404334907545, 0.12809404334907545, 0.24529967334086897], 
reward next is 0.7547, 
noisyNet noise sample is [array([-1.0184002], dtype=float32), 0.24745513]. 
=============================================
[2019-03-26 17:09:42,781] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6196775e-23 1.0000000e+00 1.6398930e-26 2.6832372e-27 1.5803650e-32], sum to 1.0000
[2019-03-26 17:09:42,791] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6296
[2019-03-26 17:09:42,795] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.53333333333333, 90.50000000000001, 1.0, 2.0, 0.6111462772103123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 854044.4074519783, 854044.4074519777, 202832.4062318242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7794600.0000, 
sim time next is 7795200.0000, 
raw observation next is [25.66666666666666, 90.0, 1.0, 2.0, 0.5804340464531003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811109.3113124119, 811109.3113124119, 197151.1795605981], 
processed observation next is [1.0, 0.21739130434782608, 0.4154818325434437, 0.9, 1.0, 1.0, 0.49449885114831355, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22530814203122554, 0.22530814203122554, 0.2942554918814897], 
reward next is 0.7057, 
noisyNet noise sample is [array([-1.4964991], dtype=float32), -0.8531519]. 
=============================================
[2019-03-26 17:09:46,927] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8085890e-25 1.0000000e+00 6.2399952e-28 5.3173888e-30 1.6560100e-35], sum to 1.0000
[2019-03-26 17:09:46,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-26 17:09:46,942] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.3810260201994432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586932.2282260108, 586932.2282260101, 173833.5239642372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 100200.0000, 
sim time next is 100800.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.379467015531183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584533.8555543392, 584533.8555543387, 173620.7069622091], 
processed observation next is [1.0, 0.17391304347826086, 0.2654028436018958, 0.9, 1.0, 1.0, 0.25236989823034095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1623705154317609, 0.16237051543176073, 0.2591353835256852], 
reward next is 0.7409, 
noisyNet noise sample is [array([1.7135643], dtype=float32), 0.88701355]. 
=============================================
[2019-03-26 17:09:47,213] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.7978123e-08 7.2221059e-01 6.2966413e-15 2.7778929e-01 3.3482405e-17], sum to 1.0000
[2019-03-26 17:09:47,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-26 17:09:47,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2225544.652362535 W.
[2019-03-26 17:09:47,237] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.7, 59.83333333333333, 1.0, 2.0, 0.7957843914003422, 1.0, 1.0, 0.7957843914003422, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2225544.652362535, 2225544.652362535, 417818.8455987855], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7743000.0000, 
sim time next is 7743600.0000, 
raw observation next is [31.6, 60.0, 1.0, 2.0, 0.5009646548344366, 1.0, 2.0, 0.5009646548344366, 1.0, 1.0, 0.8605342324974068, 6.911200000000001, 6.9112, 170.5573041426782, 2101427.822262456, 2101427.822262455, 414091.1672980124], 
processed observation next is [1.0, 0.6521739130434783, 0.6966824644549764, 0.6, 1.0, 1.0, 0.39875259618606823, 1.0, 1.0, 0.39875259618606823, 1.0, 0.5, 0.8299197957285449, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.58372995062846, 0.5837299506284597, 0.6180465183552424], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.802357], dtype=float32), -1.4006624]. 
=============================================
[2019-03-26 17:09:48,104] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9091350e-10 9.9999976e-01 7.0815718e-16 2.8913038e-07 4.3347045e-19], sum to 1.0000
[2019-03-26 17:09:48,111] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4022
[2019-03-26 17:09:48,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1703442.546957992 W.
[2019-03-26 17:09:48,126] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.53333333333334, 77.66666666666667, 1.0, 2.0, 0.4061633082973334, 1.0, 1.0, 0.4061633082973334, 1.0, 2.0, 0.6973816116919771, 6.9112, 6.9112, 170.5573041426782, 1703442.546957992, 1703442.546957992, 355184.8748237335], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7809600.0000, 
sim time next is 7810200.0000, 
raw observation next is [28.65, 77.0, 1.0, 2.0, 0.6235059082643712, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.950973329780632, 6.9112, 168.9126853194932, 1743362.244912475, 1715145.721175629, 369732.313338838], 
processed observation next is [1.0, 0.391304347826087, 0.5568720379146919, 0.77, 1.0, 1.0, 0.5463926605594834, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.003977332978063242, 0.0, 0.8294386134806463, 0.4842672902534653, 0.47642936699323024, 0.5518392736400567], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04111726], dtype=float32), -0.0018264311]. 
=============================================
[2019-03-26 17:09:48,507] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:48,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:48,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run8
[2019-03-26 17:09:49,313] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:49,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:49,375] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run8
[2019-03-26 17:09:50,092] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2622086e-24 1.0000000e+00 2.3628503e-27 1.3206687e-28 1.6161998e-34], sum to 1.0000
[2019-03-26 17:09:50,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0765
[2019-03-26 17:09:50,105] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666666, 90.0, 1.0, 2.0, 0.5804340464531003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811109.3113124119, 811109.3113124119, 197151.1795605981], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7795200.0000, 
sim time next is 7795800.0000, 
raw observation next is [25.8, 89.5, 1.0, 2.0, 0.5824384932220675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813911.4356362551, 813911.4356362551, 197513.6046262231], 
processed observation next is [1.0, 0.21739130434782608, 0.42180094786729866, 0.895, 1.0, 1.0, 0.496913847255503, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22608650989895973, 0.22608650989895973, 0.29479642481525836], 
reward next is 0.7052, 
noisyNet noise sample is [array([0.44842166], dtype=float32), -0.23518476]. 
=============================================
[2019-03-26 17:09:52,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:52,427] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:52,494] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run8
[2019-03-26 17:09:53,586] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:53,586] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:53,650] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run8
[2019-03-26 17:09:54,730] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:54,731] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:54,785] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run8
[2019-03-26 17:09:55,603] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:55,603] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:55,642] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run8
[2019-03-26 17:09:56,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3733229e-24 1.0000000e+00 7.5137032e-28 6.3297074e-28 1.0217070e-34], sum to 1.0000
[2019-03-26 17:09:56,012] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1948
[2019-03-26 17:09:56,015] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.8, 81.0, 1.0, 2.0, 0.2395520510864864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 396475.7470193428, 396475.7470193428, 159782.2534271332], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 507600.0000, 
sim time next is 508200.0000, 
raw observation next is [19.73333333333333, 81.5, 1.0, 2.0, 0.2390725688475068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 395713.5954245069, 395713.5954245076, 159734.1476376303], 
processed observation next is [1.0, 0.9130434782608695, 0.13428120063191146, 0.815, 1.0, 1.0, 0.08321996246687566, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10992044317347413, 0.10992044317347434, 0.23840917557855268], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.65342754], dtype=float32), 0.36049765]. 
=============================================
[2019-03-26 17:09:56,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:56,637] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:56,695] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run8
[2019-03-26 17:09:57,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:57,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:57,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run8
[2019-03-26 17:09:57,634] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:57,668] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run8
[2019-03-26 17:09:57,697] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run8
[2019-03-26 17:09:57,872] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,872] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:57,906] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run8
[2019-03-26 17:09:57,931] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:57,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run8
[2019-03-26 17:09:57,994] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:57,996] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:58,043] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run8
[2019-03-26 17:09:58,319] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:09:58,319] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:09:58,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run8
[2019-03-26 17:10:05,013] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3247686e-24 1.0000000e+00 1.3811647e-27 3.5328676e-26 5.6088199e-34], sum to 1.0000
[2019-03-26 17:10:05,023] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4458
[2019-03-26 17:10:05,028] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.85, 87.0, 1.0, 2.0, 0.2325930176599129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 385719.082205185, 385719.082205185, 159052.3526245966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 516600.0000, 
sim time next is 517200.0000, 
raw observation next is [18.83333333333333, 87.0, 1.0, 2.0, 0.2321318764183155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 385011.7829843339, 385011.7829843339, 159002.7278875467], 
processed observation next is [1.0, 1.0, 0.0916271721958924, 0.87, 1.0, 1.0, 0.07485768243170542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10694771749564831, 0.10694771749564831, 0.2373175043097712], 
reward next is 0.7627, 
noisyNet noise sample is [array([-1.4961877], dtype=float32), 0.35878798]. 
=============================================
[2019-03-26 17:10:05,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7143390e-27 1.0000000e+00 1.5349508e-28 8.1301289e-31 1.2661566e-35], sum to 1.0000
[2019-03-26 17:10:05,569] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7187
[2019-03-26 17:10:05,574] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.86666666666666, 91.0, 1.0, 2.0, 0.3670398073843508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557268.6903578637, 557268.6903578637, 171022.0574552652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 111000.0000, 
sim time next is 111600.0000, 
raw observation next is [22.9, 91.0, 1.0, 2.0, 0.3677547410208171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 557765.5716413929, 557765.5716413935, 171045.9753533538], 
processed observation next is [1.0, 0.30434782608695654, 0.2843601895734597, 0.91, 1.0, 1.0, 0.2382587241214664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15493488101149802, 0.1549348810114982, 0.2552925005273937], 
reward next is 0.7447, 
noisyNet noise sample is [array([1.9166857], dtype=float32), -2.2213087]. 
=============================================
[2019-03-26 17:10:08,658] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.4432697e-26 1.0000000e+00 2.2526433e-28 1.8765395e-29 2.7025782e-36], sum to 1.0000
[2019-03-26 17:10:08,665] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5475
[2019-03-26 17:10:08,671] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.06666666666667, 96.0, 1.0, 2.0, 0.2946152574974321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472899.1159788866, 472899.1159788866, 165158.8503494025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 178800.0000, 
sim time next is 179400.0000, 
raw observation next is [20.03333333333333, 96.0, 1.0, 2.0, 0.293820680113893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 471937.8987883507, 471937.8987883501, 165093.0315112215], 
processed observation next is [0.0, 0.043478260869565216, 0.14849921011058448, 0.96, 1.0, 1.0, 0.14918154230589517, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13109386077454185, 0.1310938607745417, 0.24640750971824102], 
reward next is 0.7536, 
noisyNet noise sample is [array([-1.0967002], dtype=float32), 0.10066288]. 
=============================================
[2019-03-26 17:10:17,514] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1013301e-24 1.0000000e+00 7.8228909e-27 4.1796296e-28 1.4045063e-33], sum to 1.0000
[2019-03-26 17:10:17,522] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4125
[2019-03-26 17:10:17,528] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 69.0, 1.0, 2.0, 0.4610482251419944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758572.5729980959, 758572.5729980959, 189053.0230014907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 553200.0000, 
sim time next is 553800.0000, 
raw observation next is [22.2, 67.5, 1.0, 2.0, 0.4726403767214698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777850.2612768414, 777850.2612768414, 191015.0072088683], 
processed observation next is [1.0, 0.391304347826087, 0.2511848341232228, 0.675, 1.0, 1.0, 0.36462695990538535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21606951702134483, 0.21606951702134483, 0.28509702568487805], 
reward next is 0.7149, 
noisyNet noise sample is [array([-0.502894], dtype=float32), -0.0025283354]. 
=============================================
[2019-03-26 17:10:17,535] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.9486157e-26 1.0000000e+00 4.0612611e-29 5.9563940e-31 4.2550298e-36], sum to 1.0000
[2019-03-26 17:10:17,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4718
[2019-03-26 17:10:17,548] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 77.83333333333333, 1.0, 2.0, 0.3080996017122549, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487513.7142572048, 487513.7142572048, 166108.3679744664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 316200.0000, 
sim time next is 316800.0000, 
raw observation next is [23.0, 78.0, 1.0, 2.0, 0.3066500209044473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485678.6350541453, 485678.6350541453, 165984.1924993817], 
processed observation next is [0.0, 0.6956521739130435, 0.28909952606635075, 0.78, 1.0, 1.0, 0.16463857940294857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1349107319594848, 0.1349107319594848, 0.24773760074534582], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.90756536], dtype=float32), -1.9798508]. 
=============================================
[2019-03-26 17:10:25,461] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1895654e-27 1.0000000e+00 3.2057441e-29 2.6033559e-32 2.4275895e-36], sum to 1.0000
[2019-03-26 17:10:25,468] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3187
[2019-03-26 17:10:25,472] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2443283175102852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402511.2493185347, 402511.249318534, 160338.3618880211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 459600.0000, 
sim time next is 460200.0000, 
raw observation next is [20.36666666666667, 80.16666666666667, 1.0, 2.0, 0.2448750141086938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403357.0519538737, 403357.0519538737, 160392.7216056463], 
processed observation next is [1.0, 0.30434782608695654, 0.1642969984202214, 0.8016666666666667, 1.0, 1.0, 0.09021086037192023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11204362554274269, 0.11204362554274269, 0.2393921217994721], 
reward next is 0.7606, 
noisyNet noise sample is [array([-0.11750795], dtype=float32), -0.28614727]. 
=============================================
[2019-03-26 17:10:26,662] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 17:10:26,664] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:10:26,664] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:10:26,665] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:26,665] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:26,667] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:10:26,666] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:10:26,667] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:26,668] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:10:26,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:26,670] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:10:27,598] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run61
[2019-03-26 17:10:27,618] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run61
[2019-03-26 17:10:27,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run61
[2019-03-26 17:10:27,660] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run61
[2019-03-26 17:10:27,660] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run61
[2019-03-26 17:10:33,543] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00297478], dtype=float32), 0.10092441]
[2019-03-26 17:10:33,544] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.4, 72.0, 1.0, 2.0, 0.2509657991921493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 413840.0250766923, 413840.0250766923, 160974.3917827331]
[2019-03-26 17:10:33,547] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:10:33,550] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.8133486e-28 1.0000000e+00 6.9973654e-30 1.2187118e-33 9.6552522e-37], sampled 0.07428062058886054
[2019-03-26 17:11:14,764] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00297478], dtype=float32), 0.10092441]
[2019-03-26 17:11:14,765] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.9353257, 92.83878997, 1.0, 2.0, 0.5151778729217814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719888.2217792232, 719888.2217792238, 186008.4053653901]
[2019-03-26 17:11:14,766] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:11:14,772] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7754219e-23 1.0000000e+00 3.5368049e-26 1.8035745e-24 1.3171141e-32], sampled 0.19714058411327806
[2019-03-26 17:11:34,021] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00297478], dtype=float32), 0.10092441]
[2019-03-26 17:11:34,024] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.69542318333333, 77.82250984833334, 1.0, 2.0, 0.5321704766204071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 743641.2939043358, 743641.2939043352, 188785.7244669621]
[2019-03-26 17:11:34,026] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:11:34,027] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0507814e-22 1.0000000e+00 1.2849443e-26 1.3515114e-23 7.2272177e-33], sampled 0.6311559003814362
[2019-03-26 17:11:58,300] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.00297478], dtype=float32), 0.10092441]
[2019-03-26 17:11:58,300] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.0, 69.0, 1.0, 2.0, 0.7732684640129138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1080716.813133015, 1080716.813133015, 237454.5447864651]
[2019-03-26 17:11:58,301] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:11:58,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.5878552e-24 1.0000000e+00 8.3848318e-27 5.4670734e-27 3.4780700e-33], sampled 0.7566326586642828
[2019-03-26 17:12:07,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00297478], dtype=float32), 0.10092441]
[2019-03-26 17:12:07,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.12952763166667, 61.38760331166667, 1.0, 2.0, 1.035862347173437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1447967.200566371, 1447967.200566372, 310039.788879606]
[2019-03-26 17:12:07,687] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:12:07,689] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.9229840e-20 1.0000000e+00 2.3305569e-23 2.9447785e-20 4.8970973e-29], sampled 0.07746739684984472
[2019-03-26 17:12:25,945] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7979.0168 3154832151.4448 1544.0000
[2019-03-26 17:12:25,963] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8520.1571 2840060531.0069 1074.0000
[2019-03-26 17:12:26,000] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8286.4782 2924829264.9700 1273.0000
[2019-03-26 17:12:26,028] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8035.6179 3003967791.5490 1672.0000
[2019-03-26 17:12:26,140] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8674.3622 2777852921.6848 899.0000
[2019-03-26 17:12:27,156] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1500000, evaluation results [1500000.0, 7979.016827914199, 3154832151.44483, 1544.0, 8286.478199264968, 2924829264.9699535, 1273.0, 8674.362217172, 2777852921.6848044, 899.0, 8035.617920949502, 3003967791.5490227, 1672.0, 8520.157054840696, 2840060531.006871, 1074.0]
[2019-03-26 17:12:29,383] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0705670e-21 1.0000000e+00 2.8938130e-25 7.8333282e-23 1.8209824e-31], sum to 1.0000
[2019-03-26 17:12:29,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3860
[2019-03-26 17:12:29,397] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.93333333333334, 50.0, 1.0, 2.0, 0.5761181493514851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950958.3910729398, 950958.3910729398, 210527.7958741349], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 750000.0000, 
sim time next is 750600.0000, 
raw observation next is [24.85, 50.0, 1.0, 2.0, 0.5764482826910733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 952258.2389934983, 952258.2389934983, 210572.8166373943], 
processed observation next is [1.0, 0.6956521739130435, 0.37677725118483424, 0.5, 1.0, 1.0, 0.4896967261338232, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26451617749819395, 0.26451617749819395, 0.31428778602596164], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.2509367], dtype=float32), -0.007269384]. 
=============================================
[2019-03-26 17:12:33,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2197514e-24 1.0000000e+00 6.9583009e-27 1.4800285e-26 1.0254207e-33], sum to 1.0000
[2019-03-26 17:12:33,021] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-26 17:12:33,025] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 55.33333333333333, 1.0, 2.0, 0.3501702907954479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 573934.1410301038, 573934.1410301044, 172526.7757412604], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 564000.0000, 
sim time next is 564600.0000, 
raw observation next is [24.5, 55.66666666666667, 1.0, 2.0, 0.3498141191536414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573622.1155521977, 573622.1155521977, 172483.1554737045], 
processed observation next is [1.0, 0.5217391304347826, 0.3601895734597157, 0.5566666666666668, 1.0, 1.0, 0.21664351705258, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15933947654227712, 0.15933947654227712, 0.2574375454831411], 
reward next is 0.7426, 
noisyNet noise sample is [array([-0.579046], dtype=float32), -0.19210246]. 
=============================================
[2019-03-26 17:12:33,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.4018139e-23 1.0000000e+00 8.4293824e-26 4.0994802e-26 8.5770349e-33], sum to 1.0000
[2019-03-26 17:12:33,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2378
[2019-03-26 17:12:33,614] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.83333333333333, 59.83333333333334, 1.0, 2.0, 0.5921751943221502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970182.2452247476, 970182.2452247476, 213914.8060947911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 643800.0000, 
sim time next is 644400.0000, 
raw observation next is [24.0, 59.0, 1.0, 2.0, 0.5363459962582982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 878464.0334300835, 878464.0334300835, 202600.1829859363], 
processed observation next is [1.0, 0.4782608695652174, 0.3364928909952607, 0.59, 1.0, 1.0, 0.44138071838349174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24401778706391208, 0.24401778706391208, 0.3023883328148303], 
reward next is 0.6976, 
noisyNet noise sample is [array([-0.402725], dtype=float32), -0.18480848]. 
=============================================
[2019-03-26 17:12:36,120] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0441855e-24 1.0000000e+00 6.8032300e-28 1.5301226e-27 7.8494673e-34], sum to 1.0000
[2019-03-26 17:12:36,124] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0842
[2019-03-26 17:12:36,127] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.36666666666667, 89.0, 1.0, 2.0, 0.3026761867764391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481203.8092262834, 481203.8092262834, 165695.3336316373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865200.0000, 
sim time next is 865800.0000, 
raw observation next is [21.35, 89.0, 1.0, 2.0, 0.3020354382085937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 480360.7102689046, 480360.710268904, 165637.8022522679], 
processed observation next is [0.0, 0.0, 0.2109004739336494, 0.89, 1.0, 1.0, 0.1590788412151731, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13343353063025126, 0.1334335306302511, 0.24722060037651925], 
reward next is 0.7528, 
noisyNet noise sample is [array([0.34183884], dtype=float32), -2.3397567]. 
=============================================
[2019-03-26 17:12:39,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1682999e-27 1.0000000e+00 1.0706403e-29 5.8889064e-32 1.9536614e-36], sum to 1.0000
[2019-03-26 17:12:39,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3637
[2019-03-26 17:12:39,225] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 69.0, 1.0, 2.0, 0.3156583322286775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496459.4292085069, 496459.4292085069, 166700.2157904235], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 918000.0000, 
sim time next is 918600.0000, 
raw observation next is [24.63333333333333, 69.33333333333333, 1.0, 2.0, 0.3155173422487395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 496224.8312151646, 496224.8312151639, 166682.3374941126], 
processed observation next is [0.0, 0.6521739130434783, 0.3665086887835701, 0.6933333333333332, 1.0, 1.0, 0.17532209909486687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1378402308931013, 0.1378402308931011, 0.24877960820016806], 
reward next is 0.7512, 
noisyNet noise sample is [array([1.9337556], dtype=float32), 0.37722337]. 
=============================================
[2019-03-26 17:12:57,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.8846391e-27 1.0000000e+00 2.8460752e-29 5.5693394e-32 4.1325575e-36], sum to 1.0000
[2019-03-26 17:12:57,029] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1569
[2019-03-26 17:12:57,033] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3282851924684677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508893.8120397911, 508893.8120397917, 167434.2684789953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 973200.0000, 
sim time next is 973800.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3321974131769301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514957.990941065, 514957.990941065, 167906.5624564621], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19541857009268684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14304388637251805, 0.14304388637251805, 0.2506068096365106], 
reward next is 0.7494, 
noisyNet noise sample is [array([-0.27277878], dtype=float32), 0.7519925]. 
=============================================
[2019-03-26 17:13:10,011] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1383124e-23 1.0000000e+00 5.5903198e-27 5.8421348e-27 3.5954207e-34], sum to 1.0000
[2019-03-26 17:13:10,019] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2060
[2019-03-26 17:13:10,027] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 93.16666666666666, 1.0, 2.0, 0.3460372273495639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535188.9095105969, 535188.9095105969, 169485.4041763998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1821000.0000, 
sim time next is 1821600.0000, 
raw observation next is [22.0, 93.0, 1.0, 2.0, 0.3453446244914873, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533927.2220454625, 533927.2220454625, 169377.4132252798], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.93, 1.0, 1.0, 0.21125858372468348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1483131172348507, 0.1483131172348507, 0.2528021092914624], 
reward next is 0.7472, 
noisyNet noise sample is [array([-1.7179376], dtype=float32), -0.09149492]. 
=============================================
[2019-03-26 17:13:12,628] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0814352e-25 1.0000000e+00 5.5514911e-28 1.9903854e-29 1.5312900e-35], sum to 1.0000
[2019-03-26 17:13:12,637] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5249
[2019-03-26 17:13:12,640] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 89.0, 1.0, 2.0, 0.3856454651342247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586264.3113747791, 586264.3113747791, 173589.0443797303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1233600.0000, 
sim time next is 1234200.0000, 
raw observation next is [23.25, 88.5, 1.0, 2.0, 0.3846810340594198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 583261.3342351102, 583261.3342351095, 173278.2983729321], 
processed observation next is [1.0, 0.2608695652173913, 0.30094786729857825, 0.885, 1.0, 1.0, 0.25865184826436116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1620170372875306, 0.16201703728753042, 0.2586243259297494], 
reward next is 0.7414, 
noisyNet noise sample is [array([1.5000491], dtype=float32), 2.883609]. 
=============================================
[2019-03-26 17:13:16,739] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2502966e-23 1.0000000e+00 3.7248367e-27 1.5674801e-25 3.4210775e-34], sum to 1.0000
[2019-03-26 17:13:16,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9555
[2019-03-26 17:13:16,752] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.05, 95.83333333333333, 1.0, 2.0, 0.3637668005163909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 555650.6147185443, 555650.6147185436, 170987.8806704729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1464600.0000, 
sim time next is 1465200.0000, 
raw observation next is [22.0, 96.0, 1.0, 2.0, 0.3641120629178933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 556686.7973403676, 556686.797340367, 171091.2633168608], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.96, 1.0, 1.0, 0.23386995532276297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15463522148343545, 0.15463522148343528, 0.2553600945027773], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.86449516], dtype=float32), 2.059649]. 
=============================================
[2019-03-26 17:13:17,297] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8911063e-21 1.0000000e+00 7.4915053e-25 8.4306133e-24 8.1607040e-31], sum to 1.0000
[2019-03-26 17:13:17,304] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9939
[2019-03-26 17:13:17,309] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.53333333333333, 85.0, 1.0, 2.0, 0.7318827464191792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1114832.101468987, 1114832.101468988, 239745.0294733926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1588800.0000, 
sim time next is 1589400.0000, 
raw observation next is [23.55, 85.0, 1.0, 2.0, 0.7709525610057512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1173762.643976374, 1173762.643976374, 249564.6657224942], 
processed observation next is [1.0, 0.391304347826087, 0.3151658767772513, 0.85, 1.0, 1.0, 0.724039230127411, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32604517888232615, 0.32604517888232615, 0.3724845757052152], 
reward next is 0.6275, 
noisyNet noise sample is [array([-0.00217248], dtype=float32), -0.269321]. 
=============================================
[2019-03-26 17:13:18,371] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1477476e-19 1.0000000e+00 8.7402096e-23 4.5271455e-19 1.1484854e-28], sum to 1.0000
[2019-03-26 17:13:18,380] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1423
[2019-03-26 17:13:18,389] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 88.16666666666667, 1.0, 2.0, 0.8792083519838492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1281363.709296258, 1281363.709296258, 271862.067511845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1763400.0000, 
sim time next is 1764000.0000, 
raw observation next is [24.3, 88.0, 1.0, 2.0, 0.8490209401339973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1241531.474424428, 1241531.474424428, 264079.1401714162], 
processed observation next is [1.0, 0.43478260869565216, 0.3507109004739337, 0.88, 1.0, 1.0, 0.8180975182337317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3448698540067856, 0.3448698540067856, 0.39414797040509886], 
reward next is 0.6059, 
noisyNet noise sample is [array([-0.5858542], dtype=float32), 1.2857008]. 
=============================================
[2019-03-26 17:13:18,404] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[62.68405]
 [63.06653]
 [63.65652]
 [62.95798]
 [61.88714]], R is [[62.83315659]
 [62.79906082]
 [62.77204514]
 [62.7839241 ]
 [62.78803635]].
[2019-03-26 17:13:22,099] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 17:13:22,102] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:13:22,104] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:22,105] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:13:22,106] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:22,107] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:13:22,107] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:13:22,108] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:22,108] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:13:22,109] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:22,110] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:13:22,134] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run62
[2019-03-26 17:13:22,159] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run62
[2019-03-26 17:13:22,183] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run62
[2019-03-26 17:13:22,210] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run62
[2019-03-26 17:13:22,233] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run62
[2019-03-26 17:13:33,894] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:13:33,895] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.91474171, 66.47746952666667, 1.0, 2.0, 0.2299783077970537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 382803.9732954365, 382803.9732954365, 158570.2126004159]
[2019-03-26 17:13:33,896] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:13:33,901] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2345216e-27 1.0000000e+00 1.0582603e-28 8.8385420e-32 2.0569006e-35], sampled 0.3622350632183633
[2019-03-26 17:13:42,562] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:13:42,564] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.78386484333334, 82.17309810333333, 1.0, 2.0, 0.5075918185702748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752141.0870266482, 752141.0870266475, 190135.8010400923]
[2019-03-26 17:13:42,564] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:13:42,567] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0252854e-24 1.0000000e+00 2.5409903e-27 2.5853803e-27 1.2205727e-33], sampled 0.7229466244438156
[2019-03-26 17:13:53,567] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:13:53,568] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.13333333333333, 96.0, 1.0, 2.0, 0.4602961970323435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649894.0932472008, 649894.0932472001, 178476.709614409]
[2019-03-26 17:13:53,569] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:13:53,570] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9239955e-25 1.0000000e+00 4.4788223e-28 2.5075468e-28 1.4790630e-34], sampled 0.8961082415497267
[2019-03-26 17:14:05,039] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:14:05,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.3505705274872588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 540041.7948673894, 540041.79486739, 169819.9699637635]
[2019-03-26 17:14:05,041] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:14:05,046] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6476905e-22 1.0000000e+00 4.6721905e-26 8.9288563e-24 2.6489163e-32], sampled 0.22642393294440588
[2019-03-26 17:14:06,078] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:14:06,079] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.16666666666667, 99.0, 1.0, 2.0, 0.308800462644727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387395, 166428.6719962212]
[2019-03-26 17:14:06,080] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:14:06,082] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0437598e-24 1.0000000e+00 1.6440449e-27 1.7453440e-26 5.3965834e-34], sampled 0.6303740566756411
[2019-03-26 17:15:03,237] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:15:03,238] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.06300725, 61.47284194, 1.0, 2.0, 0.4633489096001224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647442.5046528752, 647442.5046528758, 178053.5820305461]
[2019-03-26 17:15:03,239] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:15:03,243] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1758116e-21 1.0000000e+00 2.1223179e-25 8.9278823e-21 5.5571825e-31], sampled 0.775657050490578
[2019-03-26 17:15:07,677] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.00127208], dtype=float32), 0.10074901]
[2019-03-26 17:15:07,681] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.43333333333333, 81.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.14552857527107, 6.9112, 168.9114295139391, 1620108.032865948, 1453868.779440942, 311351.2253156985]
[2019-03-26 17:15:07,682] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:15:07,684] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.07925285e-19 1.00000000e+00 2.61602961e-24 1.12867355e-17
 2.65743214e-29], sampled 0.8050078067760396
[2019-03-26 17:15:20,043] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8006.0346 3152658789.4242 1483.0000
[2019-03-26 17:15:20,755] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8681.0398 2777400556.5226 886.0000
[2019-03-26 17:15:20,756] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8054.7028 3001896452.5855 1623.0000
[2019-03-26 17:15:20,791] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8295.1841 2923916650.4371 1253.0000
[2019-03-26 17:15:20,864] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8524.4088 2839328702.8404 1053.0000
[2019-03-26 17:15:21,879] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1525000, evaluation results [1525000.0, 8006.034648276296, 3152658789.424213, 1483.0, 8295.184142061016, 2923916650.4371443, 1253.0, 8681.03979613923, 2777400556.522607, 886.0, 8054.702820353889, 3001896452.5855317, 1623.0, 8524.408763244617, 2839328702.8404417, 1053.0]
[2019-03-26 17:15:37,980] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1890391e-10 9.9992335e-01 6.5082604e-17 7.6642209e-05 1.4879302e-19], sum to 1.0000
[2019-03-26 17:15:37,988] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8144
[2019-03-26 17:15:37,998] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1831166.389924841 W.
[2019-03-26 17:15:38,003] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.35, 78.0, 1.0, 2.0, 0.6685831341543348, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982560660380929, 6.9112, 168.912531384571, 1831166.389924841, 1780540.808822728, 378832.3738187], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1697400.0000, 
sim time next is 1698000.0000, 
raw observation next is [28.4, 77.66666666666666, 1.0, 2.0, 0.7684730263442021, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981053470639717, 6.9112, 168.9124831184937, 1970951.121004489, 1921394.803647652, 401092.9615732438], 
processed observation next is [1.0, 0.6521739130434783, 0.5450236966824644, 0.7766666666666666, 1.0, 1.0, 0.7210518389689182, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006985347063971669, 0.0, 0.8294376205811708, 0.5474864225012469, 0.5337207787910144, 0.5986462113033489], 
reward next is 0.0521, 
noisyNet noise sample is [array([-0.23761538], dtype=float32), -0.16699506]. 
=============================================
[2019-03-26 17:15:38,020] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.079815]
 [54.976368]
 [54.576836]
 [55.324574]
 [53.787678]], R is [[54.20298386]
 [53.66095352]
 [53.12434387]
 [52.5931015 ]
 [52.06716919]].
[2019-03-26 17:15:44,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5965016e-14 1.0000000e+00 1.7751490e-20 2.3697298e-11 2.1020388e-24], sum to 1.0000
[2019-03-26 17:15:44,883] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8192
[2019-03-26 17:15:44,897] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 76.33333333333334, 1.0, 2.0, 0.9128659244075692, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1278977.761517787, 1278977.761517787, 273954.0630372406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1945200.0000, 
sim time next is 1945800.0000, 
raw observation next is [27.0, 76.0, 1.0, 2.0, 0.859532861746436, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1212077.563723863, 1212077.563723863, 260606.4952699443], 
processed observation next is [1.0, 0.5217391304347826, 0.4786729857819906, 0.76, 1.0, 1.0, 0.8307624840318505, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33668821214551753, 0.33668821214551753, 0.38896491831334973], 
reward next is 0.6110, 
noisyNet noise sample is [array([1.3574531], dtype=float32), 0.8225989]. 
=============================================
[2019-03-26 17:15:52,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0894132e-24 1.0000000e+00 9.1487421e-28 7.1971925e-28 1.1132402e-34], sum to 1.0000
[2019-03-26 17:15:52,815] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4208
[2019-03-26 17:15:52,820] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 96.0, 1.0, 2.0, 0.4679034022419606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 656059.6261236903, 656059.626123691, 179011.1074033558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2080800.0000, 
sim time next is 2081400.0000, 
raw observation next is [24.26666666666667, 96.0, 1.0, 2.0, 0.4668021613574072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655153.3928290574, 655153.3928290581, 178931.0186076815], 
processed observation next is [0.0, 0.08695652173913043, 0.34913112164297017, 0.96, 1.0, 1.0, 0.3575929654908521, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18198705356362707, 0.18198705356362727, 0.2670612218025097], 
reward next is 0.7329, 
noisyNet noise sample is [array([-0.699119], dtype=float32), 0.13140962]. 
=============================================
[2019-03-26 17:16:04,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7735954e-24 1.0000000e+00 3.0511372e-27 6.1935910e-26 1.7754351e-33], sum to 1.0000
[2019-03-26 17:16:04,056] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1574
[2019-03-26 17:16:04,064] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.15, 84.5, 1.0, 2.0, 0.5519986809863414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771358.7754463197, 771358.7754463197, 192144.2854512214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2143800.0000, 
sim time next is 2144400.0000, 
raw observation next is [27.96666666666667, 85.33333333333334, 1.0, 2.0, 0.5507295009673426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 769584.59041656, 769584.5904165606, 191926.0473097618], 
processed observation next is [0.0, 0.8260869565217391, 0.524486571879937, 0.8533333333333334, 1.0, 1.0, 0.4587102421293284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21377349733793333, 0.21377349733793352, 0.28645678702949523], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.8820042], dtype=float32), 0.6589984]. 
=============================================
[2019-03-26 17:16:08,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1243954e-21 1.0000000e+00 2.6640654e-25 4.7802936e-24 2.0402129e-31], sum to 1.0000
[2019-03-26 17:16:08,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3918
[2019-03-26 17:16:08,966] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 77.0, 1.0, 2.0, 0.7166497822587589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1001549.461716232, 1001549.461716232, 224478.8678559963], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2356200.0000, 
sim time next is 2356800.0000, 
raw observation next is [28.43333333333333, 76.33333333333334, 1.0, 2.0, 0.7052609130727916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 985625.6320818511, 985625.6320818511, 221983.717802521], 
processed observation next is [1.0, 0.2608695652173913, 0.546603475513428, 0.7633333333333334, 1.0, 1.0, 0.644892666352761, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2737848978005142, 0.2737848978005142, 0.33131898179480745], 
reward next is 0.6687, 
noisyNet noise sample is [array([-1.0831242], dtype=float32), 2.3483744]. 
=============================================
[2019-03-26 17:16:09,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.5191649e-20 1.0000000e+00 3.2342016e-23 8.2448278e-20 4.3532429e-29], sum to 1.0000
[2019-03-26 17:16:09,101] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9717
[2019-03-26 17:16:09,106] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 87.0, 1.0, 2.0, 0.7738629247581036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1136964.717315444, 1136964.717315444, 245131.8117654669], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2821200.0000, 
sim time next is 2821800.0000, 
raw observation next is [24.16666666666666, 88.0, 1.0, 2.0, 0.7977978938658373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1173371.202606536, 1173371.202606536, 251394.3311992045], 
processed observation next is [1.0, 0.6521739130434783, 0.34439178515007873, 0.88, 1.0, 1.0, 0.7563830046576353, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3259364451684822, 0.3259364451684822, 0.3752154197003052], 
reward next is 0.6248, 
noisyNet noise sample is [array([1.0089989], dtype=float32), 1.6756418]. 
=============================================
[2019-03-26 17:16:09,648] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1744167e-08 9.5714641e-01 3.5868711e-15 4.2853594e-02 2.4037771e-17], sum to 1.0000
[2019-03-26 17:16:09,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2731
[2019-03-26 17:16:09,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2454709.290022555 W.
[2019-03-26 17:16:09,669] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.05, 64.33333333333333, 1.0, 2.0, 0.877646019738817, 1.0, 2.0, 0.877646019738817, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2454709.290022555, 2454709.290022555, 459442.9609098232], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2371800.0000, 
sim time next is 2372400.0000, 
raw observation next is [32.2, 64.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.540129057731008, 6.9112, 168.9094136350961, 2730899.856061621, 2284725.294952065, 474726.7950376416], 
processed observation next is [1.0, 0.4782608695652174, 0.7251184834123224, 0.64, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.06289290577310078, 0.0, 0.829422548012473, 0.7585832933504503, 0.6346459152644626, 0.7085474552800621], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1794324], dtype=float32), -1.6685338]. 
=============================================
[2019-03-26 17:16:16,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0798816e-23 1.0000000e+00 3.1783620e-27 1.0738907e-24 2.7351058e-34], sum to 1.0000
[2019-03-26 17:16:16,047] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9428
[2019-03-26 17:16:16,052] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 81.0, 1.0, 2.0, 0.5506626327980185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769491.1155753976, 769491.1155753976, 191914.4735542212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2329200.0000, 
sim time next is 2329800.0000, 
raw observation next is [28.55, 81.0, 1.0, 2.0, 0.5518384396192169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 771134.7740927695, 771134.7740927688, 192116.342783177], 
processed observation next is [1.0, 1.0, 0.552132701421801, 0.81, 1.0, 1.0, 0.46004631279423713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2142041039146582, 0.214204103914658, 0.28674081012414476], 
reward next is 0.7133, 
noisyNet noise sample is [array([1.2686678], dtype=float32), -0.2592185]. 
=============================================
[2019-03-26 17:16:16,768] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.5282217e-24 1.0000000e+00 9.4118595e-29 2.8850597e-26 1.0477090e-34], sum to 1.0000
[2019-03-26 17:16:16,779] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0809
[2019-03-26 17:16:16,788] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 87.0, 1.0, 2.0, 0.5415113386926087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756698.6227808386, 756698.6227808392, 190356.3363476639], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2485800.0000, 
sim time next is 2486400.0000, 
raw observation next is [27.63333333333333, 87.66666666666666, 1.0, 2.0, 0.5447932851181566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761286.4016643214, 761286.401664322, 190912.3790330254], 
processed observation next is [1.0, 0.782608695652174, 0.5086887835703, 0.8766666666666666, 1.0, 1.0, 0.4515581748411525, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21146844490675595, 0.21146844490675612, 0.284943849303023], 
reward next is 0.7151, 
noisyNet noise sample is [array([-0.25821343], dtype=float32), -0.31621218]. 
=============================================
[2019-03-26 17:16:17,156] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 17:16:17,159] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:16:17,161] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:16:17,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:17,163] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:17,163] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:16:17,164] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:16:17,166] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:16:17,167] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:17,169] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:17,169] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:16:17,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run63
[2019-03-26 17:16:17,212] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run63
[2019-03-26 17:16:17,230] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run63
[2019-03-26 17:16:17,231] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run63
[2019-03-26 17:16:17,277] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run63
[2019-03-26 17:16:18,401] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:16:18,402] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.33127865, 85.10115493, 1.0, 2.0, 0.2726693894564519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 445202.6494653438, 445202.6494653438, 163194.3527043803]
[2019-03-26 17:16:18,402] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:16:18,404] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5848820e-23 1.0000000e+00 1.6195593e-24 4.3764203e-29 9.7861458e-30], sampled 0.2005135894616168
[2019-03-26 17:16:33,784] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:16:33,785] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.4235943, 96.15749011, 1.0, 2.0, 0.3602707522081157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547771.3454747592, 547771.3454747585, 170240.5044979405]
[2019-03-26 17:16:33,786] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:16:33,788] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.2695544e-29 1.0000000e+00 9.2875903e-31 2.6399040e-35 8.3317619e-38], sampled 0.3903708307432895
[2019-03-26 17:16:38,841] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:16:38,844] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.6, 88.5, 1.0, 2.0, 0.3851740829385485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577888.3025299233, 577888.302529924, 172617.3626335623]
[2019-03-26 17:16:38,845] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:16:38,849] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7764703e-28 1.0000000e+00 2.4198490e-30 1.4437159e-33 2.9946197e-37], sampled 0.457926574257969
[2019-03-26 17:16:55,953] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:16:55,955] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.66666666666666, 94.83333333333333, 1.0, 2.0, 0.4957848750506703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 692780.4131373968, 692780.4131373974, 182937.2439685969]
[2019-03-26 17:16:55,956] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:16:55,960] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.6010747e-25 1.0000000e+00 2.8901790e-28 8.0200798e-28 6.9416494e-35], sampled 0.14496346958402273
[2019-03-26 17:17:43,537] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:17:43,539] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.28333333333333, 82.16666666666667, 1.0, 2.0, 0.8528473451741722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1191998.355556287, 1191998.355556287, 257297.132162842]
[2019-03-26 17:17:43,541] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:17:43,545] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0692390e-24 1.0000000e+00 3.2657466e-27 5.1238199e-29 5.0636683e-34], sampled 0.2773789715022513
[2019-03-26 17:17:48,321] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:17:48,323] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.86666666666667, 87.0, 1.0, 2.0, 0.5681098957461883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793880.8783214532, 793880.8783214532, 194954.397847839]
[2019-03-26 17:17:48,327] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:17:48,331] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.0754179e-24 1.0000000e+00 2.9861592e-27 5.1404294e-26 1.0592148e-33], sampled 0.8739453404527077
[2019-03-26 17:18:06,296] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0015164], dtype=float32), 0.100121155]
[2019-03-26 17:18:06,298] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.7, 77.0, 1.0, 2.0, 0.5718861823195915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 799159.8736673747, 799159.8736673754, 195624.8271158703]
[2019-03-26 17:18:06,300] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:18:06,303] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3551089e-24 1.0000000e+00 3.3690254e-28 5.1076078e-27 1.0654754e-34], sampled 0.316462893925216
[2019-03-26 17:18:14,769] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7913.0108 3161633969.5889 1722.0000
[2019-03-26 17:18:14,807] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.1421 2926833760.2449 1324.0000
[2019-03-26 17:18:14,840] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8666.8473 2778810084.2075 918.0000
[2019-03-26 17:18:15,241] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.6645 2841948425.8495 1116.0000
[2019-03-26 17:18:15,277] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8005.5315 3006953414.7894 1751.0000
[2019-03-26 17:18:16,293] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1550000, evaluation results [1550000.0, 7913.010805436879, 3161633969.588932, 1722.0, 8261.142110061013, 2926833760.244891, 1324.0, 8666.847263529344, 2778810084.207484, 918.0, 8005.531500641665, 3006953414.7894263, 1751.0, 8500.664470432514, 2841948425.849505, 1116.0]
[2019-03-26 17:18:19,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7443295e-25 1.0000000e+00 9.6410115e-29 2.1664533e-28 2.6962555e-36], sum to 1.0000
[2019-03-26 17:18:19,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5912
[2019-03-26 17:18:19,806] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.81666666666667, 74.33333333333334, 1.0, 2.0, 0.5856821183125834, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818445.8898779831, 818445.8898779831, 198109.0939281125], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2405400.0000, 
sim time next is 2406000.0000, 
raw observation next is [30.73333333333333, 74.66666666666667, 1.0, 2.0, 0.5842371234322484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 816425.8441769247, 816425.8441769254, 197846.3589911139], 
processed observation next is [1.0, 0.8695652173913043, 0.6556082148499209, 0.7466666666666667, 1.0, 1.0, 0.49908087160511855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22678495671581242, 0.2267849567158126, 0.2952930731210655], 
reward next is 0.7047, 
noisyNet noise sample is [array([-2.1070921], dtype=float32), 0.21303825]. 
=============================================
[2019-03-26 17:18:19,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.79135]
 [70.35345]
 [70.68533]
 [70.9471 ]
 [71.60666]], R is [[69.47093964]
 [69.48054504]
 [69.49013519]
 [69.50027466]
 [69.51132965]].
[2019-03-26 17:18:20,013] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.2751696e-24 1.0000000e+00 7.3942837e-27 3.3944793e-27 2.5189780e-33], sum to 1.0000
[2019-03-26 17:18:20,024] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4432
[2019-03-26 17:18:20,028] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.75, 83.0, 1.0, 2.0, 0.7142453982520539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 998187.6505371014, 998187.650537102, 223949.9227639498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2435400.0000, 
sim time next is 2436000.0000, 
raw observation next is [27.7, 83.33333333333334, 1.0, 2.0, 0.72440626249048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1012394.649632712, 1012394.649632711, 226201.2772083527], 
processed observation next is [1.0, 0.17391304347826086, 0.5118483412322274, 0.8333333333333335, 1.0, 1.0, 0.6679593523981687, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28122073600908665, 0.28122073600908637, 0.3376138465796309], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.45360893], dtype=float32), 0.11692698]. 
=============================================
[2019-03-26 17:18:20,045] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[62.995804]
 [62.474773]
 [61.83005 ]
 [61.428196]
 [61.556927]], R is [[63.29115677]
 [63.32398987]
 [63.34924316]
 [63.35646057]
 [63.35371399]].
[2019-03-26 17:18:20,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.9888009e-23 1.0000000e+00 1.5769853e-26 1.5796361e-24 3.0593561e-33], sum to 1.0000
[2019-03-26 17:18:20,922] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1505
[2019-03-26 17:18:20,927] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 80.0, 1.0, 2.0, 0.5586144297159925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 780606.9696201672, 780606.9696201679, 193289.1812310101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2420400.0000, 
sim time next is 2421000.0000, 
raw observation next is [28.95, 80.0, 1.0, 2.0, 0.5566361447008397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 777841.5048890228, 777841.5048890234, 192945.4512849399], 
processed observation next is [1.0, 0.0, 0.5710900473933649, 0.8, 1.0, 1.0, 0.4658266803624574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2160670846913952, 0.21606708469139538, 0.2879782854999103], 
reward next is 0.7120, 
noisyNet noise sample is [array([0.36700818], dtype=float32), -1.2095524]. 
=============================================
[2019-03-26 17:18:20,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.56601]
 [70.86345]
 [71.73206]
 [73.26786]
 [73.2282 ]], R is [[70.48979187]
 [70.49640656]
 [70.50245667]
 [70.50804138]
 [70.51327515]].
[2019-03-26 17:18:21,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3852039e-23 1.0000000e+00 2.6650587e-27 1.9057519e-26 4.5286655e-34], sum to 1.0000
[2019-03-26 17:18:21,916] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0364
[2019-03-26 17:18:21,922] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 90.33333333333334, 1.0, 2.0, 0.5116815054405028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715000.8983977824, 715000.8983977824, 185446.2512504732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2587200.0000, 
sim time next is 2587800.0000, 
raw observation next is [25.9, 90.66666666666667, 1.0, 2.0, 0.5097320774808656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712275.9414929863, 712275.9414929857, 185134.6251956974], 
processed observation next is [1.0, 0.9565217391304348, 0.42654028436018954, 0.9066666666666667, 1.0, 1.0, 0.4093157560010428, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19785442819249618, 0.19785442819249602, 0.2763203361129812], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.0889182], dtype=float32), -1.0499945]. 
=============================================
[2019-03-26 17:18:23,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5108900e-26 1.0000000e+00 1.7019864e-29 6.3402582e-31 3.8835413e-36], sum to 1.0000
[2019-03-26 17:18:23,908] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7493
[2019-03-26 17:18:23,914] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.96666666666667, 93.0, 1.0, 2.0, 0.5563324514544964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777416.9696505311, 777416.9696505311, 192892.673262696], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2492400.0000, 
sim time next is 2493000.0000, 
raw observation next is [26.95, 93.0, 1.0, 2.0, 0.5557684444988097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776628.5402283682, 776628.5402283682, 192794.9312219789], 
processed observation next is [1.0, 0.8695652173913043, 0.476303317535545, 0.93, 1.0, 1.0, 0.4647812584323008, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21573015006343563, 0.21573015006343563, 0.28775362868952076], 
reward next is 0.7122, 
noisyNet noise sample is [array([0.72441715], dtype=float32), 1.1489931]. 
=============================================
[2019-03-26 17:18:23,937] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[69.164795]
 [69.02095 ]
 [69.020424]
 [68.99276 ]
 [68.88702 ]], R is [[69.34777069]
 [69.36639404]
 [69.38510132]
 [69.40387726]
 [69.42259979]].
[2019-03-26 17:18:28,858] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.8392447e-23 1.0000000e+00 1.2274314e-26 4.2174777e-27 5.5487218e-34], sum to 1.0000
[2019-03-26 17:18:28,868] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7417
[2019-03-26 17:18:28,873] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 86.0, 1.0, 2.0, 0.6977168232560289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024736.695136607, 1024736.695136607, 226878.1001928396], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2813400.0000, 
sim time next is 2814000.0000, 
raw observation next is [24.66666666666666, 85.0, 1.0, 2.0, 0.7398663022558563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1085476.948340733, 1085476.948340732, 236579.1987460428], 
processed observation next is [1.0, 0.5652173913043478, 0.36808846761453373, 0.85, 1.0, 1.0, 0.6865859063323569, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3015213745390925, 0.30152137453909217, 0.35310328171051164], 
reward next is 0.6469, 
noisyNet noise sample is [array([0.18306904], dtype=float32), -0.15396632]. 
=============================================
[2019-03-26 17:18:28,890] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.078545]
 [65.908936]
 [66.781624]
 [66.45399 ]
 [67.02084 ]], R is [[64.26542664]
 [64.28414917]
 [64.31737518]
 [64.38148499]
 [64.43109894]].
[2019-03-26 17:18:37,897] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3376091e-30 1.0000000e+00 2.1477451e-32 5.5228264e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:18:37,905] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-26 17:18:37,910] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4301449196680473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 624343.1823901994, 624343.1823902001, 176365.8898578028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2712000.0000, 
sim time next is 2712600.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.4298083115286231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 623859.9893660145, 623859.9893660152, 176318.8735887948], 
processed observation next is [0.0, 0.391304347826087, 0.28909952606635075, 1.0, 1.0, 1.0, 0.3130220620826784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1732944414905596, 0.17329444149055978, 0.2631624978937236], 
reward next is 0.7368, 
noisyNet noise sample is [array([1.3468053], dtype=float32), 0.7353281]. 
=============================================
[2019-03-26 17:18:39,216] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7016496e-28 1.0000000e+00 1.5175412e-30 1.1319932e-33 4.3768176e-38], sum to 1.0000
[2019-03-26 17:18:39,227] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9953
[2019-03-26 17:18:39,232] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.393498388311652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 587159.3775001465, 587159.3775001465, 173357.6295001984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2734200.0000, 
sim time next is 2734800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3939020088306986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587761.3349344825, 587761.3349344818, 173412.6244485988], 
processed observation next is [0.0, 0.6521739130434783, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2697614564225284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1632670374818007, 0.1632670374818005, 0.25882481260984896], 
reward next is 0.7412, 
noisyNet noise sample is [array([0.47203383], dtype=float32), -0.9252326]. 
=============================================
[2019-03-26 17:18:40,789] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.01500274e-25 1.00000000e+00 9.68214275e-29 5.96037476e-30
 6.51532882e-36], sum to 1.0000
[2019-03-26 17:18:40,798] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2587
[2019-03-26 17:18:40,803] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3479686845064236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536037.1310052006, 536037.1310052006, 169491.6814487811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3482858314377635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536525.5723650093, 536525.57236501, 169531.6095425041], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21480220655152227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490348812125026, 0.1490348812125028, 0.25303225304851357], 
reward next is 0.7470, 
noisyNet noise sample is [array([1.1372786], dtype=float32), -1.3897165]. 
=============================================
[2019-03-26 17:18:41,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1924947e-26 1.0000000e+00 1.9417369e-28 6.2675188e-30 3.8881533e-35], sum to 1.0000
[2019-03-26 17:18:41,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9689
[2019-03-26 17:18:41,951] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3477371748223802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535680.1998126784, 535680.1998126784, 169462.5135409374], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2770800.0000, 
sim time next is 2771400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3474518561810484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535240.9313666883, 535240.9313666878, 169426.6608317343], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2137974170856005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14867803649074676, 0.1486780364907466, 0.252875613181693], 
reward next is 0.7471, 
noisyNet noise sample is [array([0.14056359], dtype=float32), -0.5357048]. 
=============================================
[2019-03-26 17:18:45,471] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6506573e-27 1.0000000e+00 1.6367523e-30 1.0767419e-31 2.3148827e-38], sum to 1.0000
[2019-03-26 17:18:45,477] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4378
[2019-03-26 17:18:45,481] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3159174402727212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499659.2191652672, 499659.2191652672, 167001.6353500614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2930400.0000, 
sim time next is 2931000.0000, 
raw observation next is [21.0, 94.00000000000001, 1.0, 2.0, 0.3162247988953518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500056.7546586314, 500056.754658632, 167029.6317560708], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.9400000000000002, 1.0, 1.0, 0.17617445650042388, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13890465407184205, 0.13890465407184222, 0.2492979578448818], 
reward next is 0.7507, 
noisyNet noise sample is [array([0.682445], dtype=float32), -1.1089833]. 
=============================================
[2019-03-26 17:18:45,497] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[78.484024]
 [78.39217 ]
 [78.319595]
 [78.22219 ]
 [78.11602 ]], R is [[78.47161102]
 [78.43763733]
 [78.40392303]
 [78.37055206]
 [78.33768463]].
[2019-03-26 17:18:49,652] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9967014e-25 1.0000000e+00 2.5093924e-29 6.1854325e-30 6.6795333e-37], sum to 1.0000
[2019-03-26 17:18:49,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6720
[2019-03-26 17:18:49,668] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.58333333333334, 96.50000000000001, 1.0, 2.0, 0.312656314054623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495910.2715004249, 495910.2715004249, 166748.6065074436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2927400.0000, 
sim time next is 2928000.0000, 
raw observation next is [20.66666666666667, 96.0, 1.0, 2.0, 0.3134946486893489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 496952.0609642697, 496952.0609642704, 166820.8496323185], 
processed observation next is [1.0, 0.9130434782608695, 0.17851500789889443, 0.96, 1.0, 1.0, 0.17288511890282998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13804223915674158, 0.13804223915674177, 0.24898634273480375], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.30909598], dtype=float32), 1.007533]. 
=============================================
[2019-03-26 17:18:49,678] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[74.79317 ]
 [74.745865]
 [74.59311 ]
 [74.54364 ]
 [74.529854]], R is [[74.88648987]
 [74.88874817]
 [74.89104462]
 [74.89332581]
 [74.8956604 ]].
[2019-03-26 17:18:53,315] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9617600e-25 1.0000000e+00 1.9934334e-28 9.1841197e-30 7.2003523e-35], sum to 1.0000
[2019-03-26 17:18:53,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7114
[2019-03-26 17:18:53,327] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.5230612596804076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821864.6246631006, 821864.6246631006, 197837.1363894793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2978400.0000, 
sim time next is 2979000.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.5180023575694004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813921.2367332013, 813921.2367332013, 196910.6037159325], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.88, 1.0, 1.0, 0.4192799488787956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22608923242588924, 0.22608923242588924, 0.29389642345661565], 
reward next is 0.7061, 
noisyNet noise sample is [array([-0.8294174], dtype=float32), 0.75818485]. 
=============================================
[2019-03-26 17:18:53,343] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[70.233055]
 [70.12177 ]
 [70.057434]
 [69.989235]
 [69.26149 ]], R is [[70.3482666 ]
 [70.34950256]
 [70.34814453]
 [70.34590912]
 [70.35431671]].
[2019-03-26 17:19:00,700] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2982746e-27 1.0000000e+00 2.5983383e-30 2.5955987e-34 1.5145573e-37], sum to 1.0000
[2019-03-26 17:19:00,708] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8981
[2019-03-26 17:19:00,713] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.3358450250939594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520389.6335634867, 520389.6335634874, 168327.2748711748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3129600.0000, 
sim time next is 3130200.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3388838356279035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 524372.102370692, 524372.102370692, 168621.6197838128], 
processed observation next is [1.0, 0.21739130434782608, 0.21800947867298584, 0.97, 1.0, 1.0, 0.2034745007565102, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1456589173251922, 0.1456589173251922, 0.2516740593788251], 
reward next is 0.7483, 
noisyNet noise sample is [array([1.0490621], dtype=float32), -0.8712109]. 
=============================================
[2019-03-26 17:19:02,214] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7668038e-22 1.0000000e+00 5.2330641e-26 1.7932487e-25 2.9982279e-32], sum to 1.0000
[2019-03-26 17:19:02,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0260
[2019-03-26 17:19:02,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 82.33333333333334, 1.0, 2.0, 0.7645639183483103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1117259.567119488, 1117259.567119488, 242017.6803069109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3150600.0000, 
sim time next is 3151200.0000, 
raw observation next is [25.33333333333334, 81.66666666666667, 1.0, 2.0, 0.8276831794280174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1206354.169971211, 1206354.169971211, 257779.7054740786], 
processed observation next is [1.0, 0.4782608695652174, 0.3996840442338076, 0.8166666666666668, 1.0, 1.0, 0.7923893728048402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33509838054755864, 0.33509838054755864, 0.38474582906578897], 
reward next is 0.6153, 
noisyNet noise sample is [array([-0.49818814], dtype=float32), -0.1834298]. 
=============================================
[2019-03-26 17:19:11,188] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:19:11,190] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:19:11,190] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:19:11,191] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:19:11,193] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:19:11,194] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:19:11,195] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:19:11,196] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:19:11,196] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:19:11,197] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:19:11,197] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:19:11,233] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run64
[2019-03-26 17:19:11,233] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run64
[2019-03-26 17:19:11,282] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run64
[2019-03-26 17:19:11,284] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run64
[2019-03-26 17:19:11,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run64
[2019-03-26 17:19:56,325] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:19:56,327] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.44195983, 97.10590681, 1.0, 2.0, 0.296103358969134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479905.7072653375, 479905.7072653375, 165626.4067785992]
[2019-03-26 17:19:56,327] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:19:56,331] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3353360e-28 1.0000000e+00 3.2042140e-30 1.9216668e-33 3.2854604e-37], sampled 0.9264627891503558
[2019-03-26 17:20:01,700] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:20:01,701] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.81666666666667, 65.0, 1.0, 2.0, 0.9234298291061298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1290709.273777289, 1290709.27377729, 276466.0451766765]
[2019-03-26 17:20:01,702] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:20:01,703] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6694979e-24 1.0000000e+00 3.5549015e-27 1.2704429e-28 5.8095121e-34], sampled 0.44022783533747356
[2019-03-26 17:20:24,457] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:20:24,458] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.77194110333334, 83.49426663333334, 1.0, 2.0, 0.8271086767232899, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1156004.631723596, 1156004.631723596, 250679.0233768274]
[2019-03-26 17:20:24,460] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:20:24,463] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7486320e-23 1.0000000e+00 2.0870155e-26 6.7535106e-27 8.9654374e-33], sampled 0.8064565250117365
[2019-03-26 17:20:27,297] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:20:27,298] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.74845319, 60.23037346, 1.0, 2.0, 0.5583795798136194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780278.6701778483, 780278.6701778483, 193248.584313305]
[2019-03-26 17:20:27,301] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:20:27,305] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1227766e-26 1.0000000e+00 2.8214717e-29 2.5904096e-31 5.5069640e-36], sampled 0.8339589058746919
[2019-03-26 17:20:29,590] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:20:29,591] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.170804105, 63.47758169833333, 1.0, 2.0, 0.6836705736005013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 955438.8402082573, 955438.8402082573, 217359.9307431436]
[2019-03-26 17:20:29,592] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:20:29,595] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.3645730e-28 1.0000000e+00 5.6842194e-30 1.6050859e-33 3.1341233e-37], sampled 0.7015497751471456
[2019-03-26 17:20:52,478] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0025416], dtype=float32), 0.098310016]
[2019-03-26 17:20:52,480] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.1465074, 86.48633635, 1.0, 2.0, 0.511338838590348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802668.5557576488, 802668.5557576488, 195630.3243015402]
[2019-03-26 17:20:52,482] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:20:52,484] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.8676214e-26 1.0000000e+00 3.4319631e-28 5.3595203e-31 8.2890725e-35], sampled 0.045731570892672435
[2019-03-26 17:21:08,538] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.1248 2926599601.6871 1317.0000
[2019-03-26 17:21:08,711] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7918.1125 3160917118.8309 1699.0000
[2019-03-26 17:21:08,953] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8006.9341 3006804960.4547 1746.0000
[2019-03-26 17:21:09,116] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.3640 2778721716.4848 918.0000
[2019-03-26 17:21:09,185] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.1928 2841841008.7546 1117.0000
[2019-03-26 17:21:10,203] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1575000, evaluation results [1575000.0, 7918.112544245096, 3160917118.8309336, 1699.0, 8265.124758854232, 2926599601.687063, 1317.0, 8667.36397027857, 2778721716.4847794, 918.0, 8006.934132974097, 3006804960.4546742, 1746.0, 8502.192808329548, 2841841008.7546134, 1117.0]
[2019-03-26 17:21:14,282] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.1347179e-08 5.2917361e-01 3.8131255e-15 4.7082645e-01 7.2847464e-18], sum to 1.0000
[2019-03-26 17:21:14,291] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9886
[2019-03-26 17:21:14,296] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.9461641896328206, 1.0, 2.0, 0.9461641896328206, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2646552.370621444, 2646552.370621445, 497306.1005616391], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3603600.0000, 
sim time next is 3604200.0000, 
raw observation next is [32.83333333333334, 63.66666666666666, 1.0, 2.0, 0.4108124532972721, 1.0, 2.0, 0.4108124532972721, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1148330.134670943, 1148330.134670943, 274896.0209343368], 
processed observation next is [1.0, 0.7391304347826086, 0.7551342812006324, 0.6366666666666666, 1.0, 1.0, 0.29013548590032784, 1.0, 1.0, 0.29013548590032784, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3189805929641508, 0.3189805929641508, 0.41029256855871166], 
reward next is 0.5897, 
noisyNet noise sample is [array([0.44696411], dtype=float32), -1.6391225]. 
=============================================
[2019-03-26 17:21:14,775] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7987269e-24 1.0000000e+00 1.4771069e-26 8.8547295e-27 9.2141095e-33], sum to 1.0000
[2019-03-26 17:21:14,788] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6034
[2019-03-26 17:21:14,798] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 90.66666666666666, 1.0, 2.0, 0.8117824857550356, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1134572.607413059, 1134572.60741306, 246823.3154878099], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3390000.0000, 
sim time next is 3390600.0000, 
raw observation next is [26.83333333333333, 89.83333333333333, 1.0, 2.0, 0.8089821532016161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1130656.691245038, 1130656.691245037, 246127.4654552584], 
processed observation next is [1.0, 0.21739130434782608, 0.470774091627172, 0.8983333333333333, 1.0, 1.0, 0.7698580159055616, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3140713031236217, 0.31407130312362136, 0.36735442605262447], 
reward next is 0.6326, 
noisyNet noise sample is [array([-0.4953775], dtype=float32), -0.30465722]. 
=============================================
[2019-03-26 17:21:17,889] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4487802e-26 1.0000000e+00 1.8903403e-30 1.4800255e-30 8.5423405e-37], sum to 1.0000
[2019-03-26 17:21:17,898] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9871
[2019-03-26 17:21:17,907] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.521772456269125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729106.38192588, 729106.38192588, 187077.9046272713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3438000.0000, 
sim time next is 3438600.0000, 
raw observation next is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5192834623208975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725627.1618463501, 725627.1618463501, 186672.8798474257], 
processed observation next is [1.0, 0.8260869565217391, 0.5655608214849924, 0.7483333333333334, 1.0, 1.0, 0.4208234485793946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20156310051287502, 0.20156310051287502, 0.2786162385782473], 
reward next is 0.7214, 
noisyNet noise sample is [array([1.9815502], dtype=float32), 1.028481]. 
=============================================
[2019-03-26 17:21:21,658] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.4728020e-23 1.0000000e+00 1.2117070e-26 6.4642186e-25 4.3247792e-34], sum to 1.0000
[2019-03-26 17:21:21,665] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8164
[2019-03-26 17:21:21,670] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 78.16666666666667, 1.0, 2.0, 0.5143106731378517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 718676.0227941895, 718676.0227941902, 185868.5921187371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3543000.0000, 
sim time next is 3543600.0000, 
raw observation next is [28.0, 77.33333333333334, 1.0, 2.0, 0.5112727953489912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714429.59310311, 714429.5931031107, 185380.9944871597], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.7733333333333334, 1.0, 1.0, 0.41117204258914597, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19845266475086387, 0.19845266475086407, 0.2766880514733727], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.1326493], dtype=float32), -0.6977721]. 
=============================================
[2019-03-26 17:21:28,112] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.2244449e-10 5.0214017e-05 1.2154941e-17 9.9994981e-01 3.6814679e-19], sum to 1.0000
[2019-03-26 17:21:28,121] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4871
[2019-03-26 17:21:28,131] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3704022.920079823 W.
[2019-03-26 17:21:28,142] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.5, 53.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.019287934354576, 6.9112, 170.5573041426782, 3704022.920079823, 2910254.458566331, 547169.2949877119], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [36.66666666666666, 52.33333333333333, 1.0, 2.0, 0.9440749795044744, 1.0, 2.0, 0.7926275292664998, 1.0, 1.0, 1.03, 7.005116985138263, 6.9112, 170.5573041426782, 3326537.876298444, 3259261.319545206, 609514.314463201], 
processed observation next is [1.0, 0.6086956521739131, 0.9368088467614529, 0.5233333333333333, 1.0, 1.0, 0.9326204572343065, 1.0, 1.0, 0.7501536497186745, 1.0, 0.5, 1.0365853658536586, 0.009391698513826263, 0.0, 0.8375144448122397, 0.92403829897179, 0.9053503665403351, 0.9097228574077627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20173751], dtype=float32), -0.20184171]. 
=============================================
[2019-03-26 17:21:28,160] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[42.392517]
 [42.259876]
 [42.561428]
 [41.696632]
 [40.5635  ]], R is [[41.16848373]
 [40.75679779]
 [40.34923172]
 [39.94573975]
 [39.54628372]].
[2019-03-26 17:21:35,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2223418e-28 1.0000000e+00 4.7043524e-31 1.8399594e-33 1.7964754e-38], sum to 1.0000
[2019-03-26 17:21:35,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-26 17:21:35,723] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333333, 55.5, 1.0, 2.0, 0.5448953182429783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761429.0324075156, 761429.0324075156, 190929.3690719922], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3865800.0000, 
sim time next is 3866400.0000, 
raw observation next is [33.0, 56.0, 1.0, 2.0, 0.5386672034981668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752722.8690367057, 752722.8690367057, 189876.3394393971], 
processed observation next is [0.0, 0.782608695652174, 0.7630331753554502, 0.56, 1.0, 1.0, 0.4441773536122491, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20908968584352935, 0.20908968584352935, 0.28339752155133896], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.9249196], dtype=float32), -0.6047158]. 
=============================================
[2019-03-26 17:21:39,094] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.7283915e-29 1.0000000e+00 5.0926313e-33 3.4732403e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:21:39,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4904
[2019-03-26 17:21:39,108] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 66.83333333333334, 1.0, 2.0, 0.5622856942543256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785739.0867143802, 785739.0867143802, 193931.2111422897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3780600.0000, 
sim time next is 3781200.0000, 
raw observation next is [31.66666666666667, 66.66666666666667, 1.0, 2.0, 0.5576751982178993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779294.0074643632, 779294.0074643632, 193126.7232787446], 
processed observation next is [1.0, 0.782608695652174, 0.6998420221169038, 0.6666666666666667, 1.0, 1.0, 0.46707855206975823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21647055762898978, 0.21647055762898978, 0.2882488407145442], 
reward next is 0.7118, 
noisyNet noise sample is [array([0.6973474], dtype=float32), 0.023959817]. 
=============================================
[2019-03-26 17:21:44,302] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1438281e-08 1.5164105e-02 8.8391369e-15 9.8483592e-01 5.6460576e-17], sum to 1.0000
[2019-03-26 17:21:44,313] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7353
[2019-03-26 17:21:44,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3365170.080551636 W.
[2019-03-26 17:21:44,329] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.0, 64.0, 1.0, 2.0, 0.9624603059306952, 1.0, 2.0, 0.80182019247961, 1.0, 1.0, 1.03, 7.00511843603906, 6.9112, 170.5573041426782, 3365170.080551636, 3297892.484459138, 617059.5862169879], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4114800.0000, 
sim time next is 4115400.0000, 
raw observation next is [35.83333333333334, 64.5, 1.0, 2.0, 1.000146160468607, 1.0, 2.0, 0.8206631197485662, 1.0, 2.0, 1.03, 7.005121410345391, 6.9112, 170.5573041426782, 3444361.294652454, 3377081.567943344, 632916.6067778536], 
processed observation next is [1.0, 0.6521739130434783, 0.8973143759873622, 0.645, 1.0, 1.0, 1.000176096950129, 1.0, 1.0, 0.7839314695765858, 1.0, 1.0, 1.0365853658536586, 0.009392141034539137, 0.0, 0.8375144448122397, 0.9567670262923483, 0.9380782133175956, 0.9446516519072441], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2212119], dtype=float32), 1.1600242]. 
=============================================
[2019-03-26 17:21:49,490] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.5910465e-08 7.2566283e-01 3.1856928e-15 2.7433711e-01 2.1191337e-17], sum to 1.0000
[2019-03-26 17:21:49,499] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7406
[2019-03-26 17:21:49,503] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.5, 53.5, 1.0, 2.0, 0.8844650678822403, 1.0, 2.0, 0.7628225734553826, 1.0, 2.0, 1.03, 7.005112281565201, 6.9112, 170.5573041426782, 3201290.648134623, 3134017.460742098, 585926.5193121238], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4199400.0000, 
sim time next is 4200000.0000, 
raw observation next is [36.66666666666666, 52.33333333333333, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.913820417765173, 6.9112, 170.5573041426782, 3628384.210875319, 2910166.421639097, 547866.8520994694], 
processed observation next is [1.0, 0.6086956521739131, 0.9368088467614529, 0.5233333333333333, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.10026204177651729, 0.0, 0.8375144448122397, 1.0078845030209218, 0.8083795615664158, 0.8177117195514468], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5472474], dtype=float32), 0.8122418]. 
=============================================
[2019-03-26 17:21:49,519] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[40.203796]
 [40.02769 ]
 [39.657974]
 [40.014423]
 [40.13952 ]], R is [[39.59756088]
 [39.20158386]
 [38.8095665 ]
 [38.42147064]
 [38.03725815]].
[2019-03-26 17:21:58,068] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6513397e-30 1.0000000e+00 3.4667841e-33 1.2078105e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:21:58,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-26 17:21:58,081] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 63.66666666666667, 1.0, 2.0, 0.6021277200999823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841436.4615245695, 841436.4615245695, 201144.1869816601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4216800.0000, 
sim time next is 4217400.0000, 
raw observation next is [33.5, 65.5, 1.0, 2.0, 0.6084434744291457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 850265.8725331981, 850265.8725331975, 202330.8089788183], 
processed observation next is [1.0, 0.8260869565217391, 0.7867298578199052, 0.655, 1.0, 1.0, 0.5282451499146333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23618496459255503, 0.23618496459255486, 0.30198628205793776], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.08743276], dtype=float32), 0.013987899]. 
=============================================
[2019-03-26 17:21:59,775] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3487457e-26 1.0000000e+00 1.3977852e-29 2.5688788e-31 4.8289225e-37], sum to 1.0000
[2019-03-26 17:21:59,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4059
[2019-03-26 17:21:59,790] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 77.0, 1.0, 2.0, 0.6179284919022626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863526.0445108453, 863526.0445108453, 204134.2642666469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4312200.0000, 
sim time next is 4312800.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6196549133722872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 865939.6209307091, 865939.6209307091, 204465.4127909181], 
processed observation next is [1.0, 0.9565217391304348, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5417529076774544, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24053878359186362, 0.24053878359186362, 0.30517225789689273], 
reward next is 0.6948, 
noisyNet noise sample is [array([-0.24849057], dtype=float32), -1.2377118]. 
=============================================
[2019-03-26 17:21:59,943] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5752136e-30 1.0000000e+00 1.4163754e-33 1.3929371e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:21:59,950] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6426
[2019-03-26 17:21:59,956] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 65.66666666666667, 1.0, 2.0, 0.5575788072303608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779159.2615228037, 779159.2615228037, 193110.3235444762], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4386000.0000, 
sim time next is 4386600.0000, 
raw observation next is [32.0, 65.0, 1.0, 2.0, 0.5550751307338234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775659.3526796368, 775659.3526796368, 192676.106123211], 
processed observation next is [1.0, 0.782608695652174, 0.7156398104265403, 0.65, 1.0, 1.0, 0.4639459406431607, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2154609312998991, 0.2154609312998991, 0.28757627779583733], 
reward next is 0.7124, 
noisyNet noise sample is [array([-1.4409869], dtype=float32), 0.6878676]. 
=============================================
[2019-03-26 17:22:03,285] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2041324e-33 1.0000000e+00 3.6135001e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:22:03,287] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-26 17:22:03,294] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [36.0, 50.0, 1.0, 2.0, 0.5702680169259311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796897.7837683539, 796897.7837683539, 195338.9931550254], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4301400.0000, 
sim time next is 4302000.0000, 
raw observation next is [36.0, 50.0, 1.0, 2.0, 0.5713963860043857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 798475.1697896112, 798475.169789612, 195539.38747306], 
processed observation next is [1.0, 0.8260869565217391, 0.9052132701421801, 0.5, 1.0, 1.0, 0.48361010361974177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.221798658274892, 0.2217986582748922, 0.2918498320493433], 
reward next is 0.7082, 
noisyNet noise sample is [array([1.1800816], dtype=float32), 1.0442951]. 
=============================================
[2019-03-26 17:22:03,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.77978 ]
 [72.415985]
 [73.11015 ]
 [73.67967 ]
 [74.27351 ]], R is [[71.21707916]
 [71.21335602]
 [71.20979309]
 [71.20595551]
 [71.20173645]].
[2019-03-26 17:22:05,648] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 17:22:05,649] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:22:05,651] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:22:05,653] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:22:05,654] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:22:05,655] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:22:05,656] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:22:05,658] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:22:05,657] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:22:05,659] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:22:05,660] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:22:05,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run65
[2019-03-26 17:22:05,715] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run65
[2019-03-26 17:22:05,738] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run65
[2019-03-26 17:22:05,738] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run65
[2019-03-26 17:22:05,760] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run65
[2019-03-26 17:22:06,964] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:22:06,965] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.6935092, 83.00845064333333, 1.0, 2.0, 0.2583937671893332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 423527.1064415993, 423527.1064415993, 161747.306819378]
[2019-03-26 17:22:06,966] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:22:06,971] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0697826e-33 1.0000000e+00 8.3232659e-34 0.0000000e+00 0.0000000e+00], sampled 0.9203287240498708
[2019-03-26 17:22:28,430] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:22:28,432] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.06666666666667, 76.33333333333334, 1.0, 2.0, 0.371240135605223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 560304.8119079579, 560304.8119079586, 171176.2902761309]
[2019-03-26 17:22:28,433] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:22:28,436] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0568830e-31 1.0000000e+00 4.5801106e-33 0.0000000e+00 0.0000000e+00], sampled 0.35953829178526187
[2019-03-26 17:22:39,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:22:39,584] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.83652056666667, 61.80642891, 1.0, 2.0, 0.996518214131548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1392934.414614433, 1392934.414614433, 297865.0482547404]
[2019-03-26 17:22:39,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:22:39,588] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5449227e-24 1.0000000e+00 2.0404506e-27 8.4599404e-29 3.1219213e-34], sampled 0.3753201966880525
[2019-03-26 17:22:49,804] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:22:49,807] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.76666666666667, 71.33333333333334, 1.0, 2.0, 0.5085672421500708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710647.7102172275, 710647.7102172275, 184948.7962076727]
[2019-03-26 17:22:49,808] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:22:49,810] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0625464e-27 1.0000000e+00 7.2191558e-30 2.6324162e-32 4.3763690e-37], sampled 0.43719054498373555
[2019-03-26 17:23:13,545] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:23:13,545] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.15573420666667, 81.03348377666667, 1.0, 2.0, 0.4869442842062169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686103.4372337228, 686103.4372337228, 182305.8197339139]
[2019-03-26 17:23:13,546] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:23:13,549] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5446821e-30 1.0000000e+00 3.1255945e-32 5.5260665e-38 0.0000000e+00], sampled 0.1948002113808549
[2019-03-26 17:23:18,224] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00264848], dtype=float32), 0.09676336]
[2019-03-26 17:23:18,226] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.0, 82.0, 1.0, 2.0, 0.6149954735722993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859425.630854698, 859425.630854698, 203572.4325710443]
[2019-03-26 17:23:18,227] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:23:18,230] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8361704e-27 1.0000000e+00 1.1841147e-29 4.7325188e-32 6.2976218e-37], sampled 0.3004622806378454
[2019-03-26 17:24:02,674] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1318 3164071238.8952 1774.0000
[2019-03-26 17:24:03,178] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:24:03,579] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2300 2927457024.3359 1338.0000
[2019-03-26 17:24:03,602] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0118 2842572848.4797 1131.0000
[2019-03-26 17:24:03,615] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 17:24:04,627] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1600000, evaluation results [1600000.0, 7884.131844980227, 3164071238.8952265, 1774.0, 8254.230042292205, 2927457024.3359056, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8496.011805747043, 2842572848.4796743, 1131.0]
[2019-03-26 17:24:07,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6865797e-09 1.2497284e-03 1.6651489e-16 9.9875021e-01 2.4795966e-17], sum to 1.0000
[2019-03-26 17:24:07,859] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9714
[2019-03-26 17:24:07,867] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3431788.979018739 W.
[2019-03-26 17:24:07,872] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.5, 57.0, 1.0, 2.0, 0.9941633526035749, 1.0, 2.0, 0.8176717158160499, 1.0, 2.0, 1.03, 7.005120938134999, 6.9112, 170.5573041426782, 3431788.979018739, 3364509.590573141, 630362.6350989953], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4361400.0000, 
sim time next is 4362000.0000, 
raw observation next is [36.66666666666666, 56.0, 1.0, 2.0, 0.980102082421531, 1.0, 2.0, 0.8106410807250278, 1.0, 2.0, 1.03, 7.005119828346049, 6.9112, 170.5573041426782, 3402241.022752801, 3334962.429294171, 624415.333130737], 
processed observation next is [1.0, 0.4782608695652174, 0.9368088467614529, 0.56, 1.0, 1.0, 0.9760266053271457, 1.0, 1.0, 0.7718567237650937, 1.0, 1.0, 1.0365853658536586, 0.009391982834604917, 0.0, 0.8375144448122397, 0.945066950764667, 0.9263784525817141, 0.9319631837772193], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8905701], dtype=float32), 1.7901573]. 
=============================================
[2019-03-26 17:24:07,884] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[38.895786]
 [38.984936]
 [40.21543 ]
 [42.636765]
 [43.616215]], R is [[39.14167023]
 [38.75025558]
 [38.36275482]
 [37.97912598]
 [37.59933472]].
[2019-03-26 17:24:20,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1359981e-30 1.0000000e+00 1.1148733e-32 1.2754186e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:24:20,416] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7342
[2019-03-26 17:24:20,423] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.507745637686434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709499.2557531429, 709499.2557531429, 184818.0670325271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4500600.0000, 
sim time next is 4501200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5079039030453599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709720.4820082138, 709720.4820082145, 184843.2213397491], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4071131361992288, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19714457833561494, 0.19714457833561513, 0.27588540498470016], 
reward next is 0.7241, 
noisyNet noise sample is [array([-0.46383604], dtype=float32), -3.104471]. 
=============================================
[2019-03-26 17:24:37,203] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.1574835e-27 1.0000000e+00 2.0403395e-29 6.6680902e-33 2.1938639e-36], sum to 1.0000
[2019-03-26 17:24:37,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2808
[2019-03-26 17:24:37,215] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.51552657840625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720375.6536032964, 720375.6536032964, 186064.1725502636], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5191200.0000, 
sim time next is 5191800.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.379225645507997, 6.9112, 168.9108766384548, 1786011.749639883, 1453982.336937338, 311348.6666362893], 
processed observation next is [1.0, 0.08695652173913043, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.046802564550799716, 0.0, 0.82942973202873, 0.49611437489996746, 0.40388398248259394, 0.4646995024422228], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9755898], dtype=float32), 1.9853038]. 
=============================================
[2019-03-26 17:24:50,659] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1691099e-26 1.0000000e+00 5.8325731e-30 3.3526227e-31 8.5071176e-38], sum to 1.0000
[2019-03-26 17:24:50,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5736
[2019-03-26 17:24:50,675] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 90.66666666666667, 1.0, 2.0, 0.5261981594406021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735292.8434909399, 735292.8434909392, 187802.383680857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5614800.0000, 
sim time next is 5615400.0000, 
raw observation next is [26.35, 90.83333333333334, 1.0, 2.0, 0.5259481155828085, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734943.3191541422, 734943.3191541422, 187761.2183691676], 
processed observation next is [1.0, 1.0, 0.4478672985781992, 0.9083333333333334, 1.0, 1.0, 0.42885315130458856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2041509219872617, 0.2041509219872617, 0.2802406244315934], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.5351154], dtype=float32), -0.98947424]. 
=============================================
[2019-03-26 17:24:52,262] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.7025312e-31 1.0000000e+00 1.8128653e-32 2.2163717e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:24:52,271] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2260
[2019-03-26 17:24:52,278] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 72.0, 1.0, 2.0, 0.5249969805333947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733613.7740593866, 733613.774059386, 187605.231820317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5042400.0000, 
sim time next is 5043000.0000, 
raw observation next is [29.66666666666666, 69.0, 1.0, 2.0, 0.5190845397182875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725349.0999853517, 725349.0999853524, 186640.1265021333], 
processed observation next is [0.0, 0.34782608695652173, 0.6050552922590835, 0.69, 1.0, 1.0, 0.4205837827931174, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20148586110704214, 0.20148586110704234, 0.27856735298825863], 
reward next is 0.7214, 
noisyNet noise sample is [array([0.61157495], dtype=float32), -1.2381333]. 
=============================================
[2019-03-26 17:24:52,292] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.69743]
 [72.58569]
 [72.50337]
 [72.44922]
 [72.43034]], R is [[72.8217926 ]
 [72.81356812]
 [72.80427551]
 [72.79416656]
 [72.78348541]].
[2019-03-26 17:24:53,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.1810679e-31 1.0000000e+00 1.5781962e-32 2.3621430e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:24:53,129] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9390
[2019-03-26 17:24:53,137] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 63.5, 1.0, 2.0, 0.5143577971479303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718741.8941740311, 718741.8941740311, 185876.7264951668], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5050200.0000, 
sim time next is 5050800.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5159538375002802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720972.8905128329, 720972.8905128335, 186134.0273546086], 
processed observation next is [0.0, 0.4782608695652174, 0.6682464454976303, 0.63, 1.0, 1.0, 0.41681185240997615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2002702473646758, 0.20027024736467597, 0.2778119811262815], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.94229066], dtype=float32), 0.39917102]. 
=============================================
[2019-03-26 17:24:53,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0266004e-30 1.0000000e+00 1.8385922e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:24:53,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3675
[2019-03-26 17:24:53,568] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 78.0, 1.0, 2.0, 0.533352413587641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745293.4815419449, 745293.4815419449, 188986.9330234895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5041200.0000, 
sim time next is 5041800.0000, 
raw observation next is [29.0, 75.0, 1.0, 2.0, 0.5296682617982389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740143.5453028558, 740143.5453028558, 188375.121748588], 
processed observation next is [0.0, 0.34782608695652173, 0.5734597156398105, 0.75, 1.0, 1.0, 0.43333525517860105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20559542925079327, 0.20559542925079327, 0.2811568981322209], 
reward next is 0.7188, 
noisyNet noise sample is [array([0.9277715], dtype=float32), 0.9212336]. 
=============================================
[2019-03-26 17:25:00,162] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 17:25:00,165] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:25:00,166] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:25:00,167] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:25:00,168] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:25:00,168] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:25:00,169] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:25:00,170] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:25:00,170] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:25:00,172] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:25:00,173] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:25:00,196] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run66
[2019-03-26 17:25:00,221] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run66
[2019-03-26 17:25:00,247] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run66
[2019-03-26 17:25:00,247] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run66
[2019-03-26 17:25:00,297] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run66
[2019-03-26 17:26:10,811] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-9.239677e-06], dtype=float32), 0.09770568]
[2019-03-26 17:26:10,812] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.5164198616967963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721624.3149491311, 721624.3149491318, 186208.848346045]
[2019-03-26 17:26:10,813] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:26:10,815] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5556853e-31 1.0000000e+00 3.4607590e-33 0.0000000e+00 0.0000000e+00], sampled 0.5816517440548014
[2019-03-26 17:26:57,125] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 17:26:57,343] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5218 3164216843.8166 1775.0000
[2019-03-26 17:26:57,900] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 17:26:58,050] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:26:58,121] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.2939 2842570500.4657 1131.0000
[2019-03-26 17:26:59,140] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1625000, evaluation results [1625000.0, 7883.521784886193, 3164216843.816594, 1775.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8495.29385357824, 2842570500.4656844, 1131.0]
[2019-03-26 17:26:59,664] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1833551e-12 1.0000000e+00 1.7423377e-18 4.9555724e-09 5.3719898e-22], sum to 1.0000
[2019-03-26 17:26:59,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4445
[2019-03-26 17:26:59,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3265652.234039308 W.
[2019-03-26 17:26:59,690] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.15000000000001, 52.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.408041709994095, 6.9112, 170.5573041426782, 3265652.234039308, 2909744.306941937, 550970.7679310611], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5319000.0000, 
sim time next is 5319600.0000, 
raw observation next is [36.13333333333333, 52.66666666666666, 1.0, 2.0, 0.821838965403674, 1.0, 2.0, 0.7315095222160997, 1.0, 1.0, 1.03, 7.005107341012395, 6.9112, 170.5573041426782, 3069719.588161332, 3002449.93988775, 562573.8650809017], 
processed observation next is [1.0, 0.5652173913043478, 0.9115323854660348, 0.5266666666666666, 1.0, 1.0, 0.7853481510887638, 1.0, 1.0, 0.6765174966459032, 1.0, 0.5, 1.0365853658536586, 0.009390734101239495, 0.0, 0.8375144448122397, 0.85269988560037, 0.8340138721910416, 0.8396624851953756], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2802097], dtype=float32), -1.789336]. 
=============================================
[2019-03-26 17:26:59,829] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9803315e-22 1.0000000e+00 6.1073483e-25 8.5708229e-25 6.5197962e-31], sum to 1.0000
[2019-03-26 17:26:59,841] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9024
[2019-03-26 17:26:59,849] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 86.5, 1.0, 2.0, 0.5373240918244456, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9084363489052549, 6.911199999999999, 6.9112, 168.9129564226556, 1502221.859434403, 1502221.859434404, 324166.7424325305], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5193000.0000, 
sim time next is 5193600.0000, 
raw observation next is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.546640891294885, 6.9112, 168.9095570980267, 1904858.269240045, 1454063.703295549, 311348.3218831458], 
processed observation next is [1.0, 0.08695652173913043, 0.44707740916271754, 0.8733333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0635440891294885, 0.0, 0.8294232524811399, 0.5291272970111236, 0.4039065842487636, 0.4646989878852922], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7717115], dtype=float32), 1.5808959]. 
=============================================
[2019-03-26 17:27:14,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8302157e-28 1.0000000e+00 3.9625501e-31 8.1777285e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:27:14,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7740
[2019-03-26 17:27:14,856] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 89.0, 1.0, 2.0, 0.587981458989028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821660.2851378199, 821660.2851378199, 198528.4640222481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5446800.0000, 
sim time next is 5447400.0000, 
raw observation next is [28.41666666666666, 89.66666666666667, 1.0, 2.0, 0.5883698627198274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822203.2604925588, 822203.2604925588, 198599.4757223906], 
processed observation next is [1.0, 0.043478260869565216, 0.5458135860979461, 0.8966666666666667, 1.0, 1.0, 0.504060075566057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22838979458126635, 0.22838979458126635, 0.2964171279438666], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.28862435], dtype=float32), 1.1331455]. 
=============================================
[2019-03-26 17:27:16,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.2205767e-26 1.0000000e+00 8.7794845e-28 6.6039442e-33 3.0222115e-35], sum to 1.0000
[2019-03-26 17:27:16,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6377
[2019-03-26 17:27:16,167] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.08333333333334, 80.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.948623555477348, 6.9112, 168.9125158918635, 1480322.598985363, 1453773.109966313, 311355.0218934852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5469000.0000, 
sim time next is 5469600.0000, 
raw observation next is [30.26666666666667, 79.33333333333334, 1.0, 2.0, 0.9418233949843522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129260385771, 1316434.525867723, 1316434.525867723, 281706.0533911566], 
processed observation next is [1.0, 0.30434782608695654, 0.6334913112164299, 0.7933333333333334, 1.0, 1.0, 0.9299077048004243, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294397955215499, 0.3656762571854786, 0.3656762571854786, 0.4204567961062039], 
reward next is 0.5795, 
noisyNet noise sample is [array([-0.11610983], dtype=float32), 0.91396266]. 
=============================================
[2019-03-26 17:27:21,974] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.08755635e-33 1.00000000e+00 3.07460936e-35 0.00000000e+00
 0.00000000e+00], sum to 1.0000
[2019-03-26 17:27:21,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6203
[2019-03-26 17:27:21,989] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 77.5, 1.0, 2.0, 0.5220835440044166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729541.2342042342, 729541.2342042349, 187128.3554926587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5729400.0000, 
sim time next is 5730000.0000, 
raw observation next is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.5231095193629334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730975.3894732237, 730975.3894732231, 187295.9904514712], 
processed observation next is [0.0, 0.30434782608695654, 0.5481832543443919, 0.7666666666666667, 1.0, 1.0, 0.42543315585895586, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20304871929811769, 0.20304871929811755, 0.27954625440518094], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.952318], dtype=float32), -0.2383226]. 
=============================================
[2019-03-26 17:27:22,010] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[72.09016 ]
 [72.07028 ]
 [72.05845 ]
 [72.038414]
 [71.94521 ]], R is [[72.12295532]
 [72.12242889]
 [72.12213135]
 [72.12204742]
 [72.12236023]].
[2019-03-26 17:27:33,520] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1612428e-26 1.0000000e+00 1.9178040e-29 6.0095657e-33 8.1340125e-37], sum to 1.0000
[2019-03-26 17:27:33,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6658
[2019-03-26 17:27:33,532] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7233181724426507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1010873.264611454, 1010873.264611454, 225959.1443215436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6147000.0000, 
sim time next is 6147600.0000, 
raw observation next is [26.6, 92.0, 1.0, 2.0, 0.7153428128753893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 999722.0550100794, 999722.0550100801, 224192.0248112489], 
processed observation next is [1.0, 0.13043478260869565, 0.4597156398104266, 0.92, 1.0, 1.0, 0.6570395335848063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27770057083613314, 0.27770057083613336, 0.3346149624048491], 
reward next is 0.6654, 
noisyNet noise sample is [array([-0.14638603], dtype=float32), -0.9567328]. 
=============================================
[2019-03-26 17:27:44,317] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1222346e-27 1.0000000e+00 1.4150652e-30 2.0887455e-32 4.6687615e-37], sum to 1.0000
[2019-03-26 17:27:44,325] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5776
[2019-03-26 17:27:44,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 82.16666666666667, 1.0, 2.0, 0.5669550317200499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792266.461110864, 792266.461110864, 194751.4917006472], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5944200.0000, 
sim time next is 5944800.0000, 
raw observation next is [28.9, 82.33333333333334, 1.0, 2.0, 0.5665647677207547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 791720.9005407364, 791720.900540737, 194682.4580988192], 
processed observation next is [1.0, 0.8260869565217391, 0.5687203791469194, 0.8233333333333335, 1.0, 1.0, 0.4777888767719936, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21992247237242676, 0.21992247237242693, 0.2905708329833122], 
reward next is 0.7094, 
noisyNet noise sample is [array([-0.14172232], dtype=float32), -0.25045475]. 
=============================================
[2019-03-26 17:27:51,187] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.6183860e-26 1.0000000e+00 1.4067136e-28 1.9120230e-32 3.8314504e-36], sum to 1.0000
[2019-03-26 17:27:51,191] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2450
[2019-03-26 17:27:51,196] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.51666666666667, 92.0, 1.0, 2.0, 0.7281500722678417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1017629.321383568, 1017629.321383569, 227038.6975987976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6151800.0000, 
sim time next is 6152400.0000, 
raw observation next is [26.5, 92.0, 1.0, 2.0, 0.8048604585854447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1124893.041138004, 1124893.041138004, 245107.2172532902], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.92, 1.0, 1.0, 0.7648921187776443, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31247028920500114, 0.31247028920500114, 0.3658316675422242], 
reward next is 0.6342, 
noisyNet noise sample is [array([-0.09419181], dtype=float32), -1.0857944]. 
=============================================
[2019-03-26 17:27:54,687] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 17:27:54,689] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:27:54,691] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:27:54,691] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:54,692] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:54,693] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:27:54,694] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:54,695] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:27:54,696] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:27:54,697] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:54,697] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:27:54,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run67
[2019-03-26 17:27:54,748] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run67
[2019-03-26 17:27:54,781] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run67
[2019-03-26 17:27:54,803] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run67
[2019-03-26 17:27:54,803] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run67
[2019-03-26 17:28:15,451] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:15,452] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.85, 92.5, 1.0, 2.0, 0.298805755712317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476170.2542246285, 476170.2542246285, 165354.0656031102]
[2019-03-26 17:28:15,454] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:28:15,456] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2884231e-28 1.0000000e+00 4.1070301e-31 5.3279947e-35 1.9051296e-38], sampled 0.18812970245720773
[2019-03-26 17:28:24,257] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:24,258] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.09617046, 95.77319603000001, 1.0, 2.0, 0.492699138452962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688467.1903617484, 688467.1903617478, 182460.4988523567]
[2019-03-26 17:28:24,259] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:28:24,260] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.8605774e-28 1.0000000e+00 1.7148044e-30 1.4200217e-33 1.0731220e-37], sampled 0.32603791641604996
[2019-03-26 17:28:33,302] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:33,302] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.57401504333333, 97.37454529833333, 1.0, 2.0, 0.5306553003172131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741523.2866131635, 741523.2866131635, 188538.1704185053]
[2019-03-26 17:28:33,303] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:28:33,309] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8284690e-27 1.0000000e+00 2.3064303e-30 4.9880002e-33 1.4767324e-37], sampled 0.015735131922457235
[2019-03-26 17:28:37,314] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:37,315] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.68359768666667, 87.23282040666668, 1.0, 2.0, 0.3245885482480444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514987.7137665941, 514987.7137665941, 168188.1385960152]
[2019-03-26 17:28:37,317] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:28:37,319] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1447901e-30 1.0000000e+00 1.0617275e-32 5.5003897e-37 0.0000000e+00], sampled 0.3096020513799267
[2019-03-26 17:28:48,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:48,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.5, 65.0, 1.0, 2.0, 0.5474955679184457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765063.893182569, 765063.893182569, 191375.1169888875]
[2019-03-26 17:28:48,781] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:28:48,784] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4426564e-24 1.0000000e+00 1.6699211e-28 1.9277235e-26 2.4669312e-34], sampled 0.7908979048413883
[2019-03-26 17:28:52,165] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:28:52,167] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.86666666666667, 72.0, 1.0, 2.0, 0.5476830057483149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 765325.9109694514, 765325.910969452, 191403.825488201]
[2019-03-26 17:28:52,168] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:28:52,170] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2781240e-31 1.0000000e+00 3.6407338e-33 0.0000000e+00 0.0000000e+00], sampled 0.11824781736730039
[2019-03-26 17:29:03,265] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:29:03,267] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 52.66666666666667, 1.0, 2.0, 0.5184773727713303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724500.3785256048, 724500.3785256048, 186540.9711553631]
[2019-03-26 17:29:03,268] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:29:03,272] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0166481e-28 1.0000000e+00 1.0561415e-31 2.0395484e-34 0.0000000e+00], sampled 0.32759911357993887
[2019-03-26 17:29:09,207] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:29:09,209] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.00832729333333, 84.72565838833334, 1.0, 2.0, 0.4179411673532654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622552.3995160499, 622552.3995160499, 176616.5115531177]
[2019-03-26 17:29:09,211] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:29:09,215] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5429583e-28 1.0000000e+00 1.7097936e-31 2.1584698e-34 0.0000000e+00], sampled 0.9008746430893484
[2019-03-26 17:29:18,845] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00620992], dtype=float32), 0.09877511]
[2019-03-26 17:29:18,847] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.629162915, 61.44376099999999, 1.0, 2.0, 0.5668349928138148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792098.6554565208, 792098.6554565208, 194730.0045149706]
[2019-03-26 17:29:18,849] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:29:18,851] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.7534584e-30 1.0000000e+00 2.2938805e-32 1.6463083e-37 0.0000000e+00], sampled 0.02072597625418615
[2019-03-26 17:29:51,515] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7698 2779391179.5378 933.0000
[2019-03-26 17:29:51,821] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.4471 3007786103.6909 1766.0000
[2019-03-26 17:29:51,929] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7891.9865 3163652262.6576 1761.0000
[2019-03-26 17:29:52,024] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.9894 2927341240.0875 1334.0000
[2019-03-26 17:29:52,212] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6909 2842579001.8733 1130.0000
[2019-03-26 17:29:53,233] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1650000, evaluation results [1650000.0, 7891.986544318722, 3163652262.6575527, 1761.0, 8255.989382374484, 2927341240.087533, 1334.0, 8660.769831095575, 2779391179.5378137, 933.0, 7999.4470836124665, 3007786103.6908946, 1766.0, 8497.690939361179, 2842579001.8733263, 1130.0]
[2019-03-26 17:29:56,712] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2003270e-24 1.0000000e+00 2.3400307e-27 3.6673487e-30 1.7289228e-34], sum to 1.0000
[2019-03-26 17:29:56,720] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7746
[2019-03-26 17:29:56,728] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333333, 86.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.15934877929128, 6.9112, 168.9118537293756, 1629919.627037903, 1453875.491732661, 311351.9455118412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6163800.0000, 
sim time next is 6164400.0000, 
raw observation next is [27.96666666666667, 86.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 10.80234669686688, 6.9112, 168.8853601891817, 4215511.649550125, 1455449.261463032, 303345.9558527796], 
processed observation next is [1.0, 0.34782608695652173, 0.524486571879937, 0.86, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.38911466968668806, 0.0, 0.8293044345813181, 1.170975458208368, 0.40429146151750894, 0.45275515798922333], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.80004066], dtype=float32), 0.6247791]. 
=============================================
[2019-03-26 17:30:09,080] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1046814e-28 1.0000000e+00 3.8271508e-31 2.6903932e-33 6.4412836e-38], sum to 1.0000
[2019-03-26 17:30:09,090] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9445
[2019-03-26 17:30:09,095] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 82.0, 1.0, 2.0, 0.5238429018108497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732000.5461796583, 732000.546179659, 187415.5353258191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6384000.0000, 
sim time next is 6384600.0000, 
raw observation next is [27.45, 82.0, 1.0, 2.0, 0.5227449343679943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730465.7556748218, 730465.7556748218, 187235.9598224992], 
processed observation next is [0.0, 0.9130434782608695, 0.5, 0.82, 1.0, 1.0, 0.42499389682890876, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20290715435411716, 0.20290715435411716, 0.2794566564514913], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.0740492], dtype=float32), 0.19258575]. 
=============================================
[2019-03-26 17:30:09,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0516377e-27 1.0000000e+00 6.5865194e-30 3.5734920e-32 4.3383053e-37], sum to 1.0000
[2019-03-26 17:30:09,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8207
[2019-03-26 17:30:09,750] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.15, 82.5, 1.0, 2.0, 0.512316550059083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715888.5804238338, 715888.5804238344, 185548.0190812189], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [27.13333333333333, 82.66666666666666, 1.0, 2.0, 0.5122698657261385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715823.3238133806, 715823.3238133806, 185540.5564482097], 
processed observation next is [0.0, 1.0, 0.484992101105845, 0.8266666666666665, 1.0, 1.0, 0.41237333220016686, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1988398121703835, 0.1988398121703835, 0.27692620365404436], 
reward next is 0.7231, 
noisyNet noise sample is [array([1.9103659], dtype=float32), 0.8272663]. 
=============================================
[2019-03-26 17:30:12,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7682648e-08 5.7667816e-01 3.1225870e-15 4.2332181e-01 1.2462687e-17], sum to 1.0000
[2019-03-26 17:30:12,585] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-26 17:30:12,591] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2118125.508342401 W.
[2019-03-26 17:30:12,595] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 67.0, 1.0, 2.0, 0.7574119898223519, 1.0, 2.0, 0.7574119898223519, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2118125.508342401, 2118125.508342401, 399664.0262128448], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6452400.0000, 
sim time next is 6453000.0000, 
raw observation next is [30.0, 67.0, 1.0, 2.0, 0.5072532797124254, 1.0, 2.0, 0.5072532797124254, 1.0, 1.0, 0.8684487981159804, 6.9112, 6.9112, 170.5573041426782, 2127833.310935672, 2127833.310935672, 417890.4797068569], 
processed observation next is [1.0, 0.6956521739130435, 0.6208530805687204, 0.67, 1.0, 1.0, 0.40632925266557274, 1.0, 1.0, 0.40632925266557274, 1.0, 0.5, 0.8395717050194882, 0.0, 0.0, 0.8375144448122397, 0.5910648085932422, 0.5910648085932422, 0.6237171338908312], 
reward next is 0.3763, 
noisyNet noise sample is [array([0.3394827], dtype=float32), 0.29484895]. 
=============================================
[2019-03-26 17:30:12,611] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[43.277004]
 [42.472122]
 [41.827198]
 [41.23043 ]
 [41.030663]], R is [[42.53140259]
 [42.5095787 ]
 [42.49868393]
 [42.44923401]
 [42.02474213]].
[2019-03-26 17:30:12,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.029662e-09 7.818022e-04 8.969860e-16 9.992182e-01 6.294347e-17], sum to 1.0000
[2019-03-26 17:30:12,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7457
[2019-03-26 17:30:12,749] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 69.0, 1.0, 2.0, 0.851975153282298, 1.0, 2.0, 0.851975153282298, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2382841.368627954, 2382841.368627954, 445960.6646075353], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6435000.0000, 
sim time next is 6435600.0000, 
raw observation next is [29.86666666666667, 69.0, 1.0, 2.0, 0.8611423766571136, 1.0, 2.0, 0.8611423766571136, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2408505.368326906, 2408505.368326906, 450728.0431117683], 
processed observation next is [1.0, 0.4782608695652174, 0.6145339652448659, 0.69, 1.0, 1.0, 0.8327016586230284, 1.0, 1.0, 0.8327016586230284, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6690292689796962, 0.6690292689796962, 0.6727284225548781], 
reward next is 0.3273, 
noisyNet noise sample is [array([0.6481719], dtype=float32), -1.8259138]. 
=============================================
[2019-03-26 17:30:13,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0581353e-31 1.0000000e+00 3.4694830e-33 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:30:13,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5902
[2019-03-26 17:30:13,618] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.06666666666667, 41.66666666666667, 1.0, 2.0, 0.295865018235059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 474243.6429437394, 474243.64294374, 165249.1464019666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6870000.0000, 
sim time next is 6870600.0000, 
raw observation next is [29.15, 40.5, 1.0, 2.0, 0.2916470678733095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 469016.0463452892, 469016.0463452886, 164891.3695147251], 
processed observation next is [0.0, 0.5217391304347826, 0.5805687203791469, 0.405, 1.0, 1.0, 0.14656273237748135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13028223509591366, 0.1302822350959135, 0.2461065216637688], 
reward next is 0.7539, 
noisyNet noise sample is [array([-0.3102836], dtype=float32), -0.37705976]. 
=============================================
[2019-03-26 17:30:19,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0003669e-25 1.0000000e+00 2.5513331e-28 5.7693046e-31 5.3107639e-36], sum to 1.0000
[2019-03-26 17:30:19,842] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2146
[2019-03-26 17:30:19,847] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 90.5, 1.0, 2.0, 0.6809257936400074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 951601.2546873514, 951601.2546873514, 216780.1846437203], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6587400.0000, 
sim time next is 6588000.0000, 
raw observation next is [26.1, 90.0, 1.0, 2.0, 0.6755937162824901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 944146.3058865666, 944146.3058865673, 215663.5895416749], 
processed observation next is [1.0, 0.2608695652173913, 0.4360189573459717, 0.9, 1.0, 1.0, 0.6091490557620363, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26226286274626853, 0.2622628627462687, 0.3218859545398133], 
reward next is 0.6781, 
noisyNet noise sample is [array([0.48526528], dtype=float32), 0.6471849]. 
=============================================
[2019-03-26 17:30:19,859] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.489998]
 [63.212208]
 [62.863247]
 [63.126587]
 [63.98102 ]], R is [[63.71879578]
 [63.75805664]
 [63.79003143]
 [63.80445862]
 [63.81225586]].
[2019-03-26 17:30:24,794] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.9523011e-21 1.0000000e+00 5.2935233e-24 6.5199437e-24 1.7853741e-30], sum to 1.0000
[2019-03-26 17:30:24,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5811
[2019-03-26 17:30:24,807] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 54.0, 1.0, 2.0, 0.9205375371748775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1427949.057023887, 1427949.057023887, 295253.8556154072], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6778800.0000, 
sim time next is 6779400.0000, 
raw observation next is [28.08333333333334, 53.5, 1.0, 2.0, 0.8869597601751618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1375976.908876777, 1375976.908876778, 284938.1606865572], 
processed observation next is [1.0, 0.4782608695652174, 0.53001579778831, 0.535, 1.0, 1.0, 0.8638069399700744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38221580802132693, 0.38221580802132726, 0.42528083684560775], 
reward next is 0.5747, 
noisyNet noise sample is [array([-0.08492251], dtype=float32), 0.923159]. 
=============================================
[2019-03-26 17:30:41,318] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7295917e-09 9.8536265e-01 3.8790729e-16 1.4637345e-02 3.1770860e-18], sum to 1.0000
[2019-03-26 17:30:41,325] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4272
[2019-03-26 17:30:41,333] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1816663.917968771 W.
[2019-03-26 17:30:41,343] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.43333333333334, 54.83333333333333, 1.0, 2.0, 0.649166143449925, 1.0, 2.0, 0.649166143449925, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1816663.917968771, 1816663.917968771, 353293.2212548333], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7037400.0000, 
sim time next is 7038000.0000, 
raw observation next is [30.6, 54.0, 1.0, 2.0, 0.4585729474085664, 1.0, 2.0, 0.4585729474085664, 1.0, 1.0, 0.7655934962536, 6.9112, 6.9112, 170.5573041426782, 1923445.037121733, 1923445.037121733, 382465.5826331911], 
processed observation next is [1.0, 0.4782608695652174, 0.6492890995260664, 0.54, 1.0, 1.0, 0.3476782498898391, 1.0, 1.0, 0.3476782498898391, 1.0, 0.5, 0.7141384100653658, 0.0, 0.0, 0.8375144448122397, 0.5342902880893703, 0.5342902880893703, 0.5708441531838673], 
reward next is 0.4292, 
noisyNet noise sample is [array([1.4291477], dtype=float32), 0.8176752]. 
=============================================
[2019-03-26 17:30:41,360] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[52.10355 ]
 [50.707985]
 [50.28978 ]
 [51.611794]
 [50.74667 ]], R is [[50.77160263]
 [50.73658371]
 [50.69896698]
 [50.62390518]
 [50.3547821 ]].
[2019-03-26 17:30:45,277] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 17:30:45,280] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:30:45,282] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:45,283] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:30:45,284] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:30:45,285] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:30:45,286] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:45,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:30:45,287] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:45,286] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:45,289] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:30:45,324] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run68
[2019-03-26 17:30:45,350] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run68
[2019-03-26 17:30:45,384] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run68
[2019-03-26 17:30:45,405] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run68
[2019-03-26 17:30:45,427] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run68
[2019-03-26 17:31:02,352] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00883425], dtype=float32), 0.099886626]
[2019-03-26 17:31:02,353] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.16666666666667, 91.33333333333334, 1.0, 2.0, 0.338083751641006, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536461.4741244041, 536461.4741244034, 169866.1182775708]
[2019-03-26 17:31:02,355] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:31:02,359] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.09582887e-29 1.00000000e+00 3.75178136e-31 1.18887256e-35
 4.49194042e-38], sampled 0.7831930876260987
[2019-03-26 17:31:25,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00883425], dtype=float32), 0.099886626]
[2019-03-26 17:31:25,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.82051692, 87.3513677, 1.0, 2.0, 0.4320918748663432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628321.4031479091, 628321.4031479085, 176786.9603823155]
[2019-03-26 17:31:25,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:31:25,096] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1382035e-29 1.0000000e+00 3.0729035e-31 4.1736216e-36 3.7227279e-38], sampled 0.6590268265821011
[2019-03-26 17:32:03,577] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00883425], dtype=float32), 0.099886626]
[2019-03-26 17:32:03,577] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.76666666666667, 84.0, 1.0, 2.0, 0.6237279568047518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 871633.8498768875, 871633.8498768875, 205249.0081515096]
[2019-03-26 17:32:03,579] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:32:03,583] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3761134e-23 1.0000000e+00 3.9912306e-27 2.1057123e-26 2.4067819e-33], sampled 0.465398813335995
[2019-03-26 17:32:12,155] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00883425], dtype=float32), 0.099886626]
[2019-03-26 17:32:12,156] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.85, 88.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.231639772079443, 6.9112, 168.9107295504362, 1681238.629090167, 1453910.623238727, 311352.5190011209]
[2019-03-26 17:32:12,157] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:32:12,161] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.6474032e-18 1.0000000e+00 1.5876724e-22 2.6797421e-17 1.3165253e-26], sampled 0.9914648589762243
[2019-03-26 17:32:12,162] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1681238.629090167 W.
[2019-03-26 17:32:42,816] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8518.7691 2840537263.6830 1075.0000
[2019-03-26 17:32:42,865] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7973.4112 3155908540.2957 1571.0000
[2019-03-26 17:32:42,955] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8276.7581 2925720886.9610 1291.0000
[2019-03-26 17:32:43,132] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8031.0793 3004394245.7352 1685.0000
[2019-03-26 17:32:43,144] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8672.3905 2778305653.5653 906.0000
[2019-03-26 17:32:44,160] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1675000, evaluation results [1675000.0, 7973.411175247244, 3155908540.2956505, 1571.0, 8276.758114944916, 2925720886.9610286, 1291.0, 8672.390470238288, 2778305653.565342, 906.0, 8031.079332876738, 3004394245.735167, 1685.0, 8518.769072758505, 2840537263.683041, 1075.0]
[2019-03-26 17:32:45,973] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.8798244e-29 1.0000000e+00 1.0072973e-30 2.4283619e-33 7.4259052e-37], sum to 1.0000
[2019-03-26 17:32:45,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1087
[2019-03-26 17:32:45,989] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 75.66666666666667, 1.0, 2.0, 0.4192357920482003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608953.8282641704, 608953.8282641704, 174894.0318396651], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7489200.0000, 
sim time next is 7489800.0000, 
raw observation next is [26.4, 75.5, 1.0, 2.0, 0.4208928791457533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610439.0602725557, 610439.0602725557, 175008.0735928292], 
processed observation next is [0.0, 0.6956521739130435, 0.45023696682464454, 0.755, 1.0, 1.0, 0.3022805772840402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16956640563126546, 0.16956640563126546, 0.2612060799892973], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.63063556], dtype=float32), -0.7987691]. 
=============================================
[2019-03-26 17:32:54,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7557593e-10 9.9996400e-01 9.6488177e-17 3.6022328e-05 5.9648108e-19], sum to 1.0000
[2019-03-26 17:32:54,583] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7143
[2019-03-26 17:32:54,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1935243.513421241 W.
[2019-03-26 17:32:54,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.41666666666667, 74.0, 1.0, 2.0, 0.7429576920728066, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.98873016061588, 6.9112, 168.9124955442264, 1935243.513421241, 1880241.099201034, 394881.6110709689], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7211400.0000, 
sim time next is 7212000.0000, 
raw observation next is [29.33333333333334, 75.0, 1.0, 2.0, 0.7308735691771677, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988911545173915, 6.9112, 168.9124309366858, 1918332.725737019, 1863201.652506897, 392122.6725769881], 
processed observation next is [1.0, 0.4782608695652174, 0.5892575039494474, 0.75, 1.0, 1.0, 0.6757512881652623, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007771154517391477, 0.0, 0.8294373643446051, 0.5328702015936164, 0.5175560145852491, 0.5852577202641613], 
reward next is 0.0262, 
noisyNet noise sample is [array([0.99178183], dtype=float32), 1.4652381]. 
=============================================
[2019-03-26 17:32:54,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[50.040928]
 [50.612236]
 [48.88498 ]
 [47.796543]
 [47.202465]], R is [[50.46762848]
 [49.98592377]
 [49.96710587]
 [49.94430161]
 [49.89415741]].
[2019-03-26 17:32:57,160] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9969248e-29 1.0000000e+00 2.7041218e-31 7.0791013e-35 2.1131508e-38], sum to 1.0000
[2019-03-26 17:32:57,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3255
[2019-03-26 17:32:57,175] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333333, 89.66666666666667, 1.0, 2.0, 0.3310579444283711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522246.5324323068, 522246.5324323062, 168702.9998408542], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7270800.0000, 
sim time next is 7271400.0000, 
raw observation next is [21.61666666666667, 89.83333333333333, 1.0, 2.0, 0.3282927001426869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517834.9143904585, 517834.9143904591, 168359.0085167426], 
processed observation next is [1.0, 0.13043478260869565, 0.22353870458135885, 0.8983333333333333, 1.0, 1.0, 0.1907140965574541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14384303177512736, 0.14384303177512753, 0.2512821022637949], 
reward next is 0.7487, 
noisyNet noise sample is [array([0.25949383], dtype=float32), -1.8271846]. 
=============================================
[2019-03-26 17:32:59,239] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.3611120e-25 1.0000000e+00 1.1849563e-27 2.9135456e-29 2.4435538e-34], sum to 1.0000
[2019-03-26 17:32:59,247] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6350
[2019-03-26 17:32:59,251] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 76.0, 1.0, 2.0, 0.6569810501595487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020581.07467465, 1020581.07467465, 224321.9139956906], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7291200.0000, 
sim time next is 7291800.0000, 
raw observation next is [24.35, 75.0, 1.0, 2.0, 0.6882301421210009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067253.913742923, 1067253.913742923, 231366.6282060146], 
processed observation next is [1.0, 0.391304347826087, 0.35308056872037924, 0.75, 1.0, 1.0, 0.6243736652060251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29645942048414525, 0.29645942048414525, 0.3453233256806188], 
reward next is 0.6547, 
noisyNet noise sample is [array([0.08830605], dtype=float32), -0.8913042]. 
=============================================
[2019-03-26 17:33:00,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7015766e-25 1.0000000e+00 1.9707440e-27 5.5871161e-29 6.3112673e-34], sum to 1.0000
[2019-03-26 17:33:00,483] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0768
[2019-03-26 17:33:00,488] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666666, 74.0, 1.0, 2.0, 0.7306945428776342, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1131166.859759534, 1131166.859759534, 241497.8793449228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7292400.0000, 
sim time next is 7293000.0000, 
raw observation next is [24.78333333333333, 73.0, 1.0, 2.0, 0.7518275171007635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161936.169716239, 1161936.169716239, 246643.2278884322], 
processed observation next is [1.0, 0.391304347826087, 0.37361769352290675, 0.73, 1.0, 1.0, 0.7009970085551367, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32276004714339973, 0.32276004714339973, 0.36812422072900325], 
reward next is 0.6319, 
noisyNet noise sample is [array([1.4452491], dtype=float32), -0.0370197]. 
=============================================
[2019-03-26 17:33:00,505] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.4854 ]
 [67.28183]
 [67.92141]
 [68.47169]
 [68.64354]], R is [[65.81465149]
 [65.79606628]
 [65.79278564]
 [65.80004883]
 [65.81950378]].
[2019-03-26 17:33:02,234] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5936118e-26 1.0000000e+00 3.3164107e-30 5.7170997e-30 4.3878889e-36], sum to 1.0000
[2019-03-26 17:33:02,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3246
[2019-03-26 17:33:02,250] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333334, 93.66666666666667, 1.0, 2.0, 0.3173719816561104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500730.4681504198, 500730.4681504204, 167056.7677478002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431000.0000, 
sim time next is 7431600.0000, 
raw observation next is [21.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3177128470433545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501348.4929683455, 501348.4929683455, 167104.9131622994], 
processed observation next is [0.0, 0.0, 0.2022116903633494, 0.9333333333333335, 1.0, 1.0, 0.177967285594403, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13926347026898486, 0.13926347026898486, 0.2494103181526857], 
reward next is 0.7506, 
noisyNet noise sample is [array([-0.25605664], dtype=float32), 0.36741218]. 
=============================================
[2019-03-26 17:33:03,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:03,041] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:03,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run9
[2019-03-26 17:33:04,211] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.0956637e-20 1.0000000e+00 2.4430630e-24 4.9636914e-23 1.1719545e-29], sum to 1.0000
[2019-03-26 17:33:04,218] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8936
[2019-03-26 17:33:04,223] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2418050.347225101 W.
[2019-03-26 17:33:04,228] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 80.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.269608184639154, 6.9112, 168.9052210898378, 2418050.347225101, 1454392.961246871, 310956.4473081857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7806600.0000, 
sim time next is 7807200.0000, 
raw observation next is [28.1, 80.0, 1.0, 2.0, 0.776263863722995, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.981816094499994, 6.9112, 168.9114298610583, 1981854.312202973, 1931757.277131543, 402929.0767082038], 
processed observation next is [1.0, 0.34782608695652173, 0.5308056872037916, 0.8, 1.0, 1.0, 0.7304383900277048, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007061609449999384, 0.0, 0.8294324486049797, 0.550515086723048, 0.5365992436476509, 0.6013866816540355], 
reward next is 0.0455, 
noisyNet noise sample is [array([-0.13068393], dtype=float32), -1.4344273]. 
=============================================
[2019-03-26 17:33:07,864] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.5180619e-29 1.0000000e+00 3.7594030e-31 1.7839876e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:33:07,872] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3328
[2019-03-26 17:33:07,876] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666666, 90.83333333333334, 1.0, 2.0, 0.3804741892488303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 571961.4395648274, 571961.4395648274, 172124.7326947786], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7531800.0000, 
sim time next is 7532400.0000, 
raw observation next is [23.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3780343696340843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569319.488506724, 569319.4885067233, 171924.0297224739], 
processed observation next is [0.0, 0.17391304347826086, 0.29541864139020524, 0.9066666666666667, 1.0, 1.0, 0.25064381883624615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15814430236297888, 0.1581443023629787, 0.25660302943652824], 
reward next is 0.7434, 
noisyNet noise sample is [array([1.1696149], dtype=float32), 0.7714839]. 
=============================================
[2019-03-26 17:33:07,901] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.57770948e-29 1.00000000e+00 3.52049508e-31 1.08969804e-35
 0.00000000e+00], sum to 1.0000
[2019-03-26 17:33:07,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0684
[2019-03-26 17:33:07,917] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3780343696340843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 569319.488506724, 569319.4885067233, 171924.0297224739], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7532400.0000, 
sim time next is 7533000.0000, 
raw observation next is [23.1, 90.5, 1.0, 2.0, 0.3755939519671112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 566659.9541613702, 566659.9541613702, 171722.8529146654], 
processed observation next is [0.0, 0.17391304347826086, 0.2938388625592418, 0.905, 1.0, 1.0, 0.24770355658688098, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15740554282260283, 0.15740554282260283, 0.2563027655442767], 
reward next is 0.7437, 
noisyNet noise sample is [array([1.1696149], dtype=float32), 0.7714839]. 
=============================================
[2019-03-26 17:33:07,933] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.4427 ]
 [73.53467]
 [73.53774]
 [73.59738]
 [73.72726]], R is [[73.37501526]
 [73.38466644]
 [73.39391327]
 [73.40283203]
 [73.41151428]].
[2019-03-26 17:33:08,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.8136957e-24 1.0000000e+00 2.1749409e-28 8.3234811e-28 2.2234726e-34], sum to 1.0000
[2019-03-26 17:33:08,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0611
[2019-03-26 17:33:08,170] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.6, 93.0, 1.0, 2.0, 0.4084714586318052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599274.7086393032, 599274.7086393038, 174167.2460016372], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7516800.0000, 
sim time next is 7517400.0000, 
raw observation next is [23.58333333333334, 93.0, 1.0, 2.0, 0.4085312912341218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599467.876503546, 599467.8765035466, 174188.4731945665], 
processed observation next is [0.0, 0.0, 0.31674565560821516, 0.93, 1.0, 1.0, 0.2873870978724359, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16651885458431834, 0.1665188545843185, 0.2599827958127858], 
reward next is 0.7400, 
noisyNet noise sample is [array([1.3698814], dtype=float32), -0.5814652]. 
=============================================
[2019-03-26 17:33:09,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0798574e-28 1.0000000e+00 1.2883823e-30 5.8687365e-35 1.4133022e-36], sum to 1.0000
[2019-03-26 17:33:09,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2668
[2019-03-26 17:33:09,400] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 91.0, 1.0, 2.0, 0.3575150991065352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 546297.0502730453, 546297.050273046, 170204.3564429357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7465200.0000, 
sim time next is 7465800.0000, 
raw observation next is [22.78333333333333, 90.5, 1.0, 2.0, 0.3589739889621958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547644.7454565306, 547644.7454565306, 170289.4345128814], 
processed observation next is [0.0, 0.391304347826087, 0.27883096366508686, 0.905, 1.0, 1.0, 0.22767950477372986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15212354040459183, 0.15212354040459183, 0.2541633350938528], 
reward next is 0.7458, 
noisyNet noise sample is [array([1.0185326], dtype=float32), -0.23500584]. 
=============================================
[2019-03-26 17:33:14,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:14,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:14,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run9
[2019-03-26 17:33:19,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5270505e-08 3.3263150e-01 2.8922342e-15 6.6736853e-01 6.6882085e-17], sum to 1.0000
[2019-03-26 17:33:19,738] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3228
[2019-03-26 17:33:19,747] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2042230.610148566 W.
[2019-03-26 17:33:19,754] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.73333333333333, 60.0, 1.0, 2.0, 0.7302988827052546, 1.0, 2.0, 0.7302988827052546, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2042230.610148566, 2042230.610148566, 387355.0526688889], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7654800.0000, 
sim time next is 7655400.0000, 
raw observation next is [30.6, 61.0, 1.0, 2.0, 0.8654728396098879, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.969833527590444, 6.9112, 168.9126074053623, 2106709.135117817, 2065112.578605777, 425864.3136464588], 
processed observation next is [1.0, 0.6086956521739131, 0.6492890995260664, 0.61, 1.0, 1.0, 0.8379190838673347, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.005863352759044371, 0.0, 0.8294382308865944, 0.5851969819771714, 0.5736423829460492, 0.6356183785768041], 
reward next is 0.0712, 
noisyNet noise sample is [array([0.3678486], dtype=float32), -0.33595738]. 
=============================================
[2019-03-26 17:33:22,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:22,458] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:22,532] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run9
[2019-03-26 17:33:22,947] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:22,948] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:23,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run9
[2019-03-26 17:33:26,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:26,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:26,731] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run9
[2019-03-26 17:33:28,495] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:28,496] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:28,609] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run9
[2019-03-26 17:33:29,187] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4914340e-23 1.0000000e+00 4.7712318e-27 5.0097622e-24 3.3325496e-33], sum to 1.0000
[2019-03-26 17:33:29,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0015
[2019-03-26 17:33:29,197] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.31666666666667, 88.66666666666667, 1.0, 2.0, 0.5071788152856568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708706.9412628271, 708706.9412628271, 184728.6671675867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7861800.0000, 
sim time next is 7862400.0000, 
raw observation next is [26.3, 89.0, 1.0, 2.0, 0.5071408397273727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708653.8583693281, 708653.8583693281, 184722.7078784022], 
processed observation next is [1.0, 0.0, 0.4454976303317536, 0.89, 1.0, 1.0, 0.40619378280406343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19684829399148002, 0.19684829399148002, 0.27570553414686894], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.36712873], dtype=float32), 1.9562236]. 
=============================================
[2019-03-26 17:33:30,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3802854e-19 1.0000000e+00 1.9368795e-25 3.8761045e-17 8.1190684e-30], sum to 1.0000
[2019-03-26 17:33:30,377] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3335
[2019-03-26 17:33:30,385] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 65.0, 1.0, 2.0, 0.4647914170593566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649458.752257823, 649458.7522578236, 178266.1113256522], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7925400.0000, 
sim time next is 7926000.0000, 
raw observation next is [30.13333333333333, 66.0, 1.0, 2.0, 0.4748563033345679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663526.933567307, 663526.9335673077, 179752.5839570643], 
processed observation next is [1.0, 0.7391304347826086, 0.6271721958925749, 0.66, 1.0, 1.0, 0.3672967510055035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1843130371020297, 0.1843130371020299, 0.268287438741887], 
reward next is 0.7317, 
noisyNet noise sample is [array([-0.15139851], dtype=float32), -1.7938465]. 
=============================================
[2019-03-26 17:33:30,411] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.572014]
 [67.64981 ]
 [61.09789 ]
 [54.937965]
 [54.201225]], R is [[74.34629059]
 [74.33676147]
 [73.59339142]
 [73.44285583]
 [73.11854553]].
[2019-03-26 17:33:30,444] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:30,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:30,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run9
[2019-03-26 17:33:31,705] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:31,706] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:31,783] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run9
[2019-03-26 17:33:32,477] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:32,477] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:32,544] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run9
[2019-03-26 17:33:34,247] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:34,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:34,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run9
[2019-03-26 17:33:34,490] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:34,494] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:34,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run9
[2019-03-26 17:33:35,084] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:35,085] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:35,135] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run9
[2019-03-26 17:33:35,199] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:35,200] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:35,253] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run9
[2019-03-26 17:33:35,405] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:35,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:35,453] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run9
[2019-03-26 17:33:35,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:35,483] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:35,530] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run9
[2019-03-26 17:33:36,030] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:33:36,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run9
[2019-03-26 17:33:36,670] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 17:33:36,671] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:33:36,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,672] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:33:36,674] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:33:36,674] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:33:36,679] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,676] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:33:36,680] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,681] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,681] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:33:36,692] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run69
[2019-03-26 17:33:36,712] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run69
[2019-03-26 17:33:36,731] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run69
[2019-03-26 17:33:36,732] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run69
[2019-03-26 17:33:36,781] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run69
[2019-03-26 17:33:39,884] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:33:39,886] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.85, 54.66666666666666, 1.0, 2.0, 0.2050607840481767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 343013.7744612553, 343013.7744612547, 155540.862906336]
[2019-03-26 17:33:39,887] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:33:39,895] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4599022e-26 1.0000000e+00 3.9403356e-29 7.6790402e-29 3.1065828e-35], sampled 0.6061039589583914
[2019-03-26 17:33:39,979] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:33:39,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.840409835, 93.94808416000001, 1.0, 2.0, 0.2951908062369136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478401.6470086155, 478401.6470086149, 165521.4455651874]
[2019-03-26 17:33:39,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:33:39,982] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0851075e-25 1.0000000e+00 4.2669923e-29 4.6304537e-28 3.0549680e-35], sampled 0.10589374275822716
[2019-03-26 17:33:42,841] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:33:42,842] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.4, 65.83333333333333, 1.0, 2.0, 0.2252356539659053, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 374415.0823425769, 374415.0823425762, 158244.3082544917]
[2019-03-26 17:33:42,844] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:33:42,847] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0059213e-26 1.0000000e+00 3.6327225e-29 7.5818794e-29 2.9292501e-35], sampled 0.9980747277627817
[2019-03-26 17:33:50,724] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:33:50,726] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.9, 76.5, 1.0, 2.0, 0.2965128329127142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 472918.5376668115, 472918.5376668122, 165130.0208093765]
[2019-03-26 17:33:50,727] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:33:50,729] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8833405e-28 1.0000000e+00 1.4918725e-30 4.2093960e-33 5.5106387e-37], sampled 0.874825979221999
[2019-03-26 17:34:05,902] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:34:05,904] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.56666666666667, 86.33333333333334, 1.0, 2.0, 0.4954060534024404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695947.7705394746, 695947.7705394746, 183354.3104194054]
[2019-03-26 17:34:05,905] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:34:05,908] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4016752e-25 1.0000000e+00 1.4904632e-28 9.5709486e-29 1.1015640e-34], sampled 0.7267551549207671
[2019-03-26 17:34:12,890] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:34:12,892] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.01666666666667, 75.5, 1.0, 2.0, 0.6194639421120884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 910206.7535687527, 910206.7535687527, 210108.8537726798]
[2019-03-26 17:34:12,894] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:34:12,898] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.5622095e-25 1.0000000e+00 9.4158147e-28 4.2279940e-28 8.7649350e-34], sampled 0.2579673793688907
[2019-03-26 17:34:20,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:34:20,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.024675585, 86.81858025, 1.0, 2.0, 0.3684434100108492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562716.000050564, 562716.0000505645, 171590.1135560764]
[2019-03-26 17:34:20,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:34:20,732] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.5570277e-27 1.0000000e+00 1.1162410e-29 2.0736791e-30 6.0118267e-36], sampled 0.5271205121507458
[2019-03-26 17:34:31,395] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:34:31,395] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.43333333333334, 71.0, 1.0, 2.0, 0.5960773188320659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 832978.0823636448, 832978.0823636455, 200017.029191647]
[2019-03-26 17:34:31,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:34:31,399] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.4188122e-25 1.0000000e+00 5.5950504e-29 6.7239193e-28 2.5363122e-35], sampled 0.5160382694597779
[2019-03-26 17:35:16,216] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:35:16,217] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.03333333333333, 73.0, 1.0, 2.0, 0.66921834193147, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978613412835262, 6.9112, 168.9125004634724, 1832055.234268899, 1784229.968136421, 379086.3398500137]
[2019-03-26 17:35:16,218] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:35:16,220] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1126248e-11 9.9994850e-01 7.4837487e-18 5.1502000e-05 5.1159822e-20], sampled 0.1001975042927814
[2019-03-26 17:35:16,222] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1832055.234268899 W.
[2019-03-26 17:35:20,306] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01159363], dtype=float32), 0.10769134]
[2019-03-26 17:35:20,307] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.6574294, 50.16973933, 1.0, 2.0, 0.360703231411869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558007.9323391584, 558007.9323391584, 171380.4391995308]
[2019-03-26 17:35:20,307] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:35:20,309] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7647749e-27 1.0000000e+00 7.0843874e-30 1.2124026e-30 4.9063731e-36], sampled 0.8249858413120484
[2019-03-26 17:35:33,797] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8305.8356 2923148830.2205 1229.0000
[2019-03-26 17:35:34,127] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8688.3196 2777048293.7334 874.0000
[2019-03-26 17:35:34,193] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8040.4340 3149924300.1397 1402.0000
[2019-03-26 17:35:34,214] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8098.6424 2998255131.9361 1529.0000
[2019-03-26 17:35:34,267] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8543.7251 2837838696.4111 1008.0000
[2019-03-26 17:35:35,285] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1700000, evaluation results [1700000.0, 8040.433951211964, 3149924300.139708, 1402.0, 8305.835563850243, 2923148830.2204714, 1229.0, 8688.319590636247, 2777048293.7334366, 874.0, 8098.64237124233, 2998255131.936118, 1529.0, 8543.725145714021, 2837838696.411059, 1008.0]
[2019-03-26 17:35:57,464] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5104701e-25 1.0000000e+00 2.2823984e-28 1.2275888e-29 2.1840465e-34], sum to 1.0000
[2019-03-26 17:35:57,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6981
[2019-03-26 17:35:57,480] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 78.0, 1.0, 2.0, 0.3832612156722808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 624262.9154209254, 624262.915420926, 176952.8392955865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 378000.0000, 
sim time next is 378600.0000, 
raw observation next is [21.56666666666667, 77.5, 1.0, 2.0, 0.4451912335440866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725006.8517060048, 725006.8517060041, 186307.5833496577], 
processed observation next is [1.0, 0.391304347826087, 0.22116903633491333, 0.775, 1.0, 1.0, 0.3315557030651646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20139079214055688, 0.2013907921405567, 0.2780710199248623], 
reward next is 0.7219, 
noisyNet noise sample is [array([-0.17874868], dtype=float32), 0.5839108]. 
=============================================
[2019-03-26 17:35:59,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5831539e-23 1.0000000e+00 5.1926149e-27 2.7361305e-25 8.2058968e-33], sum to 1.0000
[2019-03-26 17:35:59,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7236
[2019-03-26 17:35:59,204] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666666, 81.33333333333334, 1.0, 2.0, 0.2887871776284492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 465252.1205791599, 465252.1205791593, 164632.2609034044], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 409200.0000, 
sim time next is 409800.0000, 
raw observation next is [21.58333333333334, 81.16666666666666, 1.0, 2.0, 0.285048506549507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 460102.2410224798, 460102.2410224804, 164278.6277934112], 
processed observation next is [1.0, 0.7391304347826086, 0.22195892575039528, 0.8116666666666665, 1.0, 1.0, 0.1386126584933819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12780617806179995, 0.1278061780618001, 0.24519198178121074], 
reward next is 0.7548, 
noisyNet noise sample is [array([0.9132883], dtype=float32), -0.43359637]. 
=============================================
[2019-03-26 17:36:09,482] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4586613e-25 1.0000000e+00 6.5507161e-29 5.5363518e-27 3.9115694e-35], sum to 1.0000
[2019-03-26 17:36:09,492] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3214
[2019-03-26 17:36:09,499] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 70.33333333333334, 1.0, 2.0, 0.2457068401454845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 404915.7620557561, 404915.7620557561, 160467.7599854153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 674400.0000, 
sim time next is 675000.0000, 
raw observation next is [21.45, 71.5, 1.0, 2.0, 0.2442429345325114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402702.5802681952, 402702.5802681945, 160319.3379870274], 
processed observation next is [1.0, 0.8260869565217391, 0.2156398104265403, 0.715, 1.0, 1.0, 0.08944931871386913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11186182785227644, 0.11186182785227625, 0.23928259401048865], 
reward next is 0.7607, 
noisyNet noise sample is [array([0.23011094], dtype=float32), -1.4364942]. 
=============================================
[2019-03-26 17:36:09,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.77014 ]
 [77.74289 ]
 [77.758026]
 [77.7068  ]
 [77.72655 ]], R is [[77.75315094]
 [77.7361145 ]
 [77.71898651]
 [77.70188904]
 [77.68502045]].
[2019-03-26 17:36:20,165] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8647771e-24 1.0000000e+00 4.7243033e-28 8.9627972e-27 1.4427580e-33], sum to 1.0000
[2019-03-26 17:36:20,175] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6339
[2019-03-26 17:36:20,182] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 60.5, 1.0, 2.0, 0.2436747180262885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402194.8189099152, 402194.8189099146, 160246.7239985138], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 756600.0000, 
sim time next is 757200.0000, 
raw observation next is [22.9, 62.0, 1.0, 2.0, 0.2448529244925271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403930.1500833399, 403930.1500833393, 160369.7330999935], 
processed observation next is [1.0, 0.782608695652174, 0.2843601895734597, 0.62, 1.0, 1.0, 0.09018424637653867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11220281946759442, 0.11220281946759425, 0.23935781059700523], 
reward next is 0.7606, 
noisyNet noise sample is [array([0.78647304], dtype=float32), 1.5710996]. 
=============================================
[2019-03-26 17:36:21,131] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.8192401e-23 1.0000000e+00 5.5137131e-28 1.1073791e-25 1.2687204e-33], sum to 1.0000
[2019-03-26 17:36:21,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8899
[2019-03-26 17:36:21,144] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.73333333333333, 87.0, 1.0, 2.0, 0.2569188624737023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 421992.8074784896, 421992.807478489, 161600.1278023405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 772800.0000, 
sim time next is 773400.0000, 
raw observation next is [19.66666666666667, 87.5, 1.0, 2.0, 0.2563921792308387, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421159.7838542316, 421159.7838542322, 161546.9231726904], 
processed observation next is [1.0, 0.9565217391304348, 0.1311216429699845, 0.875, 1.0, 1.0, 0.10408696292872129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11698882884839766, 0.11698882884839784, 0.24111481070550808], 
reward next is 0.7589, 
noisyNet noise sample is [array([-1.3590726], dtype=float32), -0.22056739]. 
=============================================
[2019-03-26 17:36:21,849] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.5393626e-27 1.0000000e+00 2.3870916e-29 1.5404463e-29 3.6581318e-35], sum to 1.0000
[2019-03-26 17:36:21,857] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4171
[2019-03-26 17:36:21,861] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.1, 73.0, 1.0, 2.0, 0.3160070917888493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 496657.4922854217, 496657.4922854217, 166706.1415441102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 924000.0000, 
sim time next is 924600.0000, 
raw observation next is [24.05, 73.5, 1.0, 2.0, 0.3166512713863182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497365.1924567967, 497365.1924567967, 166751.2736341544], 
processed observation next is [0.0, 0.6956521739130435, 0.3388625592417062, 0.735, 1.0, 1.0, 0.17668827877869664, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13815699790466576, 0.13815699790466576, 0.24888249796142448], 
reward next is 0.7511, 
noisyNet noise sample is [array([1.4832295], dtype=float32), 0.7380862]. 
=============================================
[2019-03-26 17:36:25,107] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.5456451e-23 1.0000000e+00 3.9432268e-27 1.5566640e-26 5.2550504e-33], sum to 1.0000
[2019-03-26 17:36:25,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4366
[2019-03-26 17:36:25,121] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.23333333333333, 89.0, 1.0, 2.0, 0.2982847161562726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 475532.2353180773, 475532.2353180779, 165311.6454479684], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 868800.0000, 
sim time next is 869400.0000, 
raw observation next is [21.2, 89.0, 1.0, 2.0, 0.297252464870841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474221.0642466588, 474221.0642466588, 165223.691732129], 
processed observation next is [0.0, 0.043478260869565216, 0.20379146919431282, 0.89, 1.0, 1.0, 0.15331622273595302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13172807340184967, 0.13172807340184967, 0.24660252497332685], 
reward next is 0.7534, 
noisyNet noise sample is [array([-0.64780456], dtype=float32), 0.25218144]. 
=============================================
[2019-03-26 17:36:28,194] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.8066549e-24 1.0000000e+00 9.5159135e-27 6.0039703e-27 8.8104286e-33], sum to 1.0000
[2019-03-26 17:36:28,203] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1457
[2019-03-26 17:36:28,210] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 83.16666666666667, 1.0, 2.0, 0.5932656126963484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 943452.3655298231, 943452.3655298224, 212566.1425890614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1073400.0000, 
sim time next is 1074000.0000, 
raw observation next is [22.2, 82.33333333333334, 1.0, 2.0, 0.5205601970345691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827988.8692706674, 827988.8692706674, 198243.4293223979], 
processed observation next is [1.0, 0.43478260869565216, 0.2511848341232228, 0.8233333333333335, 1.0, 1.0, 0.42236168317417966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22999690813074095, 0.22999690813074095, 0.295885715406564], 
reward next is 0.7041, 
noisyNet noise sample is [array([0.340122], dtype=float32), -0.25839546]. 
=============================================
[2019-03-26 17:36:28,225] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.23528 ]
 [71.201706]
 [71.3945  ]
 [71.2639  ]
 [71.14378 ]], R is [[70.57288361]
 [70.54989624]
 [70.54969788]
 [70.55879974]
 [70.56636047]].
[2019-03-26 17:36:30,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.2182694e-23 1.0000000e+00 2.9394483e-27 1.7853601e-23 7.0461857e-33], sum to 1.0000
[2019-03-26 17:36:30,198] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6976
[2019-03-26 17:36:30,204] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.96666666666667, 97.66666666666666, 1.0, 2.0, 0.3647809916978575, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555219.2460212935, 555219.2460212935, 170890.4417163264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1032000.0000, 
sim time next is 1032600.0000, 
raw observation next is [21.98333333333333, 97.83333333333334, 1.0, 2.0, 0.3643513155949491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553924.9319534462, 553924.9319534457, 170759.8298645259], 
processed observation next is [1.0, 0.9565217391304348, 0.24091627172195884, 0.9783333333333334, 1.0, 1.0, 0.23415821156017963, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15386803665373508, 0.1538680366537349, 0.2548654177082476], 
reward next is 0.7451, 
noisyNet noise sample is [array([0.27135035], dtype=float32), -2.2747288]. 
=============================================
[2019-03-26 17:36:31,101] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 17:36:31,106] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:36:31,107] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:36:31,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:31,109] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:36:31,110] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:36:31,113] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:31,109] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:36:31,112] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:31,110] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:31,115] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:36:31,146] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run70
[2019-03-26 17:36:31,173] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run70
[2019-03-26 17:36:31,174] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run70
[2019-03-26 17:36:31,217] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run70
[2019-03-26 17:36:31,241] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run70
[2019-03-26 17:36:52,900] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:36:52,901] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [17.86666666666667, 89.66666666666666, 1.0, 2.0, 0.2221406480368135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 370252.829616319, 370252.829616319, 157729.4044251519]
[2019-03-26 17:36:52,904] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:36:52,910] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.9979033e-27 1.0000000e+00 2.4716190e-29 6.2156822e-31 1.4435933e-35], sampled 0.6993938673993895
[2019-03-26 17:37:11,799] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:37:11,801] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.36666666666667, 85.83333333333334, 1.0, 2.0, 0.5088106574395467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710987.9610119676, 710987.961011967, 184987.2946880446]
[2019-03-26 17:37:11,802] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:37:11,804] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.95076547e-27 1.00000000e+00 2.06541437e-29 1.38836709e-31
 1.17089626e-35], sampled 0.9020941054263578
[2019-03-26 17:37:27,100] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:37:27,100] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.7355581, 74.44508158333333, 1.0, 2.0, 0.7792720332450862, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.950939988014524, 6.9112, 168.9127180942301, 1998049.447949308, 1969856.572500533, 405984.5313971639]
[2019-03-26 17:37:27,101] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:37:27,104] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.7857061e-12 9.9999988e-01 1.6335077e-16 1.0241285e-07 6.5701405e-20], sampled 0.9959177005902814
[2019-03-26 17:37:27,105] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1998049.447949308 W.
[2019-03-26 17:37:41,072] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:37:41,074] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.03970679, 90.54754426666668, 1.0, 2.0, 0.4789232102645088, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 672598.012776305, 672598.0127763057, 180796.2182928893]
[2019-03-26 17:37:41,074] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:37:41,079] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.9631934e-25 1.0000000e+00 1.5408525e-28 3.1830940e-27 1.0706580e-34], sampled 0.8255568877393049
[2019-03-26 17:38:17,862] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:38:17,862] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.5, 72.0, 1.0, 2.0, 0.5602465382635088, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9729629606023222, 6.9112, 6.9112, 168.9129328481322, 1566354.490495886, 1566354.490495886, 342771.3023379163]
[2019-03-26 17:38:17,863] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:38:17,866] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1422064e-13 9.9984312e-01 1.6896689e-21 1.5686864e-04 4.6850632e-23], sampled 0.2521146248905669
[2019-03-26 17:38:23,919] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00816343], dtype=float32), 0.107486546]
[2019-03-26 17:38:23,920] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.36666666666667, 54.00000000000001, 1.0, 2.0, 1.014079422604637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1417497.882726586, 1417497.882726587, 303249.9918725874]
[2019-03-26 17:38:23,922] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:38:23,923] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7076271e-19 1.0000000e+00 1.3673591e-23 2.4269359e-18 1.6617682e-28], sampled 0.16703547629403315
[2019-03-26 17:38:28,193] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8312.8100 2922267461.4637 1210.0000
[2019-03-26 17:38:28,485] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8047.5772 3149134360.8215 1379.0000
[2019-03-26 17:38:28,517] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8551.5542 2837229843.4362 991.0000
[2019-03-26 17:38:28,539] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8692.2242 2776534539.8061 862.0000
[2019-03-26 17:38:28,687] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8109.3004 2997282537.1083 1504.0000
[2019-03-26 17:38:29,706] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1725000, evaluation results [1725000.0, 8047.577155736751, 3149134360.8214536, 1379.0, 8312.809950929319, 2922267461.4637322, 1210.0, 8692.224181316253, 2776534539.806121, 862.0, 8109.300398248219, 2997282537.1083207, 1504.0, 8551.554235922584, 2837229843.4361897, 991.0]
[2019-03-26 17:38:33,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0194684e-21 1.0000000e+00 3.9525678e-25 9.2496289e-21 9.5482566e-31], sum to 1.0000
[2019-03-26 17:38:33,016] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-26 17:38:33,019] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 88.16666666666667, 1.0, 2.0, 0.3486060157665278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 539487.9497954753, 539487.9497954753, 169845.2876534384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1210200.0000, 
sim time next is 1210800.0000, 
raw observation next is [22.53333333333333, 88.33333333333334, 1.0, 2.0, 0.3474276772837944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537843.0262861188, 537843.0262861188, 169715.7440230381], 
processed observation next is [1.0, 0.0, 0.26698262243285936, 0.8833333333333334, 1.0, 1.0, 0.21376828588408966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.149400840635033, 0.149400840635033, 0.25330708063140017], 
reward next is 0.7467, 
noisyNet noise sample is [array([0.99902284], dtype=float32), 0.27439633]. 
=============================================
[2019-03-26 17:38:36,848] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [6.7088928e-24 1.0000000e+00 1.8074494e-27 1.4131060e-24 1.8935780e-33], sum to 1.0000
[2019-03-26 17:38:36,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6478
[2019-03-26 17:38:36,865] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 73.66666666666667, 1.0, 2.0, 0.3276070559093963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513846.8382420852, 513846.8382420846, 167988.2240346978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1105800.0000, 
sim time next is 1106400.0000, 
raw observation next is [23.93333333333334, 74.33333333333334, 1.0, 2.0, 0.3295784873726749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517333.696293955, 517333.696293955, 168267.787656064], 
processed observation next is [1.0, 0.8260869565217391, 0.3333333333333337, 0.7433333333333334, 1.0, 1.0, 0.1922632377984035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14370380452609863, 0.14370380452609863, 0.25114595172546866], 
reward next is 0.7489, 
noisyNet noise sample is [array([1.3185833], dtype=float32), -0.8459938]. 
=============================================
[2019-03-26 17:38:50,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0462353e-19 1.0000000e+00 4.3193933e-24 1.0027215e-19 1.3355477e-29], sum to 1.0000
[2019-03-26 17:38:50,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6013
[2019-03-26 17:38:50,901] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 85.0, 1.0, 2.0, 0.5474757219086761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822363.5549683154, 822363.5549683154, 198444.5911828252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1601400.0000, 
sim time next is 1602000.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.6383729827092052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 958392.0700820248, 958392.0700820254, 216470.8191801312], 
processed observation next is [1.0, 0.5652173913043478, 0.3364928909952607, 0.85, 1.0, 1.0, 0.5643047984448255, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2662200194672291, 0.2662200194672293, 0.3230907748957182], 
reward next is 0.6769, 
noisyNet noise sample is [array([0.7588417], dtype=float32), -0.54269403]. 
=============================================
[2019-03-26 17:38:50,916] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[69.209404]
 [68.59795 ]
 [67.530075]
 [66.54574 ]
 [65.17936 ]], R is [[68.65348816]
 [68.67076874]
 [68.68551636]
 [68.68344879]
 [68.67321014]].
[2019-03-26 17:39:03,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0269929e-21 1.0000000e+00 4.2190888e-26 3.0844521e-21 8.9958290e-32], sum to 1.0000
[2019-03-26 17:39:03,967] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8912
[2019-03-26 17:39:03,971] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 96.33333333333334, 1.0, 2.0, 0.4605817607332746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 652516.0638483983, 652516.0638483976, 178803.1379552874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1988400.0000, 
sim time next is 1989000.0000, 
raw observation next is [24.1, 96.0, 1.0, 2.0, 0.4614787545987428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653075.4499261105, 653075.4499261105, 178844.1525383143], 
processed observation next is [0.0, 0.0, 0.3412322274881518, 0.96, 1.0, 1.0, 0.35117922240812394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18140984720169734, 0.18140984720169734, 0.26693157095270786], 
reward next is 0.7331, 
noisyNet noise sample is [array([-0.2522906], dtype=float32), -1.2605238]. 
=============================================
[2019-03-26 17:39:03,990] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.75499]
 [74.6668 ]
 [74.80874]
 [75.39791]
 [75.38412]], R is [[74.80934143]
 [74.79438019]
 [74.77978516]
 [74.76567078]
 [74.75213623]].
[2019-03-26 17:39:05,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.0329750e-25 1.0000000e+00 2.6004530e-28 3.4756099e-29 1.7276702e-34], sum to 1.0000
[2019-03-26 17:39:05,300] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9558
[2019-03-26 17:39:05,304] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 92.0, 1.0, 2.0, 0.3940268177230484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589394.8802071229, 589394.8802071229, 173605.6239739308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1839600.0000, 
sim time next is 1840200.0000, 
raw observation next is [23.31666666666667, 91.66666666666667, 1.0, 2.0, 0.4840337286073762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722343.5373102932, 722343.5373102926, 186838.6230784724], 
processed observation next is [1.0, 0.30434782608695654, 0.30410742496050575, 0.9166666666666667, 1.0, 1.0, 0.3783538898884051, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20065098258619254, 0.20065098258619238, 0.27886361653503344], 
reward next is 0.7211, 
noisyNet noise sample is [array([-0.13863596], dtype=float32), -0.65784854]. 
=============================================
[2019-03-26 17:39:07,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6803468e-19 1.0000000e+00 1.8645788e-23 3.2562435e-19 3.0508447e-28], sum to 1.0000
[2019-03-26 17:39:07,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4055
[2019-03-26 17:39:07,288] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 88.0, 1.0, 2.0, 0.8490209401339973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1241531.474424428, 1241531.474424428, 264079.1401714162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1764000.0000, 
sim time next is 1764600.0000, 
raw observation next is [24.21666666666667, 87.00000000000001, 1.0, 2.0, 0.8346412022571453, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1228578.621944959, 1228578.621944959, 261279.0360663521], 
processed observation next is [1.0, 0.43478260869565216, 0.34676145339652464, 0.8700000000000001, 1.0, 1.0, 0.8007725328399341, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3412718394291553, 0.3412718394291553, 0.38996871054679416], 
reward next is 0.6100, 
noisyNet noise sample is [array([0.34331477], dtype=float32), 0.47554228]. 
=============================================
[2019-03-26 17:39:08,554] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0508070e-24 1.0000000e+00 1.1277812e-27 9.6893300e-25 1.4925020e-33], sum to 1.0000
[2019-03-26 17:39:08,562] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6287
[2019-03-26 17:39:08,567] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 99.0, 1.0, 2.0, 0.4658711685958647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671398.7925332873, 671398.7925332873, 181028.0595106483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1652400.0000, 
sim time next is 1653000.0000, 
raw observation next is [23.3, 99.0, 1.0, 2.0, 0.463202052953941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667408.0869076167, 667408.0869076167, 180606.4819490124], 
processed observation next is [1.0, 0.13043478260869565, 0.3033175355450238, 0.99, 1.0, 1.0, 0.3532554854866759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18539113525211576, 0.18539113525211576, 0.26956191335673496], 
reward next is 0.7304, 
noisyNet noise sample is [array([2.6586242], dtype=float32), 0.34296986]. 
=============================================
[2019-03-26 17:39:08,594] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.53175]
 [72.56397]
 [72.6452 ]
 [72.60651]
 [71.98537]], R is [[72.74104309]
 [72.74344635]
 [72.74510956]
 [72.74575806]
 [72.7473526 ]].
[2019-03-26 17:39:10,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.8277570e-24 1.0000000e+00 5.6639221e-28 5.2137735e-27 3.1311765e-34], sum to 1.0000
[2019-03-26 17:39:11,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9469
[2019-03-26 17:39:11,014] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 94.66666666666667, 1.0, 2.0, 0.3638138941523408, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 560595.237147645, 560595.237147645, 171545.0667072892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1824600.0000, 
sim time next is 1825200.0000, 
raw observation next is [21.9, 95.0, 1.0, 2.0, 0.3646920546257617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561563.3696320932, 561563.3696320932, 171617.7061094161], 
processed observation next is [1.0, 0.13043478260869565, 0.23696682464454974, 0.95, 1.0, 1.0, 0.23456874051296592, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15598982489780366, 0.15598982489780366, 0.2561458300140539], 
reward next is 0.7439, 
noisyNet noise sample is [array([-1.2912425], dtype=float32), -0.23474158]. 
=============================================
[2019-03-26 17:39:14,439] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7826537e-21 1.0000000e+00 2.8776970e-25 9.4780439e-22 5.9338513e-31], sum to 1.0000
[2019-03-26 17:39:14,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2012
[2019-03-26 17:39:14,451] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 96.33333333333334, 1.0, 2.0, 0.4605817607332746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 652516.0638483983, 652516.0638483976, 178803.1379552874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1988400.0000, 
sim time next is 1989000.0000, 
raw observation next is [24.1, 96.0, 1.0, 2.0, 0.4614787545987428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653075.4499261105, 653075.4499261105, 178844.1525383143], 
processed observation next is [0.0, 0.0, 0.3412322274881518, 0.96, 1.0, 1.0, 0.35117922240812394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18140984720169734, 0.18140984720169734, 0.26693157095270786], 
reward next is 0.7331, 
noisyNet noise sample is [array([1.4990267], dtype=float32), 1.8105712]. 
=============================================
[2019-03-26 17:39:14,467] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[72.76352 ]
 [72.65243 ]
 [72.77921 ]
 [73.350914]
 [73.33512 ]], R is [[72.85871124]
 [72.86325836]
 [72.86797333]
 [72.87297821]
 [72.87837219]].
[2019-03-26 17:39:20,238] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2690655e-24 1.0000000e+00 4.8892043e-28 2.0978001e-25 1.8260864e-33], sum to 1.0000
[2019-03-26 17:39:20,251] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8405
[2019-03-26 17:39:20,258] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 92.0, 1.0, 2.0, 0.3197204806825953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504505.9850825375, 504505.9850825375, 167342.7604367631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [21.36666666666667, 92.33333333333334, 1.0, 2.0, 0.324855744863134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 511905.0107555073, 511905.0107555079, 167891.8686927303], 
processed observation next is [1.0, 0.8695652173913043, 0.21169036334913136, 0.9233333333333335, 1.0, 1.0, 0.18657318658208916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14219583632097424, 0.14219583632097443, 0.2505848786458661], 
reward next is 0.7494, 
noisyNet noise sample is [array([-1.3023468], dtype=float32), 0.40354982]. 
=============================================
[2019-03-26 17:39:22,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.2500660e-15 1.0000000e+00 1.7893241e-20 1.9462328e-11 3.4572251e-24], sum to 1.0000
[2019-03-26 17:39:22,776] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3136
[2019-03-26 17:39:22,782] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.06666666666667, 75.66666666666667, 1.0, 2.0, 0.8619179330157656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1215179.016987219, 1215179.016987219, 261202.8761945246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1946400.0000, 
sim time next is 1947000.0000, 
raw observation next is [27.13333333333333, 75.33333333333333, 1.0, 2.0, 0.8720883541155204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1228875.472310606, 1228875.472310606, 263832.6274542133], 
processed observation next is [1.0, 0.5217391304347826, 0.484992101105845, 0.7533333333333333, 1.0, 1.0, 0.8458895832717114, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3413542978640572, 0.3413542978640572, 0.3937800409764377], 
reward next is 0.6062, 
noisyNet noise sample is [array([0.10037167], dtype=float32), -0.0063156267]. 
=============================================
[2019-03-26 17:39:22,799] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[62.89945 ]
 [61.66239 ]
 [58.769238]
 [55.655056]
 [54.13225 ]], R is [[62.96941757]
 [62.94987106]
 [62.93140793]
 [62.89321518]
 [62.26428223]].
[2019-03-26 17:39:22,888] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8950180e-24 1.0000000e+00 1.5422758e-28 3.1274512e-27 2.7975847e-35], sum to 1.0000
[2019-03-26 17:39:22,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7184
[2019-03-26 17:39:22,901] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 87.16666666666667, 1.0, 2.0, 0.4643297663735304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654385.5020715554, 654385.5020715548, 178915.4794144672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1887000.0000, 
sim time next is 1887600.0000, 
raw observation next is [25.3, 87.33333333333334, 1.0, 2.0, 0.4663137935741867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 657973.7384515434, 657973.7384515428, 179310.312292584], 
processed observation next is [1.0, 0.8695652173913043, 0.39810426540284366, 0.8733333333333334, 1.0, 1.0, 0.35700457057130924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1827704829032065, 0.18277048290320633, 0.26762733177997616], 
reward next is 0.7324, 
noisyNet noise sample is [array([-0.87063503], dtype=float32), 0.51325715]. 
=============================================
[2019-03-26 17:39:23,460] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.9977787e-14 1.0000000e+00 8.0305518e-20 2.5734397e-12 2.0701446e-24], sum to 1.0000
[2019-03-26 17:39:23,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7803
[2019-03-26 17:39:23,479] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1711303.247535836 W.
[2019-03-26 17:39:23,485] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.6, 87.0, 1.0, 2.0, 0.6120541392614658, 1.0, 1.0, 0.6120541392614658, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1711303.247535836, 1711303.247535836, 338735.1636245618], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1855800.0000, 
sim time next is 1856400.0000, 
raw observation next is [25.7, 86.66666666666666, 1.0, 2.0, 0.3858171560745624, 1.0, 2.0, 0.3858171560745624, 1.0, 1.0, 0.6492286215198427, 6.9112, 6.9112, 170.5573041426782, 1618046.684303418, 1618046.684303418, 342315.1281565443], 
processed observation next is [1.0, 0.4782608695652174, 0.4170616113744076, 0.8666666666666666, 1.0, 1.0, 0.2600206699693523, 1.0, 1.0, 0.2600206699693523, 1.0, 0.5, 0.5722300262437107, 0.0, 0.0, 0.8375144448122397, 0.449457412306505, 0.449457412306505, 0.5109181017261855], 
reward next is 0.4891, 
noisyNet noise sample is [array([-0.7659158], dtype=float32), -0.50105596]. 
=============================================
[2019-03-26 17:39:24,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0455849e-21 1.0000000e+00 9.5887608e-26 1.6784403e-21 1.2462672e-32], sum to 1.0000
[2019-03-26 17:39:24,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7460
[2019-03-26 17:39:24,646] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 90.33333333333333, 1.0, 2.0, 0.4527578666226864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645650.7652913006, 645650.7652913006, 178200.1073501263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1894200.0000, 
sim time next is 1894800.0000, 
raw observation next is [24.6, 90.66666666666667, 1.0, 2.0, 0.4526484860288028, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645650.250328264, 645650.250328264, 178203.9470475904], 
processed observation next is [1.0, 0.9565217391304348, 0.36492890995260674, 0.9066666666666667, 1.0, 1.0, 0.3405403446130154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1793472917578511, 0.1793472917578511, 0.2659760403695379], 
reward next is 0.7340, 
noisyNet noise sample is [array([-1.0708553], dtype=float32), -0.6588529]. 
=============================================
[2019-03-26 17:39:25,015] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 17:39:25,018] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:39:25,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:39:25,022] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:39:25,023] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:39:25,027] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:39:25,028] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:39:25,030] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:39:25,030] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:39:25,032] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:39:25,034] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:39:25,052] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run71
[2019-03-26 17:39:25,076] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run71
[2019-03-26 17:39:25,077] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run71
[2019-03-26 17:39:25,121] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run71
[2019-03-26 17:39:25,143] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run71
[2019-03-26 17:39:44,330] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623473], dtype=float32), 0.10683453]
[2019-03-26 17:39:44,333] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.18484642, 87.09067722500001, 1.0, 2.0, 0.663406604587403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 938746.8048434927, 938746.8048434933, 214684.1334575841]
[2019-03-26 17:39:44,334] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:39:44,336] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5940741e-23 1.0000000e+00 1.5465133e-26 2.9247637e-26 2.2741722e-32], sampled 0.9703899599735947
[2019-03-26 17:39:45,300] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00623473], dtype=float32), 0.10683453]
[2019-03-26 17:39:45,300] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.3, 94.0, 1.0, 2.0, 0.459051136245247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 651035.2717632691, 651035.2717632685, 178666.2408256308]
[2019-03-26 17:39:45,303] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:39:45,306] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2332887e-21 1.0000000e+00 1.7466636e-25 1.4292419e-21 5.2506874e-31], sampled 0.2658549469270435
[2019-03-26 17:39:52,239] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623473], dtype=float32), 0.10683453]
[2019-03-26 17:39:52,240] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.96892669333333, 90.92667892000001, 1.0, 2.0, 0.6402928113304674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 894792.2956195525, 894792.2956195532, 208483.6182849829]
[2019-03-26 17:39:52,242] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:39:52,245] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5699231e-23 1.0000000e+00 1.0438039e-26 5.3101426e-26 1.6451135e-32], sampled 0.3939757447015053
[2019-03-26 17:40:24,877] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00623473], dtype=float32), 0.10683453]
[2019-03-26 17:40:24,879] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [38.19775442166667, 63.66078778000001, 1.0, 2.0, 0.8331488266170916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1164451.248433086, 1164451.248433087, 252228.2925287913]
[2019-03-26 17:40:24,880] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:40:24,884] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0290007e-21 1.0000000e+00 8.8945799e-26 5.9074307e-22 5.0303494e-31], sampled 0.6321481189657814
[2019-03-26 17:40:29,828] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00623473], dtype=float32), 0.10683453]
[2019-03-26 17:40:29,831] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 79.0, 1.0, 2.0, 0.6213418748053967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868298.0366210239, 868298.0366210239, 204789.8230371206]
[2019-03-26 17:40:29,833] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:40:29,835] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6652134e-21 1.0000000e+00 6.0781770e-26 3.7117702e-21 2.7871514e-31], sampled 0.7770245105335992
[2019-03-26 17:41:22,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8567.4815 2835794677.9052 955.0000
[2019-03-26 17:41:22,511] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8067.6582 3146663830.8825 1320.0000
[2019-03-26 17:41:22,593] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8328.1773 2921538082.7046 1183.0000
[2019-03-26 17:41:22,662] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8141.3601 2994438994.2411 1432.0000
[2019-03-26 17:41:22,747] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8693.6406 2776348682.0533 856.0000
[2019-03-26 17:41:23,764] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1750000, evaluation results [1750000.0, 8067.658246363846, 3146663830.8824964, 1320.0, 8328.177335452325, 2921538082.7045655, 1183.0, 8693.640635153813, 2776348682.05332, 856.0, 8141.360073222748, 2994438994.2410617, 1432.0, 8567.481538945312, 2835794677.905218, 955.0]
[2019-03-26 17:41:25,112] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.3285028e-22 1.0000000e+00 4.5007325e-26 2.5031963e-22 5.1955140e-32], sum to 1.0000
[2019-03-26 17:41:25,120] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7424
[2019-03-26 17:41:25,124] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 95.33333333333334, 1.0, 2.0, 0.4625111874732546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653122.8952995116, 653122.8952995116, 178815.037821896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1990200.0000, 
sim time next is 1990800.0000, 
raw observation next is [24.3, 95.0, 1.0, 2.0, 0.4628879070773849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652952.9311250609, 652952.9311250609, 178780.3507710804], 
processed observation next is [0.0, 0.043478260869565216, 0.3507109004739337, 0.95, 1.0, 1.0, 0.35287699647877696, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1813758142014058, 0.1813758142014058, 0.26683634443444837], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.7138425], dtype=float32), 0.32319987]. 
=============================================
[2019-03-26 17:41:28,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.3632819e-24 1.0000000e+00 1.0340263e-27 2.6432113e-26 1.1302413e-33], sum to 1.0000
[2019-03-26 17:41:28,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2083
[2019-03-26 17:41:28,522] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 96.16666666666666, 1.0, 2.0, 0.6231774175942596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 870864.1788365295, 870864.1788365302, 205134.0757047103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2175000.0000, 
sim time next is 2175600.0000, 
raw observation next is [24.7, 96.33333333333333, 1.0, 2.0, 0.5916131441029758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826737.2696399585, 826737.2696399585, 199186.5375727023], 
processed observation next is [1.0, 0.17391304347826086, 0.3696682464454976, 0.9633333333333333, 1.0, 1.0, 0.5079676434975612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22964924156665514, 0.22964924156665514, 0.2972933396607497], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.62277806], dtype=float32), -0.95229506]. 
=============================================
[2019-03-26 17:41:30,072] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3126830e-20 1.0000000e+00 1.8861252e-24 3.0306955e-21 6.1086146e-30], sum to 1.0000
[2019-03-26 17:41:30,080] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8868
[2019-03-26 17:41:30,083] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 94.33333333333334, 1.0, 2.0, 1.001253187031836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1399557.328591492, 1399557.328591492, 299305.3428096813], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2168400.0000, 
sim time next is 2169000.0000, 
raw observation next is [25.15, 94.5, 1.0, 2.0, 0.8989701569902202, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1256500.92769338, 1256500.92769338, 269651.8516837089], 
processed observation next is [1.0, 0.08695652173913043, 0.3909952606635071, 0.945, 1.0, 1.0, 0.8782772975785785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34902803547038336, 0.34902803547038336, 0.4024654502741924], 
reward next is 0.5975, 
noisyNet noise sample is [array([0.38314223], dtype=float32), 0.11328265]. 
=============================================
[2019-03-26 17:41:30,097] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[64.99426 ]
 [66.39737 ]
 [70.58532 ]
 [70.08897 ]
 [69.986115]], R is [[65.24623871]
 [65.14705658]
 [65.03543091]
 [65.10949707]
 [65.18289185]].
[2019-03-26 17:41:33,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.1141851e-23 1.0000000e+00 1.1339507e-26 4.1471593e-24 4.6200848e-33], sum to 1.0000
[2019-03-26 17:41:33,657] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-26 17:41:33,665] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333334, 92.66666666666666, 1.0, 2.0, 0.5262457040990456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735359.3039055692, 735359.3039055692, 187810.3494373734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2155800.0000, 
sim time next is 2156400.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.5246303416972946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733101.2680343774, 733101.2680343774, 187545.0784434577], 
processed observation next is [0.0, 1.0, 0.4360189573459717, 0.93, 1.0, 1.0, 0.4272654719244513, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20363924112066037, 0.20363924112066037, 0.2799180275275488], 
reward next is 0.7201, 
noisyNet noise sample is [array([-2.1964397], dtype=float32), -1.1741303]. 
=============================================
[2019-03-26 17:41:35,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3426640e-09 8.2970422e-04 2.2391228e-17 9.9917030e-01 4.6041674e-19], sum to 1.0000
[2019-03-26 17:41:35,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1427
[2019-03-26 17:41:35,217] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.8, 66.0, 1.0, 2.0, 0.6129386122642385, 1.0, 1.0, 0.6129386122642385, 1.0, 2.0, 1.03, 6.949952215530724, 6.9112, 170.5573041426782, 2571634.349722875, 2543874.561398875, 492717.3983411579], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2208600.0000, 
sim time next is 2209200.0000, 
raw observation next is [31.9, 65.66666666666666, 1.0, 2.0, 0.8769796945633477, 1.0, 2.0, 0.8769796945633477, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2452843.799943425, 2452843.799943425, 459089.1518219268], 
processed observation next is [1.0, 0.5652173913043478, 0.7109004739336492, 0.6566666666666666, 1.0, 1.0, 0.8517827645341538, 1.0, 1.0, 0.8517827645341538, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6813454999842847, 0.6813454999842847, 0.6852076892864579], 
reward next is 0.3148, 
noisyNet noise sample is [array([1.2079717], dtype=float32), 0.31589696]. 
=============================================
[2019-03-26 17:41:35,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.1653824e-22 1.0000000e+00 8.3370907e-26 6.3705403e-23 1.4454147e-31], sum to 1.0000
[2019-03-26 17:41:35,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-26 17:41:35,606] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 95.5, 1.0, 2.0, 0.6251284712388214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873591.8153861965, 873591.8153861965, 205511.5342816726], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2172600.0000, 
sim time next is 2173200.0000, 
raw observation next is [24.86666666666667, 95.66666666666667, 1.0, 2.0, 0.6136397413985974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857530.2976508441, 857530.2976508441, 203305.9632519845], 
processed observation next is [1.0, 0.13043478260869565, 0.3775671406003162, 0.9566666666666667, 1.0, 1.0, 0.5345057125284306, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2382028604585678, 0.2382028604585678, 0.3034417361969918], 
reward next is 0.6966, 
noisyNet noise sample is [array([-0.01136958], dtype=float32), 0.28579444]. 
=============================================
[2019-03-26 17:41:36,432] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5503748e-27 1.0000000e+00 8.3977836e-30 3.3052929e-32 1.9639216e-35], sum to 1.0000
[2019-03-26 17:41:36,440] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4622
[2019-03-26 17:41:36,447] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 97.0, 1.0, 2.0, 0.4631844348492491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 653250.2282410933, 653250.2282410928, 178808.4811557962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092800.0000, 
sim time next is 2093400.0000, 
raw observation next is [24.2, 96.5, 1.0, 2.0, 0.470418714713117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661346.4960762226, 661346.4960762219, 179610.3312836227], 
processed observation next is [0.0, 0.21739130434782608, 0.3459715639810427, 0.965, 1.0, 1.0, 0.3619502586905024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18370736002117294, 0.18370736002117274, 0.26807512131883987], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.27654523], dtype=float32), -0.29092452]. 
=============================================
[2019-03-26 17:41:40,921] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1338301e-24 1.0000000e+00 1.2742781e-27 1.4325563e-27 4.1913358e-34], sum to 1.0000
[2019-03-26 17:41:40,932] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5083
[2019-03-26 17:41:40,936] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 96.5, 1.0, 2.0, 0.5889505493944133, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 823015.0414544895, 823015.0414544889, 198698.2665550767], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2176200.0000, 
sim time next is 2176800.0000, 
raw observation next is [24.6, 96.66666666666666, 1.0, 2.0, 0.5738524123772334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801908.541795593, 801908.541795593, 195969.5670910848], 
processed observation next is [1.0, 0.17391304347826086, 0.36492890995260674, 0.9666666666666666, 1.0, 1.0, 0.4865691715388354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22275237272099804, 0.22275237272099804, 0.2924918911807236], 
reward next is 0.7075, 
noisyNet noise sample is [array([1.3141851], dtype=float32), 0.3894393]. 
=============================================
[2019-03-26 17:41:42,465] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9384490e-10 9.9804085e-01 2.1706350e-16 1.9592023e-03 1.1721350e-18], sum to 1.0000
[2019-03-26 17:41:42,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2546
[2019-03-26 17:41:42,489] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2377049.098085314 W.
[2019-03-26 17:41:42,494] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.7, 66.33333333333334, 1.0, 2.0, 0.8499061185699935, 1.0, 1.0, 0.8499061185699935, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2377049.098085314, 2377049.098085315, 444900.1979081481], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2208000.0000, 
sim time next is 2208600.0000, 
raw observation next is [31.8, 66.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.065933153583785, 6.9112, 168.9064611963536, 3104050.697850723, 2284874.757339364, 473366.7335471088], 
processed observation next is [1.0, 0.5652173913043478, 0.7061611374407584, 0.66, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.1154733153583785, 0.0, 0.829408050186615, 0.8622363049585341, 0.6346874325942677, 0.7065175127568788], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4098542], dtype=float32), 0.89778817]. 
=============================================
[2019-03-26 17:41:43,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.8540336e-24 1.0000000e+00 2.6032533e-27 3.0146341e-28 1.0746563e-33], sum to 1.0000
[2019-03-26 17:41:43,753] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7362
[2019-03-26 17:41:43,759] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.85, 87.5, 1.0, 2.0, 0.702177594599907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 981314.6008886645, 981314.6008886645, 221312.7913619412], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2262600.0000, 
sim time next is 2263200.0000, 
raw observation next is [25.8, 87.66666666666667, 1.0, 2.0, 0.6718116308829478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 938858.4824038736, 938858.482403873, 214875.2521243671], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.8766666666666667, 1.0, 1.0, 0.6045923263649974, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2607940228899649, 0.2607940228899647, 0.3207093315289061], 
reward next is 0.6793, 
noisyNet noise sample is [array([1.6734723], dtype=float32), -0.1172945]. 
=============================================
[2019-03-26 17:41:55,617] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8671655e-26 1.0000000e+00 5.0617694e-29 2.0705262e-29 1.7037221e-35], sum to 1.0000
[2019-03-26 17:41:55,627] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1495
[2019-03-26 17:41:55,631] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 95.0, 1.0, 2.0, 0.5444001895171413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 760736.8987499457, 760736.8987499464, 190845.0597908571], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2512800.0000, 
sim time next is 2513400.0000, 
raw observation next is [26.38333333333333, 95.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.359698216321023, 6.9112, 169.6265963146485, 1773492.994362928, 1453968.645634479, 311482.866855632], 
processed observation next is [1.0, 0.08695652173913043, 0.44944707740916257, 0.9516666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.04484982163210231, 0.0, 0.8329442432967267, 0.4926369428785911, 0.4038801793429108, 0.46489980127706265], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0362847], dtype=float32), -1.4091115]. 
=============================================
[2019-03-26 17:42:05,433] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7580148e-30 1.0000000e+00 4.2514369e-32 2.0986998e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 17:42:05,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0839
[2019-03-26 17:42:05,448] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 86.5, 1.0, 2.0, 0.4660689571230514, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655977.7309307858, 655977.7309307863, 179061.9022285829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2619000.0000, 
sim time next is 2619600.0000, 
raw observation next is [25.66666666666666, 85.66666666666667, 1.0, 2.0, 0.4682794274503636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657664.9178185721, 657664.9178185728, 179205.7604229623], 
processed observation next is [0.0, 0.30434782608695654, 0.4154818325434437, 0.8566666666666667, 1.0, 1.0, 0.35937280415706463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18268469939404783, 0.18268469939404802, 0.26747128421337657], 
reward next is 0.7325, 
noisyNet noise sample is [array([-2.1736932], dtype=float32), -0.586795]. 
=============================================
[2019-03-26 17:42:08,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0996014e-30 1.0000000e+00 5.3694194e-33 2.6644455e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 17:42:08,756] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8107
[2019-03-26 17:42:08,763] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.4782925138206723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668329.9348324661, 668329.9348324666, 180264.7621281692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2634000.0000, 
sim time next is 2634600.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 1.0, 2.0, 0.4792904809376818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669724.8584926792, 669724.8584926798, 180414.8840751948], 
processed observation next is [0.0, 0.4782608695652174, 0.470774091627172, 0.7983333333333335, 1.0, 1.0, 0.37263913365985757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1860346829146331, 0.18603468291463326, 0.26927594638088775], 
reward next is 0.7307, 
noisyNet noise sample is [array([-0.79470867], dtype=float32), -0.07358256]. 
=============================================
[2019-03-26 17:42:09,223] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3902938e-27 1.0000000e+00 8.9915453e-31 2.8150799e-33 6.7937556e-38], sum to 1.0000
[2019-03-26 17:42:09,232] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1063
[2019-03-26 17:42:09,240] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3924585160969249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 585608.0311971834, 585608.0311971828, 173216.1269029395], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3117000.0000, 
sim time next is 3117600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3916300719444722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 584371.8003753352, 584371.8003753345, 173103.6085864089], 
processed observation next is [1.0, 0.08695652173913043, 0.28909952606635075, 0.94, 1.0, 1.0, 0.26702418306562914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16232550010425975, 0.16232550010425956, 0.2583635949050879], 
reward next is 0.7416, 
noisyNet noise sample is [array([0.4157758], dtype=float32), 0.26978946]. 
=============================================
[2019-03-26 17:42:11,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4010676e-30 1.0000000e+00 1.6781237e-32 2.1469686e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:42:11,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8744
[2019-03-26 17:42:11,653] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4759033026671583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664990.3861802926, 664990.3861802932, 179906.6897810711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2701200.0000, 
sim time next is 2701800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4759374510523071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665038.117422774, 665038.117422774, 179911.7946116094], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3685993386172375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.184732810395215, 0.184732810395215, 0.26852506658449166], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.43520823], dtype=float32), -0.41016063]. 
=============================================
[2019-03-26 17:42:12,461] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7000780e-29 1.0000000e+00 1.1062864e-31 3.3526270e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:42:12,470] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2980
[2019-03-26 17:42:12,474] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3733463671546196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575119.4601687302, 575119.4601687302, 172793.2798823809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2792400.0000, 
sim time next is 2793000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3799617438694608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585306.2526241723, 585306.2526241723, 173689.40024381], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.25296595646922987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16258507017338117, 0.16258507017338117, 0.2592379108116567], 
reward next is 0.7408, 
noisyNet noise sample is [array([-0.9378961], dtype=float32), -1.1163071]. 
=============================================
[2019-03-26 17:42:12,488] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.23392 ]
 [71.30057 ]
 [71.2861  ]
 [71.36278 ]
 [71.688286]], R is [[71.16294098]
 [71.19340515]
 [71.22527313]
 [71.25646973]
 [71.28544617]].
[2019-03-26 17:42:14,914] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3942644e-30 1.0000000e+00 4.9826752e-33 7.2014988e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 17:42:14,925] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7409
[2019-03-26 17:42:14,931] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.00000000000001, 1.0, 2.0, 0.3926703583748353, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585939.7882578761, 585939.7882578761, 173246.8439187614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2733000.0000, 
sim time next is 2733600.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3930336420206463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 586467.0610255925, 586467.0610255925, 173294.4695076119], 
processed observation next is [0.0, 0.6521739130434783, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2687152313501762, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16290751695155348, 0.16290751695155348, 0.2586484619516596], 
reward next is 0.7414, 
noisyNet noise sample is [array([0.20116146], dtype=float32), 1.0148169]. 
=============================================
[2019-03-26 17:42:19,378] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 17:42:19,380] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:42:19,382] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:42:19,383] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:42:19,385] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:42:19,382] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:42:19,386] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:42:19,387] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:42:19,389] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:42:19,389] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:42:19,393] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:42:19,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run72
[2019-03-26 17:42:19,441] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run72
[2019-03-26 17:42:19,465] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run72
[2019-03-26 17:42:19,465] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run72
[2019-03-26 17:42:19,485] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run72
[2019-03-26 17:42:22,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:42:22,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.58083553, 97.61578004, 1.0, 2.0, 0.4558305228004364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684570.2971634181, 684570.2971634181, 182870.2277337285]
[2019-03-26 17:42:22,387] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:42:22,389] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1507608e-29 1.0000000e+00 4.8588507e-32 4.4293946e-36 0.0000000e+00], sampled 0.8763394792239031
[2019-03-26 17:42:28,759] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:42:28,760] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.56666666666667, 67.5, 1.0, 2.0, 0.2573000799277182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 421632.5319611416, 421632.531961141, 161635.2801093342]
[2019-03-26 17:42:28,762] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:42:28,766] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6075280e-29 1.0000000e+00 4.1438057e-32 4.8628669e-35 0.0000000e+00], sampled 0.3573848932507696
[2019-03-26 17:42:34,664] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:42:34,665] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.37758565833333, 93.4716576, 1.0, 2.0, 0.6428048910363559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 898304.3452985847, 898304.3452985854, 208981.7920026221]
[2019-03-26 17:42:34,667] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:42:34,669] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.5712958e-29 1.0000000e+00 3.4128837e-31 1.3395496e-34 5.3855499e-38], sampled 0.860544123264504
[2019-03-26 17:42:45,122] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:42:45,123] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.73333333333333, 85.33333333333334, 1.0, 2.0, 0.4806583762338302, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8109241064742785, 6.9112, 6.9112, 168.9122918588123, 1343698.630586681, 1343698.630586681, 293672.2948298876]
[2019-03-26 17:42:45,124] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:42:45,127] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0061224e-22 1.0000000e+00 6.3918299e-26 2.0200376e-25 7.7285468e-32], sampled 0.11730439719171237
[2019-03-26 17:42:48,206] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:42:48,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.365620975, 86.109141585, 1.0, 2.0, 0.8153423107200474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1139550.599937396, 1139550.599937396, 247709.0723819653]
[2019-03-26 17:42:48,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:42:48,212] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.0830909e-24 1.0000000e+00 1.6180749e-27 4.7814739e-26 2.5950358e-33], sampled 0.8694723436309255
[2019-03-26 17:43:09,494] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:43:09,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.5, 73.0, 1.0, 2.0, 0.5984203200604482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836253.5584078835, 836253.5584078835, 200452.5541738454]
[2019-03-26 17:43:09,498] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:43:09,499] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0710160e-29 1.0000000e+00 5.2625360e-32 4.0169056e-35 0.0000000e+00], sampled 0.9196283270222617
[2019-03-26 17:43:26,539] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:43:26,541] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.96666666666667, 65.0, 1.0, 2.0, 0.5782352965939777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808035.5687137821, 808035.5687137821, 196760.5574095364]
[2019-03-26 17:43:26,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:43:26,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.5962156e-28 1.0000000e+00 4.0025357e-31 1.0719633e-31 1.1543526e-37], sampled 0.07929649091080615
[2019-03-26 17:43:45,549] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:43:45,551] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.63333333333333, 66.83333333333333, 1.0, 2.0, 0.6081627170312022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 849873.3727340285, 849873.3727340285, 202276.3251873711]
[2019-03-26 17:43:45,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:43:45,555] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.2544515e-29 1.0000000e+00 9.7139068e-32 8.1502690e-34 2.1592066e-38], sampled 0.871791135121008
[2019-03-26 17:44:05,368] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00437652], dtype=float32), 0.10706268]
[2019-03-26 17:44:05,370] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.05, 79.0, 1.0, 2.0, 0.5967874250666728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833970.7977889155, 833970.7977889155, 200148.5569650856]
[2019-03-26 17:44:05,372] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:44:05,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.9449551e-29 1.0000000e+00 4.5015600e-32 1.3704644e-33 0.0000000e+00], sampled 0.3190872048685911
[2019-03-26 17:44:16,246] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:44:16,281] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 17:44:16,297] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7891.4690 3163605694.7026 1767.0000
[2019-03-26 17:44:16,446] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.5558 2927414952.7171 1337.0000
[2019-03-26 17:44:16,561] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 17:44:17,578] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1775000, evaluation results [1775000.0, 7891.469011325354, 3163605694.7025814, 1767.0, 8255.555771581707, 2927414952.717087, 1337.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 17:44:20,164] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6907280e-30 1.0000000e+00 2.0675159e-32 5.7730544e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:44:20,174] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7216
[2019-03-26 17:44:20,178] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 69.0, 1.0, 2.0, 0.5852834853996871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817888.6164457739, 817888.6164457739, 198037.1086386241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3331800.0000, 
sim time next is 3332400.0000, 
raw observation next is [32.0, 69.66666666666666, 1.0, 2.0, 0.5884164292016372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822268.358886864, 822268.358886864, 198608.6892002957], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.6966666666666665, 1.0, 1.0, 0.5041161797610086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22840787746857336, 0.22840787746857336, 0.2964308794034264], 
reward next is 0.7036, 
noisyNet noise sample is [array([0.21648195], dtype=float32), -0.8231598]. 
=============================================
[2019-03-26 17:44:23,662] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.604146e-28 1.000000e+00 1.465994e-31 6.330847e-34 0.000000e+00], sum to 1.0000
[2019-03-26 17:44:23,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7729
[2019-03-26 17:44:23,674] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3084721257190241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 491020.2512022325, 491020.2512022319, 166416.1234467001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2923200.0000, 
sim time next is 2923800.0000, 
raw observation next is [20.08333333333334, 99.5, 1.0, 2.0, 0.3084631333891708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524192, 166413.9369656206], 
processed observation next is [1.0, 0.8695652173913043, 0.15086887835703036, 0.995, 1.0, 1.0, 0.1668230522761094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13638670984789422, 0.13638670984789422, 0.24837901039644866], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.16617689], dtype=float32), -0.68299294]. 
=============================================
[2019-03-26 17:44:28,553] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6784272e-29 1.0000000e+00 3.7409608e-32 2.1946267e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:44:28,567] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9478
[2019-03-26 17:44:28,572] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 94.00000000000001, 1.0, 2.0, 0.4934154542202681, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 689468.4503746668, 689468.4503746675, 182570.842177091], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3186600.0000, 
sim time next is 3187200.0000, 
raw observation next is [25.33333333333334, 94.0, 1.0, 2.0, 0.4969973463677968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 694475.2025412312, 694475.2025412312, 183127.1426194583], 
processed observation next is [1.0, 0.9130434782608695, 0.3996840442338076, 0.94, 1.0, 1.0, 0.39397270646722504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19290977848367533, 0.19290977848367533, 0.273324093461878], 
reward next is 0.7267, 
noisyNet noise sample is [array([-1.1309259], dtype=float32), 0.7968198]. 
=============================================
[2019-03-26 17:44:34,140] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2418182e-28 1.0000000e+00 4.3286973e-31 2.1949209e-34 2.4195069e-38], sum to 1.0000
[2019-03-26 17:44:34,148] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0781
[2019-03-26 17:44:34,156] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.08333333333334, 83.5, 1.0, 2.0, 0.6458875547944924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 902614.1242056534, 902614.1242056529, 209594.8043431386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559800.0000, 
sim time next is 3560400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.6358323880912397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 888556.3644588677, 888556.3644588677, 207600.4960712228], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.84, 1.0, 1.0, 0.5612438410737827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24682121234968546, 0.24682121234968546, 0.30985148667346685], 
reward next is 0.6901, 
noisyNet noise sample is [array([-0.07506884], dtype=float32), 0.6287638]. 
=============================================
[2019-03-26 17:44:46,009] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3580981e-12 1.0000000e+00 2.8370385e-19 9.3883201e-10 9.9900184e-22], sum to 1.0000
[2019-03-26 17:44:46,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6377
[2019-03-26 17:44:46,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2170185.463655292 W.
[2019-03-26 17:44:46,026] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 67.33333333333334, 1.0, 2.0, 0.9108227483478897, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993941479565493, 6.9112, 168.9123995739561, 2170185.463655292, 2111486.003852923, 437530.3698531908], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3579600.0000, 
sim time next is 3580200.0000, 
raw observation next is [31.0, 68.0, 1.0, 2.0, 0.8431466287646118, 1.0, 1.0, 0.8431466287646118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2358126.067808397, 2358126.067808397, 441422.5250473192], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.68, 1.0, 1.0, 0.8110200346561588, 1.0, 0.5, 0.8110200346561588, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6550350188356658, 0.6550350188356658, 0.6588395896228645], 
reward next is 0.3412, 
noisyNet noise sample is [array([-2.2030919], dtype=float32), -1.2160773]. 
=============================================
[2019-03-26 17:44:46,057] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4875634e-24 1.0000000e+00 2.2337078e-27 6.0777269e-29 5.1281671e-34], sum to 1.0000
[2019-03-26 17:44:46,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7245
[2019-03-26 17:44:46,071] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.83333333333334, 1.0, 2.0, 0.8107814939858168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1133172.843484096, 1133172.843484096, 246571.6962283344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3484200.0000, 
sim time next is 3484800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.8173905210953945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1142414.789522128, 1142414.789522127, 248221.2262875607], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.74, 1.0, 1.0, 0.7799885796330054, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3173374415339244, 0.3173374415339242, 0.3704794422202399], 
reward next is 0.6295, 
noisyNet noise sample is [array([-0.07526955], dtype=float32), -1.3088367]. 
=============================================
[2019-03-26 17:45:01,844] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.4203895e-28 1.0000000e+00 3.4745875e-30 6.2355711e-35 3.9678320e-37], sum to 1.0000
[2019-03-26 17:45:01,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6312
[2019-03-26 17:45:01,862] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666666, 83.0, 1.0, 2.0, 0.6581222760653266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 919719.2901947432, 919719.2901947432, 212061.7720320993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3559200.0000, 
sim time next is 3559800.0000, 
raw observation next is [26.08333333333334, 83.5, 1.0, 2.0, 0.6458875547944924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 902614.1242056534, 902614.1242056529, 209594.8043431386], 
processed observation next is [1.0, 0.17391304347826086, 0.43522906793049004, 0.835, 1.0, 1.0, 0.5733584997524005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25072614561268153, 0.25072614561268136, 0.31282806618378894], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.19017759], dtype=float32), -0.2802456]. 
=============================================
[2019-03-26 17:45:02,403] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4751117e-11 9.9999499e-01 1.6380603e-17 5.0566887e-06 6.1791128e-20], sum to 1.0000
[2019-03-26 17:45:02,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5841
[2019-03-26 17:45:02,424] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2380666.475675163 W.
[2019-03-26 17:45:02,431] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.16666666666667, 69.5, 1.0, 2.0, 0.5674655128325884, 1.0, 2.0, 0.5674655128325884, 1.0, 1.0, 0.9854999320774427, 6.911200000000001, 6.9112, 170.5573041426782, 2380666.475675163, 2380666.475675163, 464934.4969302221], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3582600.0000, 
sim time next is 3583200.0000, 
raw observation next is [31.33333333333334, 69.0, 1.0, 2.0, 0.9776058306050938, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.00599211807711, 6.9112, 168.9123931359716, 2263657.715373676, 2196409.14861138, 456475.3019300993], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.69, 1.0, 1.0, 0.9730190730181852, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009479211807710986, 0.0, 0.829437178725793, 0.6287938098260211, 0.61011365239205, 0.681306420791193], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.25714284], dtype=float32), 0.21444501]. 
=============================================
[2019-03-26 17:45:02,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2618251e-30 1.0000000e+00 9.1109312e-33 5.9474757e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 17:45:02,985] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9597
[2019-03-26 17:45:02,990] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 76.5, 1.0, 2.0, 0.5105657294396888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 713441.2392319824, 713441.2392319817, 185267.6695008594], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3706200.0000, 
sim time next is 3706800.0000, 
raw observation next is [28.0, 75.66666666666666, 1.0, 2.0, 0.5054199822890488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706248.4168026005, 706248.4168026012, 184449.2617156579], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.7566666666666666, 1.0, 1.0, 0.4041204605892154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19618011577850014, 0.19618011577850034, 0.27529740554575804], 
reward next is 0.7247, 
noisyNet noise sample is [array([-0.45137414], dtype=float32), -0.12933369]. 
=============================================
[2019-03-26 17:45:13,462] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 17:45:13,463] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:45:13,464] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:45:13,465] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:45:13,465] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:45:13,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:45:13,467] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:45:13,467] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:45:13,468] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:45:13,469] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:45:13,471] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:45:13,503] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run73
[2019-03-26 17:45:13,528] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run73
[2019-03-26 17:45:13,528] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run73
[2019-03-26 17:45:13,549] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run73
[2019-03-26 17:45:13,595] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run73
[2019-03-26 17:45:25,092] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00373773], dtype=float32), 0.10511595]
[2019-03-26 17:45:25,093] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.53718042, 61.86724112, 1.0, 2.0, 0.2363122848242901, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395162.9976060155, 395162.9976060155, 155756.6690535959]
[2019-03-26 17:45:25,095] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:45:25,100] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.4894423e-34 1.0000000e+00 6.8617715e-35 0.0000000e+00 0.0000000e+00], sampled 0.8325917949278832
[2019-03-26 17:45:46,597] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00373773], dtype=float32), 0.10511595]
[2019-03-26 17:45:46,599] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.95, 93.0, 1.0, 2.0, 0.5198918164369748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726477.5436797593, 726477.5436797593, 186771.2839850073]
[2019-03-26 17:45:46,601] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:45:46,603] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.8267250e-30 1.0000000e+00 8.9251715e-33 5.1909074e-36 0.0000000e+00], sampled 0.6623612017554542
[2019-03-26 17:46:09,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.00373773], dtype=float32), 0.10511595]
[2019-03-26 17:46:09,861] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.45, 64.0, 1.0, 2.0, 0.9383797122390878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1311618.141600575, 1311618.141600574, 280713.8333960383]
[2019-03-26 17:46:09,862] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:46:09,864] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.7861859e-26 1.0000000e+00 9.9898684e-29 1.1318092e-30 5.2042935e-35], sampled 0.1633074808702708
[2019-03-26 17:46:59,949] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.00373773], dtype=float32), 0.10511595]
[2019-03-26 17:46:59,950] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.63333333333333, 65.33333333333334, 1.0, 2.0, 0.4940306120670604, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8579677947405048, 6.911200000000001, 6.9112, 168.9129277095231, 1381105.533869965, 1381105.533869964, 304967.5010866051]
[2019-03-26 17:46:59,951] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:46:59,954] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7986312e-20 1.0000000e+00 2.7255467e-25 1.8456587e-20 1.3052768e-29], sampled 0.9395811037544942
[2019-03-26 17:47:10,121] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 17:47:10,481] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.6640 2842632297.7926 1131.0000
[2019-03-26 17:47:10,736] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:47:10,755] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 17:47:10,841] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.0863 3164237066.6468 1775.0000
[2019-03-26 17:47:11,859] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1800000, evaluation results [1800000.0, 7883.086341896734, 3164237066.646846, 1775.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8496.663997866628, 2842632297.792627, 1131.0]
[2019-03-26 17:47:21,427] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5657333e-08 1.9538410e-01 1.9049879e-15 8.0461586e-01 4.7971426e-17], sum to 1.0000
[2019-03-26 17:47:21,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4514
[2019-03-26 17:47:21,437] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.33333333333333, 68.66666666666667, 1.0, 2.0, 0.6064646691786867, 1.0, 2.0, 0.6064646691786867, 1.0, 2.0, 1.03, 6.93352833753731, 6.9112, 170.5573041426782, 2544444.73232392, 2528450.035887245, 490492.9776444128], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4012800.0000, 
sim time next is 4013400.0000, 
raw observation next is [30.66666666666667, 67.33333333333333, 1.0, 2.0, 0.9130880121816084, 1.0, 2.0, 0.9130880121816084, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2553939.159163418, 2553939.159163418, 478676.6442410506], 
processed observation next is [1.0, 0.43478260869565216, 0.6524486571879939, 0.6733333333333333, 1.0, 1.0, 0.8952867616645884, 1.0, 1.0, 0.8952867616645884, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7094275442120607, 0.7094275442120607, 0.7144427525985829], 
reward next is 0.2856, 
noisyNet noise sample is [array([-0.59235704], dtype=float32), 1.2120391]. 
=============================================
[2019-03-26 17:47:25,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3881002e-22 1.0000000e+00 1.7091467e-25 7.3202791e-26 1.0505367e-30], sum to 1.0000
[2019-03-26 17:47:25,888] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3842
[2019-03-26 17:47:25,892] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 84.0, 1.0, 2.0, 0.9836277700152309, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1374904.467449562, 1374904.467449563, 293981.007786133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3996600.0000, 
sim time next is 3997200.0000, 
raw observation next is [29.33333333333334, 84.0, 1.0, 2.0, 0.9560641707630189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1336352.111159913, 1336352.111159913, 285829.2553981238], 
processed observation next is [1.0, 0.2608695652173913, 0.5892575039494474, 0.84, 1.0, 1.0, 0.9470652659795408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3712089197666425, 0.3712089197666425, 0.4266108289524236], 
reward next is 0.5734, 
noisyNet noise sample is [array([-2.033959], dtype=float32), 0.8566075]. 
=============================================
[2019-03-26 17:47:31,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4232711e-11 9.9968672e-01 3.5569931e-17 3.1328265e-04 3.4055677e-19], sum to 1.0000
[2019-03-26 17:47:31,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4197
[2019-03-26 17:47:31,822] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2540437.31854687 W.
[2019-03-26 17:47:31,988] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.16666666666667, 71.0, 1.0, 2.0, 0.9082657170261085, 1.0, 2.0, 0.9082657170261085, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2540437.31854687, 2540437.31854687, 476029.8796187527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4101000.0000, 
sim time next is 4101600.0000, 
raw observation next is [32.33333333333334, 71.0, 1.0, 2.0, 0.616425803829575, 1.0, 2.0, 0.616425803829575, 1.0, 1.0, 1.03, 6.956760601860908, 6.9112, 170.5573041426782, 2586280.291242929, 2553643.378843169, 494012.4853535078], 
processed observation next is [1.0, 0.4782608695652174, 0.7314375987361774, 0.71, 1.0, 1.0, 0.5378624142525, 1.0, 1.0, 0.5378624142525, 1.0, 0.5, 1.0365853658536586, 0.004556060186090782, 0.0, 0.8375144448122397, 0.7184111920119248, 0.7093453830119915, 0.7373320676918027], 
reward next is 0.0349, 
noisyNet noise sample is [array([-0.5726956], dtype=float32), 1.9483203]. 
=============================================
[2019-03-26 17:47:32,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0230829e-28 1.0000000e+00 2.0848447e-32 1.0193512e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:47:32,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4423
[2019-03-26 17:47:32,938] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5814238993722727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 812493.0792092942, 812493.0792092936, 197336.242391479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4139400.0000, 
sim time next is 4140000.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5826754100228536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 814242.634907639, 814242.634907639, 197562.6636269549], 
processed observation next is [1.0, 0.9565217391304348, 0.5734597156398105, 0.84, 1.0, 1.0, 0.49719928918416095, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2261785096965664, 0.2261785096965664, 0.2948696472044103], 
reward next is 0.7051, 
noisyNet noise sample is [array([-1.633738], dtype=float32), -2.1445045]. 
=============================================
[2019-03-26 17:47:32,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.936516]
 [72.293144]
 [72.39645 ]
 [72.33338 ]
 [72.21588 ]], R is [[71.81130981]
 [71.79866791]
 [71.78642273]
 [71.77443695]
 [71.76263428]].
[2019-03-26 17:47:43,258] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7468466e-29 1.0000000e+00 2.6846636e-32 3.2947369e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:47:43,268] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6489
[2019-03-26 17:47:43,277] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6162785628958777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861219.4114177788, 861219.4114177788, 203818.1714228774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4407600.0000, 
sim time next is 4408200.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6170304800647188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 862270.6057377337, 862270.605737733, 203961.9125217134], 
processed observation next is [0.0, 0.0, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5385909398370107, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23951961270492603, 0.23951961270492583, 0.3044207649577812], 
reward next is 0.6956, 
noisyNet noise sample is [array([0.0547902], dtype=float32), -0.336902]. 
=============================================
[2019-03-26 17:47:44,507] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2465741e-11 1.0000000e+00 3.2063400e-16 3.0531777e-10 1.5641041e-19], sum to 1.0000
[2019-03-26 17:47:44,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3385
[2019-03-26 17:47:44,529] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3281610.763845968 W.
[2019-03-26 17:47:44,535] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 79.5, 1.0, 2.0, 0.9226931484343041, 1.0, 2.0, 0.7819366137314144, 1.0, 1.0, 1.03, 7.005115297877424, 6.9112, 170.5573041426782, 3281610.763845968, 3214335.415746302, 600901.6615075356], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4350600.0000, 
sim time next is 4351200.0000, 
raw observation next is [32.33333333333334, 78.0, 1.0, 2.0, 0.8895878771055757, 1.0, 2.0, 0.7653839780670505, 1.0, 2.0, 1.03, 7.005112685747985, 6.9112, 170.5573041426782, 3212053.761653062, 3144780.284727968, 587902.4243168072], 
processed observation next is [1.0, 0.34782608695652173, 0.7314375987361774, 0.78, 1.0, 1.0, 0.8669733459103323, 1.0, 1.0, 0.7173300940566874, 1.0, 1.0, 1.0365853658536586, 0.009391268574798505, 0.0, 0.8375144448122397, 0.8922371560147394, 0.8735500790911022, 0.8774663049504585], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6181968], dtype=float32), -0.11813027]. 
=============================================
[2019-03-26 17:47:46,733] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6808704e-19 1.0000000e+00 3.0883933e-23 6.4048038e-22 4.7435694e-29], sum to 1.0000
[2019-03-26 17:47:46,745] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9375
[2019-03-26 17:47:46,756] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2894429.977882543 W.
[2019-03-26 17:47:46,762] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.16666666666667, 65.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.758292722842601, 6.9112, 168.9072602645149, 2894429.977882543, 2293493.511660065, 474632.550009697], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4806600.0000, 
sim time next is 4807200.0000, 
raw observation next is [31.33333333333334, 65.0, 1.0, 2.0, 0.8392202052461856, 1.0, 1.0, 0.8392202052461856, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2347134.270505286, 2347134.270505287, 439414.6207024034], 
processed observation next is [1.0, 0.6521739130434783, 0.6840442338072673, 0.65, 1.0, 1.0, 0.806289403911067, 1.0, 0.5, 0.806289403911067, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6519817418070238, 0.6519817418070242, 0.6558427174662738], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7030332], dtype=float32), -0.94042337]. 
=============================================
[2019-03-26 17:47:49,849] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.362806e-22 1.000000e+00 7.762968e-25 5.308644e-26 3.466168e-30], sum to 1.0000
[2019-03-26 17:47:49,860] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4493
[2019-03-26 17:47:49,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2552178.866442685 W.
[2019-03-26 17:47:49,878] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 87.33333333333334, 1.0, 2.0, 0.6083062079246087, 1.0, 1.0, 0.6083062079246087, 1.0, 1.0, 1.03, 6.940908041209208, 6.9112, 170.5573041426782, 2552178.866442685, 2530897.788078676, 491009.4283904542], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4587600.0000, 
sim time next is 4588200.0000, 
raw observation next is [28.0, 86.5, 1.0, 2.0, 0.6967097299423636, 1.0, 2.0, 0.6967097299423636, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1948215.447494898, 1948215.447494898, 372722.1456067696], 
processed observation next is [1.0, 0.08695652173913043, 0.5260663507109005, 0.865, 1.0, 1.0, 0.6345900360751369, 1.0, 1.0, 0.6345900360751369, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5411709576374717, 0.5411709576374717, 0.5563017098608501], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75657725], dtype=float32), 2.9064157]. 
=============================================
[2019-03-26 17:47:57,457] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.160882e-33 1.000000e+00 1.437807e-34 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 17:47:57,466] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0663
[2019-03-26 17:47:57,472] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5523590424186343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 771862.5247446579, 771862.5247446572, 192206.0057901137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4547400.0000, 
sim time next is 4548000.0000, 
raw observation next is [34.0, 53.0, 1.0, 2.0, 0.54038328846118, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755121.744507196, 755121.744507196, 190165.9052695419], 
processed observation next is [0.0, 0.6521739130434783, 0.8104265402843602, 0.53, 1.0, 1.0, 0.44624492585684333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20975604014088778, 0.20975604014088778, 0.2838297093575252], 
reward next is 0.7162, 
noisyNet noise sample is [array([-1.8339761], dtype=float32), 0.66322833]. 
=============================================
[2019-03-26 17:47:57,485] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.26122 ]
 [73.38478 ]
 [73.30026 ]
 [73.266266]
 [73.21266 ]], R is [[73.30255127]
 [73.28265381]
 [73.266922  ]
 [73.25203705]
 [73.237854  ]].
[2019-03-26 17:47:58,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.26943160e-30 1.00000000e+00 1.15421405e-33 9.70058794e-37
 0.00000000e+00], sum to 1.0000
[2019-03-26 17:47:58,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6447
[2019-03-26 17:47:58,533] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 70.0, 1.0, 2.0, 0.5098914425048809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712498.7054627757, 712498.7054627764, 185161.3104872976], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4818000.0000, 
sim time next is 4818600.0000, 
raw observation next is [29.5, 70.0, 1.0, 2.0, 0.506334780575076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707527.1355426661, 707527.1355426661, 184595.3005569133], 
processed observation next is [1.0, 0.782608695652174, 0.5971563981042655, 0.7, 1.0, 1.0, 0.4052226271988867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19653531542851835, 0.19653531542851835, 0.27551537396554227], 
reward next is 0.7245, 
noisyNet noise sample is [array([-0.8059854], dtype=float32), -0.02331346]. 
=============================================
[2019-03-26 17:48:04,655] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.7570515e-29 1.0000000e+00 1.8719251e-32 1.5987291e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:48:04,664] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1406
[2019-03-26 17:48:04,670] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.491204384838853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686377.8396673821, 686377.8396673815, 182229.1919985354], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4665000.0000, 
sim time next is 4665600.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.492324315942019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687943.2670588401, 687943.2670588401, 182401.8646252258], 
processed observation next is [1.0, 0.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.38834254932773365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19109535196078892, 0.19109535196078892, 0.2722415889928743], 
reward next is 0.7278, 
noisyNet noise sample is [array([0.30003518], dtype=float32), 1.3446897]. 
=============================================
[2019-03-26 17:48:05,936] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0228844e-27 1.0000000e+00 3.0361434e-30 1.0199079e-34 2.1220457e-37], sum to 1.0000
[2019-03-26 17:48:05,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2044
[2019-03-26 17:48:05,953] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7957369330861369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1112135.096893048, 1112135.096893047, 242863.5803199192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4847400.0000, 
sim time next is 4848000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7863176796647563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1098963.780301931, 1098963.780301931, 240576.5413430417], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7425514212828389, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30526771675053643, 0.30526771675053643, 0.359069464691107], 
reward next is 0.6409, 
noisyNet noise sample is [array([1.8419174], dtype=float32), -0.80503607]. 
=============================================
[2019-03-26 17:48:05,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[65.37892]
 [64.99183]
 [66.13195]
 [70.65117]
 [70.33301]], R is [[65.32766724]
 [65.31191254]
 [65.2533493 ]
 [65.16338348]
 [65.2412262 ]].
[2019-03-26 17:48:07,608] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 17:48:07,610] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:48:07,612] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:48:07,613] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:48:07,613] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:48:07,615] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:48:07,614] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:48:07,617] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:48:07,618] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:48:07,621] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:48:07,621] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:48:07,644] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run74
[2019-03-26 17:48:07,672] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run74
[2019-03-26 17:48:07,673] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run74
[2019-03-26 17:48:07,696] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run74
[2019-03-26 17:48:07,717] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run74
[2019-03-26 17:48:18,898] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00613518], dtype=float32), 0.104876384]
[2019-03-26 17:48:18,900] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.34418723333333, 91.58673026333334, 1.0, 2.0, 0.2677200048762663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437566.6611859103, 437566.6611859103, 162685.075663801]
[2019-03-26 17:48:18,903] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:48:18,906] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8292895e-30 1.0000000e+00 1.6830343e-32 6.7695933e-38 0.0000000e+00], sampled 0.5171451098027005
[2019-03-26 17:48:25,233] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.00613518], dtype=float32), 0.104876384]
[2019-03-26 17:48:25,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.4, 91.66666666666667, 1.0, 2.0, 0.2968436553141644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478136.7622501294, 478136.7622501287, 165529.0784781773]
[2019-03-26 17:48:25,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:48:25,238] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6290638e-32 1.0000000e+00 2.4635834e-34 0.0000000e+00 0.0000000e+00], sampled 0.13227310461715447
[2019-03-26 17:49:16,750] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.00613518], dtype=float32), 0.104876384]
[2019-03-26 17:49:16,753] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.66330852666667, 83.84036513333334, 1.0, 2.0, 0.7846490971151354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1096630.552010041, 1096630.55201004, 240177.4648180085]
[2019-03-26 17:49:16,756] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:49:16,758] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.8549901e-29 1.0000000e+00 7.3931970e-31 2.6685054e-36 4.2324589e-38], sampled 0.7804694793699856
[2019-03-26 17:49:22,950] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00613518], dtype=float32), 0.104876384]
[2019-03-26 17:49:22,952] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.4827398, 65.38345046, 1.0, 2.0, 0.5057424565207355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706699.1759358903, 706699.1759358909, 184499.6154171604]
[2019-03-26 17:49:22,953] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:49:22,954] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4158628e-32 1.0000000e+00 2.4497137e-34 0.0000000e+00 0.0000000e+00], sampled 0.7857712644924704
[2019-03-26 17:49:46,471] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.00613518], dtype=float32), 0.104876384]
[2019-03-26 17:49:46,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.97277621, 59.23644456, 1.0, 2.0, 0.6016396365576283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 878386.3552596613, 878386.3552596613, 205849.2250984967]
[2019-03-26 17:49:46,475] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:49:46,480] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.4758939e-30 1.0000000e+00 3.1253324e-32 2.9229517e-37 0.0000000e+00], sampled 0.89120266603189
[2019-03-26 17:50:04,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 17:50:04,250] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4454 2779139371.5791 933.0000
[2019-03-26 17:50:04,442] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:50:04,491] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 17:50:04,669] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.6459 3163993905.9670 1774.0000
[2019-03-26 17:50:05,688] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1825000, evaluation results [1825000.0, 7885.645930145866, 3163993905.967023, 1774.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.445426124437, 2779139371.579139, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 17:50:10,446] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2243933e-32 1.0000000e+00 2.9184437e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:10,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1565
[2019-03-26 17:50:10,461] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 62.33333333333333, 1.0, 2.0, 0.5346691542317358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747134.109469819, 747134.109469819, 189205.5921577475], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5062200.0000, 
sim time next is 5062800.0000, 
raw observation next is [31.33333333333334, 61.66666666666667, 1.0, 2.0, 0.5224315252581876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730027.658095248, 730027.6580952486, 187185.5399929009], 
processed observation next is [0.0, 0.6086956521739131, 0.6840442338072673, 0.6166666666666667, 1.0, 1.0, 0.42461629549179225, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20278546058201335, 0.2027854605820135, 0.279381402974479], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.9999989], dtype=float32), 0.2911792]. 
=============================================
[2019-03-26 17:50:24,826] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.515786e-31 1.000000e+00 2.403479e-33 3.010390e-38 0.000000e+00], sum to 1.0000
[2019-03-26 17:50:24,837] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8310
[2019-03-26 17:50:24,842] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 61.66666666666667, 1.0, 2.0, 0.5211783218355135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728275.8748730033, 728275.8748730033, 186981.1706634392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5067600.0000, 
sim time next is 5068200.0000, 
raw observation next is [31.16666666666667, 62.33333333333333, 1.0, 2.0, 0.5208317382904694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727791.405560802, 727791.4055608013, 186924.6560493465], 
processed observation next is [0.0, 0.6521739130434783, 0.6761453396524489, 0.6233333333333333, 1.0, 1.0, 0.42268884131381845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.202164279322445, 0.2021642793224448, 0.2789920239542485], 
reward next is 0.7210, 
noisyNet noise sample is [array([0.4302001], dtype=float32), 0.30435067]. 
=============================================
[2019-03-26 17:50:35,736] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.2171560e-28 1.0000000e+00 4.1063584e-30 8.1721509e-35 2.3144159e-37], sum to 1.0000
[2019-03-26 17:50:35,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8117
[2019-03-26 17:50:35,753] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.7880341560464447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1101363.985304268, 1101363.985304269, 240994.054750318], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5212800.0000, 
sim time next is 5213400.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.8752579471840831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1223339.005476991, 1223339.00547699, 263221.7120277325], 
processed observation next is [1.0, 0.34782608695652173, 0.581358609794629, 0.7333333333333334, 1.0, 1.0, 0.849708370101305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3398163904102753, 0.339816390410275, 0.39286822690706347], 
reward next is 0.6071, 
noisyNet noise sample is [array([0.7258976], dtype=float32), -0.63142204]. 
=============================================
[2019-03-26 17:50:38,177] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0483979e-32 1.0000000e+00 1.1826496e-33 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:38,187] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2425
[2019-03-26 17:50:38,191] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 87.0, 1.0, 2.0, 0.5098274620631409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712409.2721748042, 712409.2721748042, 185149.8167344803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5709600.0000, 
sim time next is 5710200.0000, 
raw observation next is [26.36666666666667, 87.33333333333333, 1.0, 2.0, 0.5096567978102957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712170.713913877, 712170.713913877, 185122.6269993627], 
processed observation next is [0.0, 0.08695652173913043, 0.4486571879936811, 0.8733333333333333, 1.0, 1.0, 0.4092250576027659, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19782519830941028, 0.19782519830941028, 0.27630242835725777], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.45460296], dtype=float32), -0.16678035]. 
=============================================
[2019-03-26 17:50:44,319] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4823280e-35 1.0000000e+00 7.9277595e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:44,327] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5041
[2019-03-26 17:50:44,333] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 80.33333333333333, 1.0, 2.0, 0.5109121195867617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713925.4316630303, 713925.431663031, 185323.6492722135], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5641800.0000, 
sim time next is 5642400.0000, 
raw observation next is [27.83333333333334, 79.66666666666667, 1.0, 2.0, 0.5134237457774172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717436.249416491, 717436.2494164916, 185726.2133214409], 
processed observation next is [0.0, 0.30434782608695654, 0.5181674565560824, 0.7966666666666667, 1.0, 1.0, 0.4137635491294183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19928784706013639, 0.19928784706013655, 0.2772033034648372], 
reward next is 0.7228, 
noisyNet noise sample is [array([0.2059221], dtype=float32), -0.4483099]. 
=============================================
[2019-03-26 17:50:45,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2599212e-34 1.0000000e+00 1.3512969e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:45,505] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1477
[2019-03-26 17:50:45,513] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 62.0, 1.0, 2.0, 0.5515476370620779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770728.261415984, 770728.261415984, 192066.9628499384], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5662800.0000, 
sim time next is 5663400.0000, 
raw observation next is [32.25, 61.66666666666667, 1.0, 2.0, 0.5633880387887035, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787280.0759132232, 787280.0759132232, 194122.8681325436], 
processed observation next is [0.0, 0.5652173913043478, 0.7274881516587678, 0.6166666666666667, 1.0, 1.0, 0.4739614925165102, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21868890997589532, 0.21868890997589532, 0.2897356240784233], 
reward next is 0.7103, 
noisyNet noise sample is [array([-1.1106596], dtype=float32), -0.7116659]. 
=============================================
[2019-03-26 17:50:50,842] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.6944212e-30 1.0000000e+00 1.8716333e-31 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:50,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-26 17:50:50,856] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.43333333333333, 83.33333333333334, 1.0, 2.0, 0.8754328606615432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1223583.621110263, 1223583.621110263, 263270.877240783], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5557200.0000, 
sim time next is 5557800.0000, 
raw observation next is [28.61666666666667, 82.66666666666667, 1.0, 2.0, 0.8653921654850423, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1209541.849792792, 1209541.849792792, 260597.1165747585], 
processed observation next is [1.0, 0.30434782608695654, 0.5552922590837285, 0.8266666666666667, 1.0, 1.0, 0.837821886126557, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.33598384716466445, 0.33598384716466445, 0.38895092026083355], 
reward next is 0.6110, 
noisyNet noise sample is [array([-0.13973615], dtype=float32), -2.2610602]. 
=============================================
[2019-03-26 17:50:57,611] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.2640729e-30 1.0000000e+00 2.0969275e-33 5.1199693e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 17:50:57,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7472
[2019-03-26 17:50:57,625] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.5443115827248639, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 760613.0365774072, 760613.0365774079, 190829.6614970489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5869200.0000, 
sim time next is 5869800.0000, 
raw observation next is [27.25, 87.5, 1.0, 2.0, 0.542161046907426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757606.837626292, 757606.837626292, 190465.1503829337], 
processed observation next is [1.0, 0.9565217391304348, 0.490521327014218, 0.875, 1.0, 1.0, 0.4483868035029228, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21044634378508112, 0.21044634378508112, 0.2842763438551249], 
reward next is 0.7157, 
noisyNet noise sample is [array([2.5846117], dtype=float32), -1.145813]. 
=============================================
[2019-03-26 17:50:58,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.358218e-30 1.000000e+00 7.382279e-34 1.968435e-37 0.000000e+00], sum to 1.0000
[2019-03-26 17:50:58,431] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0451
[2019-03-26 17:50:58,435] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.4, 65.0, 1.0, 2.0, 0.5245087571855964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732931.3112031848, 732931.3112031848, 187527.1367841043], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5594400.0000, 
sim time next is 5595000.0000, 
raw observation next is [31.11666666666667, 66.66666666666667, 1.0, 2.0, 0.5294437350616796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739829.6886895798, 739829.6886895798, 188339.5782874875], 
processed observation next is [1.0, 0.782608695652174, 0.6737756714060034, 0.6666666666666667, 1.0, 1.0, 0.4330647410381682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20550824685821661, 0.20550824685821661, 0.28110384819027984], 
reward next is 0.7189, 
noisyNet noise sample is [array([1.3844082], dtype=float32), -0.9169007]. 
=============================================
[2019-03-26 17:50:58,453] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[67.387505]
 [66.8925  ]
 [65.70514 ]
 [63.13377 ]
 [58.457066]], R is [[67.70061493]
 [67.74372101]
 [67.78873444]
 [67.83666992]
 [67.88724518]].
[2019-03-26 17:51:00,939] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 17:51:00,943] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:51:00,944] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:51:00,945] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:51:00,946] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:51:00,948] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:51:00,949] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:51:00,950] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:51:00,950] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:51:00,951] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:51:00,952] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:51:00,983] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run75
[2019-03-26 17:51:01,008] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run75
[2019-03-26 17:51:01,009] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run75
[2019-03-26 17:51:01,067] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run75
[2019-03-26 17:51:01,069] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run75
[2019-03-26 17:51:02,822] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:51:02,823] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.46666666666667, 67.0, 1.0, 2.0, 0.9025384816926337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1261491.379166497, 1261491.379166496, 270634.3311148396]
[2019-03-26 17:51:02,824] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:51:02,826] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1287626e-27 1.0000000e+00 3.0360275e-30 6.1833441e-34 2.5501246e-37], sampled 0.6732131579024478
[2019-03-26 17:51:14,050] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:51:14,050] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.36666666666667, 89.0, 1.0, 2.0, 0.3026761867764391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481203.8092262834, 481203.8092262834, 165695.3336316373]
[2019-03-26 17:51:14,051] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:51:14,056] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.0567183e-32 1.0000000e+00 2.7369845e-34 0.0000000e+00 0.0000000e+00], sampled 0.2921241633688605
[2019-03-26 17:51:53,098] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:51:53,099] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.71608857, 78.74639636, 1.0, 2.0, 0.5158855596107621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720877.4493954248, 720877.4493954248, 186121.8658280396]
[2019-03-26 17:51:53,101] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:51:53,105] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4437016e-30 1.0000000e+00 3.2575623e-33 7.0755539e-38 0.0000000e+00], sampled 0.6281211199899926
[2019-03-26 17:51:56,802] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:51:56,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 63.0, 1.0, 2.0, 1.012954679295406, 1.0, 2.0, 1.012954679295406, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2833586.500436506, 2833586.500436505, 536863.9947773037]
[2019-03-26 17:51:56,807] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:51:56,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.0047666e-12 1.0000000e+00 1.1307028e-18 8.4171328e-09 1.0977666e-21], sampled 0.5266423030685694
[2019-03-26 17:51:56,809] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2833586.500436506 W.
[2019-03-26 17:51:56,863] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:51:56,864] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.49859612, 62.36675254666667, 1.0, 2.0, 0.6374086734045835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 890760.0988395016, 890760.0988395016, 207915.2564987009]
[2019-03-26 17:51:56,866] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:51:56,867] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.836519e-32 1.000000e+00 1.037999e-33 0.000000e+00 0.000000e+00], sampled 0.9491744671018341
[2019-03-26 17:52:08,006] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:52:08,009] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.85, 61.5, 1.0, 2.0, 0.5877857902959164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 821386.7469897743, 821386.7469897737, 198491.5458650544]
[2019-03-26 17:52:08,011] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:52:08,015] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4702055e-31 1.0000000e+00 3.3081405e-34 0.0000000e+00 0.0000000e+00], sampled 0.2675759551082657
[2019-03-26 17:52:19,654] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:52:19,656] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.53333333333333, 77.66666666666667, 1.0, 2.0, 0.7105295020373541, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000685024592222, 6.9112, 168.9123510760065, 1889863.398655595, 1826379.869917735, 387149.9888249384]
[2019-03-26 17:52:19,657] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:52:19,660] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2230374e-19 1.0000000e+00 2.5001889e-23 6.3501454e-20 9.4707499e-28], sampled 0.19425174002092405
[2019-03-26 17:52:19,662] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1889863.398655595 W.
[2019-03-26 17:52:30,152] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:52:30,153] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.65, 91.16666666666667, 1.0, 2.0, 0.5363461140211148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749478.2803711395, 749478.2803711395, 189486.5991619451]
[2019-03-26 17:52:30,153] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:52:30,155] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.3434418e-30 1.0000000e+00 7.0859710e-33 2.6959148e-37 0.0000000e+00], sampled 0.05063023505327802
[2019-03-26 17:52:38,681] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01354946], dtype=float32), 0.10577081]
[2019-03-26 17:52:38,681] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.63333333333333, 86.83333333333333, 1.0, 2.0, 0.5122795829055696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715836.9067466138, 715836.9067466138, 185542.3660197811]
[2019-03-26 17:52:38,684] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:52:38,687] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.3654991e-32 1.0000000e+00 1.2412935e-34 0.0000000e+00 0.0000000e+00], sampled 0.39402176393939115
[2019-03-26 17:52:57,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 17:52:57,209] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2118 2927459259.5787 1338.0000
[2019-03-26 17:52:57,364] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 17:52:57,563] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 17:52:57,582] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 17:52:58,600] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1850000, evaluation results [1850000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8254.211789258557, 2927459259.5787225, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 17:52:59,495] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6277609e-32 1.0000000e+00 1.2977616e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:52:59,502] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0574
[2019-03-26 17:52:59,506] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.6, 67.0, 1.0, 2.0, 0.5343108440677539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746633.2392995686, 746633.239299568, 189146.6838414601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5680800.0000, 
sim time next is 5681400.0000, 
raw observation next is [30.36666666666667, 68.16666666666667, 1.0, 2.0, 0.5471835544208284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764627.7322469015, 764627.7322469022, 191318.1072345072], 
processed observation next is [0.0, 0.782608695652174, 0.6382306477093209, 0.6816666666666668, 1.0, 1.0, 0.4544380173744921, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21239659229080596, 0.21239659229080615, 0.28554941378284654], 
reward next is 0.7145, 
noisyNet noise sample is [array([1.4870213], dtype=float32), 0.013623164]. 
=============================================
[2019-03-26 17:52:59,511] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8554154e-14 1.0000000e+00 2.6990973e-20 8.8515376e-12 5.1336934e-24], sum to 1.0000
[2019-03-26 17:52:59,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5795
[2019-03-26 17:52:59,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2439249.427633308 W.
[2019-03-26 17:52:59,536] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.4, 79.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.130289309439858, 6.9112, 168.9117986806225, 2439249.427633308, 2283820.996450744, 475609.3180493296], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5936400.0000, 
sim time next is 5937000.0000, 
raw observation next is [30.3, 79.16666666666667, 1.0, 2.0, 0.4101865838888405, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7123584454387585, 6.911200000000001, 6.9112, 168.9127781185568, 1146585.696624556, 1146585.696624556, 264022.3730720503], 
processed observation next is [1.0, 0.7391304347826086, 0.6350710900473934, 0.7916666666666667, 1.0, 1.0, 0.28938142637209696, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6492176163887298, 8.881784197001253e-17, 0.0, 0.8294390691665321, 0.3184960268401545, 0.3184960268401545, 0.3940632433911198], 
reward next is 0.6059, 
noisyNet noise sample is [array([-1.0657736], dtype=float32), 0.02517152]. 
=============================================
[2019-03-26 17:52:59,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.72844 ]
 [48.562237]
 [47.95385 ]
 [47.554535]
 [48.02937 ]], R is [[56.10670471]
 [55.54563904]
 [55.36183167]
 [54.80821228]
 [54.5865593 ]].
[2019-03-26 17:53:00,691] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.6354233e-29 1.0000000e+00 1.8948580e-32 2.5640565e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 17:53:00,699] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9059
[2019-03-26 17:53:00,705] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.63333333333333, 90.33333333333333, 1.0, 2.0, 0.5301574870471409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740827.4133099086, 740827.4133099093, 188456.0373991262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5875800.0000, 
sim time next is 5876400.0000, 
raw observation next is [26.56666666666667, 90.66666666666667, 1.0, 2.0, 0.5315501682670467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742774.1879536851, 742774.1879536845, 188686.8297456057], 
processed observation next is [1.0, 0.0, 0.45813586097946307, 0.9066666666666667, 1.0, 1.0, 0.43560261236993575, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20632616332046808, 0.2063261633204679, 0.28162213394866525], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.41656163], dtype=float32), 1.230636]. 
=============================================
[2019-03-26 17:53:08,021] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.2068035e-25 1.0000000e+00 1.6538450e-27 1.6604484e-30 9.8524261e-34], sum to 1.0000
[2019-03-26 17:53:08,026] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0357
[2019-03-26 17:53:08,031] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 93.66666666666667, 1.0, 2.0, 0.8595539333973279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1201377.249518551, 1201377.24951855, 259053.2830891143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5805600.0000, 
sim time next is 5806200.0000, 
raw observation next is [25.95, 93.83333333333334, 1.0, 2.0, 0.8472554202854963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1184178.336783012, 1184178.336783011, 255839.8913648864], 
processed observation next is [1.0, 0.17391304347826086, 0.42890995260663506, 0.9383333333333335, 1.0, 1.0, 0.8159703858861401, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32893842688416997, 0.32893842688416974, 0.3818505841266961], 
reward next is 0.6181, 
noisyNet noise sample is [array([1.2763143], dtype=float32), 0.6421745]. 
=============================================
[2019-03-26 17:53:09,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1755143e-21 1.0000000e+00 2.2033777e-26 2.2014581e-22 3.1293303e-31], sum to 1.0000
[2019-03-26 17:53:09,058] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0871
[2019-03-26 17:53:09,063] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.6, 67.0, 1.0, 2.0, 0.5249805173124283, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564928207, 733590.7609439166, 733590.7609439173, 187605.9427649844], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5851200.0000, 
sim time next is 5851800.0000, 
raw observation next is [31.4, 68.0, 1.0, 2.0, 0.5145617171271465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104266, 719026.939793122, 719026.9397931226, 185913.1239536483], 
processed observation next is [1.0, 0.7391304347826086, 0.6872037914691943, 0.68, 1.0, 1.0, 0.41513459894836924, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.829439945152281, 0.19972970549808944, 0.1997297054980896, 0.27748227455768404], 
reward next is 0.7225, 
noisyNet noise sample is [array([-2.012476], dtype=float32), 0.34932157]. 
=============================================
[2019-03-26 17:53:11,421] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0731397e-27 1.0000000e+00 1.2512362e-31 2.0192280e-33 1.1768367e-38], sum to 1.0000
[2019-03-26 17:53:11,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9142
[2019-03-26 17:53:11,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 88.33333333333334, 1.0, 2.0, 0.5317020573634238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742986.5080006435, 742986.5080006435, 188712.1889039932], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5872200.0000, 
sim time next is 5872800.0000, 
raw observation next is [26.9, 88.66666666666667, 1.0, 2.0, 0.5308549561676368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741802.3776865877, 741802.3776865872, 188571.6623203371], 
processed observation next is [1.0, 1.0, 0.4739336492890995, 0.8866666666666667, 1.0, 1.0, 0.43476500743088764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20605621602405216, 0.206056216024052, 0.2814502422691599], 
reward next is 0.7185, 
noisyNet noise sample is [array([-1.1822703], dtype=float32), -1.2074084]. 
=============================================
[2019-03-26 17:53:16,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5674453e-13 1.0000000e+00 2.9436022e-18 1.3200808e-11 4.4640647e-22], sum to 1.0000
[2019-03-26 17:53:16,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9357
[2019-03-26 17:53:16,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1843651.514524098 W.
[2019-03-26 17:53:16,806] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.36666666666667, 77.33333333333334, 1.0, 2.0, 0.4395655438573535, 1.0, 1.0, 0.4395655438573535, 1.0, 2.0, 0.7529021230554955, 6.9112, 6.9112, 170.5573041426782, 1843651.514524098, 1843651.514524098, 374225.7830010339], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6600000.0000, 
sim time next is 6600600.0000, 
raw observation next is [28.55, 76.5, 1.0, 2.0, 0.6436177472025306, 1.0, 2.0, 0.6436177472025306, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1799629.196079942, 1799629.196079942, 350917.7057097977], 
processed observation next is [1.0, 0.391304347826087, 0.552132701421801, 0.765, 1.0, 1.0, 0.5706237918102779, 1.0, 1.0, 0.5706237918102779, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.49989699891109496, 0.49989699891109496, 0.523757769716116], 
reward next is 0.4762, 
noisyNet noise sample is [array([0.0669503], dtype=float32), 1.8467885]. 
=============================================
[2019-03-26 17:53:29,426] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.7915495e-28 1.0000000e+00 1.5569272e-31 7.0055011e-33 0.0000000e+00], sum to 1.0000
[2019-03-26 17:53:29,435] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5222
[2019-03-26 17:53:29,439] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 87.33333333333333, 1.0, 2.0, 0.5352399445195771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747931.999209393, 747931.9992093937, 189301.8224338974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6131400.0000, 
sim time next is 6132000.0000, 
raw observation next is [27.23333333333333, 87.66666666666667, 1.0, 2.0, 0.535146327582743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747801.1350051593, 747801.1350051587, 189286.2240246458], 
processed observation next is [1.0, 1.0, 0.4897314375987361, 0.8766666666666667, 1.0, 1.0, 0.4399353344370398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20772253750143313, 0.207722537501433, 0.28251675227559075], 
reward next is 0.7175, 
noisyNet noise sample is [array([-1.6635126], dtype=float32), -0.5218947]. 
=============================================
[2019-03-26 17:53:29,457] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[72.30669]
 [72.26721]
 [72.15222]
 [72.12688]
 [72.10862]], R is [[72.32230377]
 [72.31654358]
 [72.31069946]
 [72.30465698]
 [72.29854584]].
[2019-03-26 17:53:29,484] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.3462094e-10 9.9999440e-01 2.7150733e-16 5.6234098e-06 8.9020981e-19], sum to 1.0000
[2019-03-26 17:53:29,492] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2004
[2019-03-26 17:53:29,500] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2260667.593013022 W.
[2019-03-26 17:53:29,505] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.808331895963005, 1.0, 1.0, 0.808331895963005, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2260667.593013022, 2260667.593013022, 423941.6551845674], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6446400.0000, 
sim time next is 6447000.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.9752429282646454, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982014793231636, 6.9112, 168.9125350350256, 2260350.490436228, 2210112.164216734, 456639.8627402056], 
processed observation next is [1.0, 0.6086956521739131, 0.6208530805687204, 0.68, 1.0, 1.0, 0.9701722027284885, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007081479323163631, 0.0, 0.8294378755151098, 0.6278751362322855, 0.6139200456157594, 0.6815520339406054], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24399737], dtype=float32), 1.5323584]. 
=============================================
[2019-03-26 17:53:29,517] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[42.192566]
 [41.895344]
 [43.302044]
 [42.065285]
 [43.16972 ]], R is [[41.75664902]
 [41.33908463]
 [40.92569351]
 [40.88564682]
 [40.47679138]].
[2019-03-26 17:53:37,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.2373956e-26 1.0000000e+00 4.8111803e-29 2.3295264e-30 2.8179013e-36], sum to 1.0000
[2019-03-26 17:53:37,524] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4382
[2019-03-26 17:53:37,533] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 88.66666666666667, 1.0, 2.0, 0.5192630779451771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725598.6677585011, 725598.6677585011, 186669.2128722406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6569400.0000, 
sim time next is 6570000.0000, 
raw observation next is [26.5, 89.0, 1.0, 2.0, 0.5195887127387313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726053.8530634192, 726053.8530634185, 186722.0346897692], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.89, 1.0, 1.0, 0.4211912201671461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20168162585094979, 0.2016816258509496, 0.2786896040145809], 
reward next is 0.7213, 
noisyNet noise sample is [array([-1.364204], dtype=float32), 0.38893178]. 
=============================================
[2019-03-26 17:53:37,547] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[67.93295]
 [67.95851]
 [67.95382]
 [68.00272]
 [68.32181]], R is [[67.97322845]
 [68.01488495]
 [68.05619812]
 [68.09709167]
 [68.1375351 ]].
[2019-03-26 17:53:40,389] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5303605e-29 1.0000000e+00 2.3046513e-32 1.0467971e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:53:40,396] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5057
[2019-03-26 17:53:40,403] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 67.5, 1.0, 2.0, 0.5192269032085003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725548.1012805, 725548.1012805, 186663.2580894719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [29.6, 69.0, 1.0, 2.0, 0.5174312777073655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723038.1079451895, 723038.1079451895, 186372.1032476231], 
processed observation next is [0.0, 0.6956521739130435, 0.6018957345971565, 0.69, 1.0, 1.0, 0.41859190085224757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20084391887366373, 0.20084391887366373, 0.2781673182800345], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.3030796], dtype=float32), 0.40072876]. 
=============================================
[2019-03-26 17:53:41,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6214207e-27 1.0000000e+00 2.3341951e-31 4.1304856e-32 1.3702317e-37], sum to 1.0000
[2019-03-26 17:53:41,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4749
[2019-03-26 17:53:41,580] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.28333333333333, 85.00000000000001, 1.0, 2.0, 0.5161159084074503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721199.4386814024, 721199.4386814018, 186160.3090534493], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6631800.0000, 
sim time next is 6632400.0000, 
raw observation next is [27.26666666666667, 85.0, 1.0, 2.0, 0.518071380718566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723932.8674980478, 723932.8674980478, 186476.430714987], 
processed observation next is [1.0, 0.782608695652174, 0.4913112164297, 0.85, 1.0, 1.0, 0.419363109299477, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20109246319390217, 0.20109246319390217, 0.278323030917891], 
reward next is 0.7217, 
noisyNet noise sample is [array([0.4895569], dtype=float32), 0.8547178]. 
=============================================
[2019-03-26 17:53:43,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3215294e-26 1.0000000e+00 7.4625933e-30 2.6442117e-32 3.6433381e-37], sum to 1.0000
[2019-03-26 17:53:43,966] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9220
[2019-03-26 17:53:43,972] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.5135106425592673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717557.7162522693, 717557.7162522699, 185739.9079392068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6573600.0000, 
sim time next is 6574200.0000, 
raw observation next is [26.16666666666666, 90.16666666666667, 1.0, 2.0, 0.8706117203170282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216841.300810235, 1216841.300810236, 261979.8620683027], 
processed observation next is [1.0, 0.08695652173913043, 0.4391785150078987, 0.9016666666666667, 1.0, 1.0, 0.844110506406058, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3380114724472875, 0.3380114724472878, 0.3910147195049294], 
reward next is 0.6090, 
noisyNet noise sample is [array([0.68391144], dtype=float32), -0.49636027]. 
=============================================
[2019-03-26 17:53:44,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7512884e-29 1.0000000e+00 1.9955989e-31 2.2586745e-36 1.1369243e-37], sum to 1.0000
[2019-03-26 17:53:44,152] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1805
[2019-03-26 17:53:44,157] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 93.66666666666667, 1.0, 2.0, 0.6639687041702164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 927893.1840765299, 927893.1840765305, 213257.4504737729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6675000.0000, 
sim time next is 6675600.0000, 
raw observation next is [25.3, 93.33333333333334, 1.0, 2.0, 0.5781019979394263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807849.2241314964, 807849.2241314964, 196731.3767457523], 
processed observation next is [1.0, 0.2608695652173913, 0.39810426540284366, 0.9333333333333335, 1.0, 1.0, 0.4916891541438871, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.224402562258749, 0.224402562258749, 0.2936289205160482], 
reward next is 0.7064, 
noisyNet noise sample is [array([-0.0957403], dtype=float32), -0.5201235]. 
=============================================
[2019-03-26 17:53:54,654] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 17:53:54,655] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:53:54,656] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:53:54,657] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:54,657] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:53:54,659] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:53:54,659] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:54,660] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:54,658] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:53:54,662] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:54,665] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:53:54,682] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run76
[2019-03-26 17:53:54,709] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run76
[2019-03-26 17:53:54,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run76
[2019-03-26 17:53:54,732] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run76
[2019-03-26 17:53:54,783] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run76
[2019-03-26 17:54:06,889] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:54:06,891] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.45, 71.5, 1.0, 2.0, 0.4144614305345706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613710.1867136027, 613710.1867136027, 175683.9501985668]
[2019-03-26 17:54:06,894] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:06,896] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3683425e-29 1.0000000e+00 3.0108815e-32 5.3680620e-35 0.0000000e+00], sampled 0.5894508072038657
[2019-03-26 17:54:20,176] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:54:20,177] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.25, 99.0, 1.0, 2.0, 0.4681029145885947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 675971.529121182, 675971.5291211813, 181536.7750607812]
[2019-03-26 17:54:20,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:20,182] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2693953e-30 1.0000000e+00 6.2525367e-33 4.3673779e-38 0.0000000e+00], sampled 0.9033685482612506
[2019-03-26 17:54:28,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:54:28,225] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.28333333333333, 85.83333333333334, 1.0, 2.0, 0.4509763779643538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 667080.1530006353, 667080.1530006359, 180915.6580671027]
[2019-03-26 17:54:28,226] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:28,229] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0376313e-30 1.0000000e+00 1.5852799e-32 9.8971993e-37 0.0000000e+00], sampled 0.20103092354235064
[2019-03-26 17:54:51,068] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:54:51,070] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.77447453, 58.5429552, 1.0, 2.0, 0.5214295773871155, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8976512944300622, 6.911200000000001, 6.9112, 168.9127111787408, 1457754.317446583, 1457754.317446582, 318504.493991897]
[2019-03-26 17:54:51,073] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:54:51,076] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2824524e-19 1.0000000e+00 1.1978021e-23 2.4383581e-19 2.0040086e-28], sampled 0.008125228062991652
[2019-03-26 17:54:54,383] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:54:54,384] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.66666666666667, 58.33333333333334, 1.0, 2.0, 0.6080301507260163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 849688.0446379943, 849688.0446379943, 202251.8993186689]
[2019-03-26 17:54:54,385] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:54:54,387] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1815428e-29 1.0000000e+00 2.1173693e-32 4.6870904e-36 0.0000000e+00], sampled 0.9235562363142787
[2019-03-26 17:55:33,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:55:33,033] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.8, 85.33333333333334, 1.0, 2.0, 0.4462056919131142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649973.1892792701, 649973.1892792707, 178970.0262447787]
[2019-03-26 17:55:33,034] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 17:55:33,036] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2678385e-29 1.0000000e+00 3.1939842e-32 1.0275621e-34 0.0000000e+00], sampled 0.6042749794290653
[2019-03-26 17:55:42,699] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01595173], dtype=float32), 0.10665124]
[2019-03-26 17:55:42,700] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.57754268166667, 86.97448422333335, 1.0, 2.0, 0.4335107039708073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633652.9331200874, 633652.9331200874, 177395.1628056386]
[2019-03-26 17:55:42,702] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:55:42,704] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8242980e-32 1.0000000e+00 3.6484757e-34 0.0000000e+00 0.0000000e+00], sampled 0.2024883080267985
[2019-03-26 17:55:47,164] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.4862 2842492294.1625 1128.0000
[2019-03-26 17:55:47,239] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.9623 2779214753.4435 930.0000
[2019-03-26 17:55:47,637] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.7396 3007636034.9064 1764.0000
[2019-03-26 17:55:47,682] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7900.6504 3162270325.3910 1740.0000
[2019-03-26 17:55:47,775] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.9333 2927315404.2952 1336.0000
[2019-03-26 17:55:48,792] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1875000, evaluation results [1875000.0, 7900.650428809067, 3162270325.390973, 1740.0, 8255.933265025831, 2927315404.295249, 1336.0, 8661.962277310608, 2779214753.443548, 930.0, 8001.739560321358, 3007636034.9063563, 1764.0, 8498.486207739612, 2842492294.1624637, 1128.0]
[2019-03-26 17:55:50,507] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1091355e-25 1.0000000e+00 2.5508355e-29 1.5584465e-26 1.1934033e-34], sum to 1.0000
[2019-03-26 17:55:50,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7895
[2019-03-26 17:55:50,523] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 76.0, 1.0, 2.0, 0.4706989770548355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657716.0137445311, 657716.0137445311, 179133.26588439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7063200.0000, 
sim time next is 7063800.0000, 
raw observation next is [27.48333333333333, 76.66666666666667, 1.0, 2.0, 0.4743345089592749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662797.591599204, 662797.591599204, 179673.0550941164], 
processed observation next is [1.0, 0.782608695652174, 0.5015797788309636, 0.7666666666666667, 1.0, 1.0, 0.3666680830834638, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18411044211089, 0.18411044211089, 0.2681687389464424], 
reward next is 0.7318, 
noisyNet noise sample is [array([-0.17030239], dtype=float32), -0.8718433]. 
=============================================
[2019-03-26 17:55:53,420] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3175814e-27 1.0000000e+00 6.7849256e-30 2.5476821e-31 2.5103504e-36], sum to 1.0000
[2019-03-26 17:55:53,430] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1490
[2019-03-26 17:55:53,435] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 92.33333333333334, 1.0, 2.0, 0.4948652071567946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691494.9054366194, 691494.9054366194, 182795.4937304375], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6657000.0000, 
sim time next is 6657600.0000, 
raw observation next is [25.36666666666667, 92.66666666666667, 1.0, 2.0, 0.494836743597242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691455.1192242103, 691455.1192242103, 182791.027977962], 
processed observation next is [1.0, 0.043478260869565216, 0.40126382306477115, 0.9266666666666667, 1.0, 1.0, 0.3913695705990868, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19207086645116953, 0.19207086645116953, 0.2728224298178537], 
reward next is 0.7272, 
noisyNet noise sample is [array([-0.70998454], dtype=float32), -0.37216368]. 
=============================================
[2019-03-26 17:55:56,779] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4367882e-25 1.0000000e+00 3.5278119e-29 1.4579249e-30 1.1115259e-34], sum to 1.0000
[2019-03-26 17:55:56,791] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1515
[2019-03-26 17:55:56,797] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.95, 81.5, 1.0, 2.0, 0.4568281602864971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650143.7942152263, 650143.7942152263, 178629.3499898101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7003800.0000, 
sim time next is 7004400.0000, 
raw observation next is [25.9, 82.0, 1.0, 2.0, 0.4577543287379321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 650813.4133146324, 650813.413314633, 178682.7072981246], 
processed observation next is [1.0, 0.043478260869565216, 0.42654028436018954, 0.82, 1.0, 1.0, 0.3466919623348579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18078150369850898, 0.18078150369850915, 0.26669060790764865], 
reward next is 0.7333, 
noisyNet noise sample is [array([-0.6571582], dtype=float32), -0.9111659]. 
=============================================
[2019-03-26 17:56:02,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.5068865e-32 1.0000000e+00 2.9153727e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 17:56:02,998] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8956
[2019-03-26 17:56:03,005] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.66666666666667, 1.0, 2.0, 0.4169826035801141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613833.7400076356, 613833.7400076349, 175596.5747421358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6927600.0000, 
sim time next is 6928200.0000, 
raw observation next is [23.75, 91.0, 1.0, 2.0, 0.4167690655225633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613665.0841539429, 613665.0841539429, 175584.6354077567], 
processed observation next is [0.0, 0.17391304347826086, 0.3246445497630332, 0.91, 1.0, 1.0, 0.29731212713561844, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17046252337609524, 0.17046252337609524, 0.26206662001157716], 
reward next is 0.7379, 
noisyNet noise sample is [array([0.67283547], dtype=float32), -1.4810601]. 
=============================================
[2019-03-26 17:56:06,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.4151064e-21 1.0000000e+00 2.2279477e-26 1.7171312e-19 5.4149241e-31], sum to 1.0000
[2019-03-26 17:56:06,527] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5286
[2019-03-26 17:56:06,532] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 73.5, 1.0, 2.0, 0.4505744976238668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 629587.3895932087, 629587.3895932081, 176215.9289444848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7061400.0000, 
sim time next is 7062000.0000, 
raw observation next is [27.86666666666667, 74.33333333333333, 1.0, 2.0, 0.4605019313745764, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 643463.1860064131, 643463.1860064125, 177640.0654665236], 
processed observation next is [1.0, 0.7391304347826086, 0.519747235387046, 0.7433333333333333, 1.0, 1.0, 0.3500023269573209, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1787397738906703, 0.17873977389067014, 0.2651344260694382], 
reward next is 0.7349, 
noisyNet noise sample is [array([-1.652313], dtype=float32), -0.2907651]. 
=============================================
[2019-03-26 17:56:06,550] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.87766 ]
 [67.29321 ]
 [61.26177 ]
 [54.53484 ]
 [54.549347]], R is [[72.0987854 ]
 [72.11479187]
 [71.39364624]
 [71.34269714]
 [71.08504486]].
[2019-03-26 17:56:07,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.3697643e-30 1.0000000e+00 8.6385699e-33 2.0904788e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:56:07,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6675
[2019-03-26 17:56:07,147] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 59.83333333333334, 1.0, 2.0, 0.3651673809196034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557958.4867546587, 557958.4867546587, 171189.7000053049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6894600.0000, 
sim time next is 6895200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 1.0, 2.0, 0.3659445231085839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 558768.4986753551, 558768.4986753558, 171247.8002511893], 
processed observation next is [0.0, 0.8260869565217391, 0.4944707740916275, 0.6066666666666667, 1.0, 1.0, 0.2360777386850408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15521347185426532, 0.1552134718542655, 0.255593731718193], 
reward next is 0.7444, 
noisyNet noise sample is [array([0.11267811], dtype=float32), -1.4898298]. 
=============================================
[2019-03-26 17:56:09,570] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1967368e-27 1.0000000e+00 1.6973625e-30 7.5054662e-32 3.7191385e-37], sum to 1.0000
[2019-03-26 17:56:09,577] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0618
[2019-03-26 17:56:09,583] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 89.66666666666666, 1.0, 2.0, 0.4826771398221034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 674458.6259223645, 674458.6259223652, 180926.3670615676], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7595400.0000, 
sim time next is 7596000.0000, 
raw observation next is [25.4, 90.0, 1.0, 2.0, 0.4827560712536802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674568.9540967228, 674568.9540967228, 180938.2768481406], 
processed observation next is [0.0, 0.9565217391304348, 0.4028436018957346, 0.9, 1.0, 1.0, 0.3768145436791328, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18738026502686744, 0.18738026502686744, 0.27005712962409045], 
reward next is 0.7299, 
noisyNet noise sample is [array([0.20661433], dtype=float32), 1.1128671]. 
=============================================
[2019-03-26 17:56:09,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[73.41743 ]
 [73.38383 ]
 [73.33161 ]
 [73.285614]
 [73.251755]], R is [[73.51218414]
 [73.50701904]
 [73.50185394]
 [73.49648285]
 [73.49074554]].
[2019-03-26 17:56:12,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5357866e-30 1.0000000e+00 1.0819581e-32 9.4368118e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:56:12,449] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0482
[2019-03-26 17:56:12,458] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 55.0, 1.0, 2.0, 0.3801386057698529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575676.5679285721, 575676.5679285721, 172582.4786308239], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6984000.0000, 
sim time next is 6984600.0000, 
raw observation next is [28.58333333333334, 56.16666666666667, 1.0, 2.0, 0.3787869744852119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572972.2634874393, 572972.2634874393, 172323.9844759611], 
processed observation next is [0.0, 0.8695652173913043, 0.5537124802527649, 0.5616666666666668, 1.0, 1.0, 0.25155057166893, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15915896207984423, 0.15915896207984423, 0.2571999768297927], 
reward next is 0.7428, 
noisyNet noise sample is [array([1.0823565], dtype=float32), -0.3133243]. 
=============================================
[2019-03-26 17:56:32,315] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:56:32,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:32,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run10
[2019-03-26 17:56:34,865] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5452976e-27 1.0000000e+00 2.3910263e-31 7.0501648e-33 0.0000000e+00], sum to 1.0000
[2019-03-26 17:56:34,876] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-26 17:56:34,883] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 69.0, 1.0, 2.0, 0.3908386473102726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 585495.8023767654, 585495.8023767654, 173276.329776291], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7324800.0000, 
sim time next is 7325400.0000, 
raw observation next is [26.4, 69.5, 1.0, 2.0, 0.3891532766210155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583257.8294127703, 583257.8294127703, 173082.2079879798], 
processed observation next is [1.0, 0.782608695652174, 0.45023696682464454, 0.695, 1.0, 1.0, 0.2640400923144765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16201606372576954, 0.16201606372576954, 0.2583316537134027], 
reward next is 0.7417, 
noisyNet noise sample is [array([0.2149758], dtype=float32), 0.2228191]. 
=============================================
[2019-03-26 17:56:40,064] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.041648e-32 1.000000e+00 2.280678e-33 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 17:56:40,072] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5070
[2019-03-26 17:56:40,078] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 90.0, 1.0, 2.0, 0.3786747759208431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569430.3873835728, 569430.3873835728, 171906.6431254898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7538400.0000, 
sim time next is 7539000.0000, 
raw observation next is [23.33333333333334, 90.0, 1.0, 2.0, 0.3805791359382132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 571559.6915575337, 571559.6915575344, 172071.3743986867], 
processed observation next is [0.0, 0.2608695652173913, 0.3048973143759877, 0.9, 1.0, 1.0, 0.25370980233519663, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15876658098820381, 0.158766580988204, 0.2568229468637115], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.13252035], dtype=float32), 0.98487693]. 
=============================================
[2019-03-26 17:56:40,102] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.96222]
 [73.90481]
 [73.91777]
 [73.91856]
 [73.92796]], R is [[73.94691467]
 [73.9508667 ]
 [73.95508575]
 [73.95948792]
 [73.96396637]].
[2019-03-26 17:56:42,839] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5862322e-25 1.0000000e+00 3.6931121e-29 1.7944572e-28 8.9429822e-36], sum to 1.0000
[2019-03-26 17:56:42,848] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1021
[2019-03-26 17:56:42,851] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 89.0, 1.0, 2.0, 0.5255363923189079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734367.7911673023, 734367.791167303, 187693.8481186313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7768800.0000, 
sim time next is 7769400.0000, 
raw observation next is [26.65, 89.33333333333334, 1.0, 2.0, 0.5249685783710689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733574.0720935244, 733574.0720935238, 187600.6626257591], 
processed observation next is [1.0, 0.9565217391304348, 0.462085308056872, 0.8933333333333334, 1.0, 1.0, 0.42767298598923964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20377057558153455, 0.20377057558153439, 0.2800009889936703], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.462647], dtype=float32), -1.0895237]. 
=============================================
[2019-03-26 17:56:44,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:56:44,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,207] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run10
[2019-03-26 17:56:44,236] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 17:56:44,240] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:56:44,241] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,242] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:56:44,244] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,246] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:56:44,248] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:56:44,249] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:56:44,250] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,249] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,249] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:56:44,273] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run77
[2019-03-26 17:56:44,299] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run77
[2019-03-26 17:56:44,299] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run77
[2019-03-26 17:56:44,336] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run77
[2019-03-26 17:56:44,336] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run77
[2019-03-26 17:56:46,633] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:56:46,635] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.72495860833333, 95.08303198833333, 1.0, 2.0, 0.402971445052589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 604203.7927797982, 604203.7927797989, 175002.485150904]
[2019-03-26 17:56:46,636] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:56:46,639] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.1467740e-27 1.0000000e+00 2.1417421e-30 7.0363620e-31 1.0300728e-36], sampled 0.6540951009784077
[2019-03-26 17:56:49,644] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:56:49,645] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.66666666666667, 76.0, 1.0, 2.0, 0.3164178053903801, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497159.1405195004, 497159.140519501, 166739.9996131021]
[2019-03-26 17:56:49,646] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:56:49,648] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1948891e-30 1.0000000e+00 1.6768439e-32 4.5785640e-37 0.0000000e+00], sampled 0.9393294155740577
[2019-03-26 17:56:57,487] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:56:57,489] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.37848423, 72.496716765, 1.0, 2.0, 0.2805144570988937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455185.9716197714, 455185.9716197708, 163923.6672804483]
[2019-03-26 17:56:57,491] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:56:57,494] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8185550e-30 1.0000000e+00 1.7344338e-32 5.0860978e-37 0.0000000e+00], sampled 0.6155952277480464
[2019-03-26 17:57:12,174] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:57:12,175] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.31719763, 97.83414298666666, 1.0, 2.0, 0.3614073897908684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 559308.044404267, 559308.044404267, 171495.9161147969]
[2019-03-26 17:57:12,176] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:57:12,184] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6942219e-27 1.0000000e+00 1.0841738e-30 1.1882221e-31 4.8379572e-37], sampled 0.07000695217200503
[2019-03-26 17:57:36,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:57:36,714] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.43899971666667, 85.42095266333334, 1.0, 2.0, 0.7951834624139631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1111361.15232688, 1111361.152326879, 242737.1424504962]
[2019-03-26 17:57:36,715] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:57:36,718] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.9193931e-27 1.0000000e+00 3.1003885e-29 1.1715906e-32 1.3754910e-35], sampled 0.4869281479052635
[2019-03-26 17:57:58,722] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:57:58,723] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.77315381333333, 88.73323769, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.975136424700453, 6.9112, 168.9123687312492, 1499144.53330819, 1453785.990941874, 311347.3045789138]
[2019-03-26 17:57:58,726] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:57:58,730] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0156759e-19 1.0000000e+00 8.6233651e-24 2.2329064e-20 1.8792124e-28], sampled 0.27857285260914066
[2019-03-26 17:58:01,934] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:58:01,935] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.113227735, 81.41554558166666, 1.0, 2.0, 0.4648717596695782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661542.9532444252, 661542.9532444252, 179813.8538576299]
[2019-03-26 17:58:01,939] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 17:58:01,941] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.5118116e-26 1.0000000e+00 3.1704514e-29 2.0682843e-29 2.3527132e-35], sampled 0.7776223307251366
[2019-03-26 17:58:22,470] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:58:22,471] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.1, 94.0, 1.0, 2.0, 0.4932284750188914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 689207.0923656292, 689207.0923656285, 182541.7730666905]
[2019-03-26 17:58:22,472] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:58:22,476] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8087784e-27 1.0000000e+00 3.3668637e-30 6.1934070e-32 1.1980364e-36], sampled 0.39376659902900435
[2019-03-26 17:58:24,980] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01554419], dtype=float32), 0.1070624]
[2019-03-26 17:58:24,982] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.13333333333333, 80.66666666666667, 1.0, 2.0, 0.3321118661138523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519975.3937631316, 519975.3937631322, 168442.7892429112]
[2019-03-26 17:58:24,984] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:58:24,987] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.2648425e-30 1.0000000e+00 3.3666546e-32 3.4248606e-36 0.0000000e+00], sampled 0.29304618515959
[2019-03-26 17:58:40,679] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8268.4565 2926281284.5493 1310.0000
[2019-03-26 17:58:40,801] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7937.0925 3159220023.0151 1653.0000
[2019-03-26 17:58:41,330] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8513.4375 2841205087.1760 1097.0000
[2019-03-26 17:58:41,357] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8019.6237 3005606738.7615 1716.0000
[2019-03-26 17:58:41,369] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.8369 2778615853.6738 916.0000
[2019-03-26 17:58:42,385] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1900000, evaluation results [1900000.0, 7937.092464458242, 3159220023.0150867, 1653.0, 8268.456486980887, 2926281284.549318, 1310.0, 8667.836946937492, 2778615853.67381, 916.0, 8019.623690944017, 3005606738.7615385, 1716.0, 8513.437460152336, 2841205087.175983, 1097.0]
[2019-03-26 17:58:42,847] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4796191e-30 1.0000000e+00 6.6961808e-33 2.5457591e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:58:42,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7893
[2019-03-26 17:58:42,858] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 85.0, 1.0, 2.0, 0.419905837964151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 609759.0852984514, 609759.0852984514, 174965.8218824987], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7548600.0000, 
sim time next is 7549200.0000, 
raw observation next is [25.2, 84.0, 1.0, 2.0, 0.4237843468856708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613192.212126483, 613192.212126483, 175229.2722180709], 
processed observation next is [0.0, 0.391304347826087, 0.3933649289099526, 0.84, 1.0, 1.0, 0.30576427335622985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17033117003513415, 0.17033117003513415, 0.2615362271911506], 
reward next is 0.7385, 
noisyNet noise sample is [array([2.0216212], dtype=float32), 0.38021356]. 
=============================================
[2019-03-26 17:58:48,747] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7092432e-08 5.3155822e-01 6.5752706e-16 4.6844178e-01 3.3115028e-17], sum to 1.0000
[2019-03-26 17:58:48,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6493
[2019-03-26 17:58:48,765] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.13333333333333, 60.66666666666667, 1.0, 2.0, 0.8494594834741939, 1.0, 2.0, 0.8494594834741939, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2375798.744960048, 2375798.744960048, 444659.1403674427], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7746000.0000, 
sim time next is 7746600.0000, 
raw observation next is [31.01666666666667, 60.83333333333334, 1.0, 2.0, 0.8397585829309557, 1.0, 2.0, 0.8397585829309557, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2348641.422216945, 2348641.422216945, 439681.9462705003], 
processed observation next is [1.0, 0.6521739130434783, 0.6690363349131123, 0.6083333333333334, 1.0, 1.0, 0.8069380517240431, 1.0, 1.0, 0.8069380517240431, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6524003950602625, 0.6524003950602625, 0.656241710851493], 
reward next is 0.3438, 
noisyNet noise sample is [array([-1.1874567], dtype=float32), 0.622666]. 
=============================================
[2019-03-26 17:58:51,931] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:58:51,932] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:52,009] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run10
[2019-03-26 17:58:52,337] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:58:52,338] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:52,387] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run10
[2019-03-26 17:58:56,298] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:58:56,299] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:56,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run10
[2019-03-26 17:58:57,491] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [0.02064647 0.29108128 0.00111308 0.68588686 0.0012723 ], sum to 1.0000
[2019-03-26 17:58:57,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2088
[2019-03-26 17:58:57,509] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.25, 86.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 492964.1386797937, 492964.1386797937, 231911.0109609807], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1800.0000, 
sim time next is 2400.0000, 
raw observation next is [20.9, 85.66666666666667, 1.0, 2.0, 0.2947429798145724, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474714.548354781, 474714.548354781, 165288.3789456236], 
processed observation next is [1.0, 0.0, 0.1895734597156398, 0.8566666666666667, 1.0, 1.0, 0.15029274676454507, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1318651523207725, 0.1318651523207725, 0.24669907305316957], 
reward next is 0.7533, 
noisyNet noise sample is [array([0.05565041], dtype=float32), -0.51956815]. 
=============================================
[2019-03-26 17:58:57,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:58:57,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:58:57,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run10
[2019-03-26 17:59:00,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:00,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:00,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run10
[2019-03-26 17:59:01,388] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:01,389] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:01,441] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run10
[2019-03-26 17:59:02,064] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:02,064] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:02,137] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run10
[2019-03-26 17:59:05,609] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:05,610] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:05,679] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run10
[2019-03-26 17:59:06,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:06,295] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:06,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:06,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:06,377] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run10
[2019-03-26 17:59:06,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run10
[2019-03-26 17:59:06,510] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:06,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:06,558] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run10
[2019-03-26 17:59:06,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:06,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:06,973] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run10
[2019-03-26 17:59:07,023] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.2753978e-25 1.0000000e+00 4.6786419e-28 1.7309268e-29 1.8834553e-34], sum to 1.0000
[2019-03-26 17:59:07,026] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2875
[2019-03-26 17:59:07,032] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.93333333333333, 91.66666666666666, 1.0, 2.0, 0.6899812295964433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1041901.524199216, 1041901.524199216, 228628.4966481672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 117600.0000, 
sim time next is 118200.0000, 
raw observation next is [22.91666666666666, 91.83333333333333, 1.0, 2.0, 0.6901428479089019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1041999.03035852, 1041999.03035852, 228648.5417650107], 
processed observation next is [1.0, 0.34782608695652173, 0.2851500789889413, 0.9183333333333333, 1.0, 1.0, 0.6266781300107251, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28944417509958886, 0.28944417509958886, 0.34126648024628464], 
reward next is 0.6587, 
noisyNet noise sample is [array([-0.50388974], dtype=float32), 1.4211534]. 
=============================================
[2019-03-26 17:59:07,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:07,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:07,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run10
[2019-03-26 17:59:07,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 17:59:07,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:07,719] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run10
[2019-03-26 17:59:11,140] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2790825e-31 1.0000000e+00 4.3723398e-33 6.1011840e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 17:59:11,150] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3770
[2019-03-26 17:59:11,156] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.76666666666667, 92.33333333333333, 1.0, 2.0, 0.3016456660709038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481606.5066932109, 481606.5066932116, 165753.8694256359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 211200.0000, 
sim time next is 211800.0000, 
raw observation next is [20.78333333333333, 92.16666666666667, 1.0, 2.0, 0.3010305345907621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480659.1345238702, 480659.1345238708, 165686.503816592], 
processed observation next is [0.0, 0.43478260869565216, 0.18404423380726695, 0.9216666666666667, 1.0, 1.0, 0.15786811396477363, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1335164262566306, 0.13351642625663077, 0.24729328927849553], 
reward next is 0.7527, 
noisyNet noise sample is [array([1.4569712], dtype=float32), -0.3168645]. 
=============================================
[2019-03-26 17:59:12,204] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.6792770e-30 1.0000000e+00 1.5297219e-32 3.6360507e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 17:59:12,216] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8364
[2019-03-26 17:59:12,223] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333333, 90.66666666666667, 1.0, 2.0, 0.3043012910266282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 484301.3616666102, 484301.3616666108, 165926.8352959028], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 214800.0000, 
sim time next is 215400.0000, 
raw observation next is [21.21666666666667, 90.33333333333333, 1.0, 2.0, 0.3056395780180961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 485981.2259200464, 485981.225920047, 166041.3180243992], 
processed observation next is [0.0, 0.4782608695652174, 0.20458135860979476, 0.9033333333333333, 1.0, 1.0, 0.16342117833505554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13499478497779066, 0.13499478497779085, 0.24782286272298387], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.2320392], dtype=float32), -1.422696]. 
=============================================
[2019-03-26 17:59:13,095] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9133864e-24 1.0000000e+00 2.3066966e-28 1.3330608e-26 2.0815050e-34], sum to 1.0000
[2019-03-26 17:59:13,104] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9837
[2019-03-26 17:59:13,113] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 89.0, 1.0, 2.0, 0.3446370056566652, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535723.0073958393, 535723.0073958393, 169602.3903136275], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 89400.0000, 
sim time next is 90000.0000, 
raw observation next is [22.3, 89.0, 1.0, 2.0, 0.3439598067111493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534671.6033206601, 534671.6033206594, 169517.3064282207], 
processed observation next is [1.0, 0.043478260869565216, 0.25592417061611383, 0.89, 1.0, 1.0, 0.20959012856764975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14851988981129446, 0.14851988981129427, 0.25301090511674734], 
reward next is 0.7470, 
noisyNet noise sample is [array([1.693539], dtype=float32), -0.5178112]. 
=============================================
[2019-03-26 17:59:13,135] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.780235]
 [73.877785]
 [73.97345 ]
 [74.12746 ]
 [74.55882 ]], R is [[73.75183868]
 [73.76118469]
 [73.77037811]
 [73.77953339]
 [73.78859711]].
[2019-03-26 17:59:16,053] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1568323e-26 1.0000000e+00 6.9514750e-29 6.0993537e-28 1.1152842e-35], sum to 1.0000
[2019-03-26 17:59:16,065] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-26 17:59:16,070] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.18333333333333, 61.33333333333333, 1.0, 2.0, 0.2504187298447559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412273.4695163005, 412273.4695163011, 160939.509386387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 670200.0000, 
sim time next is 670800.0000, 
raw observation next is [22.96666666666667, 62.66666666666667, 1.0, 2.0, 0.2497542569032178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 411159.580403137, 411159.5804031377, 160874.469992949], 
processed observation next is [1.0, 0.782608695652174, 0.2875197472353872, 0.6266666666666667, 1.0, 1.0, 0.09608946614845515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11421099455642696, 0.11421099455642715, 0.24011114924320745], 
reward next is 0.7599, 
noisyNet noise sample is [array([-0.91617984], dtype=float32), -0.98622364]. 
=============================================
[2019-03-26 17:59:23,084] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3864841e-27 1.0000000e+00 1.4527619e-30 3.2349287e-31 4.2310241e-37], sum to 1.0000
[2019-03-26 17:59:23,095] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-26 17:59:23,103] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.8, 90.5, 1.0, 2.0, 0.2907289948954743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465958.3967604042, 465958.3967604042, 164670.8623561137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 250200.0000, 
sim time next is 250800.0000, 
raw observation next is [20.76666666666667, 90.66666666666667, 1.0, 2.0, 0.2943811953996872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471934.3171387933, 471934.3171387933, 165087.7251199895], 
processed observation next is [0.0, 0.9130434782608695, 0.18325434439178534, 0.9066666666666667, 1.0, 1.0, 0.149856861927334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13109286587188704, 0.13109286587188704, 0.24639958973132764], 
reward next is 0.7536, 
noisyNet noise sample is [array([0.9934222], dtype=float32), -0.5019044]. 
=============================================
[2019-03-26 17:59:30,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.31054705e-26 1.00000000e+00 3.01494312e-29 3.80733442e-30
 1.01355824e-35], sum to 1.0000
[2019-03-26 17:59:30,102] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-26 17:59:30,107] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 72.0, 1.0, 2.0, 0.467161369936644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760201.3799058652, 760201.3799058646, 189919.8213142541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385200.0000, 
sim time next is 385800.0000, 
raw observation next is [22.43333333333333, 72.16666666666667, 1.0, 2.0, 0.4887070843447773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794751.4259406975, 794751.4259406975, 193622.5392612843], 
processed observation next is [1.0, 0.4782608695652174, 0.2622432859399683, 0.7216666666666667, 1.0, 1.0, 0.38398443896961115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2207642849835271, 0.2207642849835271, 0.28898886456908107], 
reward next is 0.7110, 
noisyNet noise sample is [array([-0.53246117], dtype=float32), 0.91225696]. 
=============================================
[2019-03-26 17:59:30,507] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0673755e-26 1.0000000e+00 5.5207790e-30 2.0192542e-30 5.4552778e-36], sum to 1.0000
[2019-03-26 17:59:30,513] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-26 17:59:30,522] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 73.0, 1.0, 2.0, 0.3120328401531444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504413.3474573876, 504413.3474573876, 167408.9133559373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.3208786493000252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518560.6218782662, 518560.6218782662, 168467.3340876571], 
processed observation next is [1.0, 0.5652173913043478, 0.27488151658767773, 0.73, 1.0, 1.0, 0.18178150518075323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14404461718840728, 0.14404461718840728, 0.2514437822203837], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.9417604], dtype=float32), -1.5427321]. 
=============================================
[2019-03-26 17:59:33,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9355297e-23 1.0000000e+00 2.3408163e-27 1.1832321e-25 4.7687270e-32], sum to 1.0000
[2019-03-26 17:59:33,216] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0717
[2019-03-26 17:59:33,223] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.66666666666667, 48.66666666666666, 1.0, 2.0, 0.5705225740678224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 937448.0702151209, 937448.0702151209, 209427.0785945094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 744000.0000, 
sim time next is 744600.0000, 
raw observation next is [25.58333333333333, 48.83333333333334, 1.0, 2.0, 0.5706191838045479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 938096.8019000163, 938096.8019000157, 209447.1767618534], 
processed observation next is [1.0, 0.6086956521739131, 0.41153238546603454, 0.48833333333333345, 1.0, 1.0, 0.48267371542716614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2605824449722267, 0.2605824449722266, 0.31260772651022894], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.4188535], dtype=float32), 0.51589715]. 
=============================================
[2019-03-26 17:59:36,114] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 17:59:36,121] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 17:59:36,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:36,123] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 17:59:36,124] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 17:59:36,125] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:36,126] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:36,125] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 17:59:36,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 17:59:36,130] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:36,131] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 17:59:36,155] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run78
[2019-03-26 17:59:36,181] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run78
[2019-03-26 17:59:36,206] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run78
[2019-03-26 17:59:36,237] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run78
[2019-03-26 17:59:36,238] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run78
[2019-03-26 17:59:52,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01784459], dtype=float32), 0.11498894]
[2019-03-26 17:59:52,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.279465275, 91.61260001, 1.0, 2.0, 0.356715570475485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548487.5837591827, 548487.5837591827, 170490.8342806059]
[2019-03-26 17:59:52,475] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 17:59:52,479] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0956266e-30 1.0000000e+00 2.0659548e-32 5.0143176e-37 0.0000000e+00], sampled 0.22193200581336103
[2019-03-26 17:59:59,023] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01784459], dtype=float32), 0.11498894]
[2019-03-26 17:59:59,024] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.2, 53.33333333333334, 1.0, 2.0, 0.3717713452669654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561023.7390579762, 561023.7390579769, 171235.8826332963]
[2019-03-26 17:59:59,026] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 17:59:59,027] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0470601e-29 1.0000000e+00 7.2159543e-32 7.5777256e-34 6.5221856e-38], sampled 0.04761079911730792
[2019-03-26 18:00:00,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01784459], dtype=float32), 0.11498894]
[2019-03-26 18:00:00,838] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.55, 83.0, 1.0, 2.0, 0.4482939238261501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 666977.9242965096, 666977.9242965089, 180973.5311710705]
[2019-03-26 18:00:00,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:00:00,843] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.6271243e-29 1.0000000e+00 1.2826295e-31 1.1987508e-34 7.1099154e-38], sampled 0.8310450240914964
[2019-03-26 18:01:14,286] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01784459], dtype=float32), 0.11498894]
[2019-03-26 18:01:14,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.20660214833333, 62.72465077666667, 1.0, 2.0, 0.8342386826763112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1165975.32313065, 1165975.323130651, 252485.9728368468]
[2019-03-26 18:01:14,288] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:01:14,291] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2793237e-24 1.0000000e+00 1.7618995e-27 1.7128531e-26 4.4809812e-33], sampled 0.9196184588041608
[2019-03-26 18:01:31,815] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7957.8900 3157284455.5820 1599.0000
[2019-03-26 18:01:32,074] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8673.3896 2778163044.6041 904.0000
[2019-03-26 18:01:32,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8275.6819 2925607098.7838 1295.0000
[2019-03-26 18:01:32,625] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8031.5202 3004295395.0494 1683.0000
[2019-03-26 18:01:32,676] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8515.9799 2840773902.5067 1086.0000
[2019-03-26 18:01:33,692] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1925000, evaluation results [1925000.0, 7957.889979286484, 3157284455.58199, 1599.0, 8275.681865772114, 2925607098.78384, 1295.0, 8673.389571711972, 2778163044.6041045, 904.0, 8031.520247824904, 3004295395.0493917, 1683.0, 8515.979882110734, 2840773902.506654, 1086.0]
[2019-03-26 18:01:38,644] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.8748757e-26 1.0000000e+00 2.1958728e-29 9.3139872e-31 2.0476938e-35], sum to 1.0000
[2019-03-26 18:01:38,651] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2141
[2019-03-26 18:01:38,654] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 64.5, 1.0, 2.0, 0.4529028689701042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745795.1515899012, 745795.1515899012, 187695.6014266481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 555000.0000, 
sim time next is 555600.0000, 
raw observation next is [22.83333333333333, 63.00000000000001, 1.0, 2.0, 0.4305719741467672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709213.5452492372, 709213.5452492366, 184102.8378267748], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115322, 0.6300000000000001, 1.0, 1.0, 0.31394213752622546, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19700376256923255, 0.1970037625692324, 0.27478035496533554], 
reward next is 0.7252, 
noisyNet noise sample is [array([-0.30267537], dtype=float32), -0.272219]. 
=============================================
[2019-03-26 18:01:43,716] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7031223e-26 1.0000000e+00 3.0521686e-30 1.8944055e-29 1.1760391e-36], sum to 1.0000
[2019-03-26 18:01:43,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4957
[2019-03-26 18:01:43,732] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.45, 73.5, 1.0, 2.0, 0.2509682782545777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412607.3434961428, 412607.3434961434, 161003.1870389815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 761400.0000, 
sim time next is 762000.0000, 
raw observation next is [21.23333333333333, 75.33333333333333, 1.0, 2.0, 0.2516731837169294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 413551.2212386939, 413551.2212386939, 161074.9106078469], 
processed observation next is [1.0, 0.8260869565217391, 0.2053712480252764, 0.7533333333333333, 1.0, 1.0, 0.0984014261649752, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11487533923297054, 0.11487533923297054, 0.24041031434006999], 
reward next is 0.7596, 
noisyNet noise sample is [array([-0.8421136], dtype=float32), -0.067466445]. 
=============================================
[2019-03-26 18:01:43,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.51185]
 [77.54526]
 [77.59284]
 [77.65127]
 [77.59972]], R is [[77.43082428]
 [77.41621399]
 [77.40185547]
 [77.38780975]
 [77.37411499]].
[2019-03-26 18:01:47,043] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2856256e-25 1.0000000e+00 6.3464801e-30 9.7439132e-28 3.1753177e-36], sum to 1.0000
[2019-03-26 18:01:47,056] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8692
[2019-03-26 18:01:47,063] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 96.16666666666666, 1.0, 2.0, 0.3564194821925666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546522.4986521256, 546522.4986521256, 170282.1450057607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026600.0000, 
sim time next is 1027200.0000, 
raw observation next is [21.9, 96.33333333333333, 1.0, 2.0, 0.3566509502024217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546549.2769441827, 546549.2769441821, 170274.4045019448], 
processed observation next is [1.0, 0.9130434782608695, 0.23696682464454974, 0.9633333333333333, 1.0, 1.0, 0.224880662894484, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1518192435956063, 0.15181924359560614, 0.25414090224170865], 
reward next is 0.7459, 
noisyNet noise sample is [array([-0.09449403], dtype=float32), -1.4527944]. 
=============================================
[2019-03-26 18:02:05,148] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8482054e-22 1.0000000e+00 1.8892485e-26 1.8368270e-23 9.3580371e-32], sum to 1.0000
[2019-03-26 18:02:05,158] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4219
[2019-03-26 18:02:05,168] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 97.0, 1.0, 2.0, 0.3802825846655978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572803.730547473, 572803.730547473, 172234.9270182879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [22.4, 97.0, 1.0, 2.0, 0.3809588480346077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573181.2049272379, 573181.2049272379, 172248.3978779776], 
processed observation next is [1.0, 0.043478260869565216, 0.2606635071090047, 0.97, 1.0, 1.0, 0.254167286788684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1592170013686772, 0.1592170013686772, 0.2570871610119069], 
reward next is 0.7429, 
noisyNet noise sample is [array([1.3919694], dtype=float32), -2.25755]. 
=============================================
[2019-03-26 18:02:06,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5288673e-26 1.0000000e+00 4.2487820e-30 1.0280201e-28 6.1546011e-37], sum to 1.0000
[2019-03-26 18:02:06,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9701
[2019-03-26 18:02:06,132] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 86.0, 1.0, 2.0, 0.5067137639541339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708056.8846347855, 708056.8846347849, 184654.8703867525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1713600.0000, 
sim time next is 1714200.0000, 
raw observation next is [26.65, 86.5, 1.0, 2.0, 0.5082943590738291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861516, 184905.9869181053], 
processed observation next is [1.0, 0.8695652173913043, 0.462085308056872, 0.865, 1.0, 1.0, 0.4075835651491917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19729618580170877, 0.19729618580170877, 0.275979084952396], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.0021962], dtype=float32), 0.052180752]. 
=============================================
[2019-03-26 18:02:20,977] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1027244e-10 9.8799324e-01 1.2517253e-16 1.2006796e-02 1.2892873e-18], sum to 1.0000
[2019-03-26 18:02:20,989] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1111
[2019-03-26 18:02:20,994] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 72.33333333333334, 1.0, 2.0, 0.4635229545765331, 1.0, 2.0, 0.4635229545765331, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1295759.052754257, 1295759.052754257, 289304.3362222163], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1254000.0000, 
sim time next is 1254600.0000, 
raw observation next is [28.3, 72.5, 1.0, 2.0, 0.8087661367941441, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1130354.619813759, 1130354.61981376, 246070.9694003943], 
processed observation next is [1.0, 0.5217391304347826, 0.5402843601895735, 0.725, 1.0, 1.0, 0.7695977551736676, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31398739439271084, 0.3139873943927111, 0.3672701035826781], 
reward next is 0.6327, 
noisyNet noise sample is [array([-0.90957755], dtype=float32), 0.45102656]. 
=============================================
[2019-03-26 18:02:22,139] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5865608e-19 1.0000000e+00 1.4531876e-24 4.4440876e-20 9.1651900e-29], sum to 1.0000
[2019-03-26 18:02:22,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1307
[2019-03-26 18:02:22,155] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 85.0, 1.0, 2.0, 0.7691121061979522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1158428.610921606, 1158428.610921607, 247567.397529114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1598400.0000, 
sim time next is 1599000.0000, 
raw observation next is [23.91666666666667, 85.00000000000001, 1.0, 2.0, 0.7486606651701452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1126843.687314722, 1126843.687314722, 242303.078706332], 
processed observation next is [1.0, 0.5217391304347826, 0.3325434439178518, 0.8500000000000001, 1.0, 1.0, 0.6971815243013797, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31301213536520056, 0.31301213536520056, 0.3616463861288537], 
reward next is 0.6384, 
noisyNet noise sample is [array([0.21285795], dtype=float32), 0.7555034]. 
=============================================
[2019-03-26 18:02:22,173] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[63.891594]
 [63.428707]
 [63.300262]
 [63.04965 ]
 [63.302612]], R is [[64.33399963]
 [64.32115173]
 [64.29810333]
 [64.27362061]
 [64.23860931]].
[2019-03-26 18:02:25,038] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.84909485e-26 1.00000000e+00 2.06344556e-29 1.25568436e-29
 3.67197286e-35], sum to 1.0000
[2019-03-26 18:02:25,049] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2733
[2019-03-26 18:02:25,058] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 91.33333333333334, 1.0, 2.0, 0.5004109943526287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712177.3340614865, 712177.3340614858, 185313.8003381039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1312800.0000, 
sim time next is 1313400.0000, 
raw observation next is [24.58333333333334, 91.16666666666667, 1.0, 2.0, 0.4932840924185918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702203.8162529498, 702203.8162529498, 184203.1094174622], 
processed observation next is [1.0, 0.17391304347826086, 0.3641390205371251, 0.9116666666666667, 1.0, 1.0, 0.3894989065284239, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19505661562581939, 0.19505661562581939, 0.2749300140559137], 
reward next is 0.7251, 
noisyNet noise sample is [array([1.0302386], dtype=float32), -0.41151837]. 
=============================================
[2019-03-26 18:02:30,033] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 18:02:30,036] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:02:30,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:02:30,037] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:02:30,038] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:02:30,038] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:02:30,040] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:02:30,040] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:02:30,043] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:02:30,039] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:02:30,046] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:02:30,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run79
[2019-03-26 18:02:30,104] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run79
[2019-03-26 18:02:30,105] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run79
[2019-03-26 18:02:30,106] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run79
[2019-03-26 18:02:30,151] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run79
[2019-03-26 18:02:39,893] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01670763], dtype=float32), 0.11454593]
[2019-03-26 18:02:39,895] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.0, 88.0, 1.0, 2.0, 0.29689756430671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 477167.309475534, 477167.3094755334, 165460.9335058425]
[2019-03-26 18:02:39,896] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:02:39,900] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.9712790e-29 1.0000000e+00 2.3200271e-31 6.1207985e-35 1.2472485e-37], sampled 0.8152144956547734
[2019-03-26 18:03:20,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01670763], dtype=float32), 0.11454593]
[2019-03-26 18:03:20,940] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.55, 58.0, 1.0, 2.0, 0.5189591217862123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725173.7858898403, 725173.785889841, 186619.1739082506]
[2019-03-26 18:03:20,942] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:03:20,946] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.1836575e-24 1.0000000e+00 2.6934910e-28 2.0661514e-25 1.2091077e-33], sampled 0.23473818719181783
[2019-03-26 18:03:42,452] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01670763], dtype=float32), 0.11454593]
[2019-03-26 18:03:42,453] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.82629738, 82.8091861, 1.0, 2.0, 0.4185471484551903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 618148.3534012848, 618148.3534012855, 176061.8613362875]
[2019-03-26 18:03:42,456] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:03:42,457] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8689146e-24 1.0000000e+00 3.6616211e-28 1.2700760e-26 7.8890925e-34], sampled 0.39230216142204544
[2019-03-26 18:04:01,800] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01670763], dtype=float32), 0.11454593]
[2019-03-26 18:04:01,802] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.83333333333333, 56.0, 1.0, 2.0, 0.6531570317723532, 1.0, 2.0, 0.6531570317723532, 0.0, 2.0, 0.0, 6.9112, 6.9112, 169.0403247858759, 1826338.831543144, 1826338.831543144, 354439.5578654755]
[2019-03-26 18:04:01,803] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:04:01,806] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.5286535e-12 7.8002381e-01 2.9835665e-20 2.1997616e-01 5.9548195e-21], sampled 0.3860496946583336
[2019-03-26 18:04:01,807] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1826338.831543144 W.
[2019-03-26 18:04:24,309] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01670763], dtype=float32), 0.11454593]
[2019-03-26 18:04:24,310] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.3, 71.0, 1.0, 2.0, 0.7693413752234409, 1.0, 2.0, 0.7693413752234409, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2151519.898487369, 2151519.898487369, 405221.5951802116]
[2019-03-26 18:04:24,311] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:04:24,313] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0698213e-11 3.4707255e-04 1.5019310e-19 9.9965298e-01 3.8083709e-20], sampled 0.3069546241029525
[2019-03-26 18:04:25,294] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8690.1854 2776666155.9599 867.0000
[2019-03-26 18:04:25,577] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8051.0066 3149411439.8723 1382.0000
[2019-03-26 18:04:25,700] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8308.1309 2923221984.6084 1228.0000
[2019-03-26 18:04:25,748] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8552.1932 2837393991.3921 993.0000
[2019-03-26 18:04:25,800] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8118.4734 2996347940.0250 1486.0000
[2019-03-26 18:04:26,818] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1950000, evaluation results [1950000.0, 8051.006641464885, 3149411439.8723145, 1382.0, 8308.130935515814, 2923221984.6084113, 1228.0, 8690.185397513585, 2776666155.95989, 867.0, 8118.47342256146, 2996347940.024983, 1486.0, 8552.193211160273, 2837393991.39207, 993.0]
[2019-03-26 18:04:37,813] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3696216e-20 1.0000000e+00 2.4540837e-25 7.5875489e-22 1.0480150e-30], sum to 1.0000
[2019-03-26 18:04:37,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6632
[2019-03-26 18:04:37,833] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 85.0, 1.0, 2.0, 0.5474757219086761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822363.5549683154, 822363.5549683154, 198444.5911828252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1601400.0000, 
sim time next is 1602000.0000, 
raw observation next is [24.0, 85.0, 1.0, 2.0, 0.6383729827092052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 958392.0700820248, 958392.0700820254, 216470.8191801312], 
processed observation next is [1.0, 0.5652173913043478, 0.3364928909952607, 0.85, 1.0, 1.0, 0.5643047984448255, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2662200194672291, 0.2662200194672293, 0.3230907748957182], 
reward next is 0.6769, 
noisyNet noise sample is [array([0.32173538], dtype=float32), 1.2401955]. 
=============================================
[2019-03-26 18:04:37,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.5423  ]
 [68.9951  ]
 [67.951675]
 [66.97592 ]
 [65.55722 ]], R is [[68.88813019]
 [68.90306091]
 [68.91548157]
 [68.91110992]
 [68.89859772]].
[2019-03-26 18:04:37,917] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.7076024e-25 1.0000000e+00 4.1607468e-28 9.8910928e-28 3.3044574e-34], sum to 1.0000
[2019-03-26 18:04:37,925] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9349
[2019-03-26 18:04:37,931] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.83333333333333, 1.0, 2.0, 0.5619807788988245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785312.8399107563, 785312.8399107563, 193877.3503473001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2119800.0000, 
sim time next is 2120400.0000, 
raw observation next is [30.0, 76.0, 1.0, 2.0, 0.5622836267046358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785736.1964479298, 785736.1964479298, 193930.428104229], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.76, 1.0, 1.0, 0.472630875547754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2182600545688694, 0.2182600545688694, 0.28944840015556567], 
reward next is 0.7106, 
noisyNet noise sample is [array([0.29683027], dtype=float32), 0.2553776]. 
=============================================
[2019-03-26 18:04:42,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.5634808e-19 1.0000000e+00 5.4990208e-24 4.9333637e-20 1.1581468e-28], sum to 1.0000
[2019-03-26 18:04:42,588] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4561
[2019-03-26 18:04:42,598] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.78333333333333, 88.5, 1.0, 2.0, 0.9213328693092347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1287776.504167697, 1287776.504167696, 275870.1029602659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1680600.0000, 
sim time next is 1681200.0000, 
raw observation next is [25.9, 88.0, 1.0, 2.0, 0.9123370336778922, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1275195.184950111, 1275195.184950111, 273350.8277725301], 
processed observation next is [1.0, 0.4782608695652174, 0.42654028436018954, 0.88, 1.0, 1.0, 0.8943819682866171, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35422088470836416, 0.35422088470836416, 0.40798631010825387], 
reward next is 0.5920, 
noisyNet noise sample is [array([-0.6141997], dtype=float32), -0.6579124]. 
=============================================
[2019-03-26 18:04:49,588] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3027667e-26 1.0000000e+00 7.0922287e-30 9.0920139e-32 9.3584057e-37], sum to 1.0000
[2019-03-26 18:04:49,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0939
[2019-03-26 18:04:49,604] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 83.0, 1.0, 2.0, 0.4865390156703512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698938.4954897553, 698938.4954897553, 183945.1048319371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1929600.0000, 
sim time next is 1930200.0000, 
raw observation next is [25.55, 82.83333333333334, 1.0, 2.0, 0.5465004769424989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 784310.8514507177, 784310.8514507182, 193833.0144228241], 
processed observation next is [1.0, 0.34782608695652173, 0.40995260663507116, 0.8283333333333335, 1.0, 1.0, 0.45361503246084206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21786412540297712, 0.21786412540297728, 0.28930300660123004], 
reward next is 0.7107, 
noisyNet noise sample is [array([-0.42790043], dtype=float32), -0.9537519]. 
=============================================
[2019-03-26 18:04:51,061] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8033442e-20 1.0000000e+00 4.8397008e-26 4.4626239e-19 1.7710748e-30], sum to 1.0000
[2019-03-26 18:04:51,070] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6397
[2019-03-26 18:04:51,075] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 89.33333333333334, 1.0, 2.0, 0.4079308692919311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595140.6724189988, 595140.6724189988, 173675.8816295062], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1964400.0000, 
sim time next is 1965000.0000, 
raw observation next is [24.1, 89.66666666666666, 1.0, 2.0, 0.4130268027696385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 603858.4284902002, 603858.4284901995, 174531.8067971169], 
processed observation next is [1.0, 0.7391304347826086, 0.3412322274881518, 0.8966666666666666, 1.0, 1.0, 0.29280337683088975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16773845235838894, 0.16773845235838875, 0.26049523402554764], 
reward next is 0.7395, 
noisyNet noise sample is [array([-0.0453621], dtype=float32), -1.407598]. 
=============================================
[2019-03-26 18:04:51,090] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[70.88738]
 [69.51836]
 [66.49813]
 [61.5173 ]
 [56.155  ]], R is [[71.47845459]
 [71.50445557]
 [71.53149414]
 [71.55779266]
 [70.84221649]].
[2019-03-26 18:04:51,458] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7736869e-27 1.0000000e+00 3.3811242e-30 1.0060367e-32 2.1759775e-36], sum to 1.0000
[2019-03-26 18:04:51,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1458
[2019-03-26 18:04:51,471] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.61666666666667, 94.5, 1.0, 2.0, 0.3781118518647175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 570729.9378662504, 570729.937866251, 172088.9409996399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1836600.0000, 
sim time next is 1837200.0000, 
raw observation next is [22.73333333333333, 94.0, 1.0, 2.0, 0.3728431648453216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561758.9606749591, 561758.9606749597, 171270.8390035334], 
processed observation next is [1.0, 0.2608695652173913, 0.27646129541864134, 0.94, 1.0, 1.0, 0.24438935523532723, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1560441557430442, 0.15604415574304437, 0.2556281179157215], 
reward next is 0.7444, 
noisyNet noise sample is [array([-0.9353362], dtype=float32), -0.44879884]. 
=============================================
[2019-03-26 18:04:55,635] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.8941636e-25 1.0000000e+00 8.7580388e-29 2.6233005e-27 1.5534780e-34], sum to 1.0000
[2019-03-26 18:04:55,649] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8410
[2019-03-26 18:04:55,659] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.06666666666666, 75.66666666666666, 1.0, 2.0, 0.5661459106881557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791135.3693099535, 791135.3693099535, 194608.8102520434], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2137200.0000, 
sim time next is 2137800.0000, 
raw observation next is [29.88333333333333, 76.33333333333334, 1.0, 2.0, 0.5653684545235572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790048.5438035389, 790048.5438035389, 194471.7247832766], 
processed observation next is [0.0, 0.7391304347826086, 0.6153238546603473, 0.7633333333333334, 1.0, 1.0, 0.4763475355705508, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21945792883431636, 0.21945792883431636, 0.2902563056466815], 
reward next is 0.7097, 
noisyNet noise sample is [array([0.90120035], dtype=float32), -0.36231276]. 
=============================================
[2019-03-26 18:04:56,084] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2459013e-26 1.0000000e+00 1.1394298e-29 8.7025176e-30 2.0948786e-35], sum to 1.0000
[2019-03-26 18:04:56,094] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1069
[2019-03-26 18:04:56,099] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 83.33333333333334, 1.0, 2.0, 0.5168558437300147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722233.745791788, 722233.7457917886, 186279.3772949345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2036400.0000, 
sim time next is 2037000.0000, 
raw observation next is [27.48333333333333, 82.66666666666667, 1.0, 2.0, 0.51679997508885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722155.6506434007, 722155.6506434013, 186270.3905373753], 
processed observation next is [0.0, 0.5652173913043478, 0.5015797788309636, 0.8266666666666667, 1.0, 1.0, 0.4178312952877711, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2005987918453891, 0.20059879184538926, 0.27801550826473925], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.51334655], dtype=float32), 1.2550864]. 
=============================================
[2019-03-26 18:04:56,110] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.270454]
 [75.23385 ]
 [75.212   ]
 [75.20421 ]
 [75.197235]], R is [[75.27306366]
 [75.24230194]
 [75.21186829]
 [75.18173981]
 [75.15201569]].
[2019-03-26 18:05:01,399] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.4966343e-23 1.0000000e+00 4.2527291e-27 7.5494880e-24 1.2546667e-33], sum to 1.0000
[2019-03-26 18:05:01,411] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1781
[2019-03-26 18:05:01,414] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.63333333333333, 97.66666666666667, 1.0, 2.0, 0.4488983664727622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642619.5072123181, 642619.5072123181, 177953.8439553231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1984800.0000, 
sim time next is 1985400.0000, 
raw observation next is [23.7, 97.5, 1.0, 2.0, 0.4504408295010301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643562.3911438324, 643562.3911438324, 178017.7064078728], 
processed observation next is [1.0, 1.0, 0.3222748815165877, 0.975, 1.0, 1.0, 0.33788051747112063, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17876733087328678, 0.17876733087328678, 0.26569806926548184], 
reward next is 0.7343, 
noisyNet noise sample is [array([-1.6879815], dtype=float32), 0.3181852]. 
=============================================
[2019-03-26 18:05:14,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.13480055e-23 1.00000000e+00 1.98629918e-27 4.59047944e-27
 5.77643361e-33], sum to 1.0000
[2019-03-26 18:05:14,105] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6935
[2019-03-26 18:05:14,113] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 90.66666666666667, 1.0, 2.0, 0.621225282094197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 952801.9272920782, 952801.9272920782, 215142.7409349323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2889600.0000, 
sim time next is 2890200.0000, 
raw observation next is [22.63333333333333, 90.33333333333333, 1.0, 2.0, 0.6346173765704584, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 972623.6768112426, 972623.6768112426, 217936.2613286352], 
processed observation next is [1.0, 0.43478260869565216, 0.27172195892575024, 0.9033333333333333, 1.0, 1.0, 0.5597799717716365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2701732435586785, 0.2701732435586785, 0.32527800198303763], 
reward next is 0.6747, 
noisyNet noise sample is [array([-0.2773277], dtype=float32), -0.030680157]. 
=============================================
[2019-03-26 18:05:16,590] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.4369314e-22 1.0000000e+00 1.4922903e-27 1.2727212e-23 1.6959167e-33], sum to 1.0000
[2019-03-26 18:05:16,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9403
[2019-03-26 18:05:16,603] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5280614931723017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737897.5121206605, 737897.5121206605, 188109.414758441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2242800.0000, 
sim time next is 2243400.0000, 
raw observation next is [27.25, 85.00000000000001, 1.0, 2.0, 0.5256722112767287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734557.6458683417, 734557.6458683423, 187716.0619513254], 
processed observation next is [1.0, 1.0, 0.490521327014218, 0.8500000000000001, 1.0, 1.0, 0.42852073647798633, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2040437905189838, 0.20404379051898397, 0.280173226793023], 
reward next is 0.7198, 
noisyNet noise sample is [array([-1.9188886], dtype=float32), 0.083272286]. 
=============================================
[2019-03-26 18:05:23,191] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:05:23,194] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:05:23,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:05:23,196] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:05:23,197] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:05:23,199] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:05:23,201] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:05:23,202] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:05:23,200] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:05:23,203] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:05:23,205] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:05:23,228] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run80
[2019-03-26 18:05:23,260] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run80
[2019-03-26 18:05:23,261] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run80
[2019-03-26 18:05:23,261] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run80
[2019-03-26 18:05:23,280] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run80
[2019-03-26 18:05:27,262] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01781155], dtype=float32), 0.11396861]
[2019-03-26 18:05:27,263] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.81925467, 86.84957730500001, 1.0, 2.0, 0.3024687761068579, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487273.9516556647, 487273.9516556647, 166177.956807582]
[2019-03-26 18:05:27,263] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:05:27,265] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4737024e-30 1.0000000e+00 1.2590351e-32 3.6012492e-37 0.0000000e+00], sampled 0.9096688998482018
[2019-03-26 18:05:35,990] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01781155], dtype=float32), 0.11396861]
[2019-03-26 18:05:35,992] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.063815815, 93.70999882999999, 1.0, 2.0, 0.2358093333462556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391199.3987140352, 391199.3987140352, 159333.7381194367]
[2019-03-26 18:05:35,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:05:36,000] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5235202e-31 1.0000000e+00 3.0330478e-33 0.0000000e+00 0.0000000e+00], sampled 0.6953227307354396
[2019-03-26 18:05:40,784] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01781155], dtype=float32), 0.11396861]
[2019-03-26 18:05:40,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.23333333333333, 85.66666666666666, 1.0, 2.0, 0.3019022311166337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485483.9450303089, 485483.9450303083, 166051.9476229188]
[2019-03-26 18:05:40,787] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:05:40,791] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7827975e-27 1.0000000e+00 7.4270611e-31 8.9529676e-32 6.4698780e-37], sampled 0.9146425185113547
[2019-03-26 18:06:47,764] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01781155], dtype=float32), 0.11396861]
[2019-03-26 18:06:47,765] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.59179506333334, 81.10301197, 1.0, 2.0, 0.5576862872058602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779309.5088744799, 779309.5088744799, 193127.2455690064]
[2019-03-26 18:06:47,766] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:06:47,768] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7063531e-26 1.0000000e+00 9.0984075e-30 7.5895194e-29 1.6652588e-35], sampled 0.14563077572387373
[2019-03-26 18:07:03,255] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01781155], dtype=float32), 0.11396861]
[2019-03-26 18:07:03,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.4, 45.0, 1.0, 2.0, 0.9470836105389412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1487683.571324547, 1487683.571324547, 305814.7340321878]
[2019-03-26 18:07:03,258] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:07:03,261] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1026650e-20 1.0000000e+00 1.3265385e-24 1.3157053e-21 1.0214562e-29], sampled 0.7419665474361605
[2019-03-26 18:07:19,003] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8269.5921 2926458992.9772 1306.0000
[2019-03-26 18:07:19,026] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8023.2680 3005442107.4440 1710.0000
[2019-03-26 18:07:19,248] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7945.5869 3158763294.6203 1634.0000
[2019-03-26 18:07:19,366] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8510.1240 2841219371.3599 1100.0000
[2019-03-26 18:07:19,378] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8670.8501 2778542986.8341 911.0000
[2019-03-26 18:07:20,396] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1975000, evaluation results [1975000.0, 7945.586854861711, 3158763294.6203036, 1634.0, 8269.59214016397, 2926458992.9771657, 1306.0, 8670.85005129434, 2778542986.8341184, 911.0, 8023.267997781672, 3005442107.4439964, 1710.0, 8510.124031114798, 2841219371.359945, 1100.0]
[2019-03-26 18:07:23,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.2123428e-30 1.0000000e+00 1.3503766e-32 1.8511152e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:07:23,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5660
[2019-03-26 18:07:23,224] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4355793500451794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 630808.7300177492, 630808.7300177492, 176962.4834249192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2710800.0000, 
sim time next is 2711400.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.4322396927415711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 627312.4138143113, 627312.4138143107, 176654.5404167373], 
processed observation next is [0.0, 0.391304347826087, 0.28909952606635075, 1.0, 1.0, 1.0, 0.3159514370380375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17425344828175313, 0.17425344828175296, 0.26366349315930937], 
reward next is 0.7363, 
noisyNet noise sample is [array([0.35148266], dtype=float32), -1.4649804]. 
=============================================
[2019-03-26 18:07:38,604] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2877848e-27 1.0000000e+00 3.7306309e-31 9.7312547e-34 1.2351746e-37], sum to 1.0000
[2019-03-26 18:07:38,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1427
[2019-03-26 18:07:38,626] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3391349646522034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522432.1466490824, 522432.1466490824, 168393.0931199608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2863800.0000, 
sim time next is 2864400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3456146005598426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532415.1094333327, 532415.109433332, 169196.7591309555], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2115838560961959, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1478930859537035, 0.14789308595370332, 0.252532476314859], 
reward next is 0.7475, 
noisyNet noise sample is [array([0.11279981], dtype=float32), -0.0103007015]. 
=============================================
[2019-03-26 18:07:41,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.21783564e-25 1.00000000e+00 2.32532809e-29 5.53387562e-29
 1.11260705e-35], sum to 1.0000
[2019-03-26 18:07:41,912] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9687
[2019-03-26 18:07:41,921] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.348973241768224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537583.5931703661, 537583.5931703654, 169618.1941480456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2855400.0000, 
sim time next is 2856000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3485975882969864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537005.1891459094, 537005.1891459088, 169570.8333095459], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2151778172252848, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14916810809608594, 0.14916810809608577, 0.2530907959843969], 
reward next is 0.7469, 
noisyNet noise sample is [array([-1.2510378], dtype=float32), 2.3382015]. 
=============================================
[2019-03-26 18:07:41,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.60333]
 [74.66733]
 [74.66607]
 [74.70696]
 [74.73052]], R is [[74.56091309]
 [74.56214905]
 [74.56327057]
 [74.56429291]
 [74.56524658]].
[2019-03-26 18:07:42,421] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3366995e-09 1.4706488e-02 7.3873019e-18 9.8529357e-01 5.5329997e-19], sum to 1.0000
[2019-03-26 18:07:42,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4495
[2019-03-26 18:07:42,442] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 63.66666666666666, 1.0, 2.0, 0.9009813190676113, 1.0, 2.0, 0.9009813190676113, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2520042.165832719, 2520042.165832719, 472037.4930202827], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3419400.0000, 
sim time next is 3420000.0000, 
raw observation next is [34.0, 63.0, 1.0, 2.0, 0.9437685108267787, 1.0, 2.0, 0.9437685108267787, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2639844.245537792, 2639844.245537792, 495942.1601140011], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.63, 1.0, 1.0, 0.9322512178635888, 1.0, 1.0, 0.9322512178635888, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7332900682049421, 0.7332900682049421, 0.7402121792746285], 
reward next is 0.2598, 
noisyNet noise sample is [array([1.3372083], dtype=float32), -0.31302735]. 
=============================================
[2019-03-26 18:07:42,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[55.846134]
 [54.79923 ]
 [54.37578 ]
 [57.695114]
 [60.827206]], R is [[56.26338196]
 [55.99621582]
 [55.45262146]
 [54.89809418]
 [54.34911346]].
[2019-03-26 18:07:42,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [7.67988639e-30 1.00000000e+00 8.19407284e-33 1.34496555e-36
 0.00000000e+00], sum to 1.0000
[2019-03-26 18:07:42,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7610
[2019-03-26 18:07:42,577] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3816734370932218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587957.306033519, 587957.3060335184, 173925.3497632101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2866200.0000, 
sim time next is 2866800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.350244189542749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 539528.9942654476, 539528.9942654483, 169777.4929953436], 
processed observation next is [1.0, 0.17391304347826086, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21716167414789037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14986916507373543, 0.14986916507373563, 0.25339924327663227], 
reward next is 0.7466, 
noisyNet noise sample is [array([-1.1938671], dtype=float32), 1.8544747]. 
=============================================
[2019-03-26 18:07:42,694] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2598147e-30 1.0000000e+00 6.1607681e-33 4.5399039e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:07:42,705] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1958
[2019-03-26 18:07:42,713] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666667, 100.0, 1.0, 2.0, 0.4157842069799606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 610144.6145788797, 610144.6145788797, 175191.8476672653], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2715600.0000, 
sim time next is 2716200.0000, 
raw observation next is [22.5, 100.0, 1.0, 2.0, 0.409181697380103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 174749.847841923], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 1.0, 1.0, 1.0, 0.28817071973506386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16784845999691392, 0.16784845999691392, 0.2608206684207806], 
reward next is 0.7392, 
noisyNet noise sample is [array([0.13775474], dtype=float32), 0.526748]. 
=============================================
[2019-03-26 18:07:52,171] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2219300e-26 1.0000000e+00 1.2414002e-30 2.5184344e-30 7.1540748e-37], sum to 1.0000
[2019-03-26 18:07:52,184] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-26 18:07:52,188] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3055869598939788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486628.50575581, 486628.5057558094, 166099.293527577], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3018600.0000, 
sim time next is 3019200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3050170820939111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 485721.227767029, 485721.2277670284, 166033.5916795073], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 1.0, 1.0, 1.0, 0.162671183245676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13492256326861918, 0.13492256326861898, 0.24781133086493629], 
reward next is 0.7522, 
noisyNet noise sample is [array([0.92947364], dtype=float32), -0.06958021]. 
=============================================
[2019-03-26 18:07:54,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2039600e-24 1.0000000e+00 2.9600272e-28 2.8653599e-27 1.6054097e-34], sum to 1.0000
[2019-03-26 18:07:54,562] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1155
[2019-03-26 18:07:54,566] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.6798689586545278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1046995.521519257, 1046995.521519256, 228620.2719340856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2910000.0000, 
sim time next is 2910600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.6990864653169488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1076596.452656342, 1076596.452656341, 233145.4535431424], 
processed observation next is [1.0, 0.6956521739130435, 0.2417061611374408, 0.94, 1.0, 1.0, 0.6374535726710227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2990545701823172, 0.29905457018231696, 0.34797828887036175], 
reward next is 0.6520, 
noisyNet noise sample is [array([0.3325803], dtype=float32), -0.20022862]. 
=============================================
[2019-03-26 18:07:57,245] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3265567e-28 1.0000000e+00 4.9391545e-31 2.4729426e-34 6.5614646e-38], sum to 1.0000
[2019-03-26 18:07:57,254] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1408
[2019-03-26 18:07:57,260] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.5597298578214112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 864746.8019493389, 864746.8019493383, 203365.8018382049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2968800.0000, 
sim time next is 2969400.0000, 
raw observation next is [21.83333333333334, 95.0, 1.0, 2.0, 0.5720936681797003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 882650.21200267, 882650.2120026695, 205658.5751015131], 
processed observation next is [1.0, 0.34782608695652173, 0.23380726698262277, 0.95, 1.0, 1.0, 0.4844502026261449, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24518061444518613, 0.24518061444518596, 0.3069530971664375], 
reward next is 0.6930, 
noisyNet noise sample is [array([0.1732466], dtype=float32), 1.0124314]. 
=============================================
[2019-03-26 18:08:09,326] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5255468e-13 1.0000000e+00 3.4589242e-18 2.9817343e-10 4.1828162e-22], sum to 1.0000
[2019-03-26 18:08:09,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1988
[2019-03-26 18:08:09,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1940107.508423147 W.
[2019-03-26 18:08:09,344] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7464333739319017, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.975379887540377, 6.9112, 168.9125746057596, 1940107.508423147, 1894576.190245264, 396098.0311412748], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3489000.0000, 
sim time next is 3489600.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.85561219252478, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.974106940547907, 6.9112, 168.9125302547627, 2092907.678301799, 2048279.442207961, 423136.3759131589], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.8260387861744338, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006290694054790702, 0.0, 0.8294378520418305, 0.581363243972722, 0.5689665117244337, 0.6315468297211326], 
reward next is 0.0539, 
noisyNet noise sample is [array([-0.8776335], dtype=float32), 1.8823134]. 
=============================================
[2019-03-26 18:08:09,720] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0368160e-24 1.0000000e+00 3.9493969e-28 2.8206165e-25 5.3216393e-34], sum to 1.0000
[2019-03-26 18:08:09,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4924
[2019-03-26 18:08:09,736] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.504063230437664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 704351.9315865864, 704351.9315865864, 184235.3274688481], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3176400.0000, 
sim time next is 3177000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5018772838525735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701296.3944119347, 701296.394411934, 183890.9359768336], 
processed observation next is [1.0, 0.782608695652174, 0.4549763033175356, 0.865, 1.0, 1.0, 0.399852149219968, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19480455400331517, 0.19480455400331498, 0.27446408354751284], 
reward next is 0.7255, 
noisyNet noise sample is [array([-2.468983], dtype=float32), 0.88173366]. 
=============================================
[2019-03-26 18:08:09,754] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.75737]
 [69.08175]
 [68.46905]
 [67.63279]
 [67.34643]], R is [[70.22657013]
 [70.24932861]
 [70.27228546]
 [70.29613495]
 [70.32094574]].
[2019-03-26 18:08:13,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8423117e-28 1.0000000e+00 5.2419390e-32 3.9114878e-31 1.6926873e-38], sum to 1.0000
[2019-03-26 18:08:13,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5994
[2019-03-26 18:08:13,531] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5157695029439897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720715.2215249649, 720715.2215249649, 186104.0597786985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3440400.0000, 
sim time next is 3441000.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.516028016286732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721076.5801110404, 721076.5801110397, 186145.6822240083], 
processed observation next is [1.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.41690122444184574, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20029905003084456, 0.20029905003084436, 0.2778293764537437], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.7922085], dtype=float32), -0.057515595]. 
=============================================
[2019-03-26 18:08:13,558] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.649376]
 [75.22397 ]
 [75.78193 ]
 [76.393425]
 [76.6611  ]], R is [[74.27773285]
 [74.25718689]
 [74.2366333 ]
 [74.21601105]
 [74.19523621]].
[2019-03-26 18:08:14,011] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4967802e-28 1.0000000e+00 5.1771545e-32 1.2792511e-34 2.2722055e-38], sum to 1.0000
[2019-03-26 18:08:14,020] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3973
[2019-03-26 18:08:14,025] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666667, 67.5, 1.0, 2.0, 0.558430229368891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780349.4737786412, 780349.4737786412, 193258.3575492141], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3239400.0000, 
sim time next is 3240000.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5661714416204972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 791171.0596606085, 791171.0596606091, 194614.2034068987], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4773149899042134, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21976973879461348, 0.21976973879461364, 0.29046896030880404], 
reward next is 0.7095, 
noisyNet noise sample is [array([0.47998896], dtype=float32), -0.92784876]. 
=============================================
[2019-03-26 18:08:14,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.645355]
 [73.68443 ]
 [73.69847 ]
 [73.70954 ]
 [73.721634]], R is [[73.64521027]
 [73.62031555]
 [73.59752655]
 [73.57653046]
 [73.5570755 ]].
[2019-03-26 18:08:16,808] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5911806e-25 1.0000000e+00 3.8834515e-29 1.2370146e-28 1.7159451e-35], sum to 1.0000
[2019-03-26 18:08:16,818] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8931
[2019-03-26 18:08:16,826] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 83.16666666666666, 1.0, 2.0, 0.4809847450995685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 672093.0460930732, 672093.0460930738, 180669.9039054583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3286200.0000, 
sim time next is 3286800.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4792880274897444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669721.429146401, 669721.4291464004, 180414.0429977915], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3726361776984872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18603373031844472, 0.18603373031844456, 0.26927469104147983], 
reward next is 0.7307, 
noisyNet noise sample is [array([-0.7510751], dtype=float32), -1.7873527]. 
=============================================
[2019-03-26 18:08:16,826] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 18:08:16,830] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:08:16,832] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:08:16,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:08:16,834] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:08:16,834] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:08:16,836] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:08:16,840] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:08:16,840] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:08:16,843] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:08:16,842] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:08:16,864] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run81
[2019-03-26 18:08:16,889] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run81
[2019-03-26 18:08:16,913] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run81
[2019-03-26 18:08:16,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run81
[2019-03-26 18:08:16,960] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run81
[2019-03-26 18:08:23,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:08:23,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.63333333333333, 84.5, 1.0, 2.0, 0.257264450710331, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419078.1915287006, 419078.1915287006, 161570.0893810088]
[2019-03-26 18:08:23,522] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:08:23,524] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8581977e-31 1.0000000e+00 3.3034635e-33 0.0000000e+00 0.0000000e+00], sampled 0.08117058930217746
[2019-03-26 18:08:26,436] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:08:26,437] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.36666666666667, 55.66666666666667, 1.0, 2.0, 0.4024717311300918, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 652657.6086039691, 652657.6086039691, 179590.8000195687]
[2019-03-26 18:08:26,439] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:08:26,442] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.2459724e-28 1.0000000e+00 6.0816636e-31 5.9759350e-34 4.6673369e-37], sampled 0.32084802959355385
[2019-03-26 18:08:47,062] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:08:47,064] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.35055625, 79.150095975, 1.0, 2.0, 0.6122539714654731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 899378.412711276, 899378.412711276, 208625.7428901404]
[2019-03-26 18:08:47,064] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:08:47,067] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9157100e-24 1.0000000e+00 4.6852680e-28 3.2790413e-27 7.7399865e-34], sampled 0.5413157325041048
[2019-03-26 18:08:48,972] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:08:48,972] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.81666666666667, 93.66666666666667, 1.0, 2.0, 0.485893801270354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678954.7957070796, 678954.7957070796, 181414.926173429]
[2019-03-26 18:08:48,973] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:08:48,977] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2706172e-30 1.0000000e+00 2.5755005e-32 2.7026904e-37 0.0000000e+00], sampled 0.8729179460962655
[2019-03-26 18:09:26,365] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:09:26,367] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.19167879333333, 87.91611119333334, 1.0, 2.0, 0.5672231522978323, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9558205506190511, 6.911200000000001, 6.9112, 168.9125018003417, 1585874.497456737, 1585874.497456736, 340778.9745406228]
[2019-03-26 18:09:26,367] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:09:26,370] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4832231e-17 1.0000000e+00 3.2639242e-22 1.2313496e-15 8.1089940e-26], sampled 0.8545728814652053
[2019-03-26 18:09:46,590] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:09:46,591] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.271649865, 97.777818465, 1.0, 2.0, 0.6311302673138153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 881982.5657231446, 881982.565723144, 206680.8304470244]
[2019-03-26 18:09:46,593] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:09:46,595] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1143806e-26 1.0000000e+00 1.0365133e-29 2.1079905e-30 1.1478812e-35], sampled 0.9436937757832461
[2019-03-26 18:09:57,897] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01941065], dtype=float32), 0.11199086]
[2019-03-26 18:09:57,898] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.26373532, 78.96375044, 1.0, 2.0, 0.3752863497785275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574301.780232314, 574301.7802323134, 172628.0020007165]
[2019-03-26 18:09:57,899] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:09:57,902] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.1361642e-27 1.0000000e+00 1.2373720e-30 1.7965375e-30 1.6666751e-36], sampled 0.6945079910885915
[2019-03-26 18:10:12,271] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8666.5338 2778623439.4227 917.0000
[2019-03-26 18:10:12,817] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7921.2963 3160438797.4739 1690.0000
[2019-03-26 18:10:12,959] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.7166 2841944604.4047 1118.0000
[2019-03-26 18:10:13,073] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8010.4908 3006729735.8306 1741.0000
[2019-03-26 18:10:13,154] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.9121 2926465609.4183 1313.0000
[2019-03-26 18:10:14,171] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2000000, evaluation results [2000000.0, 7921.296312962064, 3160438797.4738855, 1690.0, 8265.912118131173, 2926465609.418326, 1313.0, 8666.533772533488, 2778623439.422731, 917.0, 8010.49081602207, 3006729735.8306403, 1741.0, 8502.716648420166, 2841944604.4046607, 1118.0]
[2019-03-26 18:10:14,709] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.6198531e-30 1.0000000e+00 3.0572927e-32 1.0242971e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:14,719] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2271
[2019-03-26 18:10:14,722] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.4360764697621042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632396.6356465198, 632396.6356465198, 177142.3477191151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3297000.0000, 
sim time next is 3297600.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.4273064038538791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 624174.6248391629, 624174.6248391629, 176457.5222746526], 
processed observation next is [0.0, 0.17391304347826086, 0.38388625592417064, 0.83, 1.0, 1.0, 0.3100077154866013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1733818402331008, 0.1733818402331008, 0.2633694362308248], 
reward next is 0.7366, 
noisyNet noise sample is [array([0.70623887], dtype=float32), 0.65445495]. 
=============================================
[2019-03-26 18:10:19,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2804537e-24 1.0000000e+00 1.1266155e-28 2.3753580e-27 1.0963323e-34], sum to 1.0000
[2019-03-26 18:10:19,267] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1406
[2019-03-26 18:10:19,273] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.86666666666667, 84.66666666666667, 1.0, 2.0, 0.5418295375273203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757143.4268265029, 757143.4268265023, 190409.6253148704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4063200.0000, 
sim time next is 4063800.0000, 
raw observation next is [27.83333333333334, 84.83333333333334, 1.0, 2.0, 0.5416925017101607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756951.8670642086, 756951.867064208, 190386.4460029551], 
processed observation next is [1.0, 0.0, 0.5181674565560824, 0.8483333333333334, 1.0, 1.0, 0.4478222912170611, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21026440751783573, 0.21026440751783557, 0.28415887463127626], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.6434753], dtype=float32), -0.5924928]. 
=============================================
[2019-03-26 18:10:25,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.7682607e-24 1.0000000e+00 9.2169095e-28 6.5000846e-29 1.4809551e-33], sum to 1.0000
[2019-03-26 18:10:25,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2097
[2019-03-26 18:10:25,055] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6680389578119544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 933583.8447510903, 933583.8447510909, 214094.3565840539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3468000.0000, 
sim time next is 3468600.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6578589395102451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 919351.1207138947, 919351.120713894, 212008.7175901417], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5877818548316206, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2553753113094152, 0.255375311309415, 0.31643092177633086], 
reward next is 0.6836, 
noisyNet noise sample is [array([0.9698508], dtype=float32), 0.88545334]. 
=============================================
[2019-03-26 18:10:25,643] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5225163e-30 1.0000000e+00 1.7667737e-33 1.5186419e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:25,652] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0129
[2019-03-26 18:10:25,659] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 78.33333333333334, 1.0, 2.0, 0.5521197630675306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771528.0360784814, 771528.0360784814, 192165.2362340161], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3790200.0000, 
sim time next is 3790800.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.5502098921638179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 768858.2308287701, 768858.2308287694, 191837.0223467204], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.79, 1.0, 1.0, 0.4580842074262866, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21357173078576946, 0.21357173078576927, 0.28632391395032897], 
reward next is 0.7137, 
noisyNet noise sample is [array([-0.21606563], dtype=float32), 1.388401]. 
=============================================
[2019-03-26 18:10:27,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.7202362e-27 1.0000000e+00 1.2653094e-31 2.5820350e-30 1.3222405e-37], sum to 1.0000
[2019-03-26 18:10:27,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4895
[2019-03-26 18:10:27,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 70.83333333333334, 1.0, 2.0, 0.5572918124053797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778758.0686400848, 778758.0686400848, 193060.0262843551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3521400.0000, 
sim time next is 3522000.0000, 
raw observation next is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.55988969282904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782389.6767051055, 782389.676705106, 193511.9434719727], 
processed observation next is [1.0, 0.782608695652174, 0.6524486571879939, 0.7166666666666667, 1.0, 1.0, 0.4697466178663132, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21733046575141818, 0.21733046575141834, 0.28882379622682497], 
reward next is 0.7112, 
noisyNet noise sample is [array([-2.1832123], dtype=float32), -0.019476704]. 
=============================================
[2019-03-26 18:10:27,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.57522 ]
 [72.96045 ]
 [73.07247 ]
 [73.069916]
 [71.784966]], R is [[72.21776581]
 [72.20744324]
 [72.19855499]
 [72.19094849]
 [72.1837616 ]].
[2019-03-26 18:10:29,858] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8283687e-29 1.0000000e+00 1.8728455e-33 2.4550730e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:29,871] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0714
[2019-03-26 18:10:29,876] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.556248390816755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777299.4606370268, 777299.4606370262, 192878.5460170452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [29.5, 77.0, 1.0, 2.0, 0.5552167309940984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775857.2964768948, 775857.2964768953, 192699.7982324186], 
processed observation next is [1.0, 0.8260869565217391, 0.5971563981042655, 0.77, 1.0, 1.0, 0.4641165433663836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21551591568802633, 0.21551591568802647, 0.2876116391528636], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.32530794], dtype=float32), -0.061551426]. 
=============================================
[2019-03-26 18:10:32,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.9839000e-12 9.9999487e-01 1.6019704e-18 5.1780953e-06 1.4764383e-21], sum to 1.0000
[2019-03-26 18:10:32,406] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7863
[2019-03-26 18:10:32,418] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 3161947.227304711 W.
[2019-03-26 18:10:32,422] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [38.0, 53.66666666666666, 1.0, 2.0, 0.8657388059900791, 1.0, 2.0, 0.753459442509302, 1.0, 1.0, 1.03, 7.005110804147474, 6.9112, 170.5573041426782, 3161947.227304711, 3094675.098246601, 578791.9310284306], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4281000.0000, 
sim time next is 4281600.0000, 
raw observation next is [38.0, 53.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.589870225277954, 6.9112, 170.5573041426782, 4113230.599654422, 2910730.833348863, 543097.7374420299], 
processed observation next is [1.0, 0.5652173913043478, 1.0, 0.5333333333333334, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.1678670225277954, 0.0, 0.8375144448122397, 1.1425640554595617, 0.8085363425969063, 0.810593637973179], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8248407], dtype=float32), -0.14368753]. 
=============================================
[2019-03-26 18:10:38,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7718529e-30 1.0000000e+00 3.5856687e-34 1.8851003e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:38,908] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5939
[2019-03-26 18:10:38,915] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.5576934901660396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779319.5779665861, 779319.5779665867, 193129.2585808085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3694800.0000, 
sim time next is 3695400.0000, 
raw observation next is [29.5, 77.0, 1.0, 2.0, 0.5560386540380806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777006.268033984, 777006.268033984, 192842.0680316506], 
processed observation next is [1.0, 0.782608695652174, 0.5971563981042655, 0.77, 1.0, 1.0, 0.465106812094073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21583507445388445, 0.21583507445388445, 0.28782398213679194], 
reward next is 0.7122, 
noisyNet noise sample is [array([-0.95820093], dtype=float32), -0.63234484]. 
=============================================
[2019-03-26 18:10:42,828] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.06993455e-13 1.00000000e+00 1.15767055e-19 9.22349176e-12
 6.08809462e-23], sum to 1.0000
[2019-03-26 18:10:42,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-26 18:10:42,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2218604.481466745 W.
[2019-03-26 18:10:42,849] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.9454162332362251, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.982543631889778, 6.9112, 168.9125319311012, 2218604.481466745, 2167990.980768161, 447805.5364657139], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4010400.0000, 
sim time next is 4011000.0000, 
raw observation next is [29.33333333333334, 72.66666666666667, 1.0, 2.0, 0.5892576895081172, 1.0, 1.0, 0.5892576895081172, 1.0, 2.0, 1.014034456867322, 6.9112, 6.9112, 170.5573041426782, 2472180.80158839, 2472180.80158839, 480332.6123936977], 
processed observation next is [1.0, 0.43478260869565216, 0.5892575039494474, 0.7266666666666667, 1.0, 1.0, 0.5051297463953219, 1.0, 0.5, 0.5051297463953219, 1.0, 1.0, 1.0171151913016123, 0.0, 0.0, 0.8375144448122397, 0.6867168893301083, 0.6867168893301083, 0.7169143468562652], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9040548], dtype=float32), -0.9697304]. 
=============================================
[2019-03-26 18:10:42,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[46.739323]
 [47.711952]
 [48.169727]
 [48.262466]
 [49.526745]], R is [[44.54813385]
 [44.1026535 ]
 [44.05665588]
 [43.99213791]
 [43.93976974]].
[2019-03-26 18:10:43,508] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.4881211e-30 1.0000000e+00 5.1018868e-33 1.8271419e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:43,515] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4870
[2019-03-26 18:10:43,525] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.6055076074234279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 846161.5276253807, 846161.5276253807, 201776.9095753855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4466400.0000, 
sim time next is 4467000.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.6063457077888629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 847333.1911276529, 847333.1911276529, 201934.4634184723], 
processed observation next is [0.0, 0.6956521739130435, 0.7156398104265403, 0.71, 1.0, 1.0, 0.5257177202275456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23537033086879247, 0.23537033086879247, 0.3013947215201079], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.5305848], dtype=float32), 1.9091642]. 
=============================================
[2019-03-26 18:10:43,543] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[72.75924 ]
 [72.74961 ]
 [72.758354]
 [72.83142 ]
 [73.01944 ]], R is [[72.75526428]
 [72.72654724]
 [72.69867706]
 [72.67121887]
 [72.64344788]].
[2019-03-26 18:10:44,880] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3485347e-34 1.0000000e+00 2.1057568e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:10:44,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9510
[2019-03-26 18:10:44,895] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 79.0, 1.0, 2.0, 0.5668084612773808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792061.5663031598, 792061.5663031598, 194725.6000038598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4041000.0000, 
sim time next is 4041600.0000, 
raw observation next is [29.33333333333334, 79.0, 1.0, 2.0, 0.5629319470540625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786642.4959972055, 786642.4959972055, 194043.5543312026], 
processed observation next is [1.0, 0.782608695652174, 0.5892575039494474, 0.79, 1.0, 1.0, 0.4734119844024849, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2185118044436682, 0.2185118044436682, 0.2896172452704517], 
reward next is 0.7104, 
noisyNet noise sample is [array([-0.4556776], dtype=float32), -0.36278147]. 
=============================================
[2019-03-26 18:10:51,281] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5684724e-10 9.9992597e-01 8.0042794e-17 7.4050251e-05 6.7233460e-20], sum to 1.0000
[2019-03-26 18:10:51,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5375
[2019-03-26 18:10:51,299] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2926412.335602142 W.
[2019-03-26 18:10:51,304] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.7536190821005359, 1.0, 2.0, 0.6973995805645304, 1.0, 2.0, 1.03, 7.005101960351664, 6.9112, 170.5573041426782, 2926412.335602142, 2859146.541714714, 538799.4655459999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4032000.0000, 
sim time next is 4032600.0000, 
raw observation next is [33.33333333333334, 63.16666666666666, 1.0, 2.0, 0.9174258208605414, 1.0, 2.0, 0.9174258208605414, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2566084.621153927, 2566084.621153927, 481093.7527802488], 
processed observation next is [1.0, 0.6956521739130435, 0.7788309636650873, 0.6316666666666666, 1.0, 1.0, 0.9005130371813751, 1.0, 1.0, 0.9005130371813751, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7128012836538686, 0.7128012836538686, 0.7180503772839535], 
reward next is 0.2819, 
noisyNet noise sample is [array([0.55123997], dtype=float32), -1.5871906]. 
=============================================
[2019-03-26 18:10:55,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.4455685e-28 1.0000000e+00 2.2847209e-31 5.0721308e-36 1.1874792e-38], sum to 1.0000
[2019-03-26 18:10:55,113] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8132
[2019-03-26 18:10:55,119] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.916186142425426, 6.9112, 168.9128263400949, 1457294.688481161, 1453757.350160787, 311357.4961964511], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4173600.0000, 
sim time next is 4174200.0000, 
raw observation next is [31.0, 81.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.263297578968324, 6.9112, 168.9109766956921, 1703713.217283246, 1453926.004269188, 311358.1073930356], 
processed observation next is [1.0, 0.30434782608695654, 0.6682464454976303, 0.815, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.03520975789683236, 0.0, 0.8294302233555716, 0.47325367146756836, 0.4038683345192189, 0.46471359312393373], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.04227021], dtype=float32), 0.65936196]. 
=============================================
[2019-03-26 18:10:55,527] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8126121e-09 9.6188438e-01 3.0174921e-16 3.8115676e-02 4.0511154e-18], sum to 1.0000
[2019-03-26 18:10:55,536] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7518
[2019-03-26 18:10:55,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3403852.457028285 W.
[2019-03-26 18:10:55,548] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 51.66666666666667, 1.0, 2.0, 0.9808689397300934, 1.0, 2.0, 0.8110245093793093, 1.0, 2.0, 1.03, 7.005119888869083, 6.9112, 170.5573041426782, 3403852.457028285, 3336573.820214544, 624737.9870124046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4285200.0000, 
sim time next is 4285800.0000, 
raw observation next is [38.0, 51.5, 1.0, 2.0, 0.9881256916020481, 1.0, 2.0, 0.8146528853152867, 1.0, 2.0, 1.03, 7.0051204616048, 6.9112, 170.5573041426782, 3419101.522946926, 3351822.475859293, 627800.0404851905], 
processed observation next is [1.0, 0.6086956521739131, 1.0, 0.515, 1.0, 1.0, 0.985693604339817, 1.0, 1.0, 0.7766902232714297, 1.0, 1.0, 1.0365853658536586, 0.009392046160480038, 0.0, 0.8375144448122397, 0.9497504230408127, 0.9310617988498036, 0.9370149857987917], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4600306], dtype=float32), -0.05562278]. 
=============================================
[2019-03-26 18:11:07,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6058166e-35 1.0000000e+00 1.2600361e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:11:07,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 18:11:07,167] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.66666666666666, 58.66666666666667, 1.0, 2.0, 0.5933207032444365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 829124.3933819556, 829124.393381955, 199509.7389313164], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4304400.0000, 
sim time next is 4305000.0000, 
raw observation next is [34.33333333333334, 60.83333333333333, 1.0, 2.0, 0.6001270733701467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 838639.5769942261, 838639.5769942261, 200771.0780567969], 
processed observation next is [1.0, 0.8260869565217391, 0.8262243285939973, 0.6083333333333333, 1.0, 1.0, 0.5182253896025864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2329554380539517, 0.2329554380539517, 0.2996583254579058], 
reward next is 0.7003, 
noisyNet noise sample is [array([-0.10181025], dtype=float32), -0.85925466]. 
=============================================
[2019-03-26 18:11:07,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.27724]
 [70.75592]
 [71.27242]
 [71.76411]
 [72.36793]], R is [[70.18362427]
 [70.18401337]
 [70.18580627]
 [70.18882751]
 [70.19334412]].
[2019-03-26 18:11:10,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.8909660e-32 1.0000000e+00 3.5329727e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:11:10,317] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4838
[2019-03-26 18:11:10,323] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 62.66666666666667, 1.0, 2.0, 0.5290955894582405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739343.0305724948, 739343.0305724948, 188280.6058050734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4555200.0000, 
sim time next is 4555800.0000, 
raw observation next is [31.0, 64.5, 1.0, 2.0, 0.5295354357464656, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 739957.8732625517, 739957.8732625517, 188353.3893941975], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.645, 1.0, 1.0, 0.4331752237909223, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20554385368404215, 0.20554385368404215, 0.2811244617823843], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.02490255], dtype=float32), 0.53250265]. 
=============================================
[2019-03-26 18:11:10,553] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 18:11:10,554] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:11:10,555] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:11:10,555] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:11:10,556] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:11:10,557] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:11:10,558] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:11:10,558] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:11:10,560] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:11:10,560] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:11:10,565] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:11:10,590] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run82
[2019-03-26 18:11:10,616] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run82
[2019-03-26 18:11:10,643] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run82
[2019-03-26 18:11:10,643] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run82
[2019-03-26 18:11:10,689] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run82
[2019-03-26 18:11:21,853] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:21,856] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [17.68333333333333, 93.0, 1.0, 2.0, 0.2643340343026741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 440045.684673672, 440045.6846736726, 161907.7451246051]
[2019-03-26 18:11:21,859] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:11:21,862] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4982293e-33 1.0000000e+00 1.5958045e-35 0.0000000e+00 0.0000000e+00], sampled 0.28506932759408277
[2019-03-26 18:11:32,827] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:32,829] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.93333333333334, 69.83333333333334, 1.0, 2.0, 0.4519402142382168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 639298.9911641382, 639298.9911641382, 177417.5316918393]
[2019-03-26 18:11:32,830] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:11:32,832] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.0225527e-33 1.0000000e+00 2.2616157e-35 0.0000000e+00 0.0000000e+00], sampled 0.35964143053864794
[2019-03-26 18:11:42,384] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:42,386] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.86666666666667, 94.0, 1.0, 2.0, 0.4889903649108739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683283.1137254022, 683283.1137254015, 181888.6132169166]
[2019-03-26 18:11:42,388] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:11:42,391] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.107953e-34 1.000000e+00 3.189132e-36 0.000000e+00 0.000000e+00], sampled 0.3167734664823223
[2019-03-26 18:11:42,564] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:42,565] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.79291588833333, 85.66061720666666, 1.0, 2.0, 0.4261323936164619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 626078.9685100258, 626078.9685100263, 176738.9320671173]
[2019-03-26 18:11:42,567] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:11:42,572] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2913487e-31 1.0000000e+00 1.2376905e-34 0.0000000e+00 0.0000000e+00], sampled 0.2554886368712648
[2019-03-26 18:11:52,390] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:52,391] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.91645662666667, 95.18071491, 1.0, 2.0, 0.4001726614322385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596794.9941299644, 596794.9941299644, 174233.5607219044]
[2019-03-26 18:11:52,391] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:11:52,393] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.13905375e-33 1.00000000e+00 1.06322962e-35 0.00000000e+00
 0.00000000e+00], sampled 0.20097323577260373
[2019-03-26 18:11:53,553] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:11:53,555] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804]
[2019-03-26 18:11:53,556] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:11:53,558] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.5664103e-32 1.0000000e+00 1.4272057e-34 0.0000000e+00 0.0000000e+00], sampled 0.30674762801170385
[2019-03-26 18:12:28,531] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:12:28,538] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 77.33333333333334, 1.0, 2.0, 0.5662643641543001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 791300.9584840949, 791300.9584840944, 194628.9436132418]
[2019-03-26 18:12:28,539] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:12:28,543] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.8835730e-30 1.0000000e+00 8.6466139e-33 4.6250127e-37 0.0000000e+00], sampled 0.6598127269264449
[2019-03-26 18:12:44,731] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:12:44,732] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.95444617666667, 65.57625482333334, 1.0, 2.0, 0.5713050292944835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832991.672577541, 832991.672577541, 199913.7711349649]
[2019-03-26 18:12:44,733] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:12:44,738] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.4827735e-31 1.0000000e+00 1.0250531e-33 0.0000000e+00 0.0000000e+00], sampled 0.00874600260035685
[2019-03-26 18:13:00,791] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02071849], dtype=float32), 0.11045197]
[2019-03-26 18:13:00,792] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.20483961333333, 96.54208166000001, 1.0, 2.0, 0.4111805871741657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 604521.3855472603, 604521.3855472596, 174696.1089396978]
[2019-03-26 18:13:00,795] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:13:00,797] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.145018e-32 1.000000e+00 7.777601e-35 0.000000e+00 0.000000e+00], sampled 0.8784091170091658
[2019-03-26 18:13:05,984] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 18:13:06,247] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 18:13:06,277] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 18:13:06,283] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 18:13:06,500] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 18:13:07,519] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2025000, evaluation results [2025000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 18:13:08,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7655511e-29 1.0000000e+00 2.9539976e-32 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:08,826] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9840
[2019-03-26 18:13:08,833] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6945860471020369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 970700.3330538451, 970700.3330538458, 219677.5756208749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765200.0000, 
sim time next is 4765800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.708105031886024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989602.2348464536, 989602.2348464536, 222601.007603375], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6483193155253302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27488950967957043, 0.27488950967957043, 0.3322403098557836], 
reward next is 0.6678, 
noisyNet noise sample is [array([-0.0297571], dtype=float32), 0.32152393]. 
=============================================
[2019-03-26 18:13:10,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7545068e-10 9.9947459e-01 4.8080399e-17 5.2545761e-04 8.6334954e-20], sum to 1.0000
[2019-03-26 18:13:10,398] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3946
[2019-03-26 18:13:10,414] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3378656.149663127 W.
[2019-03-26 18:13:10,420] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 51.83333333333334, 1.0, 2.0, 0.9688782831884711, 1.0, 2.0, 0.8050291811084981, 1.0, 2.0, 1.03, 7.00511894254281, 6.9112, 170.5573041426782, 3378656.149663127, 3311378.19074139, 619721.5710139654], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4284600.0000, 
sim time next is 4285200.0000, 
raw observation next is [38.0, 51.66666666666667, 1.0, 2.0, 0.9808689396111492, 1.0, 2.0, 0.8110245093198374, 1.0, 2.0, 1.03, 7.005119888869075, 6.9112, 170.5573041426782, 3403852.456778342, 3336573.819964607, 624737.9869606517], 
processed observation next is [1.0, 0.6086956521739131, 1.0, 0.5166666666666667, 1.0, 1.0, 0.9769505296519869, 1.0, 1.0, 0.772318685927515, 1.0, 1.0, 1.0365853658536586, 0.009391988886907487, 0.0, 0.8375144448122397, 0.9455145713273172, 0.9268260611012796, 0.9324447566576891], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.873237], dtype=float32), -1.8184044]. 
=============================================
[2019-03-26 18:13:13,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.2902460e-08 9.8380232e-01 1.4222092e-15 1.6197618e-02 2.9309100e-17], sum to 1.0000
[2019-03-26 18:13:13,274] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5233
[2019-03-26 18:13:13,285] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3514924.027287057 W.
[2019-03-26 18:13:13,291] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.5, 57.0, 1.0, 2.0, 1.033723842533793, 1.0, 2.0, 0.8374519607811594, 1.0, 2.0, 1.03, 7.00512406073728, 6.9112, 170.5573041426782, 3514924.027287057, 3447642.401994426, 647491.8060781468], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4361400.0000, 
sim time next is 4362000.0000, 
raw observation next is [36.66666666666666, 56.0, 1.0, 2.0, 0.9829152984195548, 1.0, 2.0, 0.8120476887240399, 1.0, 2.0, 1.03, 7.005120050375562, 6.9112, 170.5573041426782, 3408152.579491104, 3340873.826983701, 625599.2680431784], 
processed observation next is [1.0, 0.4782608695652174, 0.9368088467614529, 0.56, 1.0, 1.0, 0.9794160221922348, 1.0, 1.0, 0.7735514321976384, 1.0, 1.0, 1.0365853658536586, 0.009392005037556217, 0.0, 0.8375144448122397, 0.94670904985864, 0.9280205074954725, 0.933730250810714], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43174103], dtype=float32), 0.27162856]. 
=============================================
[2019-03-26 18:13:13,305] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[36.26476 ]
 [35.4963  ]
 [37.780956]
 [41.575947]
 [42.601913]], R is [[36.99533081]
 [36.62537766]
 [36.25912476]
 [35.89653397]
 [35.53756714]].
[2019-03-26 18:13:36,198] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5849055e-32 1.0000000e+00 8.1265770e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:36,208] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4093
[2019-03-26 18:13:36,213] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4914015331781712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686653.4112827313, 686653.4112827313, 182259.6817495035], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4824000.0000, 
sim time next is 4824600.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4916469807593624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686996.4951066292, 686996.4951066292, 182297.5075026217], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38752648284260527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19083235975184146, 0.19083235975184146, 0.27208583209346526], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.8383311], dtype=float32), -1.3148074]. 
=============================================
[2019-03-26 18:13:40,060] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.4485043e-26 1.0000000e+00 8.1814088e-29 3.4276273e-31 6.7314144e-35], sum to 1.0000
[2019-03-26 18:13:40,071] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4900
[2019-03-26 18:13:40,076] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.78333333333334, 91.0, 1.0, 2.0, 0.9952744216933831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1391194.700776381, 1391194.700776381, 297492.3228865843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5461800.0000, 
sim time next is 5462400.0000, 
raw observation next is [27.96666666666667, 90.0, 1.0, 2.0, 0.8377966243943195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1170950.829298204, 1170950.829298205, 253403.0225037101], 
processed observation next is [1.0, 0.21739130434782608, 0.524486571879937, 0.9, 1.0, 1.0, 0.8045742462582162, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3252641192495011, 0.3252641192495014, 0.3782134664234479], 
reward next is 0.6218, 
noisyNet noise sample is [array([1.7209997], dtype=float32), -1.5266677]. 
=============================================
[2019-03-26 18:13:44,198] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0999073e-31 1.0000000e+00 1.0701027e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:44,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3291
[2019-03-26 18:13:44,212] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 72.0, 1.0, 2.0, 0.5290435147289404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739270.2375146913, 739270.2375146907, 188271.8025317228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5077800.0000, 
sim time next is 5078400.0000, 
raw observation next is [29.33333333333334, 72.66666666666666, 1.0, 2.0, 0.5276515775416417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737324.5093424097, 737324.509342409, 188041.9838990092], 
processed observation next is [0.0, 0.782608695652174, 0.5892575039494474, 0.7266666666666666, 1.0, 1.0, 0.4309055151104117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2048123637062249, 0.20481236370622471, 0.2806596774612078], 
reward next is 0.7193, 
noisyNet noise sample is [array([0.56177634], dtype=float32), 0.6137466]. 
=============================================
[2019-03-26 18:13:51,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4974893e-08 3.7061058e-03 1.7401657e-15 9.9629372e-01 8.7744322e-17], sum to 1.0000
[2019-03-26 18:13:51,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6394
[2019-03-26 18:13:51,835] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 1.009902191770063, 1.0, 2.0, 1.009902191770063, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2825037.975970776, 2825037.975970776, 535009.3130544883], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5478600.0000, 
sim time next is 5479200.0000, 
raw observation next is [33.7, 68.0, 1.0, 2.0, 0.9883247802610358, 1.0, 2.0, 0.9883247802610358, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2764611.868934564, 2764611.868934563, 521982.5998201406], 
processed observation next is [1.0, 0.43478260869565216, 0.7962085308056873, 0.68, 1.0, 1.0, 0.985933470194019, 1.0, 1.0, 0.985933470194019, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7679477413707122, 0.7679477413707119, 0.7790785071942397], 
reward next is 0.2209, 
noisyNet noise sample is [array([-0.03264683], dtype=float32), -0.9569201]. 
=============================================
[2019-03-26 18:13:52,657] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7109103e-07 6.9205439e-01 1.1596104e-14 3.0794543e-01 6.6718943e-16], sum to 1.0000
[2019-03-26 18:13:52,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-26 18:13:52,670] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.73333333333333, 58.5, 1.0, 2.0, 0.9417326792961809, 1.0, 2.0, 0.9417326792961809, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2634143.754844085, 2634143.754844085, 494778.9449453451], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5307000.0000, 
sim time next is 5307600.0000, 
raw observation next is [35.06666666666666, 57.00000000000001, 1.0, 2.0, 0.9459936686045056, 1.0, 2.0, 0.9459936686045056, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2646074.894577194, 2646074.894577193, 497213.2215415586], 
processed observation next is [1.0, 0.43478260869565216, 0.8609794628751973, 0.5700000000000001, 1.0, 1.0, 0.934932130848802, 1.0, 1.0, 0.934932130848802, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7350208040492205, 0.7350208040492203, 0.7421092858829234], 
reward next is 0.2579, 
noisyNet noise sample is [array([-1.1429439], dtype=float32), 0.90265155]. 
=============================================
[2019-03-26 18:13:53,481] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2356484e-33 1.0000000e+00 2.4926886e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:53,492] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0007
[2019-03-26 18:13:53,495] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 89.0, 1.0, 2.0, 0.4839199932017846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676195.8533694813, 676195.8533694813, 181114.3606570241], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5024400.0000, 
sim time next is 5025000.0000, 
raw observation next is [25.16666666666667, 89.0, 1.0, 2.0, 0.4772217484235572, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669114.770606295, 669114.770606295, 180398.2270057079], 
processed observation next is [0.0, 0.13043478260869565, 0.39178515007898923, 0.89, 1.0, 1.0, 0.3701466848476593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18586521405730416, 0.18586521405730416, 0.2692510850831461], 
reward next is 0.7307, 
noisyNet noise sample is [array([1.0838345], dtype=float32), 0.3351232]. 
=============================================
[2019-03-26 18:13:53,506] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.040276]
 [71.864716]
 [71.70611 ]
 [71.61004 ]
 [71.443886]], R is [[72.22650909]
 [72.23392487]
 [72.24041748]
 [72.24604034]
 [72.25080872]].
[2019-03-26 18:13:53,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.5567780e-32 1.0000000e+00 1.1649135e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:53,647] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1416
[2019-03-26 18:13:53,653] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 65.0, 1.0, 2.0, 0.5646492078273323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 789043.0917657722, 789043.0917657722, 194345.3254130156], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5142600.0000, 
sim time next is 5143200.0000, 
raw observation next is [32.0, 64.33333333333334, 1.0, 2.0, 0.5609148420134713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 783822.7484076903, 783822.7484076909, 193690.6884477177], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.6433333333333334, 1.0, 1.0, 0.47098173736562804, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21772854122435842, 0.21772854122435858, 0.28909057977271296], 
reward next is 0.7109, 
noisyNet noise sample is [array([-1.3495059], dtype=float32), 0.06773192]. 
=============================================
[2019-03-26 18:13:55,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.810586e-32 1.000000e+00 9.205848e-34 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:13:55,523] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3076
[2019-03-26 18:13:55,527] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4764020168090374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665815.2861503358, 665815.2861503358, 179997.5090513399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5017200.0000, 
sim time next is 5017800.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4759964624252657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 665248.7122957862, 665248.7122957857, 179936.8883821992], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.3686704366569466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18479130897105173, 0.18479130897105156, 0.2685625199734316], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.30877796], dtype=float32), -1.3145328]. 
=============================================
[2019-03-26 18:13:58,994] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7147856e-29 1.0000000e+00 1.5533373e-32 5.2511748e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:13:59,001] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3572
[2019-03-26 18:13:59,009] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5162498980852747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721386.7339989959, 721386.7339989964, 186180.6622535018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5098800.0000, 
sim time next is 5099400.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5146236257301708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719113.4775577422, 719113.4775577415, 185918.4154986019], 
processed observation next is [0.0, 0.0, 0.4549763033175356, 0.865, 1.0, 1.0, 0.41520918762671183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1997537437660395, 0.1997537437660393, 0.277490172385973], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.31679317], dtype=float32), -1.7352788]. 
=============================================
[2019-03-26 18:14:03,293] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8010568e-33 1.0000000e+00 8.0212093e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:14:03,305] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7581
[2019-03-26 18:14:03,311] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.43333333333334, 60.00000000000001, 1.0, 2.0, 0.5469084769276154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764243.2039768497, 764243.2039768504, 191272.2893454655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5667600.0000, 
sim time next is 5668200.0000, 
raw observation next is [32.4, 60.0, 1.0, 2.0, 0.5446811968666186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761129.7150157875, 761129.7150157881, 190893.1658854079], 
processed observation next is [0.0, 0.6086956521739131, 0.7345971563981042, 0.6, 1.0, 1.0, 0.4514231287549622, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21142492083771874, 0.2114249208377189, 0.2849151729632954], 
reward next is 0.7151, 
noisyNet noise sample is [array([-1.6352193], dtype=float32), -0.51659507]. 
=============================================
[2019-03-26 18:14:03,919] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 18:14:03,920] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:14:03,921] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:14:03,921] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:14:03,922] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:14:03,923] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:14:03,924] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:14:03,926] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:14:03,924] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:14:03,926] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:14:03,928] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:14:03,957] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run83
[2019-03-26 18:14:03,987] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run83
[2019-03-26 18:14:03,988] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run83
[2019-03-26 18:14:04,042] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run83
[2019-03-26 18:14:04,043] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run83
[2019-03-26 18:14:08,585] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:14:08,587] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.7, 41.0, 1.0, 2.0, 0.21604237013034, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 361197.5706202179, 361197.5706202179, 156644.824841806]
[2019-03-26 18:14:08,588] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:14:08,591] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.286173e-35 1.000000e+00 7.539970e-37 0.000000e+00 0.000000e+00], sampled 0.38017269687310273
[2019-03-26 18:14:28,554] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:14:28,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.60049174833334, 86.40503890666668, 1.0, 2.0, 0.4351100390162859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655252.0036571901, 655252.0036571895, 179933.2762181004]
[2019-03-26 18:14:28,556] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:14:28,558] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1026583e-32 1.0000000e+00 6.1211251e-35 0.0000000e+00 0.0000000e+00], sampled 0.2933293211720046
[2019-03-26 18:15:00,488] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:15:00,489] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.99360480166666, 57.28409749333333, 1.0, 2.0, 0.5375792054673478, 0.0, 2.0, 0.0, 1.0, 1.0, 0.933597299736895, 6.9112, 6.9112, 168.9126797988663, 1502935.599144662, 1502935.599144662, 329279.5749180807]
[2019-03-26 18:15:00,491] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:15:00,494] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.0418961e-27 1.0000000e+00 6.9520286e-30 2.6738184e-33 1.8407919e-36], sampled 0.5782520227038647
[2019-03-26 18:15:16,177] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:15:16,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.779265967113488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1089103.197187177, 1089103.197187176, 238883.2484800868]
[2019-03-26 18:15:16,181] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:15:16,183] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.05767705e-32 1.00000000e+00 2.38498299e-34 0.00000000e+00
 0.00000000e+00], sampled 0.7273056988077085
[2019-03-26 18:15:22,823] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:15:22,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.19325020666667, 60.55008312, 1.0, 2.0, 0.59302146733981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 828706.0688993181, 828706.0688993181, 199452.0805522917]
[2019-03-26 18:15:22,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:15:22,831] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.8454517e-33 1.0000000e+00 1.7477269e-36 0.0000000e+00 0.0000000e+00], sampled 0.2189026632420299
[2019-03-26 18:15:32,026] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:15:32,028] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.9, 94.0, 1.0, 2.0, 0.6603204725723009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 922792.5823845468, 922792.5823845468, 212512.677932431]
[2019-03-26 18:15:32,029] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:15:32,030] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.500004e-33 1.000000e+00 6.348183e-35 0.000000e+00 0.000000e+00], sampled 0.14495590909476186
[2019-03-26 18:15:37,775] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01830774], dtype=float32), 0.110658064]
[2019-03-26 18:15:37,777] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.702239295, 75.550962675, 1.0, 2.0, 0.4817584798798711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 683162.1287711712, 683162.1287711719, 182068.4875923827]
[2019-03-26 18:15:37,778] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:15:37,780] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.2506901e-33 1.0000000e+00 1.9906982e-35 0.0000000e+00 0.0000000e+00], sampled 0.0838095033183377
[2019-03-26 18:15:59,727] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2300 2927457024.3359 1338.0000
[2019-03-26 18:15:59,782] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 18:15:59,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 18:15:59,960] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 18:16:00,009] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 18:16:01,027] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2050000, evaluation results [2050000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8254.230042292205, 2927457024.3359056, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 18:16:09,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.357798e-36 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:16:09,683] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5241
[2019-03-26 18:16:09,687] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.08333333333334, 78.83333333333334, 1.0, 2.0, 0.6249132033491641, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 873290.8635204057, 873290.8635204063, 205479.5455949387], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5345400.0000, 
sim time next is 5346000.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6238121772107247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 871751.5926885338, 871751.5926885332, 205266.4086801062], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5467616592900297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2421532201912594, 0.24215322019125923, 0.30636777414941224], 
reward next is 0.6936, 
noisyNet noise sample is [array([0.30429], dtype=float32), -0.35861382]. 
=============================================
[2019-03-26 18:16:09,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.91926 ]
 [68.169525]
 [68.45077 ]
 [68.41275 ]
 [68.34161 ]], R is [[67.75727844]
 [67.77301788]
 [67.78823853]
 [67.8028717 ]
 [67.81682587]].
[2019-03-26 18:16:09,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7328524e-33 1.0000000e+00 1.4503875e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:16:09,943] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2845
[2019-03-26 18:16:09,949] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.1, 71.33333333333334, 1.0, 2.0, 0.5685703269645005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 794524.5288780818, 794524.5288780824, 195037.5903009192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5512800.0000, 
sim time next is 5513400.0000, 
raw observation next is [30.85, 73.0, 1.0, 2.0, 0.5699094366103854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796396.5124781496, 796396.5124781496, 195274.9081794913], 
processed observation next is [1.0, 0.8260869565217391, 0.661137440758294, 0.73, 1.0, 1.0, 0.4818185983257655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22122125346615268, 0.22122125346615268, 0.2914550868350616], 
reward next is 0.7085, 
noisyNet noise sample is [array([2.4042697], dtype=float32), 0.054640293]. 
=============================================
[2019-03-26 18:16:11,893] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.156720e-31 1.000000e+00 8.358683e-33 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:16:11,899] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8796
[2019-03-26 18:16:11,905] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 95.0, 1.0, 2.0, 0.6666946170284421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 931704.3056290358, 931704.3056290364, 213819.2751754902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5547000.0000, 
sim time next is 5547600.0000, 
raw observation next is [25.6, 95.0, 1.0, 2.0, 0.6532032662147249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 912842.0689417168, 912842.0689417161, 211067.1303692612], 
processed observation next is [1.0, 0.21739130434782608, 0.4123222748815167, 0.95, 1.0, 1.0, 0.5821726098972589, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2535672413726991, 0.2535672413726989, 0.3150255677153152], 
reward next is 0.6850, 
noisyNet noise sample is [array([-0.34174287], dtype=float32), -0.78701663]. 
=============================================
[2019-03-26 18:16:15,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.5433065e-28 1.0000000e+00 5.6429483e-32 4.9273051e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:16:15,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8019
[2019-03-26 18:16:15,643] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 85.66666666666667, 1.0, 2.0, 0.5906428527188955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825380.8296423217, 825380.8296423217, 199015.6882775268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5443800.0000, 
sim time next is 5444400.0000, 
raw observation next is [28.9, 86.33333333333334, 1.0, 2.0, 0.5921734180530719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827520.5176142306, 827520.5176142306, 199296.8405240625], 
processed observation next is [1.0, 0.0, 0.5687203791469194, 0.8633333333333334, 1.0, 1.0, 0.5086426723530987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2298668104483974, 0.2298668104483974, 0.2974579709314366], 
reward next is 0.7025, 
noisyNet noise sample is [array([-0.8809822], dtype=float32), 0.7493013]. 
=============================================
[2019-03-26 18:16:17,429] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1007861e-13 1.0000000e+00 7.9686347e-20 8.9678037e-13 3.3456863e-23], sum to 1.0000
[2019-03-26 18:16:17,437] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5967
[2019-03-26 18:16:17,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2554721.277624717 W.
[2019-03-26 18:16:17,449] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.5, 62.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.289285354615496, 6.9112, 168.9107346839164, 2554721.277624717, 2286498.042535122, 475400.6205771005], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5569200.0000, 
sim time next is 5569800.0000, 
raw observation next is [32.6, 61.16666666666667, 1.0, 2.0, 0.9543644187823453, 1.0, 1.0, 0.9543644187823453, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2669514.053080255, 2669514.053080254, 502016.9805014086], 
processed observation next is [1.0, 0.4782608695652174, 0.7440758293838864, 0.6116666666666667, 1.0, 1.0, 0.9450173720269222, 1.0, 0.5, 0.9450173720269222, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.741531681411182, 0.7415316814111816, 0.7492790753752366], 
reward next is 0.2507, 
noisyNet noise sample is [array([0.2726077], dtype=float32), -0.98764205]. 
=============================================
[2019-03-26 18:16:28,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.483445e-34 1.000000e+00 4.622951e-36 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:16:28,073] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1293
[2019-03-26 18:16:28,080] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.6, 53.0, 1.0, 2.0, 0.53386065857987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746003.939925248, 746003.939925248, 189071.7306394366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5750400.0000, 
sim time next is 5751000.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 0.5284454558690004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738434.2367303645, 738434.2367303645, 188173.1746026533], 
processed observation next is [0.0, 0.5652173913043478, 0.7819905213270142, 0.53, 1.0, 1.0, 0.431861995022892, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20512062131399014, 0.20512062131399014, 0.2808554844815721], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.5828607], dtype=float32), 0.9354729]. 
=============================================
[2019-03-26 18:16:28,090] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[75.85004 ]
 [75.74055 ]
 [75.72192 ]
 [75.628044]
 [75.610565]], R is [[75.95162964]
 [75.90991974]
 [75.86670685]
 [75.82466125]
 [75.78382111]].
[2019-03-26 18:16:34,340] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3521174e-34 1.0000000e+00 6.8497636e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:16:34,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2424
[2019-03-26 18:16:34,350] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 91.0, 1.0, 2.0, 0.5251428749602071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733817.7126240182, 733817.7126240176, 187629.4753346363], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6234600.0000, 
sim time next is 6235200.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.5251337541611616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733804.9631114175, 733804.9631114168, 187627.9789351105], 
processed observation next is [0.0, 0.17391304347826086, 0.4549763033175356, 0.91, 1.0, 1.0, 0.4278719929652549, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20383471197539374, 0.20383471197539355, 0.28004175960464256], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.7178048], dtype=float32), 0.34641916]. 
=============================================
[2019-03-26 18:16:35,807] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.700537e-34 1.000000e+00 5.096102e-36 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:16:35,815] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3312
[2019-03-26 18:16:35,819] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 53.0, 1.0, 2.0, 0.5386016581491159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 752631.2448169832, 752631.2448169838, 189866.068643478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5749200.0000, 
sim time next is 5749800.0000, 
raw observation next is [33.8, 53.0, 1.0, 2.0, 0.5415173487612382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756707.0241387336, 756707.0241387343, 190356.8480943336], 
processed observation next is [0.0, 0.5652173913043478, 0.800947867298578, 0.53, 1.0, 1.0, 0.4476112635677569, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21019639559409267, 0.21019639559409287, 0.2841146986482591], 
reward next is 0.7159, 
noisyNet noise sample is [array([-0.40783006], dtype=float32), 0.92478114]. 
=============================================
[2019-03-26 18:16:37,512] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3957225e-30 1.0000000e+00 4.0044078e-34 4.1779820e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 18:16:37,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7308
[2019-03-26 18:16:37,524] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 84.33333333333333, 1.0, 2.0, 0.5468479034284822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 764158.5288643345, 764158.5288643345, 191261.2868749911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5778600.0000, 
sim time next is 5779200.0000, 
raw observation next is [27.76666666666667, 84.66666666666667, 1.0, 2.0, 0.5463694601758492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 763489.7178750446, 763489.717875044, 191179.7054464957], 
processed observation next is [0.0, 0.9130434782608695, 0.515007898894155, 0.8466666666666667, 1.0, 1.0, 0.45345718093475806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21208047718751238, 0.21208047718751222, 0.2853428439499936], 
reward next is 0.7147, 
noisyNet noise sample is [array([0.7856101], dtype=float32), 0.8675912]. 
=============================================
[2019-03-26 18:16:40,346] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.6063108e-28 1.0000000e+00 8.7859372e-31 8.1128159e-37 5.3504518e-38], sum to 1.0000
[2019-03-26 18:16:40,359] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3496
[2019-03-26 18:16:40,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 88.66666666666667, 1.0, 2.0, 0.6540641099500806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 914045.6032298539, 914045.6032298539, 211242.1877923063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6505800.0000, 
sim time next is 6506400.0000, 
raw observation next is [26.93333333333334, 88.33333333333334, 1.0, 2.0, 0.6913109286306033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 966121.196061123, 966121.196061123, 218980.6237337792], 
processed observation next is [1.0, 0.30434782608695654, 0.4755134281200636, 0.8833333333333334, 1.0, 1.0, 0.6280854561814497, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2683669989058675, 0.2683669989058675, 0.3268367518414615], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.50988716], dtype=float32), 0.03347267]. 
=============================================
[2019-03-26 18:16:45,442] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.5601001e-07 3.2804793e-01 4.4709201e-14 6.7195165e-01 4.9670372e-16], sum to 1.0000
[2019-03-26 18:16:45,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0256
[2019-03-26 18:16:45,463] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2377947.037172806 W.
[2019-03-26 18:16:45,469] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.43333333333334, 72.66666666666667, 1.0, 2.0, 0.8502268685705581, 1.0, 2.0, 0.8502268685705581, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2377947.037172806, 2377947.037172806, 445071.890120353], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5912400.0000, 
sim time next is 5913000.0000, 
raw observation next is [31.6, 72.0, 1.0, 2.0, 0.552447963387177, 1.0, 2.0, 0.552447963387177, 1.0, 1.0, 0.9594194150702554, 6.9112, 6.9112, 170.5573041426782, 2317605.500272758, 2317605.500272758, 453310.6053095451], 
processed observation next is [1.0, 0.43478260869565216, 0.6966824644549764, 0.72, 1.0, 1.0, 0.4607806787797314, 1.0, 1.0, 0.4607806787797314, 1.0, 0.5, 0.9505114817929943, 0.0, 0.0, 0.8375144448122397, 0.6437793056313216, 0.6437793056313216, 0.6765829929993211], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49494725], dtype=float32), 1.6617763]. 
=============================================
[2019-03-26 18:16:45,486] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[38.46505 ]
 [37.029194]
 [37.347004]
 [39.870216]
 [38.48056 ]], R is [[38.84524155]
 [38.79250336]
 [38.40457916]
 [38.02053452]
 [37.97945023]].
[2019-03-26 18:16:50,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.4464770e-09 8.0212456e-04 1.4314481e-16 9.9919790e-01 8.7996350e-18], sum to 1.0000
[2019-03-26 18:16:50,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6412
[2019-03-26 18:16:50,728] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 67.0, 1.0, 2.0, 0.8838153375545316, 1.0, 2.0, 0.8838153375545316, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2471981.471438034, 2471981.471438034, 462748.4742624223], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6004800.0000, 
sim time next is 6005400.0000, 
raw observation next is [32.0, 68.16666666666667, 1.0, 2.0, 0.9081734548590571, 1.0, 2.0, 0.9081734548590571, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2540178.99710968, 2540178.99710968, 475974.6449503748], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.6816666666666668, 1.0, 1.0, 0.8893656082639242, 1.0, 1.0, 0.8893656082639242, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7056052769749112, 0.7056052769749112, 0.7104099178363803], 
reward next is 0.2896, 
noisyNet noise sample is [array([0.18144478], dtype=float32), -0.55812466]. 
=============================================
[2019-03-26 18:16:54,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6312687e-28 1.0000000e+00 4.0185515e-32 7.9744958e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:16:54,443] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3113
[2019-03-26 18:16:54,450] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 92.33333333333333, 1.0, 2.0, 0.7088847551475516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 990692.4344048374, 990692.4344048367, 222774.0295728766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6066600.0000, 
sim time next is 6067200.0000, 
raw observation next is [26.36666666666667, 91.66666666666667, 1.0, 2.0, 0.6765301907666971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 945455.6171859433, 945455.6171859433, 215860.3521127785], 
processed observation next is [1.0, 0.21739130434782608, 0.4486571879936811, 0.9166666666666667, 1.0, 1.0, 0.610277338273129, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2626265603294287, 0.2626265603294287, 0.32217963001907235], 
reward next is 0.6778, 
noisyNet noise sample is [array([0.07336638], dtype=float32), 0.20994942]. 
=============================================
[2019-03-26 18:16:56,010] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.42073344e-09 1.06936665e-02 5.13807592e-16 9.89306271e-01
 2.61622454e-17], sum to 1.0000
[2019-03-26 18:16:56,016] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5265
[2019-03-26 18:16:56,022] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 0.8421688325322276, 1.0, 2.0, 0.8421688325322276, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2355388.77433095, 2355388.77433095, 440918.3317392495], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6091200.0000, 
sim time next is 6091800.0000, 
raw observation next is [31.01666666666667, 65.0, 1.0, 2.0, 0.6983701772135967, 1.0, 2.0, 0.6983701772135967, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1952862.802268803, 1952862.802268803, 373426.42415451], 
processed observation next is [1.0, 0.5217391304347826, 0.6690363349131123, 0.65, 1.0, 1.0, 0.6365905749561406, 1.0, 1.0, 0.6365905749561406, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5424618895191119, 0.5424618895191119, 0.557352871872403], 
reward next is 0.4426, 
noisyNet noise sample is [array([-1.1967945], dtype=float32), -0.09169536]. 
=============================================
[2019-03-26 18:16:57,613] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 18:16:57,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:16:57,615] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:16:57,616] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:16:57,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:16:57,618] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:16:57,618] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:16:57,617] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:16:57,622] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:16:57,622] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:16:57,621] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:16:57,643] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run84
[2019-03-26 18:16:57,669] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run84
[2019-03-26 18:16:57,670] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run84
[2019-03-26 18:16:57,698] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run84
[2019-03-26 18:16:57,698] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run84
[2019-03-26 18:17:06,743] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02399908], dtype=float32), 0.11242924]
[2019-03-26 18:17:06,746] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.63333333333333, 57.33333333333334, 1.0, 2.0, 0.3019979791048709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492677.3097260438, 492677.3097260438, 166443.8653989917]
[2019-03-26 18:17:06,746] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:17:06,749] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.2487593e-33 1.0000000e+00 5.7365496e-35 0.0000000e+00 0.0000000e+00], sampled 0.07306793398629496
[2019-03-26 18:18:03,770] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02399908], dtype=float32), 0.11242924]
[2019-03-26 18:18:03,772] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.98001128, 75.52843613, 1.0, 2.0, 0.7263336735325515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1015089.59212967, 1015089.592129669, 226647.8561390158]
[2019-03-26 18:18:03,772] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:18:03,774] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8427304e-31 1.0000000e+00 1.4441236e-33 0.0000000e+00 0.0000000e+00], sampled 0.9655731444610526
[2019-03-26 18:18:36,992] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02399908], dtype=float32), 0.11242924]
[2019-03-26 18:18:36,992] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.48333333333333, 68.33333333333334, 1.0, 2.0, 0.8467927019626957, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00598445090076, 6.9112, 168.9123159841423, 2080563.630283382, 2013320.533575465, 419731.0306323693]
[2019-03-26 18:18:36,993] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:18:36,995] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.2035728e-17 1.0000000e+00 6.1449531e-24 1.1203390e-13 6.6837473e-27], sampled 0.24265602268190345
[2019-03-26 18:18:36,997] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2080563.630283382 W.
[2019-03-26 18:18:49,129] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.7603 3007682365.2861 1766.0000
[2019-03-26 18:18:49,530] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8544 2927493856.5832 1339.0000
[2019-03-26 18:18:49,626] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6714 2779214869.5150 932.0000
[2019-03-26 18:18:49,788] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7893.3347 3163425443.8424 1762.0000
[2019-03-26 18:18:49,788] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 18:18:50,807] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2075000, evaluation results [2075000.0, 7893.334694252304, 3163425443.8424463, 1762.0, 8254.8543695633, 2927493856.5831656, 1339.0, 8660.671402064441, 2779214869.515002, 932.0, 7999.760254669288, 3007682365.2860537, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 18:18:54,144] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.3644130e-29 1.0000000e+00 6.7073049e-32 1.1082006e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:18:54,154] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-26 18:18:54,160] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.03333333333333, 90.66666666666667, 1.0, 2.0, 0.6725707463073679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 939919.8176081327, 939919.8176081327, 215034.3510619343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6680400.0000, 
sim time next is 6681000.0000, 
raw observation next is [26.11666666666666, 90.33333333333333, 1.0, 2.0, 0.6622723438651841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 925521.4954580624, 925521.4954580631, 212910.9042391225], 
processed observation next is [1.0, 0.30434782608695654, 0.4368088467614531, 0.9033333333333333, 1.0, 1.0, 0.5930992094761254, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2570893042939062, 0.2570893042939064, 0.31777746901361564], 
reward next is 0.6822, 
noisyNet noise sample is [array([1.1044172], dtype=float32), -1.026259]. 
=============================================
[2019-03-26 18:18:54,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[63.90004 ]
 [63.48261 ]
 [63.840862]
 [64.53687 ]
 [65.028694]], R is [[64.22990417]
 [64.26665497]
 [64.28659821]
 [64.31060028]
 [64.3445282 ]].
[2019-03-26 18:19:02,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.8006522e-32 1.0000000e+00 7.4431315e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:19:02,579] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0662
[2019-03-26 18:19:02,583] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 79.0, 1.0, 2.0, 0.5217524332401644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729078.3928511643, 729078.3928511643, 187074.4467776832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6334200.0000, 
sim time next is 6334800.0000, 
raw observation next is [28.2, 78.33333333333333, 1.0, 2.0, 0.52149989808993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728725.3881217334, 728725.3881217334, 187033.2608351868], 
processed observation next is [0.0, 0.30434782608695654, 0.5355450236966824, 0.7833333333333333, 1.0, 1.0, 0.4234938531203976, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20242371892270372, 0.20242371892270372, 0.27915412064953254], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.74796164], dtype=float32), -0.20256366]. 
=============================================
[2019-03-26 18:19:05,519] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5156586e-33 1.0000000e+00 1.3274372e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:19:05,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8383
[2019-03-26 18:19:05,533] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 88.0, 1.0, 2.0, 0.5282432175768795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738151.5366599717, 738151.5366599717, 188139.2296132663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6321600.0000, 
sim time next is 6322200.0000, 
raw observation next is [26.76666666666667, 88.16666666666667, 1.0, 2.0, 0.5272988100172635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736831.3916006412, 736831.3916006412, 187983.5238761928], 
processed observation next is [0.0, 0.17391304347826086, 0.46761453396524505, 0.8816666666666667, 1.0, 1.0, 0.430480493996703, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20467538655573367, 0.20467538655573367, 0.28057242369581015], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.4833524], dtype=float32), 0.7297168]. 
=============================================
[2019-03-26 18:19:07,655] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5160768e-32 1.0000000e+00 2.2138244e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:19:07,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1718
[2019-03-26 18:19:07,666] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.8, 63.33333333333334, 1.0, 2.0, 0.5173357842469581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722904.6237354839, 722904.6237354833, 186356.9608302644], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6358800.0000, 
sim time next is 6359400.0000, 
raw observation next is [30.85, 64.0, 1.0, 2.0, 0.5224580280036828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730064.704837345, 730064.704837345, 187189.8342701106], 
processed observation next is [0.0, 0.6086956521739131, 0.661137440758294, 0.64, 1.0, 1.0, 0.4246482265104612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20279575134370695, 0.20279575134370695, 0.2793878123434486], 
reward next is 0.7206, 
noisyNet noise sample is [array([0.05293489], dtype=float32), -0.66410816]. 
=============================================
[2019-03-26 18:19:07,936] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0706942e-27 1.0000000e+00 1.6355539e-30 1.1133093e-32 1.2718094e-37], sum to 1.0000
[2019-03-26 18:19:07,946] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9006
[2019-03-26 18:19:07,954] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.56666666666667, 87.16666666666667, 1.0, 2.0, 0.4811017808085878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 672256.6350135148, 672256.6350135142, 180687.5239666633], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7078200.0000, 
sim time next is 7078800.0000, 
raw observation next is [25.53333333333333, 87.33333333333334, 1.0, 2.0, 0.4820045854936138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673518.5485279667, 673518.548527966, 180823.9668520683], 
processed observation next is [1.0, 0.9565217391304348, 0.4091627172195892, 0.8733333333333334, 1.0, 1.0, 0.37590913914893226, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18708848570221298, 0.1870884857022128, 0.26988651768965416], 
reward next is 0.7301, 
noisyNet noise sample is [array([-1.3625914], dtype=float32), 1.2017326]. 
=============================================
[2019-03-26 18:19:12,423] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5504936e-30 1.0000000e+00 2.7831963e-33 4.4328577e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:19:12,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9900
[2019-03-26 18:19:12,438] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.41666666666666, 67.83333333333333, 1.0, 2.0, 0.4183159584869597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612532.4056348385, 612532.4056348385, 175380.4542522756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6990600.0000, 
sim time next is 6991200.0000, 
raw observation next is [27.3, 69.0, 1.0, 2.0, 0.4224405810370953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616696.7005535706, 616696.7005535706, 175725.2670841848], 
processed observation next is [0.0, 0.9565217391304348, 0.4928909952606636, 0.69, 1.0, 1.0, 0.3041452783579462, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17130463904265852, 0.17130463904265852, 0.2622765180360967], 
reward next is 0.7377, 
noisyNet noise sample is [array([-2.0231314], dtype=float32), 0.09287898]. 
=============================================
[2019-03-26 18:19:15,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.0858714e-27 1.0000000e+00 2.9702365e-31 2.9397788e-31 2.1646259e-37], sum to 1.0000
[2019-03-26 18:19:15,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2104
[2019-03-26 18:19:15,427] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.3956186e-16 1.0000000e+00 1.1118768e-21 1.8001460e-15 1.0058293e-25], sum to 1.0000
[2019-03-26 18:19:15,429] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.18333333333333, 67.5, 1.0, 2.0, 0.4822364814289826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673842.6860054275, 673842.6860054282, 180860.1301193191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6545400.0000, 
sim time next is 6546000.0000, 
raw observation next is [29.06666666666667, 68.0, 1.0, 2.0, 0.4845150334527664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 677027.5858352553, 677027.585835256, 181205.7253695931], 
processed observation next is [1.0, 0.782608695652174, 0.5766192733017379, 0.68, 1.0, 1.0, 0.37893377524429694, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18806321828757092, 0.1880632182875711, 0.27045630652178076], 
reward next is 0.7295, 
noisyNet noise sample is [array([0.70287466], dtype=float32), -0.16146834]. 
=============================================
[2019-03-26 18:19:15,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2918
[2019-03-26 18:19:15,442] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3378256.740790027 W.
[2019-03-26 18:19:15,446] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 55.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.62248372061501, 6.9112, 168.8973049250954, 3378256.740790027, 1454956.984933553, 307513.022519286], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6528000.0000, 
sim time next is 6528600.0000, 
raw observation next is [31.95, 55.5, 1.0, 2.0, 0.593795335563093, 1.0, 1.0, 0.593795335563093, 1.0, 1.0, 1.012646752902263, 6.9112, 6.9112, 170.5573041426782, 2491237.089502327, 2491237.089502327, 481965.0410680001], 
processed observation next is [1.0, 0.5652173913043478, 0.7132701421800948, 0.555, 1.0, 1.0, 0.5105967898350519, 1.0, 0.5, 0.5105967898350519, 1.0, 0.5, 1.0154228693930036, 0.0, 0.0, 0.8375144448122397, 0.6920103026395353, 0.6920103026395353, 0.7193508075641792], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7539578], dtype=float32), 1.2635579]. 
=============================================
[2019-03-26 18:19:15,457] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.98209 ]
 [67.18494 ]
 [66.56361 ]
 [65.66861 ]
 [64.223755]], R is [[68.25076294]
 [68.29830933]
 [68.34645081]
 [68.39514923]
 [68.44486237]].
[2019-03-26 18:19:21,984] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.5521633e-25 1.0000000e+00 4.8872064e-29 1.4305023e-28 1.3356761e-35], sum to 1.0000
[2019-03-26 18:19:21,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2755
[2019-03-26 18:19:22,002] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4989342556943306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 697182.6152101486, 697182.6152101492, 183429.3100557103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6652800.0000, 
sim time next is 6653400.0000, 
raw observation next is [25.91666666666667, 89.5, 1.0, 2.0, 0.4981941303632086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696148.0668973145, 696148.0668973145, 183313.6742048307], 
processed observation next is [1.0, 0.0, 0.4273301737756717, 0.895, 1.0, 1.0, 0.395414614895432, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19337446302703182, 0.19337446302703182, 0.27360249881318016], 
reward next is 0.7264, 
noisyNet noise sample is [array([-2.9573758], dtype=float32), 0.76287925]. 
=============================================
[2019-03-26 18:19:22,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7342153e-33 1.0000000e+00 5.8013815e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:19:22,207] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3877
[2019-03-26 18:19:22,214] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.4, 51.0, 1.0, 2.0, 0.337884572356129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526686.61259816, 526686.6125981595, 168914.812118924], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6865200.0000, 
sim time next is 6865800.0000, 
raw observation next is [28.48333333333333, 49.83333333333334, 1.0, 2.0, 0.3310783889161891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 517710.7873216933, 517710.7873216926, 168249.5508739159], 
processed observation next is [0.0, 0.4782608695652174, 0.5489731437598735, 0.4983333333333334, 1.0, 1.0, 0.19407034809179413, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1438085520338037, 0.1438085520338035, 0.2511187326476357], 
reward next is 0.7489, 
noisyNet noise sample is [array([0.06024626], dtype=float32), 0.41206563]. 
=============================================
[2019-03-26 18:19:22,276] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.9896114e-28 1.0000000e+00 1.4034901e-31 8.1405124e-34 3.6128193e-38], sum to 1.0000
[2019-03-26 18:19:22,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7044
[2019-03-26 18:19:22,289] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 76.66666666666667, 1.0, 2.0, 0.3325084926952793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520974.8087419514, 520974.8087419508, 168530.0698893191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6828600.0000, 
sim time next is 6829200.0000, 
raw observation next is [23.6, 77.0, 1.0, 2.0, 0.3320947521374722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520553.3023742306, 520553.3023742313, 168502.3308668552], 
processed observation next is [0.0, 0.043478260869565216, 0.3175355450236968, 0.77, 1.0, 1.0, 0.19529488209333998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1445981395483974, 0.14459813954839756, 0.2514960162191868], 
reward next is 0.7485, 
noisyNet noise sample is [array([-0.02931723], dtype=float32), 0.119826004]. 
=============================================
[2019-03-26 18:19:28,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6318897e-22 1.0000000e+00 1.1743493e-28 2.4075183e-24 1.0298471e-32], sum to 1.0000
[2019-03-26 18:19:28,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3972
[2019-03-26 18:19:28,686] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.93333333333333, 67.0, 1.0, 2.0, 0.4654666963528004, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650402.6171552227, 650402.6171552227, 178362.7854053545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6717000.0000, 
sim time next is 6717600.0000, 
raw observation next is [28.8, 67.0, 1.0, 2.0, 0.4688729788307622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 655163.7272999878, 655163.7272999872, 178862.8796718929], 
processed observation next is [1.0, 0.782608695652174, 0.5639810426540285, 0.67, 1.0, 1.0, 0.36008792630212305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1819899242499966, 0.18198992424999644, 0.26695952189834765], 
reward next is 0.7330, 
noisyNet noise sample is [array([0.16984296], dtype=float32), 1.7538931]. 
=============================================
[2019-03-26 18:19:32,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.3935393e-10 9.8006618e-01 1.8453011e-16 1.9933814e-02 1.4795988e-17], sum to 1.0000
[2019-03-26 18:19:32,682] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3112
[2019-03-26 18:19:32,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1897165.908807322 W.
[2019-03-26 18:19:32,695] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.85, 52.5, 1.0, 2.0, 0.6744550184042428, 1.0, 1.0, 0.6744550184042428, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1897165.908807322, 1897165.908807323, 364771.1026433503], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7039800.0000, 
sim time next is 7040400.0000, 
raw observation next is [30.93333333333334, 52.0, 1.0, 2.0, 0.691582849777214, 1.0, 2.0, 0.691582849777214, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1941645.073007325, 1941645.073007326, 371506.7720618932], 
processed observation next is [1.0, 0.4782608695652174, 0.6650868878357034, 0.52, 1.0, 1.0, 0.6284130720207397, 1.0, 1.0, 0.6284130720207397, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5393458536131458, 0.5393458536131461, 0.554487719495363], 
reward next is 0.4455, 
noisyNet noise sample is [array([-1.5135361], dtype=float32), -1.5944691]. 
=============================================
[2019-03-26 18:19:44,222] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.9612609e-26 1.0000000e+00 4.7493998e-29 1.4102031e-32 6.2015269e-36], sum to 1.0000
[2019-03-26 18:19:44,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3045
[2019-03-26 18:19:44,236] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.25, 72.0, 1.0, 2.0, 0.7570057984266811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1084885.957718935, 1084885.957718935, 237316.1300832219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7025400.0000, 
sim time next is 7026000.0000, 
raw observation next is [27.4, 71.0, 1.0, 2.0, 0.705546750514573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1011798.27218437, 1011798.27218437, 225494.4398628975], 
processed observation next is [1.0, 0.30434782608695654, 0.4976303317535545, 0.71, 1.0, 1.0, 0.6452370488127386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28105507560676946, 0.28105507560676946, 0.3365588654670112], 
reward next is 0.6634, 
noisyNet noise sample is [array([-2.4359508], dtype=float32), -0.56578636]. 
=============================================
[2019-03-26 18:19:44,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[63.200592]
 [63.435314]
 [64.05575 ]
 [65.73035 ]
 [66.04177 ]], R is [[63.71361923]
 [63.72228241]
 [63.73060989]
 [63.73501205]
 [63.78345871]].
[2019-03-26 18:19:47,331] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 18:19:47,334] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:19:47,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:19:47,336] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:19:47,337] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:19:47,337] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:19:47,338] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:19:47,338] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:19:47,339] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:19:47,342] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:19:47,342] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:19:47,363] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run85
[2019-03-26 18:19:47,390] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run85
[2019-03-26 18:19:47,418] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run85
[2019-03-26 18:19:47,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run85
[2019-03-26 18:19:47,441] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run85
[2019-03-26 18:20:23,310] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:20:23,314] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.86666666666667, 87.66666666666666, 1.0, 2.0, 0.3913259986696381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583304.5285266292, 583304.5285266292, 172987.4496605687]
[2019-03-26 18:20:23,316] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:20:23,322] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.6742903e-32 1.0000000e+00 2.5920762e-34 0.0000000e+00 0.0000000e+00], sampled 0.08522530243869364
[2019-03-26 18:20:33,625] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:20:33,629] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.87671129, 97.00982499166668, 1.0, 2.0, 0.2885472430456273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 464727.6933316372, 464727.6933316366, 164596.4801758595]
[2019-03-26 18:20:33,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:20:33,636] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.6763031e-28 1.0000000e+00 2.1702879e-31 4.0660585e-33 1.1258155e-37], sampled 0.28408385400488256
[2019-03-26 18:20:40,750] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:20:40,752] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.29852402333334, 77.58680175, 1.0, 2.0, 0.4965638115436813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 693869.2083273692, 693869.2083273698, 183058.7366083176]
[2019-03-26 18:20:40,752] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:20:40,754] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.0105500e-26 1.0000000e+00 5.5550444e-30 7.9829555e-30 5.1256587e-36], sampled 0.10523576298178405
[2019-03-26 18:20:46,986] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:20:46,988] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.45433335666667, 59.26343486, 1.0, 2.0, 0.8046403633659289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1124585.267679032, 1124585.267679032, 245053.822219805]
[2019-03-26 18:20:46,988] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:20:46,990] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.9607507e-26 1.0000000e+00 2.6660832e-29 7.0463542e-31 2.2100515e-35], sampled 0.3907041160466044
[2019-03-26 18:20:58,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:20:58,055] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.68480934833334, 84.41629099833334, 1.0, 2.0, 0.5342053916770366, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9277381009203944, 6.911199999999999, 6.9112, 168.9128793077647, 1493496.631490258, 1493496.631490258, 327335.0647499388]
[2019-03-26 18:20:58,058] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:20:58,060] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.4165492e-16 1.0000000e+00 3.4794581e-21 6.5104701e-14 1.1154478e-24], sampled 0.7593798100478711
[2019-03-26 18:21:12,157] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:21:12,157] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.67915078, 63.32295579666666, 1.0, 2.0, 0.4261916498551773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619674.9432288575, 619674.9432288582, 175942.5588874712]
[2019-03-26 18:21:12,159] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:21:12,161] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3437689e-32 1.0000000e+00 3.8016376e-34 0.0000000e+00 0.0000000e+00], sampled 0.7139629636410033
[2019-03-26 18:21:12,670] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:21:12,671] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.9, 88.33333333333334, 1.0, 2.0, 0.9101636350539997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1272155.553965981, 1272155.553965981, 272750.9493569733]
[2019-03-26 18:21:12,672] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:21:12,675] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0906643e-25 1.0000000e+00 3.5198810e-29 3.2252330e-30 1.0243373e-34], sampled 0.774637527799626
[2019-03-26 18:21:38,930] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02672324], dtype=float32), 0.11282659]
[2019-03-26 18:21:38,933] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.02787456166667, 87.21156937833334, 1.0, 2.0, 0.4689136440627923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668606.1609983224, 668606.160998323, 180585.4826563272]
[2019-03-26 18:21:38,934] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:21:38,937] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.6432415e-26 1.0000000e+00 3.9463659e-30 2.3221268e-30 3.8364228e-36], sampled 0.3526624782194666
[2019-03-26 18:21:43,048] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7923.4971 3160984188.3206 1696.0000
[2019-03-26 18:21:43,159] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8261.3178 2926755639.0356 1323.0000
[2019-03-26 18:21:43,213] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.4385 2778913361.4630 921.0000
[2019-03-26 18:21:43,360] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8015.6072 3006111638.7130 1728.0000
[2019-03-26 18:21:43,423] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.0847 2841798956.9940 1111.0000
[2019-03-26 18:21:44,442] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2100000, evaluation results [2100000.0, 7923.497050328344, 3160984188.320617, 1696.0, 8261.317841118771, 2926755639.0355864, 1323.0, 8663.438460825912, 2778913361.4630394, 921.0, 8015.607155144462, 3006111638.712985, 1728.0, 8507.084650229664, 2841798956.993955, 1111.0]
[2019-03-26 18:21:53,051] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.3258061e-27 1.0000000e+00 1.2890565e-29 1.6977697e-31 2.0566877e-36], sum to 1.0000
[2019-03-26 18:21:53,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9871
[2019-03-26 18:21:53,078] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.0, 1.0, 2.0, 0.4834909667026012, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768347.1244336583, 768347.1244336583, 191563.4716844815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7390800.0000, 
sim time next is 7391400.0000, 
raw observation next is [20.98333333333333, 92.0, 1.0, 2.0, 0.6234993951955499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 991406.5545155546, 991406.5545155553, 219040.6241461265], 
processed observation next is [1.0, 0.5652173913043478, 0.1935229067930489, 0.92, 1.0, 1.0, 0.5463848134886142, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27539070958765405, 0.2753907095876542, 0.3269263046957112], 
reward next is 0.6731, 
noisyNet noise sample is [array([0.65818816], dtype=float32), 0.7844278]. 
=============================================
[2019-03-26 18:21:58,451] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:21:58,451] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:21:58,522] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run11
[2019-03-26 18:21:58,977] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.3989848e-28 1.0000000e+00 6.7685585e-31 6.7749580e-33 9.9374518e-37], sum to 1.0000
[2019-03-26 18:21:58,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3990
[2019-03-26 18:21:58,989] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.76666666666667, 95.0, 1.0, 2.0, 0.5236451941342106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 755012.724271016, 755012.724271016, 190340.6590097879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7612800.0000, 
sim time next is 7613400.0000, 
raw observation next is [23.73333333333333, 95.0, 1.0, 2.0, 0.5076060487552021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732893.2444389308, 732893.2444389308, 187789.0648705919], 
processed observation next is [1.0, 0.08695652173913043, 0.3238546603475513, 0.95, 1.0, 1.0, 0.4067542756086772, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20358145678859188, 0.20358145678859188, 0.28028218637401775], 
reward next is 0.7197, 
noisyNet noise sample is [array([1.5501091], dtype=float32), -1.8071399]. 
=============================================
[2019-03-26 18:22:00,260] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2107139: loss 48.7794
[2019-03-26 18:22:00,264] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2107139: learning rate 0.0000
[2019-03-26 18:22:01,044] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1200238e-30 1.0000000e+00 2.8161111e-33 1.5266342e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:22:01,057] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8331
[2019-03-26 18:22:01,060] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 84.0, 1.0, 2.0, 0.3879838743994324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579066.6838532434, 579066.6838532427, 172627.6638041803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7474800.0000, 
sim time next is 7475400.0000, 
raw observation next is [24.45, 83.5, 1.0, 2.0, 0.3895191598809441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 580439.909540628, 580439.9095406285, 172722.3176108013], 
processed observation next is [0.0, 0.5217391304347826, 0.3578199052132702, 0.835, 1.0, 1.0, 0.26448091551920977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16123330820572998, 0.16123330820573015, 0.2577945038967184], 
reward next is 0.7422, 
noisyNet noise sample is [array([0.68130827], dtype=float32), -0.107530005]. 
=============================================
[2019-03-26 18:22:01,195] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1611802e-30 1.0000000e+00 6.7712890e-33 3.8908498e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:22:01,205] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2148
[2019-03-26 18:22:01,214] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 82.0, 1.0, 2.0, 0.394913388322563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 585719.1098138968, 585719.1098138962, 173115.0791195052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7477200.0000, 
sim time next is 7477800.0000, 
raw observation next is [24.9, 81.66666666666667, 1.0, 2.0, 0.3972185431418468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588120.0993658563, 588120.099365857, 173303.1534490435], 
processed observation next is [0.0, 0.5652173913043478, 0.3791469194312796, 0.8166666666666668, 1.0, 1.0, 0.2737572808937913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1633666942682934, 0.1633666942682936, 0.2586614230582739], 
reward next is 0.7413, 
noisyNet noise sample is [array([0.26412436], dtype=float32), 0.9392527]. 
=============================================
[2019-03-26 18:22:05,722] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1088128e-14 1.0000000e+00 2.4192440e-19 1.4805608e-09 6.5114214e-23], sum to 1.0000
[2019-03-26 18:22:05,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0960
[2019-03-26 18:22:05,736] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.3, 61.0, 1.0, 2.0, 0.9742075380536848, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565001232, 1361728.522021894, 1361728.522021894, 291162.5012048015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7648200.0000, 
sim time next is 7648800.0000, 
raw observation next is [30.36666666666667, 60.66666666666667, 1.0, 2.0, 0.9954607706192742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104284, 1391455.35003689, 1391455.35003689, 297542.6836300099], 
processed observation next is [1.0, 0.5217391304347826, 0.6382306477093209, 0.6066666666666667, 1.0, 1.0, 0.9945310489388846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451522898, 0.38651537501024724, 0.38651537501024724, 0.44409355765673114], 
reward next is 0.5559, 
noisyNet noise sample is [array([-2.0046027], dtype=float32), 0.79333824]. 
=============================================
[2019-03-26 18:22:08,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:08,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:08,083] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run11
[2019-03-26 18:22:09,812] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2111480: loss 44.5249
[2019-03-26 18:22:09,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2111480: learning rate 0.0000
[2019-03-26 18:22:11,025] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.3458556e-31 1.0000000e+00 6.2131628e-33 1.4533546e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 18:22:11,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2149
[2019-03-26 18:22:11,035] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 90.33333333333334, 1.0, 2.0, 0.3731491645966507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563972.4160132934, 563972.4160132934, 171520.1497598521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [23.03333333333333, 90.16666666666666, 1.0, 2.0, 0.3708038476026096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 561413.998717409, 561413.9987174096, 171329.538400087], 
processed observation next is [0.0, 0.17391304347826086, 0.29067930489731436, 0.9016666666666666, 1.0, 1.0, 0.24193234650916817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15594833297705804, 0.1559483329770582, 0.25571572895535377], 
reward next is 0.7443, 
noisyNet noise sample is [array([-1.7230636], dtype=float32), -1.1993301]. 
=============================================
[2019-03-26 18:22:13,370] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.5019163e-24 1.0000000e+00 6.8238678e-28 5.4397437e-25 1.0305657e-33], sum to 1.0000
[2019-03-26 18:22:13,379] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6633
[2019-03-26 18:22:13,384] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 86.66666666666667, 1.0, 2.0, 0.5033711422433214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 703384.5230968969, 703384.5230968969, 184125.9005217109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7780200.0000, 
sim time next is 7780800.0000, 
raw observation next is [26.4, 86.33333333333334, 1.0, 2.0, 0.5011073382071519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 700220.1590717006, 700220.1590717013, 183769.7325406553], 
processed observation next is [1.0, 0.043478260869565216, 0.45023696682464454, 0.8633333333333334, 1.0, 1.0, 0.39892450386403844, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19450559974213907, 0.19450559974213927, 0.27428318289650044], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.45796248], dtype=float32), -0.5805052]. 
=============================================
[2019-03-26 18:22:14,012] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.6725035e-29 1.0000000e+00 1.1896099e-31 2.6085596e-36 2.2516008e-38], sum to 1.0000
[2019-03-26 18:22:14,021] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1327
[2019-03-26 18:22:14,027] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.43333333333333, 83.16666666666667, 1.0, 2.0, 0.4283950986484798, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 617267.7866510127, 617267.7866510121, 175547.0529056282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7549800.0000, 
sim time next is 7550400.0000, 
raw observation next is [25.66666666666667, 82.33333333333334, 1.0, 2.0, 0.4333419437761548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 621602.6372978551, 621602.6372978558, 175889.6279018857], 
processed observation next is [0.0, 0.391304347826087, 0.4154818325434442, 0.8233333333333335, 1.0, 1.0, 0.31727945033271665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1726673992494042, 0.17266739924940439, 0.2625218326893816], 
reward next is 0.7375, 
noisyNet noise sample is [array([0.20118238], dtype=float32), 0.12708902]. 
=============================================
[2019-03-26 18:22:16,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.1726685e-28 1.0000000e+00 2.7183530e-31 1.0089071e-33 4.6671742e-38], sum to 1.0000
[2019-03-26 18:22:16,684] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8650
[2019-03-26 18:22:16,689] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 61.0, 1.0, 2.0, 0.4303025044852923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 621446.0889224363, 621446.0889224369, 175995.2813676448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7565400.0000, 
sim time next is 7566000.0000, 
raw observation next is [29.0, 60.33333333333333, 1.0, 2.0, 0.4255031755308653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 617378.1013947607, 617378.10139476, 175682.6651552374], 
processed observation next is [0.0, 0.5652173913043478, 0.5734597156398105, 0.6033333333333333, 1.0, 1.0, 0.30783515124200644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1714939170541002, 0.1714939170541, 0.2622129330675185], 
reward next is 0.7378, 
noisyNet noise sample is [array([-0.8049317], dtype=float32), -2.5681398]. 
=============================================
[2019-03-26 18:22:16,708] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[74.34902 ]
 [74.25807 ]
 [74.16968 ]
 [74.066795]
 [73.87004 ]], R is [[74.44277191]
 [74.43566132]
 [74.42822266]
 [74.42050171]
 [74.41246796]].
[2019-03-26 18:22:17,750] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2114996: loss 0.0234
[2019-03-26 18:22:17,755] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2114996: learning rate 0.0000
[2019-03-26 18:22:18,497] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3467094e-26 1.0000000e+00 7.1491864e-31 1.3698237e-30 1.6541395e-37], sum to 1.0000
[2019-03-26 18:22:18,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0217
[2019-03-26 18:22:18,511] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.31666666666666, 85.50000000000001, 1.0, 2.0, 0.5281917196004554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738079.5499012971, 738079.5499012977, 188131.1494959067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7938600.0000, 
sim time next is 7939200.0000, 
raw observation next is [27.23333333333333, 86.0, 1.0, 2.0, 0.526670531433898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735953.1499972278, 735953.1499972272, 187880.5169773799], 
processed observation next is [1.0, 0.9130434782608695, 0.4897314375987361, 0.86, 1.0, 1.0, 0.42972353184806983, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20443143055478552, 0.20443143055478535, 0.2804186820557909], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.16614386], dtype=float32), 0.07474877]. 
=============================================
[2019-03-26 18:22:19,974] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:19,975] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:20,042] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run11
[2019-03-26 18:22:20,072] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:20,075] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:20,157] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run11
[2019-03-26 18:22:21,724] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2116915: loss 38.8672
[2019-03-26 18:22:21,727] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2116915: learning rate 0.0000
[2019-03-26 18:22:21,849] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2116970: loss 38.2750
[2019-03-26 18:22:21,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2116970: learning rate 0.0000
[2019-03-26 18:22:24,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:24,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:24,072] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run11
[2019-03-26 18:22:25,739] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2118818: loss 39.5282
[2019-03-26 18:22:25,741] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2118818: learning rate 0.0000
[2019-03-26 18:22:25,931] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:25,933] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:26,017] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run11
[2019-03-26 18:22:26,191] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2119008: loss 0.0151
[2019-03-26 18:22:26,192] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2119009: learning rate 0.0000
[2019-03-26 18:22:27,719] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2119806: loss 38.6502
[2019-03-26 18:22:27,720] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2119806: learning rate 0.0000
[2019-03-26 18:22:28,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:28,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:29,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run11
[2019-03-26 18:22:29,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:29,891] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:29,946] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run11
[2019-03-26 18:22:30,486] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:30,486] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:30,498] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2121196: loss 38.8284
[2019-03-26 18:22:30,500] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2121196: learning rate 0.0000
[2019-03-26 18:22:30,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run11
[2019-03-26 18:22:31,449] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121743: loss 39.9164
[2019-03-26 18:22:31,454] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121745: learning rate 0.0000
[2019-03-26 18:22:31,503] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.7069427e-27 1.0000000e+00 3.4460341e-31 6.0164671e-34 1.8272255e-37], sum to 1.0000
[2019-03-26 18:22:31,507] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8165
[2019-03-26 18:22:31,510] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.3892222281961041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 599538.9229341301, 599538.9229341301, 174958.839227896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3892994580637094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599667.7422333704, 599667.7422333698, 174970.4936730671], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.26421621453458966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1665743728426029, 0.16657437284260274, 0.2611499905568166], 
reward next is 0.7389, 
noisyNet noise sample is [array([-0.20148593], dtype=float32), 1.3754996]. 
=============================================
[2019-03-26 18:22:31,523] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[72.428444]
 [72.486885]
 [72.70319 ]
 [72.82717 ]
 [72.86146 ]], R is [[72.3633194 ]
 [72.3785553 ]
 [72.38735962]
 [72.40232849]
 [72.41855621]].
[2019-03-26 18:22:32,251] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2122137: loss 38.4170
[2019-03-26 18:22:32,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2122137: learning rate 0.0000
[2019-03-26 18:22:32,399] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2122203: loss 0.2423
[2019-03-26 18:22:32,401] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2122203: learning rate 0.0000
[2019-03-26 18:22:34,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:34,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:34,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run11
[2019-03-26 18:22:34,668] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0205838e-29 1.0000000e+00 3.3738542e-32 5.6156889e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:22:34,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6899
[2019-03-26 18:22:34,675] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.43333333333334, 92.33333333333334, 1.0, 2.0, 0.2848866203252448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 457874.7427059273, 457874.7427059267, 164125.7888438743], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 267000.0000, 
sim time next is 267600.0000, 
raw observation next is [20.36666666666667, 92.66666666666667, 1.0, 2.0, 0.2846646876911634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457752.9761656316, 457752.9761656316, 164118.6441627186], 
processed observation next is [0.0, 0.08695652173913043, 0.1642969984202214, 0.9266666666666667, 1.0, 1.0, 0.13815022613393177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12715360449045324, 0.12715360449045324, 0.2449532002428636], 
reward next is 0.7550, 
noisyNet noise sample is [array([0.14702189], dtype=float32), 1.0344877]. 
=============================================
[2019-03-26 18:22:35,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:35,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:35,862] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run11
[2019-03-26 18:22:36,061] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2123974: loss 39.9593
[2019-03-26 18:22:36,063] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2123975: learning rate 0.0000
[2019-03-26 18:22:36,195] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:36,195] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:36,200] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:36,200] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:36,252] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run11
[2019-03-26 18:22:36,283] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run11
[2019-03-26 18:22:36,313] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2124084: loss 0.0009
[2019-03-26 18:22:36,317] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2124086: learning rate 0.0000
[2019-03-26 18:22:36,379] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2124126: loss 0.0006
[2019-03-26 18:22:36,380] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2124126: learning rate 0.0000
[2019-03-26 18:22:36,432] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:36,433] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:36,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run11
[2019-03-26 18:22:36,856] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:36,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:36,898] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run11
[2019-03-26 18:22:37,171] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:22:37,172] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run11
[2019-03-26 18:22:37,302] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2124668: loss 39.7788
[2019-03-26 18:22:37,303] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2124668: learning rate 0.0000
[2019-03-26 18:22:37,422] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4784235e-02 4.9188844e-04 6.1502592e-03 9.4164324e-01 1.6930401e-02], sum to 1.0000
[2019-03-26 18:22:37,425] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1557
[2019-03-26 18:22:37,430] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.3, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2061999732655149, 6.911200000000001, 6.9112, 170.5573041426782, 535887.6784477276, 535887.6784477269, 235515.6743966998], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 0.0000, 
sim time next is 600.0000, 
raw observation next is [21.95, 88.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 525509.9952246582, 525509.9952246582, 238528.4853312753], 
processed observation next is [1.0, 0.0, 0.2393364928909953, 0.8816666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.14597499867351615, 0.14597499867351615, 0.3560126646735452], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5204188], dtype=float32), -3.5858357]. 
=============================================
[2019-03-26 18:22:37,784] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2124978: loss 37.2760
[2019-03-26 18:22:37,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2124978: learning rate 0.0000
[2019-03-26 18:22:37,802] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2124989: loss 38.6578
[2019-03-26 18:22:37,803] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2124989: learning rate 0.0000
[2019-03-26 18:22:37,821] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 18:22:37,823] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:22:37,823] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:22:37,824] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,825] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,826] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:22:37,828] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:22:37,825] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:22:37,830] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,834] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,834] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:22:37,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run86
[2019-03-26 18:22:37,866] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run86
[2019-03-26 18:22:37,887] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run86
[2019-03-26 18:22:37,906] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run86
[2019-03-26 18:22:37,925] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run86
[2019-03-26 18:23:48,386] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:23:48,388] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.33333333333334, 78.0, 1.0, 2.0, 0.8144763231887183, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1138339.617053048, 1138339.617053049, 247497.0031894951]
[2019-03-26 18:23:48,389] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:23:48,391] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.79766699e-26 1.00000000e+00 2.71949674e-29 1.22584275e-30
 4.40975571e-35], sampled 0.40440576734850275
[2019-03-26 18:23:53,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:23:53,504] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.33333333333334, 65.0, 1.0, 2.0, 0.5125044579218224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716151.2431057073, 716151.2431057073, 185578.5904867777]
[2019-03-26 18:23:53,505] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:23:53,509] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9714036e-29 1.0000000e+00 2.3049327e-32 3.8204623e-35 2.0265307e-38], sampled 0.1051827389004546
[2019-03-26 18:23:59,273] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:23:59,274] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 83.16666666666667, 1.0, 2.0, 0.9019687565190204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1260694.593087808, 1260694.593087808, 270483.3989518216]
[2019-03-26 18:23:59,275] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:23:59,278] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4579683e-24 1.0000000e+00 2.1840197e-28 1.3059456e-27 1.1341024e-33], sampled 0.17961983801679282
[2019-03-26 18:24:01,869] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:24:01,870] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.08333333333334, 50.0, 1.0, 2.0, 0.5989538623454799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836999.4429001182, 836999.4429001182, 200550.7219241626]
[2019-03-26 18:24:01,872] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:24:01,878] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.9499130e-28 1.0000000e+00 2.3763683e-31 6.8846189e-32 4.3331117e-37], sampled 0.5350570286039739
[2019-03-26 18:24:13,460] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:24:13,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.94928294, 71.24667145, 1.0, 2.0, 0.9977415535699042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1394645.523271612, 1394645.523271612, 298238.9200269714]
[2019-03-26 18:24:13,462] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:24:13,467] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2222949e-21 1.0000000e+00 7.1350102e-26 1.7102906e-22 7.5932760e-31], sampled 0.29930645867807537
[2019-03-26 18:24:21,640] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02863715], dtype=float32), 0.12008318]
[2019-03-26 18:24:21,641] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.701419265, 90.44602728333334, 1.0, 2.0, 0.4301663288115716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 634124.3835340289, 634124.3835340283, 177573.8850099523]
[2019-03-26 18:24:21,642] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:24:21,645] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.1672505e-27 1.0000000e+00 1.9984566e-30 1.2841038e-30 2.5071349e-36], sampled 0.8386981458013246
[2019-03-26 18:24:33,439] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8273.4874 2926137075.0066 1301.0000
[2019-03-26 18:24:33,661] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8035.8832 3003975276.8962 1679.0000
[2019-03-26 18:24:33,871] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7960.4169 3157157082.3832 1588.0000
[2019-03-26 18:24:33,974] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.3037 2778345148.2657 910.0000
[2019-03-26 18:24:34,069] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8517.8722 2840602918.8878 1080.0000
[2019-03-26 18:24:35,089] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2125000, evaluation results [2125000.0, 7960.416932790514, 3157157082.3832192, 1588.0, 8273.487429733208, 2926137075.006618, 1301.0, 8671.30371791785, 2778345148.265734, 910.0, 8035.883216361703, 3003975276.896186, 1679.0, 8517.872235064136, 2840602918.8878403, 1080.0]
[2019-03-26 18:24:35,459] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2125166: loss 39.4413
[2019-03-26 18:24:35,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2125169: learning rate 0.0000
[2019-03-26 18:24:35,765] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2125306: loss 41.0562
[2019-03-26 18:24:35,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2125307: learning rate 0.0000
[2019-03-26 18:24:35,808] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2125325: loss 41.3202
[2019-03-26 18:24:35,811] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2125325: learning rate 0.0000
[2019-03-26 18:24:36,649] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2125698: loss 0.0009
[2019-03-26 18:24:36,651] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2125698: learning rate 0.0000
[2019-03-26 18:24:37,003] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2125857: loss 0.2179
[2019-03-26 18:24:37,007] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2125858: learning rate 0.0000
[2019-03-26 18:24:38,841] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2126680: loss 0.0008
[2019-03-26 18:24:38,846] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2126682: learning rate 0.0000
[2019-03-26 18:24:42,691] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2128381: loss 0.0130
[2019-03-26 18:24:42,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2128381: learning rate 0.0000
[2019-03-26 18:24:44,047] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128985: loss 0.0006
[2019-03-26 18:24:44,049] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128985: learning rate 0.0000
[2019-03-26 18:24:44,999] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2129405: loss 0.0011
[2019-03-26 18:24:45,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2129405: learning rate 0.0000
[2019-03-26 18:24:45,092] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2129446: loss 0.0028
[2019-03-26 18:24:45,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2129446: learning rate 0.0000
[2019-03-26 18:24:45,559] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2409272e-29 1.0000000e+00 7.5288334e-33 6.0775754e-33 0.0000000e+00], sum to 1.0000
[2019-03-26 18:24:45,562] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3774
[2019-03-26 18:24:45,567] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 86.0, 1.0, 2.0, 0.275679208189076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 445079.7360947166, 445079.736094716, 163273.9126578792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 337200.0000, 
sim time next is 337800.0000, 
raw observation next is [20.93333333333333, 86.0, 1.0, 2.0, 0.2746407143913493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 443667.5745969001, 443667.5745969001, 163180.4369165069], 
processed observation next is [0.0, 0.9130434782608695, 0.19115323854660338, 0.86, 1.0, 1.0, 0.1260731498690955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12324099294358336, 0.12324099294358336, 0.24355289092015955], 
reward next is 0.7564, 
noisyNet noise sample is [array([1.2885821], dtype=float32), -1.2884094]. 
=============================================
[2019-03-26 18:24:47,776] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.0219469e-29 1.0000000e+00 5.8178312e-33 2.1691745e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:24:47,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9434
[2019-03-26 18:24:47,789] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.03333333333333, 86.66666666666666, 1.0, 2.0, 0.3209948008206268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506309.6188785122, 506309.6188785122, 167475.071336166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 222000.0000, 
sim time next is 222600.0000, 
raw observation next is [22.11666666666667, 86.33333333333334, 1.0, 2.0, 0.3211659357941711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 506100.4631545788, 506100.4631545788, 167449.0561604514], 
processed observation next is [0.0, 0.5652173913043478, 0.24723538704581383, 0.8633333333333334, 1.0, 1.0, 0.1821276334869531, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.140583461987383, 0.140583461987383, 0.2499239644185842], 
reward next is 0.7501, 
noisyNet noise sample is [array([-0.01288656], dtype=float32), -0.34470317]. 
=============================================
[2019-03-26 18:24:48,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1446041e-31 1.0000000e+00 5.2889752e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:24:48,664] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8009
[2019-03-26 18:24:48,671] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 82.0, 1.0, 2.0, 0.2994262534653076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 475955.9677280707, 475955.9677280707, 165318.6499212074], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 291600.0000, 
sim time next is 292200.0000, 
raw observation next is [22.38333333333334, 81.50000000000001, 1.0, 2.0, 0.3000432669004225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 476756.8328659078, 476756.8328659085, 165372.3594807952], 
processed observation next is [0.0, 0.391304347826087, 0.2598736176935233, 0.8150000000000002, 1.0, 1.0, 0.1566786348197861, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13243245357386327, 0.13243245357386346, 0.2468244171355152], 
reward next is 0.7532, 
noisyNet noise sample is [array([-0.5020512], dtype=float32), -2.0188124]. 
=============================================
[2019-03-26 18:24:49,807] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2131542: loss 0.0028
[2019-03-26 18:24:49,811] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2131542: learning rate 0.0000
[2019-03-26 18:24:50,033] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2385573e-27 1.0000000e+00 2.0119872e-31 1.8974267e-31 3.1600440e-36], sum to 1.0000
[2019-03-26 18:24:50,041] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2907
[2019-03-26 18:24:50,045] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.73333333333333, 90.83333333333334, 1.0, 2.0, 0.293988935910098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471426.8767904231, 471426.8767904231, 165053.0886931898], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 251400.0000, 
sim time next is 252000.0000, 
raw observation next is [20.7, 91.0, 1.0, 2.0, 0.2919226770016959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 468235.5028795577, 468235.5028795577, 164831.5760485278], 
processed observation next is [0.0, 0.9565217391304348, 0.18009478672985785, 0.91, 1.0, 1.0, 0.14689479156830829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13006541746654382, 0.13006541746654382, 0.24601727768436982], 
reward next is 0.7540, 
noisyNet noise sample is [array([1.6668696], dtype=float32), 0.14758492]. 
=============================================
[2019-03-26 18:24:50,064] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[80.41155 ]
 [80.40525 ]
 [80.420456]
 [80.40221 ]
 [80.359726]], R is [[80.49008179]
 [80.43883514]
 [80.38804626]
 [80.33838654]
 [80.28941345]].
[2019-03-26 18:24:50,140] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2131688: loss 0.2503
[2019-03-26 18:24:50,143] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2131689: learning rate 0.0000
[2019-03-26 18:24:50,296] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2131756: loss 0.2624
[2019-03-26 18:24:50,300] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2131757: learning rate 0.0000
[2019-03-26 18:24:52,205] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2132588: loss 0.0069
[2019-03-26 18:24:52,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2132588: learning rate 0.0000
[2019-03-26 18:24:52,985] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2132933: loss 0.0016
[2019-03-26 18:24:52,990] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2132935: learning rate 0.0000
[2019-03-26 18:24:53,204] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2133029: loss 0.0022
[2019-03-26 18:24:53,207] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2133030: learning rate 0.0000
[2019-03-26 18:24:53,625] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2133212: loss 0.0006
[2019-03-26 18:24:53,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2133215: learning rate 0.0000
[2019-03-26 18:24:53,724] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2133260: loss 0.0007
[2019-03-26 18:24:53,726] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2133260: learning rate 0.0000
[2019-03-26 18:24:54,027] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2133390: loss 0.0004
[2019-03-26 18:24:54,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2133391: learning rate 0.0000
[2019-03-26 18:24:54,730] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2133700: loss 0.2286
[2019-03-26 18:24:54,737] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2133702: learning rate 0.0000
[2019-03-26 18:24:54,921] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2133789: loss 0.0009
[2019-03-26 18:24:54,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2133789: learning rate 0.0000
[2019-03-26 18:24:57,043] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2134734: loss 0.2478
[2019-03-26 18:24:57,046] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2134735: learning rate 0.0000
[2019-03-26 18:25:00,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3593736e-27 1.0000000e+00 6.8944253e-31 4.0783483e-32 7.9058004e-37], sum to 1.0000
[2019-03-26 18:25:00,547] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0127
[2019-03-26 18:25:00,552] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.45, 91.5, 1.0, 2.0, 0.2596381960705009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 425020.4781945268, 425020.4781945268, 161866.2848390402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783000.0000, 
sim time next is 783600.0000, 
raw observation next is [19.43333333333333, 91.66666666666666, 1.0, 2.0, 0.2594312418392346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424664.7965696771, 424664.7965696771, 161844.985704398], 
processed observation next is [0.0, 0.043478260869565216, 0.12006319115323845, 0.9166666666666665, 1.0, 1.0, 0.10774848414365615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11796244349157697, 0.11796244349157697, 0.24155968015581789], 
reward next is 0.7584, 
noisyNet noise sample is [array([0.88692206], dtype=float32), -2.0393095]. 
=============================================
[2019-03-26 18:25:00,796] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2136401: loss 0.2289
[2019-03-26 18:25:00,801] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2136402: learning rate 0.0000
[2019-03-26 18:25:00,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5677989e-25 1.0000000e+00 2.6535219e-29 4.3338943e-27 1.9531183e-35], sum to 1.0000
[2019-03-26 18:25:01,001] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2491
[2019-03-26 18:25:01,008] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 85.83333333333334, 1.0, 2.0, 0.2435470947532007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 400939.6576215969, 400939.6576215975, 160270.3409328334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 432600.0000, 
sim time next is 433200.0000, 
raw observation next is [19.66666666666667, 85.66666666666667, 1.0, 2.0, 0.2425464766337609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399465.4648517597, 399465.4648517604, 160169.9418480094], 
processed observation next is [1.0, 0.0, 0.1311216429699845, 0.8566666666666667, 1.0, 1.0, 0.08740539353465167, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11096262912548881, 0.110962629125489, 0.23905961469852147], 
reward next is 0.7609, 
noisyNet noise sample is [array([1.445927], dtype=float32), 0.5171159]. 
=============================================
[2019-03-26 18:25:02,119] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136981: loss 0.1771
[2019-03-26 18:25:02,122] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136983: learning rate 0.0000
[2019-03-26 18:25:02,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.4169988e-29 1.0000000e+00 2.1378638e-31 3.0232030e-35 2.0412186e-37], sum to 1.0000
[2019-03-26 18:25:02,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1308
[2019-03-26 18:25:02,812] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 76.66666666666667, 1.0, 2.0, 0.3979314826951001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654638.7772868029, 654638.7772868029, 179169.1155806829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463200.0000, 
sim time next is 463800.0000, 
raw observation next is [21.06666666666667, 75.83333333333333, 1.0, 2.0, 0.4052513659093974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666519.4414477205, 666519.4414477205, 180246.454953312], 
processed observation next is [1.0, 0.34782608695652173, 0.19747235387045833, 0.7583333333333333, 1.0, 1.0, 0.28343538061373186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18514428929103346, 0.18514428929103346, 0.26902455963180893], 
reward next is 0.7310, 
noisyNet noise sample is [array([-1.6453327], dtype=float32), -0.29580224]. 
=============================================
[2019-03-26 18:25:03,041] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2137387: loss 0.1900
[2019-03-26 18:25:03,045] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2137388: learning rate 0.0000
[2019-03-26 18:25:03,235] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2137472: loss 6.7925
[2019-03-26 18:25:03,237] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2137473: learning rate 0.0000
[2019-03-26 18:25:05,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0718171e-26 1.0000000e+00 4.3320529e-30 4.8053108e-29 6.5667302e-36], sum to 1.0000
[2019-03-26 18:25:05,128] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0644
[2019-03-26 18:25:05,133] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.23333333333333, 85.0, 1.0, 2.0, 0.2357627921104252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 390452.6277067414, 390452.6277067414, 159402.8310996984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 512400.0000, 
sim time next is 513000.0000, 
raw observation next is [19.15, 85.5, 1.0, 2.0, 0.2350162099216474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 389299.1388566919, 389299.1388566919, 159325.0359620243], 
processed observation next is [1.0, 0.9565217391304348, 0.10663507109004738, 0.855, 1.0, 1.0, 0.07833278303812939, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10813864968241442, 0.10813864968241442, 0.2377985611373497], 
reward next is 0.7622, 
noisyNet noise sample is [array([1.8791801], dtype=float32), -0.41083157]. 
=============================================
[2019-03-26 18:25:05,148] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[77.73465 ]
 [77.72457 ]
 [77.70435 ]
 [77.598946]
 [77.58572 ]], R is [[77.73701477]
 [77.72173309]
 [77.70652008]
 [77.69138336]
 [77.6763382 ]].
[2019-03-26 18:25:07,833] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2139506: loss 0.2214
[2019-03-26 18:25:07,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2139506: learning rate 0.0000
[2019-03-26 18:25:08,249] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2139691: loss 0.0014
[2019-03-26 18:25:08,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2139691: learning rate 0.0000
[2019-03-26 18:25:08,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2139696: loss 0.0015
[2019-03-26 18:25:08,265] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2139696: learning rate 0.0000
[2019-03-26 18:25:10,169] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2140545: loss 0.2430
[2019-03-26 18:25:10,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2140545: learning rate 0.0000
[2019-03-26 18:25:11,086] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2140949: loss 0.2429
[2019-03-26 18:25:11,090] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2140951: learning rate 0.0000
[2019-03-26 18:25:11,338] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2141061: loss 0.2429
[2019-03-26 18:25:11,341] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2141061: learning rate 0.0000
[2019-03-26 18:25:11,695] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2141217: loss 0.2207
[2019-03-26 18:25:11,697] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2141217: learning rate 0.0000
[2019-03-26 18:25:11,806] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2141272: loss 0.2239
[2019-03-26 18:25:11,808] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2141272: learning rate 0.0000
[2019-03-26 18:25:12,202] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2141446: loss 0.2326
[2019-03-26 18:25:12,205] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2141447: learning rate 0.0000
[2019-03-26 18:25:12,557] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2141603: loss 0.0008
[2019-03-26 18:25:12,561] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2141603: learning rate 0.0000
[2019-03-26 18:25:12,822] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2141715: loss 6.3630
[2019-03-26 18:25:12,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2141717: learning rate 0.0000
[2019-03-26 18:25:14,976] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2142672: loss 0.0013
[2019-03-26 18:25:14,980] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2142673: learning rate 0.0000
[2019-03-26 18:25:15,870] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0126867e-30 1.0000000e+00 4.4213153e-33 2.6561876e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:25:15,878] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-26 18:25:15,883] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.86666666666667, 62.66666666666667, 1.0, 2.0, 0.288554224655352, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462045.0355241917, 462045.0355241924, 164396.7581199094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 823200.0000, 
sim time next is 823800.0000, 
raw observation next is [24.83333333333334, 62.83333333333333, 1.0, 2.0, 0.2893466080141956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 463352.7591582451, 463352.7591582457, 164487.1777494199], 
processed observation next is [0.0, 0.5217391304347826, 0.3759873617693526, 0.6283333333333333, 1.0, 1.0, 0.14379109399300674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1287090997661792, 0.12870909976617936, 0.24550325037226853], 
reward next is 0.7545, 
noisyNet noise sample is [array([1.2289587], dtype=float32), 0.71140045]. 
=============================================
[2019-03-26 18:25:18,852] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2144398: loss 0.0010
[2019-03-26 18:25:18,855] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2144398: learning rate 0.0000
[2019-03-26 18:25:19,434] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3943797e-25 1.0000000e+00 2.4068419e-29 9.0272285e-29 3.6044413e-35], sum to 1.0000
[2019-03-26 18:25:19,441] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1353
[2019-03-26 18:25:19,446] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 50.66666666666667, 1.0, 2.0, 0.6062070162912763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 990598.8902239722, 990598.8902239722, 216869.7082294722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [25.8, 50.0, 1.0, 2.0, 0.6286001612381256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1027981.185747482, 1027981.185747482, 221830.122651141], 
processed observation next is [1.0, 0.5652173913043478, 0.42180094786729866, 0.5, 1.0, 1.0, 0.5525303147447296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2855503293743006, 0.2855503293743006, 0.3310897353002104], 
reward next is 0.6689, 
noisyNet noise sample is [array([0.50214434], dtype=float32), -0.7784302]. 
=============================================
[2019-03-26 18:25:20,016] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144917: loss 0.0020
[2019-03-26 18:25:20,019] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144917: learning rate 0.0000
[2019-03-26 18:25:21,113] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2145407: loss 0.0009
[2019-03-26 18:25:21,115] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2145408: learning rate 0.0000
[2019-03-26 18:25:21,559] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2145604: loss 0.0060
[2019-03-26 18:25:21,562] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2145606: learning rate 0.0000
[2019-03-26 18:25:24,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7257709e-29 1.0000000e+00 1.4711864e-32 1.2962661e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:25:24,601] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1075
[2019-03-26 18:25:24,606] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 92.0, 1.0, 2.0, 0.3241191120042129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504031.8680298316, 504031.8680298316, 167111.298592803], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 968400.0000, 
sim time next is 969000.0000, 
raw observation next is [21.9, 92.16666666666667, 1.0, 2.0, 0.3322008264389752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516494.7689646671, 516494.7689646671, 168073.3060268565], 
processed observation next is [1.0, 0.21739130434782608, 0.23696682464454974, 0.9216666666666667, 1.0, 1.0, 0.1954226824565966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14347076915685197, 0.14347076915685197, 0.25085568063709923], 
reward next is 0.7491, 
noisyNet noise sample is [array([-0.3843985], dtype=float32), 0.12695079]. 
=============================================
[2019-03-26 18:25:24,622] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[75.52056 ]
 [75.412704]
 [75.37681 ]
 [75.40396 ]
 [75.386925]], R is [[75.48786926]
 [75.48357391]
 [75.47932434]
 [75.47505188]
 [75.47057343]].
[2019-03-26 18:25:25,312] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.3583502e-25 1.0000000e+00 3.2092679e-29 2.4658203e-27 1.2582410e-35], sum to 1.0000
[2019-03-26 18:25:25,322] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5012
[2019-03-26 18:25:25,327] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 73.83333333333334, 1.0, 2.0, 0.3517874959090655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 543006.3234376422, 543006.3234376422, 170095.7090169036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1195800.0000, 
sim time next is 1196400.0000, 
raw observation next is [24.6, 74.66666666666667, 1.0, 2.0, 0.3513624789805923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 541945.5373656523, 541945.5373656517, 169996.6903790539], 
processed observation next is [1.0, 0.8695652173913043, 0.36492890995260674, 0.7466666666666667, 1.0, 1.0, 0.21850901081999072, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15054042704601453, 0.15054042704601436, 0.2537264035508267], 
reward next is 0.7463, 
noisyNet noise sample is [array([1.4173821], dtype=float32), -0.22003374]. 
=============================================
[2019-03-26 18:25:25,830] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2147490: loss 0.0017
[2019-03-26 18:25:25,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2147491: learning rate 0.0000
[2019-03-26 18:25:26,142] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2147626: loss 5.7217
[2019-03-26 18:25:26,148] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2147627: learning rate 0.0000
[2019-03-26 18:25:26,288] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2147693: loss 5.9129
[2019-03-26 18:25:26,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2147693: learning rate 0.0000
[2019-03-26 18:25:26,320] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3125031e-27 1.0000000e+00 3.0960361e-31 7.2452153e-33 2.6115154e-37], sum to 1.0000
[2019-03-26 18:25:26,331] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8166
[2019-03-26 18:25:26,336] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 70.33333333333334, 1.0, 2.0, 0.4272811100127285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617414.2181239652, 617414.2181239659, 175612.5894926342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1434000.0000, 
sim time next is 1434600.0000, 
raw observation next is [27.4, 70.0, 1.0, 2.0, 0.4273507734078753, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617285.1253990417, 617285.1253990423, 175593.3555833625], 
processed observation next is [0.0, 0.6086956521739131, 0.4976303317535545, 0.7, 1.0, 1.0, 0.3100611727805726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17146809038862268, 0.17146809038862285, 0.26207963519904853], 
reward next is 0.7379, 
noisyNet noise sample is [array([-1.0142019], dtype=float32), -2.7722857]. 
=============================================
[2019-03-26 18:25:26,739] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1835482e-24 1.0000000e+00 3.7703506e-29 5.0120454e-28 1.1355434e-34], sum to 1.0000
[2019-03-26 18:25:26,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8725
[2019-03-26 18:25:26,753] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.56666666666667, 96.16666666666666, 1.0, 2.0, 0.3827724543523893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 574503.0928234248, 574503.0928234248, 172321.7144258202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1043400.0000, 
sim time next is 1044000.0000, 
raw observation next is [22.6, 96.0, 1.0, 2.0, 0.3844018335886054, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 576693.127541197, 576693.1275411964, 172509.1392122945], 
processed observation next is [1.0, 0.08695652173913043, 0.27014218009478685, 0.96, 1.0, 1.0, 0.2583154621549463, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16019253542811027, 0.16019253542811013, 0.2574763271825291], 
reward next is 0.7425, 
noisyNet noise sample is [array([-0.2361705], dtype=float32), -2.0787609]. 
=============================================
[2019-03-26 18:25:26,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.597885]
 [71.57721 ]
 [71.58051 ]
 [71.55316 ]
 [71.50787 ]], R is [[72.05761719]
 [72.07984924]
 [72.10204315]
 [72.12403107]
 [72.14579773]].
[2019-03-26 18:25:28,304] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2148589: loss 0.0008
[2019-03-26 18:25:28,305] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2148589: learning rate 0.0000
[2019-03-26 18:25:28,962] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0759101e-10 9.9416006e-01 8.2078882e-18 5.8399914e-03 1.8429691e-19], sum to 1.0000
[2019-03-26 18:25:28,973] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2536
[2019-03-26 18:25:28,981] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.26666666666667, 72.33333333333334, 1.0, 2.0, 0.3114760587674421, 1.0, 1.0, 0.3114760587674421, 1.0, 2.0, 0.5259133131311797, 6.911199999999999, 6.9112, 170.5573041426782, 1306083.74813658, 1306083.74813658, 307719.3260901202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1254000.0000, 
sim time next is 1254600.0000, 
raw observation next is [28.3, 72.5, 1.0, 2.0, 0.8091620762838252, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129565003039, 1130908.290823868, 1130908.290823868, 246169.208176392], 
processed observation next is [1.0, 0.5217391304347826, 0.5402843601895735, 0.725, 1.0, 1.0, 0.7700747907034038, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451025739, 0.31414119189551887, 0.31414119189551887, 0.3674167286214806], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.29558823], dtype=float32), -0.9791804]. 
=============================================
[2019-03-26 18:25:29,143] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2148962: loss 0.0010
[2019-03-26 18:25:29,146] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2148964: learning rate 0.0000
[2019-03-26 18:25:29,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7144202e-28 1.0000000e+00 9.5239881e-32 8.4025817e-32 1.2069578e-37], sum to 1.0000
[2019-03-26 18:25:29,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8307
[2019-03-26 18:25:29,426] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.43333333333334, 79.33333333333334, 1.0, 2.0, 0.3249882714949593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507438.459516309, 507438.4595163083, 167434.0440986101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [23.35, 80.0, 1.0, 2.0, 0.3263620706189779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509438.000932277, 509438.0009322776, 167583.715378794], 
processed observation next is [0.0, 0.782608695652174, 0.3056872037914693, 0.8, 1.0, 1.0, 0.1883880368903348, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14151055581452138, 0.14151055581452154, 0.25012494832655824], 
reward next is 0.7499, 
noisyNet noise sample is [array([0.8779379], dtype=float32), 0.25181547]. 
=============================================
[2019-03-26 18:25:29,487] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2149115: loss 0.0008
[2019-03-26 18:25:29,489] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2149115: learning rate 0.0000
[2019-03-26 18:25:29,791] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2149243: loss 0.0008
[2019-03-26 18:25:29,794] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2149245: learning rate 0.0000
[2019-03-26 18:25:29,879] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2149286: loss 0.0013
[2019-03-26 18:25:29,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2149287: learning rate 0.0000
[2019-03-26 18:25:30,220] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2149440: loss 0.0019
[2019-03-26 18:25:30,223] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2149440: learning rate 0.0000
[2019-03-26 18:25:30,399] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2149517: loss 5.4950
[2019-03-26 18:25:30,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2149517: learning rate 0.0000
[2019-03-26 18:25:30,661] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.2102752e-27 1.0000000e+00 3.9916182e-31 7.6936345e-31 1.4754711e-37], sum to 1.0000
[2019-03-26 18:25:30,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5937
[2019-03-26 18:25:30,678] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.03333333333334, 89.66666666666667, 1.0, 2.0, 0.4710253604887782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663453.2282169106, 663453.22821691, 179861.9072288264], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1282800.0000, 
sim time next is 1283400.0000, 
raw observation next is [25.0, 90.0, 1.0, 2.0, 0.4702688611050269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662040.4189823298, 662040.4189823298, 179704.3859150843], 
processed observation next is [1.0, 0.8695652173913043, 0.38388625592417064, 0.9, 1.0, 1.0, 0.36176971217473125, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1839001163839805, 0.1839001163839805, 0.26821550136579747], 
reward next is 0.7318, 
noisyNet noise sample is [array([0.21139726], dtype=float32), 0.40408048]. 
=============================================
[2019-03-26 18:25:31,021] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2149787: loss 0.0153
[2019-03-26 18:25:31,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2149787: learning rate 0.0000
[2019-03-26 18:25:31,504] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 18:25:31,507] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:25:31,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:25:31,509] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:25:31,510] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:25:31,511] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:25:31,513] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:25:31,515] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:25:31,518] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:25:31,519] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:25:31,514] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:25:31,544] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run87
[2019-03-26 18:25:31,571] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run87
[2019-03-26 18:25:31,596] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run87
[2019-03-26 18:25:31,621] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run87
[2019-03-26 18:25:31,623] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run87
[2019-03-26 18:26:12,467] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02585071], dtype=float32), 0.11776908]
[2019-03-26 18:26:12,469] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.8, 84.5, 1.0, 2.0, 0.4823663341627776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 678506.5377015005, 678506.5377014998, 181456.3830112746]
[2019-03-26 18:26:12,472] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:26:12,475] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7732611e-27 1.0000000e+00 1.2819405e-30 4.4797892e-31 2.6028343e-36], sampled 0.6989704197572327
[2019-03-26 18:27:01,938] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02585071], dtype=float32), 0.11776908]
[2019-03-26 18:27:01,939] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.05, 90.0, 1.0, 2.0, 0.7718741480684275, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99027868475638, 6.9112, 168.9124207090856, 1975710.935299867, 1919609.972611366, 401598.5523624981]
[2019-03-26 18:27:01,941] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:27:01,946] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.804943e-13 9.999999e-01 7.810368e-19 6.047772e-08 2.121027e-21], sampled 0.5433451180990944
[2019-03-26 18:27:01,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1975710.935299867 W.
[2019-03-26 18:27:17,658] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02585071], dtype=float32), 0.11776908]
[2019-03-26 18:27:17,659] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.672158265, 99.49127732500001, 1.0, 2.0, 0.4228978506370451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 621008.955895363, 621008.955895363, 176240.2861786233]
[2019-03-26 18:27:17,660] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:27:17,663] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.0771729e-25 1.0000000e+00 2.5982901e-29 3.9209969e-27 1.1100597e-34], sampled 0.752186328273449
[2019-03-26 18:27:19,076] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02585071], dtype=float32), 0.11776908]
[2019-03-26 18:27:19,078] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.72716373, 69.535349985, 1.0, 2.0, 0.3821722082489794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 581133.1898763337, 581133.1898763344, 173133.5469826089]
[2019-03-26 18:27:19,081] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:27:19,083] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.3910951e-25 1.0000000e+00 6.2079631e-29 7.2683209e-28 2.0856541e-34], sampled 0.7944861821824141
[2019-03-26 18:27:24,998] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02585071], dtype=float32), 0.11776908]
[2019-03-26 18:27:25,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.16666666666666, 84.0, 1.0, 2.0, 0.6687241109450456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 934541.766919579, 934541.766919579, 214237.9198633613]
[2019-03-26 18:27:25,084] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:27:25,086] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.948995e-27 1.000000e+00 7.311724e-30 2.390406e-31 9.924009e-36], sampled 0.8049425893122084
[2019-03-26 18:27:27,259] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7982.1597 3155433533.2059 1550.0000
[2019-03-26 18:27:27,323] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8049.6314 3002874378.8998 1647.0000
[2019-03-26 18:27:27,656] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8675.2802 2777947711.0239 901.0000
[2019-03-26 18:27:27,706] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8284.6677 2924720100.7788 1273.0000
[2019-03-26 18:27:27,987] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8521.6965 2840074026.5060 1072.0000
[2019-03-26 18:27:29,005] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2150000, evaluation results [2150000.0, 7982.159693705124, 3155433533.2058897, 1550.0, 8284.66774218071, 2924720100.7788258, 1273.0, 8675.280242766996, 2777947711.023854, 901.0, 8049.631407813046, 3002874378.899774, 1647.0, 8521.696498063257, 2840074026.506045, 1072.0]
[2019-03-26 18:27:30,457] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2150654: loss 5.0763
[2019-03-26 18:27:30,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2150654: learning rate 0.0000
[2019-03-26 18:27:34,212] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2152323: loss 5.0581
[2019-03-26 18:27:34,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2152323: learning rate 0.0000
[2019-03-26 18:27:35,253] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152783: loss 5.1157
[2019-03-26 18:27:35,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152785: learning rate 0.0000
[2019-03-26 18:27:36,686] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2153416: loss 4.8848
[2019-03-26 18:27:36,689] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2153416: learning rate 0.0000
[2019-03-26 18:27:37,262] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2153672: loss 0.0008
[2019-03-26 18:27:37,263] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2153672: learning rate 0.0000
[2019-03-26 18:27:41,265] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2155438: loss 4.6587
[2019-03-26 18:27:41,269] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2155441: learning rate 0.0000
[2019-03-26 18:27:41,793] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2155673: loss 0.0145
[2019-03-26 18:27:41,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2155675: learning rate 0.0000
[2019-03-26 18:27:42,000] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2155766: loss 0.0095
[2019-03-26 18:27:42,002] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2155766: learning rate 0.0000
[2019-03-26 18:27:43,919] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2156616: loss 4.7526
[2019-03-26 18:27:43,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2156616: learning rate 0.0000
[2019-03-26 18:27:44,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.6640645e-10 2.7344367e-01 1.9683267e-17 7.2655642e-01 4.0683671e-19], sum to 1.0000
[2019-03-26 18:27:44,310] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9922
[2019-03-26 18:27:44,317] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.46666666666667, 73.16666666666667, 1.0, 2.0, 0.6824341315637179, 1.0, 2.0, 0.6824341315637179, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1908260.918087526, 1908260.918087526, 366687.1542659668], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1260600.0000, 
sim time next is 1261200.0000, 
raw observation next is [28.43333333333334, 73.33333333333334, 1.0, 2.0, 0.6917733664111106, 1.0, 2.0, 0.6917733664111106, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1934399.390012012, 1934399.390012012, 370614.336972205], 
processed observation next is [1.0, 0.6086956521739131, 0.5466034755134285, 0.7333333333333334, 1.0, 1.0, 0.6286426101338682, 1.0, 1.0, 0.6286426101338682, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5373331638922256, 0.5373331638922256, 0.5531557268241866], 
reward next is 0.4468, 
noisyNet noise sample is [array([-1.0603634], dtype=float32), -0.41639787]. 
=============================================
[2019-03-26 18:27:44,518] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2156878: loss 4.8804
[2019-03-26 18:27:44,519] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2156878: learning rate 0.0000
[2019-03-26 18:27:44,975] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2157080: loss 4.6944
[2019-03-26 18:27:44,977] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2157080: learning rate 0.0000
[2019-03-26 18:27:45,303] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2157224: loss 4.6965
[2019-03-26 18:27:45,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2157225: learning rate 0.0000
[2019-03-26 18:27:45,471] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2157295: loss 4.8728
[2019-03-26 18:27:45,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2157297: learning rate 0.0000
[2019-03-26 18:27:45,777] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2157434: loss 4.7315
[2019-03-26 18:27:45,781] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2157436: learning rate 0.0000
[2019-03-26 18:27:46,005] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2157534: loss 0.0080
[2019-03-26 18:27:46,006] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2157534: learning rate 0.0000
[2019-03-26 18:27:46,457] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2157735: loss 0.0021
[2019-03-26 18:27:46,462] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2157736: learning rate 0.0000
[2019-03-26 18:27:48,146] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2363519e-24 1.0000000e+00 4.7344015e-30 3.5755875e-27 8.3519455e-36], sum to 1.0000
[2019-03-26 18:27:48,155] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0541
[2019-03-26 18:27:48,159] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 85.66666666666667, 1.0, 2.0, 0.470594311913093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 659201.5933764144, 659201.5933764138, 179327.9456660536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1279200.0000, 
sim time next is 1279800.0000, 
raw observation next is [25.55, 86.5, 1.0, 2.0, 0.4692381634320024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658222.2365848398, 658222.2365848392, 179245.9695006397], 
processed observation next is [1.0, 0.8260869565217391, 0.40995260663507116, 0.865, 1.0, 1.0, 0.36052790774940047, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18283951016245548, 0.18283951016245534, 0.26753129776214885], 
reward next is 0.7325, 
noisyNet noise sample is [array([0.9564289], dtype=float32), -0.9676439]. 
=============================================
[2019-03-26 18:27:48,570] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2158667: loss 0.0249
[2019-03-26 18:27:48,573] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2158667: learning rate 0.0000
[2019-03-26 18:27:50,686] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4795325e-25 1.0000000e+00 8.6556370e-30 1.1674095e-26 4.5981023e-35], sum to 1.0000
[2019-03-26 18:27:50,696] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3200
[2019-03-26 18:27:50,707] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 95.66666666666667, 1.0, 2.0, 0.3639018098302271, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 555346.3876218017, 555346.3876218017, 170946.5490673208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1464000.0000, 
sim time next is 1464600.0000, 
raw observation next is [22.05, 95.83333333333333, 1.0, 2.0, 0.3637668005163909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 555650.6147185443, 555650.6147185436, 170987.8806704729], 
processed observation next is [0.0, 0.9565217391304348, 0.24407582938388633, 0.9583333333333333, 1.0, 1.0, 0.23345397652577213, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1543473929773734, 0.1543473929773732, 0.25520579204548194], 
reward next is 0.7448, 
noisyNet noise sample is [array([0.11730317], dtype=float32), 0.8070687]. 
=============================================
[2019-03-26 18:27:52,362] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2160354: loss 0.0141
[2019-03-26 18:27:52,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2160354: learning rate 0.0000
[2019-03-26 18:27:52,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3143947e-13 1.0000000e+00 5.7886068e-19 4.7022901e-08 7.8766608e-22], sum to 1.0000
[2019-03-26 18:27:52,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3152
[2019-03-26 18:27:52,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1735040.894198976 W.
[2019-03-26 18:27:52,459] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.6, 82.66666666666667, 1.0, 2.0, 0.4136914211296287, 1.0, 2.0, 0.4136914211296287, 1.0, 1.0, 0.7075009358923121, 6.911199999999999, 6.9112, 170.5573041426782, 1735040.894198976, 1735040.894198977, 358992.9186896955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1690800.0000, 
sim time next is 1691400.0000, 
raw observation next is [27.7, 82.33333333333334, 1.0, 2.0, 0.6217876919799332, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.94555479683344, 6.9112, 168.9127263981507, 1738554.067079669, 1714181.625008108, 369470.1258581635], 
processed observation next is [1.0, 0.5652173913043478, 0.5118483412322274, 0.8233333333333335, 1.0, 1.0, 0.5443225204577509, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0034354796833439673, 0.0, 0.8294388151956607, 0.4829316852999081, 0.4761615625022522, 0.5514479490420351], 
reward next is 0.2768, 
noisyNet noise sample is [array([0.65922177], dtype=float32), -1.401009]. 
=============================================
[2019-03-26 18:27:53,511] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160858: loss 0.0133
[2019-03-26 18:27:53,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160858: learning rate 0.0000
[2019-03-26 18:27:54,720] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2161395: loss 0.0089
[2019-03-26 18:27:54,724] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2161396: learning rate 0.0000
[2019-03-26 18:27:55,350] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2161676: loss 0.0009
[2019-03-26 18:27:55,351] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2161676: learning rate 0.0000
[2019-03-26 18:27:59,277] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2163421: loss 0.0061
[2019-03-26 18:27:59,280] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2163421: learning rate 0.0000
[2019-03-26 18:27:59,690] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2163602: loss 0.0019
[2019-03-26 18:27:59,692] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2163602: learning rate 0.0000
[2019-03-26 18:27:59,965] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2163728: loss 0.0019
[2019-03-26 18:27:59,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2163728: learning rate 0.0000
[2019-03-26 18:28:01,952] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2164611: loss 0.0211
[2019-03-26 18:28:01,953] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2164611: learning rate 0.0000
[2019-03-26 18:28:02,599] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2164895: loss 0.0185
[2019-03-26 18:28:02,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2164898: learning rate 0.0000
[2019-03-26 18:28:03,094] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2165113: loss 0.0109
[2019-03-26 18:28:03,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2165116: learning rate 0.0000
[2019-03-26 18:28:03,391] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2165243: loss 0.0114
[2019-03-26 18:28:03,392] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2165243: learning rate 0.0000
[2019-03-26 18:28:03,639] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2165355: loss 0.0200
[2019-03-26 18:28:03,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2165355: learning rate 0.0000
[2019-03-26 18:28:03,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6288622e-28 1.0000000e+00 5.6314897e-31 1.2014203e-33 8.4850510e-37], sum to 1.0000
[2019-03-26 18:28:03,730] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-26 18:28:03,739] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 51.00000000000001, 1.0, 2.0, 0.3417264474549018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527180.4756653601, 527180.4756653601, 168797.571347744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1509600.0000, 
sim time next is 1510200.0000, 
raw observation next is [28.95, 51.0, 1.0, 2.0, 0.342457810327265, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527670.8989852661, 527670.8989852661, 168816.9093744429], 
processed observation next is [0.0, 0.4782608695652174, 0.5710900473933649, 0.51, 1.0, 1.0, 0.20778049437019883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14657524971812946, 0.14657524971812946, 0.25196553637976554], 
reward next is 0.7480, 
noisyNet noise sample is [array([0.6920383], dtype=float32), -0.28907448]. 
=============================================
[2019-03-26 18:28:03,837] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2165439: loss 0.0200
[2019-03-26 18:28:03,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2165443: learning rate 0.0000
[2019-03-26 18:28:04,201] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2165602: loss 0.0046
[2019-03-26 18:28:04,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2165602: learning rate 0.0000
[2019-03-26 18:28:04,598] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2165774: loss 0.0014
[2019-03-26 18:28:04,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2165775: learning rate 0.0000
[2019-03-26 18:28:06,648] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2166688: loss 0.0022
[2019-03-26 18:28:06,650] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2166689: learning rate 0.0000
[2019-03-26 18:28:10,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5138198e-19 1.0000000e+00 8.0126953e-24 1.4040142e-17 4.5377215e-29], sum to 1.0000
[2019-03-26 18:28:10,036] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7818
[2019-03-26 18:28:10,043] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 94.0, 1.0, 2.0, 0.7547092638807567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1118050.769086616, 1118050.769086617, 241571.1496205619], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1614600.0000, 
sim time next is 1615200.0000, 
raw observation next is [23.13333333333333, 94.66666666666667, 1.0, 2.0, 0.7187299363156185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1064111.398798067, 1064111.398798067, 232801.3717641809], 
processed observation next is [1.0, 0.6956521739130435, 0.29541864139020524, 0.9466666666666668, 1.0, 1.0, 0.6611204051995404, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2955864996661297, 0.2955864996661297, 0.3474647339763894], 
reward next is 0.6525, 
noisyNet noise sample is [array([0.14926265], dtype=float32), 0.029998641]. 
=============================================
[2019-03-26 18:28:10,355] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2168332: loss 0.0045
[2019-03-26 18:28:10,359] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2168334: learning rate 0.0000
[2019-03-26 18:28:11,529] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168830: loss 0.0011
[2019-03-26 18:28:11,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168831: learning rate 0.0000
[2019-03-26 18:28:12,804] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2169395: loss 0.0018
[2019-03-26 18:28:12,807] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2169395: learning rate 0.0000
[2019-03-26 18:28:13,876] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2169872: loss 0.0756
[2019-03-26 18:28:13,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2169872: learning rate 0.0000
[2019-03-26 18:28:17,179] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2171328: loss 0.0088
[2019-03-26 18:28:17,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2171328: learning rate 0.0000
[2019-03-26 18:28:17,846] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2171627: loss 0.0011
[2019-03-26 18:28:17,847] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2171627: learning rate 0.0000
[2019-03-26 18:28:18,076] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2171730: loss 0.0007
[2019-03-26 18:28:18,079] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2171730: learning rate 0.0000
[2019-03-26 18:28:18,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.8422915e-27 1.0000000e+00 2.6127504e-30 1.7290715e-30 4.7512131e-36], sum to 1.0000
[2019-03-26 18:28:18,708] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5940
[2019-03-26 18:28:18,712] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 76.5, 1.0, 2.0, 0.5654173247186274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 790116.860644358, 790116.8606443586, 194480.7021696262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2122200.0000, 
sim time next is 2122800.0000, 
raw observation next is [30.0, 76.66666666666666, 1.0, 2.0, 0.5675127653699574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793046.1325086608, 793046.1325086608, 194850.2080356091], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.7666666666666666, 1.0, 1.0, 0.4789310426144065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2202905923635169, 0.2202905923635169, 0.29082120602329714], 
reward next is 0.7092, 
noisyNet noise sample is [array([-0.35137975], dtype=float32), 0.8413795]. 
=============================================
[2019-03-26 18:28:19,975] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2172574: loss 0.0038
[2019-03-26 18:28:19,978] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2172574: learning rate 0.0000
[2019-03-26 18:28:20,528] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2172821: loss 0.0051
[2019-03-26 18:28:20,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2172821: learning rate 0.0000
[2019-03-26 18:28:20,983] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2173022: loss 0.0035
[2019-03-26 18:28:20,985] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2173024: learning rate 0.0000
[2019-03-26 18:28:21,220] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2173129: loss 0.0020
[2019-03-26 18:28:21,224] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2173130: learning rate 0.0000
[2019-03-26 18:28:21,523] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2173260: loss 0.0029
[2019-03-26 18:28:21,530] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2173262: learning rate 0.0000
[2019-03-26 18:28:21,978] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2173460: loss 0.0015
[2019-03-26 18:28:21,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2173460: learning rate 0.0000
[2019-03-26 18:28:22,387] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2173642: loss 0.0013
[2019-03-26 18:28:22,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2173642: learning rate 0.0000
[2019-03-26 18:28:23,092] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2173953: loss 0.0947
[2019-03-26 18:28:23,097] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2173953: learning rate 0.0000
[2019-03-26 18:28:24,258] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.3702659e-23 1.0000000e+00 5.9175817e-29 8.3731464e-24 1.2897622e-33], sum to 1.0000
[2019-03-26 18:28:24,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0846
[2019-03-26 18:28:24,273] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 87.0, 1.0, 2.0, 0.4957861015139746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 692782.1274833999, 692782.1274833992, 182938.4050054057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881000.0000, 
sim time next is 1881600.0000, 
raw observation next is [26.06666666666667, 87.0, 1.0, 2.0, 0.4928728000745627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688709.9329947385, 688709.9329947378, 182486.8250618643], 
processed observation next is [1.0, 0.782608695652174, 0.4344391785150081, 0.87, 1.0, 1.0, 0.38900337358381043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19130831472076068, 0.1913083147207605, 0.27236839561472287], 
reward next is 0.7276, 
noisyNet noise sample is [array([2.7403944], dtype=float32), 0.61148614]. 
=============================================
[2019-03-26 18:28:24,605] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2174626: loss 0.0022
[2019-03-26 18:28:24,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2174626: learning rate 0.0000
[2019-03-26 18:28:25,461] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 18:28:25,463] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:28:25,464] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:28:25,464] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:28:25,466] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:28:25,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:28:25,468] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:28:25,469] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:28:25,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:28:25,469] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:28:25,471] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:28:25,500] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run88
[2019-03-26 18:28:25,529] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run88
[2019-03-26 18:28:25,554] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run88
[2019-03-26 18:28:25,578] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run88
[2019-03-26 18:28:25,601] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run88
[2019-03-26 18:28:38,808] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:28:38,809] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.26666666666667, 94.0, 1.0, 2.0, 0.41352830612468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611701.2915914946, 611701.2915914946, 175477.3095100468]
[2019-03-26 18:28:38,810] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:28:38,814] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7504563e-28 1.0000000e+00 1.3871707e-31 1.3009494e-33 1.5494453e-37], sampled 0.5963541901003252
[2019-03-26 18:28:49,370] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:28:49,372] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 62.5, 1.0, 2.0, 0.3447056236442966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533215.0281412377, 533215.0281412377, 169327.6436602366]
[2019-03-26 18:28:49,372] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:28:49,375] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2233363e-27 1.0000000e+00 5.4289473e-31 5.8433265e-31 1.5940818e-36], sampled 0.820439708556698
[2019-03-26 18:28:57,074] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:28:57,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.2, 90.0, 1.0, 2.0, 0.4834404588949535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 675525.572713986, 675525.5727139867, 181041.5787179376]
[2019-03-26 18:28:57,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:28:57,103] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.64939858e-25 1.00000000e+00 1.18762515e-29 7.98034447e-28
 4.52067175e-35], sampled 0.4548892459820386
[2019-03-26 18:29:57,725] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:29:57,727] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.17972546666667, 84.65298625333334, 1.0, 2.0, 0.500302200652109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699094.7334034556, 699094.7334034549, 183642.4067993325]
[2019-03-26 18:29:57,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:29:57,731] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1437483e-24 1.0000000e+00 1.0296213e-28 1.1455637e-26 4.3029912e-34], sampled 0.42370817832187413
[2019-03-26 18:30:03,352] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:30:03,354] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.16666666666667, 85.00000000000001, 1.0, 2.0, 0.5183179903372933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724277.5877025435, 724277.587702544, 186516.119772264]
[2019-03-26 18:30:03,355] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:30:03,357] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00009407e-25 1.00000000e+00 3.32817170e-30 5.54719963e-26
 2.22342905e-35], sampled 0.46422117206138336
[2019-03-26 18:30:05,981] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02545873], dtype=float32), 0.11959849]
[2019-03-26 18:30:05,982] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.19544672166667, 63.46785151, 1.0, 2.0, 0.3916326214611284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 591554.3030483706, 591554.3030483713, 173966.5735891478]
[2019-03-26 18:30:05,982] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:30:05,985] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8814852e-26 1.0000000e+00 3.3990222e-30 6.1126037e-29 1.5279990e-35], sampled 0.3066687730290032
[2019-03-26 18:30:21,667] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8675.3341 2778058976.2544 901.0000
[2019-03-26 18:30:21,742] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8284.7489 2924682132.5518 1273.0000
[2019-03-26 18:30:21,746] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8066.8593 3001384498.6081 1610.0000
[2019-03-26 18:30:21,854] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8533.0793 2838989669.5897 1043.0000
[2019-03-26 18:30:22,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8000.8972 3153708175.2775 1505.0000
[2019-03-26 18:30:23,058] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2175000, evaluation results [2175000.0, 8000.897200924966, 3153708175.277463, 1505.0, 8284.748892896901, 2924682132.5517783, 1273.0, 8675.334133722903, 2778058976.254385, 901.0, 8066.8592565000745, 3001384498.6081257, 1610.0, 8533.07933207697, 2838989669.5897403, 1043.0]
[2019-03-26 18:30:25,975] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2176303: loss 0.0028
[2019-03-26 18:30:25,978] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2176306: learning rate 0.0000
[2019-03-26 18:30:26,978] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176748: loss 0.0018
[2019-03-26 18:30:26,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176748: learning rate 0.0000
[2019-03-26 18:30:28,313] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2177338: loss 0.0011
[2019-03-26 18:30:28,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2177339: learning rate 0.0000
[2019-03-26 18:30:28,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.0555762e-23 1.0000000e+00 6.8451980e-27 1.3126359e-23 1.1963856e-32], sum to 1.0000
[2019-03-26 18:30:28,431] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9473
[2019-03-26 18:30:28,438] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 86.0, 1.0, 2.0, 0.509365435630883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711763.4415499672, 711763.4415499666, 185076.4852775885], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2251200.0000, 
sim time next is 2251800.0000, 
raw observation next is [26.65, 86.0, 1.0, 2.0, 0.507832736013975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709621.0034056521, 709621.0034056515, 184832.4162623897], 
processed observation next is [1.0, 0.043478260869565216, 0.462085308056872, 0.86, 1.0, 1.0, 0.4070273927879217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19711694539045893, 0.19711694539045876, 0.27586927800356675], 
reward next is 0.7241, 
noisyNet noise sample is [array([1.4455808], dtype=float32), -0.07887345]. 
=============================================
[2019-03-26 18:30:29,922] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2178033: loss 0.1445
[2019-03-26 18:30:29,924] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2178033: learning rate 0.0000
[2019-03-26 18:30:32,604] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2179223: loss 0.0008
[2019-03-26 18:30:32,608] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2179223: learning rate 0.0000
[2019-03-26 18:30:33,634] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2179678: loss 0.1166
[2019-03-26 18:30:33,636] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2179678: learning rate 0.0000
[2019-03-26 18:30:33,944] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2179814: loss 0.1507
[2019-03-26 18:30:33,946] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2179814: learning rate 0.0000
[2019-03-26 18:30:35,699] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2180588: loss 0.0021
[2019-03-26 18:30:35,702] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2180588: learning rate 0.0000
[2019-03-26 18:30:36,089] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2180758: loss 0.0017
[2019-03-26 18:30:36,093] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2180759: learning rate 0.0000
[2019-03-26 18:30:36,640] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2180998: loss 0.0007
[2019-03-26 18:30:36,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2180998: learning rate 0.0000
[2019-03-26 18:30:36,755] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2181053: loss 0.0005
[2019-03-26 18:30:36,757] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2181053: learning rate 0.0000
[2019-03-26 18:30:37,130] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2181214: loss 0.0008
[2019-03-26 18:30:37,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2181218: learning rate 0.0000
[2019-03-26 18:30:37,681] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2181459: loss 0.0020
[2019-03-26 18:30:37,683] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2181459: learning rate 0.0000
[2019-03-26 18:30:38,307] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2181732: loss 0.3689
[2019-03-26 18:30:38,310] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2181732: learning rate 0.0000
[2019-03-26 18:30:38,949] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2182017: loss 0.1685
[2019-03-26 18:30:38,950] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2182017: learning rate 0.0000
[2019-03-26 18:30:40,399] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7349169e-26 1.0000000e+00 6.6639268e-31 9.1647706e-29 2.0481382e-36], sum to 1.0000
[2019-03-26 18:30:40,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2570
[2019-03-26 18:30:40,417] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.05, 93.0, 1.0, 2.0, 0.5228074776523001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730553.1815580953, 730553.1815580946, 187246.6412671545], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2157000.0000, 
sim time next is 2157600.0000, 
raw observation next is [26.0, 93.0, 1.0, 2.0, 0.5209833541982788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 728003.3407383447, 728003.3407383454, 186948.9830338373], 
processed observation next is [0.0, 1.0, 0.4312796208530806, 0.93, 1.0, 1.0, 0.42287151108226356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20222315020509576, 0.20222315020509596, 0.27902833288632434], 
reward next is 0.7210, 
noisyNet noise sample is [array([-1.9482974], dtype=float32), -3.5389242]. 
=============================================
[2019-03-26 18:30:40,653] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2182774: loss 0.1307
[2019-03-26 18:30:40,654] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2182774: learning rate 0.0000
[2019-03-26 18:30:42,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.2642843e-25 1.0000000e+00 8.0023196e-29 5.1173734e-29 3.5237125e-35], sum to 1.0000
[2019-03-26 18:30:42,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3178
[2019-03-26 18:30:42,757] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.35, 82.0, 1.0, 2.0, 0.6725323260219531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 939866.1013753957, 939866.1013753957, 215026.5012050357], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2346600.0000, 
sim time next is 2347200.0000, 
raw observation next is [27.3, 82.0, 1.0, 2.0, 0.670485267407717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 937004.0683421745, 937004.0683421738, 214601.8070888437], 
processed observation next is [1.0, 0.17391304347826086, 0.4928909952606636, 0.82, 1.0, 1.0, 0.6029942980815867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26027890787282626, 0.26027890787282604, 0.32030120461021444], 
reward next is 0.6797, 
noisyNet noise sample is [array([-1.0304487], dtype=float32), 0.0036265692]. 
=============================================
[2019-03-26 18:30:44,267] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2184373: loss 0.4458
[2019-03-26 18:30:44,271] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2184373: learning rate 0.0000
[2019-03-26 18:30:45,461] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184876: loss 0.2660
[2019-03-26 18:30:45,466] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184878: learning rate 0.0000
[2019-03-26 18:30:45,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1572520e-26 1.0000000e+00 1.3799400e-31 1.3312909e-28 2.3368353e-36], sum to 1.0000
[2019-03-26 18:30:45,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-26 18:30:45,993] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.4, 65.0, 1.0, 2.0, 0.55414718820447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774362.1775313123, 774362.1775313123, 192516.7319889916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2397600.0000, 
sim time next is 2398200.0000, 
raw observation next is [32.28333333333333, 65.66666666666667, 1.0, 2.0, 0.5635218040779693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787467.0692054107, 787467.0692054107, 194148.3641803432], 
processed observation next is [1.0, 0.782608695652174, 0.7290679304897314, 0.6566666666666667, 1.0, 1.0, 0.4741226555156256, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21874085255705852, 0.21874085255705852, 0.28977367788110925], 
reward next is 0.7102, 
noisyNet noise sample is [array([-0.65504235], dtype=float32), 0.2091343]. 
=============================================
[2019-03-26 18:30:46,765] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2185460: loss 0.2534
[2019-03-26 18:30:46,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2185460: learning rate 0.0000
[2019-03-26 18:30:47,451] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2185761: loss 0.1200
[2019-03-26 18:30:47,453] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2185761: learning rate 0.0000
[2019-03-26 18:30:48,306] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4748442e-25 1.0000000e+00 3.7258687e-30 5.6745870e-27 1.0891993e-35], sum to 1.0000
[2019-03-26 18:30:48,313] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9883
[2019-03-26 18:30:48,321] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 78.5, 1.0, 2.0, 0.5164667385774078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721689.8410657181, 721689.8410657181, 186218.1996130723], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2569800.0000, 
sim time next is 2570400.0000, 
raw observation next is [28.7, 79.0, 1.0, 2.0, 0.522806852253863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730552.3073473206, 730552.3073473212, 187248.0963012627], 
processed observation next is [1.0, 0.782608695652174, 0.5592417061611374, 0.79, 1.0, 1.0, 0.42506849669140123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20293119648536684, 0.202931196485367, 0.2794747705988996], 
reward next is 0.7205, 
noisyNet noise sample is [array([-1.8186853], dtype=float32), 0.5304998]. 
=============================================
[2019-03-26 18:30:48,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5526891e-09 8.9491047e-03 4.5487109e-17 9.9105096e-01 5.0721841e-19], sum to 1.0000
[2019-03-26 18:30:48,425] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9779
[2019-03-26 18:30:48,431] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.9, 65.0, 1.0, 2.0, 0.8484558770237028, 1.0, 2.0, 0.8484558770237028, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2372989.157367717, 2372989.157367718, 444151.8625075237], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2298600.0000, 
sim time next is 2299200.0000, 
raw observation next is [31.93333333333333, 65.0, 1.0, 2.0, 0.8371560706565971, 1.0, 2.0, 0.8371560706565971, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2341355.882954324, 2341355.882954324, 438367.1166881431], 
processed observation next is [1.0, 0.6086956521739131, 0.7124802527646128, 0.65, 1.0, 1.0, 0.8038024947669845, 1.0, 1.0, 0.8038024947669845, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.650376634153979, 0.650376634153979, 0.6542792786390196], 
reward next is 0.3457, 
noisyNet noise sample is [array([-1.147054], dtype=float32), 0.5258398]. 
=============================================
[2019-03-26 18:30:50,895] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2187288: loss 0.2988
[2019-03-26 18:30:50,896] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2187288: learning rate 0.0000
[2019-03-26 18:30:51,734] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2187656: loss 0.1422
[2019-03-26 18:30:51,739] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2187657: learning rate 0.0000
[2019-03-26 18:30:52,016] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2187784: loss 0.1401
[2019-03-26 18:30:52,017] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2187784: learning rate 0.0000
[2019-03-26 18:30:53,927] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2188627: loss 0.4546
[2019-03-26 18:30:53,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2188627: learning rate 0.0000
[2019-03-26 18:30:54,204] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2188750: loss 0.4430
[2019-03-26 18:30:54,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2188751: learning rate 0.0000
[2019-03-26 18:30:54,925] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2189071: loss 1.3584
[2019-03-26 18:30:54,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2189072: learning rate 0.0000
[2019-03-26 18:30:54,966] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2189086: loss 0.4376
[2019-03-26 18:30:54,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2189086: learning rate 0.0000
[2019-03-26 18:30:55,349] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2189257: loss 0.7100
[2019-03-26 18:30:55,353] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2189258: learning rate 0.0000
[2019-03-26 18:30:55,954] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2189523: loss 0.7198
[2019-03-26 18:30:55,957] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2189524: learning rate 0.0000
[2019-03-26 18:30:56,276] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2189666: loss 0.0828
[2019-03-26 18:30:56,278] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2189666: learning rate 0.0000
[2019-03-26 18:30:56,546] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2189787: loss 0.1164
[2019-03-26 18:30:56,548] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2189787: learning rate 0.0000
[2019-03-26 18:30:58,692] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2190734: loss 0.1186
[2019-03-26 18:30:58,695] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2190735: learning rate 0.0000
[2019-03-26 18:31:02,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000289e-32 1.000000e+00 3.451000e-35 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:31:02,430] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7413
[2019-03-26 18:31:02,435] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.33333333333333, 100.0, 1.0, 2.0, 0.4503384064312532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643133.9493691779, 643133.9493691786, 177966.7730345486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2709600.0000, 
sim time next is 2710200.0000, 
raw observation next is [23.16666666666667, 100.0, 1.0, 2.0, 0.4427102211633037, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 636735.7042807669, 636735.7042807676, 177437.2248689152], 
processed observation next is [0.0, 0.34782608695652173, 0.2969984202211693, 1.0, 1.0, 1.0, 0.3285665315220526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1768710289668797, 0.1768710289668799, 0.26483167890882864], 
reward next is 0.7352, 
noisyNet noise sample is [array([0.04244695], dtype=float32), -0.99622834]. 
=============================================
[2019-03-26 18:31:02,523] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2192425: loss 0.1341
[2019-03-26 18:31:02,527] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2192426: learning rate 0.0000
[2019-03-26 18:31:03,549] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192884: loss 0.1576
[2019-03-26 18:31:03,553] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192885: learning rate 0.0000
[2019-03-26 18:31:04,820] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2193446: loss 0.0066
[2019-03-26 18:31:04,825] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2193448: learning rate 0.0000
[2019-03-26 18:31:04,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.8670509e-28 1.0000000e+00 3.4508451e-33 2.5734663e-33 0.0000000e+00], sum to 1.0000
[2019-03-26 18:31:04,979] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5921
[2019-03-26 18:31:04,988] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.7, 79.0, 1.0, 2.0, 0.522806852253863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730552.3073473206, 730552.3073473212, 187248.0963012319], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2570400.0000, 
sim time next is 2571000.0000, 
raw observation next is [28.6, 79.66666666666667, 1.0, 2.0, 0.5319290492692991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 743303.811515374, 743303.8115153746, 188750.7687660338], 
processed observation next is [1.0, 0.782608695652174, 0.5545023696682465, 0.7966666666666667, 1.0, 1.0, 0.4360590955051796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20647328097649278, 0.20647328097649295, 0.2817175653224385], 
reward next is 0.7183, 
noisyNet noise sample is [array([1.7918462], dtype=float32), -0.8840516]. 
=============================================
[2019-03-26 18:31:05,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[75.57787 ]
 [74.93785 ]
 [74.76418 ]
 [73.29299 ]
 [69.670006]], R is [[75.40379333]
 [75.37028503]
 [75.33864594]
 [75.30879211]
 [75.28174591]].
[2019-03-26 18:31:05,107] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2193565: loss 0.1261
[2019-03-26 18:31:05,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2193567: learning rate 0.0000
[2019-03-26 18:31:08,553] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2940893e-33 1.0000000e+00 5.3790082e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:31:08,560] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6654
[2019-03-26 18:31:08,565] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4759033026671583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664990.3861802926, 664990.3861802932, 179906.6897810711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2701200.0000, 
sim time next is 2701800.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4759374510523071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665038.117422774, 665038.117422774, 179911.7946116094], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3685993386172375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.184732810395215, 0.184732810395215, 0.26852506658449166], 
reward next is 0.7315, 
noisyNet noise sample is [array([0.3247346], dtype=float32), -1.5228935]. 
=============================================
[2019-03-26 18:31:08,855] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.0016536e-33 1.0000000e+00 8.6619234e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:31:08,865] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7267
[2019-03-26 18:31:08,870] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.47695265418527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666584.9123931888, 666584.9123931894, 180079.941457943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2630400.0000, 
sim time next is 2631000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4760064844815962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665262.5215583926, 665262.5215583926, 179938.3610314093], 
processed observation next is [0.0, 0.43478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.36868251142360986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18479514487733126, 0.18479514487733126, 0.2685647179573273], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.66458404], dtype=float32), 0.99556935]. 
=============================================
[2019-03-26 18:31:08,890] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.62935 ]
 [76.59273 ]
 [76.56643 ]
 [76.550064]
 [76.52064 ]], R is [[76.631073  ]
 [76.59598541]
 [76.56122589]
 [76.52687073]
 [76.4930191 ]].
[2019-03-26 18:31:09,170] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2195373: loss 0.1097
[2019-03-26 18:31:09,173] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2195375: learning rate 0.0000
[2019-03-26 18:31:09,226] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2195397: loss 0.0562
[2019-03-26 18:31:09,230] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2195397: learning rate 0.0000
[2019-03-26 18:31:09,489] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2195512: loss 0.0718
[2019-03-26 18:31:09,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2195514: learning rate 0.0000
[2019-03-26 18:31:12,330] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2196782: loss 0.1444
[2019-03-26 18:31:12,333] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2196782: learning rate 0.0000
[2019-03-26 18:31:12,727] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2196956: loss 0.1496
[2019-03-26 18:31:12,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2196957: learning rate 0.0000
[2019-03-26 18:31:13,453] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2197278: loss 0.1399
[2019-03-26 18:31:13,455] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2197278: learning rate 0.0000
[2019-03-26 18:31:13,518] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2197307: loss 0.1392
[2019-03-26 18:31:13,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2197307: learning rate 0.0000
[2019-03-26 18:31:13,818] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2197438: loss 0.1275
[2019-03-26 18:31:13,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2197439: learning rate 0.0000
[2019-03-26 18:31:14,057] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2197547: loss 0.0049
[2019-03-26 18:31:14,059] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2197549: learning rate 0.0000
[2019-03-26 18:31:14,240] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2197629: loss 0.0567
[2019-03-26 18:31:14,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2197631: learning rate 0.0000
[2019-03-26 18:31:14,543] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2197760: loss 0.1123
[2019-03-26 18:31:14,546] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2197761: learning rate 0.0000
[2019-03-26 18:31:16,283] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2198530: loss 0.0565
[2019-03-26 18:31:16,286] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2198531: learning rate 0.0000
[2019-03-26 18:31:19,606] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 18:31:19,608] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:31:19,610] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:31:19,612] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:31:19,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:31:19,614] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:31:19,615] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:31:19,614] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:31:19,617] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:31:19,616] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:31:19,622] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:31:19,646] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run89
[2019-03-26 18:31:19,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run89
[2019-03-26 18:31:19,700] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run89
[2019-03-26 18:31:19,700] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run89
[2019-03-26 18:31:19,742] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run89
[2019-03-26 18:31:35,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02550538], dtype=float32), 0.12000143]
[2019-03-26 18:31:35,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.3, 78.0, 1.0, 2.0, 0.4340183885462121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 697177.5001189038, 697177.5001189031, 184005.2957734949]
[2019-03-26 18:31:35,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:31:35,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7300049e-31 1.0000000e+00 9.1010960e-34 1.1818394e-38 0.0000000e+00], sampled 0.4937290012267772
[2019-03-26 18:32:27,958] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02550538], dtype=float32), 0.12000143]
[2019-03-26 18:32:27,959] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [38.33333333333333, 41.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.926495941107383, 6.9112, 168.9126126863765, 1464613.804824112, 1453762.359845143, 311354.3124839046]
[2019-03-26 18:32:27,965] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:32:27,967] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2935424e-24 1.0000000e+00 1.2234894e-28 1.4324688e-27 2.4391023e-34], sampled 0.7898672658760126
[2019-03-26 18:32:48,616] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02550538], dtype=float32), 0.12000143]
[2019-03-26 18:32:48,617] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.58333333333334, 92.0, 1.0, 2.0, 0.8195761215711496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1145471.112078917, 1145471.112078916, 248772.8191490404]
[2019-03-26 18:32:48,618] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:32:48,620] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1390178e-29 1.0000000e+00 3.8450162e-32 3.1595134e-36 2.4405678e-38], sampled 0.8754553022712246
[2019-03-26 18:32:58,233] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02550538], dtype=float32), 0.12000143]
[2019-03-26 18:32:58,235] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.2, 82.0, 1.0, 2.0, 0.4928646772773733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 688698.5790215711, 688698.5790215711, 182486.4847393866]
[2019-03-26 18:32:58,237] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:32:58,239] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.8530690e-32 1.0000000e+00 1.0079871e-34 0.0000000e+00 0.0000000e+00], sampled 0.5163548069591702
[2019-03-26 18:33:15,001] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7892.6912 3163458789.8667 1764.0000
[2019-03-26 18:33:15,413] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.2902 3007628946.7148 1766.0000
[2019-03-26 18:33:15,559] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.2109 2927432838.1907 1338.0000
[2019-03-26 18:33:15,793] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.6731 2779216259.3191 930.0000
[2019-03-26 18:33:15,831] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 18:33:16,846] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2200000, evaluation results [2200000.0, 7892.691228592662, 3163458789.8666697, 1764.0, 8255.210919284205, 2927432838.1906743, 1338.0, 8661.67309374496, 2779216259.3191485, 930.0, 7999.290156831091, 3007628946.7147923, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 18:33:17,560] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2200321: loss 0.0522
[2019-03-26 18:33:17,565] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2200323: learning rate 0.0000
[2019-03-26 18:33:18,728] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200846: loss 0.0354
[2019-03-26 18:33:18,730] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200847: learning rate 0.0000
[2019-03-26 18:33:19,525] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4323683e-30 1.0000000e+00 6.3766560e-34 2.0545548e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:19,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5014
[2019-03-26 18:33:19,542] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.3162247988953518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500056.7546586314, 500056.754658632, 167029.6317560708], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2931000.0000, 
sim time next is 2931600.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3170575583172149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 501368.4287978841, 501368.4287978835, 167127.8055310481], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17717778110507817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13926900799941225, 0.13926900799941208, 0.24944448586723597], 
reward next is 0.7506, 
noisyNet noise sample is [array([1.6680294], dtype=float32), -0.15991323]. 
=============================================
[2019-03-26 18:33:20,256] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2201518: loss 0.0504
[2019-03-26 18:33:20,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2201519: learning rate 0.0000
[2019-03-26 18:33:21,099] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2201897: loss 2.3007
[2019-03-26 18:33:21,103] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2201897: learning rate 0.0000
[2019-03-26 18:33:23,272] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.9812505e-29 1.0000000e+00 4.0832185e-33 2.5225526e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:23,285] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2204
[2019-03-26 18:33:23,291] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3444608833846927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534749.1700828595, 534749.1700828589, 169505.0779180692], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2916000.0000, 
sim time next is 2916600.0000, 
raw observation next is [21.0, 99.00000000000001, 1.0, 2.0, 0.3431875476310522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534162.7870504323, 534162.7870504316, 169493.8753872201], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.9900000000000001, 1.0, 1.0, 0.20865969594102673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14837855195845343, 0.14837855195845323, 0.25297593341376134], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.6809621], dtype=float32), 1.9875184]. 
=============================================
[2019-03-26 18:33:24,231] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2203293: loss 0.0283
[2019-03-26 18:33:24,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2203294: learning rate 0.0000
[2019-03-26 18:33:24,396] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2203367: loss 0.0048
[2019-03-26 18:33:24,399] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2203367: learning rate 0.0000
[2019-03-26 18:33:24,635] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2203470: loss 0.0049
[2019-03-26 18:33:24,641] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2203470: learning rate 0.0000
[2019-03-26 18:33:24,781] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9172906e-10 9.7256392e-01 7.6894098e-18 2.7436022e-02 6.9998417e-19], sum to 1.0000
[2019-03-26 18:33:24,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2782
[2019-03-26 18:33:24,802] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2188408.28239948 W.
[2019-03-26 18:33:24,807] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.5216789853500216, 1.0, 2.0, 0.5216789853500216, 1.0, 2.0, 0.9059838756762434, 6.911200000000001, 6.9112, 170.5573041426782, 2188408.28239948, 2188408.282399479, 430460.9765288577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3671400.0000, 
sim time next is 3672000.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.8309102511672523, 1.0, 2.0, 0.8309102511672523, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2323871.349799772, 2323871.349799772, 435199.6145249247], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.63, 1.0, 1.0, 0.7962774110448823, 1.0, 1.0, 0.7962774110448823, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6455198193888255, 0.6455198193888255, 0.6495516634700369], 
reward next is 0.3504, 
noisyNet noise sample is [array([0.9077899], dtype=float32), -0.22663568]. 
=============================================
[2019-03-26 18:33:24,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[59.307816]
 [58.041252]
 [56.548553]
 [57.80413 ]
 [57.54102 ]], R is [[58.75601196]
 [58.52597427]
 [57.94071579]
 [57.36130905]
 [57.12975693]].
[2019-03-26 18:33:26,089] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1214848e-32 1.0000000e+00 6.4484480e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:26,100] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8457
[2019-03-26 18:33:26,105] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.309942844654496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490120.9203563386, 490120.9203563379, 166292.8501386649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2951400.0000, 
sim time next is 2952000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.309755161853096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489824.2734502368, 489824.2734502368, 166271.065492433], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 1.0, 1.0, 0.16837971307601926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13606229818062135, 0.13606229818062135, 0.24816576939169105], 
reward next is 0.7518, 
noisyNet noise sample is [array([-0.51629066], dtype=float32), -1.0649341]. 
=============================================
[2019-03-26 18:33:26,117] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.90266]
 [74.01144]
 [74.15799]
 [74.36124]
 [74.61613]], R is [[73.91804504]
 [73.93066406]
 [73.94309235]
 [73.95539856]
 [73.96796417]].
[2019-03-26 18:33:26,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4749094e-29 1.0000000e+00 4.3064581e-33 3.4856105e-35 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:26,949] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8607
[2019-03-26 18:33:26,954] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 82.33333333333334, 1.0, 2.0, 0.5391602199958581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753412.044838922, 753412.0448389213, 189958.9602197447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [28.0, 81.5, 1.0, 2.0, 0.5350485252847587, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747664.420231969, 747664.4202319696, 189269.4674526293], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.815, 1.0, 1.0, 0.4398175003430827, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20768456117554693, 0.2076845611755471, 0.2824917424666109], 
reward next is 0.7175, 
noisyNet noise sample is [array([-0.35046983], dtype=float32), 0.32221478]. 
=============================================
[2019-03-26 18:33:27,452] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2204717: loss 0.0576
[2019-03-26 18:33:27,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2204718: learning rate 0.0000
[2019-03-26 18:33:27,725] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2204834: loss 0.0524
[2019-03-26 18:33:27,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2204835: learning rate 0.0000
[2019-03-26 18:33:28,533] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2205180: loss 0.0608
[2019-03-26 18:33:28,536] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2205181: learning rate 0.0000
[2019-03-26 18:33:28,608] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2205211: loss 0.0693
[2019-03-26 18:33:28,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2205211: learning rate 0.0000
[2019-03-26 18:33:28,969] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2205374: loss 0.0490
[2019-03-26 18:33:28,971] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2205374: learning rate 0.0000
[2019-03-26 18:33:29,428] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2205578: loss 0.0049
[2019-03-26 18:33:29,431] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2205579: learning rate 0.0000
[2019-03-26 18:33:29,759] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2205725: loss 0.0394
[2019-03-26 18:33:29,761] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2205725: learning rate 0.0000
[2019-03-26 18:33:30,335] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2205978: loss 1.0601
[2019-03-26 18:33:30,341] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2205979: learning rate 0.0000
[2019-03-26 18:33:31,419] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2206456: loss 0.0091
[2019-03-26 18:33:31,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2206456: learning rate 0.0000
[2019-03-26 18:33:32,428] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8962085e-31 1.0000000e+00 4.7758581e-34 1.7797035e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:32,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6924
[2019-03-26 18:33:32,444] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.573834901793472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801884.0630500738, 801884.0630500738, 195973.3259548839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3328800.0000, 
sim time next is 3329400.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5740616382238679, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 802201.0270199444, 802201.0270199438, 196013.8027636713], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.48682125087212996, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2228336186166512, 0.22283361861665105, 0.29255791457264374], 
reward next is 0.7074, 
noisyNet noise sample is [array([-0.9624856], dtype=float32), 0.17021054]. 
=============================================
[2019-03-26 18:33:35,570] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2208299: loss 0.0111
[2019-03-26 18:33:35,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2208299: learning rate 0.0000
[2019-03-26 18:33:36,609] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208762: loss 0.0122
[2019-03-26 18:33:36,612] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208762: learning rate 0.0000
[2019-03-26 18:33:38,036] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2209391: loss 0.0128
[2019-03-26 18:33:38,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2209392: learning rate 0.0000
[2019-03-26 18:33:39,597] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2210082: loss 0.0291
[2019-03-26 18:33:39,600] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2210083: learning rate 0.0000
[2019-03-26 18:33:41,539] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1120153e-31 1.0000000e+00 3.0792001e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:41,549] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0857
[2019-03-26 18:33:41,557] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.5, 63.0, 1.0, 2.0, 0.5598152607579185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782285.6270513296, 782285.6270513296, 193499.3783222623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3245400.0000, 
sim time next is 3246000.0000, 
raw observation next is [32.66666666666667, 63.0, 1.0, 2.0, 0.5639949699404903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788128.5179131179, 788128.5179131179, 194231.0397517385], 
processed observation next is [0.0, 0.5652173913043478, 0.7472353870458138, 0.63, 1.0, 1.0, 0.4746927348680605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21892458830919942, 0.21892458830919942, 0.28989707425632616], 
reward next is 0.7101, 
noisyNet noise sample is [array([1.0480115], dtype=float32), -0.35852808]. 
=============================================
[2019-03-26 18:33:41,587] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[74.72149]
 [74.71439]
 [74.68966]
 [74.69871]
 [74.50633]], R is [[74.67253876]
 [74.63700867]
 [74.60248566]
 [74.56797791]
 [74.53552246]].
[2019-03-26 18:33:41,984] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2211142: loss 0.0079
[2019-03-26 18:33:41,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2211142: learning rate 0.0000
[2019-03-26 18:33:42,515] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.3673328e-30 1.0000000e+00 1.0119256e-32 1.7558010e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:42,522] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0086
[2019-03-26 18:33:42,529] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 75.66666666666667, 1.0, 2.0, 0.6046156823311563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844914.6186266005, 844914.6186266005, 201608.1970021895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3262200.0000, 
sim time next is 3262800.0000, 
raw observation next is [30.33333333333334, 76.33333333333334, 1.0, 2.0, 0.5863564233374999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819388.542952429, 819388.542952429, 198231.5427192179], 
processed observation next is [0.0, 0.782608695652174, 0.6366508688783573, 0.7633333333333334, 1.0, 1.0, 0.5016342449849397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22760792859789694, 0.22760792859789694, 0.2958679742077879], 
reward next is 0.7041, 
noisyNet noise sample is [array([-1.4470204], dtype=float32), 1.1329666]. 
=============================================
[2019-03-26 18:33:43,109] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2211629: loss 0.1261
[2019-03-26 18:33:43,114] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2211632: learning rate 0.0000
[2019-03-26 18:33:43,402] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2211763: loss 1.0016
[2019-03-26 18:33:43,406] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2211765: learning rate 0.0000
[2019-03-26 18:33:45,259] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2212569: loss 0.0066
[2019-03-26 18:33:45,260] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2212569: learning rate 0.0000
[2019-03-26 18:33:45,495] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2212672: loss 0.0072
[2019-03-26 18:33:45,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2212672: learning rate 0.0000
[2019-03-26 18:33:46,180] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2212976: loss 0.0123
[2019-03-26 18:33:46,182] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2212976: learning rate 0.0000
[2019-03-26 18:33:46,351] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2213054: loss 0.0147
[2019-03-26 18:33:46,353] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2213054: learning rate 0.0000
[2019-03-26 18:33:46,775] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2213238: loss 0.0150
[2019-03-26 18:33:46,778] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2213238: learning rate 0.0000
[2019-03-26 18:33:47,440] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2213531: loss 0.0194
[2019-03-26 18:33:47,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2213531: learning rate 0.0000
[2019-03-26 18:33:47,904] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.0635126e-09 5.7634175e-01 2.6687096e-16 4.2365828e-01 9.9821286e-18], sum to 1.0000
[2019-03-26 18:33:47,913] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1687
[2019-03-26 18:33:47,922] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2489610.92417799 W.
[2019-03-26 18:33:47,927] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333333, 70.83333333333334, 1.0, 2.0, 0.8901121784298095, 1.0, 2.0, 0.8901121784298095, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2489610.92417799, 2489610.92417799, 466132.5270256521], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3408600.0000, 
sim time next is 3409200.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.14310840089593, 6.9112, 168.9052303944343, 3158402.496414578, 2284484.252846281, 473146.0454927495], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.71, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.12319084008959295, 0.0, 0.8294020063857277, 0.8773340267818273, 0.634578959123967, 0.7061881276011186], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8070729], dtype=float32), 2.2169583]. 
=============================================
[2019-03-26 18:33:47,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2213769: loss 0.0073
[2019-03-26 18:33:47,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2213770: learning rate 0.0000
[2019-03-26 18:33:48,646] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2214064: loss 0.0271
[2019-03-26 18:33:48,648] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2214064: learning rate 0.0000
[2019-03-26 18:33:50,049] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2214686: loss 0.1098
[2019-03-26 18:33:50,051] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2214686: learning rate 0.0000
[2019-03-26 18:33:50,467] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0442747e-29 1.0000000e+00 9.6411807e-32 4.4935901e-36 3.6274575e-38], sum to 1.0000
[2019-03-26 18:33:50,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5308
[2019-03-26 18:33:50,481] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7356349309633216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1028094.881958236, 1028094.881958236, 228724.3100700208], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3387000.0000, 
sim time next is 3387600.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7310351953082055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1021663.377300856, 1021663.377300855, 227686.0590640607], 
processed observation next is [1.0, 0.21739130434782608, 0.4312796208530806, 0.94, 1.0, 1.0, 0.675946018443621, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2837953825835711, 0.28379538258357084, 0.33982993890158314], 
reward next is 0.6602, 
noisyNet noise sample is [array([2.2734048], dtype=float32), -0.48553658]. 
=============================================
[2019-03-26 18:33:53,845] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4926573e-27 1.0000000e+00 1.2688821e-30 1.0295205e-33 4.3021945e-38], sum to 1.0000
[2019-03-26 18:33:53,852] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0358
[2019-03-26 18:33:53,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.8066907044493996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1127452.396411852, 1127452.396411851, 245558.9500192037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3571200.0000, 
sim time next is 3571800.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.8455013849451568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1181725.420621157, 1181725.420621157, 255385.5487140144], 
processed observation next is [1.0, 0.34782608695652173, 0.581358609794629, 0.7333333333333334, 1.0, 1.0, 0.8138570902953697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3282570612836547, 0.3282570612836547, 0.3811724607671857], 
reward next is 0.6188, 
noisyNet noise sample is [array([1.2711078], dtype=float32), -0.23398249]. 
=============================================
[2019-03-26 18:33:53,981] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2216423: loss 0.4754
[2019-03-26 18:33:53,986] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2216423: learning rate 0.0000
[2019-03-26 18:33:54,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.01640936e-27 1.00000000e+00 7.41064694e-31 1.01670806e-32
 7.09366093e-38], sum to 1.0000
[2019-03-26 18:33:54,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-26 18:33:54,510] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333333, 1.0, 2.0, 0.5035865515859838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703685.6245507251, 703685.6245507258, 184159.9167561295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3462000.0000, 
sim time next is 3462600.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5023997800195541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702026.7437834226, 702026.7437834232, 183972.8808807829], 
processed observation next is [1.0, 0.043478260869565216, 0.4391785150078992, 0.8816666666666667, 1.0, 1.0, 0.4004816626741615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1950074288287285, 0.19500742882872868, 0.27458638937430285], 
reward next is 0.7254, 
noisyNet noise sample is [array([-0.70297873], dtype=float32), 0.23697382]. 
=============================================
[2019-03-26 18:33:55,154] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216936: loss 0.0137
[2019-03-26 18:33:55,156] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216937: learning rate 0.0000
[2019-03-26 18:33:56,579] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2217568: loss 0.1768
[2019-03-26 18:33:56,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2217570: learning rate 0.0000
[2019-03-26 18:33:56,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9535460e-32 1.0000000e+00 2.2810934e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:33:56,807] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4984
[2019-03-26 18:33:56,812] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5239995308192782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732219.4897511872, 732219.4897511872, 187441.802578741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5234008158471993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731382.5773714219, 731382.5773714213, 187343.8294250153], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4257841154785534, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20316182704761718, 0.203161827047617, 0.2796176558582318], 
reward next is 0.7204, 
noisyNet noise sample is [array([1.0103027], dtype=float32), 0.81182516]. 
=============================================
[2019-03-26 18:33:56,836] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.0775455e-11 9.9986529e-01 4.3686687e-17 1.3469164e-04 2.2957136e-19], sum to 1.0000
[2019-03-26 18:33:56,846] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6480
[2019-03-26 18:33:56,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2329916.570755095 W.
[2019-03-26 18:33:56,864] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5553798219988505, 1.0, 1.0, 0.5553798219988505, 1.0, 2.0, 0.9645110838982732, 6.911200000000001, 6.9112, 170.5573041426782, 2329916.570755095, 2329916.570755094, 455555.3901225067], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3503400.0000, 
sim time next is 3504000.0000, 
raw observation next is [33.0, 63.00000000000001, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.825305730454135, 6.9112, 168.902011019078, 3642775.690217365, 2284931.200074618, 471021.7393349839], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.6300000000000001, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.19141057304541348, 0.0, 0.8293861977788919, 1.0118821361714903, 0.6347031111318384, 0.7030175213954984], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15558623], dtype=float32), 0.23428318]. 
=============================================
[2019-03-26 18:33:56,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[49.760006]
 [49.88286 ]
 [49.395756]
 [49.878857]
 [49.88394 ]], R is [[43.76761627]
 [43.65000916]
 [43.21350861]
 [42.78137207]
 [42.71285629]].
[2019-03-26 18:33:57,632] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.9713885e-14 1.0000000e+00 1.1118949e-19 3.4008449e-11 1.5465274e-23], sum to 1.0000
[2019-03-26 18:33:57,640] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-26 18:33:57,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2329268.033047427 W.
[2019-03-26 18:33:57,651] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.02448094305643, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.991374971738649, 6.9112, 168.9124798008937, 2329268.033047427, 2272389.309211192, 471477.2856642714], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3495600.0000, 
sim time next is 3496200.0000, 
raw observation next is [31.16666666666667, 66.16666666666667, 1.0, 2.0, 1.00237373467581, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.992934199733245, 6.9112, 168.9124054253466, 2298324.507101499, 2240339.641915174, 464530.4714005063], 
processed observation next is [1.0, 0.4782608695652174, 0.6761453396524489, 0.6616666666666667, 1.0, 1.0, 1.0028599212961566, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008173419973324502, 0.0, 0.8294372390722504, 0.6384234741948608, 0.6223165671986595, 0.6933290617918005], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26779017], dtype=float32), 0.56363827]. 
=============================================
[2019-03-26 18:33:57,868] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2218132: loss 57.0053
[2019-03-26 18:33:57,871] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2218134: learning rate 0.0000
[2019-03-26 18:33:58,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6860036e-26 1.0000000e+00 1.6524560e-29 3.0474320e-31 6.1312412e-36], sum to 1.0000
[2019-03-26 18:33:58,188] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6664
[2019-03-26 18:33:58,193] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.8066290140806415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1127366.130540363, 1127366.130540363, 245540.9838231572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3639600.0000, 
sim time next is 3640200.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.7734705947839404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1080999.454055136, 1080999.454055136, 237499.5673800751], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.7270730057637836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30027762612642667, 0.30027762612642667, 0.35447696623891806], 
reward next is 0.6455, 
noisyNet noise sample is [array([-1.4492174], dtype=float32), 0.81531656]. 
=============================================
[2019-03-26 18:33:59,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7344081e-19 1.0000000e+00 9.8266845e-25 1.2551173e-17 6.8393179e-29], sum to 1.0000
[2019-03-26 18:33:59,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2371
[2019-03-26 18:33:59,956] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 67.5, 1.0, 2.0, 0.3910653750064894, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6791512290905205, 6.911200000000001, 6.9112, 168.912956510431, 1093109.082538618, 1093109.082538617, 255755.9471778866], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3517800.0000, 
sim time next is 3518400.0000, 
raw observation next is [31.66666666666667, 68.0, 1.0, 2.0, 0.545309104655413, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 762007.4591063368, 762007.4591063361, 191002.0165444262], 
processed observation next is [1.0, 0.7391304347826086, 0.6998420221169038, 0.68, 1.0, 1.0, 0.4521796441631482, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2116687386406491, 0.21166873864064892, 0.28507763663347196], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9223063], dtype=float32), -0.74230474]. 
=============================================
[2019-03-26 18:34:00,454] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2219276: loss 0.0048
[2019-03-26 18:34:00,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2219276: learning rate 0.0000
[2019-03-26 18:34:01,058] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2219542: loss 0.0417
[2019-03-26 18:34:01,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2219542: learning rate 0.0000
[2019-03-26 18:34:01,569] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2219765: loss 0.0376
[2019-03-26 18:34:01,574] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2219765: learning rate 0.0000
[2019-03-26 18:34:02,606] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1675385e-11 9.9992239e-01 4.1158506e-18 7.7550598e-05 2.5343455e-20], sum to 1.0000
[2019-03-26 18:34:02,615] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5454
[2019-03-26 18:34:02,626] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2212707.847163448 W.
[2019-03-26 18:34:02,633] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5274656102774863, 1.0, 1.0, 0.5274656102774863, 1.0, 2.0, 0.9160333295091435, 6.9112, 6.9112, 170.5573041426782, 2212707.847163448, 2212707.847163448, 434658.8461184112], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3582000.0000, 
sim time next is 3582600.0000, 
raw observation next is [31.16666666666667, 69.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.271876321995939, 6.9112, 168.9112115958737, 2539787.242121567, 2283913.689044002, 475296.4893116452], 
processed observation next is [1.0, 0.4782608695652174, 0.6761453396524489, 0.695, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0360676321995939, 0.0, 0.829431376823001, 0.7054964561448798, 0.6344204691788894, 0.7093977452412615], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6909671], dtype=float32), 0.73441905]. 
=============================================
[2019-03-26 18:34:03,442] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2220593: loss 0.3545
[2019-03-26 18:34:03,448] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2220593: learning rate 0.0000
[2019-03-26 18:34:03,657] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2220692: loss 0.0025
[2019-03-26 18:34:03,661] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2220693: learning rate 0.0000
[2019-03-26 18:34:04,228] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2220941: loss 1.3635
[2019-03-26 18:34:04,231] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2220942: learning rate 0.0000
[2019-03-26 18:34:04,517] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2221069: loss 0.0027
[2019-03-26 18:34:04,520] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2221070: learning rate 0.0000
[2019-03-26 18:34:04,836] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2221213: loss 0.0986
[2019-03-26 18:34:04,840] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2221213: learning rate 0.0000
[2019-03-26 18:34:05,670] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2221594: loss 0.0074
[2019-03-26 18:34:05,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2221594: learning rate 0.0000
[2019-03-26 18:34:05,780] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2221641: loss 0.0230
[2019-03-26 18:34:05,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2221642: learning rate 0.0000
[2019-03-26 18:34:06,872] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2222125: loss 47.1095
[2019-03-26 18:34:06,879] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2222126: learning rate 0.0000
[2019-03-26 18:34:07,746] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2222516: loss 0.0255
[2019-03-26 18:34:07,748] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2222516: learning rate 0.0000
[2019-03-26 18:34:09,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3604794e-25 1.0000000e+00 2.6561233e-30 6.1448497e-27 4.2952132e-36], sum to 1.0000
[2019-03-26 18:34:09,210] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5364
[2019-03-26 18:34:09,215] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 71.0, 1.0, 2.0, 0.5411115003201044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756139.6966558154, 756139.696655816, 190290.6057521942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3691800.0000, 
sim time next is 3692400.0000, 
raw observation next is [30.66666666666667, 72.33333333333334, 1.0, 2.0, 0.5447880578704027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 761279.0945649787, 761279.0945649781, 190912.9572911795], 
processed observation next is [1.0, 0.7391304347826086, 0.6524486571879939, 0.7233333333333334, 1.0, 1.0, 0.45155187695229243, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21146641515693854, 0.21146641515693837, 0.28494471237489477], 
reward next is 0.7151, 
noisyNet noise sample is [array([0.70202863], dtype=float32), -0.21695733]. 
=============================================
[2019-03-26 18:34:11,577] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2224213: loss 0.0358
[2019-03-26 18:34:11,582] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2224214: learning rate 0.0000
[2019-03-26 18:34:11,711] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.9574866e-32 1.0000000e+00 1.3956876e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:34:11,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6480
[2019-03-26 18:34:11,722] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 55.0, 1.0, 2.0, 0.5509185386961493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769848.8458138314, 769848.8458138308, 191958.6947708266], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3865200.0000, 
sim time next is 3865800.0000, 
raw observation next is [33.33333333333333, 55.5, 1.0, 2.0, 0.5448953182429783, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 761429.0324075156, 761429.0324075156, 190929.3690719922], 
processed observation next is [0.0, 0.7391304347826086, 0.7788309636650866, 0.555, 1.0, 1.0, 0.45168110631684133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2115080645576432, 0.2115080645576432, 0.2849692075701376], 
reward next is 0.7150, 
noisyNet noise sample is [array([-2.0228715], dtype=float32), 0.6367701]. 
=============================================
[2019-03-26 18:34:12,911] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224798: loss 0.0416
[2019-03-26 18:34:12,915] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224799: learning rate 0.0000
[2019-03-26 18:34:13,363] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 18:34:13,366] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:34:13,367] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:34:13,367] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:34:13,368] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:34:13,368] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:34:13,369] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:34:13,369] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:34:13,368] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:34:13,371] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:34:13,371] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:34:13,400] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run90
[2019-03-26 18:34:13,428] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run90
[2019-03-26 18:34:13,429] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run90
[2019-03-26 18:34:13,452] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run90
[2019-03-26 18:34:13,483] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run90
[2019-03-26 18:34:20,964] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:34:20,965] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [19.96666666666667, 90.16666666666667, 1.0, 2.0, 0.2690469771433097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 438241.3048539091, 438241.3048539085, 162777.789782113]
[2019-03-26 18:34:20,967] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:34:20,970] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.1717484e-31 1.0000000e+00 7.1473482e-34 2.1715805e-38 0.0000000e+00], sampled 0.3643817950712537
[2019-03-26 18:34:23,075] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:34:23,077] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.46666666666667, 53.16666666666667, 1.0, 2.0, 0.5092953860376532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817548.1902767449, 817548.1902767449, 196734.7291062642]
[2019-03-26 18:34:23,078] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:34:23,082] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.5936758e-31 1.0000000e+00 2.2483535e-33 1.2915165e-38 0.0000000e+00], sampled 0.8248094992072078
[2019-03-26 18:34:43,722] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:34:43,724] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.93329819666667, 96.64019314333333, 1.0, 2.0, 0.427228749510383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 630277.3796717592, 630277.3796717586, 177210.9500813114]
[2019-03-26 18:34:43,725] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:34:43,726] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0023138e-35 1.0000000e+00 6.9114148e-37 0.0000000e+00 0.0000000e+00], sampled 0.6358902668770146
[2019-03-26 18:34:49,415] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:34:49,416] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.4, 65.0, 1.0, 2.0, 0.55414718820447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774362.1775313123, 774362.1775313123, 192516.7319890026]
[2019-03-26 18:34:49,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:34:49,422] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3512132e-31 1.0000000e+00 4.8484189e-35 1.8868683e-37 0.0000000e+00], sampled 0.31223188686933756
[2019-03-26 18:35:22,123] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:35:22,124] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.0, 46.0, 1.0, 2.0, 0.5065745878326713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707862.34197224, 707862.3419722406, 184631.8870074681]
[2019-03-26 18:35:22,128] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:35:22,131] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6443112e-31 1.0000000e+00 2.2390146e-34 1.2723820e-37 0.0000000e+00], sampled 0.8303139008550124
[2019-03-26 18:35:41,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02505238], dtype=float32), 0.12288315]
[2019-03-26 18:35:41,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.46666666666667, 91.33333333333334, 1.0, 2.0, 0.6503151431811222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 908804.2321318315, 908804.2321318315, 210488.6914154046]
[2019-03-26 18:35:41,098] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:35:41,102] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7051418e-31 1.0000000e+00 1.0995956e-33 0.0000000e+00 0.0000000e+00], sampled 0.4552345576903194
[2019-03-26 18:36:08,520] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 18:36:09,424] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2115 2927419164.9367 1338.0000
[2019-03-26 18:36:09,576] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.2751 3164160213.6479 1775.0000
[2019-03-26 18:36:09,624] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 18:36:09,645] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 18:36:10,665] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 2225000, evaluation results [2225000.0, 7884.275098527334, 3164160213.6479063, 1775.0, 8254.211531981859, 2927419164.936749, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 18:36:11,608] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2225419: loss 0.0220
[2019-03-26 18:36:11,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2225419: learning rate 0.0000
[2019-03-26 18:36:13,049] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2226054: loss 0.0046
[2019-03-26 18:36:13,054] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2226054: learning rate 0.0000
[2019-03-26 18:36:15,576] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2227177: loss 0.0325
[2019-03-26 18:36:15,580] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2227177: learning rate 0.0000
[2019-03-26 18:36:16,664] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2227659: loss 47.6607
[2019-03-26 18:36:16,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2227659: learning rate 0.0000
[2019-03-26 18:36:17,370] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2227969: loss 54.2090
[2019-03-26 18:36:17,375] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2227969: learning rate 0.0000
[2019-03-26 18:36:18,489] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2228466: loss 0.0249
[2019-03-26 18:36:18,491] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2228466: learning rate 0.0000
[2019-03-26 18:36:18,832] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2228621: loss 0.0254
[2019-03-26 18:36:18,838] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2228621: learning rate 0.0000
[2019-03-26 18:36:19,418] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.9101828e-20 1.0000000e+00 4.2481146e-24 2.0347437e-21 4.0445639e-29], sum to 1.0000
[2019-03-26 18:36:19,432] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4683
[2019-03-26 18:36:19,437] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.099002070566851, 6.9112, 168.9117969943893, 1587078.509918046, 1453846.171999448, 311352.5923403744], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4246200.0000, 
sim time next is 4246800.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.422537518088347, 6.9112, 168.9098553374627, 1816757.164379603, 1454003.390302139, 311352.6397782], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.05113375180883466, 0.0, 0.8294247169733051, 0.504654767883223, 0.4038898306394831, 0.46470543250477614], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.16558781], dtype=float32), -0.5118911]. 
=============================================
[2019-03-26 18:36:19,529] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2228924: loss 0.0236
[2019-03-26 18:36:19,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2228926: learning rate 0.0000
[2019-03-26 18:36:19,594] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2228955: loss 0.0266
[2019-03-26 18:36:19,598] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2228957: learning rate 0.0000
[2019-03-26 18:36:20,281] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2229258: loss 0.0253
[2019-03-26 18:36:20,285] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2229258: learning rate 0.0000
[2019-03-26 18:36:20,877] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2229522: loss 0.0415
[2019-03-26 18:36:20,880] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2229523: learning rate 0.0000
[2019-03-26 18:36:21,500] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2229791: loss 42.3145
[2019-03-26 18:36:21,504] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2229793: learning rate 0.0000
[2019-03-26 18:36:22,430] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2230205: loss 0.0129
[2019-03-26 18:36:22,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2230205: learning rate 0.0000
[2019-03-26 18:36:23,702] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2230752: loss 56.3285
[2019-03-26 18:36:23,705] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2230753: learning rate 0.0000
[2019-03-26 18:36:24,698] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0551164e-22 1.0000000e+00 1.1495900e-28 5.3605698e-21 1.8727026e-33], sum to 1.0000
[2019-03-26 18:36:24,705] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8035
[2019-03-26 18:36:24,710] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.66666666666667, 68.33333333333334, 1.0, 2.0, 0.6158849449608891, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564927939, 860669.126569043, 860669.126569043, 203745.3224239536], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4123200.0000, 
sim time next is 4123800.0000, 
raw observation next is [33.5, 69.0, 1.0, 2.0, 0.6105962847065015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104266, 853275.5134580921, 853275.5134580921, 202739.568083241], 
processed observation next is [1.0, 0.7391304347826086, 0.7867298578199052, 0.69, 1.0, 1.0, 0.5308388972367488, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.829439945152281, 0.23702097596058114, 0.23702097596058114, 0.302596370273494], 
reward next is 0.6974, 
noisyNet noise sample is [array([1.3902603], dtype=float32), 1.2310052]. 
=============================================
[2019-03-26 18:36:25,884] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4139156e-08 7.8720140e-01 7.2674649e-16 2.1279861e-01 2.5179742e-18], sum to 1.0000
[2019-03-26 18:36:25,896] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6302
[2019-03-26 18:36:25,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3319389.995703626 W.
[2019-03-26 18:36:25,910] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 52.33333333333334, 1.0, 2.0, 0.9406731925862595, 1.0, 2.0, 0.7909266358073923, 1.0, 2.0, 1.03, 7.005116716691871, 6.9112, 170.5573041426782, 3319389.995703626, 3252113.631249458, 608133.7376275321], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4283400.0000, 
sim time next is 4284000.0000, 
raw observation next is [38.0, 52.0, 1.0, 2.0, 1.002267124459197, 1.0, 2.0, 0.8217236017438613, 1.0, 2.0, 1.03, 7.005121577750882, 6.9112, 170.5573041426782, 3448818.334086964, 3381538.487458492, 633823.9737910104], 
processed observation next is [1.0, 0.6086956521739131, 1.0, 0.52, 1.0, 1.0, 1.0027314752520446, 1.0, 1.0, 0.7852091587275437, 1.0, 1.0, 1.0365853658536586, 0.009392157775088172, 0.0, 0.8375144448122397, 0.9580050928019345, 0.9393162465162478, 0.9460059310313589], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0912966], dtype=float32), -1.3981184]. 
=============================================
[2019-03-26 18:36:25,927] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[40.52547 ]
 [38.51125 ]
 [37.21074 ]
 [38.323284]
 [43.829174]], R is [[40.18632889]
 [39.78446579]
 [39.38662338]
 [38.99275589]
 [38.60282898]].
[2019-03-26 18:36:27,324] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2232349: loss 57.2500
[2019-03-26 18:36:27,325] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2232349: learning rate 0.0000
[2019-03-26 18:36:27,937] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.258481e-35 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:36:27,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2873
[2019-03-26 18:36:27,959] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 73.66666666666667, 1.0, 2.0, 0.5728741468199305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800540.9861039179, 800540.9861039174, 195802.5889659582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4394400.0000, 
sim time next is 4395000.0000, 
raw observation next is [31.0, 76.33333333333334, 1.0, 2.0, 0.5887426322615759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822724.3800377763, 822724.3800377763, 198668.8642275119], 
processed observation next is [1.0, 0.8695652173913043, 0.6682464454976303, 0.7633333333333334, 1.0, 1.0, 0.5045091954958745, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22853455001049341, 0.22853455001049341, 0.29652069287688343], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.00101361], dtype=float32), 0.095720336]. 
=============================================
[2019-03-26 18:36:27,974] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.71964]
 [67.88783]
 [67.77882]
 [67.64294]
 [67.4289 ]], R is [[67.72564697]
 [67.75614929]
 [67.79053497]
 [67.82820892]
 [67.86814117]].
[2019-03-26 18:36:28,637] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232929: loss 49.4895
[2019-03-26 18:36:28,644] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232933: learning rate 0.0000
[2019-03-26 18:36:29,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8950409e-31 1.0000000e+00 5.8703930e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:36:29,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2597
[2019-03-26 18:36:29,465] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5799068443955615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 810372.3083294906, 810372.3083294906, 197062.4012206825], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4138200.0000, 
sim time next is 4138800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5804033018767291, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811066.331867296, 811066.331867296, 197151.9409428816], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.84, 1.0, 1.0, 0.494461809490035, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22529620329647113, 0.22529620329647113, 0.2942566282729576], 
reward next is 0.7057, 
noisyNet noise sample is [array([0.5965512], dtype=float32), -1.9152421]. 
=============================================
[2019-03-26 18:36:29,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2973031e-19 1.0000000e+00 2.7259549e-23 5.5800037e-21 2.6557209e-28], sum to 1.0000
[2019-03-26 18:36:29,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8176
[2019-03-26 18:36:29,616] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2176614.887170687 W.
[2019-03-26 18:36:29,624] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666666, 79.83333333333334, 1.0, 2.0, 0.7783057437052899, 1.0, 2.0, 0.7783057437052899, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2176614.887170687, 2176614.887170687, 409453.4977214306], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4092600.0000, 
sim time next is 4093200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5111949835824866, 1.0, 2.0, 0.5111949835824866, 1.0, 1.0, 0.8877766317184004, 6.9112, 6.9112, 170.5573041426782, 2144384.577053608, 2144384.577053608, 422974.5430177957], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.79, 1.0, 1.0, 0.4110782934728754, 1.0, 1.0, 0.4110782934728754, 1.0, 0.5, 0.8631422338029273, 0.0, 0.0, 0.8375144448122397, 0.5956623825148911, 0.5956623825148911, 0.6313052880862623], 
reward next is 0.3687, 
noisyNet noise sample is [array([-0.84651077], dtype=float32), 0.055724256]. 
=============================================
[2019-03-26 18:36:29,954] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2233514: loss 62.9543
[2019-03-26 18:36:29,959] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2233514: learning rate 0.0000
[2019-03-26 18:36:31,415] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2234154: loss -140.2203
[2019-03-26 18:36:31,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2234154: learning rate 0.0000
[2019-03-26 18:36:31,883] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.315533e-31 1.000000e+00 6.881664e-36 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:36:31,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3634
[2019-03-26 18:36:31,894] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6184073565569635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864195.5076228321, 864195.5076228321, 204226.0443763449], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4129200.0000, 
sim time next is 4129800.0000, 
raw observation next is [31.0, 78.33333333333334, 1.0, 2.0, 0.6175177135275672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862951.7678225458, 862951.7678225458, 204055.3345715984], 
processed observation next is [1.0, 0.8260869565217391, 0.6682464454976303, 0.7833333333333334, 1.0, 1.0, 0.5391779681055027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23970882439515162, 0.23970882439515162, 0.3045602008531319], 
reward next is 0.6954, 
noisyNet noise sample is [array([-1.1389679], dtype=float32), 1.6878498]. 
=============================================
[2019-03-26 18:36:33,986] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2235295: loss 49.7764
[2019-03-26 18:36:33,988] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2235296: learning rate 0.0000
[2019-03-26 18:36:34,579] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2235558: loss 0.0055
[2019-03-26 18:36:34,582] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2235559: learning rate 0.0000
[2019-03-26 18:36:35,236] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2235846: loss 0.0078
[2019-03-26 18:36:35,239] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2235847: learning rate 0.0000
[2019-03-26 18:36:36,612] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2236456: loss 50.7140
[2019-03-26 18:36:36,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2236457: learning rate 0.0000
[2019-03-26 18:36:36,872] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2236569: loss 60.0671
[2019-03-26 18:36:36,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2236569: learning rate 0.0000
[2019-03-26 18:36:37,715] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2236941: loss 42.2308
[2019-03-26 18:36:37,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2236942: learning rate 0.0000
[2019-03-26 18:36:37,809] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2236979: loss 54.5213
[2019-03-26 18:36:37,811] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2236979: learning rate 0.0000
[2019-03-26 18:36:38,567] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2237305: loss 38.6130
[2019-03-26 18:36:38,570] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2237306: learning rate 0.0000
[2019-03-26 18:36:38,765] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1490101e-30 1.0000000e+00 2.5457254e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:36:38,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3929
[2019-03-26 18:36:38,777] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.5988962928921273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836918.9616015643, 836918.9616015643, 200540.7644253055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4229400.0000, 
sim time next is 4230000.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.5977174704536253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835270.9854980216, 835270.9854980216, 200321.6919845118], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5153222535585847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23201971819389489, 0.23201971819389489, 0.2989875999768833], 
reward next is 0.7010, 
noisyNet noise sample is [array([-0.30252308], dtype=float32), -0.18227369]. 
=============================================
[2019-03-26 18:36:38,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[69.94223]
 [69.89403]
 [69.83157]
 [69.7831 ]
 [69.75531]], R is [[70.06614685]
 [70.06616974]
 [70.06578064]
 [70.06488037]
 [70.06345367]].
[2019-03-26 18:36:39,221] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2237587: loss 45.0742
[2019-03-26 18:36:39,226] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2237587: learning rate 0.0000
[2019-03-26 18:36:39,338] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2237642: loss 0.0055
[2019-03-26 18:36:39,342] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2237642: learning rate 0.0000
[2019-03-26 18:36:40,642] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2238220: loss -226.7909
[2019-03-26 18:36:40,645] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2238220: learning rate 0.0000
[2019-03-26 18:36:41,494] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2238596: loss 0.0087
[2019-03-26 18:36:41,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2238597: learning rate 0.0000
[2019-03-26 18:36:45,255] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2240264: loss 0.0067
[2019-03-26 18:36:45,260] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2240265: learning rate 0.0000
[2019-03-26 18:36:45,337] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.5680940e-35 1.0000000e+00 7.5469586e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:36:45,346] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7964
[2019-03-26 18:36:45,351] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 63.0, 1.0, 2.0, 0.5300957246783313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740741.078191181, 740741.0781911802, 188445.7701651514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4391400.0000, 
sim time next is 4392000.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5247837973173619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 733315.7759126496, 733315.7759126503, 187570.242284233], 
processed observation next is [1.0, 0.8695652173913043, 0.6682464454976303, 0.63, 1.0, 1.0, 0.42745035821368904, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20369882664240266, 0.20369882664240285, 0.27995558549885524], 
reward next is 0.7200, 
noisyNet noise sample is [array([0.19413233], dtype=float32), 0.09667655]. 
=============================================
[2019-03-26 18:36:45,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[69.86949 ]
 [69.39775 ]
 [69.23818 ]
 [68.92232 ]
 [68.689964]], R is [[70.32175446]
 [70.33727264]
 [70.35151672]
 [70.36471558]
 [70.37678528]].
[2019-03-26 18:36:46,639] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240874: loss 0.0054
[2019-03-26 18:36:46,645] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240878: learning rate 0.0000
[2019-03-26 18:36:47,834] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2241407: loss 0.0054
[2019-03-26 18:36:47,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2241409: learning rate 0.0000
[2019-03-26 18:36:48,973] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.8216906e-34 1.0000000e+00 9.6419702e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:36:48,985] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2176
[2019-03-26 18:36:48,990] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 77.33333333333333, 1.0, 2.0, 0.6295088546874651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879715.759654855, 879715.759654855, 206364.6282519365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.6447217940894097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 900984.307387953, 900984.307387953, 209365.1597014838], 
processed observation next is [1.0, 0.30434782608695654, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.5719539687824212, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2502734187188758, 0.2502734187188758, 0.31248531298728927], 
reward next is 0.6875, 
noisyNet noise sample is [array([1.092747], dtype=float32), -0.27629328]. 
=============================================
[2019-03-26 18:36:49,003] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[64.43301 ]
 [64.52991 ]
 [64.32264 ]
 [63.782825]
 [62.664764]], R is [[64.25467682]
 [64.30412292]
 [64.35855865]
 [64.41461945]
 [64.46628571]].
[2019-03-26 18:36:49,073] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2241955: loss 0.0804
[2019-03-26 18:36:49,074] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2241955: learning rate 0.0000
[2019-03-26 18:36:49,728] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2159614e-35 1.0000000e+00 1.0370074e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:36:49,740] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7892
[2019-03-26 18:36:49,747] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 51.0, 1.0, 2.0, 0.5252597767891714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733981.1239060323, 733981.1239060316, 187649.1260269228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4544400.0000, 
sim time next is 4545000.0000, 
raw observation next is [34.0, 51.5, 1.0, 2.0, 0.5282437871637812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738152.332860504, 738152.332860504, 188140.407343605], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.515, 1.0, 1.0, 0.4316190206792544, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20504231468347334, 0.20504231468347334, 0.2808065781247836], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.01723371], dtype=float32), 0.0354867]. 
=============================================
[2019-03-26 18:36:49,758] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.77297]
 [73.61367]
 [73.7093 ]
 [73.48717]
 [73.36799]], R is [[73.83096313]
 [73.81257629]
 [73.79029083]
 [73.77242279]
 [73.75320435]].
[2019-03-26 18:36:52,238] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2243354: loss 0.0083
[2019-03-26 18:36:52,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2243354: learning rate 0.0000
[2019-03-26 18:36:52,807] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2243608: loss -121.4459
[2019-03-26 18:36:52,809] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2243608: learning rate 0.0000
[2019-03-26 18:36:53,508] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2243907: loss -142.3777
[2019-03-26 18:36:53,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2243907: learning rate 0.0000
[2019-03-26 18:36:54,780] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2244469: loss 0.0107
[2019-03-26 18:36:54,788] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2244474: learning rate 0.0000
[2019-03-26 18:36:54,967] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2244554: loss 0.0098
[2019-03-26 18:36:54,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2244555: learning rate 0.0000
[2019-03-26 18:36:55,945] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2244988: loss 0.0105
[2019-03-26 18:36:55,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2244988: learning rate 0.0000
[2019-03-26 18:36:56,098] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2245054: loss 0.0131
[2019-03-26 18:36:56,101] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2245054: learning rate 0.0000
[2019-03-26 18:36:56,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2245307: loss 0.0064
[2019-03-26 18:36:56,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2245307: learning rate 0.0000
[2019-03-26 18:36:57,351] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2245610: loss 0.0158
[2019-03-26 18:36:57,353] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2245610: learning rate 0.0000
[2019-03-26 18:36:57,683] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2245755: loss -240.7357
[2019-03-26 18:36:57,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2245756: learning rate 0.0000
[2019-03-26 18:36:58,576] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2246150: loss 0.0905
[2019-03-26 18:36:58,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2246150: learning rate 0.0000
[2019-03-26 18:36:59,758] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2246672: loss -118.0464
[2019-03-26 18:36:59,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2246673: learning rate 0.0000
[2019-03-26 18:37:00,590] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.0705898e-27 1.0000000e+00 1.4672264e-29 6.8393493e-35 7.1993016e-37], sum to 1.0000
[2019-03-26 18:37:00,604] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3873
[2019-03-26 18:37:00,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5417827096919977, 1.0, 2.0, 0.5417827096919977, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1514685.498569606, 1514685.498569606, 313759.3328913067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4606800.0000, 
sim time next is 4607400.0000, 
raw observation next is [29.83333333333333, 84.83333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.136555650542752, 6.9112, 168.9115927618169, 1613738.182714873, 1453864.418856456, 311356.3845316944], 
processed observation next is [1.0, 0.30434782608695654, 0.6129541864139019, 0.8483333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.022535565054275165, 0.0, 0.8294332485222806, 0.44826060630968695, 0.40385122746012664, 0.4647110216890961], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.79072416], dtype=float32), -0.073156044]. 
=============================================
[2019-03-26 18:37:01,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7241292e-33 1.0000000e+00 1.8374544e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:37:01,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3524
[2019-03-26 18:37:01,418] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 77.33333333333333, 1.0, 2.0, 0.6295088546874651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879715.759654855, 879715.759654855, 206364.6282519365], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4952400.0000, 
sim time next is 4953000.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.6447217940894097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 900984.307387953, 900984.307387953, 209365.1597014838], 
processed observation next is [1.0, 0.30434782608695654, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.5719539687824212, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2502734187188758, 0.2502734187188758, 0.31248531298728927], 
reward next is 0.6875, 
noisyNet noise sample is [array([-0.6703115], dtype=float32), -2.054597]. 
=============================================
[2019-03-26 18:37:01,434] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.7386  ]
 [65.83775 ]
 [65.63654 ]
 [65.104836]
 [63.988598]], R is [[65.54081726]
 [65.57740021]
 [65.61910248]
 [65.66255951]
 [65.70175171]].
[2019-03-26 18:37:03,762] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2248433: loss 56.9730
[2019-03-26 18:37:03,764] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2248433: learning rate 0.0000
[2019-03-26 18:37:04,966] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248970: loss 84.1424
[2019-03-26 18:37:04,968] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248970: learning rate 0.0000
[2019-03-26 18:37:06,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2249544: loss 70.6169
[2019-03-26 18:37:06,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2249544: learning rate 0.0000
[2019-03-26 18:37:06,596] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6802845e-13 1.0000000e+00 4.1710952e-19 2.7611022e-09 2.2366136e-21], sum to 1.0000
[2019-03-26 18:37:06,603] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3262
[2019-03-26 18:37:06,610] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2501083.586516507 W.
[2019-03-26 18:37:06,615] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.66666666666666, 71.66666666666667, 1.0, 2.0, 0.596139937082101, 1.0, 2.0, 0.596139937082101, 1.0, 1.0, 1.03, 6.917155630385929, 6.9112, 170.5573041426782, 2501083.586516507, 2496817.326211511, 486582.4556932228], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4704000.0000, 
sim time next is 4704600.0000, 
raw observation next is [30.83333333333334, 70.83333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.983747330865868, 6.9112, 168.9069755407155, 3045254.907219844, 2284379.858940397, 473566.3409522126], 
processed observation next is [1.0, 0.43478260869565216, 0.6603475513428123, 0.7083333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.10725473308658681, 0.0, 0.8294105758528998, 0.8459041408944011, 0.634549960816777, 0.7068154342570336], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5273347], dtype=float32), -0.27859488]. 
=============================================
[2019-03-26 18:37:07,301] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 18:37:07,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:37:07,302] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:37:07,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:37:07,305] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:37:07,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:37:07,306] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:37:07,306] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:37:07,310] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:37:07,307] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:37:07,311] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:37:07,335] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run91
[2019-03-26 18:37:07,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run91
[2019-03-26 18:37:07,399] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run91
[2019-03-26 18:37:07,427] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run91
[2019-03-26 18:37:07,447] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run91
[2019-03-26 18:37:21,875] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:37:21,877] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.5, 88.33333333333333, 1.0, 2.0, 0.3383860009893634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524331.8892428037, 524331.8892428043, 168640.3182976949]
[2019-03-26 18:37:21,878] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:37:21,882] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0189421e-33 1.0000000e+00 5.5339195e-36 0.0000000e+00 0.0000000e+00], sampled 0.8120995084111152
[2019-03-26 18:37:27,268] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:37:27,269] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.32925133, 77.58645411, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.400489865745826, 6.9112, 168.9101205614257, 1801105.917529726, 1453992.674636759, 311352.049663619]
[2019-03-26 18:37:27,271] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:37:27,274] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5507005e-23 1.0000000e+00 6.8414910e-27 1.3031594e-26 1.8846071e-32], sampled 0.4688531034459028
[2019-03-26 18:37:27,275] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1801105.917529726 W.
[2019-03-26 18:37:38,170] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:37:38,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.44467799833333, 91.65834741833334, 1.0, 2.0, 0.4164871087322122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 617799.688581696, 617799.688581696, 176099.8529772397]
[2019-03-26 18:37:38,174] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:37:38,177] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0874119e-35 1.0000000e+00 3.0258998e-37 0.0000000e+00 0.0000000e+00], sampled 0.16027393449605243
[2019-03-26 18:37:41,372] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:37:41,373] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.1, 92.0, 1.0, 2.0, 0.3914010634589919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 587064.0676119039, 587064.0676119033, 173440.4836227728]
[2019-03-26 18:37:41,374] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:37:41,379] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.59006619e-30 1.00000000e+00 1.05013835e-33 6.77496643e-38
 0.00000000e+00], sampled 0.20146630707513913
[2019-03-26 18:38:01,996] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:38:01,997] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.58333333333334, 45.66666666666666, 1.0, 2.0, 0.7908775160625644, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988671250349641, 6.9112, 168.9124334417222, 2002306.227445089, 1947345.6262881, 406241.4413036318]
[2019-03-26 18:38:01,999] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:38:02,002] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6325727e-20 1.0000000e+00 1.3384313e-26 2.9833266e-18 9.6886772e-30], sampled 0.9067313129049251
[2019-03-26 18:38:02,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2002306.227445089 W.
[2019-03-26 18:38:16,323] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:38:16,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 74.0, 1.0, 2.0, 0.5173717296712005, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722954.869546444, 722954.8695464433, 186363.1535348479]
[2019-03-26 18:38:16,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:38:16,329] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.258090e-31 1.000000e+00 9.675468e-35 0.000000e+00 0.000000e+00], sampled 0.10984300210537656
[2019-03-26 18:38:56,706] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:38:56,706] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.98195047, 64.02019641, 1.0, 2.0, 0.3399568591007482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536415.581327479, 536415.581327479, 169824.2314865861]
[2019-03-26 18:38:56,708] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:38:56,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.49255250e-34 1.00000000e+00 1.04210365e-36 0.00000000e+00
 0.00000000e+00], sampled 0.24404481369516373
[2019-03-26 18:39:03,079] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02261222], dtype=float32), 0.12271164]
[2019-03-26 18:39:03,081] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.67783477333333, 65.11338505, 1.0, 2.0, 0.6180188203617786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 910003.0511495487, 910003.0511495481, 210052.0628253363]
[2019-03-26 18:39:03,085] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:39:03,086] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0768487e-31 1.0000000e+00 2.3465746e-34 0.0000000e+00 0.0000000e+00], sampled 0.3203885336894293
[2019-03-26 18:39:03,353] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1931 3164058217.0206 1776.0000
[2019-03-26 18:39:03,353] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 18:39:03,408] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 18:39:03,458] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 18:39:03,637] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 18:39:04,656] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2250000, evaluation results [2250000.0, 7884.193114182361, 3164058217.0205803, 1776.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 18:39:04,704] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2250021: loss -222.7260
[2019-03-26 18:39:04,709] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2250021: learning rate 0.0000
[2019-03-26 18:39:07,076] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.3064539e-19 1.0000000e+00 1.4220346e-23 5.8080052e-19 4.6402143e-28], sum to 1.0000
[2019-03-26 18:39:07,086] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-26 18:39:07,091] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.95, 92.5, 1.0, 2.0, 0.5836784465040682, 1.0, 2.0, 0.5836784465040682, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1631904.407911684, 1631904.407911684, 328311.5463162246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5452200.0000, 
sim time next is 5452800.0000, 
raw observation next is [27.93333333333333, 92.33333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.399918476859602, 6.9112, 168.9101704534783, 1800700.385843585, 1453992.396677082, 311354.3369471883], 
processed observation next is [1.0, 0.08695652173913043, 0.522906793048973, 0.9233333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0488718476859602, 0.0, 0.8294262643372025, 0.500194551623218, 0.403886776854745, 0.46470796559281835], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9299321], dtype=float32), 0.17511812]. 
=============================================
[2019-03-26 18:39:07,431] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.5320555e-08 9.5194554e-01 1.6234527e-14 4.8054472e-02 4.3650605e-17], sum to 1.0000
[2019-03-26 18:39:07,441] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3035
[2019-03-26 18:39:07,455] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2699558.418211444 W.
[2019-03-26 18:39:07,458] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.4, 55.5, 1.0, 2.0, 0.6456117012172018, 1.0, 2.0, 0.6433958901228635, 1.0, 1.0, 1.03, 7.005093444081144, 6.9112, 170.5573041426782, 2699558.418211444, 2632298.724875009, 504700.1075690007], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5308200.0000, 
sim time next is 5308800.0000, 
raw observation next is [35.73333333333333, 54.0, 1.0, 2.0, 1.000680362571817, 1.0, 2.0, 1.000680362571817, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2799212.498470158, 2799212.498470158, 529402.2226960723], 
processed observation next is [1.0, 0.43478260869565216, 0.8925750394944705, 0.54, 1.0, 1.0, 1.0008197139419481, 1.0, 1.0, 1.0008197139419481, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7775590273528217, 0.7775590273528217, 0.7901525711881676], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1044141], dtype=float32), -0.3299195]. 
=============================================
[2019-03-26 18:39:07,583] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2251313: loss -43.0096
[2019-03-26 18:39:07,586] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2251314: learning rate 0.0000
[2019-03-26 18:39:08,053] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2251516: loss 0.1034
[2019-03-26 18:39:08,054] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2251516: learning rate 0.0000
[2019-03-26 18:39:08,696] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2251810: loss 0.1177
[2019-03-26 18:39:08,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2251810: learning rate 0.0000
[2019-03-26 18:39:10,271] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2252502: loss 78.9884
[2019-03-26 18:39:10,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2252505: learning rate 0.0000
[2019-03-26 18:39:10,533] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2252618: loss -44.0640
[2019-03-26 18:39:10,535] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2252618: learning rate 0.0000
[2019-03-26 18:39:11,403] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2253000: loss -111.4767
[2019-03-26 18:39:11,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2253000: learning rate 0.0000
[2019-03-26 18:39:11,543] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2253063: loss 35.5746
[2019-03-26 18:39:11,548] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2253064: learning rate 0.0000
[2019-03-26 18:39:11,650] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.390050e-28 1.000000e+00 5.024498e-32 3.170649e-34 0.000000e+00], sum to 1.0000
[2019-03-26 18:39:11,657] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2431
[2019-03-26 18:39:11,660] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333334, 87.5, 1.0, 2.0, 0.5495289017941459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767906.2771858142, 767906.2771858149, 191719.8930627896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5526600.0000, 
sim time next is 5527200.0000, 
raw observation next is [27.46666666666667, 88.0, 1.0, 2.0, 0.5491351243688971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767355.8177284313, 767355.817728432, 191652.4824874598], 
processed observation next is [1.0, 1.0, 0.500789889415482, 0.88, 1.0, 1.0, 0.4567893064685507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21315439381345314, 0.21315439381345333, 0.2860484813245669], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.6222916], dtype=float32), -2.5097713]. 
=============================================
[2019-03-26 18:39:12,000] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.6357588e-28 1.0000000e+00 9.4510974e-32 1.2905835e-34 1.2010553e-38], sum to 1.0000
[2019-03-26 18:39:12,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2627
[2019-03-26 18:39:12,015] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4852247618911349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678019.6274489578, 678019.6274489585, 181313.2182542439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4841400.0000, 
sim time next is 4842000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4866235312329953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679974.7968419387, 679974.7968419387, 181526.4634067646], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.79, 1.0, 1.0, 0.38147413401565694, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18888188801164965, 0.18888188801164965, 0.27093502001009645], 
reward next is 0.7291, 
noisyNet noise sample is [array([-1.2423471], dtype=float32), -0.61094314]. 
=============================================
[2019-03-26 18:39:12,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.314674]
 [68.385414]
 [68.42539 ]
 [68.470474]
 [68.75891 ]], R is [[68.34223938]
 [68.38820648]
 [68.43389893]
 [68.47906494]
 [68.52362061]].
[2019-03-26 18:39:12,184] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2253342: loss -362.9218
[2019-03-26 18:39:12,186] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2253342: learning rate 0.0000
[2019-03-26 18:39:12,675] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2253558: loss 0.0714
[2019-03-26 18:39:12,680] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2253558: learning rate 0.0000
[2019-03-26 18:39:12,982] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2253695: loss 93.8208
[2019-03-26 18:39:12,984] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2253695: learning rate 0.0000
[2019-03-26 18:39:13,992] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2254144: loss -69.6675
[2019-03-26 18:39:13,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2254144: learning rate 0.0000
[2019-03-26 18:39:14,821] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2254511: loss 0.0983
[2019-03-26 18:39:14,822] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2254512: learning rate 0.0000
[2019-03-26 18:39:17,589] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.6412077e-16 1.0000000e+00 2.3979543e-20 3.9753437e-16 8.8522727e-25], sum to 1.0000
[2019-03-26 18:39:17,599] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2458
[2019-03-26 18:39:17,607] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2711893.226016694 W.
[2019-03-26 18:39:17,611] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.65, 74.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.514255534095039, 6.9112, 168.9099903604246, 2711893.226016694, 2284072.38732336, 474776.0178673169], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5473800.0000, 
sim time next is 5474400.0000, 
raw observation next is [31.86666666666667, 73.33333333333334, 1.0, 2.0, 0.879044640331059, 1.0, 1.0, 0.879044640331059, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2458624.974092392, 2458624.974092392, 460198.4092545297], 
processed observation next is [1.0, 0.34782608695652173, 0.7093206951026858, 0.7333333333333334, 1.0, 1.0, 0.8542706510012759, 1.0, 0.5, 0.8542706510012759, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.682951381692331, 0.682951381692331, 0.6868632973948204], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9092326], dtype=float32), -0.05074178]. 
=============================================
[2019-03-26 18:39:18,861] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2256309: loss 0.1104
[2019-03-26 18:39:18,864] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2256309: learning rate 0.0000
[2019-03-26 18:39:20,162] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256884: loss 0.1218
[2019-03-26 18:39:20,165] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256885: learning rate 0.0000
[2019-03-26 18:39:21,498] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2257470: loss 0.1037
[2019-03-26 18:39:21,503] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2257473: learning rate 0.0000
[2019-03-26 18:39:22,618] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2257966: loss 1.2499
[2019-03-26 18:39:22,620] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2257966: learning rate 0.0000
[2019-03-26 18:39:24,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7312058e-07 5.9108824e-01 1.5708966e-14 4.0891156e-01 1.4141109e-16], sum to 1.0000
[2019-03-26 18:39:24,546] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5152
[2019-03-26 18:39:24,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2832216.513018818 W.
[2019-03-26 18:39:24,561] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.06666666666666, 52.5, 1.0, 2.0, 1.012465488733521, 1.0, 2.0, 1.012465488733521, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2832216.513018818, 2832216.513018818, 536568.9653328166], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5309400.0000, 
sim time next is 5310000.0000, 
raw observation next is [36.4, 51.0, 1.0, 2.0, 0.7279958570344639, 1.0, 2.0, 0.6845879680314945, 1.0, 1.0, 1.03, 7.005099939707097, 6.9112, 170.5573041426782, 2872590.721418749, 2805326.375001219, 530317.8715443924], 
processed observation next is [1.0, 0.4782608695652174, 0.924170616113744, 0.51, 1.0, 1.0, 0.6722841651017637, 1.0, 1.0, 0.6199855036524029, 1.0, 0.5, 1.0365853658536586, 0.009389993970709743, 0.0, 0.8375144448122397, 0.7979418670607636, 0.7792573263892275, 0.7915192112602872], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49672765], dtype=float32), 0.29441133]. 
=============================================
[2019-03-26 18:39:24,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[38.467487]
 [38.513973]
 [39.524952]
 [39.839645]
 [39.818295]], R is [[37.7446022 ]
 [37.56630707]
 [37.19064331]
 [36.81873703]
 [36.45055008]].
[2019-03-26 18:39:25,457] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2259221: loss 0.0972
[2019-03-26 18:39:25,460] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2259222: learning rate 0.0000
[2019-03-26 18:39:26,334] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2259607: loss -158.5856
[2019-03-26 18:39:26,343] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2259608: learning rate 0.0000
[2019-03-26 18:39:26,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4145345e-09 9.9991179e-01 3.7679726e-16 8.8149704e-05 1.0630963e-18], sum to 1.0000
[2019-03-26 18:39:26,634] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9959
[2019-03-26 18:39:26,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2698301.388213357 W.
[2019-03-26 18:39:26,643] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.06666666666666, 57.00000000000001, 1.0, 2.0, 0.645013162230693, 1.0, 2.0, 0.643096620629609, 1.0, 1.0, 1.03, 7.005093396895575, 6.9112, 170.5573041426782, 2698301.388213357, 2631041.728677865, 504523.2142489791], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5307600.0000, 
sim time next is 5308200.0000, 
raw observation next is [35.4, 55.5, 1.0, 2.0, 0.9511583878656594, 1.0, 2.0, 0.9511583878656594, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2660536.70933519, 2660536.709335189, 500177.9787479885], 
processed observation next is [1.0, 0.43478260869565216, 0.8767772511848341, 0.555, 1.0, 1.0, 0.9411546841754933, 1.0, 1.0, 0.9411546841754933, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7390379748153305, 0.7390379748153303, 0.7465342966387889], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.1411863], dtype=float32), 0.7605133]. 
=============================================
[2019-03-26 18:39:27,055] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2259914: loss -248.3795
[2019-03-26 18:39:27,058] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2259915: learning rate 0.0000
[2019-03-26 18:39:28,387] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2260506: loss 0.0954
[2019-03-26 18:39:28,389] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2260506: learning rate 0.0000
[2019-03-26 18:39:28,500] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2260554: loss 0.0799
[2019-03-26 18:39:28,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2260554: learning rate 0.0000
[2019-03-26 18:39:29,416] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2260961: loss 0.0964
[2019-03-26 18:39:29,423] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2260962: learning rate 0.0000
[2019-03-26 18:39:29,640] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2261062: loss 0.0673
[2019-03-26 18:39:29,642] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2261062: learning rate 0.0000
[2019-03-26 18:39:30,301] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2261357: loss 0.0615
[2019-03-26 18:39:30,304] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2261357: learning rate 0.0000
[2019-03-26 18:39:31,014] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2261670: loss -94.9027
[2019-03-26 18:39:31,018] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2261670: learning rate 0.0000
[2019-03-26 18:39:31,074] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2261696: loss 0.0624
[2019-03-26 18:39:31,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2261697: learning rate 0.0000
[2019-03-26 18:39:31,595] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2514879e-18 1.0000000e+00 7.4572410e-23 7.5956320e-21 6.9830267e-28], sum to 1.0000
[2019-03-26 18:39:31,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-26 18:39:31,615] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2185159.676114385 W.
[2019-03-26 18:39:31,620] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.9215205019015208, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.985181403981107, 6.9112, 168.91245413565, 2185159.676114385, 2132674.877985615, 440852.9358138613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5215800.0000, 
sim time next is 5216400.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5170721121442676, 1.0, 1.0, 0.5170721121442676, 1.0, 2.0, 0.8914248043577363, 6.911200000000001, 6.9112, 170.5573041426782, 2169063.191714759, 2169063.191714759, 425921.0988089025], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.7, 1.0, 1.0, 0.4181591712581537, 1.0, 0.5, 0.4181591712581537, 1.0, 1.0, 0.8675912248265075, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6025175532540997, 0.6025175532540997, 0.6357031325506007], 
reward next is 0.3643, 
noisyNet noise sample is [array([-0.63650525], dtype=float32), 0.27057785]. 
=============================================
[2019-03-26 18:39:31,865] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2262043: loss 1.3865
[2019-03-26 18:39:31,871] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2262045: learning rate 0.0000
[2019-03-26 18:39:33,307] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2262677: loss -101.0708
[2019-03-26 18:39:33,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2262678: learning rate 0.0000
[2019-03-26 18:39:36,263] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9464161e-10 9.9984956e-01 5.7469088e-17 1.5040023e-04 1.6123791e-19], sum to 1.0000
[2019-03-26 18:39:36,272] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0582
[2019-03-26 18:39:36,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2793728.434240665 W.
[2019-03-26 18:39:36,287] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.66666666666667, 68.0, 1.0, 2.0, 0.9987220740016562, 1.0, 2.0, 0.9987220740016562, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2793728.434240665, 2793728.434240665, 528212.594216401], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5242800.0000, 
sim time next is 5243400.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.9976530657598458, 1.0, 2.0, 0.9976530657598458, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2790734.753913577, 2790734.753913576, 527567.3688879111], 
processed observation next is [1.0, 0.6956521739130435, 0.6919431279620853, 0.685, 1.0, 1.0, 0.9971723683853564, 1.0, 1.0, 0.9971723683853564, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.775204098309327, 0.7752040983093266, 0.7874139834147926], 
reward next is 0.2126, 
noisyNet noise sample is [array([-0.9029393], dtype=float32), 0.3596678]. 
=============================================
[2019-03-26 18:39:37,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8556604e-18 1.0000000e+00 7.1542040e-24 1.5464445e-16 1.5329211e-27], sum to 1.0000
[2019-03-26 18:39:37,013] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5057
[2019-03-26 18:39:37,025] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2407393.327248302 W.
[2019-03-26 18:39:37,029] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.59999999999999, 51.5, 1.0, 2.0, 0.8607451576366019, 1.0, 2.0, 0.8607451576366019, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2407393.327248302, 2407393.327248303, 450520.9553232723], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5585400.0000, 
sim time next is 5586000.0000, 
raw observation next is [33.53333333333333, 52.0, 1.0, 2.0, 0.5756513534256269, 1.0, 2.0, 0.5756513534256269, 1.0, 1.0, 0.9916881595053612, 6.9112, 6.9112, 170.5573041426782, 2415041.40609564, 2415041.40609564, 469703.2012757686], 
processed observation next is [1.0, 0.6521739130434783, 0.7883096366508688, 0.52, 1.0, 1.0, 0.48873657039232155, 1.0, 1.0, 0.48873657039232155, 1.0, 0.5, 0.9898636091528793, 0.0, 0.0, 0.8375144448122397, 0.6708448350265667, 0.6708448350265667, 0.7010495541429381], 
reward next is 0.2990, 
noisyNet noise sample is [array([0.8601619], dtype=float32), 1.9806051]. 
=============================================
[2019-03-26 18:39:37,042] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[48.330975]
 [48.725506]
 [49.116104]
 [48.345936]
 [48.28477 ]], R is [[46.68120956]
 [46.54197693]
 [46.41193008]
 [46.30320358]
 [46.17138672]].
[2019-03-26 18:39:37,297] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2264436: loss -121.1881
[2019-03-26 18:39:37,299] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2264437: learning rate 0.0000
[2019-03-26 18:39:38,494] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264969: loss -109.5748
[2019-03-26 18:39:38,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264969: learning rate 0.0000
[2019-03-26 18:39:39,983] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2265629: loss -205.7110
[2019-03-26 18:39:39,984] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2265630: learning rate 0.0000
[2019-03-26 18:39:40,974] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2266070: loss -48.4273
[2019-03-26 18:39:40,982] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2266072: learning rate 0.0000
[2019-03-26 18:39:42,501] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.6635581e-34 1.0000000e+00 3.1649902e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:39:42,510] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2876
[2019-03-26 18:39:42,518] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.43333333333334, 60.00000000000001, 1.0, 2.0, 0.5469084769276154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 764243.2039768497, 764243.2039768504, 191272.2893454655], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5667600.0000, 
sim time next is 5668200.0000, 
raw observation next is [32.4, 60.0, 1.0, 2.0, 0.5446811968666186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761129.7150157875, 761129.7150157881, 190893.1658854079], 
processed observation next is [0.0, 0.6086956521739131, 0.7345971563981042, 0.6, 1.0, 1.0, 0.4514231287549622, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21142492083771874, 0.2114249208377189, 0.2849151729632954], 
reward next is 0.7151, 
noisyNet noise sample is [array([-1.1149999], dtype=float32), -0.2217138]. 
=============================================
[2019-03-26 18:39:43,837] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2267329: loss -155.0154
[2019-03-26 18:39:43,841] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2267330: learning rate 0.0000
[2019-03-26 18:39:44,154] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2267466: loss 1.5083
[2019-03-26 18:39:44,158] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2267466: learning rate 0.0000
[2019-03-26 18:39:44,986] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2267833: loss 1.3522
[2019-03-26 18:39:44,988] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2267833: learning rate 0.0000
[2019-03-26 18:39:46,506] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.5266825e-36 1.0000000e+00 2.4054448e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:39:46,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4608
[2019-03-26 18:39:46,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.8, 53.0, 1.0, 2.0, 0.5123013271457002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715867.3014275094, 715867.3014275087, 185545.9111822582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5752800.0000, 
sim time next is 5753400.0000, 
raw observation next is [33.0, 53.0, 1.0, 2.0, 0.5296397848215211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740103.7385129881, 740103.7385129888, 188369.5678431455], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.53, 1.0, 1.0, 0.4333009455680977, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20558437180916336, 0.20558437180916356, 0.2811486087211127], 
reward next is 0.7189, 
noisyNet noise sample is [array([1.1201397], dtype=float32), -0.78193384]. 
=============================================
[2019-03-26 18:39:46,590] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2268538: loss -379.0414
[2019-03-26 18:39:46,592] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2268538: learning rate 0.0000
[2019-03-26 18:39:46,892] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2268675: loss -172.7966
[2019-03-26 18:39:46,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2268675: learning rate 0.0000
[2019-03-26 18:39:47,673] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2268996: loss -279.4398
[2019-03-26 18:39:47,675] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2268996: learning rate 0.0000
[2019-03-26 18:39:47,740] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2269026: loss -263.7095
[2019-03-26 18:39:47,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2269026: learning rate 0.0000
[2019-03-26 18:39:48,524] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2269370: loss -219.2031
[2019-03-26 18:39:48,528] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2269371: learning rate 0.0000
[2019-03-26 18:39:48,952] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2269565: loss 1.2486
[2019-03-26 18:39:48,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2269565: learning rate 0.0000
[2019-03-26 18:39:49,193] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2269668: loss -65.2141
[2019-03-26 18:39:49,197] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2269670: learning rate 0.0000
[2019-03-26 18:39:49,762] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2269924: loss -163.3083
[2019-03-26 18:39:49,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2269924: learning rate 0.0000
[2019-03-26 18:39:51,237] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2270572: loss 1.2912
[2019-03-26 18:39:51,239] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2270572: learning rate 0.0000
[2019-03-26 18:39:55,181] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2272316: loss 1.1555
[2019-03-26 18:39:55,183] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2272316: learning rate 0.0000
[2019-03-26 18:39:56,482] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272896: loss 1.3507
[2019-03-26 18:39:56,485] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272897: learning rate 0.0000
[2019-03-26 18:39:57,926] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2273534: loss 1.3635
[2019-03-26 18:39:57,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2273534: learning rate 0.0000
[2019-03-26 18:39:58,907] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2273970: loss 0.0293
[2019-03-26 18:39:58,912] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2273970: learning rate 0.0000
[2019-03-26 18:40:00,815] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2919500e-10 9.9999714e-01 2.8139460e-17 2.8800146e-06 4.4010548e-20], sum to 1.0000
[2019-03-26 18:40:00,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0220
[2019-03-26 18:40:00,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2261196.147659548 W.
[2019-03-26 18:40:00,840] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.8, 72.33333333333333, 1.0, 2.0, 0.808520716919395, 1.0, 1.0, 0.808520716919395, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2261196.147659548, 2261196.147659548, 424038.3162212042], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6190800.0000, 
sim time next is 6191400.0000, 
raw observation next is [29.7, 72.66666666666667, 1.0, 2.0, 0.7743655981897233, 1.0, 2.0, 0.7743655981897233, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2165584.711817054, 2165584.711817054, 407582.4113177891], 
processed observation next is [1.0, 0.6521739130434783, 0.6066350710900474, 0.7266666666666667, 1.0, 1.0, 0.7281513231201485, 1.0, 1.0, 0.7281513231201485, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6015513088380706, 0.6015513088380706, 0.60833195719073], 
reward next is 0.3917, 
noisyNet noise sample is [array([0.5960341], dtype=float32), -0.39530918]. 
=============================================
[2019-03-26 18:40:01,235] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 18:40:01,236] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:40:01,236] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:40:01,237] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:40:01,238] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:40:01,239] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:40:01,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:40:01,241] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:40:01,241] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:40:01,242] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:40:01,241] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:40:01,275] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run92
[2019-03-26 18:40:01,303] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run92
[2019-03-26 18:40:01,330] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run92
[2019-03-26 18:40:01,330] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run92
[2019-03-26 18:40:01,374] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run92
[2019-03-26 18:40:08,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:40:08,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.63333333333333, 90.66666666666667, 1.0, 2.0, 0.3202215810727902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 503797.6258143983, 503797.625814399, 167256.0937469923]
[2019-03-26 18:40:08,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:40:08,921] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3161470e-37 1.0000000e+00 1.3758195e-38 0.0000000e+00 0.0000000e+00], sampled 0.6807595218662359
[2019-03-26 18:40:09,825] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:40:09,826] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.60854757666667, 72.70019518833334, 1.0, 2.0, 0.1973581739892493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 330134.0953698937, 330134.095369893, 140159.258582817]
[2019-03-26 18:40:09,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:40:09,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1982622e-33 1.0000000e+00 5.3805036e-36 0.0000000e+00 0.0000000e+00], sampled 0.21795936062740762
[2019-03-26 18:41:03,618] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:41:03,620] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.53333333333333, 59.66666666666666, 1.0, 2.0, 0.5574485635565868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778977.1925941028, 778977.1925941028, 193086.0017025201]
[2019-03-26 18:41:03,621] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:41:03,624] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.9993751e-32 1.0000000e+00 2.6719802e-35 0.0000000e+00 0.0000000e+00], sampled 0.8798765799037034
[2019-03-26 18:41:05,875] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:41:05,875] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.0, 56.0, 1.0, 2.0, 0.7419943116411651, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005977905713613, 6.9112, 168.9123160264259, 1933895.329563671, 1866656.876202345, 394038.1079432969]
[2019-03-26 18:41:05,877] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:41:05,881] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3112136e-17 1.0000000e+00 1.1826506e-24 3.3084660e-13 6.0223440e-27], sampled 0.9161970407804649
[2019-03-26 18:41:05,881] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1933895.329563671 W.
[2019-03-26 18:41:20,380] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:41:20,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.5, 72.0, 1.0, 2.0, 0.5736526673550476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801629.3102721281, 801629.3102721281, 195939.369858968]
[2019-03-26 18:41:20,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:41:20,387] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4292652e-34 1.0000000e+00 2.7696761e-37 0.0000000e+00 0.0000000e+00], sampled 0.8112125686612688
[2019-03-26 18:41:42,533] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:41:42,534] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.35, 70.16666666666667, 1.0, 2.0, 0.5291769393915986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739456.7462077115, 739456.7462077121, 188292.6879008335]
[2019-03-26 18:41:42,536] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:41:42,539] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0583223e-34 1.0000000e+00 1.2145931e-36 0.0000000e+00 0.0000000e+00], sampled 0.6639611834586197
[2019-03-26 18:41:54,359] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01943369], dtype=float32), 0.12163716]
[2019-03-26 18:41:54,360] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.2, 68.0, 1.0, 2.0, 0.3868556285345932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 586703.484745474, 586703.4847454733, 173591.2910898727]
[2019-03-26 18:41:54,361] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:41:54,365] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5814974e-35 1.0000000e+00 1.9163335e-37 0.0000000e+00 0.0000000e+00], sampled 0.9068282231063475
[2019-03-26 18:41:56,208] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 18:41:56,324] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.5266 3164046000.1525 1776.0000
[2019-03-26 18:41:56,745] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7647 3007775956.8125 1766.0000
[2019-03-26 18:41:57,032] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8717 2927447046.3306 1338.0000
[2019-03-26 18:41:57,093] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.3184 2842623991.1978 1131.0000
[2019-03-26 18:41:58,113] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2275000, evaluation results [2275000.0, 7885.526566417096, 3164046000.152481, 1776.0, 8254.871735174753, 2927447046.3306217, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.764734894051, 3007775956.812482, 1766.0, 8497.318449684271, 2842623991.1978283, 1131.0]
[2019-03-26 18:41:58,710] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2275267: loss 1.1678
[2019-03-26 18:41:58,714] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2275270: learning rate 0.0000
[2019-03-26 18:41:58,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2756916e-34 1.0000000e+00 2.3133842e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:41:58,862] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-26 18:41:58,867] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.7, 65.66666666666666, 1.0, 2.0, 0.5579837094885417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779725.2786213666, 779725.2786213666, 193179.9490393823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5658000.0000, 
sim time next is 5658600.0000, 
raw observation next is [31.75, 65.33333333333334, 1.0, 2.0, 0.5579412373779853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 779665.906399961, 779665.9063999616, 193172.5295775913], 
processed observation next is [0.0, 0.4782608695652174, 0.7037914691943128, 0.6533333333333334, 1.0, 1.0, 0.4673990811782955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21657386288887806, 0.2165738628888782, 0.28831720832476315], 
reward next is 0.7117, 
noisyNet noise sample is [array([0.28309926], dtype=float32), -0.041166663]. 
=============================================
[2019-03-26 18:41:59,236] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2275500: loss -103.0156
[2019-03-26 18:41:59,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2275501: learning rate 0.0000
[2019-03-26 18:42:00,065] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2275863: loss -90.4378
[2019-03-26 18:42:00,068] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2275864: learning rate 0.0000
[2019-03-26 18:42:01,203] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.3652954e-26 1.0000000e+00 7.6307677e-30 1.0014496e-32 9.0208279e-36], sum to 1.0000
[2019-03-26 18:42:01,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1382
[2019-03-26 18:42:01,217] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 84.33333333333334, 1.0, 2.0, 0.521590178621047, 0.0, 2.0, 0.0, 1.0, 1.0, 0.880909918004268, 6.911200000000001, 6.9112, 168.9127241827837, 1458203.616674439, 1458203.616674438, 315261.710837274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6403200.0000, 
sim time next is 6403800.0000, 
raw observation next is [26.91666666666667, 84.66666666666667, 1.0, 2.0, 0.964747707836527, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564524179, 1348497.355635101, 1348497.355635101, 288367.1482246378], 
processed observation next is [1.0, 0.08695652173913043, 0.4747235387045816, 0.8466666666666667, 1.0, 1.0, 0.9575273588391892, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399448674318, 0.37458259878752803, 0.37458259878752803, 0.4303987286934892], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4010309], dtype=float32), -0.433242]. 
=============================================
[2019-03-26 18:42:01,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2276521: loss 1.2529
[2019-03-26 18:42:01,561] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2276522: learning rate 0.0000
[2019-03-26 18:42:01,968] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2276702: loss 1.3155
[2019-03-26 18:42:01,971] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2276704: learning rate 0.0000
[2019-03-26 18:42:02,388] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.723326e-37 1.000000e+00 1.029597e-37 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:42:02,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1589
[2019-03-26 18:42:02,400] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 91.0, 1.0, 2.0, 0.5106868069915107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713610.4843042409, 713610.4843042409, 185286.9209277059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5718600.0000, 
sim time next is 5719200.0000, 
raw observation next is [25.76666666666667, 91.33333333333333, 1.0, 2.0, 0.5113428308367751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714527.4904560291, 714527.4904560298, 185391.8352907108], 
processed observation next is [0.0, 0.17391304347826086, 0.42022116903633505, 0.9133333333333333, 1.0, 1.0, 0.41125642269490975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19847985846000807, 0.19847985846000826, 0.2767042317771803], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.8049682], dtype=float32), -0.8256968]. 
=============================================
[2019-03-26 18:42:02,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2277006: loss 1.3841
[2019-03-26 18:42:02,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2277007: learning rate 0.0000
[2019-03-26 18:42:02,787] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2277067: loss 1.4269
[2019-03-26 18:42:02,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2277068: learning rate 0.0000
[2019-03-26 18:42:03,483] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2277373: loss 1.5399
[2019-03-26 18:42:03,488] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2277374: learning rate 0.0000
[2019-03-26 18:42:03,905] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2277561: loss -88.2264
[2019-03-26 18:42:03,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2277561: learning rate 0.0000
[2019-03-26 18:42:04,247] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2277708: loss 1.3752
[2019-03-26 18:42:04,253] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2277709: learning rate 0.0000
[2019-03-26 18:42:04,855] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2277977: loss 0.0156
[2019-03-26 18:42:04,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2277977: learning rate 0.0000
[2019-03-26 18:42:06,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2278685: loss -36.8534
[2019-03-26 18:42:06,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2278685: learning rate 0.0000
[2019-03-26 18:42:10,344] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2280415: loss -71.5130
[2019-03-26 18:42:10,346] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2280416: learning rate 0.0000
[2019-03-26 18:42:10,834] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6997773e-10 5.8414113e-08 3.1063252e-18 1.0000000e+00 1.1001069e-19], sum to 1.0000
[2019-03-26 18:42:10,841] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2804
[2019-03-26 18:42:10,845] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.15, 64.0, 1.0, 2.0, 1.011416902586046, 1.0, 2.0, 1.011416902586046, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2829279.932749122, 2829279.932749123, 535919.7936499857], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5848200.0000, 
sim time next is 5848800.0000, 
raw observation next is [32.1, 64.33333333333333, 1.0, 2.0, 0.9810211042877937, 1.0, 2.0, 0.9810211042877937, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2744159.071818765, 2744159.071818765, 517620.0071885476], 
processed observation next is [1.0, 0.6956521739130435, 0.7203791469194314, 0.6433333333333333, 1.0, 1.0, 0.9771338605877032, 1.0, 1.0, 0.9771338605877032, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7622664088385458, 0.7622664088385458, 0.77256717490828], 
reward next is 0.2274, 
noisyNet noise sample is [array([0.80237395], dtype=float32), -1.3858154]. 
=============================================
[2019-03-26 18:42:11,490] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280923: loss -60.4781
[2019-03-26 18:42:11,492] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280923: learning rate 0.0000
[2019-03-26 18:42:13,073] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2281618: loss -114.1311
[2019-03-26 18:42:13,077] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2281619: learning rate 0.0000
[2019-03-26 18:42:14,076] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2282062: loss 114.6206
[2019-03-26 18:42:14,079] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2282063: learning rate 0.0000
[2019-03-26 18:42:16,791] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2283262: loss -128.4156
[2019-03-26 18:42:16,795] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2283263: learning rate 0.0000
[2019-03-26 18:42:17,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5353292e-31 1.0000000e+00 2.6480446e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:42:17,159] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6602
[2019-03-26 18:42:17,163] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 91.0, 1.0, 2.0, 0.5227364245701821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730453.8602880726, 730453.8602880719, 187235.4257428593], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6230400.0000, 
sim time next is 6231000.0000, 
raw observation next is [26.48333333333333, 91.0, 1.0, 2.0, 0.5235740968312212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731624.7977381628, 731624.7977381635, 187372.411295583], 
processed observation next is [0.0, 0.08695652173913043, 0.4541864139020536, 0.91, 1.0, 1.0, 0.4259928877484593, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.203229110482823, 0.2032291104828232, 0.2796603153665418], 
reward next is 0.7203, 
noisyNet noise sample is [array([0.50472945], dtype=float32), 0.3526227]. 
=============================================
[2019-03-26 18:42:17,177] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.95797]
 [72.02742]
 [72.23935]
 [72.12776]
 [71.68215]], R is [[72.00947571]
 [72.00992584]
 [72.01048279]
 [72.01113129]
 [72.01181793]].
[2019-03-26 18:42:17,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.4950385e-28 1.0000000e+00 1.5788223e-32 9.3337535e-33 0.0000000e+00], sum to 1.0000
[2019-03-26 18:42:17,259] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2283463: loss 0.0242
[2019-03-26 18:42:17,265] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2283463: learning rate 0.0000
[2019-03-26 18:42:17,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1841
[2019-03-26 18:42:17,274] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 80.0, 1.0, 2.0, 0.5675700002850056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793126.1428223375, 793126.1428223375, 194861.2474470231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5940000.0000, 
sim time next is 5940600.0000, 
raw observation next is [29.68333333333334, 80.33333333333334, 1.0, 2.0, 0.5710748388473635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798025.667698816, 798025.667698816, 195481.9636586821], 
processed observation next is [1.0, 0.782608695652174, 0.6058451816745659, 0.8033333333333335, 1.0, 1.0, 0.48322269740646207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22167379658300446, 0.22167379658300446, 0.2917641248637046], 
reward next is 0.7082, 
noisyNet noise sample is [array([-0.3327948], dtype=float32), 2.0967085]. 
=============================================
[2019-03-26 18:42:18,018] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2283801: loss 0.0397
[2019-03-26 18:42:18,021] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2283802: learning rate 0.0000
[2019-03-26 18:42:19,766] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2284577: loss -32.9226
[2019-03-26 18:42:19,773] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2284578: learning rate 0.0000
[2019-03-26 18:42:19,833] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2284603: loss -89.3791
[2019-03-26 18:42:19,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2284604: learning rate 0.0000
[2019-03-26 18:42:20,583] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2284939: loss -62.0297
[2019-03-26 18:42:20,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2284940: learning rate 0.0000
[2019-03-26 18:42:20,599] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2284947: loss -111.7162
[2019-03-26 18:42:20,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2284947: learning rate 0.0000
[2019-03-26 18:42:21,499] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2285342: loss -29.4725
[2019-03-26 18:42:21,501] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2285342: learning rate 0.0000
[2019-03-26 18:42:21,857] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2285496: loss 0.0250
[2019-03-26 18:42:21,860] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2285497: learning rate 0.0000
[2019-03-26 18:42:22,093] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2285600: loss -33.9179
[2019-03-26 18:42:22,095] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2285600: learning rate 0.0000
[2019-03-26 18:42:22,821] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2285919: loss 109.2959
[2019-03-26 18:42:22,823] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2285919: learning rate 0.0000
[2019-03-26 18:42:24,554] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2286688: loss 0.0216
[2019-03-26 18:42:24,557] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2286688: learning rate 0.0000
[2019-03-26 18:42:28,384] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2288386: loss 0.0301
[2019-03-26 18:42:28,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2288386: learning rate 0.0000
[2019-03-26 18:42:29,623] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288940: loss 0.0080
[2019-03-26 18:42:29,627] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288941: learning rate 0.0000
[2019-03-26 18:42:30,681] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.866280e-29 1.000000e+00 1.640476e-32 8.687640e-34 0.000000e+00], sum to 1.0000
[2019-03-26 18:42:30,690] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8136
[2019-03-26 18:42:30,696] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 85.0, 1.0, 2.0, 0.5317478955359676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743050.5834638949, 743050.5834638949, 188719.5245679506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303000.0000, 
sim time next is 6303600.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5301995827677464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740886.2572201214, 740886.2572201214, 188462.7370218643], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4339754009249956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2058017381167004, 0.2058017381167004, 0.2812876671968124], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.94319844], dtype=float32), -1.3882629]. 
=============================================
[2019-03-26 18:42:31,256] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2289644: loss 0.0120
[2019-03-26 18:42:31,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2289645: learning rate 0.0000
[2019-03-26 18:42:31,544] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2289773: loss 8.4358
[2019-03-26 18:42:31,548] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2289773: learning rate 0.0000
[2019-03-26 18:42:34,965] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2291290: loss 0.0410
[2019-03-26 18:42:34,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2291291: learning rate 0.0000
[2019-03-26 18:42:35,474] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2291513: loss 91.5478
[2019-03-26 18:42:35,478] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2291514: learning rate 0.0000
[2019-03-26 18:42:35,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4931562e-34 1.0000000e+00 3.5814545e-36 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:42:35,927] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0344
[2019-03-26 18:42:35,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 86.33333333333334, 1.0, 2.0, 0.5240657996925021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732312.1235873987, 732312.1235873987, 187452.4993230246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6327600.0000, 
sim time next is 6328200.0000, 
raw observation next is [27.1, 85.66666666666667, 1.0, 2.0, 0.5237910485583507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731928.0632159087, 731928.0632159094, 187407.5278585231], 
processed observation next is [0.0, 0.21739130434782608, 0.4834123222748816, 0.8566666666666667, 1.0, 1.0, 0.42625427537150684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.203313350893308, 0.20331335089330818, 0.2797127281470494], 
reward next is 0.7203, 
noisyNet noise sample is [array([-1.222896], dtype=float32), -1.6498271]. 
=============================================
[2019-03-26 18:42:36,215] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2291838: loss 203.3392
[2019-03-26 18:42:36,217] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2291838: learning rate 0.0000
[2019-03-26 18:42:36,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3085104e-32 1.0000000e+00 1.5518670e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:42:36,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8512
[2019-03-26 18:42:36,358] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.15, 80.5, 1.0, 2.0, 0.3313289706066871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 518834.3089583835, 518834.3089583841, 168355.5775026499], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6834600.0000, 
sim time next is 6835200.0000, 
raw observation next is [23.13333333333333, 80.66666666666667, 1.0, 2.0, 0.3321118661138523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519975.3937631316, 519975.3937631322, 168442.7892429112], 
processed observation next is [0.0, 0.08695652173913043, 0.29541864139020524, 0.8066666666666668, 1.0, 1.0, 0.19531550134199072, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14443760937864766, 0.14443760937864783, 0.2514071481237481], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.0803818], dtype=float32), 0.3110737]. 
=============================================
[2019-03-26 18:42:37,764] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2292537: loss 0.0183
[2019-03-26 18:42:37,770] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2292538: learning rate 0.0000
[2019-03-26 18:42:38,047] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2292665: loss 0.0138
[2019-03-26 18:42:38,050] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2292666: learning rate 0.0000
[2019-03-26 18:42:38,733] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2292964: loss 0.0145
[2019-03-26 18:42:38,738] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2292965: learning rate 0.0000
[2019-03-26 18:42:38,983] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2293076: loss 0.0088
[2019-03-26 18:42:38,984] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2293076: learning rate 0.0000
[2019-03-26 18:42:39,826] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2293449: loss 0.0008
[2019-03-26 18:42:39,829] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2293450: learning rate 0.0000
[2019-03-26 18:42:40,187] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2293609: loss 68.6039
[2019-03-26 18:42:40,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2293609: learning rate 0.0000
[2019-03-26 18:42:40,312] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2293663: loss 0.0006
[2019-03-26 18:42:40,315] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2293663: learning rate 0.0000
[2019-03-26 18:42:40,790] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2293879: loss 8.2115
[2019-03-26 18:42:40,793] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2293879: learning rate 0.0000
[2019-03-26 18:42:42,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.0575744e-09 7.6303852e-01 6.7393419e-16 2.3696153e-01 2.2194486e-18], sum to 1.0000
[2019-03-26 18:42:42,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9777
[2019-03-26 18:42:42,103] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 61.5, 1.0, 2.0, 0.4859148964562979, 1.0, 1.0, 0.4859148964562979, 1.0, 2.0, 0.8210181833854299, 6.9112, 6.9112, 170.5573041426782, 2038237.599664449, 2038237.599664449, 401465.372594481], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6705000.0000, 
sim time next is 6705600.0000, 
raw observation next is [30.06666666666667, 62.0, 1.0, 2.0, 0.7317332516149497, 1.0, 2.0, 0.7317332516149497, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2046245.555013591, 2046245.555013591, 387993.7283618696], 
processed observation next is [1.0, 0.6086956521739131, 0.6240126382306479, 0.62, 1.0, 1.0, 0.6767870501384936, 1.0, 1.0, 0.6767870501384936, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5684015430593308, 0.5684015430593308, 0.5790951169580143], 
reward next is 0.4209, 
noisyNet noise sample is [array([-0.5548217], dtype=float32), 1.0963837]. 
=============================================
[2019-03-26 18:42:42,707] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2294726: loss 110.8477
[2019-03-26 18:42:42,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2294728: learning rate 0.0000
[2019-03-26 18:42:44,559] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0246721e-29 1.0000000e+00 4.2531053e-33 6.3091911e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:42:44,570] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7983
[2019-03-26 18:42:44,574] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 77.0, 1.0, 2.0, 0.4946960288855848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691258.4289693049, 691258.4289693049, 182769.3002074526], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6555600.0000, 
sim time next is 6556200.0000, 
raw observation next is [27.66666666666666, 77.66666666666667, 1.0, 2.0, 0.4962764284963369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 693467.5050002947, 693467.5050002947, 183014.8726285548], 
processed observation next is [1.0, 0.9130434782608695, 0.5102685624012636, 0.7766666666666667, 1.0, 1.0, 0.39310413071847816, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19262986250008185, 0.19262986250008185, 0.2731565263112758], 
reward next is 0.7268, 
noisyNet noise sample is [array([0.3583684], dtype=float32), 1.6602327]. 
=============================================
[2019-03-26 18:42:46,619] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2296447: loss 164.1202
[2019-03-26 18:42:46,623] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2296447: learning rate 0.0000
[2019-03-26 18:42:47,905] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2297019: loss 113.7663
[2019-03-26 18:42:47,908] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2297020: learning rate 0.0000
[2019-03-26 18:42:48,753] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.0031006e-26 1.0000000e+00 4.3324825e-30 1.1192122e-30 6.7277111e-37], sum to 1.0000
[2019-03-26 18:42:48,760] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2858
[2019-03-26 18:42:48,766] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 87.83333333333334, 1.0, 2.0, 0.5296403702742243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740104.556893132, 740104.5568931315, 188370.3616267271], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6479400.0000, 
sim time next is 6480000.0000, 
raw observation next is [26.9, 88.0, 1.0, 2.0, 0.5286159030669341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 738672.4974779445, 738672.4974779452, 188201.0023743313], 
processed observation next is [1.0, 0.0, 0.4739336492890995, 0.88, 1.0, 1.0, 0.4320673530926916, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20518680485498458, 0.20518680485498478, 0.28089701846915116], 
reward next is 0.7191, 
noisyNet noise sample is [array([-0.34887734], dtype=float32), -1.2787405]. 
=============================================
[2019-03-26 18:42:48,782] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[71.74993]
 [71.71725]
 [71.67918]
 [71.66929]
 [71.68244]], R is [[69.21395111]
 [69.24066162]
 [69.26679993]
 [69.29236603]
 [69.31757355]].
[2019-03-26 18:42:49,381] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2297671: loss 267.6582
[2019-03-26 18:42:49,385] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2297672: learning rate 0.0000
[2019-03-26 18:42:49,433] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2297691: loss -52.6264
[2019-03-26 18:42:49,434] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2297692: learning rate 0.0000
[2019-03-26 18:42:53,091] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2299313: loss 8.3911
[2019-03-26 18:42:53,095] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2299313: learning rate 0.0000
[2019-03-26 18:42:53,216] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2299370: loss 103.8231
[2019-03-26 18:42:53,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2299371: learning rate 0.0000
[2019-03-26 18:42:54,099] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2299758: loss 8.3447
[2019-03-26 18:42:54,101] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2299758: learning rate 0.0000
[2019-03-26 18:42:54,646] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 18:42:54,651] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:42:54,651] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:42:54,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:42:54,652] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:42:54,653] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:42:54,654] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:42:54,653] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:42:54,655] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:42:54,659] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:42:54,660] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:42:54,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run93
[2019-03-26 18:42:54,715] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run93
[2019-03-26 18:42:54,739] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run93
[2019-03-26 18:42:54,740] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run93
[2019-03-26 18:42:54,741] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run93
[2019-03-26 18:43:03,905] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:43:03,907] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.26666666666667, 73.0, 1.0, 2.0, 0.2258258067261842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 375675.4906496943, 375675.4906496943, 158242.0343672327]
[2019-03-26 18:43:03,911] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:43:03,914] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1751075e-34 1.0000000e+00 2.8008402e-36 0.0000000e+00 0.0000000e+00], sampled 0.7978400516036347
[2019-03-26 18:43:06,630] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:43:06,632] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.48333333333333, 91.16666666666667, 1.0, 2.0, 0.2598342173364092, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 425380.873992416, 425380.873992416, 161886.837825513]
[2019-03-26 18:43:06,633] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:43:06,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.4033627e-30 1.0000000e+00 4.1822186e-33 9.9774119e-37 0.0000000e+00], sampled 0.14418495173424828
[2019-03-26 18:43:09,793] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:43:09,794] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.34734607666667, 91.76489188166667, 1.0, 2.0, 0.3453130106047487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532762.9770495761, 532762.9770495761, 169250.1642178737]
[2019-03-26 18:43:09,795] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:43:09,799] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.8182765e-30 1.0000000e+00 2.4270654e-33 1.4352033e-35 0.0000000e+00], sampled 0.4729863834316256
[2019-03-26 18:43:14,649] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:43:14,650] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.93333333333334, 91.33333333333334, 1.0, 2.0, 0.6037842607230055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 962711.6791604629, 962711.6791604629, 214989.1359678286]
[2019-03-26 18:43:14,654] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:43:14,656] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1679262e-26 1.0000000e+00 4.9307045e-30 9.1398635e-32 4.1036839e-36], sampled 0.6910150965880701
[2019-03-26 18:43:58,282] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:43:58,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [38.2, 43.0, 1.0, 2.0, 0.7604076125503536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1062733.545989113, 1062733.545989113, 234429.0044968788]
[2019-03-26 18:43:58,286] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:43:58,289] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7120506e-27 1.0000000e+00 5.8506869e-31 5.1184398e-32 8.0864293e-37], sampled 0.7048803467583568
[2019-03-26 18:44:43,531] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:44:43,532] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.533612485, 82.067909175, 1.0, 2.0, 0.5721451719266218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799521.9247284133, 799521.9247284133, 195670.0013250348]
[2019-03-26 18:44:43,534] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:44:43,537] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5132558e-26 1.0000000e+00 3.0809455e-30 5.7179969e-29 8.4966187e-36], sampled 0.5868963178727818
[2019-03-26 18:44:44,010] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01730466], dtype=float32), 0.11967859]
[2019-03-26 18:44:44,014] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.05, 81.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.44408968161086, 6.9112, 168.9098585607443, 1832057.210900905, 1454013.863753549, 311355.4238092016]
[2019-03-26 18:44:44,015] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:44:44,018] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6695679e-24 1.0000000e+00 8.1527195e-28 2.6695228e-29 8.7928640e-34], sampled 0.9575159491283669
[2019-03-26 18:44:44,020] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1832057.210900905 W.
[2019-03-26 18:44:46,033] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7925.2725 3160776093.8815 1702.0000
[2019-03-26 18:44:47,028] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8011.2400 3006507166.7811 1739.0000
[2019-03-26 18:44:47,167] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.3277 2841776648.9995 1114.0000
[2019-03-26 18:44:47,249] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.1266 2778939424.3962 924.0000
[2019-03-26 18:44:47,334] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.0118 2927020849.3266 1329.0000
[2019-03-26 18:44:48,352] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 2300000, evaluation results [2300000.0, 7925.2725073784195, 3160776093.8815036, 1702.0, 8259.011836979735, 2927020849.3265853, 1329.0, 8664.12663711701, 2778939424.3961782, 924.0, 8011.240012155065, 3006507166.781074, 1739.0, 8507.327692023326, 2841776648.9994535, 1114.0]
[2019-03-26 18:44:48,780] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.5348285e-30 1.0000000e+00 2.7091369e-33 1.9061993e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:44:48,785] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9476
[2019-03-26 18:44:48,789] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.36666666666667, 69.16666666666667, 1.0, 2.0, 0.3889071075812468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 583851.0151141803, 583851.0151141803, 173164.8069045458], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6729000.0000, 
sim time next is 6729600.0000, 
raw observation next is [26.23333333333333, 69.33333333333334, 1.0, 2.0, 0.3848427439331689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579613.0163836644, 579613.0163836639, 172839.5019586726], 
processed observation next is [1.0, 0.9130434782608695, 0.44233807266982617, 0.6933333333333335, 1.0, 1.0, 0.2588466794375529, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.161003615662129, 0.16100361566212884, 0.25796940590846656], 
reward next is 0.7420, 
noisyNet noise sample is [array([-0.72279227], dtype=float32), -1.0247482]. 
=============================================
[2019-03-26 18:44:49,506] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2300517: loss 89.4816
[2019-03-26 18:44:49,510] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2300518: learning rate 0.0000
[2019-03-26 18:44:49,633] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5057323e-33 1.0000000e+00 1.3456180e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:44:49,642] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9275
[2019-03-26 18:44:49,649] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.76666666666667, 34.66666666666666, 1.0, 2.0, 0.2555223416276268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417128.1149687485, 417128.1149687485, 161425.1264053406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6878400.0000, 
sim time next is 6879000.0000, 
raw observation next is [29.73333333333333, 35.83333333333334, 1.0, 2.0, 0.2642705186186445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 429899.7820331121, 429899.7820331121, 162259.4320529815], 
processed observation next is [0.0, 0.6086956521739131, 0.6082148499210109, 0.35833333333333345, 1.0, 1.0, 0.11357893809475238, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11941660612030891, 0.11941660612030891, 0.24217825679549476], 
reward next is 0.7578, 
noisyNet noise sample is [array([1.7408073], dtype=float32), -0.7826107]. 
=============================================
[2019-03-26 18:44:49,665] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[80.36843 ]
 [80.314606]
 [80.28234 ]
 [80.26152 ]
 [80.2097  ]], R is [[80.27011871]
 [80.22647858]
 [80.18330383]
 [80.14066315]
 [80.09867096]].
[2019-03-26 18:44:50,068] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2300769: loss 122.9328
[2019-03-26 18:44:50,071] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2300769: learning rate 0.0000
[2019-03-26 18:44:50,614] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2301006: loss 106.3979
[2019-03-26 18:44:50,619] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2301008: learning rate 0.0000
[2019-03-26 18:44:50,932] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2301150: loss 78.0652
[2019-03-26 18:44:50,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2301151: learning rate 0.0000
[2019-03-26 18:44:51,553] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2301430: loss 8.6031
[2019-03-26 18:44:51,557] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2301430: learning rate 0.0000
[2019-03-26 18:44:51,726] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2301506: loss 186.1254
[2019-03-26 18:44:51,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2301506: learning rate 0.0000
[2019-03-26 18:44:52,319] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2301763: loss 271.3682
[2019-03-26 18:44:52,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2301764: learning rate 0.0000
[2019-03-26 18:44:52,446] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2301825: loss -64.8725
[2019-03-26 18:44:52,449] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2301826: learning rate 0.0000
[2019-03-26 18:44:54,122] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2302562: loss 8.7484
[2019-03-26 18:44:54,126] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2302564: learning rate 0.0000
[2019-03-26 18:44:58,181] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2304348: loss 8.5230
[2019-03-26 18:44:58,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2304348: learning rate 0.0000
[2019-03-26 18:44:59,381] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304889: loss 8.7533
[2019-03-26 18:44:59,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304889: learning rate 0.0000
[2019-03-26 18:45:00,613] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2305430: loss 0.0062
[2019-03-26 18:45:00,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2305430: learning rate 0.0000
[2019-03-26 18:45:01,030] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2305612: loss 8.4008
[2019-03-26 18:45:01,035] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2305613: learning rate 0.0000
[2019-03-26 18:45:01,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1091124e-25 1.0000000e+00 2.8712093e-30 8.5615862e-30 8.0300536e-37], sum to 1.0000
[2019-03-26 18:45:01,913] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5354
[2019-03-26 18:45:01,922] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 87.66666666666667, 1.0, 2.0, 0.4784223821799258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668809.4186767162, 668809.4186767162, 180322.4065576535], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7080000.0000, 
sim time next is 7080600.0000, 
raw observation next is [25.43333333333333, 87.83333333333334, 1.0, 2.0, 0.4763658806335168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 666240.161627436, 666240.1616274355, 180053.5501212139], 
processed observation next is [1.0, 0.9565217391304348, 0.40442338072669815, 0.8783333333333334, 1.0, 1.0, 0.3691155188355624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1850667115631767, 0.18506671156317653, 0.268736641971961], 
reward next is 0.7313, 
noisyNet noise sample is [array([-0.57769585], dtype=float32), 0.8081363]. 
=============================================
[2019-03-26 18:45:04,979] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2307336: loss 8.9058
[2019-03-26 18:45:04,982] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2307338: learning rate 0.0000
[2019-03-26 18:45:05,213] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2307441: loss -151.4532
[2019-03-26 18:45:05,216] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2307441: learning rate 0.0000
[2019-03-26 18:45:06,346] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2307944: loss -41.7771
[2019-03-26 18:45:06,349] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2307944: learning rate 0.0000
[2019-03-26 18:45:07,607] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2308501: loss 8.4933
[2019-03-26 18:45:07,610] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2308502: learning rate 0.0000
[2019-03-26 18:45:08,327] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2308820: loss 8.4622
[2019-03-26 18:45:08,330] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2308820: learning rate 0.0000
[2019-03-26 18:45:08,896] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2309068: loss 8.0929
[2019-03-26 18:45:08,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2309068: learning rate 0.0000
[2019-03-26 18:45:09,051] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2309141: loss 8.2001
[2019-03-26 18:45:09,053] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2309141: learning rate 0.0000
[2019-03-26 18:45:09,821] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2309479: loss 8.1326
[2019-03-26 18:45:09,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2309479: learning rate 0.0000
[2019-03-26 18:45:10,092] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2309604: loss -119.4082
[2019-03-26 18:45:10,095] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2309605: learning rate 0.0000
[2019-03-26 18:45:10,359] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2309721: loss 0.0009
[2019-03-26 18:45:10,361] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2309722: learning rate 0.0000
[2019-03-26 18:45:10,652] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2309853: loss 8.2973
[2019-03-26 18:45:10,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2309854: learning rate 0.0000
[2019-03-26 18:45:12,456] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2310659: loss -42.5999
[2019-03-26 18:45:12,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2310659: learning rate 0.0000
[2019-03-26 18:45:15,820] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1074103e-29 1.0000000e+00 3.8044974e-33 7.2243201e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 18:45:15,828] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8208
[2019-03-26 18:45:15,832] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 82.33333333333333, 1.0, 2.0, 0.5133104802856304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717277.9236559131, 717277.9236559131, 185708.3142314998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7760400.0000, 
sim time next is 7761000.0000, 
raw observation next is [27.36666666666667, 83.66666666666667, 1.0, 2.0, 0.5151455530457196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719843.044020643, 719843.044020643, 186003.5474558465], 
processed observation next is [1.0, 0.8260869565217391, 0.49605055292259104, 0.8366666666666667, 1.0, 1.0, 0.4158380157177345, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1999564011168453, 0.1999564011168453, 0.27761723500872615], 
reward next is 0.7224, 
noisyNet noise sample is [array([-0.9682619], dtype=float32), 2.1560779]. 
=============================================
[2019-03-26 18:45:15,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.38627]
 [76.64491]
 [76.72111]
 [76.83642]
 [76.87727]], R is [[76.16267395]
 [76.12387085]
 [76.08597565]
 [76.0488205 ]
 [76.01224518]].
[2019-03-26 18:45:16,844] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2312601: loss -100.4792
[2019-03-26 18:45:16,848] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2312601: learning rate 0.0000
[2019-03-26 18:45:17,613] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312942: loss -19.1780
[2019-03-26 18:45:17,617] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312943: learning rate 0.0000
[2019-03-26 18:45:18,784] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2313458: loss -116.2492
[2019-03-26 18:45:18,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2313460: learning rate 0.0000
[2019-03-26 18:45:19,420] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2313742: loss -86.3556
[2019-03-26 18:45:19,426] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2313745: learning rate 0.0000
[2019-03-26 18:45:22,872] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2315274: loss 0.0019
[2019-03-26 18:45:22,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2315275: learning rate 0.0000
[2019-03-26 18:45:23,056] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2315354: loss -98.1658
[2019-03-26 18:45:23,066] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2315357: learning rate 0.0000
[2019-03-26 18:45:23,139] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.6347182e-18 1.0000000e+00 7.5243274e-25 4.7520975e-15 5.7908332e-28], sum to 1.0000
[2019-03-26 18:45:23,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8963
[2019-03-26 18:45:23,159] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 85.5, 1.0, 2.0, 0.4571306072271876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 638750.9904433275, 638750.9904433275, 177153.0573897664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7147800.0000, 
sim time next is 7148400.0000, 
raw observation next is [26.1, 85.33333333333334, 1.0, 2.0, 0.4665703161739961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 651945.1925584234, 651945.1925584228, 178524.8083911056], 
processed observation next is [1.0, 0.7391304347826086, 0.4360189573459717, 0.8533333333333334, 1.0, 1.0, 0.3573136339445736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18109588682178426, 0.18109588682178412, 0.2664549378971725], 
reward next is 0.7335, 
noisyNet noise sample is [array([1.3774029], dtype=float32), 1.3148422]. 
=============================================
[2019-03-26 18:45:23,980] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2315764: loss 0.0042
[2019-03-26 18:45:23,982] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2315765: learning rate 0.0000
[2019-03-26 18:45:25,799] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4693211e-29 1.0000000e+00 3.9903353e-33 1.3367612e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:45:25,807] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8866
[2019-03-26 18:45:25,813] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 80.0, 1.0, 2.0, 0.4075194854067613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 597900.8704023627, 597900.8704023634, 174040.2020620153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7480800.0000, 
sim time next is 7481400.0000, 
raw observation next is [25.46666666666667, 79.66666666666667, 1.0, 2.0, 0.4087537099248951, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 599111.1658647363, 599111.1658647369, 174134.0460525193], 
processed observation next is [0.0, 0.6086956521739131, 0.40600315955766203, 0.7966666666666667, 1.0, 1.0, 0.2876550721986688, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16641976829576008, 0.16641976829576025, 0.25990156127241687], 
reward next is 0.7401, 
noisyNet noise sample is [array([0.85353714], dtype=float32), -0.8199456]. 
=============================================
[2019-03-26 18:45:26,021] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2316653: loss -37.5977
[2019-03-26 18:45:26,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2316654: learning rate 0.0000
[2019-03-26 18:45:26,377] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0822613e-23 1.0000000e+00 1.2767644e-27 9.1238025e-25 6.2630128e-34], sum to 1.0000
[2019-03-26 18:45:26,390] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9862
[2019-03-26 18:45:26,396] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 86.0, 1.0, 2.0, 0.4736779639699703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 661879.9016697747, 661879.9016697753, 179574.5086698887], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7172400.0000, 
sim time next is 7173000.0000, 
raw observation next is [25.75, 86.0, 1.0, 2.0, 0.4740798169992675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662441.5942000849, 662441.5942000843, 179634.3761610241], 
processed observation next is [1.0, 0.0, 0.41943127962085314, 0.86, 1.0, 1.0, 0.3663612253003222, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18401155394446803, 0.18401155394446786, 0.26811100919555836], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.5388096], dtype=float32), 0.5381522]. 
=============================================
[2019-03-26 18:45:26,405] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.759636]
 [71.02473 ]
 [72.44639 ]
 [75.053474]
 [75.01843 ]], R is [[70.74573517]
 [70.77025604]
 [70.79456329]
 [70.81880951]
 [70.84303284]].
[2019-03-26 18:45:26,622] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2316921: loss 25.2799
[2019-03-26 18:45:26,626] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2316924: learning rate 0.0000
[2019-03-26 18:45:27,047] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2317107: loss -97.2061
[2019-03-26 18:45:27,050] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2317107: learning rate 0.0000
[2019-03-26 18:45:27,100] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6641191e-31 1.0000000e+00 6.7326251e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:45:27,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4386
[2019-03-26 18:45:27,114] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 94.66666666666667, 1.0, 2.0, 0.3381506709639861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 524440.2747357157, 524440.2747357157, 168662.9221081334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7459800.0000, 
sim time next is 7460400.0000, 
raw observation next is [21.8, 94.33333333333334, 1.0, 2.0, 0.3411922987100115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528292.002205022, 528292.002205022, 168945.619375232], 
processed observation next is [0.0, 0.34782608695652173, 0.23222748815165886, 0.9433333333333335, 1.0, 1.0, 0.2062557815783271, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14674777839028388, 0.14674777839028388, 0.25215764085855524], 
reward next is 0.7478, 
noisyNet noise sample is [array([0.16290835], dtype=float32), -0.84808415]. 
=============================================
[2019-03-26 18:45:27,443] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2317283: loss -33.8782
[2019-03-26 18:45:27,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2317283: learning rate 0.0000
[2019-03-26 18:45:27,592] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2317348: loss 0.0027
[2019-03-26 18:45:27,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2317349: learning rate 0.0000
[2019-03-26 18:45:28,049] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2317548: loss -220.4649
[2019-03-26 18:45:28,052] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2317549: learning rate 0.0000
[2019-03-26 18:45:28,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:45:28,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:28,413] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2317711: loss 6.2962
[2019-03-26 18:45:28,416] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2317711: learning rate 0.0000
[2019-03-26 18:45:28,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run12
[2019-03-26 18:45:28,745] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2317863: loss -218.4783
[2019-03-26 18:45:28,751] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2317863: learning rate 0.0000
[2019-03-26 18:45:29,794] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2318442: loss 0.0161
[2019-03-26 18:45:29,800] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2318444: learning rate 0.0000
[2019-03-26 18:45:34,169] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2320382: loss 0.0073
[2019-03-26 18:45:34,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2320382: learning rate 0.0000
[2019-03-26 18:45:34,929] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320721: loss 0.0097
[2019-03-26 18:45:34,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320721: learning rate 0.0000
[2019-03-26 18:45:36,733] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2321516: loss 0.0046
[2019-03-26 18:45:36,738] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2321516: learning rate 0.0000
[2019-03-26 18:45:37,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:45:37,646] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:37,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run12
[2019-03-26 18:45:38,947] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8797014e-25 1.0000000e+00 4.3969360e-29 3.1316606e-30 1.1375676e-35], sum to 1.0000
[2019-03-26 18:45:38,962] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3540
[2019-03-26 18:45:38,971] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.93333333333333, 92.0, 1.0, 2.0, 0.6805497348109224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1083154.631615145, 1083154.631615145, 232199.5134803211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7393200.0000, 
sim time next is 7393800.0000, 
raw observation next is [20.91666666666667, 92.0, 1.0, 2.0, 0.6932037179371177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1103666.675103436, 1103666.675103435, 235280.3307514945], 
processed observation next is [1.0, 0.5652173913043478, 0.19036334913112193, 0.92, 1.0, 1.0, 0.630365925225443, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30657407641762113, 0.30657407641762086, 0.3511646727634246], 
reward next is 0.6488, 
noisyNet noise sample is [array([0.6665164], dtype=float32), -0.3422529]. 
=============================================
[2019-03-26 18:45:39,994] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2323080: loss 0.0093
[2019-03-26 18:45:39,997] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2323081: learning rate 0.0000
[2019-03-26 18:45:40,046] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9599423e-10 2.8664661e-03 6.9063022e-18 9.9713349e-01 4.9649603e-19], sum to 1.0000
[2019-03-26 18:45:40,053] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5762
[2019-03-26 18:45:40,059] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.5067058708126001, 1.0, 1.0, 0.5067058708126001, 1.0, 2.0, 0.8756562283662057, 6.9112, 6.9112, 170.5573041426782, 2125534.754027965, 2125534.754027965, 419021.8971580576], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7729200.0000, 
sim time next is 7729800.0000, 
raw observation next is [31.16666666666667, 64.66666666666667, 1.0, 2.0, 0.8231057863444791, 1.0, 2.0, 0.8231057863444791, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2302023.892182159, 2302023.892182158, 431273.4161939551], 
processed observation next is [1.0, 0.4782608695652174, 0.6761453396524489, 0.6466666666666667, 1.0, 1.0, 0.7868744413788904, 1.0, 1.0, 0.7868744413788904, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6394510811617108, 0.6394510811617106, 0.643691665961127], 
reward next is 0.3563, 
noisyNet noise sample is [array([-1.1293947], dtype=float32), -1.4198449]. 
=============================================
[2019-03-26 18:45:40,479] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2323296: loss -14.4807
[2019-03-26 18:45:40,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2323296: learning rate 0.0000
[2019-03-26 18:45:40,929] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9135191e-10 9.9946266e-01 4.7805494e-17 5.3734524e-04 2.0926041e-19], sum to 1.0000
[2019-03-26 18:45:40,936] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3264
[2019-03-26 18:45:40,950] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2204123.438545497 W.
[2019-03-26 18:45:40,956] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.53333333333333, 70.66666666666667, 1.0, 2.0, 0.9350695796473565, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.998283046602504, 6.9112, 168.9124389461601, 2204123.438545497, 2142343.917417035, 444259.1370186644], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7818000.0000, 
sim time next is 7818600.0000, 
raw observation next is [30.76666666666667, 70.33333333333333, 1.0, 2.0, 0.5244785119785645, 1.0, 1.0, 0.5244785119785645, 1.0, 2.0, 0.9108457276124191, 6.911200000000001, 6.9112, 170.5573041426782, 2200164.169817129, 2200164.169817128, 432486.1638741574], 
processed observation next is [1.0, 0.4782608695652174, 0.6571879936808849, 0.7033333333333333, 1.0, 1.0, 0.4270825445524874, 1.0, 0.5, 0.4270825445524874, 1.0, 1.0, 0.8912752775761209, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6111567138380914, 0.6111567138380912, 0.6455017371256081], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4329894], dtype=float32), -1.3566945]. 
=============================================
[2019-03-26 18:45:41,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5649877e-26 1.0000000e+00 7.0246993e-30 4.8469285e-32 1.0750160e-35], sum to 1.0000
[2019-03-26 18:45:41,038] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8147
[2019-03-26 18:45:41,042] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 82.0, 1.0, 2.0, 0.7750000565356212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1083138.113945953, 1083138.113945952, 237866.0188770856], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7804800.0000, 
sim time next is 7805400.0000, 
raw observation next is [27.8, 81.50000000000001, 1.0, 2.0, 0.7127881500550555, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 996150.1304022573, 996150.1304022567, 223629.0965376089], 
processed observation next is [1.0, 0.34782608695652173, 0.5165876777251186, 0.8150000000000002, 1.0, 1.0, 0.653961626572356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2767083695561826, 0.27670836955618244, 0.33377477095165503], 
reward next is 0.6662, 
noisyNet noise sample is [array([0.8523675], dtype=float32), -0.045790315]. 
=============================================
[2019-03-26 18:45:41,543] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2323766: loss 30.0416
[2019-03-26 18:45:41,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2323766: learning rate 0.0000
[2019-03-26 18:45:43,051] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2324435: loss 0.0034
[2019-03-26 18:45:43,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2324435: learning rate 0.0000
[2019-03-26 18:45:43,587] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2324671: loss 0.0037
[2019-03-26 18:45:43,589] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2324671: learning rate 0.0000
[2019-03-26 18:45:44,071] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2324888: loss 0.0024
[2019-03-26 18:45:44,073] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2324888: learning rate 0.0000
[2019-03-26 18:45:44,340] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 18:45:44,343] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:45:44,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:44,344] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:45:44,346] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:45:44,347] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:44,348] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:45:44,349] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:45:44,350] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:44,350] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:44,353] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:45:44,379] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run94
[2019-03-26 18:45:44,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run94
[2019-03-26 18:45:44,433] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run94
[2019-03-26 18:45:44,460] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run94
[2019-03-26 18:45:44,486] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run94
[2019-03-26 18:45:51,958] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:45:51,959] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.33644081, 61.80854389666666, 1.0, 2.0, 0.2927249043211923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486224.0204312336, 486224.020431233, 165161.4633551153]
[2019-03-26 18:45:51,960] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:45:51,964] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2823485e-31 1.0000000e+00 1.4262431e-33 0.0000000e+00 0.0000000e+00], sampled 0.029762670304896655
[2019-03-26 18:45:59,578] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:45:59,579] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.8, 95.0, 1.0, 2.0, 0.3426359610186044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 528995.1205086668, 528995.1205086668, 168956.2888355418]
[2019-03-26 18:45:59,580] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:45:59,583] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9964556e-27 1.0000000e+00 5.9855947e-31 3.7681162e-32 8.7390470e-37], sampled 0.8777266724288763
[2019-03-26 18:46:06,316] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:06,317] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.96666666666667, 56.0, 1.0, 2.0, 0.2734062676775846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 445560.1760768106, 445560.1760768099, 163245.3726330434]
[2019-03-26 18:46:06,318] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:46:06,323] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.6288206e-33 1.0000000e+00 9.3986278e-35 0.0000000e+00 0.0000000e+00], sampled 0.03667114152899009
[2019-03-26 18:46:19,915] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:19,916] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.99895042333333, 77.99421762666667, 1.0, 2.0, 0.7241938988034826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1012097.719135678, 1012097.719135678, 226168.3879626053]
[2019-03-26 18:46:19,917] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:46:19,919] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9685940e-28 1.0000000e+00 4.8555155e-32 1.7510998e-33 1.6506276e-38], sampled 0.19319887209646247
[2019-03-26 18:46:22,119] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:22,121] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.719762005, 97.67157659, 1.0, 2.0, 0.8150465243427047, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005982468000148, 6.9112, 168.9123159987234, 2036131.819239066, 1968890.12925795, 411610.7367752755]
[2019-03-26 18:46:22,123] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:46:22,125] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1048210e-14 1.0000000e+00 4.6057387e-20 8.0518155e-11 6.3771295e-23], sampled 0.011906745989383016
[2019-03-26 18:46:22,126] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2036131.819239066 W.
[2019-03-26 18:46:33,231] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:33,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.16666666666667, 83.16666666666667, 1.0, 2.0, 0.4268892088796643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622013.9468405113, 622013.9468405107, 176205.7505025073]
[2019-03-26 18:46:33,234] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:46:33,236] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0947527e-32 1.0000000e+00 3.9995226e-34 0.0000000e+00 0.0000000e+00], sampled 0.909585150348422
[2019-03-26 18:46:36,157] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:36,159] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.63333333333333, 74.33333333333334, 1.0, 2.0, 0.5894181797687883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 823668.7738606934, 823668.7738606929, 198790.6570978189]
[2019-03-26 18:46:36,161] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:46:36,163] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7611045e-27 1.0000000e+00 2.0940520e-31 1.9861294e-30 7.3107772e-37], sampled 0.10517970365166718
[2019-03-26 18:46:48,652] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:46:48,653] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.92206359666667, 81.51800102166666, 1.0, 2.0, 0.6532173626728693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912861.7770031985, 912861.7770031985, 211081.5773040488]
[2019-03-26 18:46:48,654] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:46:48,655] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9989684e-29 1.0000000e+00 3.4761069e-33 2.1142770e-33 0.0000000e+00], sampled 0.8277999110324201
[2019-03-26 18:47:03,410] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:03,412] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.4, 53.0, 1.0, 2.0, 0.7137681998847096, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00597614315473, 6.9112, 168.9123160471352, 1894395.556235504, 1827158.353281127, 387659.5551652403]
[2019-03-26 18:47:03,413] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:47:03,417] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0346709e-14 9.9999857e-01 2.1841150e-22 1.3952397e-06 1.0681903e-23], sampled 0.3611559752272978
[2019-03-26 18:47:03,419] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1894395.556235504 W.
[2019-03-26 18:47:14,318] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:14,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.46666666666667, 76.0, 1.0, 2.0, 0.7989793362376116, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.99477284413706, 6.9112, 168.9123916208647, 2013644.961540485, 1954355.707833941, 408012.4763068135]
[2019-03-26 18:47:14,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:47:14,323] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2014933e-12 9.9894327e-01 1.4054319e-19 1.0568016e-03 8.9123266e-21], sampled 0.7044971199148803
[2019-03-26 18:47:14,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2013644.961540485 W.
[2019-03-26 18:47:23,576] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:23,577] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.23333333333333, 48.33333333333333, 1.0, 2.0, 0.9685269977396771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1502575.608151765, 1502575.608151765, 310683.3331273543]
[2019-03-26 18:47:23,578] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:47:23,580] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0608434e-20 1.0000000e+00 6.5382468e-25 1.1467602e-21 5.8583949e-30], sampled 0.6174777580023298
[2019-03-26 18:47:24,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:24,050] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.02271274, 59.92283776, 1.0, 2.0, 0.5242845387116417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788115.2561945404, 788115.2561945404, 194320.7816700662]
[2019-03-26 18:47:24,052] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:47:24,055] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5814470e-29 1.0000000e+00 3.4088875e-32 1.6134754e-36 2.1032590e-38], sampled 0.9265305906530817
[2019-03-26 18:47:26,617] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:26,619] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.07141827666667, 63.12786233666667, 1.0, 2.0, 0.4953390912148646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 692157.2982757225, 692157.2982757225, 182868.9143613589]
[2019-03-26 18:47:26,621] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:47:26,623] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3346964e-30 1.0000000e+00 3.9525821e-33 4.0824449e-38 0.0000000e+00], sampled 0.4581689657053162
[2019-03-26 18:47:33,254] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01862857], dtype=float32), 0.11857632]
[2019-03-26 18:47:33,255] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.63333333333333, 62.0, 1.0, 2.0, 0.393827877143643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 592088.9201962883, 592088.920196289, 173938.7397132552]
[2019-03-26 18:47:33,256] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:47:33,259] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7627029e-31 1.0000000e+00 9.5685516e-34 0.0000000e+00 0.0000000e+00], sampled 0.5894346478627406
[2019-03-26 18:47:40,109] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8519.6802 2840711206.1761 1081.0000
[2019-03-26 18:47:40,394] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8271.7222 2925926588.5714 1302.0000
[2019-03-26 18:47:40,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7955.1727 3157836444.0806 1611.0000
[2019-03-26 18:47:40,675] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8027.5195 3004619358.3773 1695.0000
[2019-03-26 18:47:40,721] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8670.3375 2778526242.8412 912.0000
[2019-03-26 18:47:41,737] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 2325000, evaluation results [2325000.0, 7955.172687151145, 3157836444.080639, 1611.0, 8271.722166730338, 2925926588.5714374, 1302.0, 8670.337489947478, 2778526242.841161, 912.0, 8027.519514987066, 3004619358.3773255, 1695.0, 8519.68022483985, 2840711206.1760583, 1081.0]
[2019-03-26 18:47:41,859] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2325066: loss 0.0021
[2019-03-26 18:47:41,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2325067: learning rate 0.0000
[2019-03-26 18:47:41,907] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0111339e-27 1.0000000e+00 9.5123695e-32 2.6063196e-30 1.0525024e-37], sum to 1.0000
[2019-03-26 18:47:41,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0498
[2019-03-26 18:47:41,922] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 77.0, 1.0, 2.0, 0.5068590382560402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708259.9514718591, 708259.9514718591, 184678.1952016931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7758000.0000, 
sim time next is 7758600.0000, 
raw observation next is [28.03333333333333, 78.33333333333334, 1.0, 2.0, 0.5087483121397305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710900.8134856811, 710900.8134856817, 184978.5656967247], 
processed observation next is [1.0, 0.8260869565217391, 0.5276461295418641, 0.7833333333333334, 1.0, 1.0, 0.4081304965538921, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19747244819046697, 0.19747244819046714, 0.2760874114876488], 
reward next is 0.7239, 
noisyNet noise sample is [array([-0.3112856], dtype=float32), -0.63557607]. 
=============================================
[2019-03-26 18:47:42,384] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2325292: loss 0.0011
[2019-03-26 18:47:42,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2325293: learning rate 0.0000
[2019-03-26 18:47:42,554] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2325366: loss 30.1858
[2019-03-26 18:47:42,558] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2325366: learning rate 0.0000
[2019-03-26 18:47:43,340] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2325717: loss 0.0009
[2019-03-26 18:47:43,343] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2325717: learning rate 0.0000
[2019-03-26 18:47:45,156] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2326521: loss -170.9632
[2019-03-26 18:47:45,159] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2326522: learning rate 0.0000
[2019-03-26 18:47:47,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:47,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:47,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run12
[2019-03-26 18:47:47,917] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1993742e-24 1.0000000e+00 1.5310560e-28 5.6183016e-28 9.5737366e-34], sum to 1.0000
[2019-03-26 18:47:47,924] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1101
[2019-03-26 18:47:47,928] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 94.83333333333333, 1.0, 2.0, 0.448102153616107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 641251.1882009836, 641251.1882009836, 177809.1674965124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7609800.0000, 
sim time next is 7610400.0000, 
raw observation next is [23.9, 95.0, 1.0, 2.0, 0.4451436701503949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 638235.8368343628, 638235.8368343628, 177536.0851415757], 
processed observation next is [1.0, 0.08695652173913043, 0.33175355450236965, 0.95, 1.0, 1.0, 0.3314983977715601, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17728773245398968, 0.17728773245398968, 0.2649792315545906], 
reward next is 0.7350, 
noisyNet noise sample is [array([0.593789], dtype=float32), 0.42963293]. 
=============================================
[2019-03-26 18:47:47,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.2392301e-23 1.0000000e+00 1.7797804e-27 3.6841441e-24 9.9919389e-34], sum to 1.0000
[2019-03-26 18:47:47,938] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7154
[2019-03-26 18:47:47,941] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 88.0, 1.0, 2.0, 0.5101332702930573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712836.7378048967, 712836.737804896, 185198.9423960287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777800.0000, 
sim time next is 7778400.0000, 
raw observation next is [26.4, 87.66666666666667, 1.0, 2.0, 0.5083499806877253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710344.0178609152, 710344.0178609157, 184914.6543833675], 
processed observation next is [1.0, 0.0, 0.45023696682464454, 0.8766666666666667, 1.0, 1.0, 0.40765057914183767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1973177827391431, 0.19731778273914327, 0.2759920214677127], 
reward next is 0.7240, 
noisyNet noise sample is [array([1.0133487], dtype=float32), 0.7949359]. 
=============================================
[2019-03-26 18:47:48,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:48,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:48,506] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run12
[2019-03-26 18:47:48,719] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2328218: loss -91.8753
[2019-03-26 18:47:48,721] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2328218: learning rate 0.0000
[2019-03-26 18:47:49,403] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328607: loss -58.8144
[2019-03-26 18:47:49,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328607: learning rate 0.0000
[2019-03-26 18:47:50,815] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2329268: loss -153.4602
[2019-03-26 18:47:50,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2329268: learning rate 0.0000
[2019-03-26 18:47:51,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:51,164] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:51,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run12
[2019-03-26 18:47:51,984] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.8217166e-26 1.0000000e+00 2.7859850e-29 1.3972354e-30 2.4714419e-35], sum to 1.0000
[2019-03-26 18:47:51,992] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1841
[2019-03-26 18:47:51,997] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 85.0, 1.0, 2.0, 0.6652724666991984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 929715.9836599164, 929715.9836599157, 213527.6294061075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7718400.0000, 
sim time next is 7719000.0000, 
raw observation next is [27.6, 83.83333333333334, 1.0, 2.0, 0.8698121618601413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1215723.129822778, 1215723.129822777, 261768.3282773621], 
processed observation next is [1.0, 0.34782608695652173, 0.5071090047393366, 0.8383333333333334, 1.0, 1.0, 0.8431471829640257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33770086939521615, 0.3377008693952158, 0.3906989974288987], 
reward next is 0.6093, 
noisyNet noise sample is [array([-0.58898485], dtype=float32), -0.526399]. 
=============================================
[2019-03-26 18:47:52,004] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[65.21368 ]
 [64.96236 ]
 [65.54878 ]
 [66.236885]
 [66.3635  ]], R is [[62.88006592]
 [62.9325676 ]
 [62.97389603]
 [63.02338409]
 [63.08935547]].
[2019-03-26 18:47:53,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:53,243] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:53,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run12
[2019-03-26 18:47:53,918] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2330808: loss -132.1330
[2019-03-26 18:47:53,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2330808: learning rate 0.0000
[2019-03-26 18:47:56,757] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2332150: loss -141.1539
[2019-03-26 18:47:56,758] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2332150: learning rate 0.0000
[2019-03-26 18:47:56,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:56,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:57,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run12
[2019-03-26 18:47:57,097] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2332284: loss -63.5744
[2019-03-26 18:47:57,100] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2332285: learning rate 0.0000
[2019-03-26 18:47:57,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:57,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:57,667] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2332603: loss -118.7636
[2019-03-26 18:47:57,669] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2332603: learning rate 0.0000
[2019-03-26 18:47:57,695] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run12
[2019-03-26 18:47:57,732] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2332624: loss -42.9707
[2019-03-26 18:47:57,734] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2332624: learning rate 0.0000
[2019-03-26 18:47:58,074] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2332839: loss -61.8966
[2019-03-26 18:47:58,075] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2332839: learning rate 0.0000
[2019-03-26 18:47:58,742] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2333234: loss -272.4835
[2019-03-26 18:47:58,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2333234: learning rate 0.0000
[2019-03-26 18:47:58,949] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:47:58,949] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:47:59,028] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run12
[2019-03-26 18:48:02,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:02,006] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:02,070] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run12
[2019-03-26 18:48:04,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:04,649] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:04,734] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run12
[2019-03-26 18:48:04,940] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:04,940] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:05,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run12
[2019-03-26 18:48:05,518] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:05,519] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:05,582] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run12
[2019-03-26 18:48:05,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:05,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:05,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run12
[2019-03-26 18:48:06,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:06,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:06,166] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run12
[2019-03-26 18:48:06,659] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 18:48:06,660] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:06,705] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run12
[2019-03-26 18:48:11,277] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.8401921e-29 1.0000000e+00 1.9655510e-32 9.7750496e-33 9.8977612e-38], sum to 1.0000
[2019-03-26 18:48:11,284] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3982
[2019-03-26 18:48:11,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 87.5, 1.0, 2.0, 0.306765042468953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486322.4256024822, 486322.4256024816, 166040.3258112925], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 858600.0000, 
sim time next is 859200.0000, 
raw observation next is [21.66666666666667, 88.0, 1.0, 2.0, 0.3075302115573703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 487202.2530669138, 487202.2530669138, 166097.8522348183], 
processed observation next is [0.0, 0.9565217391304348, 0.22590837282780438, 0.88, 1.0, 1.0, 0.16569905006912086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13533395918525384, 0.13533395918525384, 0.24790724214151985], 
reward next is 0.7521, 
noisyNet noise sample is [array([-0.15643363], dtype=float32), -1.0338892]. 
=============================================
[2019-03-26 18:48:13,075] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9870560e-28 1.0000000e+00 2.0291204e-32 1.5030672e-32 4.3308788e-38], sum to 1.0000
[2019-03-26 18:48:13,083] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6026
[2019-03-26 18:48:13,086] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.05, 79.5, 1.0, 2.0, 0.2408018876667755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 398325.5686412163, 398325.5686412163, 159918.3715501579], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 505800.0000, 
sim time next is 506400.0000, 
raw observation next is [19.96666666666667, 80.0, 1.0, 2.0, 0.2409283209151263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 398606.4369118143, 398606.436911815, 159924.9910059306], 
processed observation next is [1.0, 0.8695652173913043, 0.14533965244865735, 0.8, 1.0, 1.0, 0.08545580833147746, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11072401025328175, 0.11072401025328195, 0.2386940164267621], 
reward next is 0.7613, 
noisyNet noise sample is [array([0.06641091], dtype=float32), -0.62914836]. 
=============================================
[2019-03-26 18:48:14,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6846526e-25 1.0000000e+00 2.3343223e-29 5.3033708e-30 7.6195746e-36], sum to 1.0000
[2019-03-26 18:48:14,341] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9541
[2019-03-26 18:48:14,345] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 93.33333333333334, 1.0, 2.0, 0.6944983242685399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1042988.007843672, 1042988.007843671, 228991.4354119874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 121200.0000, 
sim time next is 121800.0000, 
raw observation next is [22.9, 93.66666666666667, 1.0, 2.0, 0.6772672177176389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1015721.395939352, 1015721.395939352, 224885.0827546244], 
processed observation next is [1.0, 0.391304347826087, 0.2843601895734597, 0.9366666666666668, 1.0, 1.0, 0.6111653225513721, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28214483220537556, 0.28214483220537556, 0.33564937724570804], 
reward next is 0.6644, 
noisyNet noise sample is [array([-0.47593543], dtype=float32), -0.2862992]. 
=============================================
[2019-03-26 18:48:16,928] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.5790766e-34 1.0000000e+00 1.5724068e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:48:16,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1158
[2019-03-26 18:48:16,941] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 94.0, 1.0, 2.0, 0.2888478642626525, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464688.8910107907, 464688.8910107907, 164593.0614477661], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 198000.0000, 
sim time next is 198600.0000, 
raw observation next is [20.23333333333333, 93.83333333333334, 1.0, 2.0, 0.2893638462053617, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465394.6007317224, 465394.6007317224, 164641.3125937561], 
processed observation next is [0.0, 0.30434782608695654, 0.15797788309636643, 0.9383333333333335, 1.0, 1.0, 0.14381186289802614, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.129276277981034, 0.129276277981034, 0.24573330237874044], 
reward next is 0.7543, 
noisyNet noise sample is [array([0.4588899], dtype=float32), 0.8470189]. 
=============================================
[2019-03-26 18:48:21,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9632239e-28 1.0000000e+00 6.7617162e-32 4.8657505e-32 1.4901097e-37], sum to 1.0000
[2019-03-26 18:48:21,562] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3581
[2019-03-26 18:48:21,567] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.5, 91.33333333333334, 1.0, 2.0, 0.2833883711786864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456068.3070089751, 456068.3070089751, 164005.9628730823], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 256800.0000, 
sim time next is 257400.0000, 
raw observation next is [20.5, 91.5, 1.0, 2.0, 0.2839297291492424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 456765.0287974051, 456765.0287974051, 164052.4937628196], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.915, 1.0, 1.0, 0.1372647339147499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12687917466594587, 0.12687917466594587, 0.24485446830271582], 
reward next is 0.7551, 
noisyNet noise sample is [array([0.3869317], dtype=float32), 0.9230219]. 
=============================================
[2019-03-26 18:48:30,279] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.6705531e-27 1.0000000e+00 1.8298957e-31 1.0661398e-31 7.4191344e-38], sum to 1.0000
[2019-03-26 18:48:30,290] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1041
[2019-03-26 18:48:30,296] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 81.5, 1.0, 2.0, 0.2557607449046097, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 419868.8159036694, 419868.8159036688, 161484.0978469386], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 766200.0000, 
sim time next is 766800.0000, 
raw observation next is [20.4, 82.0, 1.0, 2.0, 0.2567924316637124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 421572.8536829458, 421572.8536829464, 161587.8803266313], 
processed observation next is [1.0, 0.9130434782608695, 0.16587677725118483, 0.82, 1.0, 1.0, 0.10456919477555711, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11710357046748494, 0.11710357046748511, 0.24117594078601687], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.25750414], dtype=float32), -0.011073798]. 
=============================================
[2019-03-26 18:48:30,741] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2520345e-33 1.0000000e+00 1.2791382e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:48:30,755] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9941
[2019-03-26 18:48:30,758] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.85, 90.5, 1.0, 2.0, 0.2652308954835433, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 432473.5304145942, 432473.5304145948, 162397.0306133403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 797400.0000, 
sim time next is 798000.0000, 
raw observation next is [20.0, 89.66666666666667, 1.0, 2.0, 0.266010431261114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 433403.7071040743, 433403.7071040743, 162465.6624087682], 
processed observation next is [0.0, 0.21739130434782608, 0.1469194312796209, 0.8966666666666667, 1.0, 1.0, 0.11567521838688434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12038991864002065, 0.12038991864002065, 0.24248606329666894], 
reward next is 0.7575, 
noisyNet noise sample is [array([-0.7864003], dtype=float32), 0.45449215]. 
=============================================
[2019-03-26 18:48:30,776] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[76.77997 ]
 [76.78668 ]
 [76.802765]
 [76.802605]
 [76.686455]], R is [[76.77698517]
 [76.76683044]
 [76.75691986]
 [76.74731445]
 [76.7379837 ]].
[2019-03-26 18:48:31,755] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.5108329e-27 1.0000000e+00 7.2361943e-30 9.6861966e-31 4.8601382e-36], sum to 1.0000
[2019-03-26 18:48:31,763] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1168
[2019-03-26 18:48:31,770] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.73333333333333, 50.66666666666667, 1.0, 2.0, 0.6062070162912763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 990598.8902239722, 990598.8902239722, 216869.7082294722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 739200.0000, 
sim time next is 739800.0000, 
raw observation next is [25.8, 50.0, 1.0, 2.0, 0.6286001612381256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1027981.185747482, 1027981.185747482, 221830.122651141], 
processed observation next is [1.0, 0.5652173913043478, 0.42180094786729866, 0.5, 1.0, 1.0, 0.5525303147447296, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2855503293743006, 0.2855503293743006, 0.3310897353002104], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.19714607], dtype=float32), 0.30474433]. 
=============================================
[2019-03-26 18:48:35,034] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 18:48:35,037] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:48:35,038] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:35,039] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:48:35,041] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:48:35,042] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:48:35,045] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:35,040] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:48:35,048] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:35,052] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:35,053] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:48:35,070] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run95
[2019-03-26 18:48:35,099] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run95
[2019-03-26 18:48:35,122] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run95
[2019-03-26 18:48:35,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run95
[2019-03-26 18:48:35,172] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run95
[2019-03-26 18:49:24,565] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01733865], dtype=float32), 0.11199603]
[2019-03-26 18:49:24,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.85, 65.0, 1.0, 2.0, 0.7733835328930916, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984513986201795, 6.9112, 168.912460233641, 1977823.300815533, 1925811.988544235, 402153.3141853385]
[2019-03-26 18:49:24,568] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:49:24,570] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4503049e-13 1.0000000e+00 1.9649042e-19 1.9603632e-08 4.4777770e-22], sampled 0.8320727025314488
[2019-03-26 18:49:24,572] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1977823.300815533 W.
[2019-03-26 18:49:42,250] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01733865], dtype=float32), 0.11199603]
[2019-03-26 18:49:42,250] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.98333333333333, 46.66666666666667, 1.0, 2.0, 0.7811764337597396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1091774.640648121, 1091774.640648121, 239346.98066811]
[2019-03-26 18:49:42,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:49:42,255] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1368422e-29 1.0000000e+00 6.5061959e-34 1.5954774e-33 0.0000000e+00], sampled 0.21249455573712506
[2019-03-26 18:50:17,167] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01733865], dtype=float32), 0.11199603]
[2019-03-26 18:50:17,171] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.7, 81.16666666666667, 1.0, 2.0, 0.3507842258646424, 0.0, 2.0, 0.0, 1.0, 2.0, 0.609196194210713, 6.911200000000001, 6.9112, 168.912910584869, 980462.912301529, 980462.9123015283, 239683.4683503592]
[2019-03-26 18:50:17,172] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:50:17,174] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0077162e-15 1.0000000e+00 4.2418841e-22 1.0814926e-08 1.6112280e-24], sampled 0.5685297285110921
[2019-03-26 18:50:30,227] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8024.1634 3005016675.7685 1703.0000
[2019-03-26 18:50:30,782] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7949.0709 3158335993.7161 1628.0000
[2019-03-26 18:50:30,999] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8270.5838 2926288026.7496 1306.0000
[2019-03-26 18:50:31,025] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8668.8322 2778449481.5616 911.0000
[2019-03-26 18:50:31,047] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8514.0513 2841092808.2228 1092.0000
[2019-03-26 18:50:32,065] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2350000, evaluation results [2350000.0, 7949.070869401545, 3158335993.716101, 1628.0, 8270.58378028118, 2926288026.7496367, 1306.0, 8668.832248716215, 2778449481.561598, 911.0, 8024.1634497766245, 3005016675.768511, 1703.0, 8514.051256647197, 2841092808.222804, 1092.0]
[2019-03-26 18:50:34,049] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0891917e-32 1.0000000e+00 1.8843464e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:50:34,060] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3600
[2019-03-26 18:50:34,064] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 80.0, 1.0, 2.0, 0.2321895276978192, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 384136.3550020184, 384136.3550020184, 159105.5177691892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 543600.0000, 
sim time next is 544200.0000, 
raw observation next is [20.2, 79.16666666666667, 1.0, 2.0, 0.2379483029790189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 393328.7558126719, 393328.7558126719, 159667.2780906805], 
processed observation next is [1.0, 0.30434782608695654, 0.15639810426540288, 0.7916666666666667, 1.0, 1.0, 0.08186542527592637, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1092579877257422, 0.1092579877257422, 0.23830937028459778], 
reward next is 0.7617, 
noisyNet noise sample is [array([0.45194757], dtype=float32), 0.78623873]. 
=============================================
[2019-03-26 18:50:41,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1284131e-28 1.0000000e+00 6.6991223e-32 4.7038859e-31 2.5437205e-38], sum to 1.0000
[2019-03-26 18:50:41,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8848
[2019-03-26 18:50:41,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.18333333333334, 86.5, 1.0, 2.0, 0.2164753084279003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 360915.5059647441, 360915.5059647434, 157198.1531305439], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 604200.0000, 
sim time next is 604800.0000, 
raw observation next is [18.1, 87.0, 1.0, 2.0, 0.21592877989939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 360056.391797975, 360056.3917979744, 157132.8464596541], 
processed observation next is [1.0, 0.0, 0.05687203791469207, 0.87, 1.0, 1.0, 0.0553358793968554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10001566438832639, 0.10001566438832622, 0.2345266365069464], 
reward next is 0.7655, 
noisyNet noise sample is [array([0.8221181], dtype=float32), -0.6165991]. 
=============================================
[2019-03-26 18:50:42,108] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7246482e-27 1.0000000e+00 4.9261710e-31 3.2874153e-30 1.6670621e-37], sum to 1.0000
[2019-03-26 18:50:42,118] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8614
[2019-03-26 18:50:42,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 57.0, 1.0, 2.0, 0.2372704020837894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 390053.9359032724, 390053.9359032724, 159683.1448555862], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 667800.0000, 
sim time next is 668400.0000, 
raw observation next is [23.83333333333333, 58.0, 1.0, 2.0, 0.2390808087388393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 393206.1058125191, 393206.1058125191, 159851.4308128346], 
processed observation next is [1.0, 0.7391304347826086, 0.32859399684044216, 0.58, 1.0, 1.0, 0.08322989004679433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1092239182812553, 0.1092239182812553, 0.23858422509378296], 
reward next is 0.7614, 
noisyNet noise sample is [array([0.9534318], dtype=float32), 0.14887457]. 
=============================================
[2019-03-26 18:50:44,861] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.8697839e-28 1.0000000e+00 3.6162773e-32 9.2799008e-32 6.0058867e-37], sum to 1.0000
[2019-03-26 18:50:44,872] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6108
[2019-03-26 18:50:44,878] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.2, 95.33333333333334, 1.0, 2.0, 0.366633294487637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 558481.7451203557, 558481.7451203557, 171183.0095961729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1462800.0000, 
sim time next is 1463400.0000, 
raw observation next is [22.15, 95.5, 1.0, 2.0, 0.3652517941314636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 556892.7480991762, 556892.7480991769, 171062.7908768603], 
processed observation next is [0.0, 0.9565217391304348, 0.24881516587677724, 0.955, 1.0, 1.0, 0.23524312545959467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15469243002754895, 0.15469243002754915, 0.25531759832367207], 
reward next is 0.7447, 
noisyNet noise sample is [array([-0.21947585], dtype=float32), -0.89566696]. 
=============================================
[2019-03-26 18:50:44,901] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.1466504e-33 1.0000000e+00 6.3880714e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:50:44,909] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0031
[2019-03-26 18:50:44,920] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.2, 95.33333333333333, 1.0, 2.0, 0.2901553888209243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465414.2904711285, 465414.2904711285, 164636.3037502427], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1057200.0000, 
sim time next is 1057800.0000, 
raw observation next is [20.25, 95.16666666666667, 1.0, 2.0, 0.2912758945374515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466920.9517367519, 466920.9517367513, 164738.2797270654], 
processed observation next is [1.0, 0.21739130434782608, 0.1587677725118484, 0.9516666666666667, 1.0, 1.0, 0.14611553558729096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12970026437131996, 0.12970026437131982, 0.24587802944338122], 
reward next is 0.7541, 
noisyNet noise sample is [array([0.84714425], dtype=float32), 0.25346178]. 
=============================================
[2019-03-26 18:50:44,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.0667814e-33 1.0000000e+00 7.3484755e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:50:44,968] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-26 18:50:44,979] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 95.0, 1.0, 2.0, 0.2932622200729397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469811.226344271, 469811.226344271, 164936.77485295], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1058400.0000, 
sim time next is 1059000.0000, 
raw observation next is [20.35, 95.0, 1.0, 2.0, 0.3116334845821996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498790.3928910713, 498790.3928910707, 167013.0434558021], 
processed observation next is [1.0, 0.2608695652173913, 0.16350710900473947, 0.95, 1.0, 1.0, 0.1706427525086742, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13855288691418646, 0.1385528869141863, 0.24927319918776433], 
reward next is 0.7507, 
noisyNet noise sample is [array([0.84714425], dtype=float32), 0.25346178]. 
=============================================
[2019-03-26 18:50:44,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[73.988625]
 [73.964226]
 [74.03341 ]
 [74.06796 ]
 [74.06874 ]], R is [[73.76508331]
 [73.78125763]
 [73.79756927]
 [73.81386566]
 [73.83037567]].
[2019-03-26 18:50:45,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0455787e-27 1.0000000e+00 1.4316192e-31 2.9244329e-31 4.9932825e-37], sum to 1.0000
[2019-03-26 18:50:45,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1850
[2019-03-26 18:50:45,882] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.81666666666667, 96.0, 1.0, 2.0, 0.3542167051187126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544791.930782759, 544791.930782759, 170187.3006609642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1023000.0000, 
sim time next is 1023600.0000, 
raw observation next is [21.83333333333334, 96.0, 1.0, 2.0, 0.3546689625840897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 545224.731305105, 545224.7313051056, 170215.5432650581], 
processed observation next is [1.0, 0.8695652173913043, 0.23380726698262277, 0.96, 1.0, 1.0, 0.22249272600492734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15145131425141806, 0.15145131425141822, 0.25405304964934045], 
reward next is 0.7459, 
noisyNet noise sample is [array([0.31822369], dtype=float32), 0.38221133]. 
=============================================
[2019-03-26 18:50:46,619] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8640216e-33 1.0000000e+00 2.9568679e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:50:46,627] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4165
[2019-03-26 18:50:46,633] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 94.16666666666667, 1.0, 2.0, 0.3344629297533469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519782.143610795, 519782.1436107944, 168324.9827685973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1491000.0000, 
sim time next is 1491600.0000, 
raw observation next is [21.9, 93.33333333333334, 1.0, 2.0, 0.3382249340770461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524194.9318888809, 524194.9318888815, 168632.8292670927], 
processed observation next is [0.0, 0.2608695652173913, 0.23696682464454974, 0.9333333333333335, 1.0, 1.0, 0.20268064346632061, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14560970330246692, 0.1456097033024671, 0.2516907899508846], 
reward next is 0.7483, 
noisyNet noise sample is [array([-0.5190381], dtype=float32), -0.6263711]. 
=============================================
[2019-03-26 18:50:54,309] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8309148e-34 1.0000000e+00 1.2656738e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:50:54,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4553
[2019-03-26 18:50:54,323] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 87.66666666666667, 1.0, 2.0, 0.2817372280340162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 453932.0935879869, 453932.0935879875, 163863.0852093133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 879600.0000, 
sim time next is 880200.0000, 
raw observation next is [20.85, 87.5, 1.0, 2.0, 0.2801559704741876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 451697.7751915869, 451697.7751915863, 163713.5292860979], 
processed observation next is [0.0, 0.17391304347826086, 0.18720379146919444, 0.875, 1.0, 1.0, 0.13271803671588867, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12547160421988524, 0.12547160421988507, 0.24434855117328047], 
reward next is 0.7557, 
noisyNet noise sample is [array([-0.4331944], dtype=float32), 1.052845]. 
=============================================
[2019-03-26 18:51:06,373] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3002463e-31 1.0000000e+00 1.5202497e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:51:06,384] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2530
[2019-03-26 18:51:06,389] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 93.66666666666667, 1.0, 2.0, 0.2836976881972058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 458312.5188377349, 458312.5188377356, 164155.6497084287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1136400.0000, 
sim time next is 1137000.0000, 
raw observation next is [19.95, 93.83333333333334, 1.0, 2.0, 0.2808686411031585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 453996.2622211621, 453996.2622211621, 163863.8587897993], 
processed observation next is [1.0, 0.13043478260869565, 0.14454976303317538, 0.9383333333333335, 1.0, 1.0, 0.13357667602790183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1261100728392117, 0.1261100728392117, 0.24457292356686464], 
reward next is 0.7554, 
noisyNet noise sample is [array([-0.06376069], dtype=float32), -0.1352773]. 
=============================================
[2019-03-26 18:51:06,402] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.294945]
 [74.27707 ]
 [74.27119 ]
 [74.3574  ]
 [74.68935 ]], R is [[74.31577301]
 [74.3276062 ]
 [74.33847809]
 [74.34838867]
 [74.35383606]].
[2019-03-26 18:51:11,761] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.463756e-33 1.000000e+00 9.325843e-35 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 18:51:11,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8498
[2019-03-26 18:51:11,776] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.75, 95.0, 1.0, 2.0, 0.2733931952874039, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442485.7190894212, 442485.7190894217, 163098.7140368371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1139400.0000, 
sim time next is 1140000.0000, 
raw observation next is [19.7, 95.33333333333334, 1.0, 2.0, 0.2741422420791134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 443789.9161265534, 443789.9161265541, 163183.2810948429], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.9533333333333335, 1.0, 1.0, 0.12547258081820892, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12327497670182039, 0.12327497670182058, 0.2435571359624521], 
reward next is 0.7564, 
noisyNet noise sample is [array([0.96578467], dtype=float32), 0.9239436]. 
=============================================
[2019-03-26 18:51:11,793] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[74.04945 ]
 [74.099686]
 [74.1471  ]
 [73.99786 ]
 [73.94363 ]], R is [[73.9633255 ]
 [73.98026276]
 [73.99739838]
 [74.01386261]
 [74.02938843]].
[2019-03-26 18:51:14,262] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2330665e-28 1.0000000e+00 1.3522220e-32 3.6665737e-33 1.2113027e-37], sum to 1.0000
[2019-03-26 18:51:14,270] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8837
[2019-03-26 18:51:14,276] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 86.0, 1.0, 2.0, 0.3561579235170261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547306.5807380031, 547306.5807380031, 170382.9207291479], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1544400.0000, 
sim time next is 1545000.0000, 
raw observation next is [23.01666666666667, 86.33333333333334, 1.0, 2.0, 0.3546292568524378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545452.6811591123, 545452.6811591123, 170242.9482322007], 
processed observation next is [0.0, 0.9130434782608695, 0.2898894154818327, 0.8633333333333334, 1.0, 1.0, 0.22244488777402144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15151463365530896, 0.15151463365530896, 0.25409395258537415], 
reward next is 0.7459, 
noisyNet noise sample is [array([0.2945865], dtype=float32), -0.15778428]. 
=============================================
[2019-03-26 18:51:14,299] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.51586 ]
 [77.4151  ]
 [77.41941 ]
 [77.420975]
 [77.4328  ]], R is [[77.5002594 ]
 [77.4709549 ]
 [77.44174957]
 [77.41273499]
 [77.38404083]].
[2019-03-26 18:51:15,478] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3461658e-24 1.0000000e+00 2.5505545e-28 9.3654530e-27 2.4533340e-33], sum to 1.0000
[2019-03-26 18:51:15,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2323
[2019-03-26 18:51:15,485] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 61.0, 1.0, 2.0, 0.9160060260170056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1385697.653478942, 1385697.653478942, 289429.0482113513], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1173600.0000, 
sim time next is 1174200.0000, 
raw observation next is [27.6, 60.66666666666667, 1.0, 2.0, 0.9738410104176051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1474473.84463667, 1474473.844636671, 307746.788348244], 
processed observation next is [1.0, 0.6086956521739131, 0.5071090047393366, 0.6066666666666667, 1.0, 1.0, 0.9684831450814518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4095760679546306, 0.40957606795463086, 0.4593235646988716], 
reward next is 0.5407, 
noisyNet noise sample is [array([-0.5883245], dtype=float32), 0.859632]. 
=============================================
[2019-03-26 18:51:18,454] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0959550e-30 1.0000000e+00 3.6274649e-34 3.3011641e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 18:51:18,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6280
[2019-03-26 18:51:18,469] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.65, 51.5, 1.0, 2.0, 0.3685639424325112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 556260.8394629584, 556260.8394629578, 170827.1007411704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1517400.0000, 
sim time next is 1518000.0000, 
raw observation next is [29.7, 51.66666666666667, 1.0, 2.0, 0.3714434896909298, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 559244.8657543177, 559244.8657543184, 171039.0920033883], 
processed observation next is [0.0, 0.5652173913043478, 0.6066350710900474, 0.5166666666666667, 1.0, 1.0, 0.24270299962762623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15534579604286602, 0.15534579604286622, 0.2552822268707288], 
reward next is 0.7447, 
noisyNet noise sample is [array([-0.1481772], dtype=float32), -2.1406946]. 
=============================================
[2019-03-26 18:51:18,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[76.10094]
 [76.11732]
 [76.1565 ]
 [76.09548]
 [75.98925]], R is [[76.09388733]
 [76.07798004]
 [76.06277466]
 [76.04891205]
 [76.03456879]].
[2019-03-26 18:51:20,235] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.8455964e-25 1.0000000e+00 7.6938187e-29 8.5804647e-27 4.9921827e-35], sum to 1.0000
[2019-03-26 18:51:20,245] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7724
[2019-03-26 18:51:20,253] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.2, 99.0, 1.0, 2.0, 0.4291391812672065, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 621195.0623200836, 621195.0623200836, 176011.604917373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1645200.0000, 
sim time next is 1645800.0000, 
raw observation next is [23.2, 99.0, 1.0, 2.0, 0.4299494996397497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622072.2371497632, 622072.2371497625, 176088.7344418158], 
processed observation next is [1.0, 0.043478260869565216, 0.29857819905213273, 0.99, 1.0, 1.0, 0.31319216824066226, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17279784365271197, 0.17279784365271178, 0.2628190066295758], 
reward next is 0.7372, 
noisyNet noise sample is [array([-0.01184475], dtype=float32), 1.1318828]. 
=============================================
[2019-03-26 18:51:20,416] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1768304e-26 1.0000000e+00 5.1719654e-31 3.3911222e-30 1.0880401e-36], sum to 1.0000
[2019-03-26 18:51:20,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8722
[2019-03-26 18:51:20,432] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 94.0, 1.0, 2.0, 0.3231308022277213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509013.5723045908, 509013.5723045908, 167666.8986250857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1366800.0000, 
sim time next is 1367400.0000, 
raw observation next is [21.18333333333333, 94.0, 1.0, 2.0, 0.3236282865383968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509589.5633018786, 509589.5633018792, 167706.4437487769], 
processed observation next is [1.0, 0.8260869565217391, 0.20300157977883085, 0.94, 1.0, 1.0, 0.18509432113059857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14155265647274404, 0.14155265647274423, 0.25030812499817445], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.7767738], dtype=float32), 0.6889541]. 
=============================================
[2019-03-26 18:51:21,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.0284923e-27 1.0000000e+00 5.7038738e-31 1.6459131e-29 4.0368269e-36], sum to 1.0000
[2019-03-26 18:51:21,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8262
[2019-03-26 18:51:21,035] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 90.33333333333334, 1.0, 2.0, 0.4763995910352775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665684.0783574794, 665684.0783574794, 179980.8065091273], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2061600.0000, 
sim time next is 2062200.0000, 
raw observation next is [25.15, 90.66666666666667, 1.0, 2.0, 0.4761736845432868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 665368.315175805, 665368.3151758057, 179947.0001062051], 
processed observation next is [0.0, 0.8695652173913043, 0.3909952606635071, 0.9066666666666667, 1.0, 1.0, 0.3688839572810684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18482453199327917, 0.18482453199327936, 0.2685776120988136], 
reward next is 0.7314, 
noisyNet noise sample is [array([-0.28709507], dtype=float32), -1.0830446]. 
=============================================
[2019-03-26 18:51:26,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7049976e-26 1.0000000e+00 2.1894229e-30 7.9461319e-30 3.7477811e-36], sum to 1.0000
[2019-03-26 18:51:26,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1731
[2019-03-26 18:51:26,676] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 96.0, 1.0, 2.0, 0.349355125073672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 539403.3320129109, 539403.3320129103, 169803.4621697461], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1471200.0000, 
sim time next is 1471800.0000, 
raw observation next is [21.63333333333334, 96.0, 1.0, 2.0, 0.3475423436181706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537115.7424958579, 537115.7424958579, 169630.9236938214], 
processed observation next is [0.0, 0.0, 0.2243285939968408, 0.96, 1.0, 1.0, 0.21390643809418144, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14919881735996052, 0.14919881735996052, 0.25318048312510655], 
reward next is 0.7468, 
noisyNet noise sample is [array([-1.3242155], dtype=float32), 1.3278371]. 
=============================================
[2019-03-26 18:51:28,594] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 18:51:28,596] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:51:28,596] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:51:28,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:51:28,598] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:51:28,599] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:51:28,600] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:51:28,599] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:51:28,600] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:51:28,601] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:51:28,604] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:51:28,641] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run96
[2019-03-26 18:51:28,666] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run96
[2019-03-26 18:51:28,666] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run96
[2019-03-26 18:51:28,718] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run96
[2019-03-26 18:51:28,718] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run96
[2019-03-26 18:52:21,086] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01882431], dtype=float32), 0.112202704]
[2019-03-26 18:52:21,087] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.66666666666667, 83.66666666666666, 1.0, 2.0, 0.7890441935000405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1102776.356209393, 1102776.356209393, 241239.1217206288]
[2019-03-26 18:52:21,090] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:52:21,092] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0951466e-26 1.0000000e+00 6.8392360e-30 1.1461782e-29 1.7655727e-35], sampled 0.020497001392017045
[2019-03-26 18:52:37,550] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01882431], dtype=float32), 0.112202704]
[2019-03-26 18:52:37,551] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.66666666666666, 76.5, 1.0, 2.0, 0.813570798455795, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1137073.347465906, 1137073.347465906, 247271.1869853839]
[2019-03-26 18:52:37,555] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:52:37,559] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1785460e-27 1.0000000e+00 1.1481162e-30 1.0636409e-32 1.3075397e-36], sampled 0.12583469357022148
[2019-03-26 18:53:22,836] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01882431], dtype=float32), 0.112202704]
[2019-03-26 18:53:22,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.2, 62.0, 1.0, 2.0, 0.3302193171379765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526602.0773655184, 526602.0773655191, 169110.573977417]
[2019-03-26 18:53:22,838] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:53:22,839] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.9287780e-31 1.0000000e+00 1.1505127e-33 4.8346734e-37 0.0000000e+00], sampled 0.5788125514138482
[2019-03-26 18:53:24,173] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7937.6374 3159503449.7893 1660.0000
[2019-03-26 18:53:24,575] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8265.2048 2926636655.8814 1317.0000
[2019-03-26 18:53:24,720] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8666.4936 2778835375.8206 919.0000
[2019-03-26 18:53:24,774] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8512.5872 2841109276.0891 1094.0000
[2019-03-26 18:53:24,794] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8019.9617 3005526970.8378 1718.0000
[2019-03-26 18:53:25,809] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2375000, evaluation results [2375000.0, 7937.637373322276, 3159503449.7893114, 1660.0, 8265.20481598805, 2926636655.8814464, 1317.0, 8666.493605398224, 2778835375.8205533, 919.0, 8019.9617199850245, 3005526970.837819, 1718.0, 8512.587168485139, 2841109276.0890665, 1094.0]
[2019-03-26 18:53:33,006] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2670916e-28 1.0000000e+00 7.4355014e-33 1.3122293e-32 1.5311534e-38], sum to 1.0000
[2019-03-26 18:53:33,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6457
[2019-03-26 18:53:33,014] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666666, 71.33333333333333, 1.0, 2.0, 0.3508383085864997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540471.1066668897, 540471.1066668897, 169855.8271450381], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1536000.0000, 
sim time next is 1536600.0000, 
raw observation next is [24.98333333333333, 72.66666666666667, 1.0, 2.0, 0.3519869660847456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541815.6587861795, 541815.6587861795, 169954.1801147685], 
processed observation next is [0.0, 0.782608695652174, 0.3830963665086887, 0.7266666666666667, 1.0, 1.0, 0.21926140492138024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15050434966282764, 0.15050434966282764, 0.25366295539517686], 
reward next is 0.7463, 
noisyNet noise sample is [array([-0.34286684], dtype=float32), -0.45987684]. 
=============================================
[2019-03-26 18:53:43,594] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1218049e-26 1.0000000e+00 2.3717858e-31 7.5636475e-30 9.7401158e-37], sum to 1.0000
[2019-03-26 18:53:43,603] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3944
[2019-03-26 18:53:43,606] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.4, 97.66666666666666, 1.0, 2.0, 0.4361506749226607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 630673.5411044655, 630673.5411044655, 176923.6278133883], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1982400.0000, 
sim time next is 1983000.0000, 
raw observation next is [23.45, 97.83333333333334, 1.0, 2.0, 0.4396532603462254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633903.1751191174, 633903.1751191174, 177195.574837244], 
processed observation next is [1.0, 0.9565217391304348, 0.3104265402843602, 0.9783333333333334, 1.0, 1.0, 0.32488344620027154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17608421531086593, 0.17608421531086593, 0.2644710072197672], 
reward next is 0.7355, 
noisyNet noise sample is [array([1.4519017], dtype=float32), 0.7244549]. 
=============================================
[2019-03-26 18:53:43,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[74.38007 ]
 [74.405914]
 [74.44267 ]
 [74.48348 ]
 [74.51472 ]], R is [[74.34355927]
 [74.33605957]
 [74.32918549]
 [74.32290649]
 [74.31707001]].
[2019-03-26 18:53:45,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1727849e-30 1.0000000e+00 3.9798025e-32 2.0117286e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:53:45,355] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8174
[2019-03-26 18:53:45,362] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.26666666666667, 94.0, 1.0, 2.0, 0.4728727759363205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 671381.4619885477, 671381.4619885483, 180819.8415652192], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1743600.0000, 
sim time next is 1744200.0000, 
raw observation next is [24.25, 94.0, 1.0, 2.0, 0.490176374327415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 696470.3907968022, 696470.3907968029, 183547.8172041914], 
processed observation next is [1.0, 0.17391304347826086, 0.3483412322274882, 0.94, 1.0, 1.0, 0.3857546678643554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1934639974435562, 0.19346399744355638, 0.2739519659764051], 
reward next is 0.7260, 
noisyNet noise sample is [array([1.2432723], dtype=float32), 0.57582456]. 
=============================================
[2019-03-26 18:53:48,629] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6299275e-25 1.0000000e+00 2.5693910e-29 1.5449734e-27 3.7770927e-34], sum to 1.0000
[2019-03-26 18:53:48,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2027
[2019-03-26 18:53:48,644] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.63333333333333, 93.83333333333334, 1.0, 2.0, 0.5110489068622259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714116.6362485503, 714116.6362485496, 185345.2931599961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2163000.0000, 
sim time next is 2163600.0000, 
raw observation next is [25.6, 94.0, 1.0, 2.0, 0.5105656148420609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 713441.0790447135, 713441.0790447135, 185268.0269526198], 
processed observation next is [1.0, 0.043478260869565216, 0.4123222748815167, 0.94, 1.0, 1.0, 0.410320017882001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19817807751242042, 0.19817807751242042, 0.27651944321286537], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.17216952], dtype=float32), 0.97347784]. 
=============================================
[2019-03-26 18:53:53,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.3697334e-17 1.0000000e+00 1.8582964e-21 5.8058599e-14 1.6718742e-25], sum to 1.0000
[2019-03-26 18:53:53,589] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5635
[2019-03-26 18:53:53,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2043159.413848122 W.
[2019-03-26 18:53:53,601] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.6, 76.0, 1.0, 2.0, 0.8200677746748062, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.998473788684025, 6.9112, 168.912441389997, 2043159.413848122, 1981244.573241034, 413140.9182365512], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2196000.0000, 
sim time next is 2196600.0000, 
raw observation next is [29.7, 75.5, 1.0, 2.0, 0.506615205154, 1.0, 1.0, 0.506615205154, 1.0, 2.0, 0.8798230711439892, 6.911200000000001, 6.9112, 170.5573041426782, 2125154.051567139, 2125154.051567139, 419750.4024759541], 
processed observation next is [1.0, 0.43478260869565216, 0.6066350710900474, 0.755, 1.0, 1.0, 0.4055604881373494, 1.0, 0.5, 0.4055604881373494, 1.0, 1.0, 0.8534427696877916, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5903205698797609, 0.5903205698797609, 0.6264931380238121], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17172314], dtype=float32), -0.55906546]. 
=============================================
[2019-03-26 18:54:04,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.7124397e-29 1.0000000e+00 1.2905946e-32 9.4946681e-34 2.5006182e-38], sum to 1.0000
[2019-03-26 18:54:04,264] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9043
[2019-03-26 18:54:04,270] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.43333333333334, 86.16666666666667, 1.0, 2.0, 0.4998102840773837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698407.130317596, 698407.130317596, 183566.4228598553], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2049000.0000, 
sim time next is 2049600.0000, 
raw observation next is [26.36666666666667, 86.33333333333334, 1.0, 2.0, 0.4983523519080267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 696369.2291284859, 696369.2291284852, 183338.3804753035], 
processed observation next is [0.0, 0.7391304347826086, 0.4486571879936811, 0.8633333333333334, 1.0, 1.0, 0.39560524326268276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19343589698013497, 0.19343589698013477, 0.2736393738437366], 
reward next is 0.7264, 
noisyNet noise sample is [array([1.1120855], dtype=float32), -1.5433552]. 
=============================================
[2019-03-26 18:54:05,771] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.4813219e-32 1.0000000e+00 1.1463196e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:54:05,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7656
[2019-03-26 18:54:05,784] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.01666666666667, 96.83333333333334, 1.0, 2.0, 0.4598223004457416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649923.4768743078, 649923.4768743071, 178497.0319980301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2087400.0000, 
sim time next is 2088000.0000, 
raw observation next is [24.0, 97.0, 1.0, 2.0, 0.460795891596776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651176.1322495863, 651176.1322495863, 178624.0099571674], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.97, 1.0, 1.0, 0.3503564958997301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1808822589582184, 0.1808822589582184, 0.2666029999360708], 
reward next is 0.7334, 
noisyNet noise sample is [array([-0.24359287], dtype=float32), 2.2848942]. 
=============================================
[2019-03-26 18:54:05,795] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.673584]
 [73.82294 ]
 [74.0011  ]
 [74.19806 ]
 [74.47261 ]], R is [[73.62145996]
 [73.61883545]
 [73.61643982]
 [73.61418152]
 [73.61198425]].
[2019-03-26 18:54:15,752] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6515814e-25 1.0000000e+00 1.2324969e-29 1.3219244e-27 2.1808638e-36], sum to 1.0000
[2019-03-26 18:54:15,763] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5624
[2019-03-26 18:54:15,769] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.23333333333334, 81.0, 1.0, 2.0, 0.5402690607811881, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754962.0681075352, 754962.0681075352, 190145.7248019612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2334000.0000, 
sim time next is 2334600.0000, 
raw observation next is [28.2, 81.0, 1.0, 2.0, 0.5387324590898745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752814.0882196674, 752814.0882196674, 189886.9997333332], 
processed observation next is [1.0, 0.0, 0.5355450236966824, 0.81, 1.0, 1.0, 0.44425597480707774, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20911502450546318, 0.20911502450546318, 0.28341343243781075], 
reward next is 0.7166, 
noisyNet noise sample is [array([-0.34251595], dtype=float32), 1.1398593]. 
=============================================
[2019-03-26 18:54:20,138] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7043074e-27 1.0000000e+00 2.9214890e-31 1.1401989e-30 9.9047856e-38], sum to 1.0000
[2019-03-26 18:54:20,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3123
[2019-03-26 18:54:20,160] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.4, 79.0, 1.0, 2.0, 0.5655846257790007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790350.7349213045, 790350.7349213045, 194509.6589926694], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2323800.0000, 
sim time next is 2324400.0000, 
raw observation next is [29.3, 79.33333333333333, 1.0, 2.0, 0.5631109198253339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 786892.6856301264, 786892.6856301264, 194074.9688327717], 
processed observation next is [1.0, 0.9130434782608695, 0.5876777251184835, 0.7933333333333333, 1.0, 1.0, 0.4736276142473902, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.218581301563924, 0.218581301563924, 0.2896641325862264], 
reward next is 0.7103, 
noisyNet noise sample is [array([0.6287805], dtype=float32), 0.8078667]. 
=============================================
[2019-03-26 18:54:22,209] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 18:54:22,211] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:54:22,214] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:54:22,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:54:22,215] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:54:22,215] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:54:22,216] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:54:22,217] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:54:22,216] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:54:22,219] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:54:22,220] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:54:22,251] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run97
[2019-03-26 18:54:22,280] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run97
[2019-03-26 18:54:22,281] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run97
[2019-03-26 18:54:22,304] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run97
[2019-03-26 18:54:22,367] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run97
[2019-03-26 18:54:24,909] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.019244], dtype=float32), 0.11216716]
[2019-03-26 18:54:24,912] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.03710891833333, 91.40932385333333, 1.0, 2.0, 0.4793847404682346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675639.0519905912, 675639.0519905912, 181173.9631591308]
[2019-03-26 18:54:24,915] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:54:24,917] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.06362476e-32 1.00000000e+00 4.20233232e-35 0.00000000e+00
 0.00000000e+00], sampled 0.24738172331863983
[2019-03-26 18:54:25,298] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.019244], dtype=float32), 0.11216716]
[2019-03-26 18:54:25,299] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.43333333333333, 50.33333333333334, 1.0, 2.0, 0.2531299174220856, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419458.7525905631, 419458.7525905631, 161058.8583338517]
[2019-03-26 18:54:25,300] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:54:25,303] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4433430e-31 1.0000000e+00 1.2125945e-34 8.9015859e-38 0.0000000e+00], sampled 0.6562338233869632
[2019-03-26 18:55:39,644] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.019244], dtype=float32), 0.11216716]
[2019-03-26 18:55:39,644] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.84840342666667, 86.34480009666667, 1.0, 2.0, 1.04, 1.0, 1.0, 1.04, 1.0, 1.0, 1.03, 7.587204585374542, 6.9112, 184.5923449428631, 4264533.365971715, 3740435.225224774, 707521.9670007408]
[2019-03-26 18:55:39,646] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:55:39,648] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.6227743e-13 1.0000000e+00 2.2765841e-18 2.8170466e-10 1.2341485e-21], sampled 0.3138816113893905
[2019-03-26 18:55:39,648] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4264533.365971715 W.
[2019-03-26 18:55:47,005] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.019244], dtype=float32), 0.11216716]
[2019-03-26 18:55:47,006] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.45639281333333, 69.88684525833334, 1.0, 2.0, 0.4964020402133163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 693643.0847351671, 693643.0847351677, 183033.3164288871]
[2019-03-26 18:55:47,008] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:55:47,011] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1521315e-30 1.0000000e+00 7.0769177e-34 2.7703974e-35 0.0000000e+00], sampled 0.1215340693972875
[2019-03-26 18:55:50,480] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.019244], dtype=float32), 0.11216716]
[2019-03-26 18:55:50,481] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.047475325, 64.71977809333333, 1.0, 2.0, 0.8404006008024866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1174592.303576992, 1174592.303576993, 254067.0665180883]
[2019-03-26 18:55:50,483] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:55:50,489] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0232730e-27 1.0000000e+00 6.6992025e-31 2.6080787e-31 1.1597690e-36], sampled 0.5014613926372228
[2019-03-26 18:56:17,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.0344 2779125306.4115 928.0000
[2019-03-26 18:56:18,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7900.4407 3163434799.3037 1753.0000
[2019-03-26 18:56:18,500] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8000.4822 3007306150.5817 1762.0000
[2019-03-26 18:56:18,595] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.9538 2927344822.9032 1336.0000
[2019-03-26 18:56:18,649] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.4845 2842491920.3745 1128.0000
[2019-03-26 18:56:19,667] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2400000, evaluation results [2400000.0, 7900.440709249196, 3163434799.3037014, 1753.0, 8255.953789433284, 2927344822.903239, 1336.0, 8662.034413046234, 2779125306.4114957, 928.0, 8000.482188502659, 3007306150.5817437, 1762.0, 8498.484524682353, 2842491920.3744774, 1128.0]
[2019-03-26 18:56:20,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1279904e-30 1.0000000e+00 4.1434853e-34 1.0490357e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:56:20,574] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2830
[2019-03-26 18:56:20,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.03333333333333, 73.16666666666667, 1.0, 2.0, 0.5830151288377925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 814717.5470553037, 814717.547055303, 197624.7943381713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2404200.0000, 
sim time next is 2404800.0000, 
raw observation next is [30.9, 74.0, 1.0, 2.0, 0.5853945592538875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 818043.8933791202, 818043.8933791202, 198056.8348316016], 
processed observation next is [1.0, 0.8695652173913043, 0.6635071090047393, 0.74, 1.0, 1.0, 0.5004753725950452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22723441482753337, 0.22723441482753337, 0.29560721616656954], 
reward next is 0.7044, 
noisyNet noise sample is [array([1.8031952], dtype=float32), 0.028235363]. 
=============================================
[2019-03-26 18:56:31,734] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4263304e-21 1.0000000e+00 4.0949496e-25 2.1679572e-21 1.6632632e-30], sum to 1.0000
[2019-03-26 18:56:31,742] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2223
[2019-03-26 18:56:31,754] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1690664.646581693 W.
[2019-03-26 18:56:31,761] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.5, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.24491692381863, 6.9112, 168.9110318731211, 1690664.646581693, 1453917.072767633, 311347.5032939774], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3166200.0000, 
sim time next is 3166800.0000, 
raw observation next is [26.66666666666667, 84.0, 1.0, 2.0, 0.5416725455243105, 1.0, 1.0, 0.5416725455243105, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1514377.290227444, 1514377.290227444, 313699.8581781738], 
processed observation next is [1.0, 0.6521739130434783, 0.4628751974723541, 0.84, 1.0, 1.0, 0.44779824761965126, 1.0, 0.5, 0.44779824761965126, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4206603583965122, 0.4206603583965122, 0.4682087435495131], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33839995], dtype=float32), -0.10424376]. 
=============================================
[2019-03-26 18:56:41,002] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.3501405e-32 1.0000000e+00 5.8669457e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:56:41,011] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3260
[2019-03-26 18:56:41,015] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333333, 71.33333333333333, 1.0, 2.0, 0.5411709263616752, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756222.7671212461, 756222.7671212461, 190299.097676928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3321600.0000, 
sim time next is 3322200.0000, 
raw observation next is [30.66666666666667, 70.66666666666667, 1.0, 2.0, 0.5483562756823022, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766267.0699559365, 766267.0699559372, 191520.2590257182], 
processed observation next is [0.0, 0.43478260869565216, 0.6524486571879939, 0.7066666666666667, 1.0, 1.0, 0.45585093455699055, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21285196387664904, 0.21285196387664923, 0.28585113287420627], 
reward next is 0.7141, 
noisyNet noise sample is [array([0.38140416], dtype=float32), 0.6002812]. 
=============================================
[2019-03-26 18:56:42,963] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.18606373e-28 1.00000000e+00 1.16393755e-32 1.20626585e-32
 1.44109870e-38], sum to 1.0000
[2019-03-26 18:56:42,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6726
[2019-03-26 18:56:42,979] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3930914692769988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 586550.9406073227, 586550.9406073234, 173302.0483535628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3112200.0000, 
sim time next is 3112800.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3899718470832311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581896.8657064831, 581896.8657064831, 172879.0009968217], 
processed observation next is [1.0, 0.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.26502632178702545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16163801825180088, 0.16163801825180088, 0.2580283596967488], 
reward next is 0.7420, 
noisyNet noise sample is [array([-0.06720034], dtype=float32), 1.4613268]. 
=============================================
[2019-03-26 18:56:47,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5798551e-29 1.0000000e+00 7.0730083e-33 1.6296590e-34 0.0000000e+00], sum to 1.0000
[2019-03-26 18:56:47,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3898
[2019-03-26 18:56:47,869] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5536995296431312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875339.9862590366, 875339.9862590366, 204110.5342874565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2998800.0000, 
sim time next is 2999400.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.3604358247515858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 570259.3613013607, 570259.3613013614, 172624.7549877047], 
processed observation next is [1.0, 0.7391304347826086, 0.1864139020537123, 0.95, 1.0, 1.0, 0.229440752712754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15840537813926686, 0.15840537813926703, 0.25764888804135033], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.55849], dtype=float32), 1.3063788]. 
=============================================
[2019-03-26 18:56:49,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2989610e-31 1.0000000e+00 2.9043391e-34 1.2871111e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:56:49,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5940
[2019-03-26 18:56:49,321] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3030254175235287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 482550.5332816411, 482550.5332816406, 165804.8657590378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3022800.0000, 
sim time next is 3023400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3028285612138949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 482237.5283235412, 482237.5283235412, 165782.3666037986], 
processed observation next is [1.0, 1.0, 0.1469194312796209, 1.0, 1.0, 1.0, 0.1600344111010782, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13395486897876144, 0.13395486897876144, 0.24743636806537106], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.25481716], dtype=float32), -0.19718876]. 
=============================================
[2019-03-26 18:56:50,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3974652e-25 1.0000000e+00 1.7983417e-29 2.2802033e-30 3.1714922e-36], sum to 1.0000
[2019-03-26 18:56:50,973] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3267
[2019-03-26 18:56:50,977] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.8317339011161643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1206943.347008117, 1206943.347008117, 258127.1202715261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3075600.0000, 
sim time next is 3076200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.8235318903294749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1195045.921058673, 1195045.921058672, 255959.9240597442], 
processed observation next is [1.0, 0.6086956521739131, 0.28909952606635075, 1.0, 1.0, 1.0, 0.7873878196740661, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3319572002940758, 0.33195720029407555, 0.38202973740260326], 
reward next is 0.6180, 
noisyNet noise sample is [array([0.49197984], dtype=float32), 0.11841292]. 
=============================================
[2019-03-26 18:56:59,934] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9942529e-30 1.0000000e+00 5.2711297e-34 4.5966442e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:56:59,943] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-26 18:56:59,948] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3849212062235661, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579764.8643923954, 579764.8643923948, 172854.1836680601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3106200.0000, 
sim time next is 3106800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3857020380339127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580940.6695455962, 580940.6695455955, 172959.6041456942], 
processed observation next is [1.0, 1.0, 0.2417061611374408, 1.0, 1.0, 1.0, 0.25988197353483455, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16137240820711007, 0.16137240820710988, 0.2581486629040212], 
reward next is 0.7419, 
noisyNet noise sample is [array([-1.3101695], dtype=float32), -0.886863]. 
=============================================
[2019-03-26 18:57:05,225] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6466592e-28 1.0000000e+00 1.5331453e-32 1.3792814e-32 3.1061868e-38], sum to 1.0000
[2019-03-26 18:57:05,234] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0318
[2019-03-26 18:57:05,239] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4894258108128207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683891.7731756506, 683891.77317565, 181955.7322039544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4874377884848182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681112.9495931175, 681112.9495931175, 181651.1779037188], 
processed observation next is [1.0, 1.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.3824551668491786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18919804155364373, 0.18919804155364373, 0.2711211610503266], 
reward next is 0.7289, 
noisyNet noise sample is [array([-0.96036035], dtype=float32), 1.1118969]. 
=============================================
[2019-03-26 18:57:05,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.84703 ]
 [75.783714]
 [75.704155]
 [75.5006  ]
 [75.381996]], R is [[75.88076782]
 [75.85038757]
 [75.81972504]
 [75.78876495]
 [75.75717926]].
[2019-03-26 18:57:12,210] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1330096e-31 1.0000000e+00 4.4510269e-35 5.2219701e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:57:12,219] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4082
[2019-03-26 18:57:12,225] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333333, 66.33333333333334, 1.0, 2.0, 0.5509519625397519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769895.5689331697, 769895.5689331697, 191964.5982093485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3609600.0000, 
sim time next is 3610200.0000, 
raw observation next is [31.16666666666667, 66.16666666666666, 1.0, 2.0, 0.5461988551441728, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763251.2309266883, 763251.2309266883, 191151.2970614113], 
processed observation next is [1.0, 0.782608695652174, 0.6761453396524489, 0.6616666666666666, 1.0, 1.0, 0.45325163270382257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21201423081296897, 0.21201423081296897, 0.28530044337524074], 
reward next is 0.7147, 
noisyNet noise sample is [array([-0.6194704], dtype=float32), 0.49162802]. 
=============================================
[2019-03-26 18:57:16,193] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 18:57:16,196] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 18:57:16,198] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 18:57:16,200] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 18:57:16,200] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:57:16,201] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:57:16,202] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 18:57:16,200] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:57:16,205] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:57:16,202] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 18:57:16,208] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 18:57:16,230] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run98
[2019-03-26 18:57:16,262] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run98
[2019-03-26 18:57:16,263] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run98
[2019-03-26 18:57:16,265] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run98
[2019-03-26 18:57:16,265] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run98
[2019-03-26 18:57:27,688] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:57:27,692] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.6, 54.0, 1.0, 2.0, 0.9308975448441527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1301153.550190576, 1301153.550190575, 278574.5924102966]
[2019-03-26 18:57:27,694] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 18:57:27,697] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.4581527e-25 1.0000000e+00 8.3319593e-29 2.4063382e-28 2.5694334e-34], sampled 0.09734517337547444
[2019-03-26 18:57:51,527] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:57:51,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.4, 64.0, 1.0, 2.0, 0.8446408251537172, 1.0, 2.0, 0.8446408251537172, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2362309.0102449, 2362309.0102449, 442192.2702682525]
[2019-03-26 18:57:51,531] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:57:51,534] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4340659e-11 1.0819316e-02 7.8972913e-19 9.8918062e-01 1.8491080e-19], sampled 0.8369960806498352
[2019-03-26 18:58:07,284] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:58:07,285] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.250064895, 63.03195780999999, 1.0, 2.0, 0.927910821579003, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005989500435398, 6.9112, 168.9123159464078, 2194104.232901529, 2126857.553908555, 441910.3162972688]
[2019-03-26 18:58:07,286] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 18:58:07,289] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5949565e-15 1.0000000e+00 8.7863464e-22 3.7588106e-11 2.3191329e-24], sampled 0.5741128049899763
[2019-03-26 18:58:07,291] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2194104.232901529 W.
[2019-03-26 18:58:13,203] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:58:13,204] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.48355738, 87.94219607, 1.0, 2.0, 0.5768681245648658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 806124.3349157182, 806124.3349157182, 196516.1494615905]
[2019-03-26 18:58:13,206] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:58:13,210] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5607858e-32 1.0000000e+00 6.5866783e-35 0.0000000e+00 0.0000000e+00], sampled 0.08976443139550416
[2019-03-26 18:58:18,980] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:58:18,982] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.8, 62.33333333333333, 1.0, 2.0, 0.5423786454513385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757911.0146956397, 757911.0146956403, 190502.5708400073]
[2019-03-26 18:58:18,987] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 18:58:18,990] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2592010e-28 1.0000000e+00 3.7244722e-32 1.8390892e-33 5.1722829e-38], sampled 0.4545737022277597
[2019-03-26 18:58:55,357] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:58:55,359] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.52823727666667, 56.36024358333334, 1.0, 2.0, 0.2759347915876992, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 452507.4554173943, 452507.455417395, 163579.5547429321]
[2019-03-26 18:58:55,360] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 18:58:55,363] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1652448e-30 1.0000000e+00 3.5134463e-34 4.2360489e-36 0.0000000e+00], sampled 0.9587528218652884
[2019-03-26 18:59:00,984] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01804835], dtype=float32), 0.11394599]
[2019-03-26 18:59:00,986] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.8, 90.83333333333334, 1.0, 2.0, 0.493529391876577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689627.7115367845, 689627.7115367845, 182588.9488568095]
[2019-03-26 18:59:00,986] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 18:59:00,989] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.6393581e-33 1.0000000e+00 3.8729356e-35 0.0000000e+00 0.0000000e+00], sampled 0.2005728638175427
[2019-03-26 18:59:12,086] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.6239 2842253327.9126 1122.0000
[2019-03-26 18:59:12,113] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.0800 2779102439.6976 927.0000
[2019-03-26 18:59:12,122] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7906.0585 3162293861.0660 1734.0000
[2019-03-26 18:59:12,304] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.2327 2927050923.1470 1331.0000
[2019-03-26 18:59:12,308] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8004.4944 3007100833.5315 1752.0000
[2019-03-26 18:59:13,328] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2425000, evaluation results [2425000.0, 7906.058464275949, 3162293861.065955, 1734.0, 8258.23269834032, 2927050923.1470366, 1331.0, 8663.079993633815, 2779102439.697609, 927.0, 8004.494442143154, 3007100833.5315156, 1752.0, 8500.623881090896, 2842253327.912643, 1122.0]
[2019-03-26 18:59:14,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7476471e-10 8.9052600e-01 1.4154862e-17 1.0947396e-01 8.2568631e-19], sum to 1.0000
[2019-03-26 18:59:14,621] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2665
[2019-03-26 18:59:14,629] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2380666.912915571 W.
[2019-03-26 18:59:14,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 69.5, 1.0, 2.0, 0.851198425433759, 1.0, 2.0, 0.851198425433759, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2380666.912915571, 2380666.912915571, 445568.0941134358], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3582600.0000, 
sim time next is 3583200.0000, 
raw observation next is [31.33333333333334, 69.0, 1.0, 2.0, 0.5278703444873424, 1.0, 2.0, 0.5278703444873424, 1.0, 1.0, 0.916736218984015, 6.911199999999999, 6.9112, 170.5573041426782, 2214407.203334692, 2214407.203334692, 434954.2817672188], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.69, 1.0, 1.0, 0.431169089743786, 1.0, 1.0, 0.431169089743786, 1.0, 0.5, 0.8984588036390426, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6151131120374145, 0.6151131120374145, 0.6491854951749534], 
reward next is 0.3508, 
noisyNet noise sample is [array([-0.03830172], dtype=float32), 0.7273133]. 
=============================================
[2019-03-26 18:59:20,657] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8568971e-10 9.9849844e-01 2.9990395e-18 1.5015418e-03 2.5099035e-19], sum to 1.0000
[2019-03-26 18:59:20,665] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5336
[2019-03-26 18:59:20,676] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2650825.98560094 W.
[2019-03-26 18:59:20,682] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.6317936152838182, 1.0, 1.0, 0.6317936152838182, 1.0, 2.0, 1.03, 6.986765638319914, 6.9112, 170.5573041426782, 2650825.98560094, 2596695.245058747, 499793.8087069846], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3681000.0000, 
sim time next is 3681600.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.8952931611759517, 1.0, 2.0, 0.8952931611759517, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2504116.462238633, 2504116.462238633, 468929.0861020063], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.59, 1.0, 1.0, 0.8738471821397008, 1.0, 1.0, 0.8738471821397008, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6955879061773981, 0.6955879061773981, 0.6998941583612035], 
reward next is 0.3001, 
noisyNet noise sample is [array([0.5090005], dtype=float32), -0.8419136]. 
=============================================
[2019-03-26 18:59:22,079] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.3450399e-28 1.0000000e+00 2.3393274e-33 7.0124833e-32 0.0000000e+00], sum to 1.0000
[2019-03-26 18:59:22,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8183
[2019-03-26 18:59:22,097] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.55988969282904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782389.6767051055, 782389.676705106, 193511.9434719755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3522000.0000, 
sim time next is 3522600.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.5586218292961201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780617.3135819572, 780617.3135819572, 193291.0778714404], 
processed observation next is [1.0, 0.782608695652174, 0.6445497630331753, 0.725, 1.0, 1.0, 0.4682190714411086, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2168381426616548, 0.2168381426616548, 0.2884941460767767], 
reward next is 0.7115, 
noisyNet noise sample is [array([-0.6251545], dtype=float32), 1.3741822]. 
=============================================
[2019-03-26 18:59:31,104] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2529938e-22 1.0000000e+00 6.2088696e-27 5.5918612e-25 5.3262348e-32], sum to 1.0000
[2019-03-26 18:59:31,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3620
[2019-03-26 18:59:31,128] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1800895.632466943 W.
[2019-03-26 18:59:31,135] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.400193636850278, 6.9112, 168.9101256079742, 1800895.632466943, 1453992.530655044, 311355.9088308605], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4335600.0000, 
sim time next is 4336200.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.5944013897275555, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.913785522543783, 6.9112, 168.9125230733267, 1661920.439599504, 1660086.185626904, 363553.7498157324], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.5113269755753681, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0002585522543783192, 0.0, 0.8294378167776921, 0.4616445665554178, 0.4611350515630289, 0.5426175370384065], 
reward next is 0.4445, 
noisyNet noise sample is [array([-0.31040576], dtype=float32), 1.3774844]. 
=============================================
[2019-03-26 18:59:36,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8977245e-30 1.0000000e+00 4.6454779e-34 7.0308969e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 18:59:36,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1980
[2019-03-26 18:59:36,574] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 75.66666666666667, 1.0, 2.0, 0.4904130667426979, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 685271.7453175467, 685271.7453175472, 182107.3996066342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3712800.0000, 
sim time next is 3713400.0000, 
raw observation next is [27.5, 76.5, 1.0, 2.0, 0.4905703973505663, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 685491.6599443932, 685491.6599443926, 182131.5274935262], 
processed observation next is [1.0, 1.0, 0.5023696682464456, 0.765, 1.0, 1.0, 0.3862293943982726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19041434998455367, 0.1904143499845535, 0.27183810073660625], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.9142417], dtype=float32), 1.2422138]. 
=============================================
[2019-03-26 18:59:37,300] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9530111e-31 1.0000000e+00 1.6469075e-34 2.5727234e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 18:59:37,313] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8569
[2019-03-26 18:59:37,317] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 68.0, 1.0, 2.0, 0.5677755353998064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793413.4662478459, 793413.4662478459, 194896.0658034905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3871200.0000, 
sim time next is 3871800.0000, 
raw observation next is [31.0, 68.5, 1.0, 2.0, 0.5615181716793312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 784666.1530663765, 784666.1530663759, 193795.6428661484], 
processed observation next is [0.0, 0.8260869565217391, 0.6682464454976303, 0.685, 1.0, 1.0, 0.4717086405775074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2179628202962157, 0.21796282029621553, 0.28924722815843046], 
reward next is 0.7108, 
noisyNet noise sample is [array([0.5792174], dtype=float32), -1.9064652]. 
=============================================
[2019-03-26 18:59:44,654] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8986242e-13 1.0000000e+00 2.5877279e-20 3.1665234e-10 5.2251729e-23], sum to 1.0000
[2019-03-26 18:59:44,663] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9144
[2019-03-26 18:59:44,671] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2698009.753151438 W.
[2019-03-26 18:59:44,677] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666666, 63.5, 1.0, 2.0, 0.6448742991464013, 1.0, 2.0, 0.6430271890874633, 1.0, 1.0, 1.03, 7.005093385948375, 6.9112, 170.5573041426782, 2698009.753151438, 2630750.10145787, 504481.2017294486], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4017000.0000, 
sim time next is 4017600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.9960556065724296, 1.0, 2.0, 0.9960556065724296, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2786261.198273264, 2786261.198273264, 526607.524447368], 
processed observation next is [1.0, 0.5217391304347826, 0.7630331753554502, 0.63, 1.0, 1.0, 0.9952477187619634, 1.0, 1.0, 0.9952477187619634, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7739614439647955, 0.7739614439647955, 0.7859813797721911], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.85271615], dtype=float32), 0.30096084]. 
=============================================
[2019-03-26 18:59:44,836] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4192718e-34 1.0000000e+00 3.8818487e-38 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 18:59:44,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6253
[2019-03-26 18:59:44,849] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 77.66666666666667, 1.0, 2.0, 0.6134229029188494, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857227.1546310324, 857227.1546310324, 203273.6847184631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4130400.0000, 
sim time next is 4131000.0000, 
raw observation next is [31.0, 77.0, 1.0, 2.0, 0.6090133766131698, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851062.5981747742, 851062.5981747742, 202437.5336869241], 
processed observation next is [1.0, 0.8260869565217391, 0.6682464454976303, 0.77, 1.0, 1.0, 0.5289317790520117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23640627727077063, 0.23640627727077063, 0.3021455726670509], 
reward next is 0.6979, 
noisyNet noise sample is [array([-1.082441], dtype=float32), 0.8939358]. 
=============================================
[2019-03-26 18:59:44,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.734955]
 [72.147514]
 [72.77441 ]
 [73.181595]
 [73.83951 ]], R is [[71.41936493]
 [71.40177917]
 [71.3832016 ]
 [71.36455536]
 [71.3458252 ]].
[2019-03-26 18:59:51,096] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6695522e-30 1.0000000e+00 4.5164704e-33 2.3289126e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 18:59:51,104] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1653
[2019-03-26 18:59:51,111] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 87.5, 1.0, 2.0, 0.7967053986307002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1113489.350035161, 1113489.350035161, 243104.0109361687], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4073400.0000, 
sim time next is 4074000.0000, 
raw observation next is [27.26666666666667, 87.66666666666667, 1.0, 2.0, 0.7948406715529139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1110881.811720385, 1110881.811720385, 242648.6013289094], 
processed observation next is [1.0, 0.13043478260869565, 0.4913112164297, 0.8766666666666667, 1.0, 1.0, 0.7528200862083301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30857828103344026, 0.30857828103344026, 0.3621620915356857], 
reward next is 0.6378, 
noisyNet noise sample is [array([0.08505369], dtype=float32), -0.7238955]. 
=============================================
[2019-03-26 18:59:51,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[61.168125]
 [60.594715]
 [59.7094  ]
 [60.458843]
 [60.75861 ]], R is [[61.2553215 ]
 [61.2799263 ]
 [61.29738617]
 [61.25539398]
 [61.24304962]].
[2019-03-26 18:59:53,499] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6542013e-28 1.0000000e+00 5.4514434e-31 3.9626758e-36 3.5083917e-37], sum to 1.0000
[2019-03-26 18:59:53,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3981
[2019-03-26 18:59:53,513] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 86.5, 1.0, 2.0, 0.9740883626934729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361561.834175812, 1361561.834175812, 291136.0962604848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.9772308967099859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1365957.233263602, 1365957.233263602, 292071.0438370479], 
processed observation next is [1.0, 0.2608695652173913, 0.6050552922590839, 0.8566666666666667, 1.0, 1.0, 0.9725673454337179, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.379432564795445, 0.379432564795445, 0.43592693110007147], 
reward next is 0.5641, 
noisyNet noise sample is [array([0.24369146], dtype=float32), 0.4724695]. 
=============================================
[2019-03-26 18:59:53,530] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[54.449677]
 [54.5967  ]
 [53.4657  ]
 [53.219734]
 [51.511112]], R is [[54.6277504 ]
 [54.64694214]
 [54.67057419]
 [54.12387085]
 [53.58263397]].
[2019-03-26 19:00:01,432] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.8997721e-10 6.8172909e-02 3.2749272e-17 9.3182707e-01 1.5101954e-19], sum to 1.0000
[2019-03-26 19:00:01,438] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3874
[2019-03-26 19:00:01,442] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.83333333333334, 67.0, 1.0, 2.0, 0.8685175640222679, 1.0, 2.0, 0.7548488215253963, 1.0, 2.0, 1.03, 7.00511102337309, 6.9112, 170.5573041426782, 3167785.252038345, 3100512.965940009, 579842.456474348], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4119000.0000, 
sim time next is 4119600.0000, 
raw observation next is [34.66666666666667, 67.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.704534703277032, 6.9112, 170.5573041426782, 3478289.6590595, 2909991.740309699, 549209.4375176402], 
processed observation next is [1.0, 0.6956521739130435, 0.8420221169036337, 0.67, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.07933347032770319, 0.0, 0.8375144448122397, 0.9661915719609722, 0.8083310389749164, 0.8197155783845376], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.877377], dtype=float32), -0.16679615]. 
=============================================
[2019-03-26 19:00:03,775] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0163944e-19 1.0000000e+00 1.6640806e-24 1.4535634e-18 1.0900802e-28], sum to 1.0000
[2019-03-26 19:00:03,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3779
[2019-03-26 19:00:03,800] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2132235.615794294 W.
[2019-03-26 19:00:03,807] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.883710255731952, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990236315547882, 6.9112, 168.9124200611252, 2132235.615794294, 2076164.711400283, 430166.0074092733], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4878600.0000, 
sim time next is 4879200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.9540210246653634, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990297586826649, 6.9112, 168.9124218631763, 2230647.767825081, 2174533.395016507, 450065.5318275711], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.9446036441751366, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007909758682664858, 0.0, 0.8294373197895195, 0.6196243799514114, 0.6040370541712519, 0.6717395997426434], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3797047], dtype=float32), 0.29067212]. 
=============================================
[2019-03-26 19:00:05,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.8879534e-31 1.0000000e+00 3.0835260e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:00:05,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1398
[2019-03-26 19:00:05,948] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4857725200252103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 678785.2714381652, 678785.2714381646, 181396.6560870234], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4756800.0000, 
sim time next is 4757400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.485108267694878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 677856.794554996, 677856.794554996, 181295.4846495466], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.79, 1.0, 1.0, 0.37964851529503374, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18829355404305442, 0.18829355404305442, 0.2705902755963382], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.08852157], dtype=float32), 0.3740459]. 
=============================================
[2019-03-26 19:00:07,128] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.9800898e-25 1.0000000e+00 8.1301369e-29 4.5181147e-30 4.4792189e-34], sum to 1.0000
[2019-03-26 19:00:07,134] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8338
[2019-03-26 19:00:07,142] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.019224137043221, 6.9112, 168.9122248626646, 1530443.119138931, 1453807.410366204, 311355.8210577068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4335000.0000, 
sim time next is 4335600.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.408414623380052, 6.9112, 168.9100699466544, 1806731.664586316, 1453996.525969096, 311355.9088155664], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.04972146233800521, 0.0, 0.829425770802685, 0.5018699068295323, 0.4038879238803044, 0.46471031166502447], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.31179458], dtype=float32), -0.39081618]. 
=============================================
[2019-03-26 19:00:07,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.8502502e-35 1.0000000e+00 1.9270511e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:00:07,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5349
[2019-03-26 19:00:07,417] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5074416623186471, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 709074.3534734903, 709074.3534734909, 184769.774726508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4503000.0000, 
sim time next is 4503600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5075821942978744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709270.7916005377, 709270.7916005377, 184792.0975159945], 
processed observation next is [0.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.40672553529864386, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1970196643334827, 0.1970196643334827, 0.27580910077014104], 
reward next is 0.7242, 
noisyNet noise sample is [array([-1.3483001], dtype=float32), -0.29084077]. 
=============================================
[2019-03-26 19:00:09,650] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0880792e-28 1.0000000e+00 4.1786506e-31 3.6969470e-36 2.3523595e-38], sum to 1.0000
[2019-03-26 19:00:09,660] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5383
[2019-03-26 19:00:09,667] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.8512771823772495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1189802.557988619, 1189802.557988619, 256888.0568795293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4255200.0000, 
sim time next is 4255800.0000, 
raw observation next is [29.16666666666667, 79.00000000000001, 1.0, 2.0, 1.003181903310714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1402255.079634105, 1402255.079634106, 299898.6610264403], 
processed observation next is [1.0, 0.2608695652173913, 0.581358609794629, 0.7900000000000001, 1.0, 1.0, 1.0038336184466434, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38951529989836253, 0.3895152998983628, 0.44760994183050795], 
reward next is 0.5524, 
noisyNet noise sample is [array([-1.7266574], dtype=float32), 0.64196104]. 
=============================================
[2019-03-26 19:00:09,823] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.9469963e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:00:09,830] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-26 19:00:09,833] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.33333333333334, 65.66666666666667, 1.0, 2.0, 0.6086404693265061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850541.2721576737, 850541.2721576737, 202367.6636673483], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4308000.0000, 
sim time next is 4308600.0000, 
raw observation next is [33.16666666666666, 66.33333333333333, 1.0, 2.0, 0.6085318629347393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850389.4399952731, 850389.4399952731, 202347.0812606724], 
processed observation next is [1.0, 0.8695652173913043, 0.7709320695102682, 0.6633333333333333, 1.0, 1.0, 0.5283516420900473, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23621928888757587, 0.23621928888757587, 0.30201056904577966], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.42551392], dtype=float32), -1.2452956]. 
=============================================
[2019-03-26 19:00:09,978] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 19:00:09,980] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:00:09,981] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:00:09,981] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:00:09,983] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:00:09,983] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:00:09,984] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:00:09,985] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:00:09,985] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:00:09,986] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:00:09,988] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:00:10,009] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run99
[2019-03-26 19:00:10,037] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run99
[2019-03-26 19:00:10,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run99
[2019-03-26 19:00:10,087] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run99
[2019-03-26 19:00:10,087] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run99
[2019-03-26 19:00:13,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:00:13,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.3, 75.0, 1.0, 2.0, 0.2578552598521721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 423612.9092942144, 423612.9092942151, 161694.3753663238]
[2019-03-26 19:00:13,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:00:13,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.18138268472598784
[2019-03-26 19:00:23,537] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:00:23,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.92946326833333, 90.66964587166667, 1.0, 2.0, 0.3146967345049674, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 494115.247368684, 494115.2473686846, 166504.1280696515]
[2019-03-26 19:00:23,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:00:23,546] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4933922e-38 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.02712879866641038
[2019-03-26 19:00:32,245] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:00:32,246] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.82271339833333, 88.91010858333334, 1.0, 2.0, 0.2667997991936168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 436811.0797369443, 436811.0797369443, 162604.4272191534]
[2019-03-26 19:00:32,249] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:00:32,251] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1367557e-36 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.39771266470210864
[2019-03-26 19:00:52,266] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:00:52,267] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.5, 91.0, 1.0, 2.0, 0.5827558170493199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 894439.6703646185, 894439.6703646185, 207286.7940517343]
[2019-03-26 19:00:52,268] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:00:52,270] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4538011e-34 1.0000000e+00 1.3532926e-36 0.0000000e+00 0.0000000e+00], sampled 0.8315743203608267
[2019-03-26 19:01:01,518] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:01:01,520] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.2, 85.66666666666667, 1.0, 2.0, 0.6547808688624938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 915047.6954653427, 915047.6954653433, 211386.9642995859]
[2019-03-26 19:01:01,521] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:01:01,522] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.577815e-35 1.000000e+00 8.716075e-37 0.000000e+00 0.000000e+00], sampled 0.9999269472683658
[2019-03-26 19:01:27,789] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.01875984], dtype=float32), 0.115827575]
[2019-03-26 19:01:27,790] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 77.0, 1.0, 2.0, 0.6633004240278748, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.997862464315607, 6.9112, 168.9116743249013, 1823774.348636806, 1762293.480452387, 377208.6056044227]
[2019-03-26 19:01:27,791] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:01:27,793] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3048807e-24 1.0000000e+00 3.9929929e-29 2.8401823e-24 1.8359288e-32], sampled 0.07992270508066845
[2019-03-26 19:01:27,796] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1823774.348636806 W.
[2019-03-26 19:02:05,139] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0142 3007608811.4011 1766.0000
[2019-03-26 19:02:05,518] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 19:02:05,583] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164139523.4469 1778.0000
[2019-03-26 19:02:05,831] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 19:02:05,865] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 19:02:06,881] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2450000, evaluation results [2450000.0, 7883.41881391125, 3164139523.4469013, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7999.014205657292, 3007608811.4011106, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 19:02:18,864] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4270641e-34 1.0000000e+00 1.7918838e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:02:18,872] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9796
[2019-03-26 19:02:18,882] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5181319455756227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724017.5273238159, 724017.5273238159, 186485.7547262563], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4744800.0000, 
sim time next is 4745400.0000, 
raw observation next is [27.83333333333334, 79.83333333333334, 1.0, 2.0, 0.5171077194339162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722585.8265663391, 722585.8265663391, 186319.9044311771], 
processed observation next is [1.0, 0.9565217391304348, 0.5181674565560824, 0.7983333333333335, 1.0, 1.0, 0.4182020716071279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20071828515731643, 0.20071828515731643, 0.27808940959877176], 
reward next is 0.7219, 
noisyNet noise sample is [array([-1.3365436], dtype=float32), 0.15917261]. 
=============================================
[2019-03-26 19:02:22,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.541849e-37 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 19:02:22,312] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2254
[2019-03-26 19:02:22,315] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5308752258061428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741830.7118224282, 741830.7118224282, 188575.3002265263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5076000.0000, 
sim time next is 5076600.0000, 
raw observation next is [29.83333333333333, 70.66666666666667, 1.0, 2.0, 0.5286455297675907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738713.9113636625, 738713.9113636625, 188206.3161386328], 
processed observation next is [0.0, 0.782608695652174, 0.6129541864139019, 0.7066666666666667, 1.0, 1.0, 0.4321030479127599, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20519830871212846, 0.20519830871212846, 0.280904949460646], 
reward next is 0.7191, 
noisyNet noise sample is [array([0.59729177], dtype=float32), -1.1753051]. 
=============================================
[2019-03-26 19:02:27,867] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.7428552e-34 1.0000000e+00 3.0441463e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:02:27,873] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4086
[2019-03-26 19:02:27,880] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.522030387685166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729466.9299233659, 729466.9299233659, 187119.5133566575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5171400.0000, 
sim time next is 5172000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5215470822073178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728791.3441453838, 728791.3441453838, 187040.6993559272], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4235507014545998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20244204004038438, 0.20244204004038438, 0.27916522291929435], 
reward next is 0.7208, 
noisyNet noise sample is [array([-0.29782334], dtype=float32), 0.06324004]. 
=============================================
[2019-03-26 19:02:27,893] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.56671 ]
 [74.55725 ]
 [74.593544]
 [74.61373 ]
 [74.51678 ]], R is [[74.56214142]
 [74.53723907]
 [74.51237488]
 [74.48781586]
 [74.46383667]].
[2019-03-26 19:02:35,939] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7228298e-32 1.0000000e+00 5.4561576e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:02:35,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2532
[2019-03-26 19:02:35,956] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.7580254610233658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1059402.628320965, 1059402.628320965, 233868.611976253], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4683000.0000, 
sim time next is 4683600.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7433204213897285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1038841.079339711, 1038841.079339712, 230473.8937004936], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.6907474956502754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28856696648325303, 0.28856696648325336, 0.34399088612013967], 
reward next is 0.6560, 
noisyNet noise sample is [array([-1.8520025], dtype=float32), -0.73634255]. 
=============================================
[2019-03-26 19:02:44,902] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9290093e-35 1.0000000e+00 1.1253174e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:02:44,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9673
[2019-03-26 19:02:44,919] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 63.66666666666666, 1.0, 2.0, 0.5272032012877225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736697.7445281718, 736697.7445281718, 187968.524784506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5137800.0000, 
sim time next is 5138400.0000, 
raw observation next is [31.33333333333334, 64.33333333333334, 1.0, 2.0, 0.5341207986210382, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746367.5810222572, 746367.5810222572, 189115.5088919639], 
processed observation next is [0.0, 0.4782608695652174, 0.6840442338072673, 0.6433333333333334, 1.0, 1.0, 0.4386997573747448, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20732432806173812, 0.20732432806173812, 0.28226195357009537], 
reward next is 0.7177, 
noisyNet noise sample is [array([0.4212754], dtype=float32), -0.12830946]. 
=============================================
[2019-03-26 19:02:52,057] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8954357e-31 1.0000000e+00 2.1678437e-34 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:02:52,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3788
[2019-03-26 19:02:52,071] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4780269629038127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668042.163974603, 668042.1639746025, 180235.2955815805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5015400.0000, 
sim time next is 5016000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4774453943239098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667270.4197075511, 667270.4197075511, 180153.3690864326], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37041613773965043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18535289436320865, 0.18535289436320865, 0.2688856255021382], 
reward next is 0.7311, 
noisyNet noise sample is [array([2.295451], dtype=float32), -0.071998425]. 
=============================================
[2019-03-26 19:02:52,089] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.13037 ]
 [71.10572 ]
 [71.01704 ]
 [71.00708 ]
 [70.974945]], R is [[71.18500519]
 [71.20414734]
 [71.22283173]
 [71.24069214]
 [71.25769806]].
[2019-03-26 19:03:01,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.5882701e-32 1.0000000e+00 1.2497644e-35 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:03:01,567] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8591
[2019-03-26 19:03:01,572] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.5072402645211846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708792.8360748034, 708792.8360748028, 184737.793928313], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5102400.0000, 
sim time next is 5103000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5066312681426557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 707941.5706337645, 707941.5706337652, 184641.1618322011], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.89, 1.0, 1.0, 0.4055798411357297, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1966504362871568, 0.196650436287157, 0.2755838236301509], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.1171862], dtype=float32), -0.24945739]. 
=============================================
[2019-03-26 19:03:01,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.02748 ]
 [71.03738 ]
 [71.077675]
 [71.037315]
 [71.06065 ]], R is [[71.01758575]
 [71.03168488]
 [71.04534149]
 [71.0585556 ]
 [71.07123566]].
[2019-03-26 19:03:02,049] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8446180e-11 9.9999785e-01 2.7223411e-17 2.0959601e-06 2.9204183e-20], sum to 1.0000
[2019-03-26 19:03:02,061] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2885
[2019-03-26 19:03:02,069] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2507164.298386158 W.
[2019-03-26 19:03:02,073] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 68.0, 1.0, 2.0, 0.8963817575115095, 1.0, 2.0, 0.8963817575115095, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2507164.298386158, 2507164.298386157, 469523.4806942687], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226000.0000, 
sim time next is 5226600.0000, 
raw observation next is [31.83333333333333, 67.5, 1.0, 2.0, 0.5993638156993327, 1.0, 2.0, 0.5993638156993327, 1.0, 1.0, 1.03, 6.923449567180982, 6.9112, 170.5573041426782, 2514622.863012107, 2505847.999759834, 487747.7724363846], 
processed observation next is [1.0, 0.4782608695652174, 0.7077409162717218, 0.675, 1.0, 1.0, 0.5173058020473889, 1.0, 1.0, 0.5173058020473889, 1.0, 0.5, 1.0365853658536586, 0.0012249567180981913, 0.0, 0.8375144448122397, 0.6985063508366964, 0.6960688888221761, 0.7279817499050516], 
reward next is 0.2108, 
noisyNet noise sample is [array([-0.73550427], dtype=float32), -0.09554778]. 
=============================================
[2019-03-26 19:03:03,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.01251320e-13 1.00000000e+00 6.02200100e-19 1.13692264e-10
 1.50411882e-22], sum to 1.0000
[2019-03-26 19:03:03,439] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0492
[2019-03-26 19:03:03,440] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2460935.351222879 W.
[2019-03-26 19:03:03,487] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.3, 72.0, 1.0, 2.0, 0.8798698685472953, 1.0, 2.0, 0.8798698685472953, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2460935.351222879, 2460935.351222879, 460639.7821241837], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5475600.0000, 
sim time next is 5476200.0000, 
raw observation next is [32.53333333333333, 71.33333333333333, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 9.463436968820794, 6.9112, 168.8981940637384, 4095835.948003813, 2285349.445606336, 468734.6919550229], 
processed observation next is [1.0, 0.391304347826087, 0.7409162717219588, 0.7133333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.2552236968820794, 0.0, 0.8293674547807647, 1.137732207778837, 0.6348192904462044, 0.6996040178433178], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2412832], dtype=float32), 0.6058168]. 
=============================================
[2019-03-26 19:03:03,868] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 19:03:03,869] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:03,869] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:03,871] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:03:03,873] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:03:03,875] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:03:03,874] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:03:03,876] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:03,877] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:03,877] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:03,880] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:03:03,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run100
[2019-03-26 19:03:03,916] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run100
[2019-03-26 19:03:03,917] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run100
[2019-03-26 19:03:03,934] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run100
[2019-03-26 19:03:03,952] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run100
[2019-03-26 19:03:08,394] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:03:08,398] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.2, 71.0, 1.0, 2.0, 0.2434598004227311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402881.1917056731, 402881.1917056724, 160160.9822940587]
[2019-03-26 19:03:08,398] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:03:08,401] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9556726e-35 1.0000000e+00 6.0926249e-38 0.0000000e+00 0.0000000e+00], sampled 0.81688237635187
[2019-03-26 19:03:09,080] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:03:09,080] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.99675475, 64.90765202, 1.0, 2.0, 0.2483420583369924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 410508.8297559185, 410508.8297559179, 160666.7508188254]
[2019-03-26 19:03:09,080] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:03:09,082] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.787705e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sampled 0.0023770393942490475
[2019-03-26 19:03:15,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:03:15,990] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.28333333333334, 72.0, 1.0, 2.0, 0.2879159252798174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461782.0591718462, 461782.0591718456, 164385.9963950096]
[2019-03-26 19:03:15,992] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:03:15,995] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.7083044699554505
[2019-03-26 19:03:33,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:03:33,089] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 93.0, 1.0, 2.0, 0.3990364159924159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594414.0093480262, 594414.0093480262, 173994.3703124043]
[2019-03-26 19:03:33,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:03:33,092] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0. 1. 0. 0. 0.], sampled 0.5646982408850658
[2019-03-26 19:04:10,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:04:10,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.8, 49.5, 1.0, 2.0, 0.5465795552688409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 763783.4076311524, 763783.4076311524, 191216.0038703321]
[2019-03-26 19:04:10,292] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:04:10,294] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6290904e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sampled 0.7945088031220433
[2019-03-26 19:04:35,794] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02077582], dtype=float32), 0.115692854]
[2019-03-26 19:04:35,795] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666666, 81.0, 1.0, 2.0, 0.7186115485025792, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977530395906735, 6.9112, 168.9125082353848, 1901173.258017195, 1854116.317128814, 389734.234085771]
[2019-03-26 19:04:35,798] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 19:04:35,802] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.8658190e-27 1.0000000e+00 4.6070155e-30 2.0918372e-34 4.8865736e-36], sampled 0.5466291992572089
[2019-03-26 19:04:35,803] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1901173.258017195 W.
[2019-03-26 19:04:55,081] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 19:04:55,455] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 19:04:55,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 19:04:55,617] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 19:04:55,687] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 19:04:56,705] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 2475000, evaluation results [2475000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 19:05:12,663] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1278653e-08 9.8196906e-01 1.7501352e-15 1.8030997e-02 1.4724058e-17], sum to 1.0000
[2019-03-26 19:05:12,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-26 19:05:12,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2382125.945805038 W.
[2019-03-26 19:05:12,685] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.95, 66.66666666666667, 1.0, 2.0, 0.8517196003627914, 1.0, 1.0, 0.8517196003627914, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2382125.945805038, 2382125.945805038, 445839.4035313214], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5829000.0000, 
sim time next is 5829600.0000, 
raw observation next is [32.0, 66.33333333333334, 1.0, 2.0, 0.8688623236522155, 1.0, 2.0, 0.8688623236522155, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2430118.070138487, 2430118.070138487, 454791.4755047424], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.6633333333333334, 1.0, 1.0, 0.8420027995809826, 1.0, 1.0, 0.8420027995809826, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6750327972606909, 0.6750327972606909, 0.6787932470220036], 
reward next is 0.3212, 
noisyNet noise sample is [array([-1.3563894], dtype=float32), -0.4421281]. 
=============================================
[2019-03-26 19:05:21,491] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.993281e-38 1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 19:05:21,502] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4834
[2019-03-26 19:05:21,508] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 76.66666666666667, 1.0, 2.0, 0.5231095193629334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730975.3894732237, 730975.3894732231, 187295.9904514712], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5730000.0000, 
sim time next is 5730600.0000, 
raw observation next is [28.63333333333333, 75.83333333333333, 1.0, 2.0, 0.5236745060107719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731765.1544703929, 731765.1544703934, 187388.4692998539], 
processed observation next is [0.0, 0.30434782608695654, 0.55608214849921, 0.7583333333333333, 1.0, 1.0, 0.4261138626635806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20326809846399801, 0.20326809846399818, 0.2796842825370954], 
reward next is 0.7203, 
noisyNet noise sample is [array([-1.0689996], dtype=float32), -0.6047615]. 
=============================================
[2019-03-26 19:05:22,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4413387e-33 1.0000000e+00 2.3161116e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:05:22,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5209
[2019-03-26 19:05:22,137] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 82.83333333333334, 1.0, 2.0, 0.5585933127316969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780577.4499351569, 780577.4499351569, 193285.6528329755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5946600.0000, 
sim time next is 5947200.0000, 
raw observation next is [28.5, 83.0, 1.0, 2.0, 0.5555106039364517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776268.1032273677, 776268.1032273677, 192750.558847794], 
processed observation next is [1.0, 0.8695652173913043, 0.5497630331753555, 0.83, 1.0, 1.0, 0.4644706071523514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2156300286742688, 0.2156300286742688, 0.2876874012653642], 
reward next is 0.7123, 
noisyNet noise sample is [array([1.655932], dtype=float32), 0.1265865]. 
=============================================
[2019-03-26 19:05:25,992] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9959968e-29 1.0000000e+00 3.1853420e-34 2.4741747e-37 0.0000000e+00], sum to 1.0000
[2019-03-26 19:05:25,999] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0679
[2019-03-26 19:05:26,004] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 90.33333333333334, 1.0, 2.0, 0.5390290820073553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753228.7301823727, 753228.7301823722, 189936.9319416075], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6045600.0000, 
sim time next is 6046200.0000, 
raw observation next is [26.8, 90.5, 1.0, 2.0, 0.5385516340622541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752561.3173904936, 752561.317390493, 189856.6423010804], 
processed observation next is [1.0, 1.0, 0.4691943127962086, 0.905, 1.0, 1.0, 0.444038113328017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20904481038624823, 0.20904481038624806, 0.28336812283743346], 
reward next is 0.7166, 
noisyNet noise sample is [array([-1.3745154], dtype=float32), 1.1618781]. 
=============================================
[2019-03-26 19:05:27,461] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.4200393e-31 1.0000000e+00 2.7022305e-34 1.7434102e-38 0.0000000e+00], sum to 1.0000
[2019-03-26 19:05:27,470] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6555
[2019-03-26 19:05:27,475] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 0.5262040121936707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 735301.0247756034, 735301.0247756029, 187803.544846052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5880000.0000, 
sim time next is 5880600.0000, 
raw observation next is [26.15, 93.0, 1.0, 2.0, 0.5257780160128267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734705.5451753035, 734705.545175304, 187733.5330950924], 
processed observation next is [1.0, 0.043478260869565216, 0.43838862559241704, 0.93, 1.0, 1.0, 0.4286482120636466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20408487365980651, 0.20408487365980668, 0.2801993031270036], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.5466135], dtype=float32), 1.1596764]. 
=============================================
[2019-03-26 19:05:36,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.459695e-30 1.000000e+00 4.418415e-33 0.000000e+00 0.000000e+00], sum to 1.0000
[2019-03-26 19:05:36,853] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0446
[2019-03-26 19:05:36,861] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 87.50000000000001, 1.0, 2.0, 0.658464865065084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 920198.2623011803, 920198.262301181, 212134.1025921805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6592200.0000, 
sim time next is 6592800.0000, 
raw observation next is [26.73333333333334, 87.0, 1.0, 2.0, 0.6559225515875734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 916643.8706559733, 916643.8706559733, 211617.5633366281], 
processed observation next is [1.0, 0.30434782608695654, 0.4660347551342816, 0.87, 1.0, 1.0, 0.5854488573344258, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.254623297404437, 0.254623297404437, 0.3158471094576539], 
reward next is 0.6842, 
noisyNet noise sample is [array([0.5862677], dtype=float32), 0.72262484]. 
=============================================
[2019-03-26 19:05:37,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5352665e-28 1.0000000e+00 4.6527388e-31 2.7507681e-35 1.0884422e-37], sum to 1.0000
[2019-03-26 19:05:37,327] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7159
[2019-03-26 19:05:37,331] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 95.0, 1.0, 2.0, 0.8046205679501416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1124557.586466148, 1124557.586466147, 245046.9223346355], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5889600.0000, 
sim time next is 5890200.0000, 
raw observation next is [25.68333333333333, 95.16666666666667, 1.0, 2.0, 0.6947619233359846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 970946.2365854465, 970946.2365854458, 219717.5590062633], 
processed observation next is [1.0, 0.17391304347826086, 0.41627172195892564, 0.9516666666666667, 1.0, 1.0, 0.6322432811276923, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26970728794040183, 0.2697072879404016, 0.3279366552332288], 
reward next is 0.6721, 
noisyNet noise sample is [array([0.83278507], dtype=float32), -0.56671536]. 
=============================================
[2019-03-26 19:05:41,433] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0065544e-33 1.0000000e+00 6.6512589e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 19:05:41,441] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8495
[2019-03-26 19:05:41,445] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.86666666666667, 62.66666666666666, 1.0, 2.0, 0.5167895115338861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722141.0243194941, 722141.0243194941, 186268.4968835686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6270000.0000, 
sim time next is 6270600.0000, 
raw observation next is [30.88333333333333, 62.33333333333334, 1.0, 2.0, 0.5146297733259568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719122.070858105, 719122.0708581056, 185920.072765458], 
processed observation next is [0.0, 0.5652173913043478, 0.6627172195892573, 0.6233333333333334, 1.0, 1.0, 0.4152165943686227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19975613079391805, 0.1997561307939182, 0.277492645918594], 
reward next is 0.7225, 
noisyNet noise sample is [array([-0.05641416], dtype=float32), -0.55812883]. 
=============================================
[2019-03-26 19:05:43,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5689201e-27 1.0000000e+00 8.5489801e-32 4.8286744e-33 4.7107826e-38], sum to 1.0000
[2019-03-26 19:05:43,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5752
[2019-03-26 19:05:43,971] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 91.5, 1.0, 2.0, 0.5514018941620689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770524.5275837607, 770524.5275837613, 192041.4645244369], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5959800.0000, 
sim time next is 5960400.0000, 
raw observation next is [27.0, 91.33333333333334, 1.0, 2.0, 0.5486649305677026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766698.5365819472, 766698.5365819478, 191572.0490867477], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.9133333333333334, 1.0, 1.0, 0.45622280791289466, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21297181571720755, 0.21297181571720772, 0.28592843147275776], 
reward next is 0.7141, 
noisyNet noise sample is [array([1.7978665], dtype=float32), 1.0111009]. 
=============================================
[2019-03-26 19:05:44,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0891574e-28 1.0000000e+00 4.0717394e-33 4.5081889e-34 1.4035226e-38], sum to 1.0000
[2019-03-26 19:05:44,373] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9971
[2019-03-26 19:05:44,378] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 91.0, 1.0, 2.0, 0.5601860517267772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782803.9611360257, 782803.9611360257, 193562.9574364171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5956800.0000, 
sim time next is 5957400.0000, 
raw observation next is [27.26666666666667, 91.5, 1.0, 2.0, 0.5597967599242398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782259.7644736514, 782259.764473652, 193495.0799336155], 
processed observation next is [1.0, 0.9565217391304348, 0.4913112164297, 0.915, 1.0, 1.0, 0.4696346505111323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21729437902045873, 0.2172943790204589, 0.2887986267665903], 
reward next is 0.7112, 
noisyNet noise sample is [array([1.2639245], dtype=float32), -0.5425339]. 
=============================================
[2019-03-26 19:05:46,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.2812497e-25 1.0000000e+00 3.7519017e-28 6.5509092e-31 1.2040670e-34], sum to 1.0000
[2019-03-26 19:05:46,396] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0384
[2019-03-26 19:05:46,403] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2034293.409801028 W.
[2019-03-26 19:05:46,410] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 81.5, 1.0, 2.0, 0.813732961254945, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005602195617321, 6.9112, 168.9116567916025, 2034293.409801028, 1967321.758481784, 411260.5733551186], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [29.36666666666667, 80.66666666666667, 1.0, 2.0, 0.4757077329382635, 1.0, 1.0, 0.4757077329382635, 1.0, 2.0, 0.8261470131625065, 6.911199999999999, 6.9112, 170.5573041426782, 1995382.359376298, 1995382.359376298, 398754.0983779076], 
processed observation next is [1.0, 0.34782608695652173, 0.5908372827804109, 0.8066666666666668, 1.0, 1.0, 0.3683225698051367, 1.0, 0.5, 0.3683225698051367, 1.0, 1.0, 0.7879841623933005, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5542728776045273, 0.5542728776045273, 0.5951553707132949], 
reward next is 0.4048, 
noisyNet noise sample is [array([1.1528378], dtype=float32), -0.22783327]. 
=============================================
[2019-03-26 19:05:51,763] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.9591276e-29 1.0000000e+00 4.0395772e-32 6.6726861e-36 0.0000000e+00], sum to 1.0000
[2019-03-26 19:05:51,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7911
[2019-03-26 19:05:51,776] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.38333333333333, 91.00000000000001, 1.0, 2.0, 1.002744314557542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1401643.011032975, 1401643.011032975, 299762.3359514407], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6487800.0000, 
sim time next is 6488400.0000, 
raw observation next is [26.36666666666667, 91.0, 1.0, 2.0, 0.8897702990469574, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1243634.649434489, 1243634.64943449, 267138.3405819759], 
processed observation next is [1.0, 0.08695652173913043, 0.4486571879936811, 0.91, 1.0, 1.0, 0.8671931313818764, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34545406928735806, 0.3454540692873583, 0.39871394116712816], 
reward next is 0.6013, 
noisyNet noise sample is [array([-0.48406866], dtype=float32), -0.9536994]. 
=============================================
[2019-03-26 19:05:52,612] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 19:05:52,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 19:05:52,614] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 19:05:52,615] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:05:52,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:05:52,616] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 19:05:52,617] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:05:52,617] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 19:05:52,619] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 19:05:52,620] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:05:52,620] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 19:05:53,361] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run101
[2019-03-26 19:05:53,383] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run101
[2019-03-26 19:05:53,536] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run101
[2019-03-26 19:05:53,579] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run101
[2019-03-26 19:05:53,595] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/4/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run101
[2019-03-26 19:06:27,843] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:06:27,845] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.0, 91.0, 1.0, 2.0, 0.3857049050178095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 582749.4328306179, 582749.4328306186, 173174.5009412983]
[2019-03-26 19:06:27,846] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 19:06:27,848] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3478535e-34 1.0000000e+00 6.1570436e-37 0.0000000e+00 0.0000000e+00], sampled 0.8205402938434097
[2019-03-26 19:06:44,816] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:06:44,817] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.87174526333333, 56.20348317333334, 1.0, 2.0, 0.5576965127784778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 789825.2261902029, 789825.2261902035, 194476.8465562911]
[2019-03-26 19:06:44,817] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:06:44,822] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5120292e-32 1.0000000e+00 7.6608769e-35 0.0000000e+00 0.0000000e+00], sampled 0.2524825580542289
[2019-03-26 19:06:57,523] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:06:57,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.512468665, 60.40888234833333, 1.0, 2.0, 0.8054034556598098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1125652.349641518, 1125652.349641518, 245245.4263234862]
[2019-03-26 19:06:57,531] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:06:57,537] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0566422e-29 1.0000000e+00 1.1500739e-33 4.0211983e-35 0.0000000e+00], sampled 0.493890999321965
[2019-03-26 19:07:07,453] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:07:07,455] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.26666666666667, 83.33333333333334, 1.0, 2.0, 0.5963611118099871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833374.819603787, 833374.819603787, 200069.3648897564]
[2019-03-26 19:07:07,455] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:07:07,459] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.3588394e-34 1.0000000e+00 1.3555556e-36 0.0000000e+00 0.0000000e+00], sampled 0.7676557149898032
[2019-03-26 19:07:10,418] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:07:10,419] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.04450273, 74.69267986, 1.0, 2.0, 0.6115705896869048, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.947619220087317, 6.9112, 168.9126843489547, 1709963.44782474, 1684126.441271995, 366767.0748521472]
[2019-03-26 19:07:10,421] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 19:07:10,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5350468e-18 1.0000000e+00 1.0883753e-23 1.1785397e-15 1.2222498e-26], sampled 0.04382802208565195
[2019-03-26 19:07:10,426] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1709963.44782474 W.
[2019-03-26 19:07:19,452] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:07:19,455] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.33758669666667, 77.766101765, 1.0, 2.0, 0.5862273121937708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 819208.0503626504, 819208.0503626498, 198208.6752703812]
[2019-03-26 19:07:19,457] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:07:19,458] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5892888e-27 1.0000000e+00 9.9116203e-32 2.9234958e-31 5.1853043e-37], sampled 0.7637606954382139
[2019-03-26 19:07:20,953] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:07:20,956] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.435450835, 85.06435786833333, 1.0, 2.0, 0.5431639033063768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759008.7131744624, 759008.7131744624, 190634.4304060942]
[2019-03-26 19:07:20,957] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 19:07:20,961] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8355858e-30 1.0000000e+00 7.1398273e-34 3.0318054e-36 0.0000000e+00], sampled 0.19931691945962282
[2019-03-26 19:07:44,255] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02557575], dtype=float32), 0.11406356]
[2019-03-26 19:07:44,256] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.15, 72.0, 1.0, 2.0, 0.4470543688436241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643544.394303343, 643544.394303343, 178137.2676425549]
[2019-03-26 19:07:44,257] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 19:07:44,260] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.3044604e-34 1.0000000e+00 2.3295370e-36 0.0000000e+00 0.0000000e+00], sampled 0.35721330573263
[2019-03-26 19:07:50,464] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.3443 3007602662.4975 1765.0000
[2019-03-26 19:07:50,577] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.4722 2842464925.5433 1130.0000
[2019-03-26 19:07:50,607] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4863 2779028727.3070 931.0000
[2019-03-26 19:07:50,686] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7898.1461 3162984001.5327 1752.0000
[2019-03-26 19:07:50,761] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.2283 2927386027.9381 1337.0000
[2019-03-26 19:07:51,779] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2500000, evaluation results [2500000.0, 7898.146125071384, 3162984001.532707, 1752.0, 8255.228284895658, 2927386027.9381304, 1337.0, 8660.48628172035, 2779028727.307037, 931.0, 7999.344296992757, 3007602662.497494, 1765.0, 8496.472178776363, 2842464925.543303, 1130.0]
