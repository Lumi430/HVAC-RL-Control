Using TensorFlow backend.
[2019-03-26 09:44:37,558] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='linear', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=0.0001, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[19, 1], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-26 09:44:37,558] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-26 09:44:37.591758: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-26 09:44:53,746] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-26 09:44:53,746] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-26 09:44:53,756] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-26 09:44:53,760] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-26 09:44:53,766] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-26 09:44:53,771] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-26 09:44:53,773] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-26 09:44:53,773] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:53,774] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-26 09:44:53,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:53,828] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-26 09:44:54,775] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:54,776] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-26 09:44:54,860] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:54,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-26 09:44:55,057] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 09:44:55,057] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:44:55,058] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:44:55,058] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,059] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:44:55,058] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:44:55,059] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:44:55,059] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,060] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,059] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,060] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-26 09:44:55,070] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-26 09:44:55,071] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-26 09:44:55,084] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-26 09:44:55,093] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-26 09:44:55,777] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:55,781] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-26 09:44:55,860] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:55,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-26 09:44:56,782] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:56,786] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-26 09:44:56,859] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:56,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-26 09:44:57,786] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:57,792] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-26 09:44:57,844] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:57,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-26 09:44:58,790] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:58,795] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-26 09:44:58,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:58,848] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-26 09:44:59,797] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:44:59,800] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-26 09:44:59,850] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:44:59,851] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-26 09:45:00,801] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:00,803] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-26 09:45:00,906] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:00,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-26 09:45:01,803] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:01,813] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-26 09:45:01,873] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:01,874] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-26 09:45:02,811] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:02,814] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-26 09:45:02,880] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:02,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-26 09:45:03,815] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:03,818] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-26 09:45:03,875] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:03,877] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-26 09:45:04,817] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:04,822] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-26 09:45:04,892] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:04,893] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-26 09:45:05,822] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:05,826] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-26 09:45:05,877] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:05,878] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-26 09:45:06,825] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:06,828] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-26 09:45:06,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:06,887] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-26 09:45:07,827] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:07,833] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-26 09:45:07,925] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:07,926] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-26 09:45:08,835] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-26 09:45:08,838] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-26 09:45:08,904] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:45:08,905] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-26 09:45:23,268] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:45:23,270] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.43333333333333, 85.0, 1.0, 1.0, 0.2087181152860704, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3600507814939362, 6.911199999999999, 6.9112, 168.912956510431, 614523.3305608612, 614523.3305608617, 199904.0798781225]
[2019-03-26 09:45:23,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 09:45:23,274] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.2796925  0.22322522 0.15895599 0.10090154 0.23722474], sampled 0.11951071464956775
[2019-03-26 09:45:39,987] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:45:39,989] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.6, 83.0, 1.0, 2.0, 0.7755164053200378, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1083860.12998928, 1083860.12998928, 237989.1083968088]
[2019-03-26 09:45:39,989] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:45:39,992] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.22717413 0.21538912 0.09688725 0.02775185 0.43279767], sampled 0.2665583180725486
[2019-03-26 09:45:47,907] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:45:47,908] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.99629137, 65.421304775, 1.0, 2.0, 0.8365992802850851, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1169276.433612982, 1169276.433612983, 253093.169805487]
[2019-03-26 09:45:47,908] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 09:45:47,910] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.37456882 0.12893659 0.1469121  0.03054846 0.319034  ], sampled 0.3106397350102944
[2019-03-26 09:45:47,912] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1169276.433612982 W.
[2019-03-26 09:45:53,731] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:45:53,732] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.81666666666667, 52.5, 1.0, 2.0, 0.5883937169244059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 822236.6078774574, 822236.607877458, 198602.4262693513]
[2019-03-26 09:45:53,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:45:53,736] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.37082514 0.17075758 0.2069711  0.05086474 0.20058142], sampled 0.39655712156002987
[2019-03-26 09:46:21,019] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:46:21,021] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.03333333333333, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.82147785574856, 6.9112, 168.9081532383166, 2099961.370013516, 1454197.293510975, 311353.4503020249]
[2019-03-26 09:46:21,022] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:46:21,025] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.30907232 0.09621403 0.09640328 0.03290322 0.46540713], sampled 0.3628299587541781
[2019-03-26 09:46:21,029] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2099961.370013516 W.
[2019-03-26 09:46:21,866] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:46:21,869] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.11666666666667, 88.83333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9336893656278072, 6.911200000000001, 6.9112, 168.912956510431, 764396.4356837776, 764396.435683777, 231145.888559433]
[2019-03-26 09:46:21,870] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:46:21,873] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.2507407  0.06171825 0.23383626 0.03470775 0.41899708], sampled 0.5196170925519031
[2019-03-26 09:46:35,994] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-26 09:46:35,997] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.91666666666666, 74.83333333333333, 1.0, 2.0, 0.8098111998676982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1131816.0082075, 1131816.0082075, 246337.8276758985]
[2019-03-26 09:46:35,999] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:46:36,002] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.24839944 0.14883237 0.21306501 0.05579351 0.33390966], sampled 0.9092169086243331
[2019-03-26 09:46:48,834] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3608.0734 3355234432.3108 1382.0000
[2019-03-26 09:46:48,838] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3570.0088 3211815034.9580 836.0000
[2019-03-26 09:46:48,934] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3681.1881 3301514875.6096 1053.0000
[2019-03-26 09:46:48,957] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3621.0821 3190574521.9634 726.0000
[2019-03-26 09:46:48,981] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3428.9003 3509832846.2439 1439.0000
[2019-03-26 09:46:49,995] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3428.9003294670183, 3509832846.2438993, 1439.0, 3681.188079909269, 3301514875.60956, 1053.0, 3621.0821223824237, 3190574521.9633756, 726.0, 3608.073430794615, 3355234432.3107734, 1382.0, 3570.0087728938283, 3211815034.9580274, 836.0]
[2019-03-26 09:46:52,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.16547567 0.11958414 0.14271548 0.09790405 0.47432062], sum to 1.0000
[2019-03-26 09:46:52,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2154
[2019-03-26 09:46:52,808] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 85.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1899447444572165, 6.911199999999999, 6.9112, 170.5573041426782, 501594.9515992884, 501594.951599289, 229752.4630635666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 13800.0000, 
sim time next is 14400.0000, 
raw observation next is [21.2, 85.0, 1.0, 2.0, 0.3102873735548857, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 498993.5171055532, 498993.5171055532, 167031.0358640119], 
processed observation next is [1.0, 0.17391304347826086, 0.20379146919431282, 0.85, 1.0, 1.0, 0.16902093199383822, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1386093103070981, 0.1386093103070981, 0.24930005352837598], 
reward next is 0.7507, 
noisyNet noise sample is [array([-0.01513796], dtype=float32), -1.2485536]. 
=============================================
[2019-03-26 09:46:52,997] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [0.26809293 0.14250033 0.10234855 0.06213336 0.42492476], sum to 1.0000
[2019-03-26 09:46:53,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0204
[2019-03-26 09:46:53,105] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.36666666666666, 85.83333333333334, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2615000734165177, 6.911200000000001, 6.9112, 168.912956510431, 460505.6143819303, 460505.6143819297, 185453.4862510131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 17400.0000, 
sim time next is 18000.0000, 
raw observation next is [21.4, 86.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5257952083919842, 6.911200000000001, 6.9112, 168.912956510431, 462967.1389990058, 462967.1389990051, 155403.1547720493], 
processed observation next is [1.0, 0.21739130434782608, 0.21327014218009477, 0.86, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42170147364876126, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1286019830552794, 0.1286019830552792, 0.23194500712246166], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67079115], dtype=float32), -0.96633977]. 
=============================================
[2019-03-26 09:46:53,122] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[ 0.27884665]
 [ 0.3420227 ]
 [-0.18740246]
 [-0.81667733]
 [-1.2637405 ]], R is [[0.2283112 ]
 [0.22602808]
 [0.2237678 ]
 [0.22153012]
 [0.98890996]].
[2019-03-26 09:46:59,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.02888756 0.05494646 0.00096351 0.88113546 0.03406696], sum to 1.0000
[2019-03-26 09:46:59,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7770
[2019-03-26 09:46:59,572] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.4100170203907975, 1.0, 2.0, 0.4100170203907975, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1199573.221750882, 1199573.221750882, 281069.6969526984], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 130200.0000, 
sim time next is 130800.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.2991974747105483, 1.0, 2.0, 0.2991974747105483, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 878048.2156858937, 878048.2156858937, 255262.7560672568], 
processed observation next is [1.0, 0.5217391304347826, 0.2796208530805688, 0.96, 1.0, 1.0, 0.15565960808499796, 1.0, 1.0, 0.15565960808499796, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24390228213497045, 0.24390228213497045, 0.38098918816008476], 
reward next is 0.6190, 
noisyNet noise sample is [array([-0.27454206], dtype=float32), -0.35920763]. 
=============================================
[2019-03-26 09:47:02,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2716860e-03 5.7262341e-03 2.2877971e-06 9.9159324e-01 4.0667783e-04], sum to 1.0000
[2019-03-26 09:47:02,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5653
[2019-03-26 09:47:02,499] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [20.1, 96.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 474931.9367676105, 474931.9367676105, 228522.9823487627], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 178200.0000, 
sim time next is 178800.0000, 
raw observation next is [20.06666666666667, 96.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 473207.7690304662, 473207.7690304662, 228180.4040860595], 
processed observation next is [0.0, 0.043478260869565216, 0.1500789889415484, 0.96, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.13144660250846282, 0.13144660250846282, 0.3405677672926261], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.156906], dtype=float32), -0.13347484]. 
=============================================
[2019-03-26 09:47:05,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.8391948e-03 9.8362339e-01 3.0201102e-07 9.0385964e-03 4.9846672e-04], sum to 1.0000
[2019-03-26 09:47:05,516] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2469
[2019-03-26 09:47:05,616] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 87.0, 1.0, 2.0, 0.3066416275914061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 486969.8973651897, 486969.8973651891, 166102.9276895168], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 232800.0000, 
sim time next is 233400.0000, 
raw observation next is [21.63333333333334, 87.0, 1.0, 2.0, 0.3060200551314818, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 486341.150768379, 486341.150768379, 166063.3558147697], 
processed observation next is [0.0, 0.6956521739130435, 0.2243285939968408, 0.87, 1.0, 1.0, 0.16387958449576118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13509476410232749, 0.13509476410232749, 0.24785575494741743], 
reward next is 0.7521, 
noisyNet noise sample is [array([-1.2960497], dtype=float32), 1.1795028]. 
=============================================
[2019-03-26 09:47:09,201] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7922: loss 0.6348
[2019-03-26 09:47:09,258] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7923: learning rate 0.0001
[2019-03-26 09:47:09,283] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 7934: loss 0.6455
[2019-03-26 09:47:09,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 7934: learning rate 0.0001
[2019-03-26 09:47:09,312] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 7954: loss 0.7100
[2019-03-26 09:47:09,315] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 7957: learning rate 0.0001
[2019-03-26 09:47:09,336] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7966: loss 0.6643
[2019-03-26 09:47:09,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7966: learning rate 0.0001
[2019-03-26 09:47:09,375] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7983: loss 0.7975
[2019-03-26 09:47:09,376] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7984: learning rate 0.0001
[2019-03-26 09:47:09,385] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7987: loss 0.7984
[2019-03-26 09:47:09,388] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7987: learning rate 0.0001
[2019-03-26 09:47:09,406] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 7995: loss 0.6914
[2019-03-26 09:47:09,407] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 7995: learning rate 0.0001
[2019-03-26 09:47:09,409] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7996: loss 0.5983
[2019-03-26 09:47:09,412] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7998: learning rate 0.0001
[2019-03-26 09:47:09,417] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 7999: loss 0.6509
[2019-03-26 09:47:09,419] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 7999: loss 0.6563
[2019-03-26 09:47:09,422] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 7999: loss 0.6650
[2019-03-26 09:47:09,422] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 7999: learning rate 0.0001
[2019-03-26 09:47:09,423] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 7999: learning rate 0.0001
[2019-03-26 09:47:09,425] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 7999: learning rate 0.0001
[2019-03-26 09:47:09,444] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 8004: loss 0.6476
[2019-03-26 09:47:09,445] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 8005: loss 0.7326
[2019-03-26 09:47:09,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 8006: learning rate 0.0001
[2019-03-26 09:47:09,447] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 8006: learning rate 0.0001
[2019-03-26 09:47:09,458] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 8014: loss 0.6366
[2019-03-26 09:47:09,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 8016: learning rate 0.0001
[2019-03-26 09:47:09,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 8054: loss 0.5032
[2019-03-26 09:47:09,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 8055: learning rate 0.0001
[2019-03-26 09:47:09,552] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8061: loss 0.6357
[2019-03-26 09:47:09,556] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8061: learning rate 0.0001
[2019-03-26 09:47:10,691] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.2575191e-08 9.9999845e-01 3.8099979e-17 1.5750346e-06 9.2229190e-11], sum to 1.0000
[2019-03-26 09:47:10,697] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9234
[2019-03-26 09:47:10,704] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 79.33333333333334, 1.0, 2.0, 0.298073151873832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 474982.3846607098, 474982.3846607105, 165269.4648284748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 321000.0000, 
sim time next is 321600.0000, 
raw observation next is [22.46666666666667, 79.66666666666667, 1.0, 2.0, 0.297148701371844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473710.9967790074, 473710.9967790081, 165182.6205214337], 
processed observation next is [0.0, 0.7391304347826086, 0.2638230647709322, 0.7966666666666667, 1.0, 1.0, 0.15319120647210122, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13158638799416872, 0.1315863879941689, 0.24654122465885628], 
reward next is 0.7535, 
noisyNet noise sample is [array([0.9403344], dtype=float32), -0.25539944]. 
=============================================
[2019-03-26 09:47:14,513] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0898000e-08 9.9999976e-01 5.9749731e-20 1.9347533e-07 1.5391847e-12], sum to 1.0000
[2019-03-26 09:47:14,522] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9596
[2019-03-26 09:47:14,623] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.68333333333333, 73.0, 1.0, 2.0, 0.3120328401531444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504413.3474573876, 504413.3474573876, 167408.9133559373], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 391800.0000, 
sim time next is 392400.0000, 
raw observation next is [22.7, 73.0, 1.0, 2.0, 0.3208786493000252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518560.6218782662, 518560.6218782662, 168467.3340876571], 
processed observation next is [1.0, 0.5652173913043478, 0.27488151658767773, 0.73, 1.0, 1.0, 0.18178150518075323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14404461718840728, 0.14404461718840728, 0.2514437822203837], 
reward next is 0.7486, 
noisyNet noise sample is [array([-1.6029408], dtype=float32), 0.94161725]. 
=============================================
[2019-03-26 09:47:18,947] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2589052e-07 9.9999857e-01 1.0599738e-17 1.3577221e-06 4.2460971e-10], sum to 1.0000
[2019-03-26 09:47:18,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4555
[2019-03-26 09:47:19,069] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 71.0, 1.0, 2.0, 0.4744885287901079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779014.4280267974, 779014.4280267974, 191333.3936493586], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 468000.0000, 
sim time next is 468600.0000, 
raw observation next is [22.03333333333333, 70.16666666666667, 1.0, 2.0, 0.4494719168348666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 737800.8058433089, 737800.8058433083, 187137.2527611648], 
processed observation next is [1.0, 0.43478260869565216, 0.2432859399684044, 0.7016666666666667, 1.0, 1.0, 0.33671315281309233, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20494466828980804, 0.20494466828980787, 0.27930933247935047], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.68174905], dtype=float32), 0.98699695]. 
=============================================
[2019-03-26 09:47:26,722] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15904: loss 0.1868
[2019-03-26 09:47:26,723] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15904: loss 0.2253
[2019-03-26 09:47:26,725] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15904: learning rate 0.0001
[2019-03-26 09:47:26,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15904: learning rate 0.0001
[2019-03-26 09:47:26,751] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15917: loss 0.2535
[2019-03-26 09:47:26,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15917: learning rate 0.0001
[2019-03-26 09:47:26,764] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 15923: loss 0.2024
[2019-03-26 09:47:26,772] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 15927: learning rate 0.0001
[2019-03-26 09:47:26,795] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15939: loss 0.1883
[2019-03-26 09:47:26,797] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15939: learning rate 0.0001
[2019-03-26 09:47:26,834] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15954: loss 0.2604
[2019-03-26 09:47:26,836] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15955: learning rate 0.0001
[2019-03-26 09:47:26,845] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 15961: loss 0.2159
[2019-03-26 09:47:26,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 15962: learning rate 0.0001
[2019-03-26 09:47:26,848] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 15962: loss 0.2697
[2019-03-26 09:47:26,853] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 15963: learning rate 0.0001
[2019-03-26 09:47:26,882] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15977: loss 0.2008
[2019-03-26 09:47:26,886] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15978: learning rate 0.0001
[2019-03-26 09:47:26,950] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16006: loss 0.2301
[2019-03-26 09:47:26,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16006: learning rate 0.0001
[2019-03-26 09:47:26,954] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16007: loss 0.2383
[2019-03-26 09:47:26,959] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16008: learning rate 0.0001
[2019-03-26 09:47:26,984] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16023: loss 0.2294
[2019-03-26 09:47:26,986] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16023: learning rate 0.0001
[2019-03-26 09:47:27,006] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 16034: loss 0.2194
[2019-03-26 09:47:27,008] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 16035: learning rate 0.0001
[2019-03-26 09:47:27,087] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 16068: loss 0.2138
[2019-03-26 09:47:27,090] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 16069: learning rate 0.0001
[2019-03-26 09:47:27,206] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 16122: loss 0.1428
[2019-03-26 09:47:27,209] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 16124: loss 0.1360
[2019-03-26 09:47:27,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 16123: learning rate 0.0001
[2019-03-26 09:47:27,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 16125: learning rate 0.0001
[2019-03-26 09:47:31,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8814849e-07 9.9999809e-01 1.3790540e-15 1.6175057e-06 1.8390450e-09], sum to 1.0000
[2019-03-26 09:47:31,323] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5280
[2019-03-26 09:47:31,329] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.1, 80.0, 1.0, 2.0, 0.2428836359520094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401307.3486973058, 401307.3486973058, 160148.350047122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 680400.0000, 
sim time next is 681000.0000, 
raw observation next is [20.0, 80.66666666666667, 1.0, 2.0, 0.2415022161778914, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399074.9289187366, 399074.9289187372, 160012.917123301], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 0.8066666666666668, 1.0, 1.0, 0.08614724840709805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11085414692187127, 0.11085414692187145, 0.2388252494377627], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.38572332], dtype=float32), 0.7845833]. 
=============================================
[2019-03-26 09:47:31,344] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[67.84777]
 [67.80756]
 [67.68312]
 [67.57991]
 [67.56092]], R is [[67.95176697]
 [68.03321838]
 [68.1135788 ]
 [68.19301605]
 [68.27185059]].
[2019-03-26 09:47:32,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6661959e-07 9.9998665e-01 1.2966873e-16 1.3229230e-05 3.9671244e-09], sum to 1.0000
[2019-03-26 09:47:32,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0021
[2019-03-26 09:47:32,670] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.68333333333333, 93.0, 1.0, 2.0, 0.2643340343026741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 440045.684673672, 440045.6846736726, 161907.7451246051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 699000.0000, 
sim time next is 699600.0000, 
raw observation next is [17.66666666666667, 93.0, 1.0, 2.0, 0.2334899960315701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 388733.2498148087, 388733.2498148087, 158874.2273807432], 
processed observation next is [1.0, 0.08695652173913043, 0.03633491311216459, 0.93, 1.0, 1.0, 0.07649397112237362, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1079814582818913, 0.1079814582818913, 0.23712571250857192], 
reward next is 0.7629, 
noisyNet noise sample is [array([0.16871513], dtype=float32), 0.49724072]. 
=============================================
[2019-03-26 09:47:34,004] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.11246972e-09 9.99999166e-01 1.15726455e-17 8.60709861e-07
 1.29543681e-10], sum to 1.0000
[2019-03-26 09:47:34,010] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4833
[2019-03-26 09:47:34,017] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.41666666666667, 69.0, 1.0, 2.0, 0.5024554194723655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 822644.3336216464, 822644.3336216458, 196248.3106412334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 723000.0000, 
sim time next is 723600.0000, 
raw observation next is [22.6, 68.0, 1.0, 2.0, 0.5138985822273554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841031.7897803773, 841031.7897803773, 198340.4809023116], 
processed observation next is [1.0, 0.391304347826087, 0.27014218009478685, 0.68, 1.0, 1.0, 0.41433564123777755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23361994160566035, 0.23361994160566035, 0.2960305685109128], 
reward next is 0.7040, 
noisyNet noise sample is [array([-0.70468557], dtype=float32), 0.23502402]. 
=============================================
[2019-03-26 09:47:35,515] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4887446e-06 9.9998140e-01 1.3587917e-14 1.7000872e-05 6.2262110e-08], sum to 1.0000
[2019-03-26 09:47:35,525] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9638
[2019-03-26 09:47:35,632] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 65.0, 1.0, 2.0, 0.2450190389611186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 403835.3042693184, 403835.3042693177, 160399.4502776505], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 758400.0000, 
sim time next is 759000.0000, 
raw observation next is [22.3, 66.5, 1.0, 2.0, 0.2462789396117199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 405752.3284923912, 405752.3284923905, 160526.5582239677], 
processed observation next is [1.0, 0.782608695652174, 0.25592417061611383, 0.665, 1.0, 1.0, 0.09190233688159023, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11270898013677534, 0.11270898013677515, 0.23959187794622044], 
reward next is 0.7604, 
noisyNet noise sample is [array([-0.30186465], dtype=float32), -0.32150304]. 
=============================================
[2019-03-26 09:47:35,649] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.43641 ]
 [65.449394]
 [65.45879 ]
 [65.53887 ]
 [65.64557 ]], R is [[65.49926758]
 [65.60487366]
 [65.70957184]
 [65.81311798]
 [65.91581726]].
[2019-03-26 09:47:37,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [5.1564499e-09 9.9999988e-01 3.4536403e-16 6.1323334e-08 9.3149335e-11], sum to 1.0000
[2019-03-26 09:47:37,418] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2496
[2019-03-26 09:47:37,513] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.45, 91.5, 1.0, 2.0, 0.2596381960705009, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 425020.4781945268, 425020.4781945268, 161866.2848390402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 783000.0000, 
sim time next is 783600.0000, 
raw observation next is [19.43333333333333, 91.66666666666666, 1.0, 2.0, 0.2594312418392346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424664.7965696771, 424664.7965696771, 161844.985704398], 
processed observation next is [0.0, 0.043478260869565216, 0.12006319115323845, 0.9166666666666665, 1.0, 1.0, 0.10774848414365615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11796244349157697, 0.11796244349157697, 0.24155968015581789], 
reward next is 0.7584, 
noisyNet noise sample is [array([-0.34022892], dtype=float32), 0.15700153]. 
=============================================
[2019-03-26 09:47:43,715] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23878: loss 0.0084
[2019-03-26 09:47:43,720] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23878: learning rate 0.0001
[2019-03-26 09:47:43,764] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23899: loss 0.0123
[2019-03-26 09:47:43,765] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23900: loss 0.0056
[2019-03-26 09:47:43,765] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23900: learning rate 0.0001
[2019-03-26 09:47:43,769] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23901: learning rate 0.0001
[2019-03-26 09:47:43,813] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 23915: loss 0.0022
[2019-03-26 09:47:43,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 23915: learning rate 0.0001
[2019-03-26 09:47:43,842] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23930: loss 0.0027
[2019-03-26 09:47:43,844] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23930: learning rate 0.0001
[2019-03-26 09:47:43,871] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23942: loss 0.0014
[2019-03-26 09:47:43,874] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23944: learning rate 0.0001
[2019-03-26 09:47:43,920] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23966: loss 0.0025
[2019-03-26 09:47:43,926] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 23969: learning rate 0.0001
[2019-03-26 09:47:43,956] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 23982: loss 0.0001
[2019-03-26 09:47:43,958] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 23982: learning rate 0.0001
[2019-03-26 09:47:43,963] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 23984: loss 0.0001
[2019-03-26 09:47:43,965] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 23984: learning rate 0.0001
[2019-03-26 09:47:43,978] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23991: loss 0.0009
[2019-03-26 09:47:43,980] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23991: learning rate 0.0001
[2019-03-26 09:47:43,990] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 23995: loss 0.0005
[2019-03-26 09:47:43,994] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 23996: learning rate 0.0001
[2019-03-26 09:47:44,063] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 24023: loss 0.0002
[2019-03-26 09:47:44,068] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 24023: learning rate 0.0001
[2019-03-26 09:47:44,090] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 24036: loss 0.0004
[2019-03-26 09:47:44,094] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 24038: learning rate 0.0001
[2019-03-26 09:47:44,123] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24051: loss 0.0014
[2019-03-26 09:47:44,127] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24051: learning rate 0.0001
[2019-03-26 09:47:44,328] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24148: loss 0.0001
[2019-03-26 09:47:44,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24148: learning rate 0.0001
[2019-03-26 09:47:44,374] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 24168: loss 0.0011
[2019-03-26 09:47:44,376] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 24168: learning rate 0.0001
[2019-03-26 09:47:45,032] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1062619e-08 9.9999750e-01 8.5717193e-17 2.4629569e-06 4.3057258e-10], sum to 1.0000
[2019-03-26 09:47:45,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6509
[2019-03-26 09:47:45,048] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 67.0, 1.0, 2.0, 0.3101548194550001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489186.8624167848, 489186.8624167848, 166195.4293440731], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 915600.0000, 
sim time next is 916200.0000, 
raw observation next is [24.85, 67.5, 1.0, 2.0, 0.311547813275998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491032.7704024446, 491032.7704024446, 166322.9622889166], 
processed observation next is [0.0, 0.6086956521739131, 0.37677725118483424, 0.675, 1.0, 1.0, 0.17053953406746747, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13639799177845682, 0.13639799177845682, 0.24824322729689047], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.0915299], dtype=float32), -0.85956407]. 
=============================================
[2019-03-26 09:47:46,219] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 09:47:46,221] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:47:46,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:47:46,223] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:47:46,224] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:47:46,225] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:47:46,225] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:47:46,226] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:47:46,226] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:47:46,229] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:47:46,230] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:47:46,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-26 09:47:46,267] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-26 09:47:46,284] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-26 09:47:46,286] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-26 09:47:46,329] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-26 09:48:20,675] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07423895], dtype=float32), 0.05759718]
[2019-03-26 09:48:20,676] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.6, 82.0, 1.0, 2.0, 0.7558563743247565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1056369.644282446, 1056369.644282446, 233362.6827635489]
[2019-03-26 09:48:20,678] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:48:20,681] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1149629e-09 1.0000000e+00 3.1974186e-19 2.9539436e-08 7.0543025e-12], sampled 0.003318077063007019
[2019-03-26 09:49:16,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07423895], dtype=float32), 0.05759718]
[2019-03-26 09:49:16,726] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.01592844, 87.22292473, 1.0, 2.0, 0.5873749112319142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820812.3523250556, 820812.3523250556, 198418.388953283]
[2019-03-26 09:49:16,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 09:49:16,734] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6275953e-09 1.0000000e+00 5.9208182e-19 3.7164703e-08 1.0425265e-11], sampled 0.4306690148682354
[2019-03-26 09:49:39,656] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 09:49:39,814] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6622 3164059721.9838 1778.0000
[2019-03-26 09:49:39,908] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 09:49:40,016] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 09:49:40,081] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 09:49:41,096] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 25000, evaluation results [25000.0, 7882.662178624321, 3164059721.983761, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 09:49:42,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0745792e-09 9.9999988e-01 1.0465435e-17 7.5282394e-08 1.6283985e-10], sum to 1.0000
[2019-03-26 09:49:42,262] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8936
[2019-03-26 09:49:42,267] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.33333333333334, 1.0, 2.0, 0.340482990389693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526970.7987906242, 526970.7987906237, 168833.0523317622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 951600.0000, 
sim time next is 952200.0000, 
raw observation next is [21.8, 94.5, 1.0, 2.0, 0.3401548452683181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 526165.6061189561, 526165.6061189554, 168759.6553157746], 
processed observation next is [1.0, 0.0, 0.23222748815165886, 0.945, 1.0, 1.0, 0.2050058376726724, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14615711281082114, 0.14615711281082094, 0.25188008256085764], 
reward next is 0.7481, 
noisyNet noise sample is [array([-0.7342858], dtype=float32), -1.5561765]. 
=============================================
[2019-03-26 09:49:50,326] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.3862672e-07 9.9998760e-01 3.7667674e-14 1.2305916e-05 7.9351219e-09], sum to 1.0000
[2019-03-26 09:49:50,334] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1409
[2019-03-26 09:49:50,342] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 71.5, 1.0, 2.0, 0.3334198661261245, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520393.1444944203, 520393.1444944209, 168434.5801737338], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1103400.0000, 
sim time next is 1104000.0000, 
raw observation next is [24.46666666666667, 72.0, 1.0, 2.0, 0.3296099892819256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 515132.1048108037, 515132.1048108043, 168041.358064677], 
processed observation next is [1.0, 0.782608695652174, 0.3586097946287521, 0.72, 1.0, 1.0, 0.19230119190593445, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14309225133633438, 0.14309225133633452, 0.25080799711145824], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.66646326], dtype=float32), 0.050125025]. 
=============================================
[2019-03-26 09:49:50,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.048794]
 [63.009693]
 [63.0927  ]
 [63.163177]
 [63.204727]], R is [[63.11238861]
 [63.22986984]
 [63.34568024]
 [63.46051025]
 [63.57464218]].
[2019-03-26 09:49:55,790] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31854: loss 0.5012
[2019-03-26 09:49:55,792] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31856: learning rate 0.0001
[2019-03-26 09:49:55,870] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31889: loss 0.4372
[2019-03-26 09:49:55,873] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31889: learning rate 0.0001
[2019-03-26 09:49:55,900] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 31904: loss 0.4327
[2019-03-26 09:49:55,902] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 31904: learning rate 0.0001
[2019-03-26 09:49:55,932] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31919: loss 0.3695
[2019-03-26 09:49:55,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31920: learning rate 0.0001
[2019-03-26 09:49:55,948] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31925: loss 0.4012
[2019-03-26 09:49:55,951] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31926: learning rate 0.0001
[2019-03-26 09:49:55,974] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31936: loss 0.3809
[2019-03-26 09:49:55,977] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31937: learning rate 0.0001
[2019-03-26 09:49:55,985] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 31940: loss 0.3473
[2019-03-26 09:49:55,987] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 31940: learning rate 0.0001
[2019-03-26 09:49:55,998] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31945: loss 0.3291
[2019-03-26 09:49:55,999] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31945: learning rate 0.0001
[2019-03-26 09:49:56,012] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31950: loss 0.3322
[2019-03-26 09:49:56,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31950: learning rate 0.0001
[2019-03-26 09:49:56,035] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 31960: loss 0.3034
[2019-03-26 09:49:56,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 31960: learning rate 0.0001
[2019-03-26 09:49:56,118] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 32000: loss 0.2604
[2019-03-26 09:49:56,123] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 32000: learning rate 0.0001
[2019-03-26 09:49:56,182] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 32028: loss 0.2285
[2019-03-26 09:49:56,185] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 32028: learning rate 0.0001
[2019-03-26 09:49:56,257] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32063: loss 0.1429
[2019-03-26 09:49:56,258] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32063: learning rate 0.0001
[2019-03-26 09:49:56,300] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32082: loss 0.1210
[2019-03-26 09:49:56,303] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32082: learning rate 0.0001
[2019-03-26 09:49:56,446] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32150: loss 0.0710
[2019-03-26 09:49:56,450] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32150: learning rate 0.0001
[2019-03-26 09:49:56,561] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0591643e-08 9.9999893e-01 5.2572153e-16 1.0283285e-06 9.1947250e-09], sum to 1.0000
[2019-03-26 09:49:56,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6972
[2019-03-26 09:49:56,574] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.2, 78.0, 1.0, 2.0, 0.3582388996383469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551037.1222666402, 551037.1222666402, 170710.5296477101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1198800.0000, 
sim time next is 1199400.0000, 
raw observation next is [24.08333333333334, 78.66666666666667, 1.0, 2.0, 0.358055639261249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 550841.4673749172, 550841.4673749172, 170696.5097147721], 
processed observation next is [1.0, 0.9130434782608695, 0.34044233807267016, 0.7866666666666667, 1.0, 1.0, 0.2265730593509024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15301151871525479, 0.15301151871525479, 0.25477091002204794], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.26376626], dtype=float32), -1.0609761]. 
=============================================
[2019-03-26 09:49:56,611] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 32226: loss 0.0279
[2019-03-26 09:49:56,616] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 32226: learning rate 0.0001
[2019-03-26 09:49:58,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.9926870e-10 1.0000000e+00 4.7764800e-18 2.7521376e-09 1.1023715e-11], sum to 1.0000
[2019-03-26 09:49:58,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0923
[2019-03-26 09:49:58,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1780997.064492748 W.
[2019-03-26 09:49:58,949] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.01666666666667, 74.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.329390880512875, 6.9112, 168.9110677347442, 1780997.064492748, 1484321.378286425, 316201.3668282327], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1246200.0000, 
sim time next is 1246800.0000, 
raw observation next is [27.23333333333334, 73.66666666666667, 1.0, 2.0, 0.5858543537126845, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9817998996662797, 6.911200000000001, 6.9112, 168.9126160012299, 1654672.817811926, 1654672.817811925, 351970.31968934], 
processed observation next is [1.0, 0.43478260869565216, 0.4897314375987366, 0.7366666666666667, 1.0, 1.0, 0.5010293418225114, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9778047556905848, 8.881784197001253e-17, 0.0, 0.8294382730962395, 0.45963133828109054, 0.45963133828109026, 0.5253288353572239], 
reward next is 0.4747, 
noisyNet noise sample is [array([0.6954998], dtype=float32), 0.28122017]. 
=============================================
[2019-03-26 09:50:02,705] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9312749e-11 1.0000000e+00 7.6219911e-20 3.6910717e-13 8.4136440e-14], sum to 1.0000
[2019-03-26 09:50:02,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0945
[2019-03-26 09:50:02,829] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.85, 93.5, 1.0, 2.0, 0.5543588314973338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802578.0055774802, 802578.0055774802, 196096.477506292], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1319400.0000, 
sim time next is 1320000.0000, 
raw observation next is [23.76666666666667, 93.66666666666667, 1.0, 2.0, 0.536796362988044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779058.4267126544, 779058.4267126544, 193226.5869690716], 
processed observation next is [1.0, 0.2608695652173913, 0.32543443917851517, 0.9366666666666668, 1.0, 1.0, 0.4419233289012578, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2164051185312929, 0.2164051185312929, 0.2883978909986143], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.00615398], dtype=float32), 1.029852]. 
=============================================
[2019-03-26 09:50:02,855] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.200066]
 [70.16944 ]
 [70.11602 ]
 [70.028595]
 [69.903946]], R is [[70.28856659]
 [70.29299927]
 [70.30142212]
 [70.31808472]
 [70.35158539]].
[2019-03-26 09:50:05,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.0143211e-11 1.0000000e+00 1.4350999e-19 1.2868985e-12 3.6170004e-14], sum to 1.0000
[2019-03-26 09:50:05,019] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3527
[2019-03-26 09:50:05,024] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.9, 91.5, 1.0, 2.0, 0.5898153121947395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 940732.0345272601, 940732.0345272601, 212064.7947096643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1355400.0000, 
sim time next is 1356000.0000, 
raw observation next is [20.86666666666667, 91.66666666666666, 1.0, 2.0, 0.607121084351589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 968618.3829843592, 968618.3829843592, 215748.4737343594], 
processed observation next is [1.0, 0.6956521739130435, 0.18799368088467638, 0.9166666666666665, 1.0, 1.0, 0.526651908857336, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26906066194009975, 0.26906066194009975, 0.3220126473647155], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.37864065], dtype=float32), -1.5680283]. 
=============================================
[2019-03-26 09:50:05,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[70.88275]
 [70.91805]
 [70.99135]
 [71.04048]
 [70.94697]], R is [[70.85561371]
 [70.83054352]
 [70.80136108]
 [70.76100159]
 [70.69624329]].
[2019-03-26 09:50:12,359] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6294392e-12 1.0000000e+00 7.1816952e-21 8.7280714e-14 5.0348634e-15], sum to 1.0000
[2019-03-26 09:50:12,368] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3349
[2019-03-26 09:50:12,375] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.63333333333334, 96.0, 1.0, 2.0, 0.3475423436181706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 537115.7424958579, 537115.7424958579, 169630.9236938214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1471800.0000, 
sim time next is 1472400.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.3458799522248043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535052.604252729, 535052.604252729, 169477.3413485671], 
processed observation next is [0.0, 0.043478260869565216, 0.22274881516587688, 0.96, 1.0, 1.0, 0.21190355689735454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14862572340353583, 0.14862572340353583, 0.25295125574413], 
reward next is 0.7470, 
noisyNet noise sample is [array([0.16784212], dtype=float32), -0.3314886]. 
=============================================
[2019-03-26 09:50:13,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7872587e-12 1.0000000e+00 7.6601968e-22 1.7336891e-14 3.6087568e-15], sum to 1.0000
[2019-03-26 09:50:13,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9616
[2019-03-26 09:50:13,062] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 92.5, 1.0, 2.0, 0.3419022963034121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 528449.00397552, 528449.0039755206, 168930.2571604968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1492200.0000, 
sim time next is 1492800.0000, 
raw observation next is [22.3, 91.66666666666667, 1.0, 2.0, 0.3455451185530622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 532615.9710408411, 532615.9710408417, 169222.6397857861], 
processed observation next is [0.0, 0.2608695652173913, 0.25592417061611383, 0.9166666666666667, 1.0, 1.0, 0.21150014283501467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14794888084467808, 0.14794888084467825, 0.2525711041578897], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.78383565], dtype=float32), -0.06344846]. 
=============================================
[2019-03-26 09:50:13,067] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 39796: loss 0.0444
[2019-03-26 09:50:13,069] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 39796: learning rate 0.0001
[2019-03-26 09:50:13,278] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39894: loss 0.0363
[2019-03-26 09:50:13,280] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39895: learning rate 0.0001
[2019-03-26 09:50:13,286] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39899: loss 0.0273
[2019-03-26 09:50:13,290] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39899: learning rate 0.0001
[2019-03-26 09:50:13,318] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 39911: loss 0.0294
[2019-03-26 09:50:13,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 39914: learning rate 0.0001
[2019-03-26 09:50:13,333] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 39915: loss 0.0203
[2019-03-26 09:50:13,338] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 39915: learning rate 0.0001
[2019-03-26 09:50:13,341] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39918: loss 0.0117
[2019-03-26 09:50:13,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39918: learning rate 0.0001
[2019-03-26 09:50:13,356] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39925: loss 0.0147
[2019-03-26 09:50:13,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39925: learning rate 0.0001
[2019-03-26 09:50:13,396] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39942: loss 0.0136
[2019-03-26 09:50:13,401] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39943: learning rate 0.0001
[2019-03-26 09:50:13,444] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39967: loss 0.0235
[2019-03-26 09:50:13,450] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39969: learning rate 0.0001
[2019-03-26 09:50:13,512] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39998: loss 0.0113
[2019-03-26 09:50:13,513] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39999: learning rate 0.0001
[2019-03-26 09:50:13,517] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 39999: loss 0.0114
[2019-03-26 09:50:13,522] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 39999: learning rate 0.0001
[2019-03-26 09:50:13,539] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 40009: loss 0.0093
[2019-03-26 09:50:13,544] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 40009: learning rate 0.0001
[2019-03-26 09:50:13,701] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40083: loss 0.0033
[2019-03-26 09:50:13,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40084: learning rate 0.0001
[2019-03-26 09:50:13,811] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40134: loss 0.0032
[2019-03-26 09:50:13,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40135: learning rate 0.0001
[2019-03-26 09:50:13,973] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40209: loss 0.0011
[2019-03-26 09:50:13,976] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40209: learning rate 0.0001
[2019-03-26 09:50:13,985] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 40216: loss 0.0006
[2019-03-26 09:50:13,987] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 40216: learning rate 0.0001
[2019-03-26 09:50:18,993] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.3453314e-11 1.0000000e+00 2.6477429e-18 1.6877344e-13 4.3822486e-15], sum to 1.0000
[2019-03-26 09:50:18,998] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7537
[2019-03-26 09:50:19,003] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.5, 85.0, 1.0, 2.0, 0.6640628917258884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1012614.973353868, 1012614.973353868, 223877.5349002591], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1587600.0000, 
sim time next is 1588200.0000, 
raw observation next is [23.51666666666667, 85.00000000000001, 1.0, 2.0, 0.7677448542104809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1170121.890334053, 1170121.890334052, 248882.1399740402], 
processed observation next is [1.0, 0.391304347826087, 0.31358609794628767, 0.8500000000000001, 1.0, 1.0, 0.7201745231451577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3250338584261258, 0.3250338584261256, 0.37146588055826896], 
reward next is 0.6285, 
noisyNet noise sample is [array([-0.49808228], dtype=float32), 0.3853586]. 
=============================================
[2019-03-26 09:50:20,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.4370154e-12 1.0000000e+00 1.0165514e-20 9.0403928e-14 3.7856977e-15], sum to 1.0000
[2019-03-26 09:50:20,519] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0676
[2019-03-26 09:50:20,620] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 95.16666666666667, 1.0, 2.0, 0.4111456044390976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607956.8574825437, 607956.8574825437, 175119.2022666656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1623000.0000, 
sim time next is 1623600.0000, 
raw observation next is [23.1, 95.0, 1.0, 2.0, 0.4099282734275939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 606616.0465647251, 606616.0465647251, 175006.7955966006], 
processed observation next is [1.0, 0.8260869565217391, 0.2938388625592418, 0.95, 1.0, 1.0, 0.28907020894890834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1685044573790903, 0.1685044573790903, 0.2612041725322397], 
reward next is 0.7388, 
noisyNet noise sample is [array([1.4262347], dtype=float32), -0.8701167]. 
=============================================
[2019-03-26 09:50:25,636] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.9999078e-09 1.0000000e+00 8.5064951e-17 8.0439518e-12 1.9562954e-12], sum to 1.0000
[2019-03-26 09:50:25,646] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9005
[2019-03-26 09:50:25,763] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.81666666666667, 85.33333333333334, 1.0, 2.0, 0.5083002362419704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710274.4841059294, 710274.4841059294, 184906.9153788787], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1713000.0000, 
sim time next is 1713600.0000, 
raw observation next is [26.7, 86.0, 1.0, 2.0, 0.5067137639541339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708056.8846347855, 708056.8846347849, 184654.8703867525], 
processed observation next is [1.0, 0.8695652173913043, 0.46445497630331756, 0.86, 1.0, 1.0, 0.4056792336796794, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19668246795410707, 0.1966824679541069, 0.2756042841593321], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.23926131], dtype=float32), -1.4668108]. 
=============================================
[2019-03-26 09:50:25,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.1453862e-08 1.0000000e+00 2.6252800e-14 2.4641866e-10 3.3112724e-11], sum to 1.0000
[2019-03-26 09:50:25,799] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1345
[2019-03-26 09:50:25,806] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.78333333333333, 74.66666666666667, 1.0, 2.0, 0.3334034716191943, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5663955314035035, 6.911199999999999, 6.9112, 168.912956510431, 931861.3501354652, 931861.3501354659, 231826.9517801831], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1703400.0000, 
sim time next is 1704000.0000, 
raw observation next is [28.66666666666667, 75.33333333333334, 1.0, 2.0, 0.4834331287363109, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675515.3268110428, 675515.3268110428, 181043.3518200786], 
processed observation next is [1.0, 0.7391304347826086, 0.5576619273301741, 0.7533333333333334, 1.0, 1.0, 0.3776302755859168, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18764314633640078, 0.18764314633640078, 0.2702139579404158], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8395058], dtype=float32), -0.19267938]. 
=============================================
[2019-03-26 09:50:25,818] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[45.94259 ]
 [45.92619 ]
 [45.867794]
 [46.09199 ]
 [46.212627]], R is [[46.20260239]
 [45.7405777 ]
 [45.28317261]
 [44.83034134]
 [44.38203812]].
[2019-03-26 09:50:30,481] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.9342778e-12 1.0000000e+00 1.1803544e-20 4.1618058e-15 9.3122776e-17], sum to 1.0000
[2019-03-26 09:50:30,492] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1268
[2019-03-26 09:50:30,498] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 92.0, 1.0, 2.0, 0.6004387425506822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953896.1516256345, 953896.1516256345, 213998.0517939191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1782000.0000, 
sim time next is 1782600.0000, 
raw observation next is [21.0, 92.33333333333334, 1.0, 2.0, 0.611183759918883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970856.4212880665, 970856.4212880665, 216282.768564925], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.9233333333333335, 1.0, 1.0, 0.5315466986974493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26968233924668517, 0.26968233924668517, 0.32281010233570895], 
reward next is 0.6772, 
noisyNet noise sample is [array([-1.2893565], dtype=float32), 1.3431184]. 
=============================================
[2019-03-26 09:50:30,598] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47792: loss 0.0731
[2019-03-26 09:50:30,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47793: learning rate 0.0001
[2019-03-26 09:50:30,780] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47877: loss 0.0364
[2019-03-26 09:50:30,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47878: learning rate 0.0001
[2019-03-26 09:50:30,798] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47886: loss 0.0340
[2019-03-26 09:50:30,799] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47886: loss 0.0371
[2019-03-26 09:50:30,805] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47887: learning rate 0.0001
[2019-03-26 09:50:30,805] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47887: learning rate 0.0001
[2019-03-26 09:50:30,862] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 47914: loss 0.0239
[2019-03-26 09:50:30,866] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 47915: learning rate 0.0001
[2019-03-26 09:50:30,882] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47922: loss 0.0244
[2019-03-26 09:50:30,887] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47924: learning rate 0.0001
[2019-03-26 09:50:30,921] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 47939: loss 0.0171
[2019-03-26 09:50:30,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 47940: learning rate 0.0001
[2019-03-26 09:50:30,998] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47979: loss 0.0111
[2019-03-26 09:50:31,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47980: learning rate 0.0001
[2019-03-26 09:50:31,005] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 47981: loss 0.0144
[2019-03-26 09:50:31,008] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 47981: learning rate 0.0001
[2019-03-26 09:50:31,020] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47989: loss 0.0100
[2019-03-26 09:50:31,022] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47989: learning rate 0.0001
[2019-03-26 09:50:31,028] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47990: loss 0.0075
[2019-03-26 09:50:31,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47991: learning rate 0.0001
[2019-03-26 09:50:31,076] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 48010: loss 0.0123
[2019-03-26 09:50:31,078] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 48010: learning rate 0.0001
[2019-03-26 09:50:31,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48095: loss 0.0021
[2019-03-26 09:50:31,263] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48095: learning rate 0.0001
[2019-03-26 09:50:31,364] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48147: loss 0.0022
[2019-03-26 09:50:31,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48147: learning rate 0.0001
[2019-03-26 09:50:31,396] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48158: loss 0.0022
[2019-03-26 09:50:31,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48159: learning rate 0.0001
[2019-03-26 09:50:31,499] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 48207: loss 0.0030
[2019-03-26 09:50:31,501] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 48208: learning rate 0.0001
[2019-03-26 09:50:34,953] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 09:50:34,955] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:50:34,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:50:34,958] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:50:34,959] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:50:34,959] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:50:34,960] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:50:34,960] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:50:34,961] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:50:34,960] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:50:34,962] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:50:34,982] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-26 09:50:34,998] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-26 09:50:35,024] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-26 09:50:35,026] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-26 09:50:35,026] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-26 09:50:38,014] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05979577], dtype=float32), 0.038211245]
[2019-03-26 09:50:38,016] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.46666666666667, 40.66666666666667, 1.0, 2.0, 0.4998575647216528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 828866.7321686547, 828866.7321686553, 195575.0416010927]
[2019-03-26 09:50:38,018] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 09:50:38,021] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.3516809e-10 1.0000000e+00 1.1703673e-16 1.2954045e-12 1.2859654e-13], sampled 0.3838574246822505
[2019-03-26 09:50:42,705] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05979577], dtype=float32), 0.038211245]
[2019-03-26 09:50:42,706] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.85, 79.5, 1.0, 2.0, 0.4587181654427347, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 663890.9208651294, 663890.92086513, 180302.0763142952]
[2019-03-26 09:50:42,707] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 09:50:42,709] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3792918e-10 1.0000000e+00 1.3711136e-17 2.7503111e-13 2.7973372e-14], sampled 0.8973358651591867
[2019-03-26 09:50:52,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05979577], dtype=float32), 0.038211245]
[2019-03-26 09:50:52,848] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.6, 57.5, 1.0, 2.0, 0.8694337795922499, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1338358.83683975, 1338358.836839749, 278471.2090432497]
[2019-03-26 09:50:52,852] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:50:52,856] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3600079e-09 1.0000000e+00 1.6170780e-16 1.7055855e-12 3.3286067e-13], sampled 0.8563227632229365
[2019-03-26 09:51:16,531] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05979577], dtype=float32), 0.038211245]
[2019-03-26 09:51:16,532] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.0, 89.0, 1.0, 2.0, 0.7195063087567697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1059854.113421362, 1059854.113421363, 232299.514397812]
[2019-03-26 09:51:16,533] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:51:16,538] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5714194e-10 1.0000000e+00 2.5183453e-17 5.1846456e-13 6.8833163e-14], sampled 0.5085878748708996
[2019-03-26 09:52:29,814] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 09:52:30,193] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7281 2779199535.5119 933.0000
[2019-03-26 09:52:30,334] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.1321 2842497763.3803 1131.0000
[2019-03-26 09:52:30,402] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 09:52:30,437] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 09:52:31,451] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 50000, evaluation results [50000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8660.728066421085, 2779199535.5119066, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.132109434688, 2842497763.3802733, 1131.0]
[2019-03-26 09:52:31,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1384958e-10 1.0000000e+00 4.2076622e-18 4.0882553e-13 2.1586440e-14], sum to 1.0000
[2019-03-26 09:52:31,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7597
[2019-03-26 09:52:31,662] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 87.0, 1.0, 2.0, 0.4928728000745627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688709.9329947385, 688709.9329947378, 182486.8250618643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881600.0000, 
sim time next is 1882200.0000, 
raw observation next is [25.98333333333333, 87.0, 1.0, 2.0, 0.4892254776866197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 683611.7506314571, 683611.7506314571, 181925.0582542246], 
processed observation next is [1.0, 0.782608695652174, 0.43048973143759867, 0.87, 1.0, 1.0, 0.38460900926098757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1898921529531825, 0.1898921529531825, 0.27152993769287254], 
reward next is 0.7285, 
noisyNet noise sample is [array([-0.9682796], dtype=float32), -1.0364763]. 
=============================================
[2019-03-26 09:52:43,294] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3044362e-13 1.0000000e+00 3.3956019e-22 8.9220442e-17 1.0989462e-17], sum to 1.0000
[2019-03-26 09:52:43,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5385
[2019-03-26 09:52:43,306] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 96.5, 1.0, 2.0, 0.4581625852114105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647824.8115850058, 647824.8115850058, 178285.9516952029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2086200.0000, 
sim time next is 2086800.0000, 
raw observation next is [24.03333333333333, 96.66666666666666, 1.0, 2.0, 0.4587731826357281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648564.1280802464, 648564.128080247, 178359.3039740096], 
processed observation next is [0.0, 0.13043478260869565, 0.3380726698262243, 0.9666666666666666, 1.0, 1.0, 0.3479194971514796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18015670224451288, 0.18015670224451305, 0.26620791637911884], 
reward next is 0.7338, 
noisyNet noise sample is [array([-1.1980104], dtype=float32), -0.035925988]. 
=============================================
[2019-03-26 09:52:43,894] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55837: loss 0.0052
[2019-03-26 09:52:43,899] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55837: learning rate 0.0001
[2019-03-26 09:52:43,914] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55846: loss 0.0040
[2019-03-26 09:52:43,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55847: learning rate 0.0001
[2019-03-26 09:52:44,051] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 55912: loss 0.0086
[2019-03-26 09:52:44,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 55913: learning rate 0.0001
[2019-03-26 09:52:44,068] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55918: loss 0.0035
[2019-03-26 09:52:44,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55918: learning rate 0.0001
[2019-03-26 09:52:44,115] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 55938: loss 0.0025
[2019-03-26 09:52:44,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 55938: learning rate 0.0001
[2019-03-26 09:52:44,128] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55943: loss 0.0027
[2019-03-26 09:52:44,130] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55945: learning rate 0.0001
[2019-03-26 09:52:44,137] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55947: loss 0.0031
[2019-03-26 09:52:44,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55948: learning rate 0.0001
[2019-03-26 09:52:44,139] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 55948: loss 0.0024
[2019-03-26 09:52:44,146] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 55950: learning rate 0.0001
[2019-03-26 09:52:44,224] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55990: loss 0.0002
[2019-03-26 09:52:44,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55991: learning rate 0.0001
[2019-03-26 09:52:44,273] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 56010: loss 0.0001
[2019-03-26 09:52:44,277] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 56010: learning rate 0.0001
[2019-03-26 09:52:44,322] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 56032: loss 0.0008
[2019-03-26 09:52:44,326] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 56032: learning rate 0.0001
[2019-03-26 09:52:44,343] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56040: loss 0.0003
[2019-03-26 09:52:44,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56040: learning rate 0.0001
[2019-03-26 09:52:44,408] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 56071: loss 0.0019
[2019-03-26 09:52:44,413] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 56072: learning rate 0.0001
[2019-03-26 09:52:44,454] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56092: loss 0.0022
[2019-03-26 09:52:44,458] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56094: learning rate 0.0001
[2019-03-26 09:52:44,509] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56115: loss 0.0007
[2019-03-26 09:52:44,513] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56115: learning rate 0.0001
[2019-03-26 09:52:44,595] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 56156: loss 0.0014
[2019-03-26 09:52:44,598] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 56157: learning rate 0.0001
[2019-03-26 09:52:53,187] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4007013e-11 1.0000000e+00 1.6681597e-18 1.1965198e-14 1.2064276e-16], sum to 1.0000
[2019-03-26 09:52:53,188] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8011
[2019-03-26 09:52:53,196] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 85.0, 1.0, 2.0, 0.5183004901568588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724253.125288148, 724253.1252881474, 186513.1048810808], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2245200.0000, 
sim time next is 2245800.0000, 
raw observation next is [27.05, 85.0, 1.0, 2.0, 0.5177060535173704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723422.1995952782, 723422.1995952775, 186416.7020522391], 
processed observation next is [1.0, 1.0, 0.4810426540284361, 0.85, 1.0, 1.0, 0.41892295604502455, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2009506109986884, 0.20095061099868822, 0.27823388366005836], 
reward next is 0.7218, 
noisyNet noise sample is [array([0.09848201], dtype=float32), 0.7192532]. 
=============================================
[2019-03-26 09:52:56,275] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.8656607e-07 9.9999928e-01 4.0952940e-12 3.7447929e-09 1.8788805e-10], sum to 1.0000
[2019-03-26 09:52:56,284] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3167
[2019-03-26 09:52:56,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2378575.331484531 W.
[2019-03-26 09:52:56,294] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.36666666666667, 64.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.044842718608957, 6.9112, 168.9121118295561, 2378575.331484531, 2283765.061394826, 475766.3088947255], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2307000.0000, 
sim time next is 2307600.0000, 
raw observation next is [32.4, 64.0, 1.0, 2.0, 0.5708441567398447, 1.0, 1.0, 0.5708441567398447, 1.0, 2.0, 0.9913675192097328, 6.911199999999999, 6.9112, 170.5573041426782, 2394854.354099343, 2394854.354099343, 467592.801331468], 
processed observation next is [1.0, 0.7391304347826086, 0.7345971563981042, 0.64, 1.0, 1.0, 0.48294476715643936, 1.0, 0.5, 0.48294476715643936, 1.0, 1.0, 0.9894725844021129, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6652373205831509, 0.6652373205831509, 0.697899703479803], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17684434], dtype=float32), -2.7616177]. 
=============================================
[2019-03-26 09:53:01,672] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 63849: loss 26.2188
[2019-03-26 09:53:01,675] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 63849: learning rate 0.0001
[2019-03-26 09:53:01,718] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63872: loss 36.1371
[2019-03-26 09:53:01,719] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63873: learning rate 0.0001
[2019-03-26 09:53:01,752] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63889: loss 46.2031
[2019-03-26 09:53:01,758] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63889: learning rate 0.0001
[2019-03-26 09:53:01,776] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 63898: loss 36.2846
[2019-03-26 09:53:01,777] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 63898: learning rate 0.0001
[2019-03-26 09:53:01,793] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63905: loss 37.5644
[2019-03-26 09:53:01,795] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63905: learning rate 0.0001
[2019-03-26 09:53:01,834] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63923: loss 40.2163
[2019-03-26 09:53:01,836] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63924: learning rate 0.0001
[2019-03-26 09:53:01,911] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63962: loss 38.4532
[2019-03-26 09:53:01,915] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63963: learning rate 0.0001
[2019-03-26 09:53:01,969] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63988: loss 24.1390
[2019-03-26 09:53:01,972] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63989: learning rate 0.0001
[2019-03-26 09:53:01,988] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 63995: loss 35.4984
[2019-03-26 09:53:01,989] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 63995: learning rate 0.0001
[2019-03-26 09:53:02,024] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 64009: loss 35.9214
[2019-03-26 09:53:02,025] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 64009: learning rate 0.0001
[2019-03-26 09:53:02,031] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64010: loss 41.5139
[2019-03-26 09:53:02,036] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64012: learning rate 0.0001
[2019-03-26 09:53:02,080] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 64037: loss 26.2564
[2019-03-26 09:53:02,081] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 64037: learning rate 0.0001
[2019-03-26 09:53:02,123] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64059: loss 39.2805
[2019-03-26 09:53:02,124] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64059: learning rate 0.0001
[2019-03-26 09:53:02,305] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64145: loss 36.1418
[2019-03-26 09:53:02,305] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 64145: loss 33.2631
[2019-03-26 09:53:02,308] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64146: learning rate 0.0001
[2019-03-26 09:53:02,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 64146: learning rate 0.0001
[2019-03-26 09:53:02,329] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64153: loss 27.1513
[2019-03-26 09:53:02,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64153: learning rate 0.0001
[2019-03-26 09:53:04,421] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4401842e-11 1.0000000e+00 1.6741951e-20 2.6403299e-14 3.0683223e-17], sum to 1.0000
[2019-03-26 09:53:04,432] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5377
[2019-03-26 09:53:04,439] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 84.16666666666667, 1.0, 2.0, 0.8077665982720743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1128956.89362321, 1128956.89362321, 245825.962736549], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2441400.0000, 
sim time next is 2442000.0000, 
raw observation next is [27.63333333333333, 84.33333333333334, 1.0, 2.0, 0.7969237828233532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1113794.727662552, 1113794.727662553, 243157.0469207724], 
processed observation next is [1.0, 0.2608695652173913, 0.5086887835703, 0.8433333333333334, 1.0, 1.0, 0.755329858823317, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3093874243507089, 0.3093874243507092, 0.36292096555339165], 
reward next is 0.6371, 
noisyNet noise sample is [array([0.38824633], dtype=float32), 0.28507665]. 
=============================================
[2019-03-26 09:53:04,457] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[60.08776 ]
 [60.019276]
 [59.84132 ]
 [59.6759  ]
 [59.55766 ]], R is [[59.80086899]
 [59.83595657]
 [59.86445236]
 [59.88279724]
 [59.88722992]].
[2019-03-26 09:53:04,871] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1118882e-13 1.0000000e+00 9.4555448e-22 7.7856018e-16 2.3345301e-19], sum to 1.0000
[2019-03-26 09:53:04,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2950
[2019-03-26 09:53:04,886] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.16666666666667, 1.0, 2.0, 0.7531453279333653, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1052578.862651041, 1052578.862651041, 232735.2849056105], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2445000.0000, 
sim time next is 2445600.0000, 
raw observation next is [27.7, 85.33333333333334, 1.0, 2.0, 0.7423467209443687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1037479.601694007, 1037479.601694007, 230251.8085865166], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.8533333333333334, 1.0, 1.0, 0.6895743625835767, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2881887782483353, 0.2881887782483353, 0.34365941580077103], 
reward next is 0.6563, 
noisyNet noise sample is [array([0.6827115], dtype=float32), 0.056337565]. 
=============================================
[2019-03-26 09:53:10,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9500035e-08 1.0000000e+00 8.3718473e-14 1.4292650e-08 1.8759983e-11], sum to 1.0000
[2019-03-26 09:53:10,366] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-26 09:53:10,373] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1810677.217536847 W.
[2019-03-26 09:53:10,482] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.45, 73.5, 1.0, 2.0, 0.4317104106062066, 1.0, 2.0, 0.4317104106062066, 1.0, 1.0, 0.7442294076730696, 6.911200000000001, 6.9112, 170.5573041426782, 1810677.217536847, 1810677.217536846, 370294.19617438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2550600.0000, 
sim time next is 2551200.0000, 
raw observation next is [29.56666666666667, 72.66666666666666, 1.0, 2.0, 0.6254631339134227, 1.0, 2.0, 0.6254631339134227, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1748825.38691154, 1748825.38691154, 343846.4817753671], 
processed observation next is [1.0, 0.5217391304347826, 0.6003159557661929, 0.7266666666666666, 1.0, 1.0, 0.5487507637511116, 1.0, 1.0, 0.5487507637511116, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.48578482969765, 0.48578482969765, 0.513203704142339], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.69416237], dtype=float32), 2.2961853]. 
=============================================
[2019-03-26 09:53:19,029] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 71865: loss 0.0325
[2019-03-26 09:53:19,033] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 71866: learning rate 0.0001
[2019-03-26 09:53:19,036] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71868: loss 0.0407
[2019-03-26 09:53:19,038] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 71868: loss 0.0332
[2019-03-26 09:53:19,040] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71868: learning rate 0.0001
[2019-03-26 09:53:19,042] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 71868: learning rate 0.0001
[2019-03-26 09:53:19,103] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71892: loss 0.0320
[2019-03-26 09:53:19,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71893: learning rate 0.0001
[2019-03-26 09:53:19,112] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71899: loss 0.0356
[2019-03-26 09:53:19,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71899: learning rate 0.0001
[2019-03-26 09:53:19,161] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71924: loss 0.0317
[2019-03-26 09:53:19,161] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71924: loss 0.0328
[2019-03-26 09:53:19,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71924: learning rate 0.0001
[2019-03-26 09:53:19,165] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71924: learning rate 0.0001
[2019-03-26 09:53:19,177] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 71930: loss 0.0243
[2019-03-26 09:53:19,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 71930: learning rate 0.0001
[2019-03-26 09:53:19,341] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72000: loss 0.0304
[2019-03-26 09:53:19,344] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72000: learning rate 0.0001
[2019-03-26 09:53:19,415] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72040: loss 0.0195
[2019-03-26 09:53:19,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 72041: loss 0.0271
[2019-03-26 09:53:19,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72041: learning rate 0.0001
[2019-03-26 09:53:19,421] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 72041: learning rate 0.0001
[2019-03-26 09:53:19,437] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 72047: loss 0.0138
[2019-03-26 09:53:19,443] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 72049: learning rate 0.0001
[2019-03-26 09:53:19,483] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 72067: loss 0.0070
[2019-03-26 09:53:19,485] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 72068: learning rate 0.0001
[2019-03-26 09:53:19,570] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 72108: loss 0.0066
[2019-03-26 09:53:19,572] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 72110: learning rate 0.0001
[2019-03-26 09:53:19,643] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72139: loss 0.0036
[2019-03-26 09:53:19,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72140: learning rate 0.0001
[2019-03-26 09:53:19,773] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72203: loss 0.0001
[2019-03-26 09:53:19,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72203: learning rate 0.0001
[2019-03-26 09:53:23,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.15822155e-14 1.00000000e+00 1.27014997e-24 8.53438237e-17
 1.03384355e-22], sum to 1.0000
[2019-03-26 09:53:24,002] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1096
[2019-03-26 09:53:24,007] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3540312321264625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545380.3656194228, 545380.3656194228, 170261.4877199658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2787000.0000, 
sim time next is 2787600.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3377006207281725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520218.5628121088, 520218.5628121095, 168216.6743281917], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.20204894063635237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1445051563366969, 0.14450515633669708, 0.2510696631764055], 
reward next is 0.7489, 
noisyNet noise sample is [array([1.1300792], dtype=float32), -0.5759863]. 
=============================================
[2019-03-26 09:53:24,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9667099e-15 1.0000000e+00 9.6742296e-24 3.7197743e-16 1.4977519e-22], sum to 1.0000
[2019-03-26 09:53:24,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2492
[2019-03-26 09:53:24,184] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3381475861693375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520911.9204612995, 520911.9204612989, 168271.9779602908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2788200.0000, 
sim time next is 2788800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3394014927768481, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522844.8595298342, 522844.8595298342, 168426.1075300047], 
processed observation next is [1.0, 0.2608695652173913, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2040981840684917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14523468320273172, 0.14523468320273172, 0.25138225004478315], 
reward next is 0.7486, 
noisyNet noise sample is [array([0.8057048], dtype=float32), 0.28038508]. 
=============================================
[2019-03-26 09:53:25,349] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 09:53:25,352] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:53:25,353] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:53:25,354] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:53:25,354] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:53:25,356] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:53:25,359] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:53:25,355] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:53:25,361] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:53:25,359] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:53:25,365] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:53:25,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-26 09:53:25,396] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-26 09:53:25,398] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-26 09:53:25,415] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-26 09:53:25,447] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-26 09:53:36,614] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07650647], dtype=float32), 0.044335127]
[2019-03-26 09:53:36,616] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [16.22721724, 81.27325955, 1.0, 2.0, 0.1715171951818519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 286902.4905571361, 286902.4905571355, 116736.3856620871]
[2019-03-26 09:53:36,617] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 09:53:36,622] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.8165030e-13 1.0000000e+00 7.7335151e-21 3.6615215e-14 1.6832446e-19], sampled 0.3240601918156447
[2019-03-26 09:53:54,978] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07650647], dtype=float32), 0.044335127]
[2019-03-26 09:53:54,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.2, 94.16666666666667, 1.0, 2.0, 0.4695657493547293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666991.0464479001, 666991.0464479001, 180360.2002843013]
[2019-03-26 09:53:54,981] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 09:53:54,985] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1076759e-12 1.0000000e+00 7.5424477e-21 8.6014298e-14 3.8489893e-19], sampled 0.1448500629981272
[2019-03-26 09:54:04,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07650647], dtype=float32), 0.044335127]
[2019-03-26 09:54:04,467] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5461899606128484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 763238.797357988, 763238.7973579873, 191148.8816599273]
[2019-03-26 09:54:04,468] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:54:04,471] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8522460e-12 1.0000000e+00 3.9452570e-20 1.9167189e-13 1.4921491e-18], sampled 0.6902754059934907
[2019-03-26 09:54:14,487] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07650647], dtype=float32), 0.044335127]
[2019-03-26 09:54:14,489] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.36390796166667, 80.97913296666668, 1.0, 2.0, 0.6092432482422163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 851383.9598446614, 851383.9598446608, 202478.4171376959]
[2019-03-26 09:54:14,490] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 09:54:14,494] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3985933e-12 1.0000000e+00 4.7068380e-20 2.3743420e-13 2.0846689e-18], sampled 0.391977709128004
[2019-03-26 09:55:02,596] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07650647], dtype=float32), 0.044335127]
[2019-03-26 09:55:02,598] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.75933085333333, 91.68048303, 1.0, 2.0, 0.4571149952791426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662689.1990391369, 662689.1990391363, 180200.4764850032]
[2019-03-26 09:55:02,600] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 09:55:02,603] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.8337252e-12 1.0000000e+00 2.3019065e-20 1.9368581e-13 9.0276186e-19], sampled 0.9932512879803674
[2019-03-26 09:55:20,238] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 09:55:20,657] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 09:55:20,900] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6679 2927328479.9021 1338.0000
[2019-03-26 09:55:20,960] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9509 2779224265.4428 933.0000
[2019-03-26 09:55:20,998] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5675 3007653631.8268 1766.0000
[2019-03-26 09:55:22,013] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 75000, evaluation results [75000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.667895353341, 2927328479.9020863, 1338.0, 8659.950916828071, 2779224265.4427943, 933.0, 7997.567474937318, 3007653631.8268285, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 09:55:23,510] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.8844300e-14 1.0000000e+00 3.6471344e-22 4.6074750e-14 2.0714837e-20], sum to 1.0000
[2019-03-26 09:55:23,519] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0175
[2019-03-26 09:55:23,527] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.4094262076607182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603250.7644546658, 603250.7644546658, 174616.0758322382], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2833800.0000, 
sim time next is 2834400.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4091672451503332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602870.9496955557, 602870.9496955563, 174580.6887437804], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 1.0, 1.0, 0.28815330741004, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1674641526932099, 0.16746415269321008, 0.2605681921548961], 
reward next is 0.7394, 
noisyNet noise sample is [array([-0.3820473], dtype=float32), 0.14373904]. 
=============================================
[2019-03-26 09:55:25,474] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6766649e-13 1.0000000e+00 4.0290885e-21 4.9772144e-14 4.6583079e-19], sum to 1.0000
[2019-03-26 09:55:25,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9153
[2019-03-26 09:55:25,597] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3448394295254273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 531217.893419224, 531217.8934192245, 169099.5435714672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869200.0000, 
sim time next is 2869800.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3835916465584336, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590912.58056965, 590912.5805696495, 174189.2145948113], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.257339333202932, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16414238349156945, 0.1641423834915693, 0.2599839023803154], 
reward next is 0.7400, 
noisyNet noise sample is [array([0.40049705], dtype=float32), 0.93674254]. 
=============================================
[2019-03-26 09:55:29,263] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.6527800e-14 1.0000000e+00 8.9150814e-22 2.4722886e-14 9.6394693e-21], sum to 1.0000
[2019-03-26 09:55:29,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5007
[2019-03-26 09:55:29,278] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.75, 95.5, 1.0, 2.0, 0.3147153254597316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 498600.5081672747, 498600.5081672741, 166938.3623574729], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2928600.0000, 
sim time next is 2929200.0000, 
raw observation next is [20.83333333333334, 95.0, 1.0, 2.0, 0.3159479759907824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 500268.3602040446, 500268.3602040446, 167057.7114591704], 
processed observation next is [1.0, 0.9130434782608695, 0.1864139020537128, 0.95, 1.0, 1.0, 0.1758409349286535, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13896343339001238, 0.13896343339001238, 0.24933986784950804], 
reward next is 0.7507, 
noisyNet noise sample is [array([0.23007517], dtype=float32), 0.10574621]. 
=============================================
[2019-03-26 09:55:32,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.4082915e-13 1.0000000e+00 2.7487620e-22 1.3778795e-14 4.8691385e-21], sum to 1.0000
[2019-03-26 09:55:32,105] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5627
[2019-03-26 09:55:32,111] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.66666666666667, 96.0, 1.0, 2.0, 0.5099191171375111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 808332.3011028171, 808332.3011028176, 196071.1602527268], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2986800.0000, 
sim time next is 2987400.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.5252021543128828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831588.4355212437, 831588.4355212437, 198793.9828026842], 
processed observation next is [1.0, 0.5652173913043478, 0.1864139020537123, 0.95, 1.0, 1.0, 0.4279544027866057, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23099678764478992, 0.23099678764478992, 0.2967074370189316], 
reward next is 0.7033, 
noisyNet noise sample is [array([0.6016625], dtype=float32), 0.6216556]. 
=============================================
[2019-03-26 09:55:32,527] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 79866: loss 0.2234
[2019-03-26 09:55:32,528] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79866: loss 0.2260
[2019-03-26 09:55:32,529] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 79866: learning rate 0.0001
[2019-03-26 09:55:32,532] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79868: learning rate 0.0001
[2019-03-26 09:55:32,698] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79881: loss 0.2349
[2019-03-26 09:55:32,700] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79882: learning rate 0.0001
[2019-03-26 09:55:32,784] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79891: loss 0.2297
[2019-03-26 09:55:32,785] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79891: learning rate 0.0001
[2019-03-26 09:55:32,881] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 79902: loss 0.2499
[2019-03-26 09:55:32,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 79903: learning rate 0.0001
[2019-03-26 09:55:32,969] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79912: loss 0.2653
[2019-03-26 09:55:32,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79913: learning rate 0.0001
[2019-03-26 09:55:33,125] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 79957: loss 0.2772
[2019-03-26 09:55:33,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 79957: learning rate 0.0001
[2019-03-26 09:55:33,246] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79988: loss 0.2496
[2019-03-26 09:55:33,247] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79988: learning rate 0.0001
[2019-03-26 09:55:33,341] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 80000: loss 0.2536
[2019-03-26 09:55:33,342] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 80000: learning rate 0.0001
[2019-03-26 09:55:33,439] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80015: loss 0.2490
[2019-03-26 09:55:33,442] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80017: learning rate 0.0001
[2019-03-26 09:55:33,529] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 80028: loss 0.2512
[2019-03-26 09:55:33,532] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 80030: learning rate 0.0001
[2019-03-26 09:55:33,617] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 80037: loss 0.2048
[2019-03-26 09:55:33,622] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 80038: learning rate 0.0001
[2019-03-26 09:55:33,702] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 80047: loss 0.2173
[2019-03-26 09:55:33,705] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 80047: learning rate 0.0001
[2019-03-26 09:55:33,813] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 80071: loss 0.1843
[2019-03-26 09:55:33,814] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 80072: learning rate 0.0001
[2019-03-26 09:55:33,987] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80126: loss 0.1663
[2019-03-26 09:55:33,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80126: learning rate 0.0001
[2019-03-26 09:55:34,135] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80164: loss 0.1225
[2019-03-26 09:55:34,140] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80165: learning rate 0.0001
[2019-03-26 09:55:37,913] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.6107727e-12 1.0000000e+00 1.2582218e-20 1.4131732e-13 1.2974752e-18], sum to 1.0000
[2019-03-26 09:55:37,923] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4812
[2019-03-26 09:55:37,929] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.8317339011161643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1206943.347008117, 1206943.347008117, 258127.1202715261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3075600.0000, 
sim time next is 3076200.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.8235318903294749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1195045.921058673, 1195045.921058672, 255959.9240597442], 
processed observation next is [1.0, 0.6086956521739131, 0.28909952606635075, 1.0, 1.0, 1.0, 0.7873878196740661, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3319572002940758, 0.33195720029407555, 0.38202973740260326], 
reward next is 0.6180, 
noisyNet noise sample is [array([-0.4601412], dtype=float32), 1.6282458]. 
=============================================
[2019-03-26 09:55:44,459] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1107824e-12 1.0000000e+00 1.3607075e-18 5.6477728e-13 5.3972479e-17], sum to 1.0000
[2019-03-26 09:55:44,467] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1163
[2019-03-26 09:55:44,471] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333333, 92.33333333333334, 1.0, 2.0, 0.4914239763024455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686684.7820207494, 686684.7820207487, 182263.2816266926], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3181200.0000, 
sim time next is 3181800.0000, 
raw observation next is [25.16666666666667, 93.16666666666667, 1.0, 2.0, 0.4920327516193084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 687535.7214298253, 687535.7214298247, 182357.0076422961], 
processed observation next is [1.0, 0.8260869565217391, 0.39178515007898923, 0.9316666666666668, 1.0, 1.0, 0.3879912670112149, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19098214484161813, 0.19098214484161796, 0.27217463827208377], 
reward next is 0.7278, 
noisyNet noise sample is [array([-1.6597296], dtype=float32), 1.3569086]. 
=============================================
[2019-03-26 09:55:46,044] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.6196293e-13 1.0000000e+00 8.6915387e-22 4.2075541e-16 1.0562320e-20], sum to 1.0000
[2019-03-26 09:55:46,055] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9607
[2019-03-26 09:55:46,062] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4574900929419624, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 647753.9435523852, 647753.9435523859, 178300.6335371413], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3213000.0000, 
sim time next is 3213600.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4562733162907733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646031.336081831, 646031.336081831, 178123.0729837246], 
processed observation next is [0.0, 0.17391304347826086, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3449076099888834, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17945314891161973, 0.17945314891161973, 0.26585533281152923], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.73048556], dtype=float32), -0.18123974]. 
=============================================
[2019-03-26 09:55:46,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.5815714e-13 1.0000000e+00 5.4593759e-22 2.8783029e-16 7.6329278e-21], sum to 1.0000
[2019-03-26 09:55:46,466] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6042
[2019-03-26 09:55:46,468] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 89.0, 1.0, 2.0, 0.4566762021398829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646602.4204941794, 646602.4204941794, 178181.9071402132], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3216600.0000, 
sim time next is 3217200.0000, 
raw observation next is [25.0, 89.0, 1.0, 2.0, 0.4566583325064311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646576.9607043526, 646576.9607043526, 178179.2799175668], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.89, 1.0, 1.0, 0.3453714849475074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17960471130676461, 0.17960471130676461, 0.2659392237575624], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.27108634], dtype=float32), -0.015903268]. 
=============================================
[2019-03-26 09:55:48,610] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4936699e-14 1.0000000e+00 1.7801779e-23 2.8196274e-17 1.8376058e-22], sum to 1.0000
[2019-03-26 09:55:48,619] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8211
[2019-03-26 09:55:48,625] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.5786776747525947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808653.99059273, 808653.99059273, 196841.6482538433], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3249600.0000, 
sim time next is 3250200.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.5808133630351888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811639.5778681749, 811639.5778681749, 197226.576163021], 
processed observation next is [0.0, 0.6086956521739131, 0.7630331753554502, 0.63, 1.0, 1.0, 0.4949558590785407, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22545543829671524, 0.22545543829671524, 0.29436802412391194], 
reward next is 0.7056, 
noisyNet noise sample is [array([-1.7109798], dtype=float32), -0.3820204]. 
=============================================
[2019-03-26 09:55:49,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.30656145e-15 1.00000000e+00 1.15121045e-26 3.21260355e-19
 4.66032004e-25], sum to 1.0000
[2019-03-26 09:55:49,893] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8346
[2019-03-26 09:55:49,899] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4875924157084424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681329.0846189507, 681329.0846189507, 181674.5114991432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280800.0000, 
sim time next is 3281400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4870881078076754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680624.172679582, 680624.172679582, 181597.4172454706], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3820338648285246, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18906227018877278, 0.18906227018877278, 0.27104092126189644], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.9764701], dtype=float32), 0.799531]. 
=============================================
[2019-03-26 09:55:50,972] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 87823: loss 0.0120
[2019-03-26 09:55:50,973] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 87823: learning rate 0.0001
[2019-03-26 09:55:50,984] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87827: loss 0.0144
[2019-03-26 09:55:50,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87828: learning rate 0.0001
[2019-03-26 09:55:51,015] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87842: loss 0.0060
[2019-03-26 09:55:51,021] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87843: learning rate 0.0001
[2019-03-26 09:55:51,081] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87868: loss 0.0136
[2019-03-26 09:55:51,083] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87869: learning rate 0.0001
[2019-03-26 09:55:51,130] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 87890: loss 0.0155
[2019-03-26 09:55:51,132] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 87891: learning rate 0.0001
[2019-03-26 09:55:51,194] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87925: loss 0.0214
[2019-03-26 09:55:51,197] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87925: learning rate 0.0001
[2019-03-26 09:55:51,225] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 87935: loss 0.0282
[2019-03-26 09:55:51,227] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 87937: learning rate 0.0001
[2019-03-26 09:55:51,390] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 88011: loss 0.0213
[2019-03-26 09:55:51,395] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 88011: learning rate 0.0001
[2019-03-26 09:55:51,408] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 88019: loss 0.0181
[2019-03-26 09:55:51,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 88019: learning rate 0.0001
[2019-03-26 09:55:51,446] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 88035: loss 0.0183
[2019-03-26 09:55:51,449] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 88036: learning rate 0.0001
[2019-03-26 09:55:51,454] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 88037: loss 0.0186
[2019-03-26 09:55:51,456] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 88038: learning rate 0.0001
[2019-03-26 09:55:51,501] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 88064: loss 0.0169
[2019-03-26 09:55:51,505] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 88064: learning rate 0.0001
[2019-03-26 09:55:51,543] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88084: loss 0.0107
[2019-03-26 09:55:51,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88086: learning rate 0.0001
[2019-03-26 09:55:51,564] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 88091: loss 0.0109
[2019-03-26 09:55:51,568] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 88093: learning rate 0.0001
[2019-03-26 09:55:51,704] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88157: loss 0.0100
[2019-03-26 09:55:51,710] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88159: learning rate 0.0001
[2019-03-26 09:55:51,754] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88178: loss 0.0082
[2019-03-26 09:55:51,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88178: learning rate 0.0001
[2019-03-26 09:55:58,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.8470179e-06 9.9934071e-01 7.6731785e-09 6.5435842e-04 8.2896285e-09], sum to 1.0000
[2019-03-26 09:55:58,285] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7634
[2019-03-26 09:55:58,293] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2719181.545854636 W.
[2019-03-26 09:55:58,300] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333334, 62.0, 1.0, 2.0, 0.6549552401933975, 1.0, 2.0, 0.6480676596109615, 1.0, 1.0, 1.03, 7.005094180687416, 6.9112, 170.5573041426782, 2719181.545854636, 2651921.324857165, 507478.2752359217], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3426000.0000, 
sim time next is 3426600.0000, 
raw observation next is [33.16666666666666, 62.5, 1.0, 2.0, 0.6532445143850684, 1.0, 2.0, 0.6472122967067967, 1.0, 2.0, 1.03, 7.005094045819082, 6.9112, 170.5573041426782, 2715588.688120665, 2648328.563734867, 506967.0091698411], 
processed observation next is [1.0, 0.6521739130434783, 0.7709320695102682, 0.625, 1.0, 1.0, 0.5822223064880342, 1.0, 1.0, 0.5749545743455382, 1.0, 1.0, 1.0365853658536586, 0.009389404581908156, 0.0, 0.8375144448122397, 0.7543301911446292, 0.7356468232596853, 0.7566671778654345], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1446104], dtype=float32), 0.78657633]. 
=============================================
[2019-03-26 09:56:00,453] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.40197125e-11 1.00000000e+00 7.70740342e-18 1.24002067e-11
 1.44554000e-18], sum to 1.0000
[2019-03-26 09:56:00,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6908
[2019-03-26 09:56:00,471] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5023997800195541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702026.7437834226, 702026.7437834232, 183972.8808807829], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3462600.0000, 
sim time next is 3463200.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.5016900063401247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 701034.6165113848, 701034.6165113841, 183861.1716263127], 
processed observation next is [1.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.39962651366280083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19473183791982912, 0.19473183791982893, 0.27441965914375027], 
reward next is 0.7256, 
noisyNet noise sample is [array([-1.5689774], dtype=float32), -0.60287446]. 
=============================================
[2019-03-26 09:56:04,798] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0059381e-11 1.0000000e+00 6.1993130e-18 1.5961535e-10 5.7637521e-19], sum to 1.0000
[2019-03-26 09:56:04,806] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1629
[2019-03-26 09:56:04,811] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 79.0, 1.0, 2.0, 0.5347848399878199, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 747295.8228908767, 747295.8228908767, 189225.2850913939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3534000.0000, 
sim time next is 3534600.0000, 
raw observation next is [28.16666666666667, 79.0, 1.0, 2.0, 0.5292705421878953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739587.5896174719, 739587.5896174725, 188308.8996478552], 
processed observation next is [1.0, 0.9130434782608695, 0.5339652448657191, 0.79, 1.0, 1.0, 0.43285607492517497, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20544099711596442, 0.20544099711596459, 0.28105805917590326], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.0235567], dtype=float32), 0.17845905]. 
=============================================
[2019-03-26 09:56:08,449] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 95827: loss -17.1179
[2019-03-26 09:56:08,454] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 95828: learning rate 0.0001
[2019-03-26 09:56:08,562] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95878: loss 5.8240
[2019-03-26 09:56:08,566] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95878: learning rate 0.0001
[2019-03-26 09:56:08,592] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 95888: loss 3.4219
[2019-03-26 09:56:08,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 95889: learning rate 0.0001
[2019-03-26 09:56:08,603] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95895: loss -45.2523
[2019-03-26 09:56:08,606] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95896: learning rate 0.0001
[2019-03-26 09:56:08,628] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 95908: loss 4.5484
[2019-03-26 09:56:08,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 95908: learning rate 0.0001
[2019-03-26 09:56:08,643] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95913: loss -23.1415
[2019-03-26 09:56:08,644] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95913: learning rate 0.0001
[2019-03-26 09:56:08,827] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 95997: loss 2.8357
[2019-03-26 09:56:08,830] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 95999: learning rate 0.0001
[2019-03-26 09:56:08,847] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 96005: loss -8.1662
[2019-03-26 09:56:08,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 96006: learning rate 0.0001
[2019-03-26 09:56:08,855] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 96008: loss 0.8990
[2019-03-26 09:56:08,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 96009: learning rate 0.0001
[2019-03-26 09:56:08,859] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 96010: loss -58.1911
[2019-03-26 09:56:08,862] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 96011: learning rate 0.0001
[2019-03-26 09:56:08,911] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96030: loss -27.9760
[2019-03-26 09:56:08,913] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96030: learning rate 0.0001
[2019-03-26 09:56:08,925] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 96037: loss 2.2401
[2019-03-26 09:56:08,928] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 96038: learning rate 0.0001
[2019-03-26 09:56:08,975] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 96064: loss -18.1649
[2019-03-26 09:56:08,976] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 96065: learning rate 0.0001
[2019-03-26 09:56:09,035] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 96089: loss 1.6925
[2019-03-26 09:56:09,037] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96089: loss -32.0455
[2019-03-26 09:56:09,037] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 96089: learning rate 0.0001
[2019-03-26 09:56:09,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96089: learning rate 0.0001
[2019-03-26 09:56:09,286] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96204: loss -29.4782
[2019-03-26 09:56:09,289] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96204: learning rate 0.0001
[2019-03-26 09:56:17,022] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 09:56:17,024] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:56:17,025] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:56:17,026] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:56:17,026] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:56:17,027] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:56:17,028] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:56:17,029] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:56:17,029] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:56:17,029] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:56:17,031] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:56:17,043] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-26 09:56:17,061] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-26 09:56:17,062] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-26 09:56:17,063] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-26 09:56:17,080] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-26 09:56:36,760] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:56:36,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.53333333333333, 91.66666666666667, 1.0, 2.0, 0.5137428404186826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730800.3274593552, 730800.3274593552, 187428.4019170274]
[2019-03-26 09:56:36,764] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:56:36,766] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3382290e-13 1.0000000e+00 5.8919336e-19 6.0306740e-13 1.5395311e-20], sampled 0.30229782894254387
[2019-03-26 09:56:40,505] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:56:40,507] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.61666666666667, 90.0, 1.0, 2.0, 0.3226006728800868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 508495.0533680868, 508495.0533680868, 167634.0193741018]
[2019-03-26 09:56:40,508] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:56:40,510] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3170547e-13 1.0000000e+00 1.2288695e-19 1.0326402e-13 2.0385428e-21], sampled 0.400844389503795
[2019-03-26 09:56:42,170] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:56:42,171] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.89475564, 93.91688493000001, 1.0, 2.0, 0.4395982714615335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 632718.6477138575, 632718.6477138575, 177048.0108475558]
[2019-03-26 09:56:42,172] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 09:56:42,176] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.2504252e-13 1.0000000e+00 2.5852033e-19 3.8666314e-13 6.0549807e-21], sampled 0.9933374644209537
[2019-03-26 09:56:46,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:56:46,547] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.3, 97.33333333333334, 1.0, 2.0, 0.427930599859608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 622307.7078989099, 622307.7078989092, 176200.3431244663]
[2019-03-26 09:56:46,548] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 09:56:46,554] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.6694849e-13 1.0000000e+00 8.0690900e-20 4.1325035e-13 9.4683948e-22], sampled 0.34145119175888883
[2019-03-26 09:56:57,678] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:56:57,680] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.26666666666667, 53.0, 1.0, 2.0, 0.5590184440164966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781171.7462028452, 781171.7462028452, 193359.4571910899]
[2019-03-26 09:56:57,681] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:56:57,685] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3542310e-12 1.0000000e+00 3.6355432e-18 4.7723696e-12 5.6719671e-20], sampled 0.6838493409485653
[2019-03-26 09:57:23,926] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:57:23,927] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.03333333333333, 46.0, 1.0, 2.0, 0.6906110425675794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965142.6464898841, 965142.6464898841, 218835.6768498274]
[2019-03-26 09:57:23,927] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:57:23,929] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2747325e-12 1.0000000e+00 1.8313332e-17 1.8450123e-11 3.5726435e-19], sampled 0.10806424835681261
[2019-03-26 09:57:37,639] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:57:37,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.38333333333333, 70.33333333333334, 1.0, 2.0, 0.594033827703537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 830121.324614287, 830121.324614287, 199638.9884376678]
[2019-03-26 09:57:37,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 09:57:37,644] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3352816e-11 1.0000000e+00 2.1162813e-15 4.9288790e-08 1.0396639e-17], sampled 0.019000689776411006
[2019-03-26 09:57:40,099] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:57:40,101] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.45, 93.0, 1.0, 2.0, 0.6197460395986303, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 866067.0176168857, 866067.0176168857, 204481.8795784632]
[2019-03-26 09:57:40,101] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 09:57:40,104] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.2331329e-13 1.0000000e+00 1.1983034e-18 2.1060326e-12 1.6618763e-20], sampled 0.04230082006251956
[2019-03-26 09:57:55,953] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:57:55,954] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.30606085333333, 55.55347770666667, 1.0, 2.0, 0.6744070537034775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 972600.7227897686, 972600.722789768, 219383.7191385922]
[2019-03-26 09:57:55,955] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 09:57:55,957] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0445488e-12 1.0000000e+00 3.2776432e-18 3.8913000e-12 5.5310517e-20], sampled 0.7331362931951416
[2019-03-26 09:57:57,674] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07872528], dtype=float32), 0.035639606]
[2019-03-26 09:57:57,678] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.048172535, 32.43269172666667, 1.0, 2.0, 0.2735641550415212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 443382.4826865452, 443382.4826865452, 163151.6423274993]
[2019-03-26 09:57:57,681] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 09:57:57,682] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1077175e-13 1.0000000e+00 9.6287484e-19 6.7573464e-13 1.0863776e-20], sampled 0.4567587107678984
[2019-03-26 09:58:12,158] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.3458 3007715983.7441 1763.0000
[2019-03-26 09:58:12,552] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779190307.3385 933.0000
[2019-03-26 09:58:12,731] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.3520 3163880631.8979 1771.0000
[2019-03-26 09:58:12,801] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8498.1207 2842369920.3894 1129.0000
[2019-03-26 09:58:12,885] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 09:58:13,903] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 100000, evaluation results [100000.0, 7887.351959056515, 3163880631.897916, 1771.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.987755389953, 2779190307.3384666, 933.0, 7998.345843301696, 3007715983.744114, 1763.0, 8498.120677583029, 2842369920.3893714, 1129.0]
[2019-03-26 09:58:22,364] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 103770: loss 0.0656
[2019-03-26 09:58:22,369] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 103770: learning rate 0.0001
[2019-03-26 09:58:22,570] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103866: loss 0.0136
[2019-03-26 09:58:22,573] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103866: learning rate 0.0001
[2019-03-26 09:58:22,636] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103903: loss 0.0099
[2019-03-26 09:58:22,638] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103903: learning rate 0.0001
[2019-03-26 09:58:22,641] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 103903: loss 0.0066
[2019-03-26 09:58:22,645] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 103903: learning rate 0.0001
[2019-03-26 09:58:22,662] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 103911: loss 0.0023
[2019-03-26 09:58:22,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 103913: learning rate 0.0001
[2019-03-26 09:58:22,714] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 103938: loss 0.0011
[2019-03-26 09:58:22,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 103938: learning rate 0.0001
[2019-03-26 09:58:22,783] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103970: loss 0.0026
[2019-03-26 09:58:22,787] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103971: learning rate 0.0001
[2019-03-26 09:58:22,835] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103991: loss 0.0099
[2019-03-26 09:58:22,837] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103991: learning rate 0.0001
[2019-03-26 09:58:22,853] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 103997: loss 0.0117
[2019-03-26 09:58:22,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 103998: learning rate 0.0001
[2019-03-26 09:58:22,927] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 104036: loss 0.0158
[2019-03-26 09:58:22,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 104036: learning rate 0.0001
[2019-03-26 09:58:22,943] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 104042: loss 0.0140
[2019-03-26 09:58:22,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 104042: learning rate 0.0001
[2019-03-26 09:58:22,948] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 104043: loss 0.0112
[2019-03-26 09:58:22,950] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 104043: learning rate 0.0001
[2019-03-26 09:58:22,977] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 104055: loss 0.0112
[2019-03-26 09:58:22,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 104055: learning rate 0.0001
[2019-03-26 09:58:22,993] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104063: loss 0.0075
[2019-03-26 09:58:22,996] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104063: learning rate 0.0001
[2019-03-26 09:58:23,030] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104079: loss 0.0091
[2019-03-26 09:58:23,032] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104079: learning rate 0.0001
[2019-03-26 09:58:23,326] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104217: loss 0.0012
[2019-03-26 09:58:23,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104217: learning rate 0.0001
[2019-03-26 09:58:24,768] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.9329382e-17 1.0000000e+00 1.1979981e-24 4.0844048e-17 2.6530792e-27], sum to 1.0000
[2019-03-26 09:58:24,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3297
[2019-03-26 09:58:24,782] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.33333333333334, 58.66666666666667, 1.0, 2.0, 0.6018250241588811, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841013.2950912022, 841013.2950912022, 201086.6152731599], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3932400.0000, 
sim time next is 3933000.0000, 
raw observation next is [34.5, 58.0, 1.0, 2.0, 0.5935372414575378, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 829427.1086153643, 829427.1086153643, 199548.8762243844], 
processed observation next is [0.0, 0.5217391304347826, 0.8341232227488152, 0.58, 1.0, 1.0, 0.5102858330813709, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23039641905982342, 0.23039641905982342, 0.2978341436184842], 
reward next is 0.7022, 
noisyNet noise sample is [array([1.031768], dtype=float32), -0.2240246]. 
=============================================
[2019-03-26 09:58:24,794] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.00111]
 [70.02721]
 [70.1094 ]
 [70.10148]
 [70.12915]], R is [[70.01087189]
 [70.01062775]
 [69.9960556 ]
 [69.99848175]
 [70.00127411]].
[2019-03-26 09:58:27,882] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1064565e-09 9.9999595e-01 4.7295045e-13 4.0274203e-06 2.9627817e-14], sum to 1.0000
[2019-03-26 09:58:27,890] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4520
[2019-03-26 09:58:27,897] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1830653.929696107 W.
[2019-03-26 09:58:27,901] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.16666666666667, 83.16666666666666, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.442112691624255, 6.9112, 168.9099478410167, 1830653.929696107, 1454012.902484483, 311353.9967805989], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3988200.0000, 
sim time next is 3988800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.3863488406154894, 1.0, 1.0, 0.3863488406154894, 1.0, 1.0, 0.6709601686351114, 6.9112, 6.9112, 170.5573041426782, 1620278.157746472, 1620278.157746472, 345460.9352725571], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.2606612537536017, 1.0, 0.5, 0.2606612537536017, 1.0, 0.5, 0.598731912969648, 0.0, 0.0, 0.8375144448122397, 0.45007726604068665, 0.45007726604068665, 0.5156133362276971], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01564282], dtype=float32), -0.14619021]. 
=============================================
[2019-03-26 09:58:30,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0724265e-07 3.3577129e-01 2.0135928e-09 6.6422826e-01 3.5987361e-12], sum to 1.0000
[2019-03-26 09:58:30,122] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3474
[2019-03-26 09:58:30,126] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.6600026136292648, 1.0, 2.0, 0.650591346328895, 1.0, 1.0, 1.03, 7.005094578611245, 6.9112, 170.5573041426782, 2729782.074362081, 2662521.568315585, 508993.0731450386], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4023000.0000, 
sim time next is 4023600.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 1.021260310824545, 1.0, 2.0, 1.021260310824545, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2856846.807881637, 2856846.807881637, 541968.5048338851], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6, 1.0, 1.0, 1.025614832318729, 1.0, 1.0, 1.025614832318729, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7935685577448992, 0.7935685577448992, 0.8089082161699778], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.14026836], dtype=float32), -0.31391034]. 
=============================================
[2019-03-26 09:58:31,769] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4006120e-13 1.0000000e+00 7.5368426e-20 1.0523277e-11 8.1704636e-21], sum to 1.0000
[2019-03-26 09:58:31,772] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7602
[2019-03-26 09:58:31,777] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5441893921847297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760442.2281859026, 760442.228185902, 190809.369833871], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4052400.0000, 
sim time next is 4053000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5439485633559369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760105.5771243477, 760105.5771243477, 190768.5081987891], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4505404377782372, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21114043809009658, 0.21114043809009658, 0.2847291167146106], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.29057455], dtype=float32), 0.5266447]. 
=============================================
[2019-03-26 09:58:31,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[54.172142]
 [53.851315]
 [54.04023 ]
 [54.230743]
 [54.571655]], R is [[54.49029922]
 [54.66060638]
 [54.82906342]
 [54.99586868]
 [55.16127777]].
[2019-03-26 09:58:35,814] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3509969e-12 9.9999511e-01 6.1231805e-18 4.9443211e-06 8.5022141e-22], sum to 1.0000
[2019-03-26 09:58:35,819] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4601
[2019-03-26 09:58:35,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.6240140405236126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872033.8040864518, 872033.8040864518, 205306.2115417464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4127400.0000, 
sim time next is 4128000.0000, 
raw observation next is [31.66666666666666, 76.33333333333333, 1.0, 2.0, 0.6211045601145273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867966.2642322266, 867966.2642322266, 204744.678087757], 
processed observation next is [1.0, 0.782608695652174, 0.6998420221169034, 0.7633333333333333, 1.0, 1.0, 0.5434994700175028, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2411017400645074, 0.2411017400645074, 0.3055890717727716], 
reward next is 0.6944, 
noisyNet noise sample is [array([-1.6453468], dtype=float32), -0.19959432]. 
=============================================
[2019-03-26 09:58:35,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[60.958843]
 [58.43327 ]
 [55.645542]
 [52.144836]
 [48.58148 ]], R is [[62.57496643]
 [62.64279175]
 [62.70930481]
 [62.77494812]
 [62.84155655]].
[2019-03-26 09:58:35,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6027102e-13 9.9999845e-01 8.7704730e-19 1.5862028e-06 1.1451972e-22], sum to 1.0000
[2019-03-26 09:58:35,999] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8886
[2019-03-26 09:58:36,004] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.6240140405236126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 872033.8040864518, 872033.8040864518, 205306.2115417464], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4127400.0000, 
sim time next is 4128000.0000, 
raw observation next is [31.66666666666666, 76.33333333333333, 1.0, 2.0, 0.6211045601145273, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 867966.2642322266, 867966.2642322266, 204744.678087757], 
processed observation next is [1.0, 0.782608695652174, 0.6998420221169034, 0.7633333333333333, 1.0, 1.0, 0.5434994700175028, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2411017400645074, 0.2411017400645074, 0.3055890717727716], 
reward next is 0.6944, 
noisyNet noise sample is [array([-2.2094908], dtype=float32), -2.6177962]. 
=============================================
[2019-03-26 09:58:36,017] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.836014]
 [60.5712  ]
 [57.743546]
 [53.90881 ]
 [50.252064]], R is [[64.3874588 ]
 [64.43715668]
 [64.4857254 ]
 [64.53360748]
 [64.58262634]].
[2019-03-26 09:58:37,341] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8199252e-14 1.0000000e+00 1.4795073e-21 4.6224233e-13 3.9382890e-23], sum to 1.0000
[2019-03-26 09:58:37,354] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0808
[2019-03-26 09:58:37,358] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 87.33333333333333, 1.0, 2.0, 0.5751901394200108, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 803778.605609815, 803778.605609815, 196214.9194963324], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4149600.0000, 
sim time next is 4150200.0000, 
raw observation next is [28.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5735233691821542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801448.5592447157, 801448.559244715, 195917.0501734224], 
processed observation next is [1.0, 0.0, 0.5339652448657191, 0.8816666666666667, 1.0, 1.0, 0.48617273395440264, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2226245997901988, 0.2226245997901986, 0.29241350772152597], 
reward next is 0.7076, 
noisyNet noise sample is [array([-0.74093765], dtype=float32), -0.00019030127]. 
=============================================
[2019-03-26 09:58:40,056] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 111846: loss -191.1467
[2019-03-26 09:58:40,059] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 111847: learning rate 0.0001
[2019-03-26 09:58:40,094] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111863: loss -269.5636
[2019-03-26 09:58:40,097] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111864: learning rate 0.0001
[2019-03-26 09:58:40,208] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111917: loss -202.0177
[2019-03-26 09:58:40,211] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111917: learning rate 0.0001
[2019-03-26 09:58:40,214] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111918: loss -222.4008
[2019-03-26 09:58:40,216] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111919: learning rate 0.0001
[2019-03-26 09:58:40,230] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 111925: loss -223.8789
[2019-03-26 09:58:40,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 111927: learning rate 0.0001
[2019-03-26 09:58:40,302] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 111960: loss -157.2571
[2019-03-26 09:58:40,304] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 111960: learning rate 0.0001
[2019-03-26 09:58:40,308] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 111960: loss -230.9837
[2019-03-26 09:58:40,311] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 111960: learning rate 0.0001
[2019-03-26 09:58:40,354] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111983: loss -178.0890
[2019-03-26 09:58:40,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111983: learning rate 0.0001
[2019-03-26 09:58:40,380] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 111996: loss -207.5264
[2019-03-26 09:58:40,382] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 111997: learning rate 0.0001
[2019-03-26 09:58:40,447] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 112024: loss -181.1643
[2019-03-26 09:58:40,448] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 112025: learning rate 0.0001
[2019-03-26 09:58:40,455] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 112028: loss -284.0315
[2019-03-26 09:58:40,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 112028: learning rate 0.0001
[2019-03-26 09:58:40,470] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 112035: loss -170.1912
[2019-03-26 09:58:40,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 112035: learning rate 0.0001
[2019-03-26 09:58:40,507] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 112053: loss -182.1122
[2019-03-26 09:58:40,509] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 112053: learning rate 0.0001
[2019-03-26 09:58:40,554] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112070: loss -227.8945
[2019-03-26 09:58:40,557] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112071: learning rate 0.0001
[2019-03-26 09:58:40,562] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112073: loss -180.1333
[2019-03-26 09:58:40,566] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112073: learning rate 0.0001
[2019-03-26 09:58:40,803] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112188: loss -159.3667
[2019-03-26 09:58:40,804] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112188: learning rate 0.0001
[2019-03-26 09:58:41,031] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1227562e-08 3.6587542e-01 9.0360688e-12 6.3412458e-01 8.0058827e-15], sum to 1.0000
[2019-03-26 09:58:41,037] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4980
[2019-03-26 09:58:41,044] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 51.0, 1.0, 2.0, 0.9785584398725673, 1.0, 2.0, 0.9785584398725673, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2737262.842508553, 2737262.842508553, 516166.3658853484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4207200.0000, 
sim time next is 4207800.0000, 
raw observation next is [36.0, 50.5, 1.0, 2.0, 0.9614763726048466, 1.0, 2.0, 0.9614763726048466, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2689428.76821455, 2689428.76821455, 506144.1890423997], 
processed observation next is [1.0, 0.6956521739130435, 0.9052132701421801, 0.505, 1.0, 1.0, 0.9535859910901767, 1.0, 1.0, 0.9535859910901767, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7470635467262638, 0.7470635467262638, 0.7554390881229847], 
reward next is 0.2446, 
noisyNet noise sample is [array([-0.22508952], dtype=float32), -1.0823058]. 
=============================================
[2019-03-26 09:58:49,282] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6067875e-06 9.9645150e-01 1.5879805e-09 3.5468650e-03 3.2199552e-11], sum to 1.0000
[2019-03-26 09:58:49,293] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0434
[2019-03-26 09:58:49,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3764980.48292771 W.
[2019-03-26 09:58:49,305] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.33333333333334, 78.0, 1.0, 2.0, 1.04, 1.0, 2.0, 0.896939722820925, 1.0, 1.0, 1.03, 7.225263882483816, 6.9112, 170.5573041426782, 3764980.48292771, 3540003.748602615, 663871.5843257754], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4351200.0000, 
sim time next is 4351800.0000, 
raw observation next is [32.66666666666666, 76.5, 1.0, 2.0, 0.9324586683018783, 1.0, 2.0, 0.7868193736652019, 1.0, 2.0, 1.03, 7.005116068468929, 6.9112, 170.5573041426782, 3302129.695079064, 3234853.794973356, 604814.63599789], 
processed observation next is [1.0, 0.34782608695652173, 0.7472353870458132, 0.765, 1.0, 1.0, 0.918624901568528, 1.0, 1.0, 0.7431558718857855, 1.0, 1.0, 1.0365853658536586, 0.009391606846892931, 0.0, 0.8375144448122397, 0.9172582486330734, 0.8985704986037101, 0.9027084119371493], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.24048714], dtype=float32), -0.8616176]. 
=============================================
[2019-03-26 09:58:54,605] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5539827e-18 1.0000000e+00 1.9606743e-26 8.0654271e-20 3.0300241e-29], sum to 1.0000
[2019-03-26 09:58:54,614] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0365
[2019-03-26 09:58:54,617] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 70.33333333333334, 1.0, 2.0, 0.6710449508241483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 937786.5720021, 937786.5720021005, 214727.2930612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4450200.0000, 
sim time next is 4450800.0000, 
raw observation next is [33.0, 69.66666666666667, 1.0, 2.0, 0.6439446792931339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 899897.8467283173, 899897.8467283173, 209218.5528079979], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.6966666666666668, 1.0, 1.0, 0.5710176858953421, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24997162409119925, 0.24997162409119925, 0.3122664967283551], 
reward next is 0.6877, 
noisyNet noise sample is [array([0.44115713], dtype=float32), -0.26598164]. 
=============================================
[2019-03-26 09:58:57,060] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 119736: loss 0.6456
[2019-03-26 09:58:57,062] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 119736: learning rate 0.0001
[2019-03-26 09:58:57,318] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119857: loss 0.5160
[2019-03-26 09:58:57,319] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119857: learning rate 0.0001
[2019-03-26 09:58:57,345] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119868: loss 0.4894
[2019-03-26 09:58:57,352] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119868: learning rate 0.0001
[2019-03-26 09:58:57,416] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119900: loss 0.4606
[2019-03-26 09:58:57,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119900: learning rate 0.0001
[2019-03-26 09:58:57,457] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119920: loss 0.4479
[2019-03-26 09:58:57,459] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119920: learning rate 0.0001
[2019-03-26 09:58:57,521] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119949: loss 0.4276
[2019-03-26 09:58:57,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119949: learning rate 0.0001
[2019-03-26 09:58:57,536] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 119954: loss 0.3909
[2019-03-26 09:58:57,537] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 119954: learning rate 0.0001
[2019-03-26 09:58:57,610] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 119992: loss 0.4254
[2019-03-26 09:58:57,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 119993: learning rate 0.0001
[2019-03-26 09:58:57,662] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120019: loss 0.3295
[2019-03-26 09:58:57,663] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120019: learning rate 0.0001
[2019-03-26 09:58:57,671] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 120025: loss 0.3229
[2019-03-26 09:58:57,672] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 120025: learning rate 0.0001
[2019-03-26 09:58:57,724] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 120046: loss 0.2836
[2019-03-26 09:58:57,727] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 120049: learning rate 0.0001
[2019-03-26 09:58:57,799] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 120086: loss 0.2194
[2019-03-26 09:58:57,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 120086: learning rate 0.0001
[2019-03-26 09:58:57,807] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120087: loss 0.2343
[2019-03-26 09:58:57,809] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120087: learning rate 0.0001
[2019-03-26 09:58:57,821] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 120095: loss 0.2151
[2019-03-26 09:58:57,826] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 120096: learning rate 0.0001
[2019-03-26 09:58:57,842] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120104: loss 0.1759
[2019-03-26 09:58:57,844] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120105: learning rate 0.0001
[2019-03-26 09:58:57,964] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120158: loss 0.1540
[2019-03-26 09:58:57,966] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120159: learning rate 0.0001
[2019-03-26 09:59:01,738] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6486983e-22 1.0000000e+00 2.6331506e-31 1.2558558e-23 1.5020863e-33], sum to 1.0000
[2019-03-26 09:59:01,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1573
[2019-03-26 09:59:01,753] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.529300894799023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 739630.018258668, 739630.0182586674, 188313.6533800974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4563600.0000, 
sim time next is 4564200.0000, 
raw observation next is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5270184166459418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736439.4425721312, 736439.4425721312, 187937.0538408328], 
processed observation next is [0.0, 0.8260869565217391, 0.5339652448657191, 0.7816666666666667, 1.0, 1.0, 0.43014267065776124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.204566511825592, 0.204566511825592, 0.2805030654340788], 
reward next is 0.7195, 
noisyNet noise sample is [array([-2.012514], dtype=float32), 0.1404961]. 
=============================================
[2019-03-26 09:59:04,522] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5779752e-06 9.7850889e-01 7.9078077e-09 2.1489464e-02 3.5488798e-10], sum to 1.0000
[2019-03-26 09:59:04,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9193
[2019-03-26 09:59:04,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2703328.443204099 W.
[2019-03-26 09:59:04,545] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.9664401648672009, 1.0, 2.0, 0.9664401648672009, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2703328.443204099, 2703328.443204099, 509046.3914803151], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4613400.0000, 
sim time next is 4614000.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.6699620654210997, 1.0, 2.0, 0.6555710722248124, 1.0, 1.0, 1.03, 7.005095363812339, 6.9112, 170.5573041426782, 2750699.247570874, 2683438.179052894, 512010.3021984246], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.6023639342422887, 1.0, 1.0, 0.5850253882226655, 1.0, 0.5, 1.0365853658536586, 0.00938953638123392, 0.0, 0.8375144448122397, 0.7640831243252428, 0.7453994941813594, 0.764194480893171], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7063454], dtype=float32), 1.0887071]. 
=============================================
[2019-03-26 09:59:04,559] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[25.41299 ]
 [24.670713]
 [25.593733]
 [27.092648]
 [28.829512]], R is [[24.67672729]
 [24.6701889 ]
 [24.42348671]
 [24.17925262]
 [23.93745995]].
[2019-03-26 09:59:08,119] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-26 09:59:08,121] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 09:59:08,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:59:08,124] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 09:59:08,125] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 09:59:08,125] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:59:08,125] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:59:08,127] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 09:59:08,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 09:59:08,130] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:59:08,130] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 09:59:08,148] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-26 09:59:08,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-26 09:59:08,168] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-26 09:59:08,182] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-26 09:59:08,197] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-26 09:59:59,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 09:59:59,526] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.99629137, 65.421304775, 1.0, 2.0, 0.8454015441163859, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1181585.799213373, 1181585.799213373, 255360.6672920514]
[2019-03-26 09:59:59,527] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 09:59:59,530] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.1866111e-14 1.0000000e+00 5.8626949e-20 2.7964332e-12 5.0152167e-22], sampled 0.36450215760763416
[2019-03-26 10:00:00,645] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 10:00:00,646] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.33333333333334, 77.33333333333334, 1.0, 2.0, 0.9045561497491644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1264313.182788631, 1264313.182788632, 271192.9351764767]
[2019-03-26 10:00:00,649] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:00:00,651] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0474399e-14 1.0000000e+00 2.2562718e-21 7.6638779e-15 4.8588171e-23], sampled 0.4120323292389617
[2019-03-26 10:00:06,053] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 10:00:06,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.68135906, 72.20076872, 1.0, 2.0, 0.683525884618618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 955236.5444686244, 955236.5444686251, 217339.9783346762]
[2019-03-26 10:00:06,055] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:00:06,058] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0961422e-15 1.0000000e+00 1.0396176e-22 3.6787806e-16 1.2739544e-24], sampled 0.3096640963892765
[2019-03-26 10:00:08,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 10:00:08,396] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.35615078666667, 92.17489131000002, 1.0, 2.0, 0.6342957259598799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 886408.0298880667, 886408.0298880661, 207301.9442221232]
[2019-03-26 10:00:08,397] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:00:08,400] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.4927328e-15 1.0000000e+00 2.2257010e-22 1.2638388e-15 4.4876218e-24], sampled 0.3494166288196324
[2019-03-26 10:00:10,392] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 10:00:10,393] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.43333333333334, 64.33333333333333, 1.0, 2.0, 0.9374153944346015, 1.0, 2.0, 0.9374153944346015, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2622018.410871224, 2622018.410871224, 492795.5878462739]
[2019-03-26 10:00:10,395] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:00:10,397] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2832192e-11 1.0000000e+00 4.2108159e-15 4.5033732e-09 4.5005815e-17], sampled 0.8567264892065765
[2019-03-26 10:00:10,400] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2622018.410871224 W.
[2019-03-26 10:00:16,630] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05086748], dtype=float32), 0.046296306]
[2019-03-26 10:00:16,631] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.22063491, 73.9174604, 1.0, 2.0, 0.4104776886061691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 598473.6122449505, 598473.6122449512, 173974.3442275014]
[2019-03-26 10:00:16,632] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:00:16,635] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2656903e-13 1.0000000e+00 2.7116790e-19 2.6285710e-11 7.8629414e-22], sampled 0.07990692968050395
[2019-03-26 10:01:03,310] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5565 3007691332.9145 1766.0000
[2019-03-26 10:01:03,750] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 10:01:03,757] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3842 2927353765.3077 1338.0000
[2019-03-26 10:01:03,813] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 10:01:03,846] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.5677 3164177865.9947 1775.0000
[2019-03-26 10:01:04,862] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 125000, evaluation results [125000.0, 7883.567724970982, 3164177865.994713, 1775.0, 8254.384160244701, 2927353765.3077335, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7997.556513503158, 3007691332.9145484, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 10:01:07,034] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.3319044e-08 5.8810878e-01 3.7012005e-11 4.1189125e-01 4.8638668e-14], sum to 1.0000
[2019-03-26 10:01:07,044] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5670
[2019-03-26 10:01:07,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2242808.477129183 W.
[2019-03-26 10:01:07,053] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.5346345701855661, 1.0, 2.0, 0.5346345701855661, 1.0, 1.0, 0.9284834420582087, 6.911199999999999, 6.9112, 170.5573041426782, 2242808.477129183, 2242808.477129183, 439922.8397142172], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4719600.0000, 
sim time next is 4720200.0000, 
raw observation next is [30.33333333333333, 73.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.104257009564517, 6.9112, 168.9065754784738, 3131172.714738695, 2284808.984626944, 473254.1236686515], 
processed observation next is [1.0, 0.6521739130434783, 0.6366508688783569, 0.7366666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.11930570095645168, 0.0, 0.8294086113641438, 0.8697701985385263, 0.6346691623963734, 0.7063494383114202], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1985594], dtype=float32), -1.2915812]. 
=============================================
[2019-03-26 10:01:08,329] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3259476e-15 1.0000000e+00 5.6878431e-22 2.2720337e-14 7.2218456e-25], sum to 1.0000
[2019-03-26 10:01:08,337] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9088
[2019-03-26 10:01:08,341] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 81.5, 1.0, 2.0, 0.5152573297455308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719999.2890821466, 719999.2890821459, 186021.0516612937], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4746600.0000, 
sim time next is 4747200.0000, 
raw observation next is [27.33333333333334, 82.33333333333334, 1.0, 2.0, 0.5138844485620362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718080.2332563245, 718080.2332563245, 185800.0178881114], 
processed observation next is [1.0, 0.9565217391304348, 0.4944707740916275, 0.8233333333333335, 1.0, 1.0, 0.41431861272534476, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19946673146009014, 0.19946673146009014, 0.27731345953449466], 
reward next is 0.7227, 
noisyNet noise sample is [array([0.8596012], dtype=float32), -0.5738306]. 
=============================================
[2019-03-26 10:01:10,830] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 127776: loss -105.8522
[2019-03-26 10:01:10,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 127776: learning rate 0.0001
[2019-03-26 10:01:10,933] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.4358964e-07 7.4810272e-01 2.4951701e-09 2.5189674e-01 5.9819753e-12], sum to 1.0000
[2019-03-26 10:01:10,939] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0672
[2019-03-26 10:01:10,949] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2143421.829390873 W.
[2019-03-26 10:01:10,953] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.766448558610959, 1.0, 2.0, 0.766448558610959, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2143421.829390873, 2143421.829390873, 403866.27370959], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4788000.0000, 
sim time next is 4788600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 1.004968776908967, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.991872828137754, 6.9112, 168.912476778738, 2301956.75463846, 2244724.836358587, 465367.6083731171], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.66, 1.0, 1.0, 1.0059864782035748, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008067282813775379, 0.0, 0.829437589450068, 0.6394324318440167, 0.623534676766274, 0.6945785199598763], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.91607386], dtype=float32), -1.7598637]. 
=============================================
[2019-03-26 10:01:11,122] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127909: loss -68.0738
[2019-03-26 10:01:11,127] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127912: learning rate 0.0001
[2019-03-26 10:01:11,149] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127920: loss -7.5156
[2019-03-26 10:01:11,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127921: learning rate 0.0001
[2019-03-26 10:01:11,161] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 127924: loss -102.9756
[2019-03-26 10:01:11,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 127925: learning rate 0.0001
[2019-03-26 10:01:11,243] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127968: loss -49.9715
[2019-03-26 10:01:11,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127971: learning rate 0.0001
[2019-03-26 10:01:11,253] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127972: loss -58.1972
[2019-03-26 10:01:11,255] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127972: learning rate 0.0001
[2019-03-26 10:01:11,296] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 127989: loss -51.1372
[2019-03-26 10:01:11,298] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 127990: loss -65.1064
[2019-03-26 10:01:11,300] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 127990: loss -75.1728
[2019-03-26 10:01:11,300] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 127990: learning rate 0.0001
[2019-03-26 10:01:11,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 127990: learning rate 0.0001
[2019-03-26 10:01:11,302] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 127990: learning rate 0.0001
[2019-03-26 10:01:11,306] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 127992: loss 0.7583
[2019-03-26 10:01:11,310] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 127993: learning rate 0.0001
[2019-03-26 10:01:11,329] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 128001: loss -130.8064
[2019-03-26 10:01:11,330] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 128001: learning rate 0.0001
[2019-03-26 10:01:11,400] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128033: loss 1.5131
[2019-03-26 10:01:11,402] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128033: learning rate 0.0001
[2019-03-26 10:01:11,440] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 128053: loss -83.7776
[2019-03-26 10:01:11,441] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128054: loss -112.6627
[2019-03-26 10:01:11,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128054: learning rate 0.0001
[2019-03-26 10:01:11,445] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 128054: learning rate 0.0001
[2019-03-26 10:01:11,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 128092: loss -74.8562
[2019-03-26 10:01:11,535] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 128092: learning rate 0.0001
[2019-03-26 10:01:11,619] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128134: loss -341.1329
[2019-03-26 10:01:11,620] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128134: learning rate 0.0001
[2019-03-26 10:01:19,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7074950e-14 1.0000000e+00 8.4760661e-20 1.5752005e-10 3.9744824e-22], sum to 1.0000
[2019-03-26 10:01:19,905] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3986
[2019-03-26 10:01:19,912] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.7016581958525254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 980588.3901806338, 980588.3901806338, 221201.8509231201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950000.0000, 
sim time next is 4950600.0000, 
raw observation next is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.6162422541121735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861168.6510827631, 861168.6510827637, 203803.5360967583], 
processed observation next is [1.0, 0.30434782608695654, 0.494470774091627, 0.8233333333333333, 1.0, 1.0, 0.5376412700146668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23921351418965642, 0.23921351418965658, 0.3041843822339676], 
reward next is 0.6958, 
noisyNet noise sample is [array([-0.5291365], dtype=float32), 1.9675431]. 
=============================================
[2019-03-26 10:01:21,705] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6718956e-10 8.4945762e-01 7.3327832e-14 1.5054239e-01 1.3368726e-17], sum to 1.0000
[2019-03-26 10:01:21,713] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2656
[2019-03-26 10:01:21,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1964062.643719337 W.
[2019-03-26 10:01:21,731] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.9, 63.0, 1.0, 2.0, 0.7023717242315584, 1.0, 2.0, 0.7023717242315584, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1964062.643719337, 1964062.643719337, 375136.8649365691], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4980600.0000, 
sim time next is 4981200.0000, 
raw observation next is [30.93333333333333, 63.0, 1.0, 2.0, 0.4984259853399938, 1.0, 2.0, 0.4984259853399938, 1.0, 1.0, 0.8547823986617856, 6.911200000000001, 6.9112, 170.5573041426782, 2090768.313999045, 2090768.313999044, 412101.0269496224], 
processed observation next is [1.0, 0.6521739130434783, 0.6650868878357029, 0.63, 1.0, 1.0, 0.3956939582409564, 1.0, 1.0, 0.3956939582409564, 1.0, 0.5, 0.8229053642216897, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5807689761108458, 0.5807689761108455, 0.615076159626302], 
reward next is 0.3849, 
noisyNet noise sample is [array([0.6276705], dtype=float32), -0.25948188]. 
=============================================
[2019-03-26 10:01:22,608] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6434162e-14 1.0000000e+00 5.3845513e-20 6.3537031e-10 7.6397029e-24], sum to 1.0000
[2019-03-26 10:01:22,616] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0919
[2019-03-26 10:01:22,619] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5169605399671015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722380.0938837458, 722380.0938837464, 186296.2021665199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4996800.0000, 
sim time next is 4997400.0000, 
raw observation next is [27.83333333333334, 79.00000000000001, 1.0, 2.0, 0.513481379071649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717516.8109010714, 717516.8109010708, 185735.2194554481], 
processed observation next is [1.0, 0.8695652173913043, 0.5181674565560824, 0.7900000000000001, 1.0, 1.0, 0.41383298683331204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19931022525029762, 0.19931022525029746, 0.2772167454558927], 
reward next is 0.7228, 
noisyNet noise sample is [array([-0.11012479], dtype=float32), 0.25024018]. 
=============================================
[2019-03-26 10:01:23,412] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.34484070e-16 1.00000000e+00 4.06611033e-23 1.05983995e-13
 2.98061849e-26], sum to 1.0000
[2019-03-26 10:01:23,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9291
[2019-03-26 10:01:23,424] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5082536061360354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 710209.303639924, 710209.3036399233, 184899.468040855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5005200.0000, 
sim time next is 5005800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5091015903215216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711394.6329976249, 711394.6329976243, 185034.4587508654], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4085561329174959, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19760962027711804, 0.19760962027711787, 0.27617083395651554], 
reward next is 0.7238, 
noisyNet noise sample is [array([-0.5652381], dtype=float32), 0.7130336]. 
=============================================
[2019-03-26 10:01:24,222] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1296763e-15 1.0000000e+00 1.0106379e-23 2.8064851e-15 3.1302950e-25], sum to 1.0000
[2019-03-26 10:01:24,231] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8751
[2019-03-26 10:01:24,235] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 89.0, 1.0, 2.0, 0.4795703412608865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670116.037829079, 670116.037829079, 180457.010002942], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5027400.0000, 
sim time next is 5028000.0000, 
raw observation next is [25.66666666666666, 89.0, 1.0, 2.0, 0.4839063894074186, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 676176.838331621, 676176.8383316203, 181113.0564080392], 
processed observation next is [0.0, 0.17391304347826086, 0.4154818325434437, 0.89, 1.0, 1.0, 0.37820046916556455, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1878268995365614, 0.1878268995365612, 0.27031799463886447], 
reward next is 0.7297, 
noisyNet noise sample is [array([1.377783], dtype=float32), 0.9609515]. 
=============================================
[2019-03-26 10:01:24,244] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[67.232346]
 [67.472534]
 [67.757454]
 [67.75927 ]
 [67.90162 ]], R is [[66.95198059]
 [67.01312256]
 [67.07444763]
 [67.13557434]
 [67.19607544]].
[2019-03-26 10:01:27,891] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135732: loss 3.3982
[2019-03-26 10:01:27,894] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135733: learning rate 0.0001
[2019-03-26 10:01:28,530] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 135908: loss 3.5281
[2019-03-26 10:01:28,535] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 135909: learning rate 0.0001
[2019-03-26 10:01:28,540] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 135911: loss 3.5737
[2019-03-26 10:01:28,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 135911: learning rate 0.0001
[2019-03-26 10:01:28,577] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135929: loss 3.3153
[2019-03-26 10:01:28,581] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135930: learning rate 0.0001
[2019-03-26 10:01:28,636] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135957: loss 3.4545
[2019-03-26 10:01:28,641] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135957: learning rate 0.0001
[2019-03-26 10:01:28,643] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 135959: loss 3.4429
[2019-03-26 10:01:28,648] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 135960: learning rate 0.0001
[2019-03-26 10:01:28,675] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 135972: loss 3.3259
[2019-03-26 10:01:28,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 135974: learning rate 0.0001
[2019-03-26 10:01:28,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135975: loss 3.3118
[2019-03-26 10:01:28,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135976: learning rate 0.0001
[2019-03-26 10:01:28,695] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 135979: loss 3.2789
[2019-03-26 10:01:28,697] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 135980: learning rate 0.0001
[2019-03-26 10:01:28,715] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135992: loss 3.2441
[2019-03-26 10:01:28,719] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135992: learning rate 0.0001
[2019-03-26 10:01:28,732] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135999: loss 3.0212
[2019-03-26 10:01:28,734] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135999: learning rate 0.0001
[2019-03-26 10:01:28,803] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136032: loss 3.0478
[2019-03-26 10:01:28,805] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136032: learning rate 0.0001
[2019-03-26 10:01:28,819] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136039: loss 2.9707
[2019-03-26 10:01:28,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136039: learning rate 0.0001
[2019-03-26 10:01:28,946] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 136096: loss 2.7030
[2019-03-26 10:01:28,951] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 136096: learning rate 0.0001
[2019-03-26 10:01:29,045] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136145: loss 2.6558
[2019-03-26 10:01:29,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136145: learning rate 0.0001
[2019-03-26 10:01:29,086] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 136161: loss 2.5054
[2019-03-26 10:01:29,087] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 136161: learning rate 0.0001
[2019-03-26 10:01:30,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.3237932e-17 1.0000000e+00 1.7649226e-24 1.5442279e-16 3.3960208e-27], sum to 1.0000
[2019-03-26 10:01:30,428] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7492
[2019-03-26 10:01:30,434] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5103689724725529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713166.2077364186, 713166.2077364192, 185236.5954961804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5132400.0000, 
sim time next is 5133000.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5102681719364942, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713025.3064145406, 713025.3064145413, 185220.5000598621], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.40996165293553516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19806258511515018, 0.19806258511515037, 0.276448507552033], 
reward next is 0.7236, 
noisyNet noise sample is [array([-2.3161519], dtype=float32), -0.10268863]. 
=============================================
[2019-03-26 10:01:30,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.61526 ]
 [72.60073 ]
 [72.583084]
 [72.58575 ]
 [72.59607 ]], R is [[72.61003113]
 [72.60746002]
 [72.60488892]
 [72.60194397]
 [72.59638977]].
[2019-03-26 10:01:44,141] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3612710e-14 1.0000000e+00 4.5764408e-19 1.4863469e-13 5.0284922e-22], sum to 1.0000
[2019-03-26 10:01:44,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6549
[2019-03-26 10:01:44,156] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.25, 86.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 11.41401588712133, 6.9112, 170.3810597889865, 4677914.128340551, 1455697.048234397, 301122.304110757], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5364600.0000, 
sim time next is 5365200.0000, 
raw observation next is [29.2, 87.0, 1.0, 2.0, 0.6803506653049258, 1.0, 1.0, 0.6607653721667255, 1.0, 1.0, 1.03, 7.005096182875381, 6.9112, 170.5573041426782, 2772518.10512884, 2705256.449882685, 515194.8643187703], 
processed observation next is [1.0, 0.08695652173913043, 0.5829383886255924, 0.87, 1.0, 1.0, 0.614880319644489, 1.0, 0.5, 0.5912835809237657, 1.0, 0.5, 1.0365853658536586, 0.00938961828753806, 0.0, 0.8375144448122397, 0.7701439180913444, 0.7514601249674125, 0.7689475586847317], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3599089], dtype=float32), -0.5391225]. 
=============================================
[2019-03-26 10:01:45,388] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143748: loss -176.7075
[2019-03-26 10:01:45,391] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143750: learning rate 0.0001
[2019-03-26 10:01:45,629] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 143860: loss -141.1236
[2019-03-26 10:01:45,633] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 143863: learning rate 0.0001
[2019-03-26 10:01:45,675] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 143882: loss -150.0094
[2019-03-26 10:01:45,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 143882: learning rate 0.0001
[2019-03-26 10:01:45,746] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143911: loss -177.0807
[2019-03-26 10:01:45,749] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143912: learning rate 0.0001
[2019-03-26 10:01:45,841] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 143957: loss -106.3291
[2019-03-26 10:01:45,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 143958: learning rate 0.0001
[2019-03-26 10:01:45,849] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 143960: loss -138.3521
[2019-03-26 10:01:45,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 143961: learning rate 0.0001
[2019-03-26 10:01:45,858] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 143964: loss -130.0713
[2019-03-26 10:01:45,862] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 143965: learning rate 0.0001
[2019-03-26 10:01:45,893] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143977: loss -163.5438
[2019-03-26 10:01:45,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143977: learning rate 0.0001
[2019-03-26 10:01:45,925] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143991: loss -151.3340
[2019-03-26 10:01:45,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143991: learning rate 0.0001
[2019-03-26 10:01:45,935] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143995: loss -169.1756
[2019-03-26 10:01:45,936] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143995: learning rate 0.0001
[2019-03-26 10:01:45,997] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144025: loss -158.7631
[2019-03-26 10:01:45,998] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144025: learning rate 0.0001
[2019-03-26 10:01:46,019] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 144036: loss -100.0931
[2019-03-26 10:01:46,021] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 144036: learning rate 0.0001
[2019-03-26 10:01:46,080] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144062: loss -149.2131
[2019-03-26 10:01:46,082] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144062: learning rate 0.0001
[2019-03-26 10:01:46,162] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144102: loss -119.8650
[2019-03-26 10:01:46,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144102: learning rate 0.0001
[2019-03-26 10:01:46,258] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 144143: loss -143.9367
[2019-03-26 10:01:46,263] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 144144: learning rate 0.0001
[2019-03-26 10:01:46,420] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144220: loss -98.0147
[2019-03-26 10:01:46,420] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144220: learning rate 0.0001
[2019-03-26 10:01:50,098] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3130979e-09 9.9999952e-01 3.3017632e-13 4.9702192e-07 2.6288752e-15], sum to 1.0000
[2019-03-26 10:01:50,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2234
[2019-03-26 10:01:50,113] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.15, 89.0, 1.0, 2.0, 0.7952089889672792, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1111396.847317342, 1111396.847317342, 242741.3637489601], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5463000.0000, 
sim time next is 5463600.0000, 
raw observation next is [28.33333333333334, 88.0, 1.0, 2.0, 0.7928086402714412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1108040.331113781, 1108040.331113781, 242156.5278565023], 
processed observation next is [1.0, 0.21739130434782608, 0.5418641390205374, 0.88, 1.0, 1.0, 0.7503718557487242, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30778898086493917, 0.30778898086493917, 0.3614276535171676], 
reward next is 0.6386, 
noisyNet noise sample is [array([1.4052175], dtype=float32), -0.9736674]. 
=============================================
[2019-03-26 10:01:54,205] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.8892968e-14 1.0000000e+00 8.0415914e-19 8.7110625e-13 1.4271995e-20], sum to 1.0000
[2019-03-26 10:01:54,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1034
[2019-03-26 10:01:54,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 95.0, 1.0, 2.0, 0.9105049435989987, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1272632.894277708, 1272632.894277708, 272843.5281958672], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5540400.0000, 
sim time next is 5541000.0000, 
raw observation next is [26.05, 95.0, 1.0, 2.0, 0.9738793817596707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1361269.537394629, 1361269.537394629, 291067.987440143], 
processed observation next is [1.0, 0.13043478260869565, 0.43364928909952616, 0.95, 1.0, 1.0, 0.968529375614061, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37813042705406363, 0.37813042705406363, 0.43442983200021346], 
reward next is 0.5656, 
noisyNet noise sample is [array([1.5159689], dtype=float32), -0.45507312]. 
=============================================
[2019-03-26 10:01:54,240] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.44675 ]
 [46.86372 ]
 [46.399452]
 [45.99008 ]
 [47.593647]], R is [[47.93228912]
 [48.04573441]
 [48.15485382]
 [48.24477768]
 [48.2998085 ]].
[2019-03-26 10:01:54,680] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.7625132e-14 1.0000000e+00 4.1024494e-20 2.2278423e-14 2.0471997e-22], sum to 1.0000
[2019-03-26 10:01:54,693] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9012
[2019-03-26 10:01:54,698] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.51666666666667, 90.83333333333333, 1.0, 2.0, 0.6981871930302358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 975735.3311223818, 975735.3311223811, 220453.9923531722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5550600.0000, 
sim time next is 5551200.0000, 
raw observation next is [26.7, 90.0, 1.0, 2.0, 0.6987487340141891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 976520.4605154968, 976520.4605154968, 220575.1261582956], 
processed observation next is [1.0, 0.2608695652173913, 0.46445497630331756, 0.9, 1.0, 1.0, 0.6370466674869748, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2712556834765269, 0.2712556834765269, 0.32921660620641136], 
reward next is 0.6708, 
noisyNet noise sample is [array([0.7857817], dtype=float32), -0.58235246]. 
=============================================
[2019-03-26 10:01:55,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8938583e-12 1.0000000e+00 3.2650499e-19 8.3156903e-13 1.6857434e-20], sum to 1.0000
[2019-03-26 10:01:55,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4676
[2019-03-26 10:01:55,131] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.88333333333333, 85.33333333333334, 1.0, 2.0, 0.8302677065363072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1160422.247817472, 1160422.247817473, 251477.0291355819], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5555400.0000, 
sim time next is 5556000.0000, 
raw observation next is [28.06666666666667, 84.66666666666667, 1.0, 2.0, 0.9078035022282398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1268854.773628794, 1268854.773628793, 272094.4613652963], 
processed observation next is [1.0, 0.30434782608695654, 0.529225908372828, 0.8466666666666667, 1.0, 1.0, 0.8889198822026986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3524596593413316, 0.3524596593413314, 0.40611113636611385], 
reward next is 0.5939, 
noisyNet noise sample is [array([-1.2550646], dtype=float32), 0.805832]. 
=============================================
[2019-03-26 10:01:55,150] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[47.408566]
 [47.213512]
 [47.023766]
 [47.396786]
 [47.570972]], R is [[47.31414795]
 [47.46566772]
 [47.61326599]
 [47.77000427]
 [47.92783356]].
[2019-03-26 10:01:58,605] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.7522893e-18 1.0000000e+00 1.0040055e-23 8.1318485e-20 5.7912530e-28], sum to 1.0000
[2019-03-26 10:01:58,607] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4759
[2019-03-26 10:01:58,613] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 92.0, 1.0, 2.0, 0.508023626854121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709887.8341999968, 709887.8341999968, 184862.5178650199], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5626800.0000, 
sim time next is 5627400.0000, 
raw observation next is [25.68333333333333, 91.83333333333334, 1.0, 2.0, 0.506999960384305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 708456.9348052735, 708456.9348052735, 184699.8230652409], 
processed observation next is [0.0, 0.13043478260869565, 0.41627172195892564, 0.9183333333333334, 1.0, 1.0, 0.40602404865578906, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19679359300146487, 0.19679359300146487, 0.27567137770931477], 
reward next is 0.7243, 
noisyNet noise sample is [array([2.402627], dtype=float32), 0.5783333]. 
=============================================
[2019-03-26 10:01:58,767] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 10:01:58,770] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:01:58,771] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:01:58,771] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:01:58,772] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:01:58,773] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:01:58,773] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:01:58,773] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:01:58,774] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:01:58,774] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:01:58,775] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:01:58,787] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-26 10:01:58,787] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-26 10:01:58,816] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-26 10:01:58,817] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-26 10:01:58,850] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-26 10:02:22,787] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:02:22,788] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.231589005, 89.97946037833333, 1.0, 2.0, 0.3883978666428642, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 581820.9676837014, 581820.9676837008, 172942.691156976]
[2019-03-26 10:02:22,789] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:02:22,793] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8191111e-18 1.0000000e+00 2.2278808e-25 1.9435232e-20 2.3070310e-28], sampled 0.2786916310944113
[2019-03-26 10:02:44,579] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:02:44,581] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.16666666666667, 89.0, 1.0, 2.0, 0.6362739479298782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 965837.7640789308, 965837.7640789314, 217252.5311161857]
[2019-03-26 10:02:44,582] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:02:44,583] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9173256e-18 1.0000000e+00 7.7749411e-25 1.1504770e-19 1.0460156e-27], sampled 0.03273192110823109
[2019-03-26 10:02:58,693] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:02:58,694] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.03333333333333, 76.0, 1.0, 2.0, 0.5756781484030671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 804460.8143171964, 804460.8143171964, 196302.0025044802]
[2019-03-26 10:02:58,696] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:02:58,699] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0962810e-18 1.0000000e+00 2.3331698e-25 3.8924292e-19 9.1165820e-29], sampled 0.9879740070036366
[2019-03-26 10:03:01,039] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:03:01,041] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [37.0, 57.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.176909360607509, 6.9112, 170.5573041426782, 3099889.871815699, 2909551.448446795, 552268.783899546]
[2019-03-26 10:03:01,043] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:03:01,047] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3228773e-09 8.8231385e-01 2.0945804e-12 1.1768616e-01 2.2697500e-16], sampled 0.03936810976401384
[2019-03-26 10:03:01,047] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3099889.871815699 W.
[2019-03-26 10:03:06,178] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:03:06,179] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.25, 55.16666666666667, 1.0, 2.0, 0.5200929943082685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726758.758343447, 726758.7583434476, 186803.4863551677]
[2019-03-26 10:03:06,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:03:06,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8438309e-18 1.0000000e+00 1.3101083e-25 1.6609456e-19 3.5062653e-29], sampled 0.5408151254385032
[2019-03-26 10:03:06,317] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:03:06,318] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.11666666666667, 66.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.411428200189171, 6.9112, 168.9047524512329, 2518713.890334985, 1454452.064687081, 310662.2324313682]
[2019-03-26 10:03:06,319] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:03:06,321] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.7940096e-17 1.0000000e+00 2.4961102e-23 7.2673599e-18 1.6080886e-26], sampled 0.6126007627884769
[2019-03-26 10:03:06,323] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2518713.890334985 W.
[2019-03-26 10:03:24,979] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:03:24,982] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.65278574, 92.62419472666667, 1.0, 2.0, 0.9562960816700045, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104083, 1336676.47195401, 1336676.471954009, 285890.5096304456]
[2019-03-26 10:03:24,984] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:03:24,986] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.8134842e-15 1.0000000e+00 3.5140342e-20 1.6773559e-13 1.5764645e-23], sampled 0.41945716361234664
[2019-03-26 10:03:33,744] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05447386], dtype=float32), 0.04941678]
[2019-03-26 10:03:33,745] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 87.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.989563501698276, 6.9112, 168.9119815193172, 1509386.446351835, 1453793.002079113, 311349.7299390625]
[2019-03-26 10:03:33,747] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:03:33,751] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1980361e-14 1.0000000e+00 6.9706795e-20 3.6790757e-12 1.5399693e-23], sampled 0.5146969542299717
[2019-03-26 10:03:53,241] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 10:03:53,985] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.1664 3163867357.5818 1774.0000
[2019-03-26 10:03:54,341] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.2473 2779197326.4671 933.0000
[2019-03-26 10:03:54,398] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.5735 3007648438.5815 1766.0000
[2019-03-26 10:03:54,558] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0228 2842641712.8067 1131.0000
[2019-03-26 10:03:55,574] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 150000, evaluation results [150000.0, 7885.166389812335, 3163867357.5817986, 1774.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8659.247307079566, 2779197326.467062, 933.0, 7997.573465804901, 3007648438.5815053, 1766.0, 8496.022801971903, 2842641712.8067207, 1131.0]
[2019-03-26 10:03:55,854] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.9969950e-17 1.0000000e+00 1.5489532e-24 1.6569902e-19 1.8582907e-27], sum to 1.0000
[2019-03-26 10:03:55,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7535
[2019-03-26 10:03:55,871] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 91.00000000000001, 1.0, 2.0, 0.4994966976570965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 697968.7981143754, 697968.7981143754, 183516.9880804003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5631000.0000, 
sim time next is 5631600.0000, 
raw observation next is [25.6, 91.0, 1.0, 2.0, 0.4998017135289544, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698395.1503723983, 698395.1503723983, 183564.7280372388], 
processed observation next is [0.0, 0.17391304347826086, 0.4123222748815167, 0.91, 1.0, 1.0, 0.3973514620830776, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19399865288122176, 0.19399865288122176, 0.27397720602572956], 
reward next is 0.7260, 
noisyNet noise sample is [array([-1.1929038], dtype=float32), 0.27408355]. 
=============================================
[2019-03-26 10:03:56,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.7909538e-17 1.0000000e+00 9.7000972e-24 8.1821997e-19 6.6201323e-27], sum to 1.0000
[2019-03-26 10:03:56,101] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6563
[2019-03-26 10:03:56,106] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.6, 91.0, 1.0, 2.0, 0.4983819537638847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696410.6066368707, 696410.6066368707, 183342.7465845901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5632800.0000, 
sim time next is 5633400.0000, 
raw observation next is [25.6, 91.0, 1.0, 2.0, 0.4978753062570742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695702.4143876395, 695702.4143876395, 183263.6760318325], 
processed observation next is [0.0, 0.17391304347826086, 0.4123222748815167, 0.91, 1.0, 1.0, 0.39503048946635444, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1932506706632332, 0.1932506706632332, 0.27352787467437684], 
reward next is 0.7265, 
noisyNet noise sample is [array([-1.1315209], dtype=float32), 0.37903112]. 
=============================================
[2019-03-26 10:03:59,385] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151784: loss 0.0386
[2019-03-26 10:03:59,386] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151784: learning rate 0.0001
[2019-03-26 10:03:59,510] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 151841: loss 0.0207
[2019-03-26 10:03:59,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 151841: learning rate 0.0001
[2019-03-26 10:03:59,643] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 151903: loss 0.0084
[2019-03-26 10:03:59,648] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 151903: learning rate 0.0001
[2019-03-26 10:03:59,659] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151909: loss 0.0094
[2019-03-26 10:03:59,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151909: learning rate 0.0001
[2019-03-26 10:03:59,662] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 151909: loss 0.0085
[2019-03-26 10:03:59,666] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 151910: learning rate 0.0001
[2019-03-26 10:03:59,733] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 151941: loss 0.0007
[2019-03-26 10:03:59,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 151941: learning rate 0.0001
[2019-03-26 10:03:59,761] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 151953: loss 0.0014
[2019-03-26 10:03:59,763] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 151953: learning rate 0.0001
[2019-03-26 10:03:59,794] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151970: loss 0.0002
[2019-03-26 10:03:59,800] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151972: learning rate 0.0001
[2019-03-26 10:03:59,841] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151990: loss 0.0014
[2019-03-26 10:03:59,843] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151991: learning rate 0.0001
[2019-03-26 10:03:59,875] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 152007: loss 0.0005
[2019-03-26 10:03:59,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 152007: learning rate 0.0001
[2019-03-26 10:03:59,882] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 152008: loss 0.0002
[2019-03-26 10:03:59,885] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 152009: learning rate 0.0001
[2019-03-26 10:03:59,889] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 152011: loss 0.0003
[2019-03-26 10:03:59,890] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 152011: learning rate 0.0001
[2019-03-26 10:03:59,997] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 152064: loss 0.0016
[2019-03-26 10:04:00,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 152064: learning rate 0.0001
[2019-03-26 10:04:00,032] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 152082: loss 0.0016
[2019-03-26 10:04:00,035] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 152083: learning rate 0.0001
[2019-03-26 10:04:00,109] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.4829371e-21 1.0000000e+00 1.5791991e-28 4.3312092e-23 1.0085574e-32], sum to 1.0000
[2019-03-26 10:04:00,121] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4255
[2019-03-26 10:04:00,124] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.58333333333334, 87.0, 1.0, 2.0, 0.5174033452941711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722999.0630069259, 722999.0630069259, 186367.320172311], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5699400.0000, 
sim time next is 5700000.0000, 
raw observation next is [26.56666666666667, 87.0, 1.0, 2.0, 0.5164692057412986, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721693.2897524032, 721693.2897524037, 186216.2916922576], 
processed observation next is [0.0, 1.0, 0.45813586097946307, 0.87, 1.0, 1.0, 0.4174327780015646, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20047035826455642, 0.2004703582645566, 0.2779347637197875], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.20655456], dtype=float32), -0.092472985]. 
=============================================
[2019-03-26 10:04:00,132] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[77.771225]
 [77.691956]
 [77.59085 ]
 [77.538765]
 [77.46343 ]], R is [[77.77458954]
 [77.71868134]
 [77.6632843 ]
 [77.6080246 ]
 [77.55287933]].
[2019-03-26 10:04:00,133] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 152128: loss 0.0047
[2019-03-26 10:04:00,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 152129: learning rate 0.0001
[2019-03-26 10:04:00,452] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152278: loss 0.0305
[2019-03-26 10:04:00,455] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152279: learning rate 0.0001
[2019-03-26 10:04:05,850] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1394602e-14 1.0000000e+00 8.5356393e-20 2.6276008e-13 6.2465130e-23], sum to 1.0000
[2019-03-26 10:04:05,860] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4871
[2019-03-26 10:04:05,864] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 92.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.045197537907256, 6.9112, 168.9117298846221, 1548881.806807033, 1453820.031908614, 311349.7601995257], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5802000.0000, 
sim time next is 5802600.0000, 
raw observation next is [26.25, 92.66666666666666, 1.0, 2.0, 1.005786816228913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128473643711, 1405898.657887456, 1405898.657887456, 300693.4458861564], 
processed observation next is [1.0, 0.13043478260869565, 0.4431279620853081, 0.9266666666666665, 1.0, 1.0, 1.0069720677456784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294394091951812, 0.3905274049687378, 0.3905274049687378, 0.4487961878897857], 
reward next is 0.5512, 
noisyNet noise sample is [array([-1.2578185], dtype=float32), -1.0789301]. 
=============================================
[2019-03-26 10:04:14,801] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4040477e-15 1.0000000e+00 1.6719542e-21 7.4549674e-15 3.3816763e-24], sum to 1.0000
[2019-03-26 10:04:14,813] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8483
[2019-03-26 10:04:14,816] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.1, 86.0, 1.0, 2.0, 0.5581219703799527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779918.55503559, 779918.55503559, 193203.6357014503], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5950800.0000, 
sim time next is 5951400.0000, 
raw observation next is [28.01666666666667, 86.5, 1.0, 2.0, 0.5603987752780217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783101.330594362, 783101.3305943614, 193600.1619550526], 
processed observation next is [1.0, 0.9130434782608695, 0.5268562401263824, 0.865, 1.0, 1.0, 0.470359970214484, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21752814738732276, 0.21752814738732262, 0.28895546560455615], 
reward next is 0.7110, 
noisyNet noise sample is [array([1.3004442], dtype=float32), 0.5109334]. 
=============================================
[2019-03-26 10:04:15,710] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.1308768e-15 1.0000000e+00 1.5066930e-20 2.1076218e-14 2.4372370e-23], sum to 1.0000
[2019-03-26 10:04:15,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5246
[2019-03-26 10:04:15,726] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 91.0, 1.0, 2.0, 0.5259219246361109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734906.7080904213, 734906.7080904213, 187757.2462098839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5968200.0000, 
sim time next is 5968800.0000, 
raw observation next is [26.4, 91.0, 1.0, 2.0, 0.5240565623480476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732299.2111800533, 732299.2111800539, 187451.1534132516], 
processed observation next is [1.0, 0.08695652173913043, 0.45023696682464454, 0.91, 1.0, 1.0, 0.42657417150367183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2034164475500148, 0.20341644755001498, 0.2797778409153009], 
reward next is 0.7202, 
noisyNet noise sample is [array([-1.0080644], dtype=float32), 0.37644106]. 
=============================================
[2019-03-26 10:04:16,457] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.7940483e-14 1.0000000e+00 3.9468677e-20 1.3288453e-13 1.3442878e-22], sum to 1.0000
[2019-03-26 10:04:16,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1714
[2019-03-26 10:04:16,470] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.35, 92.0, 1.0, 2.0, 0.6178315982302748, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 863390.5851196287, 863390.585119628, 204108.6099141939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5981400.0000, 
sim time next is 5982000.0000, 
raw observation next is [26.5, 91.33333333333334, 1.0, 2.0, 0.6156870231956513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 860392.4285413763, 860392.4285413756, 203698.7310376298], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.9133333333333334, 1.0, 1.0, 0.5369723171031943, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23899789681704897, 0.23899789681704878, 0.30402795677258176], 
reward next is 0.6960, 
noisyNet noise sample is [array([-0.11575714], dtype=float32), 0.8716193]. 
=============================================
[2019-03-26 10:04:16,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.705837]
 [54.636585]
 [54.63927 ]
 [54.562218]
 [54.455635]], R is [[54.78227234]
 [54.92981339]
 [55.07487488]
 [55.20659256]
 [55.33734131]].
[2019-03-26 10:04:17,089] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159841: loss 110.2645
[2019-03-26 10:04:17,091] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159842: learning rate 0.0001
[2019-03-26 10:04:17,178] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159882: loss 60.5656
[2019-03-26 10:04:17,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159884: learning rate 0.0001
[2019-03-26 10:04:17,196] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159890: loss -83.9810
[2019-03-26 10:04:17,198] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159890: learning rate 0.0001
[2019-03-26 10:04:17,232] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 159906: loss -8.1061
[2019-03-26 10:04:17,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 159906: learning rate 0.0001
[2019-03-26 10:04:17,239] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 159907: loss -19.9658
[2019-03-26 10:04:17,241] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 159909: learning rate 0.0001
[2019-03-26 10:04:17,262] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 159916: loss 34.9805
[2019-03-26 10:04:17,264] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 159916: learning rate 0.0001
[2019-03-26 10:04:17,300] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159931: loss 59.7456
[2019-03-26 10:04:17,301] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159931: learning rate 0.0001
[2019-03-26 10:04:17,319] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0514697e-08 4.1920462e-01 1.8721873e-10 5.8079535e-01 2.5666897e-14], sum to 1.0000
[2019-03-26 10:04:17,326] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0153
[2019-03-26 10:04:17,334] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2437252.757467312 W.
[2019-03-26 10:04:17,339] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.43333333333333, 71.66666666666667, 1.0, 2.0, 0.8714107683087583, 1.0, 1.0, 0.8714107683087583, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2437252.757467312, 2437252.757467311, 456140.0190085922], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6000600.0000, 
sim time next is 6001200.0000, 
raw observation next is [31.6, 71.0, 1.0, 2.0, 0.5169442414938709, 1.0, 2.0, 0.5169442414938709, 1.0, 1.0, 0.8977611914018298, 6.911199999999999, 6.9112, 170.5573041426782, 2168526.244796557, 2168526.244796557, 427061.9921378531], 
processed observation next is [1.0, 0.4782608695652174, 0.6966824644549764, 0.71, 1.0, 1.0, 0.41800511023357934, 1.0, 1.0, 0.41800511023357934, 1.0, 0.5, 0.8753185260997924, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6023684013323769, 0.6023684013323769, 0.6374059584147062], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4356811], dtype=float32), -1.7606663]. 
=============================================
[2019-03-26 10:04:17,379] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159966: loss 44.2772
[2019-03-26 10:04:17,381] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159966: learning rate 0.0001
[2019-03-26 10:04:17,425] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159985: loss 38.4607
[2019-03-26 10:04:17,428] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159985: learning rate 0.0001
[2019-03-26 10:04:17,485] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160010: loss -67.2645
[2019-03-26 10:04:17,487] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160011: learning rate 0.0001
[2019-03-26 10:04:17,508] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 160023: loss -60.1315
[2019-03-26 10:04:17,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 160024: learning rate 0.0001
[2019-03-26 10:04:17,543] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 160039: loss -13.0881
[2019-03-26 10:04:17,546] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 160039: learning rate 0.0001
[2019-03-26 10:04:17,560] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 160045: loss -79.7617
[2019-03-26 10:04:17,562] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 160046: learning rate 0.0001
[2019-03-26 10:04:17,630] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 160071: loss 99.1449
[2019-03-26 10:04:17,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 160072: learning rate 0.0001
[2019-03-26 10:04:17,795] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 160155: loss 42.6147
[2019-03-26 10:04:17,798] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 160155: learning rate 0.0001
[2019-03-26 10:04:18,123] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160302: loss 104.2685
[2019-03-26 10:04:18,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160302: learning rate 0.0001
[2019-03-26 10:04:23,170] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0945397e-08 8.6019945e-01 8.5066336e-11 1.3980064e-01 2.0217833e-14], sum to 1.0000
[2019-03-26 10:04:23,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6646
[2019-03-26 10:04:23,187] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2760050.605518908 W.
[2019-03-26 10:04:23,193] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 65.33333333333334, 1.0, 2.0, 0.6744145442274799, 1.0, 1.0, 0.6577973116280026, 1.0, 2.0, 1.03, 7.001347592533429, 6.9112, 170.5573041426782, 2760050.605518908, 2695474.2180176, 513526.1517508095], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6099600.0000, 
sim time next is 6100200.0000, 
raw observation next is [30.95, 65.5, 1.0, 2.0, 0.9267254557606474, 1.0, 2.0, 0.9267254557606474, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2592123.134253309, 2592123.134253309, 486275.5771416143], 
processed observation next is [1.0, 0.6086956521739131, 0.6658767772511848, 0.655, 1.0, 1.0, 0.9117174165790932, 1.0, 1.0, 0.9117174165790932, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7200342039592526, 0.7200342039592526, 0.7257844434949466], 
reward next is 0.2742, 
noisyNet noise sample is [array([-0.8405965], dtype=float32), -0.43454432]. 
=============================================
[2019-03-26 10:04:25,353] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.1393682e-16 1.0000000e+00 5.2882206e-22 3.0347770e-15 2.4243826e-25], sum to 1.0000
[2019-03-26 10:04:25,361] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5994
[2019-03-26 10:04:25,367] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 91.33333333333333, 1.0, 2.0, 0.5392792475745962, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753578.4306708007, 753578.4306708013, 189979.2090079504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6140400.0000, 
sim time next is 6141000.0000, 
raw observation next is [26.73333333333333, 91.66666666666667, 1.0, 2.0, 0.5401712434587672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 754825.3314103496, 754825.331410349, 190129.4420498498], 
processed observation next is [1.0, 0.043478260869565216, 0.4660347551342811, 0.9166666666666667, 1.0, 1.0, 0.4459894499503219, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20967370316954154, 0.2096737031695414, 0.28377528664156687], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.11302751], dtype=float32), -2.6250393]. 
=============================================
[2019-03-26 10:04:25,382] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[64.96123 ]
 [65.14896 ]
 [65.433655]
 [65.60258 ]
 [65.94256 ]], R is [[64.84086609]
 [64.90890503]
 [64.97657013]
 [65.04383087]
 [65.11056519]].
[2019-03-26 10:04:26,249] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.1287520e-13 1.0000000e+00 1.0300474e-17 5.5267352e-10 2.2338946e-20], sum to 1.0000
[2019-03-26 10:04:26,257] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-26 10:04:26,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 92.0, 1.0, 2.0, 0.7691406544920268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1074944.883617544, 1074944.883617544, 236477.1538080403], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6145200.0000, 
sim time next is 6145800.0000, 
raw observation next is [26.6, 92.0, 1.0, 2.0, 0.7764128767016052, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1085113.676703261, 1085113.676703261, 238203.5778158909], 
processed observation next is [1.0, 0.13043478260869565, 0.4597156398104266, 0.92, 1.0, 1.0, 0.7306179237368737, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3014204657509058, 0.3014204657509058, 0.35552772808341926], 
reward next is 0.6445, 
noisyNet noise sample is [array([-0.87316495], dtype=float32), -1.416577]. 
=============================================
[2019-03-26 10:04:34,531] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167815: loss 0.0253
[2019-03-26 10:04:34,537] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167818: learning rate 0.0001
[2019-03-26 10:04:34,555] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 167826: loss 0.0348
[2019-03-26 10:04:34,558] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 167827: learning rate 0.0001
[2019-03-26 10:04:34,652] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167871: loss 0.0378
[2019-03-26 10:04:34,655] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167871: learning rate 0.0001
[2019-03-26 10:04:34,720] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167904: loss 0.0362
[2019-03-26 10:04:34,723] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167906: learning rate 0.0001
[2019-03-26 10:04:34,724] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167906: loss 0.0313
[2019-03-26 10:04:34,725] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167906: learning rate 0.0001
[2019-03-26 10:04:34,766] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 167926: loss 0.0263
[2019-03-26 10:04:34,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 167926: learning rate 0.0001
[2019-03-26 10:04:34,783] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 167932: loss 0.0239
[2019-03-26 10:04:34,787] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 167933: learning rate 0.0001
[2019-03-26 10:04:34,794] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 167936: loss 0.0155
[2019-03-26 10:04:34,798] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 167936: learning rate 0.0001
[2019-03-26 10:04:34,930] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168000: loss 0.0069
[2019-03-26 10:04:34,932] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168000: learning rate 0.0001
[2019-03-26 10:04:34,950] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168010: loss 0.0031
[2019-03-26 10:04:34,951] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168010: learning rate 0.0001
[2019-03-26 10:04:34,968] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 168016: loss 0.0027
[2019-03-26 10:04:34,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 168016: learning rate 0.0001
[2019-03-26 10:04:34,975] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 168017: loss 0.0047
[2019-03-26 10:04:34,978] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 168018: learning rate 0.0001
[2019-03-26 10:04:35,017] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168037: loss 0.0016
[2019-03-26 10:04:35,019] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168037: learning rate 0.0001
[2019-03-26 10:04:35,038] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 168045: loss 0.0010
[2019-03-26 10:04:35,041] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 168045: learning rate 0.0001
[2019-03-26 10:04:35,310] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 168170: loss 0.0056
[2019-03-26 10:04:35,315] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 168170: learning rate 0.0001
[2019-03-26 10:04:35,364] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7180082e-20 1.0000000e+00 9.9958576e-28 3.6902543e-21 7.4079898e-31], sum to 1.0000
[2019-03-26 10:04:35,375] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8664
[2019-03-26 10:04:35,381] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5275248531119994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737147.3669765511, 737147.3669765511, 188020.9582585785], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306000.0000, 
sim time next is 6306600.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5277896534109376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737517.5194075225, 737517.5194075225, 188064.6001796792], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.43107187157944293, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2048659776132007, 0.2048659776132007, 0.2806934331039988], 
reward next is 0.7193, 
noisyNet noise sample is [array([-0.16630886], dtype=float32), 0.3083576]. 
=============================================
[2019-03-26 10:04:35,725] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168362: loss 0.0243
[2019-03-26 10:04:35,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168363: learning rate 0.0001
[2019-03-26 10:04:35,947] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.5548126e-18 1.0000000e+00 4.2829684e-24 6.5925385e-19 1.2510431e-27], sum to 1.0000
[2019-03-26 10:04:35,953] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0945
[2019-03-26 10:04:35,956] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 87.33333333333334, 1.0, 2.0, 0.5312311069662969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 742328.1843169428, 742328.1843169421, 188633.784903191], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6319200.0000, 
sim time next is 6319800.0000, 
raw observation next is [26.95, 87.5, 1.0, 2.0, 0.5303874794034517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 741148.9103894912, 741148.9103894919, 188493.8891668532], 
processed observation next is [0.0, 0.13043478260869565, 0.476303317535545, 0.875, 1.0, 1.0, 0.43420178241379714, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20587469733041425, 0.20587469733041444, 0.28133416293560176], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.89330214], dtype=float32), 0.023660555]. 
=============================================
[2019-03-26 10:04:38,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0846467e-20 1.0000000e+00 1.7610453e-28 6.6770873e-22 4.4025182e-32], sum to 1.0000
[2019-03-26 10:04:38,775] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0645
[2019-03-26 10:04:38,783] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 72.0, 1.0, 2.0, 0.5143807941019103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 718774.0400198154, 718774.0400198147, 185879.6017012107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6368400.0000, 
sim time next is 6369000.0000, 
raw observation next is [28.83333333333333, 72.5, 1.0, 2.0, 0.5145958578519927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719074.6627558827, 719074.6627558821, 185914.2497892027], 
processed observation next is [0.0, 0.7391304347826086, 0.5655608214849919, 0.725, 1.0, 1.0, 0.4151757323517984, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1997429618766341, 0.19974296187663393, 0.27748395490925776], 
reward next is 0.7225, 
noisyNet noise sample is [array([1.5491858], dtype=float32), 0.3333238]. 
=============================================
[2019-03-26 10:04:38,800] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.166336]
 [78.0341  ]
 [77.96822 ]
 [77.886116]
 [77.797554]], R is [[78.21602631]
 [78.15643311]
 [78.09708405]
 [78.03794861]
 [77.97896576]].
[2019-03-26 10:04:40,733] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.6942093e-15 1.0000000e+00 1.6708336e-19 1.1612944e-13 1.5937892e-22], sum to 1.0000
[2019-03-26 10:04:40,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3270
[2019-03-26 10:04:40,750] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 85.0, 1.0, 2.0, 0.9583714355945019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104158, 1339579.157639826, 1339579.157639826, 286497.0273371793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6404400.0000, 
sim time next is 6405000.0000, 
raw observation next is [26.86666666666667, 85.16666666666667, 1.0, 2.0, 0.936310181788323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1308723.677116371, 1308723.677116372, 280119.2126248339], 
processed observation next is [1.0, 0.13043478260869565, 0.4723538704581361, 0.8516666666666667, 1.0, 1.0, 0.9232652792630398, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3635343547545475, 0.36353435475454776, 0.4180883770519909], 
reward next is 0.5819, 
noisyNet noise sample is [array([1.5017446], dtype=float32), 0.42071837]. 
=============================================
[2019-03-26 10:04:40,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[59.049324]
 [58.044598]
 [57.539066]
 [59.213524]
 [59.421455]], R is [[59.89794159]
 [59.87135315]
 [59.27264023]
 [58.67991257]
 [58.09311295]].
[2019-03-26 10:04:50,060] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 10:04:50,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:04:50,063] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:04:50,063] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:04:50,063] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:04:50,064] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:04:50,065] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:04:50,066] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:04:50,067] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:04:50,064] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:04:50,072] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:04:50,080] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-26 10:04:50,081] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-26 10:04:50,116] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-26 10:04:50,135] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-26 10:04:50,155] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-26 10:04:56,082] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:04:56,085] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.6, 73.0, 1.0, 2.0, 0.5011485573053558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 811252.6944798813, 811252.6944798807, 195669.8367907342]
[2019-03-26 10:04:56,086] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:04:56,090] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1018011e-16 1.0000000e+00 2.9053318e-22 1.0207545e-15 5.2028686e-26], sampled 0.9889633208678917
[2019-03-26 10:04:57,500] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:04:57,502] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.25, 53.0, 1.0, 2.0, 0.6298245629480145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1029490.92409195, 1029490.92409195, 222093.0732988846]
[2019-03-26 10:04:57,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:04:57,508] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1194400e-16 1.0000000e+00 4.1597932e-21 3.1499454e-14 6.5444847e-25], sampled 0.6737278362035323
[2019-03-26 10:04:59,050] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:04:59,051] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.56666666666667, 75.33333333333334, 1.0, 2.0, 0.2373339693286704, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 392692.3431698664, 392692.3431698664, 159581.6865580959]
[2019-03-26 10:04:59,053] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:04:59,055] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0251573e-17 1.0000000e+00 9.9573690e-23 1.5163310e-16 1.0955173e-26], sampled 0.4661639242292386
[2019-03-26 10:05:33,331] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:05:33,332] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.79319974, 94.13176365333334, 1.0, 2.0, 0.2833219675020743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 459152.7318249321, 459152.7318249327, 164198.8810384205]
[2019-03-26 10:05:33,333] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:05:33,338] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.0982536e-18 1.0000000e+00 6.7862927e-24 5.1460051e-17 6.5290397e-28], sampled 0.6246034945810227
[2019-03-26 10:05:37,065] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:05:37,066] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.50897423333333, 87.15223642833332, 1.0, 2.0, 0.7560902604506434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1056696.681455876, 1056696.681455876, 233421.5280787961]
[2019-03-26 10:05:37,068] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:05:37,073] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5377030e-16 1.0000000e+00 4.6139639e-22 6.2115133e-15 5.9713788e-26], sampled 0.8681701274496029
[2019-03-26 10:05:39,744] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:05:39,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.13008144333334, 93.13228685666667, 1.0, 2.0, 0.540143591946461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 754786.6779688193, 754786.6779688193, 190123.6891455374]
[2019-03-26 10:05:39,747] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:05:39,750] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.16387823e-18 1.00000000e+00 1.19105414e-23 5.22965871e-16
 6.68682973e-28], sampled 0.22770684357480453
[2019-03-26 10:05:51,739] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:05:51,741] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.38553542333334, 60.20063967833334, 1.0, 2.0, 0.7001830458927774, 1.0, 2.0, 0.7001830458927774, 0.0, 2.0, 0.0, 6.9112, 6.9112, 171.5212843490159, 1957926.730891073, 1957926.730891073, 374412.3188699725]
[2019-03-26 10:05:51,743] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:05:51,747] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2046887e-10 6.9644861e-02 8.4781363e-13 9.3035507e-01 3.0029204e-18], sampled 0.35455486224372756
[2019-03-26 10:06:00,556] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:06:00,558] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.73333333333333, 80.83333333333333, 1.0, 2.0, 0.6333475180242777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 885082.3874353421, 885082.3874353414, 207123.0093401225]
[2019-03-26 10:06:00,559] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:06:00,563] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9359234e-17 1.0000000e+00 3.3442207e-22 5.9153027e-14 1.7444454e-26], sampled 0.48654880734265515
[2019-03-26 10:06:14,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:06:14,981] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.5, 87.0, 1.0, 2.0, 0.5931679079742955, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 828910.7893073682, 828910.7893073675, 199479.0751751842]
[2019-03-26 10:06:14,983] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:06:14,986] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6865646e-16 1.0000000e+00 6.1358973e-21 1.5695000e-13 6.5227265e-25], sampled 0.4152889425957673
[2019-03-26 10:06:22,553] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.0729114], dtype=float32), 0.051920637]
[2019-03-26 10:06:22,554] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.0, 57.0, 1.0, 2.0, 0.5786498362301425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808615.0737616816, 808615.0737616816, 196835.8992989636]
[2019-03-26 10:06:22,555] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:06:22,557] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0203803e-16 1.0000000e+00 2.4671815e-22 2.8614124e-15 2.3455550e-26], sampled 0.5503359895005506
[2019-03-26 10:06:45,797] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8326.8451 2921188738.4352 1164.0000
[2019-03-26 10:06:45,842] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8015.7591 3151378019.9016 1404.0000
[2019-03-26 10:06:45,955] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8133.1663 2993751377.6638 1405.0000
[2019-03-26 10:06:45,974] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8543.8140 2836867861.8862 991.0000
[2019-03-26 10:06:46,016] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8676.7420 2777526301.6019 892.0000
[2019-03-26 10:06:47,031] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 175000, evaluation results [175000.0, 8015.759079509698, 3151378019.901613, 1404.0, 8326.845143507284, 2921188738.435208, 1164.0, 8676.741985884802, 2777526301.6018867, 892.0, 8133.166346281482, 2993751377.6638327, 1405.0, 8543.81403581784, 2836867861.88623, 991.0]
[2019-03-26 10:06:48,718] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175788: loss -332.1172
[2019-03-26 10:06:48,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175788: learning rate 0.0001
[2019-03-26 10:06:48,811] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175831: loss -260.8094
[2019-03-26 10:06:48,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175831: learning rate 0.0001
[2019-03-26 10:06:48,893] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175870: loss -235.3947
[2019-03-26 10:06:48,895] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175871: learning rate 0.0001
[2019-03-26 10:06:48,966] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175904: loss -286.7376
[2019-03-26 10:06:48,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175904: learning rate 0.0001
[2019-03-26 10:06:48,988] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175909: loss -315.1747
[2019-03-26 10:06:48,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175912: learning rate 0.0001
[2019-03-26 10:06:49,079] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 175956: loss -355.7224
[2019-03-26 10:06:49,084] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 175956: learning rate 0.0001
[2019-03-26 10:06:49,093] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 175962: loss -237.3873
[2019-03-26 10:06:49,096] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 175963: learning rate 0.0001
[2019-03-26 10:06:49,137] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175980: loss -198.8300
[2019-03-26 10:06:49,138] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175980: learning rate 0.0001
[2019-03-26 10:06:49,154] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 175986: loss -180.1718
[2019-03-26 10:06:49,161] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 175988: learning rate 0.0001
[2019-03-26 10:06:49,199] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176008: loss -140.6090
[2019-03-26 10:06:49,202] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176009: learning rate 0.0001
[2019-03-26 10:06:49,207] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176010: loss -262.9597
[2019-03-26 10:06:49,210] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176011: learning rate 0.0001
[2019-03-26 10:06:49,227] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 176019: loss -417.0119
[2019-03-26 10:06:49,230] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 176020: learning rate 0.0001
[2019-03-26 10:06:49,282] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 176047: loss -305.9344
[2019-03-26 10:06:49,285] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 176047: learning rate 0.0001
[2019-03-26 10:06:49,293] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 176050: loss -208.8496
[2019-03-26 10:06:49,298] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 176050: learning rate 0.0001
[2019-03-26 10:06:49,483] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 176137: loss -231.6469
[2019-03-26 10:06:49,487] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 176137: learning rate 0.0001
[2019-03-26 10:06:50,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176382: loss -183.3216
[2019-03-26 10:06:50,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176382: learning rate 0.0001
[2019-03-26 10:06:51,001] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.9819797e-15 1.0000000e+00 5.0742235e-20 7.3624018e-10 2.6229931e-25], sum to 1.0000
[2019-03-26 10:06:51,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2579
[2019-03-26 10:06:51,015] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.28333333333333, 85.00000000000001, 1.0, 2.0, 0.5161159084074503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721199.4386814024, 721199.4386814018, 186160.3090534492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6631800.0000, 
sim time next is 6632400.0000, 
raw observation next is [27.26666666666667, 85.0, 1.0, 2.0, 0.518071380718566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723932.8674980478, 723932.8674980478, 186476.4307149869], 
processed observation next is [1.0, 0.782608695652174, 0.4913112164297, 0.85, 1.0, 1.0, 0.419363109299477, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20109246319390217, 0.20109246319390217, 0.2783230309178909], 
reward next is 0.7217, 
noisyNet noise sample is [array([-0.4104739], dtype=float32), -0.009976655]. 
=============================================
[2019-03-26 10:06:51,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.0226357e-13 9.9997652e-01 2.3331613e-16 2.3533041e-05 1.6643615e-21], sum to 1.0000
[2019-03-26 10:06:51,084] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1346
[2019-03-26 10:06:51,090] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 85.0, 1.0, 2.0, 0.5057470514827138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 706705.5988414165, 706705.5988414172, 184502.9006645521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6630600.0000, 
sim time next is 6631200.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.510881917168669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713883.2139919854, 713883.2139919861, 185319.6803340537], 
processed observation next is [1.0, 0.782608695652174, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4107011050224928, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19830089277555152, 0.1983008927755517, 0.2765965378120204], 
reward next is 0.7234, 
noisyNet noise sample is [array([-0.04028828], dtype=float32), -0.43895096]. 
=============================================
[2019-03-26 10:07:00,632] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.1238072e-11 9.9997711e-01 2.0449757e-14 2.2835879e-05 1.5142722e-17], sum to 1.0000
[2019-03-26 10:07:00,640] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5981
[2019-03-26 10:07:00,645] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 49.33333333333334, 1.0, 2.0, 0.9085777504663121, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1404029.505111161, 1404029.505111161, 290895.8092599801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6798000.0000, 
sim time next is 6798600.0000, 
raw observation next is [29.15, 49.5, 1.0, 2.0, 0.932907198460317, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1440898.914236708, 1440898.914236708, 298401.7275727542], 
processed observation next is [1.0, 0.6956521739130435, 0.5805687203791469, 0.495, 1.0, 1.0, 0.9191652993497795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4002496983990856, 0.4002496983990856, 0.44537571279515553], 
reward next is 0.5546, 
noisyNet noise sample is [array([-0.14238784], dtype=float32), -0.7120106]. 
=============================================
[2019-03-26 10:07:05,781] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183749: loss 0.0186
[2019-03-26 10:07:05,783] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183749: learning rate 0.0001
[2019-03-26 10:07:05,988] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183841: loss 0.0071
[2019-03-26 10:07:05,989] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 183841: loss 0.0059
[2019-03-26 10:07:05,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183841: learning rate 0.0001
[2019-03-26 10:07:05,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 183842: learning rate 0.0001
[2019-03-26 10:07:06,066] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183876: loss 0.0041
[2019-03-26 10:07:06,070] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183878: learning rate 0.0001
[2019-03-26 10:07:06,073] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183878: loss 0.0053
[2019-03-26 10:07:06,076] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183879: learning rate 0.0001
[2019-03-26 10:07:06,248] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 183962: loss 0.0010
[2019-03-26 10:07:06,252] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 183963: learning rate 0.0001
[2019-03-26 10:07:06,276] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 183975: loss 0.0014
[2019-03-26 10:07:06,278] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 183976: learning rate 0.0001
[2019-03-26 10:07:06,297] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183984: loss 0.0018
[2019-03-26 10:07:06,301] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183984: learning rate 0.0001
[2019-03-26 10:07:06,304] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 183986: loss 0.0017
[2019-03-26 10:07:06,307] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 183987: learning rate 0.0001
[2019-03-26 10:07:06,342] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 184000: loss 0.0009
[2019-03-26 10:07:06,343] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 184000: learning rate 0.0001
[2019-03-26 10:07:06,388] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184019: loss 0.0019
[2019-03-26 10:07:06,390] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184021: learning rate 0.0001
[2019-03-26 10:07:06,398] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184023: loss 0.0006
[2019-03-26 10:07:06,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184023: learning rate 0.0001
[2019-03-26 10:07:06,473] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 184063: loss 0.0007
[2019-03-26 10:07:06,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 184064: learning rate 0.0001
[2019-03-26 10:07:06,490] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 184071: loss 0.0009
[2019-03-26 10:07:06,491] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 184071: learning rate 0.0001
[2019-03-26 10:07:06,965] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 184160: loss 0.0072
[2019-03-26 10:07:06,967] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 184160: learning rate 0.0001
[2019-03-26 10:07:07,435] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184384: loss 0.0073
[2019-03-26 10:07:07,438] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184384: learning rate 0.0001
[2019-03-26 10:07:08,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3487593e-18 1.0000000e+00 6.8127201e-25 1.6646936e-20 8.9961128e-30], sum to 1.0000
[2019-03-26 10:07:08,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8987
[2019-03-26 10:07:08,198] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.66666666666667, 1.0, 2.0, 0.4169826035801141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613833.7400076356, 613833.7400076349, 175596.5747421358], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6927600.0000, 
sim time next is 6928200.0000, 
raw observation next is [23.75, 91.0, 1.0, 2.0, 0.4167690655225633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 613665.0841539429, 613665.0841539429, 175584.6354077567], 
processed observation next is [0.0, 0.17391304347826086, 0.3246445497630332, 0.91, 1.0, 1.0, 0.29731212713561844, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17046252337609524, 0.17046252337609524, 0.26206662001157716], 
reward next is 0.7379, 
noisyNet noise sample is [array([1.5609096], dtype=float32), 0.37880751]. 
=============================================
[2019-03-26 10:07:14,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.3130635e-11 5.1821142e-02 8.2942821e-13 9.4817889e-01 2.4546237e-18], sum to 1.0000
[2019-03-26 10:07:14,756] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4624
[2019-03-26 10:07:14,761] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.3, 49.66666666666667, 1.0, 2.0, 0.5545393463291837, 1.0, 2.0, 0.5545393463291837, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1569731.576734437, 1569731.576734437, 320386.5490149939], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7042800.0000, 
sim time next is 7043400.0000, 
raw observation next is [31.4, 49.0, 1.0, 2.0, 0.5005290616236027, 1.0, 2.0, 0.5005290616236027, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1423936.950929098, 1423936.950929098, 303357.0074360189], 
processed observation next is [1.0, 0.5217391304347826, 0.6872037914691943, 0.49, 1.0, 1.0, 0.3982277850886779, 1.0, 1.0, 0.3982277850886779, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.39553804192474945, 0.39553804192474945, 0.45277165288958043], 
reward next is 0.5472, 
noisyNet noise sample is [array([-1.1468059], dtype=float32), -0.49934405]. 
=============================================
[2019-03-26 10:07:18,822] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.10788092e-12 9.99999881e-01 9.37047244e-16 1.10814135e-07
 1.64009236e-19], sum to 1.0000
[2019-03-26 10:07:18,829] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-26 10:07:18,841] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1708112.386814125 W.
[2019-03-26 10:07:18,846] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 70.33333333333333, 1.0, 2.0, 0.4072758830402431, 1.0, 1.0, 0.4072758830402431, 1.0, 2.0, 0.683233861706624, 6.9112, 6.9112, 170.5573041426782, 1708112.386814125, 1708112.386814125, 353413.5275318288], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7120200.0000, 
sim time next is 7120800.0000, 
raw observation next is [28.1, 70.0, 1.0, 2.0, 0.6206222991629542, 1.0, 2.0, 0.6206222991629542, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1735279.21786926, 1735279.21786926, 341981.0035319635], 
processed observation next is [1.0, 0.43478260869565216, 0.5308056872037916, 0.7, 1.0, 1.0, 0.5429184327264508, 1.0, 1.0, 0.5429184327264508, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.48202200496368336, 0.48202200496368336, 0.510419408256662], 
reward next is 0.4896, 
noisyNet noise sample is [array([-0.5698544], dtype=float32), 1.7859105]. 
=============================================
[2019-03-26 10:07:23,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1266702e-15 1.0000000e+00 1.5002580e-20 3.4538106e-13 6.0003845e-24], sum to 1.0000
[2019-03-26 10:07:23,091] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2066
[2019-03-26 10:07:23,097] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 90.33333333333334, 1.0, 2.0, 0.5211679546692625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728261.3832011225, 728261.3832011219, 186978.3157707294], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7190400.0000, 
sim time next is 7191000.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.5590150052231301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 781166.9390698414, 781166.9390698408, 193355.4766735776], 
processed observation next is [1.0, 0.21739130434782608, 0.44075829383886256, 0.9, 1.0, 1.0, 0.4686927773772651, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21699081640828927, 0.21699081640828913, 0.2885902636919069], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.35518035], dtype=float32), 1.3282163]. 
=============================================
[2019-03-26 10:07:23,116] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.27085]
 [66.24649]
 [66.36188]
 [66.23888]
 [66.13531]], R is [[66.31153107]
 [66.36933899]
 [66.40402222]
 [66.46727753]
 [66.5300827 ]].
[2019-03-26 10:07:23,572] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191806: loss 0.0333
[2019-03-26 10:07:23,578] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191806: learning rate 0.0001
[2019-03-26 10:07:23,641] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191842: loss 0.0404
[2019-03-26 10:07:23,644] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191843: learning rate 0.0001
[2019-03-26 10:07:23,675] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191856: loss 0.0518
[2019-03-26 10:07:23,678] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191857: learning rate 0.0001
[2019-03-26 10:07:23,705] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191871: loss 0.0458
[2019-03-26 10:07:23,705] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 191871: loss 0.0475
[2019-03-26 10:07:23,709] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191873: learning rate 0.0001
[2019-03-26 10:07:23,716] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 191875: learning rate 0.0001
[2019-03-26 10:07:23,892] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191953: loss 0.0285
[2019-03-26 10:07:23,894] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191955: learning rate 0.0001
[2019-03-26 10:07:23,929] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 191971: loss 0.0254
[2019-03-26 10:07:23,931] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 191971: learning rate 0.0001
[2019-03-26 10:07:23,969] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191988: loss 0.0236
[2019-03-26 10:07:23,972] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191988: learning rate 0.0001
[2019-03-26 10:07:23,986] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 191995: loss 0.0219
[2019-03-26 10:07:23,991] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 191997: learning rate 0.0001
[2019-03-26 10:07:23,994] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 191998: loss 0.0229
[2019-03-26 10:07:23,997] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 191998: learning rate 0.0001
[2019-03-26 10:07:24,025] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192013: loss 0.0186
[2019-03-26 10:07:24,029] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192013: learning rate 0.0001
[2019-03-26 10:07:24,038] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 192019: loss 0.0170
[2019-03-26 10:07:24,039] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 192019: learning rate 0.0001
[2019-03-26 10:07:24,094] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 192045: loss 0.0146
[2019-03-26 10:07:24,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 192046: learning rate 0.0001
[2019-03-26 10:07:24,128] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 192058: loss 0.0107
[2019-03-26 10:07:24,130] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 192058: learning rate 0.0001
[2019-03-26 10:07:24,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.7782329e-12 9.9999952e-01 5.5710212e-15 5.1705172e-07 1.1254179e-18], sum to 1.0000
[2019-03-26 10:07:24,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5869
[2019-03-26 10:07:24,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1941582.032593131 W.
[2019-03-26 10:07:24,208] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.86666666666667, 84.0, 1.0, 2.0, 0.7474870251171549, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005978205371678, 6.9112, 168.9123932017648, 1941582.032593131, 1874343.335923797, 395271.3247053528], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7203000.0000, 
sim time next is 7203600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.7748107117172248, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005979955055921, 6.9112, 168.912316035616, 1979820.625895751, 1912580.718662312, 401701.5713800529], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.84, 1.0, 1.0, 0.7286876044785842, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00947799550559214, 0.0, 0.8294368001277503, 0.5499501738599308, 0.5312724218506423, 0.5995545841493327], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.210905], dtype=float32), 0.28421214]. 
=============================================
[2019-03-26 10:07:24,230] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 192103: loss 0.0085
[2019-03-26 10:07:24,232] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 192103: learning rate 0.0001
[2019-03-26 10:07:24,660] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192303: loss 0.0055
[2019-03-26 10:07:24,664] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192304: learning rate 0.0001
[2019-03-26 10:07:25,494] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.2554775e-12 9.9982268e-01 2.5613995e-15 1.7732143e-04 2.1017275e-19], sum to 1.0000
[2019-03-26 10:07:25,501] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6682
[2019-03-26 10:07:25,512] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1724837.205338543 W.
[2019-03-26 10:07:25,520] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.45, 89.0, 1.0, 2.0, 0.6095927258901325, 1.0, 1.0, 0.6095927258901325, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1724837.205338543, 1724837.205338543, 340299.4225934862], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7223400.0000, 
sim time next is 7224000.0000, 
raw observation next is [24.3, 89.0, 1.0, 2.0, 0.3726727675429677, 1.0, 2.0, 0.3726727675429677, 1.0, 1.0, 0.6230306771553226, 6.911199999999999, 6.9112, 170.5573041426782, 1573345.137254351, 1573345.137254352, 335969.8002235222], 
processed observation next is [1.0, 0.6086956521739131, 0.3507109004739337, 0.89, 1.0, 1.0, 0.24418405728068396, 1.0, 1.0, 0.24418405728068396, 1.0, 0.5, 0.5402813136040518, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4370403159039864, 0.4370403159039867, 0.5014474630201824], 
reward next is 0.4986, 
noisyNet noise sample is [array([1.1584464], dtype=float32), -1.0919344]. 
=============================================
[2019-03-26 10:07:25,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[60.69163 ]
 [61.597572]
 [60.70811 ]
 [62.50446 ]
 [64.07692 ]], R is [[59.09687424]
 [58.50590515]
 [57.92084503]
 [57.82642746]
 [57.70785522]].
[2019-03-26 10:07:37,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.5595610e-20 1.0000000e+00 6.0616676e-26 5.0115358e-18 3.4299180e-30], sum to 1.0000
[2019-03-26 10:07:37,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0578
[2019-03-26 10:07:37,111] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.13333333333334, 93.66666666666667, 1.0, 2.0, 0.3173719816561104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 500730.4681504198, 500730.4681504204, 167056.7677478002], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431000.0000, 
sim time next is 7431600.0000, 
raw observation next is [21.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3177128470433545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501348.4929683455, 501348.4929683455, 167104.9131622994], 
processed observation next is [0.0, 0.0, 0.2022116903633494, 0.9333333333333335, 1.0, 1.0, 0.177967285594403, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13926347026898486, 0.13926347026898486, 0.2494103181526857], 
reward next is 0.7506, 
noisyNet noise sample is [array([-0.38961887], dtype=float32), -1.5545273]. 
=============================================
[2019-03-26 10:07:40,949] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199804: loss 0.0126
[2019-03-26 10:07:40,951] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199804: learning rate 0.0001
[2019-03-26 10:07:41,006] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199840: loss 0.0159
[2019-03-26 10:07:41,008] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199841: learning rate 0.0001
[2019-03-26 10:07:41,013] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199843: loss 0.0147
[2019-03-26 10:07:41,016] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199844: learning rate 0.0001
[2019-03-26 10:07:41,058] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199869: loss 0.0088
[2019-03-26 10:07:41,059] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199869: learning rate 0.0001
[2019-03-26 10:07:41,157] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 199932: loss 0.0047
[2019-03-26 10:07:41,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 199934: learning rate 0.0001
[2019-03-26 10:07:41,164] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 199937: loss 0.0062
[2019-03-26 10:07:41,168] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 199941: learning rate 0.0001
[2019-03-26 10:07:41,181] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199947: loss 0.0055
[2019-03-26 10:07:41,184] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199947: learning rate 0.0001
[2019-03-26 10:07:41,216] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199965: loss 0.0020
[2019-03-26 10:07:41,217] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199965: learning rate 0.0001
[2019-03-26 10:07:41,218] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 199965: loss 0.0012
[2019-03-26 10:07:41,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 199965: learning rate 0.0001
[2019-03-26 10:07:41,238] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199979: loss 0.0011
[2019-03-26 10:07:41,239] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199979: learning rate 0.0001
[2019-03-26 10:07:41,268] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 10:07:41,271] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:07:41,271] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:07:41,272] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:07:41,272] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:07:41,274] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:07:41,272] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:07:41,274] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:07:41,276] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:07:41,276] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:07:41,274] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:07:41,285] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-26 10:07:41,302] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-26 10:07:41,319] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-26 10:07:41,337] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-26 10:07:41,343] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-26 10:08:35,535] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06279635], dtype=float32), 0.077810846]
[2019-03-26 10:08:35,536] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.163701965, 71.50203445, 1.0, 2.0, 0.5601969087703578, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 782819.1383588623, 782819.1383588617, 193564.1703875582]
[2019-03-26 10:08:35,538] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:08:35,543] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0019024e-18 1.0000000e+00 5.3601730e-24 1.6844491e-15 4.3294285e-29], sampled 0.5782469812233791
[2019-03-26 10:08:53,049] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06279635], dtype=float32), 0.077810846]
[2019-03-26 10:08:53,050] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.13901371, 71.04403798499999, 1.0, 2.0, 0.5320478605806744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743469.8934517392, 743469.8934517392, 188770.7066935613]
[2019-03-26 10:08:53,052] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:08:53,054] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1149062e-19 1.0000000e+00 5.4611355e-26 3.4814662e-19 2.1001249e-30], sampled 0.15715583586418214
[2019-03-26 10:09:04,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06279635], dtype=float32), 0.077810846]
[2019-03-26 10:09:04,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.78333333333333, 91.33333333333334, 1.0, 2.0, 0.619923088964646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 866314.5369909039, 866314.5369909045, 204516.1501466305]
[2019-03-26 10:09:04,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:09:04,861] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0220482e-19 1.0000000e+00 9.1272784e-26 1.7134931e-19 4.2384219e-30], sampled 0.250933047665474
[2019-03-26 10:09:08,227] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06279635], dtype=float32), 0.077810846]
[2019-03-26 10:09:08,230] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.435450835, 85.06435786833333, 1.0, 2.0, 0.5411084395357082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756135.4180471925, 756135.4180471932, 190286.8546187121]
[2019-03-26 10:09:08,231] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:09:08,233] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4083234e-20 1.0000000e+00 2.1689196e-26 5.5821596e-19 2.5031181e-31], sampled 0.183147144659062
[2019-03-26 10:09:19,686] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06279635], dtype=float32), 0.077810846]
[2019-03-26 10:09:19,689] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.25, 52.5, 1.0, 2.0, 0.8659127067145393, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1344645.596476443, 1344645.596476443, 278803.5744350529]
[2019-03-26 10:09:19,692] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:09:19,694] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7637777e-17 1.0000000e+00 2.2631064e-22 2.7662438e-15 1.2478693e-26], sampled 0.023896290553609534
[2019-03-26 10:09:36,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7894.0146 3162836672.8084 1750.0000
[2019-03-26 10:09:36,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 10:09:36,759] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.3173 2841841854.4767 1118.0000
[2019-03-26 10:09:36,820] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8001.4195 3007176979.4601 1757.0000
[2019-03-26 10:09:36,975] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 10:09:37,989] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 200000, evaluation results [200000.0, 7894.014598539858, 3162836672.808385, 1750.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 8001.41952622402, 3007176979.460052, 1757.0, 8501.317263278846, 2841841854.4767127, 1118.0]
[2019-03-26 10:09:38,007] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200008: loss 0.0014
[2019-03-26 10:09:38,017] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200009: learning rate 0.0001
[2019-03-26 10:09:38,055] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 200032: loss 0.0008
[2019-03-26 10:09:38,060] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 200034: learning rate 0.0001
[2019-03-26 10:09:38,109] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 200060: loss 0.0003
[2019-03-26 10:09:38,112] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 200060: learning rate 0.0001
[2019-03-26 10:09:38,208] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200106: loss 0.0005
[2019-03-26 10:09:38,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200106: learning rate 0.0001
[2019-03-26 10:09:38,328] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 200161: loss 0.0016
[2019-03-26 10:09:38,331] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 200161: learning rate 0.0001
[2019-03-26 10:09:38,699] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200332: loss 0.0290
[2019-03-26 10:09:38,700] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200332: learning rate 0.0001
[2019-03-26 10:09:41,841] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3667377e-20 1.0000000e+00 9.9667787e-26 2.0957577e-20 1.1810510e-30], sum to 1.0000
[2019-03-26 10:09:41,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6007
[2019-03-26 10:09:41,859] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 61.0, 1.0, 2.0, 0.4466220104644879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 632240.670983596, 632240.6709835954, 176714.2738547961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7569600.0000, 
sim time next is 7570200.0000, 
raw observation next is [29.83333333333333, 61.5, 1.0, 2.0, 0.458272404193082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 641912.5485249424, 641912.548524943, 177519.9782074696], 
processed observation next is [0.0, 0.6086956521739131, 0.6129541864139019, 0.615, 1.0, 1.0, 0.3473161496302193, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17830904125692842, 0.1783090412569286, 0.26495519135443224], 
reward next is 0.7350, 
noisyNet noise sample is [array([0.3662829], dtype=float32), 0.7833347]. 
=============================================
[2019-03-26 10:09:46,164] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4152207e-10 1.4350123e-02 4.2929059e-12 9.8564988e-01 1.2734012e-15], sum to 1.0000
[2019-03-26 10:09:46,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6177
[2019-03-26 10:09:46,179] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 62.0, 1.0, 2.0, 0.633461198941236, 1.0, 2.0, 0.633461198941236, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1771206.848530161, 1771206.848530161, 346929.8739902041], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7646400.0000, 
sim time next is 7647000.0000, 
raw observation next is [30.16666666666667, 61.66666666666667, 1.0, 2.0, 0.6322292284717401, 1.0, 2.0, 0.6322292284717401, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1767759.321748492, 1767759.321748492, 346451.1154959053], 
processed observation next is [1.0, 0.5217391304347826, 0.6287519747235389, 0.6166666666666667, 1.0, 1.0, 0.5569026849057109, 1.0, 1.0, 0.5569026849057109, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4910442560412478, 0.4910442560412478, 0.5170912171580676], 
reward next is 0.4829, 
noisyNet noise sample is [array([0.38238713], dtype=float32), -0.46998692]. 
=============================================
[2019-03-26 10:09:46,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[51.49642 ]
 [50.795826]
 [50.54589 ]
 [51.007725]
 [52.06423 ]], R is [[51.94802856]
 [51.9107399 ]
 [51.89341736]
 [51.37448502]
 [51.10939407]].
[2019-03-26 10:09:50,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.9494955e-10 1.7326461e-02 5.1290686e-12 9.8267347e-01 4.3553505e-16], sum to 1.0000
[2019-03-26 10:09:50,766] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2813
[2019-03-26 10:09:50,771] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 70.0, 1.0, 2.0, 0.7149804947499264, 1.0, 2.0, 0.7149804947499264, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1999353.818390331, 1999353.818390332, 380602.1868117155], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7726200.0000, 
sim time next is 7726800.0000, 
raw observation next is [30.3, 69.0, 1.0, 2.0, 0.7115892504432461, 1.0, 2.0, 0.7115892504432461, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1989861.819462789, 1989861.819462789, 379124.0942514781], 
processed observation next is [1.0, 0.43478260869565216, 0.6350710900473934, 0.69, 1.0, 1.0, 0.6525171692087302, 1.0, 1.0, 0.6525171692087302, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5527393942952191, 0.5527393942952191, 0.5658568570917584], 
reward next is 0.4341, 
noisyNet noise sample is [array([0.31794715], dtype=float32), -1.683609]. 
=============================================
[2019-03-26 10:09:54,421] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3443222e-13 1.0000000e+00 6.4999476e-18 6.5129052e-10 2.8287794e-21], sum to 1.0000
[2019-03-26 10:09:54,430] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9971
[2019-03-26 10:09:54,434] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 87.0, 1.0, 2.0, 0.7053821843912768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 985795.1914524789, 985795.1914524782, 222008.5040871757], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7786800.0000, 
sim time next is 7787400.0000, 
raw observation next is [26.03333333333334, 87.33333333333333, 1.0, 2.0, 0.7174171810198852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1002622.441370717, 1002622.441370718, 224646.8171354372], 
processed observation next is [1.0, 0.13043478260869565, 0.4328593996840445, 0.8733333333333333, 1.0, 1.0, 0.6595387723131146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27850623371408806, 0.27850623371408834, 0.33529375691856295], 
reward next is 0.6647, 
noisyNet noise sample is [array([-0.86147547], dtype=float32), -0.7216953]. 
=============================================
[2019-03-26 10:09:54,623] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0892946e-13 1.0000000e+00 7.7927807e-19 1.0839077e-10 8.8557318e-22], sum to 1.0000
[2019-03-26 10:09:54,634] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4843
[2019-03-26 10:09:54,640] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.55, 86.5, 1.0, 2.0, 0.591526285397432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 826615.8435479895, 826615.8435479889, 199171.7784399833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7799400.0000, 
sim time next is 7800000.0000, 
raw observation next is [26.66666666666666, 86.0, 1.0, 2.0, 0.6004791451257872, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839131.7693257811, 839131.7693257811, 200828.6099888635], 
processed observation next is [1.0, 0.2608695652173913, 0.4628751974723536, 0.86, 1.0, 1.0, 0.5186495724407074, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23309215814605033, 0.23309215814605033, 0.2997441940132291], 
reward next is 0.7003, 
noisyNet noise sample is [array([-1.1505141], dtype=float32), -1.5763414]. 
=============================================
[2019-03-26 10:09:54,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.292244]
 [62.28366 ]
 [62.277874]
 [62.426647]
 [62.444656]], R is [[62.39167404]
 [62.47048569]
 [62.5461731 ]
 [62.60514832]
 [62.67208099]].
[2019-03-26 10:09:54,657] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207768: loss 0.0501
[2019-03-26 10:09:54,659] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207769: learning rate 0.0001
[2019-03-26 10:09:54,851] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207852: loss 0.0255
[2019-03-26 10:09:54,853] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207854: learning rate 0.0001
[2019-03-26 10:09:54,861] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207857: loss 0.0224
[2019-03-26 10:09:54,863] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207857: learning rate 0.0001
[2019-03-26 10:09:54,982] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207920: loss 0.0120
[2019-03-26 10:09:54,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207922: learning rate 0.0001
[2019-03-26 10:09:55,001] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207929: loss 0.0112
[2019-03-26 10:09:55,003] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 207929: loss 0.0128
[2019-03-26 10:09:55,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207929: learning rate 0.0001
[2019-03-26 10:09:55,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 207929: learning rate 0.0001
[2019-03-26 10:09:55,046] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 207942: loss 0.0102
[2019-03-26 10:09:55,051] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 207942: learning rate 0.0001
[2019-03-26 10:09:55,096] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207970: loss 0.0086
[2019-03-26 10:09:55,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207970: learning rate 0.0001
[2019-03-26 10:09:55,134] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 207988: loss 0.0065
[2019-03-26 10:09:55,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 207989: learning rate 0.0001
[2019-03-26 10:09:55,148] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 207995: loss 0.0065
[2019-03-26 10:09:55,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 207995: learning rate 0.0001
[2019-03-26 10:09:55,164] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208000: loss 0.0064
[2019-03-26 10:09:55,165] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208001: learning rate 0.0001
[2019-03-26 10:09:55,194] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 208011: loss 0.0057
[2019-03-26 10:09:55,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 208011: learning rate 0.0001
[2019-03-26 10:09:55,299] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 208061: loss 0.0054
[2019-03-26 10:09:55,304] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 208061: learning rate 0.0001
[2019-03-26 10:09:55,473] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208139: loss 0.0054
[2019-03-26 10:09:55,477] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208140: learning rate 0.0001
[2019-03-26 10:09:55,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 208151: loss 0.0052
[2019-03-26 10:09:55,500] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 208151: learning rate 0.0001
[2019-03-26 10:09:55,746] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208263: loss 0.0091
[2019-03-26 10:09:55,748] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208264: learning rate 0.0001
[2019-03-26 10:09:59,234] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7136814e-14 1.0000000e+00 2.0424056e-19 3.0748053e-11 6.3356417e-23], sum to 1.0000
[2019-03-26 10:09:59,245] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-26 10:09:59,253] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.01666666666667, 92.66666666666666, 1.0, 2.0, 0.516181769514956, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721291.5015678477, 721291.5015678477, 186170.4629363054], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7869000.0000, 
sim time next is 7869600.0000, 
raw observation next is [26.0, 93.0, 1.0, 2.0, 0.5168121406473952, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722172.6560878269, 722172.6560878276, 186272.348167579], 
processed observation next is [1.0, 0.08695652173913043, 0.4312796208530806, 0.93, 1.0, 1.0, 0.4178459525872231, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20060351557995193, 0.20060351557995212, 0.2780184301008642], 
reward next is 0.7220, 
noisyNet noise sample is [array([1.5023068], dtype=float32), 0.47179917]. 
=============================================
[2019-03-26 10:10:03,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4844400e-17 1.0000000e+00 1.3263115e-23 7.3013312e-14 1.2623037e-27], sum to 1.0000
[2019-03-26 10:10:03,777] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0837
[2019-03-26 10:10:03,780] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.7, 89.5, 1.0, 2.0, 0.5296601283048128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 740132.1758280952, 740132.1758280959, 188373.6006343171], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [26.63333333333333, 90.0, 1.0, 2.0, 0.528340222514659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738287.1356138209, 738287.1356138209, 188155.5502397603], 
processed observation next is [1.0, 0.9565217391304348, 0.46129541864139006, 0.9, 1.0, 1.0, 0.43173520784898667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20507975989272803, 0.20507975989272803, 0.2808291794623288], 
reward next is 0.7192, 
noisyNet noise sample is [array([-0.15628247], dtype=float32), -0.11505018]. 
=============================================
[2019-03-26 10:10:03,789] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[76.94691]
 [76.91573]
 [76.89529]
 [76.68686]
 [76.81032]], R is [[76.9295578 ]
 [76.87910461]
 [76.82917023]
 [76.78028107]
 [76.7321167 ]].
[2019-03-26 10:10:04,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,415] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-26 10:10:04,492] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,492] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,493] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-26 10:10:04,605] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,605] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,606] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-26 10:10:04,644] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-26 10:10:04,702] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,702] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,704] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-26 10:10:04,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,794] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-26 10:10:04,796] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,857] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-26 10:10:04,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:04,915] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,916] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-26 10:10:04,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-26 10:10:04,849] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,038] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,801] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:05,041] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-26 10:10:04,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,089] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:05,091] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-26 10:10:04,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,143] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:04,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,146] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:05,147] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-26 10:10:04,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:05,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-26 10:10:05,145] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-26 10:10:04,802] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:10:05,430] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:05,431] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-26 10:10:05,552] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-26 10:10:08,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2332416e-07 9.9999964e-01 6.9934047e-10 1.9510306e-07 7.5862427e-11], sum to 1.0000
[2019-03-26 10:10:08,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9118
[2019-03-26 10:10:08,049] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 84.66666666666667, 1.0, 2.0, 0.2663237007474515, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 434981.5357246883, 434981.5357246888, 162532.3415845364], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6000.0000, 
sim time next is 6600.0000, 
raw observation next is [20.53333333333333, 84.83333333333334, 1.0, 2.0, 0.2679605920393727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 437087.9319102297, 437087.9319102297, 162685.9713312101], 
processed observation next is [1.0, 0.043478260869565216, 0.17219589257503945, 0.8483333333333334, 1.0, 1.0, 0.11802480968599123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12141331441950824, 0.12141331441950824, 0.2428148825838957], 
reward next is 0.7572, 
noisyNet noise sample is [array([0.65209913], dtype=float32), 1.0557204]. 
=============================================
[2019-03-26 10:10:12,768] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5930994e-18 1.0000000e+00 5.9653291e-24 1.9213242e-16 7.7849266e-29], sum to 1.0000
[2019-03-26 10:10:12,773] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3466
[2019-03-26 10:10:12,781] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 89.0, 1.0, 2.0, 0.3454056423985683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536040.1334539771, 536040.1334539765, 169605.132465738], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [22.38333333333333, 89.0, 1.0, 2.0, 0.3465905827298968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537635.9804984198, 537635.9804984193, 169728.4461324258], 
processed observation next is [1.0, 0.043478260869565216, 0.25987361769352274, 0.89, 1.0, 1.0, 0.2127597382287913, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14934332791622773, 0.14934332791622756, 0.2533260390036206], 
reward next is 0.7467, 
noisyNet noise sample is [array([-1.0719069], dtype=float32), 0.59000736]. 
=============================================
[2019-03-26 10:10:12,794] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.98239]
 [77.00465]
 [77.14342]
 [77.19932]
 [77.47823]], R is [[76.94689178]
 [76.92427826]
 [76.90203094]
 [76.88008881]
 [76.85835266]].
[2019-03-26 10:10:23,457] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8144064e-19 1.0000000e+00 2.5071668e-26 4.4230462e-21 2.7473671e-30], sum to 1.0000
[2019-03-26 10:10:23,465] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-26 10:10:23,470] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.76666666666667, 94.66666666666666, 1.0, 2.0, 0.2734517028126561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442613.6084806612, 442613.6084806618, 163106.7859766746], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 272400.0000, 
sim time next is 273000.0000, 
raw observation next is [19.68333333333334, 94.83333333333333, 1.0, 2.0, 0.271873520447051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 440555.6388244175, 440555.6388244175, 162968.2208868575], 
processed observation next is [0.0, 0.13043478260869565, 0.13191153238546643, 0.9483333333333333, 1.0, 1.0, 0.12273918126150721, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12237656634011597, 0.12237656634011597, 0.24323615057739928], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.5813174], dtype=float32), 0.3717191]. 
=============================================
[2019-03-26 10:10:23,492] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[74.868835]
 [74.87365 ]
 [74.86628 ]
 [74.84138 ]
 [74.77557 ]], R is [[74.86743164]
 [74.87531281]
 [74.88284302]
 [74.89000702]
 [74.89680481]].
[2019-03-26 10:10:27,005] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.1681429e-21 1.0000000e+00 2.2043014e-27 1.7862339e-21 6.5084644e-31], sum to 1.0000
[2019-03-26 10:10:27,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1039
[2019-03-26 10:10:27,025] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.0, 1.0, 2.0, 0.2886586707403454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462513.7222599693, 462513.72225997, 164432.0790236724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 329400.0000, 
sim time next is 330000.0000, 
raw observation next is [21.43333333333333, 85.33333333333333, 1.0, 2.0, 0.2878063677158854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461361.9366500977, 461361.9366500982, 164355.0262740652], 
processed observation next is [0.0, 0.8260869565217391, 0.21484992101105835, 0.8533333333333333, 1.0, 1.0, 0.14193538279022339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12815609351391602, 0.12815609351391616, 0.2453060093642764], 
reward next is 0.7547, 
noisyNet noise sample is [array([-0.27120417], dtype=float32), -1.8407261]. 
=============================================
[2019-03-26 10:10:27,043] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[79.61486]
 [79.5656 ]
 [79.52247]
 [79.45992]
 [79.381  ]], R is [[79.61568451]
 [79.57410431]
 [79.53282166]
 [79.49179077]
 [79.4509201 ]].
[2019-03-26 10:10:29,710] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1404847e-18 1.0000000e+00 1.5454539e-23 3.7979327e-16 1.8853525e-27], sum to 1.0000
[2019-03-26 10:10:29,719] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4743
[2019-03-26 10:10:29,727] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 72.0, 1.0, 2.0, 0.467161369936644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 760201.3799058652, 760201.3799058646, 189919.8213142541], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 385200.0000, 
sim time next is 385800.0000, 
raw observation next is [22.43333333333333, 72.16666666666667, 1.0, 2.0, 0.4887070843447773, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794751.4259406975, 794751.4259406975, 193622.5392612843], 
processed observation next is [1.0, 0.4782608695652174, 0.2622432859399683, 0.7216666666666667, 1.0, 1.0, 0.38398443896961115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2207642849835271, 0.2207642849835271, 0.28898886456908107], 
reward next is 0.7110, 
noisyNet noise sample is [array([1.8488451], dtype=float32), -0.25048023]. 
=============================================
[2019-03-26 10:10:33,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.6933619e-17 1.0000000e+00 2.2366453e-23 5.4090016e-15 3.2426340e-26], sum to 1.0000
[2019-03-26 10:10:33,195] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9262
[2019-03-26 10:10:33,201] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.6, 85.0, 1.0, 2.0, 0.2393795938962013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 394980.12064865, 394980.1206486494, 159841.9166773104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 437400.0000, 
sim time next is 438000.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2382350530745168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 393091.6959793719, 393091.6959793713, 159733.593356395], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08221090731869495, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10919213777204775, 0.10919213777204759, 0.23840834829312685], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.07066058], dtype=float32), -0.42246482]. 
=============================================
[2019-03-26 10:10:33,213] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[71.36953 ]
 [71.422615]
 [71.38811 ]
 [71.56654 ]
 [71.77701 ]], R is [[71.47275543]
 [71.51945496]
 [71.56563568]
 [71.61147308]
 [71.65688324]].
[2019-03-26 10:10:33,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1668927e-17 1.0000000e+00 1.0744322e-23 4.5482162e-17 3.2187853e-27], sum to 1.0000
[2019-03-26 10:10:33,257] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4011
[2019-03-26 10:10:33,263] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 83.0, 1.0, 2.0, 0.2300859453973368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380247.7930478861, 380247.7930478854, 158941.7683913859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 446400.0000, 
sim time next is 447000.0000, 
raw observation next is [19.7, 82.83333333333334, 1.0, 2.0, 0.2293239952763556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379049.5574255372, 379049.5574255366, 158867.9655074656], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.8283333333333335, 1.0, 1.0, 0.07147469310404289, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10529154372931589, 0.10529154372931573, 0.23711636642905312], 
reward next is 0.7629, 
noisyNet noise sample is [array([0.27592823], dtype=float32), -0.21160676]. 
=============================================
[2019-03-26 10:10:33,284] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[72.666565]
 [72.693596]
 [72.74102 ]
 [72.79339 ]
 [72.83919 ]], R is [[72.69429016]
 [72.7301178 ]
 [72.76551819]
 [72.80051422]
 [72.83514404]].
[2019-03-26 10:10:34,505] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6047242e-18 1.0000000e+00 2.6431333e-24 8.3916547e-18 3.8432351e-28], sum to 1.0000
[2019-03-26 10:10:34,512] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8613
[2019-03-26 10:10:34,519] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.06666666666667, 75.83333333333333, 1.0, 2.0, 0.4052513659093974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666519.4414477205, 666519.4414477205, 180246.454953312], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 463800.0000, 
sim time next is 464400.0000, 
raw observation next is [21.2, 75.0, 1.0, 2.0, 0.4228065751600374, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 695236.5461233738, 695236.5461233745, 182903.5054878025], 
processed observation next is [1.0, 0.391304347826087, 0.20379146919431282, 0.75, 1.0, 1.0, 0.30458623513257516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19312126281204828, 0.19312126281204847, 0.27299030669821267], 
reward next is 0.7270, 
noisyNet noise sample is [array([0.273685], dtype=float32), -0.59325856]. 
=============================================
[2019-03-26 10:10:35,638] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 10:10:35,640] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:10:35,641] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:10:35,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:35,641] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:10:35,641] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:35,644] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:10:35,644] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:35,645] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:35,643] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:10:35,648] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:10:35,657] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-26 10:10:35,671] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-26 10:10:35,688] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-26 10:10:35,689] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-26 10:10:35,708] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-26 10:11:02,485] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:02,486] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.86666666666667, 85.33333333333334, 1.0, 2.0, 0.889633826600338, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1243443.789783539, 1243443.789783539, 267098.1761253012]
[2019-03-26 10:11:02,487] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:11:02,491] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.98623155e-16 1.00000000e+00 1.83360840e-21 1.01786655e-13
 9.91895460e-25], sampled 0.9388189045013516
[2019-03-26 10:11:15,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:15,943] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.45, 83.16666666666667, 1.0, 2.0, 0.5257593534253651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734679.4576483017, 734679.457648301, 187730.1843470889]
[2019-03-26 10:11:15,944] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:11:15,948] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.3970279e-18 1.0000000e+00 3.0200848e-24 4.4244195e-18 1.3373895e-27], sampled 0.9704251606468928
[2019-03-26 10:11:19,828] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:19,830] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.0, 88.33333333333334, 1.0, 2.0, 0.8985680567503326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1255938.575145794, 1255938.575145794, 269541.4281455348]
[2019-03-26 10:11:19,832] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:11:19,835] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.4154221e-17 1.0000000e+00 3.7106358e-22 3.9750422e-15 1.2772236e-25], sampled 0.789659947783066
[2019-03-26 10:11:26,172] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:26,174] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.78333333333333, 64.83333333333334, 1.0, 2.0, 0.6456038845230112, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.999428319890428, 6.9112, 168.9123788511698, 1799012.107079833, 1736420.114421949, 373554.9413335685]
[2019-03-26 10:11:26,176] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:11:26,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8934582e-11 9.8405427e-01 4.1496845e-14 1.5945731e-02 9.9030766e-19], sampled 0.9961891631105212
[2019-03-26 10:11:50,264] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:50,266] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.61695489166667, 71.61445131833334, 1.0, 2.0, 0.6060827841335261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 846965.6239720264, 846965.6239720258, 201884.328755056]
[2019-03-26 10:11:50,267] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:11:50,269] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.1994991e-18 1.0000000e+00 8.6418395e-24 1.9229804e-17 3.8362941e-27], sampled 0.8461273789757532
[2019-03-26 10:11:56,043] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:56,046] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.85, 73.0, 1.0, 2.0, 0.5699094366103854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796396.5124781496, 796396.5124781496, 195274.9081794913]
[2019-03-26 10:11:56,047] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:11:56,050] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.9555867e-20 1.0000000e+00 3.3276688e-27 2.8663773e-19 4.0197647e-31], sampled 0.42103721816811346
[2019-03-26 10:11:59,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06171595], dtype=float32), 0.074724145]
[2019-03-26 10:11:59,111] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.1, 50.0, 1.0, 2.0, 0.6045015837093216, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844755.1091505778, 844755.1091505778, 201586.7728702062]
[2019-03-26 10:11:59,111] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:11:59,114] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.5721704e-18 1.0000000e+00 1.3408455e-23 1.5561197e-16 2.6979861e-27], sampled 0.4038840469567532
[2019-03-26 10:12:30,719] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8262.3756 2926387397.8518 1318.0000
[2019-03-26 10:12:30,802] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4778 2778815407.3559 926.0000
[2019-03-26 10:12:30,927] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7925.7485 3159700693.1846 1678.0000
[2019-03-26 10:12:30,934] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8509.1313 2840942618.2554 1097.0000
[2019-03-26 10:12:31,008] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8030.8061 3004039113.1787 1676.0000
[2019-03-26 10:12:32,023] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 225000, evaluation results [225000.0, 7925.7485297820895, 3159700693.1846223, 1678.0, 8262.375581137741, 2926387397.851758, 1318.0, 8661.477755354015, 2778815407.3558836, 926.0, 8030.806147827484, 3004039113.178674, 1676.0, 8509.131256408453, 2840942618.255442, 1097.0]
[2019-03-26 10:12:33,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2713296e-19 1.0000000e+00 1.8070633e-27 1.2863313e-20 6.3305910e-31], sum to 1.0000
[2019-03-26 10:12:33,461] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4024
[2019-03-26 10:12:33,468] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.75, 90.5, 1.0, 2.0, 0.2112973534388778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 352227.2118951018, 352227.2118951012, 156773.0030041752], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 534600.0000, 
sim time next is 535200.0000, 
raw observation next is [17.7, 90.66666666666667, 1.0, 2.0, 0.210584084629817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 351103.5010336085, 351103.5010336078, 156690.1935485232], 
processed observation next is [1.0, 0.17391304347826086, 0.03791469194312799, 0.9066666666666667, 1.0, 1.0, 0.04889648750580361, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09752875028711347, 0.09752875028711327, 0.2338659605201839], 
reward next is 0.7661, 
noisyNet noise sample is [array([-1.0569559], dtype=float32), 0.12869504]. 
=============================================
[2019-03-26 10:12:35,482] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.4590899e-18 1.0000000e+00 6.5159122e-25 3.4710997e-17 1.1430531e-27], sum to 1.0000
[2019-03-26 10:12:35,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4602
[2019-03-26 10:12:35,501] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 72.0, 1.0, 2.0, 0.4270096543093645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 702212.8281481456, 702212.8281481449, 183554.951037988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 552000.0000, 
sim time next is 552600.0000, 
raw observation next is [21.8, 70.5, 1.0, 2.0, 0.4084047101630429, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 671773.8923314483, 671773.8923314483, 180715.5563780493], 
processed observation next is [1.0, 0.391304347826087, 0.23222748815165886, 0.705, 1.0, 1.0, 0.28723459055788303, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18660385898095785, 0.18660385898095785, 0.2697247110120139], 
reward next is 0.7303, 
noisyNet noise sample is [array([0.7705097], dtype=float32), -0.910176]. 
=============================================
[2019-03-26 10:12:36,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.1123023e-14 1.0000000e+00 8.5211334e-19 1.3145882e-11 1.0522736e-22], sum to 1.0000
[2019-03-26 10:12:36,941] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5258
[2019-03-26 10:12:36,947] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.98333333333333, 58.5, 1.0, 2.0, 0.6424025593383613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1053425.796239427, 1053425.796239427, 225013.9144379167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 568200.0000, 
sim time next is 568800.0000, 
raw observation next is [23.9, 59.0, 1.0, 2.0, 0.6052822334205809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 992495.5967563349, 992495.5967563356, 216736.5010347012], 
processed observation next is [1.0, 0.6086956521739131, 0.33175355450236965, 0.59, 1.0, 1.0, 0.5244364258079287, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2756932213212041, 0.27569322132120433, 0.323487314977166], 
reward next is 0.6765, 
noisyNet noise sample is [array([-0.08857081], dtype=float32), -0.7501003]. 
=============================================
[2019-03-26 10:12:43,983] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5297453e-17 1.0000000e+00 2.8518561e-22 4.0367876e-14 8.1104170e-26], sum to 1.0000
[2019-03-26 10:12:43,993] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3619
[2019-03-26 10:12:43,999] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.9, 92.0, 1.0, 2.0, 0.2224132996837782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 369961.1697761447, 369961.1697761447, 157944.6875884107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 696600.0000, 
sim time next is 697200.0000, 
raw observation next is [17.83333333333333, 92.33333333333334, 1.0, 2.0, 0.22213393700398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 369577.2077384248, 369577.2077384248, 157902.5166785965], 
processed observation next is [1.0, 0.043478260869565216, 0.044233807266982464, 0.9233333333333335, 1.0, 1.0, 0.06281197229395177, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10266033548289578, 0.10266033548289578, 0.23567539802775597], 
reward next is 0.7643, 
noisyNet noise sample is [array([0.8142815], dtype=float32), 0.33514366]. 
=============================================
[2019-03-26 10:12:48,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2514003e-18 1.0000000e+00 1.1568118e-23 9.1644814e-16 1.0433455e-27], sum to 1.0000
[2019-03-26 10:12:48,640] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4770
[2019-03-26 10:12:48,646] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 86.0, 1.0, 2.0, 0.2584411073714396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424435.3483623351, 424435.3483623351, 161754.2466904261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 771600.0000, 
sim time next is 772200.0000, 
raw observation next is [19.8, 86.5, 1.0, 2.0, 0.258234329483531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 424123.4588135988, 424123.4588135988, 161733.2039684664], 
processed observation next is [1.0, 0.9565217391304348, 0.13744075829383895, 0.865, 1.0, 1.0, 0.10630642106449514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11781207189266633, 0.11781207189266633, 0.2413928417439797], 
reward next is 0.7586, 
noisyNet noise sample is [array([0.89005905], dtype=float32), 0.3409844]. 
=============================================
[2019-03-26 10:12:50,687] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4078107e-20 1.0000000e+00 1.0304633e-26 1.5717651e-20 1.0303398e-29], sum to 1.0000
[2019-03-26 10:12:50,694] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5599
[2019-03-26 10:12:50,698] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.76666666666667, 75.33333333333334, 1.0, 2.0, 0.287771708005965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 461659.387396554, 461659.3873965534, 164378.4425637016], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 808800.0000, 
sim time next is 809400.0000, 
raw observation next is [22.93333333333334, 74.16666666666667, 1.0, 2.0, 0.2876578747443136, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461500.5522880002, 461500.5522880002, 164367.7413135518], 
processed observation next is [0.0, 0.34782608695652173, 0.28593996840442376, 0.7416666666666667, 1.0, 1.0, 0.14175647559555854, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12819459785777781, 0.12819459785777781, 0.24532498703515196], 
reward next is 0.7547, 
noisyNet noise sample is [array([1.4934059], dtype=float32), -1.2855723]. 
=============================================
[2019-03-26 10:12:51,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.6869797e-22 1.0000000e+00 9.8116814e-29 1.0271451e-22 4.8516064e-33], sum to 1.0000
[2019-03-26 10:12:51,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9812
[2019-03-26 10:12:51,033] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 79.33333333333334, 1.0, 2.0, 0.2996558232071326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477486.3531816378, 477486.3531816385, 165447.0151375067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 846600.0000, 
sim time next is 847200.0000, 
raw observation next is [22.46666666666667, 79.66666666666667, 1.0, 2.0, 0.2991246697559024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 476844.6019803797, 476844.6019803797, 165404.4113641931], 
processed observation next is [0.0, 0.8260869565217391, 0.2638230647709322, 0.7966666666666667, 1.0, 1.0, 0.15557189127217155, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13245683388343882, 0.13245683388343882, 0.2468722557674524], 
reward next is 0.7531, 
noisyNet noise sample is [array([1.077014], dtype=float32), -0.13155438]. 
=============================================
[2019-03-26 10:12:58,208] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.3195918e-20 1.0000000e+00 9.9103972e-27 1.9807751e-20 4.3151638e-30], sum to 1.0000
[2019-03-26 10:12:58,216] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2374
[2019-03-26 10:12:58,220] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 84.5, 1.0, 2.0, 0.3337932480252307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518922.6041117552, 518922.6041117552, 168262.5010783901], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 934200.0000, 
sim time next is 934800.0000, 
raw observation next is [22.83333333333334, 85.33333333333334, 1.0, 2.0, 0.3345505630127777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519477.9307774201, 519477.9307774206, 168288.1086678219], 
processed observation next is [0.0, 0.8260869565217391, 0.2812006319115327, 0.8533333333333334, 1.0, 1.0, 0.1982536903768406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14429942521595004, 0.14429942521595016, 0.25117628159376404], 
reward next is 0.7488, 
noisyNet noise sample is [array([1.3711799], dtype=float32), -0.16929133]. 
=============================================
[2019-03-26 10:12:58,820] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8127450e-20 1.0000000e+00 1.9691293e-26 4.2428110e-20 1.0112431e-31], sum to 1.0000
[2019-03-26 10:12:58,828] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8917
[2019-03-26 10:12:58,832] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.33333333333334, 1.0, 2.0, 0.3397946603984714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 526082.1326077123, 526082.132607713, 168767.1717017065], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 945600.0000, 
sim time next is 946200.0000, 
raw observation next is [21.85, 93.66666666666667, 1.0, 2.0, 0.3388323423950056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 524726.7692014374, 524726.7692014374, 168662.9569256562], 
processed observation next is [0.0, 0.9565217391304348, 0.23459715639810438, 0.9366666666666668, 1.0, 1.0, 0.20341246071687422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14575743588928816, 0.14575743588928816, 0.25173575660545705], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.37477058], dtype=float32), 0.41411567]. 
=============================================
[2019-03-26 10:13:00,199] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4295275e-18 1.0000000e+00 2.1646639e-25 2.3708605e-18 3.2505677e-29], sum to 1.0000
[2019-03-26 10:13:00,207] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1155
[2019-03-26 10:13:00,213] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 93.0, 1.0, 2.0, 0.3399800326892392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527009.304289304, 527009.304289304, 168860.1313533416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 977400.0000, 
sim time next is 978000.0000, 
raw observation next is [21.9, 93.0, 1.0, 2.0, 0.3350384879186246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 519354.9549688383, 519354.9549688377, 168252.030569168], 
processed observation next is [1.0, 0.30434782608695654, 0.23696682464454974, 0.93, 1.0, 1.0, 0.19884155170918627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14426526526912176, 0.14426526526912156, 0.2511224336853254], 
reward next is 0.7489, 
noisyNet noise sample is [array([-0.3216651], dtype=float32), 0.40960595]. 
=============================================
[2019-03-26 10:13:00,224] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[77.193054]
 [77.14301 ]
 [77.12066 ]
 [77.19948 ]
 [77.152054]], R is [[77.2039032 ]
 [77.17983246]
 [77.15509033]
 [77.12363434]
 [77.10150146]].
[2019-03-26 10:13:03,252] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.6746691e-17 1.0000000e+00 3.2745338e-24 2.3464363e-15 7.8069411e-27], sum to 1.0000
[2019-03-26 10:13:03,265] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0862
[2019-03-26 10:13:03,271] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 96.0, 1.0, 2.0, 0.3549255071666878, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546063.4439535406, 546063.4439535406, 170298.3032891489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1021800.0000, 
sim time next is 1022400.0000, 
raw observation next is [21.8, 96.0, 1.0, 2.0, 0.3541366531440557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544850.3118745922, 544850.3118745928, 170197.4571940295], 
processed observation next is [1.0, 0.8695652173913043, 0.23222748815165886, 0.96, 1.0, 1.0, 0.22185138933018755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1513473088540534, 0.15134730885405356, 0.25402605551347684], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.1988781], dtype=float32), 0.47828785]. 
=============================================
[2019-03-26 10:13:10,290] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7320295e-14 1.0000000e+00 1.1116064e-19 4.4331130e-10 1.4096509e-22], sum to 1.0000
[2019-03-26 10:13:10,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4626
[2019-03-26 10:13:10,302] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 58.5, 1.0, 2.0, 0.9391346255297464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1438384.40386559, 1438384.40386559, 298862.0060094066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1179000.0000, 
sim time next is 1179600.0000, 
raw observation next is [27.6, 58.33333333333333, 1.0, 2.0, 0.9201992396255323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1410577.967924249, 1410577.96792425, 293094.8122768563], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.5833333333333333, 1.0, 1.0, 0.9038545055729305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.39182721331229137, 0.3918272133122917, 0.43745494369680044], 
reward next is 0.5625, 
noisyNet noise sample is [array([-0.70236707], dtype=float32), -1.0537488]. 
=============================================
[2019-03-26 10:13:11,248] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.8842020e-16 1.0000000e+00 2.9307239e-21 1.3920192e-11 6.2329659e-24], sum to 1.0000
[2019-03-26 10:13:11,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6748
[2019-03-26 10:13:11,260] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 67.0, 1.0, 2.0, 0.7571340012460842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1158839.270742973, 1158839.270742974, 246728.8250263947], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1165200.0000, 
sim time next is 1165800.0000, 
raw observation next is [26.2, 66.5, 1.0, 2.0, 0.7591755966018255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1161510.352173782, 1161510.352173782, 247199.7190342867], 
processed observation next is [1.0, 0.4782608695652174, 0.44075829383886256, 0.665, 1.0, 1.0, 0.7098501163877416, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3226417644927172, 0.3226417644927172, 0.36895480452878615], 
reward next is 0.6310, 
noisyNet noise sample is [array([0.9660292], dtype=float32), -1.5926528]. 
=============================================
[2019-03-26 10:13:12,334] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5737139e-14 1.0000000e+00 4.9952691e-20 2.1402448e-10 3.4892504e-23], sum to 1.0000
[2019-03-26 10:13:12,345] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2514
[2019-03-26 10:13:12,348] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1184400.0000, 
sim time next is 1185000.0000, 
raw observation next is [27.45, 57.83333333333333, 1.0, 2.0, 0.4381659364294249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676160.7084975761, 676160.7084975761, 182190.6228728698], 
processed observation next is [1.0, 0.7391304347826086, 0.5, 0.5783333333333333, 1.0, 1.0, 0.3230914896740059, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18782241902710448, 0.18782241902710448, 0.2719263027953281], 
reward next is 0.7281, 
noisyNet noise sample is [array([1.6383893], dtype=float32), 0.11029833]. 
=============================================
[2019-03-26 10:13:12,363] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.0538 ]
 [69.87833]
 [69.7772 ]
 [69.59703]
 [69.39478]], R is [[71.3249054 ]
 [71.19777679]
 [71.06735992]
 [70.93812561]
 [70.81311798]].
[2019-03-26 10:13:16,874] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.66147029e-09 8.39724958e-01 1.08572466e-13 1.60275012e-01
 1.76813959e-17], sum to 1.0000
[2019-03-26 10:13:16,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7922
[2019-03-26 10:13:16,892] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2130783.516224679 W.
[2019-03-26 10:13:16,897] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.15, 74.5, 1.0, 2.0, 0.8826728152832055, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.97041042970698, 6.9112, 168.9126037844207, 2130783.516224679, 2088777.687242077, 430483.9021458462], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1265400.0000, 
sim time next is 1266000.0000, 
raw observation next is [28.1, 74.66666666666667, 1.0, 2.0, 0.8756908541506057, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.968476528135643, 6.9112, 168.9125672042731, 2121010.972286231, 2080377.125572886, 428641.8501870261], 
processed observation next is [1.0, 0.6521739130434783, 0.5308056872037916, 0.7466666666666667, 1.0, 1.0, 0.8502299447597659, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005727652813564266, 0.0, 0.8294380334808422, 0.5891697145239531, 0.5778825348813572, 0.639763955503024], 
reward next is 0.0739, 
noisyNet noise sample is [array([0.12255205], dtype=float32), 0.6084391]. 
=============================================
[2019-03-26 10:13:16,908] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.175716]
 [63.719677]
 [63.41212 ]
 [63.07138 ]
 [63.24211 ]], R is [[62.25112152]
 [61.69004822]
 [61.47893906]
 [60.864151  ]
 [60.25550842]].
[2019-03-26 10:13:22,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5958390e-15 1.0000000e+00 4.2447032e-21 5.3254354e-12 3.1670007e-25], sum to 1.0000
[2019-03-26 10:13:22,067] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0728
[2019-03-26 10:13:22,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333333, 88.83333333333334, 1.0, 2.0, 0.4991752223904971, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 794473.4551694791, 794473.4551694791, 194404.6104285996], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1349400.0000, 
sim time next is 1350000.0000, 
raw observation next is [21.3, 89.0, 1.0, 2.0, 0.5133076278684294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817199.4908224535, 817199.4908224535, 196970.023819039], 
processed observation next is [1.0, 0.6521739130434783, 0.2085308056872039, 0.89, 1.0, 1.0, 0.4136236480342523, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22699985856179264, 0.22699985856179264, 0.29398511017767015], 
reward next is 0.7060, 
noisyNet noise sample is [array([-1.8138591], dtype=float32), 0.3372432]. 
=============================================
[2019-03-26 10:13:22,089] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[73.98187 ]
 [73.888596]
 [73.74543 ]
 [73.7221  ]
 [73.61422 ]], R is [[73.97808838]
 [73.94815826]
 [73.91466522]
 [73.86865234]
 [73.82506561]].
[2019-03-26 10:13:26,118] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 10:13:26,119] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:13:26,120] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:13:26,121] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:13:26,122] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:13:26,123] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:13:26,123] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:13:26,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:13:26,125] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:13:26,124] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:13:26,126] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:13:26,146] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-26 10:13:26,147] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-26 10:13:26,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-26 10:13:26,189] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-26 10:13:26,211] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-26 10:13:49,093] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06386806], dtype=float32), 0.06929514]
[2019-03-26 10:13:49,094] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.76666666666667, 51.0, 1.0, 2.0, 0.3213292036642718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507808.24315071, 507808.2431507093, 167607.9191171762]
[2019-03-26 10:13:49,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:13:49,101] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.04215245e-19 1.00000000e+00 1.25919750e-26 2.55455733e-20
 1.28049383e-30], sampled 0.2229306375391773
[2019-03-26 10:14:41,530] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06386806], dtype=float32), 0.06929514]
[2019-03-26 10:14:41,532] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [35.93157145166667, 53.37947826666667, 1.0, 2.0, 0.7209380183657236, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005976590857494, 6.9112, 168.912316039869, 1904428.899645931, 1837191.379079901, 389261.9497757098]
[2019-03-26 10:14:41,534] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:14:41,537] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6068713e-15 1.0000000e+00 7.5158511e-21 1.5120166e-08 1.6260204e-26], sampled 0.08756703892161355
[2019-03-26 10:14:41,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1904428.899645931 W.
[2019-03-26 10:14:59,778] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06386806], dtype=float32), 0.06929514]
[2019-03-26 10:14:59,779] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.72741037333333, 87.27216001166667, 1.0, 2.0, 0.5237558981720929, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731878.9283226426, 731878.9283226419, 187401.3953762488]
[2019-03-26 10:14:59,780] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:14:59,783] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.1090153e-19 1.0000000e+00 2.2756034e-25 1.0393704e-17 1.9454652e-29], sampled 0.07301440836411044
[2019-03-26 10:15:15,845] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06386806], dtype=float32), 0.06929514]
[2019-03-26 10:15:15,847] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.48954071666667, 86.92751726666667, 1.0, 2.0, 0.3478202363369786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540194.6555227892, 540194.6555227892, 169953.8589516643]
[2019-03-26 10:15:15,849] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:15:15,851] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.5907412e-20 1.0000000e+00 7.2183677e-27 1.9574893e-20 9.8338538e-31], sampled 0.06363083866628072
[2019-03-26 10:15:19,743] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8892 2779214977.1528 933.0000
[2019-03-26 10:15:21,022] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 10:15:21,454] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.7654 3164067714.8369 1778.0000
[2019-03-26 10:15:21,661] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.1948 2842590785.6945 1131.0000
[2019-03-26 10:15:21,757] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 10:15:22,773] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 250000, evaluation results [250000.0, 7883.765416604777, 3164067714.836875, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.889248757021, 2779214977.1528425, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8495.19481276212, 2842590785.694547, 1131.0]
[2019-03-26 10:15:23,886] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.40114958e-19 1.00000000e+00 4.82981538e-26 5.36857692e-19
 1.44187435e-30], sum to 1.0000
[2019-03-26 10:15:23,899] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5613
[2019-03-26 10:15:23,904] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.73333333333333, 69.33333333333334, 1.0, 2.0, 0.4339430502299369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 622305.1670256971, 622305.1670256971, 175954.0529619521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1437600.0000, 
sim time next is 1438200.0000, 
raw observation next is [27.8, 69.5, 1.0, 2.0, 0.4380729333670599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625911.7252979735, 625911.7252979735, 176244.3485751881], 
processed observation next is [0.0, 0.6521739130434783, 0.5165876777251186, 0.695, 1.0, 1.0, 0.3229794377916384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17386436813832598, 0.17386436813832598, 0.2630512665301315], 
reward next is 0.7369, 
noisyNet noise sample is [array([-0.4102498], dtype=float32), 2.2990797]. 
=============================================
[2019-03-26 10:15:27,608] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7155676e-19 1.0000000e+00 5.6904171e-25 8.0915025e-19 3.8149398e-29], sum to 1.0000
[2019-03-26 10:15:27,615] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4054
[2019-03-26 10:15:27,619] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1511400.0000, 
sim time next is 1512000.0000, 
raw observation next is [29.1, 51.0, 1.0, 2.0, 0.3480171406727051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 534257.5264887547, 534257.5264887554, 169288.3780549595], 
processed observation next is [0.0, 0.5217391304347826, 0.5781990521327015, 0.51, 1.0, 1.0, 0.21447848273819894, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1484048684690985, 0.1484048684690987, 0.2526692209775515], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.7540548], dtype=float32), 1.5441155]. 
=============================================
[2019-03-26 10:15:27,631] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.417015]
 [75.376595]
 [75.31946 ]
 [75.25922 ]
 [75.212456]], R is [[75.49746704]
 [75.49029541]
 [75.48345947]
 [75.47665405]
 [75.46994781]].
[2019-03-26 10:15:29,086] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.0192047e-20 1.0000000e+00 9.5912798e-27 4.9070656e-21 2.1942965e-31], sum to 1.0000
[2019-03-26 10:15:29,105] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9600
[2019-03-26 10:15:29,109] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 74.0, 1.0, 2.0, 0.3532127284353498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 543324.9260934021, 543324.9260934027, 170067.8775380704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537200.0000, 
sim time next is 1537800.0000, 
raw observation next is [24.6, 75.5, 1.0, 2.0, 0.3542998769845044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544581.0258525242, 544581.0258525242, 170159.7827732003], 
processed observation next is [0.0, 0.8260869565217391, 0.36492890995260674, 0.755, 1.0, 1.0, 0.22204804455964383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15127250718125673, 0.15127250718125673, 0.25396982503462734], 
reward next is 0.7460, 
noisyNet noise sample is [array([-0.33794147], dtype=float32), 1.4338348]. 
=============================================
[2019-03-26 10:15:29,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.0382515e-20 1.0000000e+00 1.5660806e-26 6.3502147e-21 3.4943246e-31], sum to 1.0000
[2019-03-26 10:15:29,151] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7002
[2019-03-26 10:15:29,157] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 75.5, 1.0, 2.0, 0.3542998769845044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 544581.0258525242, 544581.0258525242, 170159.7827732003], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1537800.0000, 
sim time next is 1538400.0000, 
raw observation next is [24.4, 77.0, 1.0, 2.0, 0.3549531454996852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545185.9988718478, 545185.9988718478, 170198.2112257469], 
processed observation next is [0.0, 0.8260869565217391, 0.3554502369668246, 0.77, 1.0, 1.0, 0.2228351150598617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15144055524217992, 0.15144055524217992, 0.2540271809339506], 
reward next is 0.7460, 
noisyNet noise sample is [array([-0.6793941], dtype=float32), -1.019696]. 
=============================================
[2019-03-26 10:15:29,908] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.61816856e-18 1.00000000e+00 6.90244930e-24 1.83895684e-17
 1.01441725e-27], sum to 1.0000
[2019-03-26 10:15:29,915] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2660
[2019-03-26 10:15:29,921] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.51666666666667, 88.50000000000001, 1.0, 2.0, 0.3463782461698307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536092.7353356694, 536092.7353356694, 169569.568464614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1548600.0000, 
sim time next is 1549200.0000, 
raw observation next is [22.43333333333334, 89.0, 1.0, 2.0, 0.3451865020357726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534531.4758566526, 534531.4758566519, 169450.6587296302], 
processed observation next is [0.0, 0.9565217391304348, 0.2622432859399688, 0.89, 1.0, 1.0, 0.2110680747418947, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14848096551573683, 0.14848096551573664, 0.25291143093974655], 
reward next is 0.7471, 
noisyNet noise sample is [array([-0.20048414], dtype=float32), -0.69855034]. 
=============================================
[2019-03-26 10:15:33,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0468682e-15 1.0000000e+00 2.0968124e-21 3.6308991e-11 4.4507266e-25], sum to 1.0000
[2019-03-26 10:15:33,168] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1571
[2019-03-26 10:15:33,171] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.96666666666667, 86.33333333333334, 1.0, 2.0, 0.7236314791354455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1080989.417543761, 1080989.417543761, 235162.7322399884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1606800.0000, 
sim time next is 1607400.0000, 
raw observation next is [23.9, 87.0, 1.0, 2.0, 0.7590619797247687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1133001.807641249, 1133001.807641248, 243730.3944333877], 
processed observation next is [1.0, 0.6086956521739131, 0.33175355450236965, 0.87, 1.0, 1.0, 0.7097132285840587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31472272434479137, 0.3147227243447911, 0.3637767081095339], 
reward next is 0.6362, 
noisyNet noise sample is [array([0.43412143], dtype=float32), 1.0074564]. 
=============================================
[2019-03-26 10:15:37,048] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1683734e-17 1.0000000e+00 8.7225896e-23 1.7525525e-15 1.0042990e-26], sum to 1.0000
[2019-03-26 10:15:37,058] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8820
[2019-03-26 10:15:37,061] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 98.0, 1.0, 2.0, 0.4484092435607479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 640969.2873152549, 640969.2873152556, 177762.1315016774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1667400.0000, 
sim time next is 1668000.0000, 
raw observation next is [23.63333333333334, 98.0, 1.0, 2.0, 0.434594086380385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 620794.4020437129, 620794.4020437129, 175734.3568560999], 
processed observation next is [1.0, 0.30434782608695654, 0.3191153238546607, 0.98, 1.0, 1.0, 0.3187880558799819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17244288945658692, 0.17244288945658692, 0.2622900848598506], 
reward next is 0.7377, 
noisyNet noise sample is [array([-1.1947138], dtype=float32), 1.1241233]. 
=============================================
[2019-03-26 10:15:37,077] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[72.977295]
 [72.856804]
 [72.74389 ]
 [72.72053 ]
 [72.68812 ]], R is [[73.08266449]
 [73.08651733]
 [73.08666229]
 [73.08399963]
 [73.08119202]].
[2019-03-26 10:15:40,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4321583e-16 1.0000000e+00 8.9876521e-20 2.5484675e-10 1.8173872e-24], sum to 1.0000
[2019-03-26 10:15:40,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9334
[2019-03-26 10:15:40,629] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 92.0, 1.0, 2.0, 0.5097685494312868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712326.9227911418, 712326.9227911412, 185140.8630280854], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1722000.0000, 
sim time next is 1722600.0000, 
raw observation next is [25.85, 92.5, 1.0, 2.0, 0.5100168059782505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 712673.9413427863, 712673.941342787, 185180.5133621522], 
processed observation next is [1.0, 0.9565217391304348, 0.4241706161137442, 0.925, 1.0, 1.0, 0.40965880238343433, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19796498370632953, 0.19796498370632973, 0.27638882591366004], 
reward next is 0.7236, 
noisyNet noise sample is [array([-0.07994405], dtype=float32), -0.18775949]. 
=============================================
[2019-03-26 10:15:44,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.2278114e-14 1.0000000e+00 2.7762932e-18 3.6213809e-08 1.2684427e-21], sum to 1.0000
[2019-03-26 10:15:44,121] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3546
[2019-03-26 10:15:44,125] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.16666666666667, 85.66666666666666, 1.0, 2.0, 0.6861049299627314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1081520.073867193, 1081520.073867193, 232610.5293168236], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1788600.0000, 
sim time next is 1789200.0000, 
raw observation next is [22.4, 84.0, 1.0, 2.0, 0.6905797084371784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1088208.295310962, 1088208.295310963, 233649.5504868588], 
processed observation next is [1.0, 0.7391304347826086, 0.2606635071090047, 0.84, 1.0, 1.0, 0.6272044679966005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3022800820308228, 0.302280082030823, 0.34873067236844596], 
reward next is 0.6513, 
noisyNet noise sample is [array([1.5713767], dtype=float32), -1.1050793]. 
=============================================
[2019-03-26 10:15:45,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2020121e-15 1.0000000e+00 6.2935904e-21 4.8475143e-12 4.1485337e-25], sum to 1.0000
[2019-03-26 10:15:45,568] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7355
[2019-03-26 10:15:45,574] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.71666666666667, 94.83333333333334, 1.0, 2.0, 0.3456467214089191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 535202.0222888836, 535202.0222888836, 169503.9298815456], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1815000.0000, 
sim time next is 1815600.0000, 
raw observation next is [21.73333333333333, 94.66666666666667, 1.0, 2.0, 0.3454634586150254, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534966.4854327029, 534966.4854327029, 169486.1505677609], 
processed observation next is [1.0, 0.0, 0.22906793048973137, 0.9466666666666668, 1.0, 1.0, 0.2114017573675005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14860180150908414, 0.14860180150908414, 0.2529644038324789], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.351003], dtype=float32), -1.4796071]. 
=============================================
[2019-03-26 10:15:47,430] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.6604920e-12 5.5890453e-01 1.5226288e-14 4.4109553e-01 7.1552215e-20], sum to 1.0000
[2019-03-26 10:15:47,441] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8191
[2019-03-26 10:15:47,448] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.91666666666667, 87.66666666666667, 1.0, 2.0, 0.3981031483797502, 1.0, 1.0, 0.3981031483797502, 1.0, 2.0, 0.6823645445555704, 6.9112, 6.9112, 170.5573041426782, 1669612.028936265, 1669612.028936265, 350581.6747012672], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1875000.0000, 
sim time next is 1875600.0000, 
raw observation next is [26.9, 88.0, 1.0, 2.0, 0.5936335848422194, 1.0, 2.0, 0.5936335848422194, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1659759.496090485, 1659759.496090485, 331909.9850736205], 
processed observation next is [1.0, 0.7391304347826086, 0.4739336492890995, 0.88, 1.0, 1.0, 0.5104019094484571, 1.0, 1.0, 0.5104019094484571, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.46104430446957917, 0.46104430446957917, 0.4953880374233142], 
reward next is 0.5046, 
noisyNet noise sample is [array([-0.35630676], dtype=float32), 0.95731825]. 
=============================================
[2019-03-26 10:16:00,027] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1993329e-17 1.0000000e+00 1.9009273e-22 6.8622599e-15 3.7871621e-27], sum to 1.0000
[2019-03-26 10:16:00,034] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3022
[2019-03-26 10:16:00,039] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 89.33333333333334, 1.0, 2.0, 0.4770284952411142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 666563.1363382066, 666563.1363382066, 180075.0003259419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2059800.0000, 
sim time next is 2060400.0000, 
raw observation next is [25.3, 89.66666666666667, 1.0, 2.0, 0.4766639897089207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 666053.644511222, 666053.6445112227, 180020.40054449], 
processed observation next is [0.0, 0.8695652173913043, 0.39810426540284366, 0.8966666666666667, 1.0, 1.0, 0.36947468639629005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18501490125311723, 0.18501490125311743, 0.26868716499177614], 
reward next is 0.7313, 
noisyNet noise sample is [array([0.02701629], dtype=float32), -1.686857]. 
=============================================
[2019-03-26 10:16:06,402] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.1237508e-11 9.7787607e-01 5.8603444e-15 2.2123998e-02 1.8155087e-19], sum to 1.0000
[2019-03-26 10:16:06,409] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9552
[2019-03-26 10:16:06,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2452768.526958034 W.
[2019-03-26 10:16:06,424] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 65.66666666666666, 1.0, 2.0, 0.8769528081570839, 1.0, 2.0, 0.8769528081570839, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2452768.526958034, 2452768.526958034, 459074.8476375467], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2209200.0000, 
sim time next is 2209800.0000, 
raw observation next is [32.0, 65.33333333333334, 1.0, 2.0, 0.5805605573329536, 1.0, 2.0, 0.5805605573329536, 1.0, 1.0, 1.008241693777185, 6.9112, 6.9112, 170.5573041426782, 2435657.157646201, 2435657.157646201, 475324.4108919242], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.6533333333333334, 1.0, 1.0, 0.49465127389512487, 1.0, 1.0, 0.49465127389512487, 1.0, 0.5, 1.0100508460697377, 0.0, 0.0, 0.8375144448122397, 0.6765714326795003, 0.6765714326795003, 0.709439419241678], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.43444222], dtype=float32), 1.0701181]. 
=============================================
[2019-03-26 10:16:08,566] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3431446e-10 5.3203553e-01 1.5751588e-12 4.6796450e-01 2.1261296e-17], sum to 1.0000
[2019-03-26 10:16:08,574] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8714
[2019-03-26 10:16:08,580] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.08333333333334, 65.16666666666667, 1.0, 2.0, 0.5446009944093704, 1.0, 2.0, 0.5446009944093704, 1.0, 2.0, 0.9457918249881007, 6.911200000000001, 6.9112, 170.5573041426782, 2284656.149158285, 2284656.149158285, 447359.0004276073], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2211000.0000, 
sim time next is 2211600.0000, 
raw observation next is [32.06666666666667, 65.33333333333334, 1.0, 2.0, 0.8121943348508867, 1.0, 2.0, 0.8121943348508867, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2271479.520138417, 2271479.520138416, 425855.0011159839], 
processed observation next is [1.0, 0.6086956521739131, 0.7187993680884678, 0.6533333333333334, 1.0, 1.0, 0.7737281142781767, 1.0, 1.0, 0.7737281142781767, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6309665333717824, 0.6309665333717822, 0.6356044792775879], 
reward next is 0.3644, 
noisyNet noise sample is [array([0.07610741], dtype=float32), 1.3846252]. 
=============================================
[2019-03-26 10:16:17,104] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 10:16:17,108] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:16:17,109] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:16:17,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:16:17,110] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:16:17,110] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:16:17,110] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:16:17,112] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:16:17,111] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:16:17,113] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:16:17,116] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:16:17,129] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-26 10:16:17,149] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-26 10:16:17,150] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-26 10:16:17,150] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-26 10:16:17,164] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-26 10:16:18,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:16:18,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.71666666666667, 67.83333333333334, 1.0, 2.0, 0.4467897713080146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 646027.879957705, 646027.8799577056, 178458.5763312043]
[2019-03-26 10:16:18,333] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:16:18,334] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.9454834e-18 1.0000000e+00 1.3215698e-22 8.8085132e-18 1.6404435e-26], sampled 0.88713388268911
[2019-03-26 10:16:36,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:16:36,510] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.6, 43.5, 1.0, 2.0, 0.4051221729109324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 666863.9798161079, 666863.9798161073, 180223.5693367685]
[2019-03-26 10:16:36,513] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:16:36,515] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.1803363e-18 1.0000000e+00 1.4218617e-22 5.4816303e-19 3.0190449e-26], sampled 0.886345557362645
[2019-03-26 10:16:37,892] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:16:37,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.96666666666667, 36.66666666666666, 1.0, 2.0, 0.4317120294247512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718108.8953474816, 718108.8953474816, 183847.365334484]
[2019-03-26 10:16:37,896] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:16:37,901] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.2353631e-18 1.0000000e+00 1.1630646e-22 5.8371463e-19 1.9862243e-26], sampled 0.3773828795592382
[2019-03-26 10:16:49,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:16:49,829] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.85379855166667, 92.55471500333334, 1.0, 2.0, 0.6672047221181148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 932417.4893378754, 932417.4893378748, 213926.808434293]
[2019-03-26 10:16:49,830] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:16:49,836] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.37620164e-17 1.00000000e+00 1.53169159e-22 2.91197313e-18
 4.87377188e-26], sampled 0.9228801226106542
[2019-03-26 10:16:52,100] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:16:52,102] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.7, 76.0, 1.0, 2.0, 0.6514209026158279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 929795.3149058148, 929795.3149058148, 213261.1875706112]
[2019-03-26 10:16:52,102] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:16:52,105] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5997435e-17 1.0000000e+00 6.9680934e-22 2.9815417e-17 1.4241178e-25], sampled 0.22436752253533754
[2019-03-26 10:17:15,211] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:17:15,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 61.0, 1.0, 2.0, 0.6050224737384846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845483.3117925103, 845483.3117925103, 201685.7757938854]
[2019-03-26 10:17:15,213] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:17:15,216] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.16814922e-18 1.00000000e+00 1.10320604e-23 4.12344417e-19
 9.43209938e-28], sampled 0.4629062863499176
[2019-03-26 10:17:18,641] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:17:18,644] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.63333333333333, 52.0, 1.0, 2.0, 0.5318912181960874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743250.9288632642, 743250.9288632642, 188743.6030060704]
[2019-03-26 10:17:18,646] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:17:18,648] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2262571e-18 1.0000000e+00 1.8467122e-23 1.3142475e-18 1.2106345e-27], sampled 0.24460284530854404
[2019-03-26 10:17:35,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.07389112], dtype=float32), 0.08202854]
[2019-03-26 10:17:35,714] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.06509782333333, 87.79827581666666, 1.0, 2.0, 0.8389057417670449, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1172501.848883661, 1172501.848883661, 253689.9535622432]
[2019-03-26 10:17:35,715] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:17:35,719] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0161541e-16 1.0000000e+00 1.7956756e-21 1.1645377e-16 7.4021935e-25], sampled 0.9258873472751701
[2019-03-26 10:18:10,368] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 10:18:11,863] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 10:18:12,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.2541 3163547422.2483 1774.0000
[2019-03-26 10:18:12,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.1300 2842097432.1985 1128.0000
[2019-03-26 10:18:12,158] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.7594 3007578670.8776 1764.0000
[2019-03-26 10:18:13,176] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 275000, evaluation results [275000.0, 7884.254115826844, 3163547422.2482767, 1774.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.759435730423, 3007578670.877596, 1764.0, 8499.13001726693, 2842097432.1984673, 1128.0]
[2019-03-26 10:18:13,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2873622e-09 7.6353198e-01 8.5858869e-11 2.3646803e-01 4.7134703e-15], sum to 1.0000
[2019-03-26 10:18:13,604] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5698
[2019-03-26 10:18:13,616] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2350633.175373648 W.
[2019-03-26 10:18:13,624] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.45, 65.66666666666667, 1.0, 2.0, 0.5603133777874542, 1.0, 1.0, 0.5603133777874542, 1.0, 2.0, 0.9730790387512469, 6.9112, 6.9112, 170.5573041426782, 2350633.175373648, 2350633.175373648, 459359.0165861264], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2369400.0000, 
sim time next is 2370000.0000, 
raw observation next is [31.6, 65.33333333333334, 1.0, 2.0, 0.4913169620743113, 1.0, 2.0, 0.4913169620743113, 1.0, 2.0, 0.8532550821208655, 6.9112, 6.9112, 170.5573041426782, 2060919.111638392, 2060919.111638392, 409193.0606700017], 
processed observation next is [1.0, 0.43478260869565216, 0.6966824644549764, 0.6533333333333334, 1.0, 1.0, 0.3871288699690497, 1.0, 1.0, 0.3871288699690497, 1.0, 1.0, 0.8210427830742263, 0.0, 0.0, 0.8375144448122397, 0.5724775310106645, 0.5724775310106645, 0.6107359114477637], 
reward next is 0.3893, 
noisyNet noise sample is [array([-0.07029268], dtype=float32), -0.20630184]. 
=============================================
[2019-03-26 10:18:13,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[51.51425 ]
 [52.231155]
 [51.30864 ]
 [51.513504]
 [50.511425]], R is [[51.88968277]
 [51.68517303]
 [51.16832352]
 [50.6566391 ]
 [50.15007401]].
[2019-03-26 10:18:19,924] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.3923221e-11 9.9999058e-01 9.0054747e-14 9.4102843e-06 1.7466144e-17], sum to 1.0000
[2019-03-26 10:18:19,931] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7504
[2019-03-26 10:18:19,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2148904.771724942 W.
[2019-03-26 10:18:19,939] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.81666666666666, 83.66666666666667, 1.0, 2.0, 0.5122714627749662, 1.0, 2.0, 0.5122714627749662, 1.0, 1.0, 0.8841086538864799, 6.9112, 6.9112, 170.5573041426782, 2148904.771724942, 2148904.771724942, 422707.5804416711], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2477400.0000, 
sim time next is 2478000.0000, 
raw observation next is [27.93333333333333, 83.33333333333334, 1.0, 2.0, 0.7805411286970548, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.990834415396183, 6.9112, 168.9124818193614, 1987840.327256171, 1931345.090936398, 403654.863457931], 
processed observation next is [1.0, 0.6956521739130435, 0.522906793048973, 0.8333333333333335, 1.0, 1.0, 0.7355917213217528, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007963441539618277, 0.0, 0.8294376142018365, 0.5521778686822697, 0.5364847474823328, 0.6024699454595984], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3359753], dtype=float32), 0.25603658]. 
=============================================
[2019-03-26 10:18:19,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[47.23929 ]
 [48.458992]
 [48.580425]
 [48.53856 ]
 [49.36928 ]], R is [[47.30841827]
 [46.83533478]
 [46.79451752]
 [46.78871155]
 [46.76889038]].
[2019-03-26 10:18:20,573] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7943088e-18 1.0000000e+00 6.2098977e-24 7.9979883e-21 5.3463808e-27], sum to 1.0000
[2019-03-26 10:18:20,574] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3103
[2019-03-26 10:18:20,584] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 92.33333333333333, 1.0, 2.0, 0.55378696632678, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773858.6221313174, 773858.6221313174, 192452.5599444059], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2490600.0000, 
sim time next is 2491200.0000, 
raw observation next is [27.0, 93.0, 1.0, 2.0, 0.5543193037997713, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774602.7785973914, 774602.7785973914, 192544.4804045955], 
processed observation next is [1.0, 0.8695652173913043, 0.4786729857819906, 0.93, 1.0, 1.0, 0.463035305782857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2151674384992754, 0.2151674384992754, 0.2873798214993963], 
reward next is 0.7126, 
noisyNet noise sample is [array([1.6437283], dtype=float32), -0.5786817]. 
=============================================
[2019-03-26 10:18:21,988] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.6481855e-21 1.0000000e+00 5.1127961e-26 1.5367842e-21 5.2272078e-30], sum to 1.0000
[2019-03-26 10:18:21,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3710
[2019-03-26 10:18:22,000] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.45, 95.0, 1.0, 2.0, 0.5464744912966144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 763636.5397815894, 763636.53978159, 191197.9855881855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2511000.0000, 
sim time next is 2511600.0000, 
raw observation next is [26.43333333333333, 95.0, 1.0, 2.0, 0.5453855525236866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762114.3246316728, 762114.3246316728, 191012.578711956], 
processed observation next is [1.0, 0.043478260869565216, 0.4518167456556081, 0.95, 1.0, 1.0, 0.45227175002853803, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.211698423508798, 0.211698423508798, 0.28509340106262093], 
reward next is 0.7149, 
noisyNet noise sample is [array([0.27636155], dtype=float32), -0.8775349]. 
=============================================
[2019-03-26 10:18:25,227] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.2096302e-17 1.0000000e+00 1.3595580e-22 2.2330376e-17 3.7658574e-26], sum to 1.0000
[2019-03-26 10:18:25,239] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-26 10:18:25,244] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 80.33333333333334, 1.0, 2.0, 0.5381180489597529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 751955.2197556107, 751955.2197556107, 189784.2991302837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2571600.0000, 
sim time next is 2572200.0000, 
raw observation next is [28.4, 81.0, 1.0, 2.0, 0.5394234672671486, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753780.0319965587, 753780.0319965587, 190003.7560932164], 
processed observation next is [1.0, 0.782608695652174, 0.5450236966824644, 0.81, 1.0, 1.0, 0.44508851477969713, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20938334222126628, 0.20938334222126628, 0.283587695661517], 
reward next is 0.7164, 
noisyNet noise sample is [array([-0.2858029], dtype=float32), 0.27209434]. 
=============================================
[2019-03-26 10:18:27,656] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.9667976e-20 1.0000000e+00 6.7432901e-27 4.8124431e-23 3.1341943e-30], sum to 1.0000
[2019-03-26 10:18:27,667] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5384
[2019-03-26 10:18:27,671] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.05, 92.0, 1.0, 2.0, 0.4346233721842535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 629440.7439681643, 629440.7439681637, 176828.0432622833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2604600.0000, 
sim time next is 2605200.0000, 
raw observation next is [24.03333333333333, 92.0, 1.0, 2.0, 0.4335841862253737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 628352.3139503202, 628352.3139503202, 176732.0910779584], 
processed observation next is [0.0, 0.13043478260869565, 0.3380726698262243, 0.92, 1.0, 1.0, 0.31757130870526956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1745423094306445, 0.1745423094306445, 0.2637792404148633], 
reward next is 0.7362, 
noisyNet noise sample is [array([-0.4978244], dtype=float32), -0.76476717]. 
=============================================
[2019-03-26 10:18:28,947] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7350196e-22 1.0000000e+00 1.8274559e-29 8.2396106e-27 2.3047997e-33], sum to 1.0000
[2019-03-26 10:18:28,953] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5871
[2019-03-26 10:18:28,960] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 81.5, 1.0, 2.0, 0.4773453548638306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667006.0307422256, 667006.0307422249, 180122.5480859272], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2633400.0000, 
sim time next is 2634000.0000, 
raw observation next is [26.66666666666667, 80.66666666666667, 1.0, 2.0, 0.4782925138206723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668329.9348324661, 668329.9348324666, 180264.7621281692], 
processed observation next is [0.0, 0.4782608695652174, 0.4628751974723541, 0.8066666666666668, 1.0, 1.0, 0.3714367636393642, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18564720412012947, 0.18564720412012964, 0.2690518837733869], 
reward next is 0.7309, 
noisyNet noise sample is [array([-1.8227948], dtype=float32), 1.9790468]. 
=============================================
[2019-03-26 10:18:28,981] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.21282 ]
 [77.1664  ]
 [77.11743 ]
 [77.041145]
 [76.92917 ]], R is [[77.20670319]
 [77.165802  ]
 [77.1255188 ]
 [77.08580017]
 [77.04662323]].
[2019-03-26 10:18:48,452] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.8519043e-23 1.0000000e+00 2.8020150e-29 6.2403143e-25 1.0500022e-33], sum to 1.0000
[2019-03-26 10:18:48,461] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3487
[2019-03-26 10:18:48,467] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3062731660905995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 487720.7722757117, 487720.7722757111, 166178.537619431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3007800.0000, 
sim time next is 3008400.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3064534176698839, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488008.0487519372, 488008.0487519379, 166199.4117093935], 
processed observation next is [1.0, 0.8260869565217391, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16440170803600465, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13555779131998255, 0.13555779131998275, 0.24805882344685595], 
reward next is 0.7519, 
noisyNet noise sample is [array([0.85852087], dtype=float32), 0.58072966]. 
=============================================
[2019-03-26 10:19:03,911] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.7658867e-23 1.0000000e+00 5.6713786e-29 3.5056553e-26 1.3073572e-33], sum to 1.0000
[2019-03-26 10:19:03,919] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0456
[2019-03-26 10:19:03,925] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 63.0, 1.0, 2.0, 0.5639949699404903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788128.5179131179, 788128.5179131179, 194231.0397517385], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3246000.0000, 
sim time next is 3246600.0000, 
raw observation next is [32.83333333333333, 63.0, 1.0, 2.0, 0.5693407449678668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795601.5200955024, 795601.5200955024, 195174.2476920109], 
processed observation next is [0.0, 0.5652173913043478, 0.7551342812006318, 0.63, 1.0, 1.0, 0.48113342767212863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22100042224875066, 0.22100042224875066, 0.2913048473015088], 
reward next is 0.7087, 
noisyNet noise sample is [array([-1.6234758], dtype=float32), -1.6619936]. 
=============================================
[2019-03-26 10:19:07,136] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 10:19:07,139] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:19:07,140] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:19:07,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:19:07,143] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:19:07,141] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:19:07,144] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:19:07,144] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:19:07,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:19:07,149] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:19:07,152] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:19:07,166] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-26 10:19:07,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-26 10:19:07,167] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-26 10:19:07,168] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-26 10:19:07,202] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-26 10:19:15,245] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:19:15,246] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.60854757666667, 72.70019518833334, 1.0, 2.0, 0.1927509455151196, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 322426.1103660691, 322426.1103660684, 139535.7414259011]
[2019-03-26 10:19:15,248] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:19:15,253] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.43901881e-20 1.00000000e+00 6.50694198e-26 8.84964800e-23
 1.04892344e-29], sampled 0.8564134074468177
[2019-03-26 10:19:16,624] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:19:16,625] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.03750105, 84.58046664666666, 1.0, 2.0, 0.2179683132816292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 364297.599788798, 364297.5997887987, 156902.2547792298]
[2019-03-26 10:19:16,626] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:19:16,629] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.5126204e-21 1.0000000e+00 8.7022651e-27 8.8497069e-25 3.4664057e-30], sampled 0.9731339804339124
[2019-03-26 10:19:20,705] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:19:20,707] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.61086063, 73.88913546, 1.0, 2.0, 0.2756935512913363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 445784.3226171667, 445784.3226171673, 163317.9016739541]
[2019-03-26 10:19:20,709] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:19:20,712] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9125516e-21 1.0000000e+00 1.9753351e-27 4.4140194e-25 4.2096573e-31], sampled 0.06424164169975377
[2019-03-26 10:19:55,653] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:19:55,654] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.9, 63.16666666666666, 1.0, 2.0, 0.525274940167581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 734002.3200442176, 734002.3200442176, 187650.6404857002]
[2019-03-26 10:19:55,655] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:19:55,657] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8853395e-22 1.0000000e+00 1.2236161e-27 8.3674311e-24 7.8137443e-32], sampled 0.7061646567775473
[2019-03-26 10:20:05,945] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:20:05,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.92450394, 92.51363257, 1.0, 2.0, 0.5546864802953553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775116.0562435696, 775116.056243569, 192607.527466196]
[2019-03-26 10:20:05,947] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:20:05,949] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1438609e-21 1.0000000e+00 3.6026688e-27 7.7617325e-23 3.0432035e-31], sampled 0.025372577906359828
[2019-03-26 10:20:33,756] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:20:33,757] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.2, 85.0, 1.0, 2.0, 0.5316183156382182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742869.4485918415, 742869.4485918415, 188697.6504487417]
[2019-03-26 10:20:33,759] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:20:33,762] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.3576102e-23 1.0000000e+00 2.9578471e-29 3.7380907e-26 4.2384638e-33], sampled 0.10789027645099347
[2019-03-26 10:20:38,563] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.06678531], dtype=float32), 0.07623209]
[2019-03-26 10:20:38,563] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 86.0, 1.0, 2.0, 0.533688121086557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 745762.7555800806, 745762.7555800806, 189042.5036765224]
[2019-03-26 10:20:38,565] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:20:38,568] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.2648849e-21 1.0000000e+00 1.8660845e-26 8.1233412e-23 2.6476056e-30], sampled 0.9385342539400121
[2019-03-26 10:21:01,751] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 10:21:01,957] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6481 2927351128.7738 1338.0000
[2019-03-26 10:21:02,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 10:21:02,240] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 10:21:02,250] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 10:21:03,266] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 300000, evaluation results [300000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.648088117536, 2927351128.7737722, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 10:21:03,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.6346460e-21 1.0000000e+00 2.6758774e-27 2.0825719e-24 1.1624744e-30], sum to 1.0000
[2019-03-26 10:21:03,985] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0374
[2019-03-26 10:21:03,990] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.516806662117134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722164.9980060417, 722164.9980060423, 186271.7918337891], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3319200.0000, 
sim time next is 3319800.0000, 
raw observation next is [29.33333333333334, 73.33333333333334, 1.0, 2.0, 0.5209711584512375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727986.2930018047, 727986.2930018047, 186947.8906946398], 
processed observation next is [0.0, 0.43478260869565216, 0.5892575039494474, 0.7333333333333334, 1.0, 1.0, 0.4228568174111295, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20221841472272353, 0.20221841472272353, 0.2790267025293131], 
reward next is 0.7210, 
noisyNet noise sample is [array([-1.3068874], dtype=float32), -0.21267161]. 
=============================================
[2019-03-26 10:21:09,182] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.1700686e-11 9.9999058e-01 1.1987346e-12 9.4174920e-06 3.1139276e-16], sum to 1.0000
[2019-03-26 10:21:09,190] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8387
[2019-03-26 10:21:09,197] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2271282.366528273 W.
[2019-03-26 10:21:09,203] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.9830533688796455, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001669309670482, 6.9112, 168.9123413548192, 2271282.366528273, 2207100.558276053, 458294.9131949697], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3402000.0000, 
sim time next is 3402600.0000, 
raw observation next is [30.16666666666666, 74.16666666666667, 1.0, 2.0, 0.540987170281894, 1.0, 1.0, 0.540987170281894, 1.0, 2.0, 0.9395158075885756, 6.911199999999999, 6.9112, 170.5573041426782, 2269482.026791431, 2269482.026791431, 444646.7341687582], 
processed observation next is [1.0, 0.391304347826087, 0.6287519747235385, 0.7416666666666667, 1.0, 1.0, 0.44697249431553493, 1.0, 0.5, 0.44697249431553493, 1.0, 1.0, 0.9262387897421652, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6304116741087309, 0.6304116741087309, 0.6636518420429227], 
reward next is 0.3363, 
noisyNet noise sample is [array([0.65896344], dtype=float32), 0.05918131]. 
=============================================
[2019-03-26 10:21:12,254] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.6176156e-17 1.0000000e+00 1.6925146e-21 3.7841652e-16 1.2150600e-23], sum to 1.0000
[2019-03-26 10:21:12,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6404
[2019-03-26 10:21:12,270] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5113403676923621, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714524.0474111352, 714524.0474111352, 185391.8735271151], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3448800.0000, 
sim time next is 3449400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5115172011573851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714771.2296816761, 714771.2296816761, 185420.167520429], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.41146650741853624, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1985475638004656, 0.1985475638004656, 0.27674651868720745], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.2146465], dtype=float32), -1.3910319]. 
=============================================
[2019-03-26 10:21:13,657] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5267961e-16 1.0000000e+00 3.0851684e-22 1.4364433e-17 2.5542598e-24], sum to 1.0000
[2019-03-26 10:21:13,663] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3346
[2019-03-26 10:21:13,667] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6176968887537886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863202.2584671223, 863202.2584671223, 204079.8605584736], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3474000.0000, 
sim time next is 3474600.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.6895956485255197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 963722.9692951301, 963722.9692951301, 218612.0964300838], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.6260188536452044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2677008248042028, 0.2677008248042028, 0.32628671108967733], 
reward next is 0.6737, 
noisyNet noise sample is [array([0.26511204], dtype=float32), -0.2817325]. 
=============================================
[2019-03-26 10:21:18,023] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2779705e-09 9.6383137e-01 2.4448670e-12 3.6168691e-02 5.7790187e-15], sum to 1.0000
[2019-03-26 10:21:18,031] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7734
[2019-03-26 10:21:18,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2253260.624092594 W.
[2019-03-26 10:21:18,047] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 69.33333333333333, 1.0, 2.0, 0.8056858206612602, 1.0, 1.0, 0.8056858206612602, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2253260.624092594, 2253260.624092594, 422650.6125855524], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3581400.0000, 
sim time next is 3582000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.7854717985108026, 1.0, 2.0, 0.7854717985108026, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2196676.072211779, 2196676.072211779, 412863.3573506738], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.7, 1.0, 1.0, 0.7415322873624128, 1.0, 1.0, 0.7415322873624128, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6101877978366054, 0.6101877978366054, 0.6162139661950355], 
reward next is 0.3838, 
noisyNet noise sample is [array([0.02338398], dtype=float32), -0.48638168]. 
=============================================
[2019-03-26 10:21:18,056] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[45.903187]
 [46.537106]
 [46.503338]
 [47.122105]
 [46.83384 ]], R is [[46.23279572]
 [46.13964844]
 [45.67825317]
 [45.22146988]
 [45.1741333 ]].
[2019-03-26 10:21:31,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0828247e-18 1.0000000e+00 8.2054294e-25 1.3266647e-17 7.7732127e-27], sum to 1.0000
[2019-03-26 10:21:31,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1784
[2019-03-26 10:21:31,635] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.16666666666666, 66.33333333333333, 1.0, 2.0, 0.5537453639461969, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 773800.466035995, 773800.4660359956, 192447.4811714974], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3779400.0000, 
sim time next is 3780000.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5600600753774084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782627.856937847, 782627.8569378477, 193542.8126305278], 
processed observation next is [1.0, 0.782608695652174, 0.7156398104265403, 0.67, 1.0, 1.0, 0.46995189804507037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21739662692717973, 0.2173966269271799, 0.2888698695978027], 
reward next is 0.7111, 
noisyNet noise sample is [array([-0.72367513], dtype=float32), -0.6179954]. 
=============================================
[2019-03-26 10:21:31,655] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[55.649048]
 [54.486046]
 [52.384388]
 [48.590565]
 [43.76239 ]], R is [[56.28281403]
 [56.4327507 ]
 [56.5819664 ]
 [56.73098373]
 [56.1636734 ]].
[2019-03-26 10:21:56,480] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.7493458e-11 9.9287063e-01 1.1808461e-14 7.1293362e-03 5.0117533e-18], sum to 1.0000
[2019-03-26 10:21:56,488] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8589
[2019-03-26 10:21:56,495] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2752350.75400832 W.
[2019-03-26 10:21:56,507] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.0, 50.0, 1.0, 2.0, 0.9839463611928981, 1.0, 2.0, 0.9839463611928981, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2752350.75400832, 2752350.75400832, 519361.302416898], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4208400.0000, 
sim time next is 4209000.0000, 
raw observation next is [35.83333333333334, 51.0, 1.0, 2.0, 0.2843250807709631, 1.0, 2.0, 0.2843250807709631, 1.0, 1.0, 0.4937786375581238, 6.9112, 6.9112, 170.5573041426782, 1192170.761141128, 1192170.761141128, 298105.166050319], 
processed observation next is [1.0, 0.7391304347826086, 0.8973143759873622, 0.51, 1.0, 1.0, 0.13774106116983503, 1.0, 1.0, 0.13774106116983503, 1.0, 0.5, 0.38265687507088264, 0.0, 0.0, 0.8375144448122397, 0.3311585447614244, 0.3311585447614244, 0.44493308365719253], 
reward next is 0.5551, 
noisyNet noise sample is [array([-2.1478364], dtype=float32), 0.17797685]. 
=============================================
[2019-03-26 10:21:56,529] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[50.11831 ]
 [49.603153]
 [48.978634]
 [49.899715]
 [49.001328]], R is [[53.11914825]
 [52.81278992]
 [52.28466415]
 [51.76181793]
 [51.45077133]].
[2019-03-26 10:21:57,919] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 10:21:57,921] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:21:57,922] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:21:57,924] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:21:57,925] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:21:57,925] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:21:57,927] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:21:57,928] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:21:57,928] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:21:57,929] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:21:57,931] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:21:57,945] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-26 10:21:57,948] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-26 10:21:57,980] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-26 10:21:58,001] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-26 10:21:58,018] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-26 10:22:37,673] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04758616], dtype=float32), 0.07917205]
[2019-03-26 10:22:37,675] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.86666666666666, 54.66666666666667, 1.0, 2.0, 0.5588537068065172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780941.4579852616, 780941.4579852616, 193330.7735952572]
[2019-03-26 10:22:37,678] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:22:37,682] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9637621e-21 1.0000000e+00 1.2579581e-27 2.9015093e-23 5.8227471e-30], sampled 0.8066172845402395
[2019-03-26 10:22:38,509] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04758616], dtype=float32), 0.07917205]
[2019-03-26 10:22:38,509] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.3, 78.0, 1.0, 2.0, 0.6877288611846654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 961112.9181451441, 961112.9181451434, 218218.0372111709]
[2019-03-26 10:22:38,510] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:22:38,514] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0409213e-18 1.0000000e+00 3.4498066e-25 9.2401422e-21 7.3188512e-27], sampled 0.20293049194564539
[2019-03-26 10:23:12,165] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.04758616], dtype=float32), 0.07917205]
[2019-03-26 10:23:12,166] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.06666666666667, 84.16666666666667, 1.0, 2.0, 0.5856120089152521, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818347.8796242791, 818347.8796242797, 198096.0149243162]
[2019-03-26 10:23:12,167] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:23:12,172] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7075609e-20 1.0000000e+00 1.9434940e-27 1.1037112e-23 1.6683540e-29], sampled 0.9195781801355281
[2019-03-26 10:23:28,058] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.04758616], dtype=float32), 0.07917205]
[2019-03-26 10:23:28,059] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.29035402333334, 93.29110875, 1.0, 2.0, 0.5346711297493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 747136.8709824776, 747136.870982477, 189206.4618087252]
[2019-03-26 10:23:28,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:23:28,064] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.7680286e-20 1.0000000e+00 2.3155151e-26 2.9245704e-21 1.4716386e-28], sampled 0.19264722374450594
[2019-03-26 10:23:43,202] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.04758616], dtype=float32), 0.07917205]
[2019-03-26 10:23:43,205] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.81101848, 97.32450824166668, 1.0, 2.0, 0.3981366069181128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 592583.8767494529, 592583.8767494535, 173810.8784844565]
[2019-03-26 10:23:43,207] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:23:43,210] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1869783e-20 1.0000000e+00 3.2441296e-27 1.8577214e-22 1.6351866e-29], sampled 0.6657154580136929
[2019-03-26 10:23:53,031] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.9878 2779131868.1217 933.0000
[2019-03-26 10:23:53,051] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7886.2612 3163785282.3541 1774.0000
[2019-03-26 10:23:53,107] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5144 2842492707.2201 1131.0000
[2019-03-26 10:23:53,119] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 10:23:53,154] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 10:23:54,167] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 325000, evaluation results [325000.0, 7886.26117728311, 3163785282.3540506, 1774.0, 8255.124881931173, 2927277438.00382, 1338.0, 8659.98775396918, 2779131868.121704, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.514395919725, 2842492707.2200756, 1131.0]
[2019-03-26 10:23:56,482] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8947164e-10 4.0018134e-04 2.1850965e-12 9.9959987e-01 1.6543677e-14], sum to 1.0000
[2019-03-26 10:23:56,488] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-26 10:23:56,496] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.5, 55.5, 1.0, 2.0, 0.9635990772311909, 1.0, 2.0, 0.9635990772311909, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2695372.774108077, 2695372.774108077, 507396.9594037664], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4278600.0000, 
sim time next is 4279200.0000, 
raw observation next is [37.66666666666666, 55.0, 1.0, 2.0, 1.023284522143459, 1.0, 2.0, 1.023284522143459, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2862515.771482334, 2862515.771482334, 543233.6024810778], 
processed observation next is [1.0, 0.5217391304347826, 0.9842022116903629, 0.55, 1.0, 1.0, 1.0280536411366976, 1.0, 1.0, 1.0280536411366976, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7951432698562039, 0.7951432698562039, 0.8107964216135489], 
reward next is 0.1892, 
noisyNet noise sample is [array([-0.5463238], dtype=float32), 1.6447163]. 
=============================================
[2019-03-26 10:23:59,630] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7248083e-18 1.0000000e+00 3.8248603e-23 1.4587413e-17 1.2978078e-24], sum to 1.0000
[2019-03-26 10:23:59,638] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0371
[2019-03-26 10:23:59,643] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6182377847733076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 863958.4425649181, 863958.4425649188, 204193.0585556088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4326000.0000, 
sim time next is 4326600.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.6179569735819913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 863565.8625013917, 863565.8625013924, 204139.2569754155], 
processed observation next is [1.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 1.0, 0.5397071970867365, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2398794062503866, 0.23987940625038678, 0.30468545817226195], 
reward next is 0.6953, 
noisyNet noise sample is [array([1.0027137], dtype=float32), 0.32168487]. 
=============================================
[2019-03-26 10:24:17,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7428545e-09 9.9970466e-01 7.7132642e-13 2.9530487e-04 9.6358116e-14], sum to 1.0000
[2019-03-26 10:24:17,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2317
[2019-03-26 10:24:17,104] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2371607.086902479 W.
[2019-03-26 10:24:17,108] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333333, 65.66666666666667, 1.0, 2.0, 0.5653081266135278, 1.0, 2.0, 0.5653081266135278, 1.0, 2.0, 0.9817532656734594, 6.9112, 6.9112, 170.5573041426782, 2371607.086902479, 2371607.086902479, 463246.8469336834], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4624800.0000, 
sim time next is 4625400.0000, 
raw observation next is [33.66666666666667, 64.33333333333333, 1.0, 2.0, 0.5892700272929821, 1.0, 2.0, 0.5892700272929821, 1.0, 2.0, 1.023367162832026, 6.911200000000001, 6.9112, 170.5573041426782, 2472232.614927251, 2472232.61492725, 482366.7058643262], 
processed observation next is [1.0, 0.5217391304347826, 0.7946287519747238, 0.6433333333333333, 1.0, 1.0, 0.5051446111963639, 1.0, 1.0, 0.5051446111963639, 1.0, 1.0, 1.028496540039056, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6867312819242364, 0.686731281924236, 0.7199503072601884], 
reward next is 0.2800, 
noisyNet noise sample is [array([-0.65224916], dtype=float32), -0.12990797]. 
=============================================
[2019-03-26 10:24:21,129] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.1982848e-15 1.0000000e+00 1.5929033e-20 1.0106343e-15 2.1409198e-20], sum to 1.0000
[2019-03-26 10:24:21,137] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2821
[2019-03-26 10:24:21,142] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1912115.408060752 W.
[2019-03-26 10:24:21,147] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.7264307407134263, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.997361067221316, 6.9112, 168.9117644768777, 1912115.408060752, 1850990.212907785, 390815.1469627995], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4696200.0000, 
sim time next is 4696800.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.7278192408233237, 1.0, 1.0, 0.7278192408233237, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2035289.875120927, 2035289.875120928, 386264.0250031714], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.6720713744859321, 1.0, 0.5, 0.6720713744859321, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.565358298644702, 0.5653582986447022, 0.5765134701539871], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39058304], dtype=float32), 0.7069267]. 
=============================================
[2019-03-26 10:24:22,217] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9542610e-12 1.0000000e+00 7.5028940e-16 4.0349676e-08 4.5062848e-17], sum to 1.0000
[2019-03-26 10:24:22,228] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0093
[2019-03-26 10:24:22,237] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2228478.838363021 W.
[2019-03-26 10:24:22,243] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7968326289814398, 1.0, 2.0, 0.7968326289814398, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2228478.838363021, 2228478.838363022, 418329.9283726236], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4713600.0000, 
sim time next is 4714200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8382352209704714, 1.0, 2.0, 0.8382352209704714, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2344376.878722334, 2344376.878722335, 438911.6751816793], 
processed observation next is [1.0, 0.5652173913043478, 0.6682464454976303, 0.66, 1.0, 1.0, 0.8051026758680379, 1.0, 1.0, 0.8051026758680379, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6512157996450927, 0.6512157996450931, 0.6550920525099692], 
reward next is 0.3449, 
noisyNet noise sample is [array([-0.38743597], dtype=float32), -0.45704174]. 
=============================================
[2019-03-26 10:24:24,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9598587e-19 1.0000000e+00 3.0314869e-25 7.0612160e-21 4.2895205e-26], sum to 1.0000
[2019-03-26 10:24:24,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4913
[2019-03-26 10:24:24,604] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6945860471020369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 970700.3330538451, 970700.3330538458, 219677.5756208749], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4765200.0000, 
sim time next is 4765800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.708105031886024, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 989602.2348464536, 989602.2348464536, 222601.007603375], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.6483193155253302, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27488950967957043, 0.27488950967957043, 0.3322403098557836], 
reward next is 0.6678, 
noisyNet noise sample is [array([1.0545353], dtype=float32), -0.35199293]. 
=============================================
[2019-03-26 10:24:36,163] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.4456889e-18 1.0000000e+00 4.5491198e-24 4.7333782e-20 2.8562518e-24], sum to 1.0000
[2019-03-26 10:24:36,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3139
[2019-03-26 10:24:36,178] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.6162422541121735, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 861168.6510827631, 861168.6510827637, 203803.5360967583], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4950600.0000, 
sim time next is 4951200.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.6026695830860993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 842193.9819386912, 842193.9819386912, 201238.007412163], 
processed observation next is [1.0, 0.30434782608695654, 0.5102685624012641, 0.8066666666666668, 1.0, 1.0, 0.5212886543206016, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23394277276074757, 0.23394277276074757, 0.30035523494352684], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.13909006], dtype=float32), -0.19474216]. 
=============================================
[2019-03-26 10:24:36,473] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.0132807e-10 9.9998355e-01 1.2638482e-13 1.6474200e-05 8.5270256e-15], sum to 1.0000
[2019-03-26 10:24:36,480] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3844
[2019-03-26 10:24:36,490] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1968133.027746161 W.
[2019-03-26 10:24:36,494] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 67.33333333333334, 1.0, 2.0, 0.7664593529361208, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.980029171686688, 6.9112, 168.9125463654844, 1968133.027746161, 1919303.363000093, 400644.3691947806], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4963200.0000, 
sim time next is 4963800.0000, 
raw observation next is [30.0, 66.66666666666666, 1.0, 2.0, 0.4564913331170015, 1.0, 1.0, 0.4564913331170015, 1.0, 2.0, 0.7800383372538419, 6.9112, 6.9112, 170.5573041426782, 1914706.082093541, 1914706.082093541, 384269.4570254103], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.6666666666666665, 1.0, 1.0, 0.3451702808638572, 1.0, 0.5, 0.3451702808638572, 1.0, 1.0, 0.7317540698217583, 0.0, 0.0, 0.8375144448122397, 0.5318628005815392, 0.5318628005815392, 0.5735365030230005], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08576097], dtype=float32), -0.10072658]. 
=============================================
[2019-03-26 10:24:36,699] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0760476e-09 8.9941227e-01 9.2571940e-12 1.0058766e-01 5.3519892e-14], sum to 1.0000
[2019-03-26 10:24:36,708] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3522
[2019-03-26 10:24:36,715] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1924891.978850619 W.
[2019-03-26 10:24:36,720] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.2, 65.0, 1.0, 2.0, 0.4589176064959035, 1.0, 1.0, 0.4589176064959035, 1.0, 2.0, 0.7827394145960249, 6.9112, 6.9112, 170.5573041426782, 1924891.978850619, 1924891.978850619, 385538.8199398026], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4968000.0000, 
sim time next is 4968600.0000, 
raw observation next is [30.23333333333333, 65.0, 1.0, 2.0, 0.5357203960452567, 1.0, 2.0, 0.5357203960452567, 1.0, 2.0, 0.9160330888856895, 6.911199999999999, 6.9112, 170.5573041426782, 2247367.645549812, 2247367.645549813, 437907.1753121772], 
processed observation next is [1.0, 0.5217391304347826, 0.6319115323854659, 0.65, 1.0, 1.0, 0.44062698318705623, 1.0, 1.0, 0.44062698318705623, 1.0, 1.0, 0.8976013279093773, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6242687904305033, 0.6242687904305035, 0.6535927989733988], 
reward next is 0.3464, 
noisyNet noise sample is [array([0.35948482], dtype=float32), -0.15084948]. 
=============================================
[2019-03-26 10:24:38,877] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.9548645e-23 1.0000000e+00 3.6518129e-29 3.8734115e-26 2.5511553e-30], sum to 1.0000
[2019-03-26 10:24:38,884] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7245
[2019-03-26 10:24:38,891] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4780269629038127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668042.163974603, 668042.1639746025, 180235.2955815805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5015400.0000, 
sim time next is 5016000.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4774453943239098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667270.4197075511, 667270.4197075511, 180153.3690864326], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37041613773965043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18535289436320865, 0.18535289436320865, 0.2688856255021382], 
reward next is 0.7311, 
noisyNet noise sample is [array([0.99940425], dtype=float32), 1.2980081]. 
=============================================
[2019-03-26 10:24:38,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.42645 ]
 [70.52338 ]
 [70.40006 ]
 [70.18494 ]
 [69.913506]], R is [[70.45393372]
 [70.48039246]
 [70.50631714]
 [70.53134155]
 [70.55544281]].
[2019-03-26 10:24:45,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.4464560e-23 1.0000000e+00 2.3297675e-29 1.4242514e-28 3.9347872e-32], sum to 1.0000
[2019-03-26 10:24:45,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9362
[2019-03-26 10:24:45,831] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5102195583962155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712957.3532896775, 712957.3532896775, 185212.7387147144], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5133600.0000, 
sim time next is 5134200.0000, 
raw observation next is [30.16666666666666, 65.5, 1.0, 2.0, 0.5112979475508288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714464.7514776031, 714464.7514776024, 185385.2241250137], 
processed observation next is [0.0, 0.43478260869565216, 0.6287519747235385, 0.655, 1.0, 1.0, 0.41120234644678166, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19846243096600086, 0.19846243096600066, 0.27669436436569206], 
reward next is 0.7233, 
noisyNet noise sample is [array([-1.0388329], dtype=float32), -0.041031502]. 
=============================================
[2019-03-26 10:24:48,463] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 10:24:48,464] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:24:48,465] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:24:48,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:24:48,466] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:24:48,467] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:24:48,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:24:48,468] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:24:48,470] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:24:48,471] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:24:48,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:24:48,487] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-26 10:24:48,488] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-26 10:24:48,506] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-26 10:24:48,506] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-26 10:24:48,543] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-26 10:24:59,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:24:59,989] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.5, 89.33333333333334, 1.0, 2.0, 0.2540526982891675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417111.0264477726, 417111.0264477726, 161313.052710072]
[2019-03-26 10:24:59,989] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:24:59,991] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.5773026e-23 1.0000000e+00 2.3356583e-29 6.0445311e-27 1.2147584e-31], sampled 0.4668272043221273
[2019-03-26 10:25:15,728] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:15,732] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.46666666666667, 84.0, 1.0, 2.0, 0.3844868695011162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589172.4012776273, 589172.4012776273, 173965.2558138752]
[2019-03-26 10:25:15,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:25:15,735] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6272090e-22 1.0000000e+00 3.4672408e-29 3.4492766e-27 3.6754560e-31], sampled 0.17647826556487145
[2019-03-26 10:25:36,088] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:36,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 63.0, 1.0, 2.0, 0.5519723612845432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771321.98314073, 771321.98314073, 192139.9764991921]
[2019-03-26 10:25:36,092] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:25:36,099] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.6061951e-23 1.0000000e+00 8.6846094e-30 9.6814457e-28 6.4927643e-32], sampled 0.3601823602887041
[2019-03-26 10:25:51,520] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:51,521] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.33333333333334, 65.66666666666667, 1.0, 2.0, 0.6086404693265061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850541.2721576737, 850541.2721576737, 202367.6636673483]
[2019-03-26 10:25:51,522] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:25:51,524] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9401544e-26 1.0000000e+00 5.3224283e-35 5.7861120e-34 6.5826025e-37], sampled 0.18262006067567438
[2019-03-26 10:25:56,068] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:56,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.66666666666667, 68.33333333333334, 1.0, 2.0, 0.8004267221126338, 1.0, 2.0, 0.8004267221126338, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2238539.336827399, 2238539.336827399, 420090.6239722075]
[2019-03-26 10:25:56,072] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:25:56,075] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4446088e-14 1.0000000e+00 1.8403174e-18 5.7090475e-11 2.0682385e-20], sampled 0.6136341464397307
[2019-03-26 10:25:56,077] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2238539.336827399 W.
[2019-03-26 10:25:56,385] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:56,386] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.68180025, 93.38324736, 1.0, 2.0, 0.8471132496917815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1183979.519285318, 1183979.519285318, 255813.0199411835]
[2019-03-26 10:25:56,388] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:25:56,392] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.2712436e-21 1.0000000e+00 1.2452391e-27 1.6383868e-25 3.5596879e-29], sampled 0.802845888265161
[2019-03-26 10:25:59,401] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:25:59,402] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.5, 41.66666666666667, 1.0, 2.0, 0.8472534805757422, 1.0, 1.0, 0.8472534805757422, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2369643.229418816, 2369643.229418815, 443244.8724705259]
[2019-03-26 10:25:59,403] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:25:59,405] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.23652335e-14 1.00000000e+00 1.54028454e-18 2.28100927e-10
 1.62616105e-21], sampled 0.732314154095532
[2019-03-26 10:25:59,407] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2369643.229418816 W.
[2019-03-26 10:26:00,193] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:26:00,195] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.82301531333334, 87.95170416500001, 1.0, 2.0, 0.506401697529715, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707620.6731241221, 707620.6731241215, 184604.0227743886]
[2019-03-26 10:26:00,196] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:26:00,199] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.15766316e-23 1.00000000e+00 1.05985565e-29 1.21329804e-26
 5.88019655e-32], sampled 0.572405577229676
[2019-03-26 10:26:16,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:26:16,163] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.22008759, 56.02677482, 1.0, 2.0, 0.4358030221386995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 641998.5706072972, 641998.5706072967, 178337.9094038427]
[2019-03-26 10:26:16,165] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:26:16,167] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1474101e-22 1.0000000e+00 1.0095911e-28 6.4037924e-25 3.4858039e-31], sampled 0.19628073701088444
[2019-03-26 10:26:29,944] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.05805364], dtype=float32), 0.07794681]
[2019-03-26 10:26:29,944] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.85, 94.5, 1.0, 2.0, 0.5327905196420738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 744508.0296650664, 744508.0296650664, 188892.3760748432]
[2019-03-26 10:26:29,946] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:26:29,951] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.7964812e-22 1.0000000e+00 2.5134173e-28 1.4672685e-25 2.3989667e-30], sampled 0.5945618883240585
[2019-03-26 10:26:43,609] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 10:26:43,663] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8604 2842435242.9853 1131.0000
[2019-03-26 10:26:43,714] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8893 2779265366.1414 933.0000
[2019-03-26 10:26:43,769] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 10:26:43,829] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 10:26:44,842] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 350000, evaluation results [350000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8659.88925272283, 2779265366.141443, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.860364057107, 2842435242.9852624, 1131.0]
[2019-03-26 10:26:44,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.2091307e-23 1.0000000e+00 1.5176056e-29 9.4777301e-27 2.5031265e-32], sum to 1.0000
[2019-03-26 10:26:44,911] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8290
[2019-03-26 10:26:44,916] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 79.0, 1.0, 2.0, 0.5006537658082684, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 699586.1529506514, 699586.1529506508, 183697.824478063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5179800.0000, 
sim time next is 5180400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4951180188941846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 691848.2844061784, 691848.2844061791, 182833.909537162], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3917084564990176, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19218007900171621, 0.1921800790017164, 0.2728864321450179], 
reward next is 0.7271, 
noisyNet noise sample is [array([-0.6956426], dtype=float32), -0.31260356]. 
=============================================
[2019-03-26 10:26:51,124] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5052960e-08 9.9583626e-01 2.4211405e-10 4.1637924e-03 7.6276277e-12], sum to 1.0000
[2019-03-26 10:26:51,133] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8044
[2019-03-26 10:26:51,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2602449.685994293 W.
[2019-03-26 10:26:51,151] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.5, 70.0, 1.0, 2.0, 0.6202756813935845, 1.0, 2.0, 0.6202756813935845, 1.0, 2.0, 1.03, 6.964277188260723, 6.9112, 170.5573041426782, 2602449.685994293, 2564428.337001159, 495448.6386107493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5302800.0000, 
sim time next is 5303400.0000, 
raw observation next is [32.81666666666667, 68.33333333333334, 1.0, 2.0, 0.662336081289051, 1.0, 2.0, 0.651758080158788, 1.0, 2.0, 1.03, 7.005094762578989, 6.9112, 170.5573041426782, 2734682.869642479, 2667422.231812405, 509697.0038795227], 
processed observation next is [1.0, 0.391304347826087, 0.7543443917851502, 0.6833333333333335, 1.0, 1.0, 0.5931760015530735, 1.0, 1.0, 0.5804314218780579, 1.0, 1.0, 1.0365853658536586, 0.0093894762578989, 0.0, 0.8375144448122397, 0.7596341304562442, 0.7409506199478902, 0.7607417968351085], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5807549], dtype=float32), 0.09944872]. 
=============================================
[2019-03-26 10:26:51,743] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.0321343e-16 1.0000000e+00 5.6863053e-21 3.8297065e-16 1.1232422e-21], sum to 1.0000
[2019-03-26 10:26:51,748] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3460
[2019-03-26 10:26:51,753] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 87.16666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.067009331243439, 6.9112, 168.9121947712927, 1564366.62978005, 1453830.626134108, 311354.074786094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5281800.0000, 
sim time next is 5282400.0000, 
raw observation next is [28.6, 87.33333333333334, 1.0, 2.0, 0.9813925244952696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128296438561, 1371778.046970912, 1371778.046970912, 293311.358210906], 
processed observation next is [1.0, 0.13043478260869565, 0.5545023696682465, 0.8733333333333334, 1.0, 1.0, 0.9775813548135778, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294393221793401, 0.38104945749192, 0.38104945749192, 0.4377781465834418], 
reward next is 0.5622, 
noisyNet noise sample is [array([0.38294977], dtype=float32), -0.55088407]. 
=============================================
[2019-03-26 10:26:57,722] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2693668e-10 9.9997127e-01 1.3154420e-13 2.8734450e-05 1.1809135e-15], sum to 1.0000
[2019-03-26 10:26:57,732] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9233
[2019-03-26 10:26:57,744] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2898216.553030422 W.
[2019-03-26 10:26:57,747] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.9, 71.0, 1.0, 2.0, 0.7401958601673363, 1.0, 2.0, 0.6906879695979309, 1.0, 2.0, 1.03, 7.005100901776229, 6.9112, 170.5573041426782, 2898216.553030422, 2830951.517443638, 534324.739174929], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5418000.0000, 
sim time next is 5418600.0000, 
raw observation next is [30.9, 71.66666666666667, 1.0, 2.0, 0.2866932558780576, 1.0, 2.0, 0.2866932558780576, 1.0, 2.0, 0.4978913745516715, 6.9112, 6.9112, 170.5573041426782, 1202106.050352262, 1202106.050352262, 299040.6023538351], 
processed observation next is [1.0, 0.7391304347826086, 0.6635071090047393, 0.7166666666666667, 1.0, 1.0, 0.14059428419043085, 1.0, 1.0, 0.14059428419043085, 1.0, 1.0, 0.38767240798984326, 0.0, 0.0, 0.8375144448122397, 0.3339183473200728, 0.3339183473200728, 0.44632925724452993], 
reward next is 0.5537, 
noisyNet noise sample is [array([1.07706], dtype=float32), -0.07000767]. 
=============================================
[2019-03-26 10:27:01,244] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8212645e-16 1.0000000e+00 5.6162433e-21 2.5086803e-17 2.7548202e-21], sum to 1.0000
[2019-03-26 10:27:01,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3941
[2019-03-26 10:27:01,257] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 92.0, 1.0, 2.0, 0.9811337949457283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129355935981, 1371416.163929026, 1371416.163929026, 293233.7382016178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5455200.0000, 
sim time next is 5455800.0000, 
raw observation next is [27.8, 92.0, 1.0, 2.0, 0.9599290269340075, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956505208, 1341757.681915621, 1341757.681915621, 286957.8360887666], 
processed observation next is [1.0, 0.13043478260869565, 0.5165876777251186, 0.92, 1.0, 1.0, 0.9517217191975994, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451266553, 0.37271046719878365, 0.37271046719878365, 0.4282952777444277], 
reward next is 0.5717, 
noisyNet noise sample is [array([0.8202425], dtype=float32), -0.91021633]. 
=============================================
[2019-03-26 10:27:08,838] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5961416e-10 9.9233621e-01 6.6862271e-12 7.6638223e-03 1.3837012e-14], sum to 1.0000
[2019-03-26 10:27:08,844] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-26 10:27:08,852] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2424273.418650096 W.
[2019-03-26 10:27:08,859] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.46666666666666, 52.5, 1.0, 2.0, 0.5778497713893863, 1.0, 2.0, 0.5778497713893863, 1.0, 2.0, 0.9969094738370693, 6.9112, 6.9112, 170.5573041426782, 2424273.418650096, 2424273.418650096, 471748.2288596854], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5586600.0000, 
sim time next is 5587200.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.166289834029655, 6.9112, 168.9113174731695, 2477770.846340936, 2296803.094593099, 476169.3414433815], 
processed observation next is [1.0, 0.6956521739130435, 0.7819905213270142, 0.53, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0255089834029655, 0.0, 0.8294318967289942, 0.688269679539149, 0.6380008596091942, 0.7107005096169873], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45576364], dtype=float32), -0.9840965]. 
=============================================
[2019-03-26 10:27:09,520] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4278210e-19 1.0000000e+00 4.4938724e-25 2.9606521e-18 3.8455101e-27], sum to 1.0000
[2019-03-26 10:27:09,534] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5758
[2019-03-26 10:27:09,539] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333333, 68.33333333333334, 1.0, 2.0, 0.5362148964518305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749294.8551498201, 749294.8551498195, 189465.9900256225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5595600.0000, 
sim time next is 5596200.0000, 
raw observation next is [30.55, 70.0, 1.0, 2.0, 0.5429226798948982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758671.5109867644, 758671.5109867644, 190595.2286941811], 
processed observation next is [1.0, 0.782608695652174, 0.6469194312796209, 0.7, 1.0, 1.0, 0.449304433608311, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21074208638521236, 0.21074208638521236, 0.28447049058833], 
reward next is 0.7155, 
noisyNet noise sample is [array([-1.1786058], dtype=float32), 0.99092746]. 
=============================================
[2019-03-26 10:27:13,030] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.6285196e-25 1.0000000e+00 4.8019293e-33 3.7827200e-32 1.6709220e-35], sum to 1.0000
[2019-03-26 10:27:13,037] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5113
[2019-03-26 10:27:13,041] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.83333333333334, 69.0, 1.0, 2.0, 0.5511122417426166, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770119.6229159021, 770119.6229159026, 191992.1628533276], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5653200.0000, 
sim time next is 5653800.0000, 
raw observation next is [31.0, 68.5, 1.0, 2.0, 0.5529228790930725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772650.7125927593, 772650.7125927599, 192303.8211273199], 
processed observation next is [0.0, 0.43478260869565216, 0.6682464454976303, 0.685, 1.0, 1.0, 0.46135286637719575, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21462519794243312, 0.2146251979424333, 0.2870206285482387], 
reward next is 0.7130, 
noisyNet noise sample is [array([-0.48988378], dtype=float32), -1.0383495]. 
=============================================
[2019-03-26 10:27:20,274] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.5265319e-15 1.0000000e+00 3.6161338e-20 8.2920624e-16 7.5695419e-21], sum to 1.0000
[2019-03-26 10:27:20,283] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7201
[2019-03-26 10:27:20,291] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 81.33333333333334, 1.0, 2.0, 0.971369365972964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1357758.842865163, 1357758.842865164, 290324.7584659207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815200.0000, 
sim time next is 5815800.0000, 
raw observation next is [28.65, 80.5, 1.0, 2.0, 1.030111933655643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128842521867, 1439923.60576418, 1439923.60576418, 308235.99370558], 
processed observation next is [1.0, 0.30434782608695654, 0.5568720379146919, 0.805, 1.0, 1.0, 1.036279438139329, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294395903312431, 0.3999787793789389, 0.3999787793789389, 0.46005372194862687], 
reward next is 0.5399, 
noisyNet noise sample is [array([-0.22701925], dtype=float32), 1.2726694]. 
=============================================
[2019-03-26 10:27:24,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1299969e-19 1.0000000e+00 1.6796474e-25 4.6359491e-21 7.8769071e-28], sum to 1.0000
[2019-03-26 10:27:24,740] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3912
[2019-03-26 10:27:24,743] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 82.0, 1.0, 2.0, 0.5623294158321821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785800.2059291066, 785800.2059291066, 193938.4094615908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5859000.0000, 
sim time next is 5859600.0000, 
raw observation next is [28.8, 83.33333333333333, 1.0, 2.0, 0.5640999593079109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788275.2848574909, 788275.2848574909, 194248.8795101233], 
processed observation next is [1.0, 0.8260869565217391, 0.5639810426540285, 0.8333333333333333, 1.0, 1.0, 0.47481922808182037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21896535690485858, 0.21896535690485858, 0.2899237007613781], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.8457175], dtype=float32), -0.060374115]. 
=============================================
[2019-03-26 10:27:39,153] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 10:27:39,160] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:27:39,162] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:27:39,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:27:39,163] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:27:39,164] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:27:39,166] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:27:39,165] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:27:39,168] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:27:39,169] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:27:39,171] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:27:39,180] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-26 10:27:39,180] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-26 10:27:39,197] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-26 10:27:39,214] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-26 10:27:39,243] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-26 10:27:54,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:27:54,398] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.8, 83.66666666666667, 1.0, 2.0, 0.3005510868698257, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480468.1939896777, 480468.1939896783, 165679.1651944621]
[2019-03-26 10:27:54,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:27:54,401] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7136658e-20 1.0000000e+00 6.2346241e-26 1.3540619e-21 1.0439188e-27], sampled 0.9759269507978907
[2019-03-26 10:28:20,490] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:28:20,491] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.7481241, 86.17748326, 1.0, 2.0, 0.317362812052165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 504325.6282067444, 504325.628206745, 167390.3994907751]
[2019-03-26 10:28:20,493] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:28:20,496] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.3466244e-20 1.0000000e+00 8.2846172e-27 3.2096342e-22 1.5251452e-28], sampled 0.4816064517378349
[2019-03-26 10:28:25,155] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:28:25,156] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 1.032079575851926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1442675.907919105, 1442675.907919105, 308848.5206368698]
[2019-03-26 10:28:25,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:28:25,162] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3943943e-16 1.0000000e+00 1.7541255e-21 2.9331809e-16 1.9725766e-22], sampled 0.9074476214318866
[2019-03-26 10:28:28,753] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:28:28,755] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.78333333333333, 64.83333333333334, 1.0, 2.0, 0.8915125310054228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1246071.20130371, 1246071.20130371, 267615.5999473819]
[2019-03-26 10:28:28,757] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:28:28,760] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4097051e-18 1.0000000e+00 1.0750800e-23 1.5071307e-19 1.7393306e-24], sampled 0.1867838007125986
[2019-03-26 10:28:32,014] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:28:32,014] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.81631930166667, 62.58497589666666, 1.0, 2.0, 0.5772369040857642, 0.0, 2.0, 0.0, 1.0, 2.0, 1.002469607235742, 6.911200000000001, 6.9112, 168.9129182391724, 1613892.792649932, 1613892.792649932, 353238.7148799014]
[2019-03-26 10:28:32,015] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:28:32,017] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3318296e-12 9.9991572e-01 6.0659756e-16 8.4328225e-05 3.1505492e-19], sampled 0.7401478071014915
[2019-03-26 10:28:41,432] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.08369656], dtype=float32), 0.081389114]
[2019-03-26 10:28:41,435] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.65, 43.0, 1.0, 2.0, 0.8933422433033849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1248630.102479924, 1248630.102479924, 268113.9264774272]
[2019-03-26 10:28:41,437] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:28:41,440] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.1166274e-17 1.0000000e+00 1.5433280e-22 4.3385312e-17 8.5007233e-24], sampled 0.25066036764262245
[2019-03-26 10:29:33,945] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.6952 3007069496.4991 1754.0000
[2019-03-26 10:29:34,278] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.6292 2779240926.2957 932.0000
[2019-03-26 10:29:34,304] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7903.0236 3161969730.9433 1737.0000
[2019-03-26 10:29:34,337] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8252.6679 2927357160.1452 1338.0000
[2019-03-26 10:29:34,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.5921 2842033553.5121 1120.0000
[2019-03-26 10:29:35,651] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 375000, evaluation results [375000.0, 7903.023619407766, 3161969730.9433346, 1737.0, 8252.667910178618, 2927357160.1451993, 1338.0, 8660.629201205113, 2779240926.295723, 932.0, 8003.695176481658, 3007069496.4990797, 1754.0, 8500.592100662843, 2842033553.5120664, 1120.0]
[2019-03-26 10:29:39,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9940645e-10 7.4528545e-01 3.7895566e-13 2.5471458e-01 5.4010156e-16], sum to 1.0000
[2019-03-26 10:29:39,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9272
[2019-03-26 10:29:39,913] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 71.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.096940744506677, 6.9112, 168.9117429253299, 2425837.933889051, 2294068.003764193, 476191.1042086783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6189600.0000, 
sim time next is 6190200.0000, 
raw observation next is [29.9, 72.0, 1.0, 2.0, 0.8416091572259371, 1.0, 1.0, 0.8416091572259371, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2353821.992954202, 2353821.992954202, 440633.5200605918], 
processed observation next is [1.0, 0.6521739130434783, 0.6161137440758293, 0.72, 1.0, 1.0, 0.809167659308358, 1.0, 0.5, 0.809167659308358, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6538394424872783, 0.6538394424872783, 0.6576619702396893], 
reward next is 0.3423, 
noisyNet noise sample is [array([-2.2168486], dtype=float32), -1.2386887]. 
=============================================
[2019-03-26 10:29:39,945] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9072941e-10 9.8213470e-01 5.4706250e-13 1.7865280e-02 3.1633267e-15], sum to 1.0000
[2019-03-26 10:29:39,950] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9155
[2019-03-26 10:29:39,960] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2546597.563281129 W.
[2019-03-26 10:29:39,964] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.7, 68.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.27197762572276, 6.9112, 168.9111558493661, 2546597.563281129, 2290652.22706636, 475650.5242568028], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6185400.0000, 
sim time next is 6186000.0000, 
raw observation next is [30.6, 69.0, 1.0, 2.0, 0.8604200537430635, 1.0, 1.0, 0.8604200537430635, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2406483.178002581, 2406483.178002581, 450355.5227773586], 
processed observation next is [1.0, 0.6086956521739131, 0.6492890995260664, 0.69, 1.0, 1.0, 0.8318313900518838, 1.0, 0.5, 0.8318313900518838, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6684675494451614, 0.6684675494451614, 0.6721724220557591], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41655904], dtype=float32), 0.31901821]. 
=============================================
[2019-03-26 10:29:39,976] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[44.89265 ]
 [45.326   ]
 [46.378178]
 [47.419918]
 [47.340633]], R is [[43.82981491]
 [43.39151764]
 [42.95760345]
 [42.52802658]
 [42.48912048]].
[2019-03-26 10:29:41,804] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9304906e-20 1.0000000e+00 6.1689970e-26 1.7446987e-18 9.8564780e-28], sum to 1.0000
[2019-03-26 10:29:41,813] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4308
[2019-03-26 10:29:41,817] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333334, 87.33333333333334, 1.0, 2.0, 0.5239686055046059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732176.260853341, 732176.2608533415, 187436.7961721911], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6214800.0000, 
sim time next is 6215400.0000, 
raw observation next is [26.9, 87.5, 1.0, 2.0, 0.5230926273526413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730951.7770331706, 730951.7770331706, 187293.4710517119], 
processed observation next is [1.0, 0.9565217391304348, 0.4739336492890995, 0.875, 1.0, 1.0, 0.4254128040393268, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20304216028699182, 0.20304216028699182, 0.2795424941070327], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.58585596], dtype=float32), -0.5090168]. 
=============================================
[2019-03-26 10:29:43,591] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4106166e-23 1.0000000e+00 7.8845611e-31 3.7836099e-27 6.7634411e-33], sum to 1.0000
[2019-03-26 10:29:43,600] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6271
[2019-03-26 10:29:43,605] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.75, 65.5, 1.0, 2.0, 0.5292678855813084, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739583.8760587026, 739583.8760587032, 188309.0389110315], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6265800.0000, 
sim time next is 6266400.0000, 
raw observation next is [30.76666666666667, 65.0, 1.0, 2.0, 0.5271507721093261, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 736624.4561835225, 736624.4561835225, 187959.5725366013], 
processed observation next is [0.0, 0.5217391304347826, 0.6571879936808849, 0.65, 1.0, 1.0, 0.43030213507147724, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20461790449542291, 0.20461790449542291, 0.28053667542776317], 
reward next is 0.7195, 
noisyNet noise sample is [array([-0.8137477], dtype=float32), -1.8153882]. 
=============================================
[2019-03-26 10:29:54,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2155341e-10 9.4241440e-01 2.0915818e-13 5.7585537e-02 1.0062150e-15], sum to 1.0000
[2019-03-26 10:29:54,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7568
[2019-03-26 10:29:54,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2266869.175351363 W.
[2019-03-26 10:29:54,959] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.5403648968784012, 1.0, 1.0, 0.5403648968784012, 1.0, 2.0, 0.9275914448943994, 6.911199999999999, 6.9112, 170.5573041426782, 2266869.175351363, 2266869.175351363, 442035.852015694], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6447600.0000, 
sim time next is 6448200.0000, 
raw observation next is [30.0, 67.83333333333334, 1.0, 2.0, 0.5321236217840769, 1.0, 2.0, 0.5321236217840769, 1.0, 2.0, 0.9141549431373382, 6.911200000000001, 6.9112, 170.5573041426782, 2232265.564203484, 2232265.564203483, 436133.0918781452], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.6783333333333335, 1.0, 1.0, 0.43629352022177936, 1.0, 1.0, 0.43629352022177936, 1.0, 1.0, 0.8953109062650465, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6200737678343011, 0.6200737678343008, 0.6509449132509629], 
reward next is 0.3491, 
noisyNet noise sample is [array([0.7504193], dtype=float32), 0.28512433]. 
=============================================
[2019-03-26 10:29:57,794] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.8826266e-16 1.0000000e+00 2.7862513e-21 1.4973210e-14 6.2336379e-22], sum to 1.0000
[2019-03-26 10:29:57,805] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1743
[2019-03-26 10:29:57,812] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 88.0, 1.0, 2.0, 0.7102669169436563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 992624.9589280143, 992624.9589280137, 223076.7136654406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6507000.0000, 
sim time next is 6507600.0000, 
raw observation next is [27.06666666666667, 87.66666666666667, 1.0, 2.0, 0.6683857064758556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 934068.6387949549, 934068.6387949542, 214169.1743694639], 
processed observation next is [1.0, 0.30434782608695654, 0.48183254344391807, 0.8766666666666667, 1.0, 1.0, 0.6004647065974164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25946351077637636, 0.25946351077637614, 0.31965548413352823], 
reward next is 0.6803, 
noisyNet noise sample is [array([0.52931654], dtype=float32), 1.0679853]. 
=============================================
[2019-03-26 10:30:06,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8756716e-11 5.4591346e-01 9.1026674e-14 4.5408657e-01 2.6076272e-16], sum to 1.0000
[2019-03-26 10:30:06,257] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2353
[2019-03-26 10:30:06,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2002236.799266795 W.
[2019-03-26 10:30:06,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.66666666666666, 84.66666666666667, 1.0, 2.0, 0.7160105028747729, 1.0, 2.0, 0.7160105028747729, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2002236.799266795, 2002236.799266795, 381052.2944775242], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6626400.0000, 
sim time next is 6627000.0000, 
raw observation next is [27.58333333333334, 84.83333333333334, 1.0, 2.0, 0.6762966109551944, 1.0, 2.0, 0.6762966109551944, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1891083.689989682, 1891083.689989682, 364140.7605739624], 
processed observation next is [1.0, 0.6956521739130435, 0.506319115323855, 0.8483333333333334, 1.0, 1.0, 0.6099959168134873, 1.0, 1.0, 0.6099959168134873, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5253010249971339, 0.5253010249971339, 0.5434936724984514], 
reward next is 0.4565, 
noisyNet noise sample is [array([-0.26275617], dtype=float32), 1.7831227]. 
=============================================
[2019-03-26 10:30:06,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[51.22661 ]
 [50.49352 ]
 [50.656998]
 [51.363182]
 [53.119167]], R is [[52.05815506]
 [51.96884155]
 [51.79770279]
 [51.27972794]
 [50.76692963]].
[2019-03-26 10:30:07,166] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.6321093e-17 1.0000000e+00 2.6803795e-22 1.0253837e-14 7.5455153e-24], sum to 1.0000
[2019-03-26 10:30:07,176] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9357
[2019-03-26 10:30:07,185] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333334, 87.0, 1.0, 2.0, 0.5086050263659883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710700.5257481782, 710700.5257481782, 184955.3193013815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6646800.0000, 
sim time next is 6647400.0000, 
raw observation next is [26.5, 87.0, 1.0, 2.0, 0.5072361923811978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708787.1439663708, 708787.1439663714, 184737.6452244647], 
processed observation next is [1.0, 0.9565217391304348, 0.4549763033175356, 0.87, 1.0, 1.0, 0.40630866551951533, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19688531776843635, 0.1968853177684365, 0.2757278286932309], 
reward next is 0.7243, 
noisyNet noise sample is [array([1.0800878], dtype=float32), 0.863573]. 
=============================================
[2019-03-26 10:30:09,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.7319052e-17 1.0000000e+00 1.3507912e-21 4.0670418e-15 7.9907224e-23], sum to 1.0000
[2019-03-26 10:30:09,150] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-26 10:30:09,154] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 88.0, 1.0, 2.0, 0.883512695726706, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1234883.291924058, 1234883.291924058, 265441.1182576863], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6682800.0000, 
sim time next is 6683400.0000, 
raw observation next is [26.7, 87.0, 1.0, 2.0, 1.032136021574284, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1442754.863287279, 1442754.86328728, 308868.8246922487], 
processed observation next is [1.0, 0.34782608695652173, 0.46445497630331756, 0.87, 1.0, 1.0, 1.03871809828227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.40076523980202194, 0.4007652398020222, 0.46099824580932647], 
reward next is 0.5390, 
noisyNet noise sample is [array([0.4374958], dtype=float32), 0.46657878]. 
=============================================
[2019-03-26 10:30:13,667] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.1117451e-18 1.0000000e+00 8.1260997e-23 1.1034446e-18 2.8337309e-25], sum to 1.0000
[2019-03-26 10:30:13,676] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3152
[2019-03-26 10:30:13,681] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 74.66666666666667, 1.0, 2.0, 0.4137599222939741, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647443.1173423212, 647443.1173423212, 179452.465235368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6768600.0000, 
sim time next is 6769200.0000, 
raw observation next is [24.26666666666667, 73.33333333333334, 1.0, 2.0, 0.6571517913378637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1027435.739415735, 1027435.739415735, 225024.7349874153], 
processed observation next is [1.0, 0.34782608695652173, 0.34913112164297017, 0.7333333333333334, 1.0, 1.0, 0.5869298690817635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2853988165043708, 0.2853988165043708, 0.3358578134140527], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.7408918], dtype=float32), -0.5542124]. 
=============================================
[2019-03-26 10:30:18,508] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.1712616e-22 1.0000000e+00 2.0600019e-28 1.9055503e-24 1.6427266e-29], sum to 1.0000
[2019-03-26 10:30:18,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1929
[2019-03-26 10:30:18,524] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 56.33333333333334, 1.0, 2.0, 0.3468579007452334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536966.2336365948, 536966.2336365948, 169644.3454056658], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6862800.0000, 
sim time next is 6863400.0000, 
raw observation next is [27.8, 55.0, 1.0, 2.0, 0.3449734351107657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 534888.2623377481, 534888.2623377475, 169498.6112821641], 
processed observation next is [0.0, 0.43478260869565216, 0.5165876777251186, 0.55, 1.0, 1.0, 0.2108113676033322, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1485800728715967, 0.14858007287159652, 0.2529830019136778], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.56356204], dtype=float32), -1.0042756]. 
=============================================
[2019-03-26 10:30:30,220] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 10:30:30,221] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:30:30,222] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:30:30,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:30:30,223] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:30:30,224] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:30:30,226] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:30:30,229] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:30:30,231] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:30:30,229] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:30:30,232] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:30:30,251] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-26 10:30:30,268] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-26 10:30:30,269] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-26 10:30:30,270] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-26 10:30:30,313] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-26 10:30:40,237] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:30:40,239] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.11066652, 51.14391148, 1.0, 2.0, 0.2900286241361019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 471721.0076650073, 471721.0076650073, 165022.4931141826]
[2019-03-26 10:30:40,241] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:30:40,243] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.9763341e-19 1.0000000e+00 1.6802828e-24 3.1183966e-20 1.7800190e-26], sampled 0.9788794629268192
[2019-03-26 10:30:48,531] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:30:48,533] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.96666666666667, 40.66666666666667, 1.0, 2.0, 0.2855589841364975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 474962.5446254223, 474962.5446254223, 164260.1196355354]
[2019-03-26 10:30:48,538] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:30:48,540] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.5155109e-19 1.0000000e+00 2.4738420e-24 1.6055077e-19 1.7148471e-26], sampled 0.5868133360309393
[2019-03-26 10:30:49,958] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:30:49,961] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.99312918166667, 97.73782535000001, 1.0, 2.0, 0.4859632391458949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709259.2159548042, 709259.2159548042, 185237.6534568558]
[2019-03-26 10:30:49,963] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:30:49,966] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.0123152e-18 1.0000000e+00 2.4769311e-23 1.3733585e-18 7.1952822e-25], sampled 0.7710885472727951
[2019-03-26 10:30:51,359] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:30:51,360] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666667, 69.16666666666667, 1.0, 2.0, 0.4303329792422638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 619344.9523717558, 619344.9523717551, 175728.4968300429]
[2019-03-26 10:30:51,360] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:30:51,363] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1120731e-19 1.0000000e+00 4.5456504e-24 4.6666852e-19 5.0501467e-26], sampled 0.13678903936480835
[2019-03-26 10:31:14,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:31:14,290] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.83333333333334, 80.0, 1.0, 2.0, 0.7189557293120369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1004773.648284983, 1004773.648284983, 224988.8190511906]
[2019-03-26 10:31:14,291] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:31:14,293] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.2794474e-16 1.0000000e+00 5.9128445e-21 2.5100134e-15 3.2993637e-22], sampled 0.6739170345875947
[2019-03-26 10:31:20,130] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:31:20,132] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.88930516, 70.93482936000001, 1.0, 2.0, 0.5981523662920829, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.92117707501207, 6.9112, 168.9127709624056, 1672416.268312866, 1665338.195690034, 364239.5794525157]
[2019-03-26 10:31:20,133] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:31:20,137] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0556651e-11 9.9969327e-01 5.1688661e-14 3.0671558e-04 3.0955706e-16], sampled 0.7596694268137754
[2019-03-26 10:31:20,139] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1672416.268312866 W.
[2019-03-26 10:31:42,149] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:31:42,150] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.70493954666667, 96.07335762166667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.065150958358423, 6.9112, 168.9114906945037, 1563046.88806747, 1453829.727412762, 311363.3075381179]
[2019-03-26 10:31:42,151] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:31:42,152] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4073831e-15 1.0000000e+00 4.1382230e-20 2.7460744e-14 2.4871877e-21], sampled 0.739162459572793
[2019-03-26 10:31:46,558] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:31:46,559] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.6, 76.0, 1.0, 2.0, 0.601683278271614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 840815.1355658488, 840815.1355658494, 201059.3222322757]
[2019-03-26 10:31:46,561] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:31:46,562] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.5839909e-18 1.0000000e+00 3.2311680e-23 3.3712811e-17 7.0757895e-25], sampled 0.31696741236690595
[2019-03-26 10:31:55,505] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.11157193], dtype=float32), 0.078624986]
[2019-03-26 10:31:55,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 82.0, 1.0, 2.0, 0.6732990217034794, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005973612251971, 6.9112, 168.9123233126206, 1837765.334843536, 1770529.924499854, 378963.0312669945]
[2019-03-26 10:31:55,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:31:55,509] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0139690e-11 9.9999630e-01 6.4045584e-15 3.6774384e-06 1.2598480e-16], sampled 0.08215712089537985
[2019-03-26 10:31:55,511] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1837765.334843536 W.
[2019-03-26 10:32:24,814] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8055.5492 3002044271.8846 1626.0000
[2019-03-26 10:32:25,186] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7993.8934 3153637438.2609 1516.0000
[2019-03-26 10:32:25,265] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8273.6750 2925889951.2256 1295.0000
[2019-03-26 10:32:25,284] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8536.6064 2839205735.5256 1046.0000
[2019-03-26 10:32:25,403] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8671.9480 2777944515.8756 904.0000
[2019-03-26 10:32:26,417] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 400000, evaluation results [400000.0, 7993.893411107431, 3153637438.260923, 1516.0, 8273.674967436087, 2925889951.2256436, 1295.0, 8671.947990059574, 2777944515.8755693, 904.0, 8055.549155181407, 3002044271.8845997, 1626.0, 8536.60644612451, 2839205735.5256395, 1046.0]
[2019-03-26 10:32:28,145] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3657405e-16 1.0000000e+00 2.9945657e-20 1.4279024e-12 5.2799760e-22], sum to 1.0000
[2019-03-26 10:32:28,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7352
[2019-03-26 10:32:28,157] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 90.0, 1.0, 2.0, 0.4738830270649294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 664085.7216083314, 664085.7216083308, 179853.0042522342], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7086600.0000, 
sim time next is 7087200.0000, 
raw observation next is [25.06666666666666, 90.33333333333334, 1.0, 2.0, 0.4734810867919897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6182680926, 663170.6182680926, 179747.5908438063], 
processed observation next is [1.0, 0.0, 0.38704581358609763, 0.9033333333333334, 1.0, 1.0, 0.3656398636048069, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18421406063002574, 0.18421406063002574, 0.26827998633403927], 
reward next is 0.7317, 
noisyNet noise sample is [array([1.8983288], dtype=float32), 2.5020487]. 
=============================================
[2019-03-26 10:32:31,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.2626153e-15 1.0000000e+00 5.9659843e-18 6.4087985e-11 1.8838361e-19], sum to 1.0000
[2019-03-26 10:32:31,133] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0776
[2019-03-26 10:32:31,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1756130.83685398 W.
[2019-03-26 10:32:31,142] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 71.33333333333334, 1.0, 2.0, 0.6250391378059776, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.927315289307646, 6.9112, 168.9119338952648, 1756130.83685398, 1744698.165188588, 371359.4099630488], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7118400.0000, 
sim time next is 7119000.0000, 
raw observation next is [27.8, 71.0, 1.0, 2.0, 0.600543902975516, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001117024659658, 6.911200000000001, 6.9112, 168.9129431945834, 1683496.331354102, 1683496.331354101, 358850.6230905835], 
processed observation next is [1.0, 0.391304347826087, 0.5165876777251186, 0.71, 1.0, 1.0, 0.5187275939464048, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0013622251947047, 8.881784197001253e-17, 0.0, 0.8294398797653949, 0.46763786982058386, 0.4676378698205836, 0.5355979449113186], 
reward next is 0.4644, 
noisyNet noise sample is [array([1.6450354], dtype=float32), 0.77734184]. 
=============================================
[2019-03-26 10:32:31,152] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[56.293747]
 [58.137802]
 [59.688435]
 [60.438103]
 [61.43944 ]], R is [[55.59568024]
 [55.40487671]
 [54.85083008]
 [54.30232239]
 [54.12775421]].
[2019-03-26 10:32:35,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.098248e-17 1.000000e+00 5.311410e-22 9.317683e-16 8.555605e-24], sum to 1.0000
[2019-03-26 10:32:35,040] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5740
[2019-03-26 10:32:35,043] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 90.0, 1.0, 2.0, 0.5764029298571286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805474.0182349448, 805474.0182349454, 196426.5081277578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7185600.0000, 
sim time next is 7186200.0000, 
raw observation next is [25.8, 90.16666666666667, 1.0, 2.0, 0.531586835600501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742825.443834168, 742825.443834168, 188690.8426545402], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9016666666666667, 1.0, 1.0, 0.4356467898801217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20634040106504667, 0.20634040106504667, 0.2816281233649854], 
reward next is 0.7184, 
noisyNet noise sample is [array([1.3917623], dtype=float32), -0.97212493]. 
=============================================
[2019-03-26 10:32:38,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.12276294e-20 1.00000000e+00 4.50540264e-27 5.32370241e-22
 6.88024449e-29], sum to 1.0000
[2019-03-26 10:32:38,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4057
[2019-03-26 10:32:38,416] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 87.0, 1.0, 2.0, 0.3220762306654523, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 507762.1145266998, 507762.1145267004, 167580.1688882732], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7282800.0000, 
sim time next is 7283400.0000, 
raw observation next is [22.05, 86.66666666666667, 1.0, 2.0, 0.3440939055081151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542383.9099507106, 542383.9099507106, 170296.9382657273], 
processed observation next is [1.0, 0.30434782608695654, 0.24407582938388633, 0.8666666666666667, 1.0, 1.0, 0.20975169338327118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15066219720853072, 0.15066219720853072, 0.25417453472496615], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.3792908], dtype=float32), 0.58780485]. 
=============================================
[2019-03-26 10:32:48,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1222239e-22 1.0000000e+00 5.2316818e-28 4.0380263e-22 6.9576763e-31], sum to 1.0000
[2019-03-26 10:32:48,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6964
[2019-03-26 10:32:48,935] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.38333333333333, 91.16666666666667, 1.0, 2.0, 0.3132092195961585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494844.2001520874, 494844.2001520874, 166632.1570427495], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7438200.0000, 
sim time next is 7438800.0000, 
raw observation next is [21.36666666666667, 91.33333333333334, 1.0, 2.0, 0.3131527610906916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 494711.8894483713, 494711.8894483713, 166621.4210507116], 
processed observation next is [0.0, 0.08695652173913043, 0.21169036334913136, 0.9133333333333334, 1.0, 1.0, 0.1724732061333634, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13741996929121425, 0.13741996929121425, 0.24868868813539044], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.91640466], dtype=float32), 0.031323083]. 
=============================================
[2019-03-26 10:32:50,231] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4592566e-20 1.0000000e+00 1.6202630e-25 1.1841969e-20 5.7404641e-29], sum to 1.0000
[2019-03-26 10:32:50,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2399
[2019-03-26 10:32:50,247] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.26666666666667, 75.83333333333334, 1.0, 2.0, 0.4176749148650095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607589.897698016, 607589.897698016, 174791.688336351], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7488600.0000, 
sim time next is 7489200.0000, 
raw observation next is [26.33333333333334, 75.66666666666667, 1.0, 2.0, 0.4192357920482003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608953.8282641704, 608953.8282641704, 174894.0318396651], 
processed observation next is [0.0, 0.6956521739130435, 0.44707740916271754, 0.7566666666666667, 1.0, 1.0, 0.3002840868050606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16915384118449178, 0.16915384118449178, 0.2610358684174106], 
reward next is 0.7390, 
noisyNet noise sample is [array([1.7155737], dtype=float32), -1.3717195]. 
=============================================
[2019-03-26 10:32:53,338] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2734275e-21 1.0000000e+00 3.9571505e-27 9.3875558e-20 3.1256829e-29], sum to 1.0000
[2019-03-26 10:32:53,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1825
[2019-03-26 10:32:53,350] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 82.33333333333334, 1.0, 2.0, 0.4056674306009919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596655.12751652, 596655.12751652, 173970.7512253905], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7500000.0000, 
sim time next is 7500600.0000, 
raw observation next is [24.85, 83.0, 1.0, 2.0, 0.4047198760001976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 595707.356162778, 595707.356162778, 173897.1060322049], 
processed observation next is [0.0, 0.8260869565217391, 0.37677725118483424, 0.83, 1.0, 1.0, 0.2827950313255393, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16547426560077166, 0.16547426560077166, 0.2595479194510521], 
reward next is 0.7405, 
noisyNet noise sample is [array([-1.2195945], dtype=float32), -0.2804683]. 
=============================================
[2019-03-26 10:32:53,397] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3533162e-21 1.0000000e+00 6.1145225e-27 5.9543539e-22 8.4031671e-30], sum to 1.0000
[2019-03-26 10:32:53,407] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7487
[2019-03-26 10:32:53,413] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 90.0, 1.0, 2.0, 0.4051850920970963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 596411.0850560442, 596411.0850560435, 173962.7340567657], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7509600.0000, 
sim time next is 7510200.0000, 
raw observation next is [23.85, 90.33333333333333, 1.0, 2.0, 0.4051719434541921, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 596370.3290199444, 596370.3290199444, 173958.2841457388], 
processed observation next is [0.0, 0.9565217391304348, 0.3293838862559243, 0.9033333333333333, 1.0, 1.0, 0.2833396909086652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16565842472776235, 0.16565842472776235, 0.2596392300682669], 
reward next is 0.7404, 
noisyNet noise sample is [array([0.2591529], dtype=float32), -0.928172]. 
=============================================
[2019-03-26 10:33:02,281] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.7103552e-19 1.0000000e+00 4.5416292e-24 2.5475350e-17 1.4676595e-26], sum to 1.0000
[2019-03-26 10:33:02,292] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3774
[2019-03-26 10:33:02,297] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.06666666666667, 88.83333333333334, 1.0, 2.0, 0.5033813306917474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 703398.7646157708, 703398.7646157702, 184127.4413848462], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7675800.0000, 
sim time next is 7676400.0000, 
raw observation next is [26.03333333333333, 88.66666666666667, 1.0, 2.0, 0.5023513730567796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 701959.0801179268, 701959.0801179275, 183965.1251545989], 
processed observation next is [1.0, 0.8695652173913043, 0.4328593996840442, 0.8866666666666667, 1.0, 1.0, 0.4004233410322645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1949886333660908, 0.19498863336609099, 0.27457481366358044], 
reward next is 0.7254, 
noisyNet noise sample is [array([0.40722737], dtype=float32), 0.121262796]. 
=============================================
[2019-03-26 10:33:05,390] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.4756994e-16 1.0000000e+00 5.8060085e-20 3.0486475e-12 1.6019692e-22], sum to 1.0000
[2019-03-26 10:33:05,392] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0510
[2019-03-26 10:33:05,401] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333333, 87.0, 1.0, 2.0, 0.6034012002840791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843216.7781832678, 843216.7781832678, 201374.9563591422], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7716000.0000, 
sim time next is 7716600.0000, 
raw observation next is [26.9, 86.5, 1.0, 2.0, 0.6148752916851967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859257.6147002022, 859257.6147002022, 203543.1267455017], 
processed observation next is [1.0, 0.30434782608695654, 0.4739336492890995, 0.865, 1.0, 1.0, 0.5359943273315623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23868267075005617, 0.23868267075005617, 0.3037957115604503], 
reward next is 0.6962, 
noisyNet noise sample is [array([-0.6550214], dtype=float32), -0.44376206]. 
=============================================
[2019-03-26 10:33:17,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:17,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:17,667] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-26 10:33:17,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:17,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:17,995] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-26 10:33:18,061] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:18,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:18,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-26 10:33:18,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:18,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:18,402] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:18,403] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:18,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-26 10:33:18,423] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-26 10:33:18,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:18,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:18,689] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-26 10:33:19,012] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,013] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,015] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-26 10:33:19,053] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,053] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,057] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-26 10:33:19,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,070] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,077] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-26 10:33:19,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,220] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-26 10:33:19,235] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,243] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-26 10:33:19,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-26 10:33:19,275] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,275] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,276] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,276] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,277] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,278] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-26 10:33:19,278] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-26 10:33:19,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:33:19,321] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:19,324] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-26 10:33:19,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-26 10:33:20,933] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8271446e-10 1.0000000e+00 2.4099621e-13 3.9328183e-11 9.0494676e-14], sum to 1.0000
[2019-03-26 10:33:20,943] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5917
[2019-03-26 10:33:20,948] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 85.0, 1.0, 2.0, 0.2698905337457244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 439649.4341560845, 439649.4341560845, 162867.4799246197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7200.0000, 
sim time next is 7800.0000, 
raw observation next is [20.66666666666667, 85.00000000000001, 1.0, 2.0, 0.3754134674260543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610838.981024439, 610838.9810244383, 175835.0636500246], 
processed observation next is [1.0, 0.08695652173913043, 0.17851500789889443, 0.8500000000000001, 1.0, 1.0, 0.24748610533259555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16967749472901084, 0.16967749472901064, 0.26244039350749937], 
reward next is 0.7376, 
noisyNet noise sample is [array([-0.0797728], dtype=float32), 1.1309865]. 
=============================================
[2019-03-26 10:33:21,291] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 10:33:21,293] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:33:21,294] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:33:21,296] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:21,296] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:33:21,297] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:33:21,298] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:33:21,299] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:21,299] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:21,300] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:21,297] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:33:21,316] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-26 10:33:21,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-26 10:33:21,350] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-26 10:33:21,368] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-26 10:33:21,385] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-26 10:33:32,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:33:32,751] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.28379149, 60.74108953666666, 1.0, 2.0, 0.3542380848162582, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575837.2215232671, 575837.2215232671, 172920.1050180494]
[2019-03-26 10:33:32,752] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:33:32,755] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2729909e-19 1.0000000e+00 4.6158051e-25 3.2178776e-19 5.6813850e-28], sampled 0.6320926819430736
[2019-03-26 10:34:03,525] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:03,526] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.97517917, 98.53869047, 1.0, 2.0, 0.4192337471567328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 614160.6867440026, 614160.6867440033, 175543.766067256]
[2019-03-26 10:34:03,528] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:34:03,531] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9270455e-20 1.0000000e+00 1.8078709e-26 1.2070920e-21 5.2470084e-29], sampled 0.7736074273518349
[2019-03-26 10:34:05,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:05,258] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.0, 100.0, 1.0, 2.0, 0.3037599603951716, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 483719.6979696548, 483719.6979696554, 165889.0435059302]
[2019-03-26 10:34:05,260] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:34:05,263] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5991081e-19 1.0000000e+00 8.0697157e-25 5.1586209e-18 9.2509368e-28], sampled 0.6322181901761109
[2019-03-26 10:34:22,766] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:22,767] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.879776, 73.45459468, 1.0, 2.0, 0.7400654265300761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1034289.786276618, 1034289.786276618, 229729.7125009153]
[2019-03-26 10:34:22,767] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:34:22,770] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1665156e-17 1.0000000e+00 4.6905736e-23 1.2086432e-16 2.1951236e-25], sampled 0.10916043680156351
[2019-03-26 10:34:30,685] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:30,687] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.66666666666666, 64.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.579328479501864, 6.9112, 168.9092440653818, 1928062.512278318, 1454079.591351224, 311351.7861460554]
[2019-03-26 10:34:30,688] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:34:30,691] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.4338585e-14 9.9999678e-01 1.7895660e-18 3.2744911e-06 8.9727078e-23], sampled 0.693798954009722
[2019-03-26 10:34:30,692] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1928062.512278318 W.
[2019-03-26 10:34:53,604] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:53,605] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.1, 83.0, 1.0, 2.0, 0.5123525211006227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715938.8617114736, 715938.8617114729, 185553.8411422499]
[2019-03-26 10:34:53,606] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:34:53,611] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.7680441e-18 1.0000000e+00 6.8460214e-23 2.4130645e-15 9.7448900e-26], sampled 0.6711967124110774
[2019-03-26 10:34:59,673] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13355282], dtype=float32), 0.08307296]
[2019-03-26 10:34:59,675] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.43823458333333, 79.29660666333334, 1.0, 2.0, 0.6896982819966049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104687.270420729, 1104687.270420729, 234947.8236850641]
[2019-03-26 10:34:59,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:34:59,681] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.6708963e-19 1.0000000e+00 7.1616311e-24 1.1804867e-17 1.2517693e-26], sampled 0.20746041423061778
[2019-03-26 10:35:15,855] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.3154 2927336649.6058 1337.0000
[2019-03-26 10:35:15,960] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7935.7177 3159347736.1245 1661.0000
[2019-03-26 10:35:15,976] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8507.0839 2841281970.6064 1108.0000
[2019-03-26 10:35:16,146] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8012.9218 3006053918.6259 1729.0000
[2019-03-26 10:35:16,271] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.1346 2778934889.3187 926.0000
[2019-03-26 10:35:17,289] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 425000, evaluation results [425000.0, 7935.717731347724, 3159347736.1244745, 1661.0, 8256.315441479568, 2927336649.6058164, 1337.0, 8662.134592691958, 2778934889.318741, 926.0, 8012.921750422948, 3006053918.6258883, 1729.0, 8507.083944986507, 2841281970.606356, 1108.0]
[2019-03-26 10:35:25,833] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9925997e-18 1.0000000e+00 1.3508620e-23 3.0469876e-14 9.5219417e-27], sum to 1.0000
[2019-03-26 10:35:25,841] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5654
[2019-03-26 10:35:25,849] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.2, 96.0, 1.0, 2.0, 0.3383558982507733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 528818.2053455696, 528818.2053455702, 169119.0769720839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 165600.0000, 
sim time next is 166200.0000, 
raw observation next is [21.1, 96.0, 1.0, 2.0, 0.334621014927417, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524335.8812284133, 524335.8812284126, 168795.4524456441], 
processed observation next is [1.0, 0.9565217391304348, 0.1990521327014219, 0.96, 1.0, 1.0, 0.19833857220170725, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14564885589678148, 0.14564885589678128, 0.25193351111290163], 
reward next is 0.7481, 
noisyNet noise sample is [array([-0.07783654], dtype=float32), 0.42738622]. 
=============================================
[2019-03-26 10:35:27,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0560950e-20 1.0000000e+00 2.9748706e-26 2.8208699e-21 2.2977112e-29], sum to 1.0000
[2019-03-26 10:35:27,137] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6561
[2019-03-26 10:35:27,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.88333333333333, 96.0, 1.0, 2.0, 0.2862261540114023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461138.5560566716, 461138.5560566716, 164350.7811383822], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 187800.0000, 
sim time next is 188400.0000, 
raw observation next is [19.86666666666667, 96.0, 1.0, 2.0, 0.2856944411826112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460424.7653101006, 460424.7653101006, 164302.1342669122], 
processed observation next is [0.0, 0.17391304347826086, 0.14060031595576644, 0.96, 1.0, 1.0, 0.13939089299109786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12789576814169462, 0.12789576814169462, 0.24522706607001823], 
reward next is 0.7548, 
noisyNet noise sample is [array([-0.39407727], dtype=float32), 0.9209807]. 
=============================================
[2019-03-26 10:35:29,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9988261e-19 1.0000000e+00 6.7433743e-25 6.8714965e-18 8.0611459e-29], sum to 1.0000
[2019-03-26 10:35:29,048] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5347
[2019-03-26 10:35:29,055] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.26666666666667, 89.0, 1.0, 2.0, 0.3001949018991961, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 478264.1305440522, 478264.1305440522, 165501.1985853083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 241800.0000, 
sim time next is 242400.0000, 
raw observation next is [21.23333333333333, 89.0, 1.0, 2.0, 0.2996505036284212, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 477729.2055036015, 477729.2055036021, 165467.9946676845], 
processed observation next is [0.0, 0.8260869565217391, 0.2053712480252764, 0.89, 1.0, 1.0, 0.15620542605833881, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13270255708433376, 0.13270255708433393, 0.24696715622042464], 
reward next is 0.7530, 
noisyNet noise sample is [array([-1.1097912], dtype=float32), 0.22616358]. 
=============================================
[2019-03-26 10:35:31,276] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.2034481e-17 1.0000000e+00 2.3612266e-21 5.0949787e-12 8.1559090e-24], sum to 1.0000
[2019-03-26 10:35:31,284] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9995
[2019-03-26 10:35:31,289] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.61666666666667, 85.16666666666667, 1.0, 2.0, 0.2397959677748113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395445.2857745519, 395445.2857745519, 159890.7016942344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 435000.0000, 
sim time next is 435600.0000, 
raw observation next is [19.6, 85.0, 1.0, 2.0, 0.2386394219171848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393702.6486954252, 393702.6486954258, 159774.2805548117], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 1.0, 1.0, 0.08269809869540336, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10936184685984034, 0.1093618468598405, 0.23846907545494284], 
reward next is 0.7615, 
noisyNet noise sample is [array([0.05514487], dtype=float32), -0.7358354]. 
=============================================
[2019-03-26 10:35:35,669] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2234437e-19 1.0000000e+00 1.9337492e-25 2.6914798e-19 4.7479166e-28], sum to 1.0000
[2019-03-26 10:35:35,682] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0491
[2019-03-26 10:35:35,688] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.03333333333333, 89.66666666666667, 1.0, 2.0, 0.2571424099729964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 418631.7409646709, 418631.7409646703, 161548.2531185804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 362400.0000, 
sim time next is 363000.0000, 
raw observation next is [20.01666666666667, 89.83333333333333, 1.0, 2.0, 0.2575832082847994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 419326.6400830902, 419326.6400830902, 161591.6598176466], 
processed observation next is [1.0, 0.17391304347826086, 0.14770932069510287, 0.8983333333333333, 1.0, 1.0, 0.1055219376925294, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11647962224530284, 0.11647962224530284, 0.241181581817383], 
reward next is 0.7588, 
noisyNet noise sample is [array([1.3117349], dtype=float32), 0.6012832]. 
=============================================
[2019-03-26 10:35:35,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[73.812126]
 [74.04714 ]
 [74.1639  ]
 [74.267334]
 [74.40911 ]], R is [[73.83137512]
 [73.85194397]
 [73.87239075]
 [73.8928833 ]
 [73.91312408]].
[2019-03-26 10:35:36,722] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1600698e-17 1.0000000e+00 4.6946034e-22 4.8044126e-14 1.6904279e-24], sum to 1.0000
[2019-03-26 10:35:36,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7994
[2019-03-26 10:35:36,739] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.28333333333333, 87.16666666666667, 1.0, 2.0, 0.2821006884393824, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459653.4282804437, 459653.4282804437, 164179.2948031635], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 353400.0000, 
sim time next is 354000.0000, 
raw observation next is [20.26666666666667, 87.33333333333334, 1.0, 2.0, 0.2630778905028809, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 428627.6173948369, 428627.6173948369, 162163.38724596], 
processed observation next is [1.0, 0.08695652173913043, 0.15955766192733034, 0.8733333333333334, 1.0, 1.0, 0.11214203675045889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11906322705412137, 0.11906322705412137, 0.24203490633725375], 
reward next is 0.7580, 
noisyNet noise sample is [array([-0.45656568], dtype=float32), 1.576697]. 
=============================================
[2019-03-26 10:35:36,749] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.849976]
 [71.15859 ]
 [70.740524]
 [70.686584]
 [70.57729 ]], R is [[72.92255402]
 [72.94828796]
 [72.97720337]
 [73.00579071]
 [73.03407288]].
[2019-03-26 10:35:56,659] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.3567053e-16 1.0000000e+00 8.1855007e-21 1.6163783e-12 5.9245087e-24], sum to 1.0000
[2019-03-26 10:35:56,667] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4904
[2019-03-26 10:35:56,672] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 85.33333333333334, 1.0, 2.0, 0.2412295990922571, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 399198.2861125637, 399198.2861125631, 159946.3948381975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 685200.0000, 
sim time next is 685800.0000, 
raw observation next is [19.15, 86.0, 1.0, 2.0, 0.2397723131639538, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 396925.4472254777, 396925.4472254771, 159795.9672190154], 
processed observation next is [1.0, 0.9565217391304348, 0.10663507109004738, 0.86, 1.0, 1.0, 0.08406302790837808, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11025706867374381, 0.11025706867374363, 0.23850144361047076], 
reward next is 0.7615, 
noisyNet noise sample is [array([-0.3557989], dtype=float32), -1.2273787]. 
=============================================
[2019-03-26 10:36:00,115] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3158817e-20 1.0000000e+00 1.9411759e-26 5.2897970e-21 2.8292197e-30], sum to 1.0000
[2019-03-26 10:36:00,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2203
[2019-03-26 10:36:00,130] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 85.33333333333334, 1.0, 2.0, 0.3345505630127777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 519477.9307774201, 519477.9307774206, 168288.1086678219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 934800.0000, 
sim time next is 935400.0000, 
raw observation next is [22.76666666666667, 86.16666666666666, 1.0, 2.0, 0.3353269215834158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 520066.7343381367, 520066.7343381373, 168316.2579304135], 
processed observation next is [0.0, 0.8260869565217391, 0.2780410742496052, 0.8616666666666666, 1.0, 1.0, 0.19918906214869375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14446298176059352, 0.1444629817605937, 0.25121829541852764], 
reward next is 0.7488, 
noisyNet noise sample is [array([-0.03978022], dtype=float32), 1.7674798]. 
=============================================
[2019-03-26 10:36:03,356] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1719637e-21 1.0000000e+00 8.2858456e-28 6.5799163e-22 3.8308481e-30], sum to 1.0000
[2019-03-26 10:36:03,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-26 10:36:03,371] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 70.0, 1.0, 2.0, 0.2890485833937786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463072.8546722764, 463072.8546722764, 164469.9306947154], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 811800.0000, 
sim time next is 812400.0000, 
raw observation next is [23.83333333333334, 69.0, 1.0, 2.0, 0.2896023743382179, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 463720.3568616569, 463720.3568616569, 164512.0927808028], 
processed observation next is [0.0, 0.391304347826087, 0.32859399684044266, 0.69, 1.0, 1.0, 0.14409924619062395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12881121023934913, 0.12881121023934913, 0.24554043698627284], 
reward next is 0.7545, 
noisyNet noise sample is [array([-0.5468141], dtype=float32), 1.3697525]. 
=============================================
[2019-03-26 10:36:05,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1722881e-20 1.0000000e+00 5.2666690e-26 7.0119341e-21 4.3190363e-29], sum to 1.0000
[2019-03-26 10:36:05,807] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9549
[2019-03-26 10:36:05,814] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 71.33333333333333, 1.0, 2.0, 0.3014877156297535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 478693.274271819, 478693.2742718183, 165503.9728785646], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 909600.0000, 
sim time next is 910200.0000, 
raw observation next is [24.05, 70.66666666666667, 1.0, 2.0, 0.3027321731922025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480197.6300833625, 480197.6300833632, 165602.6905125778], 
processed observation next is [0.0, 0.5217391304347826, 0.3388625592417062, 0.7066666666666667, 1.0, 1.0, 0.15991828095446087, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1333882305787118, 0.133388230578712, 0.24716819479489224], 
reward next is 0.7528, 
noisyNet noise sample is [array([0.89431536], dtype=float32), -1.3966609]. 
=============================================
[2019-03-26 10:36:11,725] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 10:36:11,727] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:36:11,728] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:36:11,730] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:36:11,730] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:36:11,731] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:36:11,731] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:36:11,730] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:36:11,733] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:36:11,733] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:36:11,734] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:36:11,740] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-26 10:36:11,755] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-26 10:36:11,756] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-26 10:36:11,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-26 10:36:11,810] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-26 10:36:45,794] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:36:45,795] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.45, 81.0, 1.0, 2.0, 0.5492615862805145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767532.598159559, 767532.5981595595, 191673.9174232467]
[2019-03-26 10:36:45,795] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:36:45,796] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9183864e-17 1.0000000e+00 4.7968847e-22 2.7784299e-13 3.8827778e-25], sampled 0.5778458833642519
[2019-03-26 10:36:51,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:36:51,922] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.0, 86.33333333333334, 1.0, 2.0, 0.5665131228777155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791648.7048427727, 791648.7048427727, 194672.578472333]
[2019-03-26 10:36:51,923] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:36:51,926] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0037794e-16 1.0000000e+00 3.5264943e-21 1.5139412e-12 4.0760005e-24], sampled 0.04710553414426644
[2019-03-26 10:37:02,852] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:37:02,852] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 63.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.28466329827187, 6.9112, 168.9046021851276, 3258910.921264291, 2284576.978820261, 472727.2909603967]
[2019-03-26 10:37:02,853] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:37:02,854] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9462619e-13 9.9996793e-01 1.0099996e-17 3.2074415e-05 1.1390242e-21], sampled 0.3781444166944593
[2019-03-26 10:37:02,856] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3258910.921264291 W.
[2019-03-26 10:37:28,020] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:37:28,025] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.6, 77.0, 1.0, 2.0, 0.838409061835595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1171807.278019463, 1171807.278019464, 253559.2411398694]
[2019-03-26 10:37:28,027] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:37:28,029] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.54873700e-17 1.00000000e+00 3.67192714e-22 1.14710115e-14
 8.88281834e-25], sampled 0.4140928020300497
[2019-03-26 10:37:33,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:37:33,840] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.03333333333333, 92.0, 1.0, 2.0, 0.6385191926341557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 892312.6691220405, 892312.6691220405, 208141.2436103617]
[2019-03-26 10:37:33,842] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:37:33,845] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1067713e-17 1.0000000e+00 1.4625041e-22 1.6991935e-14 1.8131138e-25], sampled 0.38297793871445196
[2019-03-26 10:37:38,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14361554], dtype=float32), 0.07737045]
[2019-03-26 10:37:38,559] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.29295334666666, 87.29078336666667, 1.0, 2.0, 0.801792037987335, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005981640207789, 6.9112, 168.9123159192058, 2017581.448870486, 1950340.346183188, 408304.3406946603]
[2019-03-26 10:37:38,561] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:37:38,565] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9704751e-14 1.0000000e+00 2.9233256e-18 1.7531998e-09 7.9135586e-21], sampled 0.6340329998618025
[2019-03-26 10:37:38,566] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2017581.448870486 W.
[2019-03-26 10:38:05,978] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8259.5787 2926907327.5836 1324.0000
[2019-03-26 10:38:06,380] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8004.9527 3006854545.3175 1750.0000
[2019-03-26 10:38:06,511] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7924.7433 3160366610.9783 1684.0000
[2019-03-26 10:38:06,543] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8502.7885 2841686428.1784 1111.0000
[2019-03-26 10:38:06,662] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.2231 2778460214.7143 914.0000
[2019-03-26 10:38:07,677] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 450000, evaluation results [450000.0, 7924.743291896995, 3160366610.9782825, 1684.0, 8259.578682245567, 2926907327.583627, 1324.0, 8669.22314411866, 2778460214.7143364, 914.0, 8004.952671832673, 3006854545.3175473, 1750.0, 8502.788477876242, 2841686428.178369, 1111.0]
[2019-03-26 10:38:08,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.6849212e-16 1.0000000e+00 6.3569040e-21 3.0734490e-12 2.1347431e-23], sum to 1.0000
[2019-03-26 10:38:08,190] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8024
[2019-03-26 10:38:08,197] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666666, 94.83333333333333, 1.0, 2.0, 0.5968879034950557, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 918821.9658997034, 918821.9658997034, 210431.7754291751], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 993000.0000, 
sim time next is 993600.0000, 
raw observation next is [21.9, 95.0, 1.0, 2.0, 0.5948771918637855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 915602.8568341546, 915602.856834154, 210007.0210694036], 
processed observation next is [1.0, 0.5217391304347826, 0.23696682464454974, 0.95, 1.0, 1.0, 0.5119002311611873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25433412689837626, 0.2543341268983761, 0.3134433150289606], 
reward next is 0.6866, 
noisyNet noise sample is [array([1.2317127], dtype=float32), 1.1711032]. 
=============================================
[2019-03-26 10:38:09,653] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.3165484e-17 1.0000000e+00 3.5396888e-21 1.5745192e-13 9.2350534e-24], sum to 1.0000
[2019-03-26 10:38:09,664] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0627
[2019-03-26 10:38:09,669] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 93.5, 1.0, 2.0, 0.5693733268232177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 880004.0057918355, 880004.0057918349, 205284.1763980274], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 984600.0000, 
sim time next is 985200.0000, 
raw observation next is [21.96666666666667, 93.66666666666667, 1.0, 2.0, 0.5792133819971944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 894249.3052030515, 894249.3052030515, 207135.8827228688], 
processed observation next is [1.0, 0.391304347826087, 0.24012638230647723, 0.9366666666666668, 1.0, 1.0, 0.4930281710809571, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24840258477862542, 0.24840258477862542, 0.3091580339147295], 
reward next is 0.6908, 
noisyNet noise sample is [array([1.5244051], dtype=float32), 1.2838036]. 
=============================================
[2019-03-26 10:38:10,445] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2085461e-12 9.9995196e-01 1.2633009e-15 4.8068938e-05 8.9289267e-19], sum to 1.0000
[2019-03-26 10:38:10,453] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5860
[2019-03-26 10:38:10,461] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 58.5, 1.0, 2.0, 0.9391346255297464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1438384.40386559, 1438384.40386559, 298862.0060094066], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1179000.0000, 
sim time next is 1179600.0000, 
raw observation next is [27.6, 58.33333333333333, 1.0, 2.0, 0.9201992396255323, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1410577.967924249, 1410577.96792425, 293094.8122768563], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.5833333333333333, 1.0, 1.0, 0.9038545055729305, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.39182721331229137, 0.3918272133122917, 0.43745494369680044], 
reward next is 0.5625, 
noisyNet noise sample is [array([-0.8356842], dtype=float32), 1.4082606]. 
=============================================
[2019-03-26 10:38:11,594] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.3676444e-17 1.0000000e+00 3.3723291e-21 3.1829501e-11 4.3523243e-24], sum to 1.0000
[2019-03-26 10:38:11,603] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1187
[2019-03-26 10:38:11,607] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.3, 77.16666666666666, 1.0, 2.0, 0.3533114524680181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 543808.0363463858, 543808.0363463865, 170117.6531681123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1198200.0000, 
sim time next is 1198800.0000, 
raw observation next is [24.2, 78.0, 1.0, 2.0, 0.3582388996383469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551037.1222666402, 551037.1222666402, 170710.5296477101], 
processed observation next is [1.0, 0.9130434782608695, 0.3459715639810427, 0.78, 1.0, 1.0, 0.22679385498596008, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15306586729628893, 0.15306586729628893, 0.2547918352950897], 
reward next is 0.7452, 
noisyNet noise sample is [array([-0.65205073], dtype=float32), 0.33673984]. 
=============================================
[2019-03-26 10:38:17,666] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5679092e-16 1.0000000e+00 9.1664819e-22 2.9404183e-12 6.4574655e-25], sum to 1.0000
[2019-03-26 10:38:17,673] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3809
[2019-03-26 10:38:17,677] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.93333333333334, 74.33333333333334, 1.0, 2.0, 0.3295784873726749, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 517333.696293955, 517333.696293955, 168267.787656064], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1106400.0000, 
sim time next is 1107000.0000, 
raw observation next is [23.8, 75.0, 1.0, 2.0, 0.3282823112426462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515696.0292191395, 515696.0292191395, 168149.657300041], 
processed observation next is [1.0, 0.8260869565217391, 0.3270142180094788, 0.75, 1.0, 1.0, 0.19070157981041708, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1432488970053165, 0.1432488970053165, 0.25096963776125525], 
reward next is 0.7490, 
noisyNet noise sample is [array([-0.6867466], dtype=float32), 0.24748686]. 
=============================================
[2019-03-26 10:38:17,689] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.68277]
 [74.72624]
 [74.7536 ]
 [74.63624]
 [74.59076]], R is [[74.66453552]
 [74.66674805]
 [74.66934967]
 [74.67163849]
 [74.67390442]].
[2019-03-26 10:38:24,292] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6259216e-12 7.4652427e-01 1.3941963e-15 2.5347570e-01 3.0188274e-19], sum to 1.0000
[2019-03-26 10:38:24,301] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5932
[2019-03-26 10:38:24,309] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2106589.05113778 W.
[2019-03-26 10:38:24,318] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.25, 74.16666666666667, 1.0, 2.0, 0.5021938445137217, 1.0, 1.0, 0.5021938445137217, 1.0, 2.0, 0.853655090351995, 6.9112, 6.9112, 170.5573041426782, 2106589.05113778, 2106589.05113778, 413264.3810267336], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1264200.0000, 
sim time next is 1264800.0000, 
raw observation next is [28.2, 74.33333333333334, 1.0, 2.0, 0.502713686952161, 1.0, 2.0, 0.502713686952161, 1.0, 2.0, 0.8554567666922194, 6.9112, 6.9112, 170.5573041426782, 2108771.818408178, 2108771.818408178, 413790.4004469255], 
processed observation next is [1.0, 0.6521739130434783, 0.5355450236966824, 0.7433333333333334, 1.0, 1.0, 0.4008598637977843, 1.0, 1.0, 0.4008598637977843, 1.0, 1.0, 0.823727764258804, 0.0, 0.0, 0.8375144448122397, 0.5857699495578272, 0.5857699495578272, 0.6175976126073515], 
reward next is 0.3824, 
noisyNet noise sample is [array([-1.336042], dtype=float32), -0.97392327]. 
=============================================
[2019-03-26 10:38:35,994] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.6786612e-20 1.0000000e+00 3.8578562e-25 4.3304062e-20 4.2013515e-29], sum to 1.0000
[2019-03-26 10:38:36,002] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9438
[2019-03-26 10:38:36,006] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 51.0, 1.0, 2.0, 0.3428707597271431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527662.0149253301, 527662.0149253301, 168795.5129784984], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1510800.0000, 
sim time next is 1511400.0000, 
raw observation next is [29.05, 51.0, 1.0, 2.0, 0.3449039851276267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 530137.3790334774, 530137.3790334767, 168974.470872795], 
processed observation next is [0.0, 0.4782608695652174, 0.575829383886256, 0.51, 1.0, 1.0, 0.21072769292485147, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14726038306485484, 0.14726038306485464, 0.25220070279521645], 
reward next is 0.7478, 
noisyNet noise sample is [array([-0.49604046], dtype=float32), -0.44488496]. 
=============================================
[2019-03-26 10:38:37,824] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.4352031e-17 1.0000000e+00 1.4168271e-21 5.3500225e-12 2.5183844e-24], sum to 1.0000
[2019-03-26 10:38:37,836] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9020
[2019-03-26 10:38:37,842] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.83333333333334, 96.0, 1.0, 2.0, 0.3572979927717415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 548995.5839576753, 548995.5839576758, 170522.2986247193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1468200.0000, 
sim time next is 1468800.0000, 
raw observation next is [21.8, 96.0, 1.0, 2.0, 0.3566330248468683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548512.7026637949, 548512.7026637949, 170497.4604648544], 
processed observation next is [0.0, 0.0, 0.23222748815165886, 0.96, 1.0, 1.0, 0.22485906608056425, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1523646396288319, 0.1523646396288319, 0.25447382158933496], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.72448987], dtype=float32), 0.6223284]. 
=============================================
[2019-03-26 10:38:39,114] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1240534e-19 1.0000000e+00 1.5377025e-24 5.7351741e-19 6.2963326e-27], sum to 1.0000
[2019-03-26 10:38:39,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-26 10:38:39,132] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 98.5, 1.0, 2.0, 0.3117303422212508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493617.1412787182, 493617.1412787182, 166563.9223591993], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1485000.0000, 
sim time next is 1485600.0000, 
raw observation next is [20.33333333333333, 98.66666666666667, 1.0, 2.0, 0.3104452244773311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 492129.4430516197, 492129.4430516197, 166464.6233860319], 
processed observation next is [0.0, 0.17391304347826086, 0.16271721958925733, 0.9866666666666667, 1.0, 1.0, 0.16921111382810974, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13670262306989436, 0.13670262306989436, 0.24845466177019684], 
reward next is 0.7515, 
noisyNet noise sample is [array([-0.80793357], dtype=float32), 0.05955377]. 
=============================================
[2019-03-26 10:38:41,283] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2801362e-21 1.0000000e+00 6.1046205e-26 8.5634302e-19 5.4865159e-30], sum to 1.0000
[2019-03-26 10:38:41,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1142
[2019-03-26 10:38:41,296] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.85, 57.33333333333333, 1.0, 2.0, 0.3572748588014932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546906.9123869502, 546906.9123869502, 170285.8858871213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1527000.0000, 
sim time next is 1527600.0000, 
raw observation next is [27.7, 57.66666666666667, 1.0, 2.0, 0.3549844035424509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544589.4044788288, 544589.4044788294, 170129.0385365109], 
processed observation next is [0.0, 0.6956521739130435, 0.5118483412322274, 0.5766666666666667, 1.0, 1.0, 0.2228727753523505, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15127483457745244, 0.1512748345774526, 0.2539239381141954], 
reward next is 0.7461, 
noisyNet noise sample is [array([1.1046382], dtype=float32), 1.0228485]. 
=============================================
[2019-03-26 10:38:46,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6999078e-11 9.2185974e-02 1.3689958e-15 9.0781397e-01 5.2091534e-19], sum to 1.0000
[2019-03-26 10:38:46,957] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6531
[2019-03-26 10:38:46,971] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.76666666666667, 75.0, 1.0, 2.0, 0.6503947836339874, 1.0, 2.0, 0.6503947836339874, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1818594.649617133, 1818594.649617133, 353607.7596830201], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1701600.0000, 
sim time next is 1702200.0000, 
raw observation next is [28.83333333333333, 74.5, 1.0, 2.0, 0.6370040215744199, 1.0, 2.0, 0.6370040215744199, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1781121.089468031, 1781121.089468031, 348318.0458683178], 
processed observation next is [1.0, 0.6956521739130435, 0.5655608214849919, 0.745, 1.0, 1.0, 0.562655447680024, 1.0, 1.0, 0.562655447680024, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.49475585818556417, 0.49475585818556417, 0.5198776804004743], 
reward next is 0.4801, 
noisyNet noise sample is [array([0.18322396], dtype=float32), -0.22079626]. 
=============================================
[2019-03-26 10:38:48,597] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9794927e-17 1.0000000e+00 4.1984826e-22 2.2387706e-12 7.1811089e-24], sum to 1.0000
[2019-03-26 10:38:48,604] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0945
[2019-03-26 10:38:48,609] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 99.0, 1.0, 2.0, 0.4288213970175884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 617880.6233303288, 617880.6233303295, 175606.5323677504], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1656000.0000, 
sim time next is 1656600.0000, 
raw observation next is [23.31666666666667, 99.0, 1.0, 2.0, 0.4465584681719386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643133.0587700157, 643133.0587700164, 178103.1880650497], 
processed observation next is [1.0, 0.17391304347826086, 0.30410742496050575, 0.99, 1.0, 1.0, 0.3332029737011309, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17864807188055992, 0.17864807188056012, 0.2658256538284324], 
reward next is 0.7342, 
noisyNet noise sample is [array([0.14812078], dtype=float32), -1.0603169]. 
=============================================
[2019-03-26 10:38:49,135] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.7744742e-16 1.0000000e+00 1.3682123e-19 2.4096017e-11 3.2847695e-23], sum to 1.0000
[2019-03-26 10:38:49,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8762
[2019-03-26 10:38:49,140] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 99.0, 1.0, 2.0, 0.463202052953941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667408.0869076167, 667408.0869076167, 180606.4819490124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1653000.0000, 
sim time next is 1653600.0000, 
raw observation next is [23.3, 99.00000000000001, 1.0, 2.0, 0.4387657657414944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 632192.7737544909, 632192.7737544916, 177013.8418019125], 
processed observation next is [1.0, 0.13043478260869565, 0.3033175355450238, 0.9900000000000001, 1.0, 1.0, 0.3238141755921619, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17560910382069192, 0.17560910382069211, 0.2641997638834515], 
reward next is 0.7358, 
noisyNet noise sample is [array([2.0238738], dtype=float32), 1.7066151]. 
=============================================
[2019-03-26 10:38:49,446] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.82976255e-11 9.94363189e-01 1.10882322e-14 5.63680148e-03
 1.10419586e-16], sum to 1.0000
[2019-03-26 10:38:49,459] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8238
[2019-03-26 10:38:49,465] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 83.66666666666667, 1.0, 2.0, 0.4802192093139245, 1.0, 1.0, 0.4802192093139245, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1342461.960039518, 1342461.960039518, 294220.1707458569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1689000.0000, 
sim time next is 1689600.0000, 
raw observation next is [27.4, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.905025470278743, 6.9112, 168.9076804052989, 2159269.879337698, 1454237.908705249, 311349.5565719214], 
processed observation next is [1.0, 0.5652173913043478, 0.4976303317535545, 0.8333333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09938254702787433, 0.0, 0.8294140370606926, 0.5997971887049162, 0.4039549746403469, 0.4647008307043603], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.62086236], dtype=float32), 0.74787927]. 
=============================================
[2019-03-26 10:38:55,103] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7258621e-15 1.0000000e+00 1.6061632e-19 3.2472856e-09 6.6833053e-22], sum to 1.0000
[2019-03-26 10:38:55,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0833
[2019-03-26 10:38:55,117] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.4, 93.0, 1.0, 2.0, 0.3272048030727237, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514163.28648065, 514163.28648065, 168034.7519484025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1803600.0000, 
sim time next is 1804200.0000, 
raw observation next is [21.4, 93.16666666666667, 1.0, 2.0, 0.3280013532986883, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 515005.1491886139, 515005.1491886139, 168090.5317381071], 
processed observation next is [1.0, 0.9130434782608695, 0.21327014218009477, 0.9316666666666668, 1.0, 1.0, 0.19036307626347987, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1430569858857261, 0.1430569858857261, 0.2508813906538912], 
reward next is 0.7491, 
noisyNet noise sample is [array([2.5758371], dtype=float32), -0.79795367]. 
=============================================
[2019-03-26 10:39:02,252] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 10:39:02,254] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:39:02,254] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:39:02,255] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:39:02,255] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:39:02,257] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:39:02,259] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:39:02,256] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:39:02,262] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:39:02,263] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:39:02,265] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:39:02,283] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-26 10:39:02,301] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-26 10:39:02,318] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-26 10:39:02,321] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-26 10:39:02,336] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-26 10:39:21,313] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:21,315] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.86666666666667, 57.66666666666667, 1.0, 2.0, 0.2148513121521127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 358828.5056734264, 358828.5056734259, 156792.9480467917]
[2019-03-26 10:39:21,316] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:39:21,320] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4774806e-16 1.0000000e+00 1.1733242e-20 2.3173343e-12 6.6845991e-24], sampled 0.18646771589801014
[2019-03-26 10:39:25,177] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:25,178] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.38007136, 99.46185712, 1.0, 2.0, 0.4365923017745238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 628819.6101834545, 628819.6101834539, 176673.0120159575]
[2019-03-26 10:39:25,180] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:39:25,183] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.3969338e-16 1.0000000e+00 1.4722510e-20 2.4436139e-12 1.5507750e-23], sampled 0.22338986934993277
[2019-03-26 10:39:33,730] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:33,731] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.46666666666667, 92.0, 1.0, 2.0, 0.4103454896669047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607435.8290352402, 607435.8290352402, 175089.1836482912]
[2019-03-26 10:39:33,732] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:39:33,735] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.6115532e-16 1.0000000e+00 1.3043072e-20 1.7713961e-11 9.3036867e-24], sampled 0.2522334286312111
[2019-03-26 10:39:40,646] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:40,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.593473885, 90.205951495, 1.0, 2.0, 0.4776301822284497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674716.1854912251, 674716.1854912251, 181105.275710945]
[2019-03-26 10:39:40,647] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:39:40,649] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7474247e-16 1.0000000e+00 5.4323722e-21 3.2458378e-12 4.6576210e-24], sampled 0.9076826390525008
[2019-03-26 10:39:42,126] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:42,127] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.2, 53.0, 1.0, 2.0, 0.5544619740088662, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774802.2178838557, 774802.2178838557, 192569.1032629754]
[2019-03-26 10:39:42,128] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:39:42,131] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8792086e-17 1.0000000e+00 1.7966818e-22 3.8038739e-14 1.0236896e-25], sampled 0.7501604937554336
[2019-03-26 10:39:50,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:39:50,486] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.3972548, 84.6173173, 1.0, 2.0, 0.5045865153351381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 705083.3855563038, 705083.3855563038, 184316.9975822586]
[2019-03-26 10:39:50,488] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:39:50,490] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6026639e-17 1.0000000e+00 1.2803085e-22 1.1622527e-15 2.2165808e-25], sampled 0.2827596553111894
[2019-03-26 10:40:20,620] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:40:20,622] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.01628813, 75.83900844333333, 1.0, 2.0, 0.5478016354689148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765491.7425048026, 765491.7425048026, 191426.173425103]
[2019-03-26 10:40:20,624] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:40:20,626] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.7973798e-17 1.0000000e+00 3.7556219e-22 1.1948271e-11 1.1879311e-25], sampled 0.2686939769442831
[2019-03-26 10:40:30,813] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:40:30,815] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.3, 73.0, 1.0, 2.0, 0.8438505943526475, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1179416.891396058, 1179416.891396057, 254958.6921217338]
[2019-03-26 10:40:30,817] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:40:30,823] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1451943e-15 1.0000000e+00 3.1750892e-20 8.7627258e-12 6.5585372e-23], sampled 0.35092819745508963
[2019-03-26 10:40:34,005] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:40:34,006] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.23333333333333, 88.66666666666667, 1.0, 2.0, 0.5899724036791939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 824443.561800111, 824443.5618001104, 198891.8910209781]
[2019-03-26 10:40:34,006] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:40:34,010] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.6582621e-15 1.0000000e+00 1.5585174e-19 2.1043975e-09 1.1952512e-22], sampled 0.13473219620343935
[2019-03-26 10:40:39,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:40:39,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.06666666666667, 62.0, 1.0, 2.0, 0.8480130055831504, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.963291430280151, 6.9112, 168.9126048532233, 2082271.59552748, 2045316.218975049, 421406.9718365578]
[2019-03-26 10:40:39,122] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:40:39,124] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9508426e-13 9.9997127e-01 1.3654163e-17 2.8761675e-05 1.7920383e-21], sampled 0.4397906300911594
[2019-03-26 10:40:39,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2082271.59552748 W.
[2019-03-26 10:40:44,240] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.14101614], dtype=float32), 0.08278391]
[2019-03-26 10:40:44,242] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.9, 59.5, 1.0, 2.0, 0.9148733717300287, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.95382739205949, 6.9112, 168.9126692463245, 2179689.468699146, 2149448.181080878, 440322.9102298906]
[2019-03-26 10:40:44,244] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:40:44,246] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.1995713e-13 9.8559976e-01 2.2610737e-16 1.4400238e-02 2.5228942e-21], sampled 0.5541831464170607
[2019-03-26 10:40:44,248] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2179689.468699146 W.
[2019-03-26 10:40:57,031] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8743.5455 2771791337.2437 743.0000
[2019-03-26 10:40:57,183] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8144.5590 3140828092.5247 1140.0000
[2019-03-26 10:40:57,422] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8387.4427 2916116750.3315 1039.0000
[2019-03-26 10:40:57,545] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8218.8240 2989288648.2627 1260.0000
[2019-03-26 10:40:57,608] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8628.1610 2832703965.5437 829.0000
[2019-03-26 10:40:58,620] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 475000, evaluation results [475000.0, 8144.558995670145, 3140828092.5246997, 1140.0, 8387.442703376408, 2916116750.3315372, 1039.0, 8743.545482902678, 2771791337.2436833, 743.0, 8218.823950014634, 2989288648.262652, 1260.0, 8628.16101924081, 2832703965.5436954, 829.0]
[2019-03-26 10:41:00,536] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.5368603e-14 1.0000000e+00 8.5342757e-19 1.4764218e-08 1.2831401e-21], sum to 1.0000
[2019-03-26 10:41:00,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5964
[2019-03-26 10:41:00,550] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.95, 95.16666666666667, 1.0, 2.0, 0.5101565507048049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728947.7083333338, 728947.7083333338, 187253.6777058527], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1911000.0000, 
sim time next is 1911600.0000, 
raw observation next is [23.9, 95.0, 1.0, 2.0, 0.4967422336171156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711921.751088679, 711921.7510886797, 185356.2330132807], 
processed observation next is [1.0, 0.13043478260869565, 0.33175355450236965, 0.95, 1.0, 1.0, 0.3936653417073682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19775604196907748, 0.19775604196907767, 0.2766510940496727], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.23137121], dtype=float32), 0.6396661]. 
=============================================
[2019-03-26 10:41:19,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.3379967e-17 1.0000000e+00 3.0703650e-21 4.3297796e-12 5.6788834e-24], sum to 1.0000
[2019-03-26 10:41:19,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1841
[2019-03-26 10:41:19,317] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 80.0, 1.0, 2.0, 0.5704923211440605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 797211.346178428, 797211.346178428, 195377.1786382939], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2416800.0000, 
sim time next is 2417400.0000, 
raw observation next is [29.2, 80.0, 1.0, 2.0, 0.5678562392396902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793526.2844790141, 793526.2844790141, 194910.2265544807], 
processed observation next is [1.0, 1.0, 0.5829383886255924, 0.8, 1.0, 1.0, 0.47934486655384356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22042396791083727, 0.22042396791083727, 0.29091078590221], 
reward next is 0.7091, 
noisyNet noise sample is [array([1.5671642], dtype=float32), -0.58437914]. 
=============================================
[2019-03-26 10:41:30,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1052515e-20 1.0000000e+00 3.5726753e-24 4.1278962e-20 2.2469394e-25], sum to 1.0000
[2019-03-26 10:41:30,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0015
[2019-03-26 10:41:30,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1780616.485294417 W.
[2019-03-26 10:41:30,249] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 80.33333333333334, 1.0, 2.0, 0.6368185533393037, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.980865893930758, 6.9112, 168.9117906526079, 1780616.485294417, 1731193.443551129, 372184.6907090025], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2427600.0000, 
sim time next is 2428200.0000, 
raw observation next is [28.45, 80.5, 1.0, 2.0, 0.5276534786332545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9035412155196284, 6.911200000000001, 6.9112, 168.9128995989828, 1475166.491657958, 1475166.491657957, 321058.7478283998], 
processed observation next is [1.0, 0.08695652173913043, 0.54739336492891, 0.805, 1.0, 1.0, 0.43090780558223435, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8823673359995468, 8.881784197001253e-17, 0.0, 0.8294396656910378, 0.40976846990498833, 0.40976846990498805, 0.47919216093791017], 
reward next is 0.5208, 
noisyNet noise sample is [array([-0.4175944], dtype=float32), -0.220122]. 
=============================================
[2019-03-26 10:41:49,123] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.1310594e-25 1.0000000e+00 8.8627831e-32 1.3237050e-28 3.2783417e-34], sum to 1.0000
[2019-03-26 10:41:49,132] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7536
[2019-03-26 10:41:49,142] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3485187501980508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536884.2071665713, 536884.2071665713, 169560.9453816671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2768400.0000, 
sim time next is 2769000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.348595990499932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537003.0584279208, 537003.0584279202, 169570.6688884929], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.21517589216859279, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.149167516229978, 0.14916751622997784, 0.25309055057984015], 
reward next is 0.7469, 
noisyNet noise sample is [array([0.70610327], dtype=float32), 0.30490997]. 
=============================================
[2019-03-26 10:41:49,157] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.37544 ]
 [75.416626]
 [75.40265 ]
 [75.42791 ]
 [75.45748 ]], R is [[75.26371765]
 [75.25800323]
 [75.25239563]
 [75.24689484]
 [75.24150085]].
[2019-03-26 10:41:50,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8694628e-25 1.0000000e+00 8.9070865e-31 1.1232242e-30 1.2695338e-33], sum to 1.0000
[2019-03-26 10:41:50,131] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1098
[2019-03-26 10:41:50,143] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.34953729368586, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538453.7168682074, 538453.7168682081, 169689.5798246755], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2763600.0000, 
sim time next is 2764200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3498789882288919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538979.1598952005, 538979.1598952012, 169732.6897413997], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21672167256493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14971643330422235, 0.14971643330422255, 0.25333237274835774], 
reward next is 0.7467, 
noisyNet noise sample is [array([-0.19508272], dtype=float32), -1.6058106]. 
=============================================
[2019-03-26 10:41:52,923] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 10:41:52,924] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:41:52,925] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:41:52,928] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:41:52,928] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:41:52,928] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:41:52,929] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:41:52,929] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:41:52,930] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:41:52,930] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:41:52,931] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:41:52,937] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-26 10:41:52,955] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-26 10:41:52,956] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-26 10:41:52,957] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-26 10:41:53,008] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-26 10:41:56,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:41:56,288] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.96699735, 82.59050526666668, 1.0, 2.0, 0.3940431322559855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 597818.9115210066, 597818.9115210073, 174603.3763646067]
[2019-03-26 10:41:56,288] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:41:56,291] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.1800848e-27 1.0000000e+00 2.2253831e-33 2.1554770e-32 7.7239335e-36], sampled 0.005168385976350942
[2019-03-26 10:42:17,318] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:42:17,320] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.08271513, 84.718518195, 1.0, 2.0, 0.4150027712103946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 605952.5903833325, 605952.5903833319, 174705.6667655142]
[2019-03-26 10:42:17,320] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:42:17,322] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4134930e-27 1.0000000e+00 5.5267942e-34 7.4207592e-35 4.1695159e-36], sampled 0.33642447858194524
[2019-03-26 10:42:20,046] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:42:20,048] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.80680149, 81.22476324, 1.0, 2.0, 0.4885874089616066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708615.0410078922, 708615.0410078915, 185108.1356538049]
[2019-03-26 10:42:20,049] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:42:20,051] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.04778924e-26 1.00000000e+00 1.29655989e-33 8.95111489e-34
 1.05316215e-35], sampled 0.46230129361660843
[2019-03-26 10:43:17,284] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:43:17,285] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.715379675, 80.29465205833333, 1.0, 2.0, 0.5570307952223854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778393.1902896506, 778393.1902896506, 193013.437946678]
[2019-03-26 10:43:17,287] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:43:17,291] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.0999437e-27 1.0000000e+00 3.5172279e-34 2.6268475e-33 8.1847471e-37], sampled 0.7481946314116326
[2019-03-26 10:43:24,573] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:43:24,575] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.71666666666667, 88.83333333333334, 1.0, 2.0, 0.5217213575510007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729034.9538810509, 729034.9538810509, 187069.6210340689]
[2019-03-26 10:43:24,576] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:43:24,579] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.9597352e-27 1.0000000e+00 2.8668381e-33 7.5074710e-32 7.6288235e-36], sampled 0.7177447630356634
[2019-03-26 10:43:32,865] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.13943718], dtype=float32), 0.08052626]
[2019-03-26 10:43:32,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.29993867333333, 72.369403795, 1.0, 2.0, 0.2709616943411889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 441998.4712756117, 441998.4712756111, 163001.3622442808]
[2019-03-26 10:43:32,868] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:43:32,871] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.9178422e-27 1.0000000e+00 5.3580607e-34 5.6161177e-35 3.5005994e-36], sampled 0.245665940965219
[2019-03-26 10:43:49,595] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 10:43:49,627] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 10:43:49,688] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4067 2927264152.9822 1338.0000
[2019-03-26 10:43:49,804] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8604 2842435242.9853 1131.0000
[2019-03-26 10:43:49,806] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 10:43:50,821] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 500000, evaluation results [500000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8254.406660643592, 2927264152.9821725, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8496.860364057107, 2842435242.9852624, 1131.0]
[2019-03-26 10:43:52,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0364523e-25 1.0000000e+00 5.6510909e-32 5.9369762e-31 1.5357559e-32], sum to 1.0000
[2019-03-26 10:43:52,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2643
[2019-03-26 10:43:52,676] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3452222761097398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531806.5372556637, 531806.537255663, 169147.2347606855], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2878200.0000, 
sim time next is 2878800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.349769538257583, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538812.3884591636, 538812.3884591636, 169719.0486665015], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21658980512961806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14967010790532323, 0.14967010790532323, 0.2533120129350769], 
reward next is 0.7467, 
noisyNet noise sample is [array([0.77978325], dtype=float32), -0.6015919]. 
=============================================
[2019-03-26 10:44:00,811] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2436944e-24 1.0000000e+00 1.4119378e-30 4.9259342e-28 1.0253235e-32], sum to 1.0000
[2019-03-26 10:44:00,822] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5132
[2019-03-26 10:44:00,832] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5536995296431312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875339.9862590366, 875339.9862590366, 204110.5342874565], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2998800.0000, 
sim time next is 2999400.0000, 
raw observation next is [20.83333333333333, 95.0, 1.0, 2.0, 0.3604358247515858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 570259.3613013607, 570259.3613013614, 172624.7549877047], 
processed observation next is [1.0, 0.7391304347826086, 0.1864139020537123, 0.95, 1.0, 1.0, 0.229440752712754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15840537813926686, 0.15840537813926703, 0.25764888804135033], 
reward next is 0.7424, 
noisyNet noise sample is [array([0.34643576], dtype=float32), 0.32811746]. 
=============================================
[2019-03-26 10:44:03,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.7408189e-25 1.0000000e+00 5.6481598e-32 9.9684744e-29 9.0149595e-33], sum to 1.0000
[2019-03-26 10:44:03,152] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1052
[2019-03-26 10:44:03,156] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3899718470832311, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581896.8657064831, 581896.8657064831, 172879.0009968217], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3112800.0000, 
sim time next is 3113400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3910076932743205, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 583443.9995722255, 583443.9995722261, 173019.3381872587], 
processed observation next is [1.0, 0.0, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2662743292461693, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16206777765895153, 0.1620677776589517, 0.25823781818993835], 
reward next is 0.7418, 
noisyNet noise sample is [array([1.048482], dtype=float32), 2.060211]. 
=============================================
[2019-03-26 10:44:04,713] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1202115e-23 1.0000000e+00 9.6513887e-29 2.4434612e-26 1.0628147e-30], sum to 1.0000
[2019-03-26 10:44:04,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5978
[2019-03-26 10:44:04,730] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.7835795559862044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1168877.876111318, 1168877.876111319, 249875.5060570021], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3066600.0000, 
sim time next is 3067200.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.7623258149977394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1137172.003097404, 1137172.003097404, 244461.0870257267], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 1.0, 1.0, 0.7136455602382402, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3158811119715011, 0.3158811119715011, 0.3648672940682488], 
reward next is 0.6351, 
noisyNet noise sample is [array([-0.4608379], dtype=float32), 0.42296985]. 
=============================================
[2019-03-26 10:44:05,005] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.2686663e-23 1.0000000e+00 9.9330962e-29 9.1101941e-27 4.6044151e-30], sum to 1.0000
[2019-03-26 10:44:05,012] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7674
[2019-03-26 10:44:05,019] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.66666666666667, 89.0, 1.0, 2.0, 0.7330855957331389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1094865.145498275, 1094865.145498275, 237409.9708477152], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3145200.0000, 
sim time next is 3145800.0000, 
raw observation next is [23.83333333333333, 89.0, 1.0, 2.0, 0.7652901427489769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1136342.606158289, 1136342.60615829, 244539.8227294159], 
processed observation next is [1.0, 0.391304347826087, 0.32859399684044216, 0.89, 1.0, 1.0, 0.7172170394565986, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.31565072393285803, 0.31565072393285837, 0.3649848100439043], 
reward next is 0.6350, 
noisyNet noise sample is [array([0.6060219], dtype=float32), -1.2049392]. 
=============================================
[2019-03-26 10:44:10,336] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9644236e-24 1.0000000e+00 4.3723488e-29 5.8656269e-27 1.6975495e-31], sum to 1.0000
[2019-03-26 10:44:10,350] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5583
[2019-03-26 10:44:10,355] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4894258108128207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683891.7731756506, 683891.77317565, 181955.7322039544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3194400.0000, 
sim time next is 3195000.0000, 
raw observation next is [25.0, 94.0, 1.0, 2.0, 0.4874377884848182, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681112.9495931175, 681112.9495931175, 181651.1779037188], 
processed observation next is [1.0, 1.0, 0.38388625592417064, 0.94, 1.0, 1.0, 0.3824551668491786, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18919804155364373, 0.18919804155364373, 0.2711211610503266], 
reward next is 0.7289, 
noisyNet noise sample is [array([0.57105035], dtype=float32), 1.4477603]. 
=============================================
[2019-03-26 10:44:10,374] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[70.20448]
 [70.18692]
 [70.15402]
 [70.07807]
 [70.04594]], R is [[70.26019287]
 [70.28601837]
 [70.31100464]
 [70.33512878]
 [70.358078  ]].
[2019-03-26 10:44:12,052] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2877014e-24 1.0000000e+00 1.1167557e-30 1.8873017e-28 3.3832998e-33], sum to 1.0000
[2019-03-26 10:44:12,060] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1310
[2019-03-26 10:44:12,067] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 94.0, 1.0, 2.0, 0.4865236335153158, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679835.1618634638, 679835.1618634638, 181511.5270902766], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3196800.0000, 
sim time next is 3197400.0000, 
raw observation next is [25.0, 94.00000000000001, 1.0, 2.0, 0.4865847357625614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 679920.5693278117, 679920.5693278117, 181520.8536546495], 
processed observation next is [0.0, 0.0, 0.38388625592417064, 0.9400000000000002, 1.0, 1.0, 0.3814273924850138, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18886682481328104, 0.18886682481328104, 0.2709266472457455], 
reward next is 0.7291, 
noisyNet noise sample is [array([1.7269485], dtype=float32), 0.34377763]. 
=============================================
[2019-03-26 10:44:14,582] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4178129e-26 1.0000000e+00 4.3942106e-33 7.3528009e-33 4.9966958e-36], sum to 1.0000
[2019-03-26 10:44:14,593] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8244
[2019-03-26 10:44:14,598] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 68.0, 1.0, 2.0, 0.5512106582084421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 770257.1991235091, 770257.1991235097, 192009.8246502815], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3238800.0000, 
sim time next is 3239400.0000, 
raw observation next is [31.66666666666667, 67.5, 1.0, 2.0, 0.558430229368891, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780349.4737786412, 780349.4737786412, 193258.3575492141], 
processed observation next is [0.0, 0.4782608695652174, 0.6998420221169038, 0.675, 1.0, 1.0, 0.4679882281552903, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21676374271628923, 0.21676374271628923, 0.2884453097749464], 
reward next is 0.7116, 
noisyNet noise sample is [array([1.1462989], dtype=float32), 0.10501511]. 
=============================================
[2019-03-26 10:44:15,843] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.5423986e-25 1.0000000e+00 9.9194114e-32 2.8041079e-31 4.5081351e-35], sum to 1.0000
[2019-03-26 10:44:15,851] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7535
[2019-03-26 10:44:15,858] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4777145889650721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667649.3665650703, 667649.3665650703, 180194.0888419972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3288600.0000, 
sim time next is 3289200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4781172354825432, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668212.2365948637, 668212.2365948637, 180254.5258241533], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37122558491872676, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18561451016523992, 0.18561451016523992, 0.2690366057076915], 
reward next is 0.7310, 
noisyNet noise sample is [array([-1.7156932], dtype=float32), -0.11569723]. 
=============================================
[2019-03-26 10:44:16,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.2000832e-26 1.0000000e+00 2.1143345e-32 2.1113776e-31 8.0540869e-34], sum to 1.0000
[2019-03-26 10:44:16,072] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5862
[2019-03-26 10:44:16,078] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.66666666666667, 75.66666666666667, 1.0, 2.0, 0.6046156823311563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844914.6186266005, 844914.6186266005, 201608.1970021895], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3262200.0000, 
sim time next is 3262800.0000, 
raw observation next is [30.33333333333334, 76.33333333333334, 1.0, 2.0, 0.5863564233374999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819388.542952429, 819388.542952429, 198231.5427192179], 
processed observation next is [0.0, 0.782608695652174, 0.6366508688783573, 0.7633333333333334, 1.0, 1.0, 0.5016342449849397, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22760792859789694, 0.22760792859789694, 0.2958679742077879], 
reward next is 0.7041, 
noisyNet noise sample is [array([-0.3624345], dtype=float32), -0.22592114]. 
=============================================
[2019-03-26 10:44:25,251] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2397970e-19 1.0000000e+00 1.8739781e-22 2.3779164e-18 3.3363681e-24], sum to 1.0000
[2019-03-26 10:44:25,259] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2187
[2019-03-26 10:44:25,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2700419.654935238 W.
[2019-03-26 10:44:25,273] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.33333333333334, 65.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.49809657402252, 6.9112, 168.9102063940769, 2700419.654935238, 2284061.804844731, 474815.2095027713], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3417600.0000, 
sim time next is 3418200.0000, 
raw observation next is [33.5, 65.0, 1.0, 2.0, 0.9933863803080571, 1.0, 1.0, 0.9933863803080571, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2778786.28110546, 2778786.281105459, 525008.7511149652], 
processed observation next is [1.0, 0.5652173913043478, 0.7867298578199052, 0.65, 1.0, 1.0, 0.9920317835036833, 1.0, 0.5, 0.9920317835036833, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7718850780848501, 0.7718850780848497, 0.7835951509178585], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7562344], dtype=float32), -0.47341278]. 
=============================================
[2019-03-26 10:44:27,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.3516713e-21 1.0000000e+00 8.5470210e-25 1.8191292e-23 1.2646998e-26], sum to 1.0000
[2019-03-26 10:44:27,112] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9811
[2019-03-26 10:44:27,117] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5074331952403807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709062.5180404293, 709062.5180404286, 184768.9709951507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3460200.0000, 
sim time next is 3460800.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5068390298243134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708231.9833506766, 708231.983350676, 184674.5551597565], 
processed observation next is [1.0, 0.043478260869565216, 0.4628751974723541, 0.8566666666666667, 1.0, 1.0, 0.4058301564148354, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19673110648629905, 0.1967311064862989, 0.275633664417547], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.21118106], dtype=float32), -0.8103805]. 
=============================================
[2019-03-26 10:44:31,738] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0825674e-24 1.0000000e+00 1.2308396e-27 2.1597776e-28 6.1343949e-30], sum to 1.0000
[2019-03-26 10:44:31,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-26 10:44:31,752] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 79.0, 1.0, 2.0, 0.5439594202376532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 760120.7537965934, 760120.7537965934, 190770.0499095085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3532800.0000, 
sim time next is 3533400.0000, 
raw observation next is [28.5, 79.0, 1.0, 2.0, 0.5393362461112337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 753658.1075837769, 753658.1075837775, 189988.5131985938], 
processed observation next is [1.0, 0.9130434782608695, 0.5497630331753555, 0.79, 1.0, 1.0, 0.4449834290496791, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20934947432882692, 0.20934947432882708, 0.28356494507252805], 
reward next is 0.7164, 
noisyNet noise sample is [array([-1.8724823], dtype=float32), 1.4875933]. 
=============================================
[2019-03-26 10:44:37,536] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0117797e-23 1.0000000e+00 2.3845810e-28 2.7650046e-26 2.7635543e-30], sum to 1.0000
[2019-03-26 10:44:37,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1619
[2019-03-26 10:44:37,554] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5175930420140444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 723264.2279768497, 723264.2279768491, 186398.500747907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3804600.0000, 
sim time next is 3805200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5173818242852076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722968.9801625565, 722968.9801625558, 186364.3259060515], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.79, 1.0, 1.0, 0.41853231841591276, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20082471671182126, 0.20082471671182106, 0.27815571030753955], 
reward next is 0.7218, 
noisyNet noise sample is [array([-0.59802353], dtype=float32), 1.0593865]. 
=============================================
[2019-03-26 10:44:45,378] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 10:44:45,380] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:44:45,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:44:45,381] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:44:45,384] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:44:45,384] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:44:45,385] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:44:45,388] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:44:45,387] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:44:45,389] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:44:45,391] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:44:45,412] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-26 10:44:45,413] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-26 10:44:45,432] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-26 10:44:45,468] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-26 10:44:45,486] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-26 10:45:17,429] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.15163061], dtype=float32), 0.07056583]
[2019-03-26 10:45:17,430] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.58333333333333, 92.83333333333334, 1.0, 2.0, 0.5880963522836973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821820.902071321, 821820.902071321, 198543.1472285961]
[2019-03-26 10:45:17,431] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:45:17,435] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.20781830e-24 1.00000000e+00 1.10404476e-29 3.91457975e-30
 2.23311652e-30], sampled 0.12165568414763706
[2019-03-26 10:45:46,031] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.15163061], dtype=float32), 0.07056583]
[2019-03-26 10:45:46,032] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.66666666666666, 57.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.559063070620507, 6.9112, 168.9093059451776, 1913676.16867607, 1454069.741930781, 311355.4270407825]
[2019-03-26 10:45:46,033] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:45:46,034] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.4089204e-21 1.0000000e+00 1.7845131e-26 1.0817846e-25 5.3330999e-27], sampled 0.21694002455671857
[2019-03-26 10:45:46,037] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1913676.16867607 W.
[2019-03-26 10:46:39,716] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.15163061], dtype=float32), 0.07056583]
[2019-03-26 10:46:39,717] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.88333333333333, 65.66666666666667, 1.0, 2.0, 0.363829308957377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563418.9754534446, 563418.9754534453, 171853.6923942061]
[2019-03-26 10:46:39,719] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:46:39,722] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0495433e-25 1.0000000e+00 7.5024643e-31 6.0663913e-32 5.3097215e-32], sampled 0.5929669208020014
[2019-03-26 10:46:39,920] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1249 2927277438.0038 1338.0000
[2019-03-26 10:46:40,412] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0142 3007608811.4011 1766.0000
[2019-03-26 10:46:40,431] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4308 2779149198.4617 933.0000
[2019-03-26 10:46:40,496] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 10:46:40,557] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 10:46:41,572] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 525000, evaluation results [525000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8255.124881931173, 2927277438.00382, 1338.0, 8661.430759135581, 2779149198.4616733, 933.0, 7999.014205657292, 3007608811.4011106, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 10:46:42,371] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1262199e-21 1.0000000e+00 1.3374922e-26 5.6791705e-22 8.5241178e-28], sum to 1.0000
[2019-03-26 10:46:42,381] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9808
[2019-03-26 10:46:42,386] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.5505327310880919, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564992208, 769309.5263341863, 769309.5263341863, 191894.9611561643], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3777600.0000, 
sim time next is 3778200.0000, 
raw observation next is [32.5, 65.0, 1.0, 2.0, 0.5456487670270438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104282, 762482.2689981981, 762482.2689981981, 191060.3997378009], 
processed observation next is [1.0, 0.7391304347826086, 0.7393364928909952, 0.65, 1.0, 1.0, 0.4525888759361973, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451522889, 0.21180063027727725, 0.21180063027727725, 0.28516477572806104], 
reward next is 0.7148, 
noisyNet noise sample is [array([0.20736355], dtype=float32), -0.17478752]. 
=============================================
[2019-03-26 10:46:53,826] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7121337e-21 1.0000000e+00 4.6385730e-26 1.6981247e-25 3.6576741e-26], sum to 1.0000
[2019-03-26 10:46:53,835] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5351
[2019-03-26 10:46:53,840] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.929289861679488, 6.9112, 168.9126525651582, 1466597.264269796, 1453763.716882355, 311355.5335554229], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3998400.0000, 
sim time next is 3999000.0000, 
raw observation next is [29.83333333333333, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.011999370684645, 6.9112, 168.9122115008688, 1525314.127889714, 1453803.90048471, 311355.9980509268], 
processed observation next is [1.0, 0.2608695652173913, 0.6129541864139019, 0.84, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.010079937068464506, 0.0, 0.8294362868142855, 0.4236983688582539, 0.4038344168013083, 0.46471044485212953], 
reward next is 0.0313, 
noisyNet noise sample is [array([-1.2714868], dtype=float32), -1.9220334]. 
=============================================
[2019-03-26 10:46:53,857] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[46.659748]
 [47.112812]
 [47.229275]
 [47.29141 ]
 [48.068855]], R is [[45.8569603 ]
 [45.8432312 ]
 [45.93717575]
 [46.05119705]
 [46.15190887]].
[2019-03-26 10:46:55,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6452643e-13 1.0000000e+00 1.4083014e-15 3.6790582e-10 1.2771716e-15], sum to 1.0000
[2019-03-26 10:46:55,181] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1853
[2019-03-26 10:46:55,188] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2021194.113452649 W.
[2019-03-26 10:46:55,191] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.7227833499516411, 1.0, 1.0, 0.7227833499516411, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2021194.113452649, 2021194.113452649, 384038.535526401], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3984600.0000, 
sim time next is 3985200.0000, 
raw observation next is [30.0, 79.0, 1.0, 2.0, 0.5027274429099693, 1.0, 2.0, 0.5027274429099693, 1.0, 1.0, 0.8730713138287286, 6.911200000000001, 6.9112, 170.5573041426782, 2108829.578382466, 2108829.578382466, 417037.7832755385], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.79, 1.0, 1.0, 0.4008764372409268, 1.0, 1.0, 0.4008764372409268, 1.0, 0.5, 0.8452089193033274, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5857859939951294, 0.5857859939951294, 0.6224444526500574], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23407824], dtype=float32), -2.6354005]. 
=============================================
[2019-03-26 10:47:02,556] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.0502134e-17 1.0000000e+00 3.0790577e-20 7.8437101e-14 9.5971183e-23], sum to 1.0000
[2019-03-26 10:47:02,564] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2564
[2019-03-26 10:47:02,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3167785.248012776 W.
[2019-03-26 10:47:02,579] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.83333333333334, 67.0, 1.0, 2.0, 0.8685175621061992, 1.0, 2.0, 0.754848820567362, 1.0, 2.0, 1.03, 7.005111023372939, 6.9112, 170.5573041426782, 3167785.248012776, 3100512.961914549, 579842.4557347622], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4119000.0000, 
sim time next is 4119600.0000, 
raw observation next is [34.66666666666667, 67.0, 1.0, 2.0, 0.877949633696182, 1.0, 2.0, 0.7595648563623537, 1.0, 2.0, 1.03, 7.005111767516233, 6.9112, 170.5573041426782, 3187601.7387551, 3120328.919596761, 583430.0072459548], 
processed observation next is [1.0, 0.6956521739130435, 0.8420221169036337, 0.67, 1.0, 1.0, 0.8529513658990144, 1.0, 1.0, 0.7103191040510286, 1.0, 1.0, 1.0365853658536586, 0.00939117675162331, 0.0, 0.8375144448122397, 0.8854449274319722, 0.8667580332213225, 0.8707910555909774], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.648857], dtype=float32), 0.20090888]. 
=============================================
[2019-03-26 10:47:03,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.7722314e-24 1.0000000e+00 1.7173198e-28 2.3240445e-27 1.4053773e-29], sum to 1.0000
[2019-03-26 10:47:03,626] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1111
[2019-03-26 10:47:03,634] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5812969940711078, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812315.6714570721, 812315.6714570721, 197313.3088154392], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4146600.0000, 
sim time next is 4147200.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5809453277480887, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 811824.0583276125, 811824.058327613, 197249.7826141115], 
processed observation next is [1.0, 0.0, 0.5734597156398105, 0.84, 1.0, 1.0, 0.4951148527085406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22550668286878123, 0.2255066828687814, 0.29440266061807685], 
reward next is 0.7056, 
noisyNet noise sample is [array([0.89177185], dtype=float32), 1.1454161]. 
=============================================
[2019-03-26 10:47:10,167] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2756558e-25 1.0000000e+00 4.5122194e-32 2.0240731e-31 3.1093871e-31], sum to 1.0000
[2019-03-26 10:47:10,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3067
[2019-03-26 10:47:10,180] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 75.0, 1.0, 2.0, 0.6159248780729145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 860724.9537543136, 860724.9537543142, 203751.033751722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4311600.0000, 
sim time next is 4312200.0000, 
raw observation next is [31.33333333333334, 77.0, 1.0, 2.0, 0.6179284919022626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 863526.0445108453, 863526.0445108453, 204134.2642666469], 
processed observation next is [1.0, 0.9130434782608695, 0.6840442338072673, 0.77, 1.0, 1.0, 0.539672881809955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23986834569745705, 0.23986834569745705, 0.3046780063681297], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.05186613], dtype=float32), -0.3158476]. 
=============================================
[2019-03-26 10:47:15,750] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8138098e-13 1.0000000e+00 1.9521700e-15 5.9163106e-09 9.3987549e-16], sum to 1.0000
[2019-03-26 10:47:15,759] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2812
[2019-03-26 10:47:15,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2998739.888846753 W.
[2019-03-26 10:47:15,770] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.66666666666667, 67.33333333333334, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.035869888216632, 6.9112, 170.5573041426782, 2998739.888846753, 2909433.776670363, 553012.2350489955], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4357200.0000, 
sim time next is 4357800.0000, 
raw observation next is [35.0, 65.5, 1.0, 2.0, 0.7811856049231971, 1.0, 2.0, 0.7111828419758611, 1.0, 1.0, 1.03, 7.005104134438813, 6.9112, 170.5573041426782, 2984318.438709978, 2917051.087435488, 548199.5965816134], 
processed observation next is [1.0, 0.43478260869565216, 0.8578199052132701, 0.655, 1.0, 1.0, 0.7363681987026471, 1.0, 1.0, 0.6520275204528447, 1.0, 0.5, 1.0365853658536586, 0.009390413443881317, 0.0, 0.8375144448122397, 0.828977344086105, 0.81029196873208, 0.8182083531068857], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.93193495], dtype=float32), -1.4782103]. 
=============================================
[2019-03-26 10:47:16,546] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1928365e-18 1.0000000e+00 1.7377027e-20 8.3052904e-17 1.1612520e-21], sum to 1.0000
[2019-03-26 10:47:16,558] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5682
[2019-03-26 10:47:16,568] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3083035.289709841 W.
[2019-03-26 10:47:16,574] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.83333333333334, 71.5, 1.0, 2.0, 0.8281773651325062, 1.0, 2.0, 0.7346787220805157, 1.0, 2.0, 1.03, 7.005107840999369, 6.9112, 170.5573041426782, 3083035.289709841, 3015765.283275252, 564871.5385370032], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4369800.0000, 
sim time next is 4370400.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.7872289024537144, 1.0, 2.0, 0.7142044907411198, 1.0, 2.0, 1.03, 7.005104611082088, 6.9112, 170.5573041426782, 2997013.318743472, 2929745.626030015, 550296.4921463481], 
processed observation next is [1.0, 0.6086956521739131, 0.7156398104265403, 0.75, 1.0, 1.0, 0.7436492800647161, 1.0, 1.0, 0.6556680611338792, 1.0, 1.0, 1.0365853658536586, 0.009390461108208825, 0.0, 0.8375144448122397, 0.8325036996509645, 0.8138182294527819, 0.8213380479796241], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2055141], dtype=float32), -1.2120339]. 
=============================================
[2019-03-26 10:47:21,276] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.8254743e-30 1.0000000e+00 8.3324615e-38 0.0000000e+00 2.2015074e-38], sum to 1.0000
[2019-03-26 10:47:21,285] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2448
[2019-03-26 10:47:21,291] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 86.5, 1.0, 2.0, 0.4916380989483277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 686984.0802107382, 686984.0802107382, 182295.9628613867], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4509000.0000, 
sim time next is 4509600.0000, 
raw observation next is [26.0, 87.33333333333333, 1.0, 2.0, 0.4945839006506602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691101.6967614151, 691101.6967614151, 182751.5949901478], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.8733333333333333, 1.0, 1.0, 0.39106494054296415, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19197269354483754, 0.19197269354483754, 0.2727635746121609], 
reward next is 0.7272, 
noisyNet noise sample is [array([1.4868511], dtype=float32), 0.44433847]. 
=============================================
[2019-03-26 10:47:25,983] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9204878e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 10:47:25,993] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3661
[2019-03-26 10:47:25,996] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 50.5, 1.0, 2.0, 0.5416952461503156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 756955.7034645606, 756955.7034645611, 190385.9096379447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4543800.0000, 
sim time next is 4544400.0000, 
raw observation next is [34.0, 51.0, 1.0, 2.0, 0.5252597767891714, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733981.1239060323, 733981.1239060316, 187649.1260269228], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.51, 1.0, 1.0, 0.42802382745683293, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20388364552945343, 0.20388364552945323, 0.280073322428243], 
reward next is 0.7199, 
noisyNet noise sample is [array([0.7418842], dtype=float32), -1.2748859]. 
=============================================
[2019-03-26 10:47:28,490] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.51077122e-29 1.00000000e+00 1.36624995e-36 0.00000000e+00
 1.06373721e-34], sum to 1.0000
[2019-03-26 10:47:28,498] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4633
[2019-03-26 10:47:28,505] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 70.0, 1.0, 2.0, 0.4826137343085554, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 676107.6275046763, 676107.627504677, 181140.1339086928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4651200.0000, 
sim time next is 4651800.0000, 
raw observation next is [27.33333333333334, 74.0, 1.0, 2.0, 0.4745648029814758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669080.7530330656, 669080.753033065, 180474.7162654271], 
processed observation next is [1.0, 0.8695652173913043, 0.4944707740916275, 0.74, 1.0, 1.0, 0.36694554576081423, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1858557647314071, 0.18585576473140694, 0.26936524815735385], 
reward next is 0.7306, 
noisyNet noise sample is [array([0.2232548], dtype=float32), -0.48411006]. 
=============================================
[2019-03-26 10:47:33,736] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.1826292e-24 1.0000000e+00 8.2369622e-29 2.4225379e-29 3.8392347e-28], sum to 1.0000
[2019-03-26 10:47:33,742] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9797
[2019-03-26 10:47:33,745] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 90.66666666666666, 1.0, 2.0, 0.799100635436932, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1116838.735228593, 1116838.735228593, 243690.8703408965], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4678800.0000, 
sim time next is 4679400.0000, 
raw observation next is [27.0, 89.83333333333333, 1.0, 2.0, 0.7809152526721664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1091409.425548674, 1091409.425548674, 239280.5506307053], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.8983333333333333, 1.0, 1.0, 0.7360424730989957, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3031692848746317, 0.3031692848746317, 0.3571351501950825], 
reward next is 0.6429, 
noisyNet noise sample is [array([-1.1410748], dtype=float32), 0.31946388]. 
=============================================
[2019-03-26 10:47:34,582] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3270734e-19 1.0000000e+00 4.1695278e-23 5.1620578e-21 1.4159118e-24], sum to 1.0000
[2019-03-26 10:47:34,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1642
[2019-03-26 10:47:34,598] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2439551.001205715 W.
[2019-03-26 10:47:34,603] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.581487784482626, 1.0, 1.0, 0.581487784482626, 1.0, 2.0, 1.009111656077061, 6.911199999999999, 6.9112, 170.5573041426782, 2439551.001205715, 2439551.001205716, 475910.8430540046], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4716000.0000, 
sim time next is 4716600.0000, 
raw observation next is [30.83333333333334, 67.5, 1.0, 2.0, 0.5174382959568494, 1.0, 2.0, 0.5174382959568494, 1.0, 2.0, 0.8980477937464415, 6.9112, 6.9112, 170.5573041426782, 2170600.85074332, 2170600.85074332, 427307.1696159717], 
processed observation next is [1.0, 0.6086956521739131, 0.6603475513428123, 0.675, 1.0, 1.0, 0.41860035657451733, 1.0, 1.0, 0.41860035657451733, 1.0, 1.0, 0.8756680411541969, 0.0, 0.0, 0.8375144448122397, 0.6029446807620333, 0.6029446807620333, 0.6377718949492115], 
reward next is 0.3622, 
noisyNet noise sample is [array([0.6330921], dtype=float32), 0.5298934]. 
=============================================
[2019-03-26 10:47:35,715] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 10:47:35,719] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:47:35,720] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:47:35,721] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:47:35,721] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:47:35,722] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:47:35,723] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:47:35,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:47:35,723] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:47:35,724] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:47:35,727] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:47:35,744] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-26 10:47:35,744] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-26 10:47:35,762] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-26 10:47:35,803] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-26 10:47:35,819] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-26 10:47:50,818] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.18493603], dtype=float32), 0.07465299]
[2019-03-26 10:47:50,821] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.93460414, 94.739570205, 1.0, 2.0, 0.3148523964251181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499547.5251956959, 499547.5251956959, 167021.6965814944]
[2019-03-26 10:47:50,823] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:47:50,824] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5468697e-28 1.0000000e+00 8.1289062e-34 9.6647282e-36 1.6968153e-34], sampled 0.19801840173943386
[2019-03-26 10:48:11,330] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.18493603], dtype=float32), 0.07465299]
[2019-03-26 10:48:11,332] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.13333333333334, 72.0, 1.0, 2.0, 0.5562586931709723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 801144.7430608455, 801144.7430608461, 195915.4579400001]
[2019-03-26 10:48:11,333] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:48:11,337] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.8769284e-28 1.0000000e+00 7.5257568e-34 2.3793284e-36 2.4909122e-34], sampled 0.6644771915603723
[2019-03-26 10:48:47,897] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.18493603], dtype=float32), 0.07465299]
[2019-03-26 10:48:47,899] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.83333333333334, 57.33333333333334, 1.0, 2.0, 1.019513650909367, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005994405708183, 6.9112, 168.9123159123477, 2322315.233830021, 2255065.074894465, 469370.9050073535]
[2019-03-26 10:48:47,901] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:48:47,903] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.8111925e-24 1.0000000e+00 3.5255402e-28 6.6621904e-26 9.3274676e-30], sampled 0.283417606638963
[2019-03-26 10:48:47,904] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2322315.233830021 W.
[2019-03-26 10:49:05,760] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.18493603], dtype=float32), 0.07465299]
[2019-03-26 10:49:05,762] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.36666666666667, 85.66666666666666, 1.0, 2.0, 0.5305047447765191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 741312.8309831853, 741312.8309831853, 188513.7156267586]
[2019-03-26 10:49:05,764] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:49:05,767] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2880450e-30 1.0000000e+00 6.0171693e-37 0.0000000e+00 5.7046834e-37], sampled 0.05680081292685801
[2019-03-26 10:49:23,499] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.18493603], dtype=float32), 0.07465299]
[2019-03-26 10:49:23,500] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.1, 85.66666666666667, 1.0, 2.0, 0.5283695618193539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738328.1477462455, 738328.1477462455, 188159.9839787244]
[2019-03-26 10:49:23,502] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:49:23,506] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.33140886e-28 1.00000000e+00 1.18203625e-33 1.68203699e-35
 3.03884851e-34], sampled 0.7072550632547921
[2019-03-26 10:49:30,001] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.6842 2927263131.0635 1338.0000
[2019-03-26 10:49:30,710] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.0502 3007584666.7691 1766.0000
[2019-03-26 10:49:30,723] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 10:49:30,763] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.9164 3164002230.9074 1778.0000
[2019-03-26 10:49:30,789] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.8724 2842497929.8887 1131.0000
[2019-03-26 10:49:31,804] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 550000, evaluation results [550000.0, 7884.916440885027, 3164002230.907359, 1778.0, 8253.684238692544, 2927263131.0635424, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7999.050242421542, 3007584666.769063, 1766.0, 8496.87235025343, 2842497929.888741, 1131.0]
[2019-03-26 10:49:32,904] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.1487192e-17 1.0000000e+00 7.7453620e-19 2.0608722e-15 1.5051650e-20], sum to 1.0000
[2019-03-26 10:49:32,916] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3169
[2019-03-26 10:49:32,923] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2432887.309521175 W.
[2019-03-26 10:49:32,927] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333333, 69.0, 1.0, 2.0, 0.5799009814689692, 1.0, 2.0, 0.5799009814689692, 1.0, 2.0, 1.007096228626516, 6.9112, 6.9112, 170.5573041426782, 2432887.309521175, 2432887.309521175, 474795.4937769806], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4725600.0000, 
sim time next is 4726200.0000, 
raw observation next is [31.16666666666667, 69.5, 1.0, 2.0, 0.8571565572659775, 1.0, 2.0, 0.8571565572659775, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2397346.846583342, 2397346.846583342, 448658.2064993693], 
processed observation next is [1.0, 0.6956521739130435, 0.6761453396524489, 0.695, 1.0, 1.0, 0.827899466585515, 1.0, 1.0, 0.827899466585515, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.665929679606484, 0.665929679606484, 0.6696391141781631], 
reward next is 0.3304, 
noisyNet noise sample is [array([1.2437896], dtype=float32), 0.4767595]. 
=============================================
[2019-03-26 10:49:34,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9004973e-28 1.0000000e+00 2.6588463e-33 3.3938476e-33 1.6407943e-33], sum to 1.0000
[2019-03-26 10:49:34,126] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5320
[2019-03-26 10:49:34,131] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 75.66666666666667, 1.0, 2.0, 0.4905067062660677, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 685402.6333898423, 685402.6333898423, 182121.8009545039], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4753200.0000, 
sim time next is 4753800.0000, 
raw observation next is [27.5, 76.5, 1.0, 2.0, 0.4897629725854023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 684363.0528513591, 684363.0528513585, 182007.4195761309], 
processed observation next is [1.0, 0.0, 0.5023696682464456, 0.765, 1.0, 1.0, 0.38525659347638835, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1901008480142664, 0.19010084801426627, 0.2716528650390013], 
reward next is 0.7283, 
noisyNet noise sample is [array([0.44832698], dtype=float32), 1.7781447]. 
=============================================
[2019-03-26 10:49:35,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9057809e-28 1.0000000e+00 3.4300156e-34 1.6326760e-35 5.6114548e-33], sum to 1.0000
[2019-03-26 10:49:35,681] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9280
[2019-03-26 10:49:35,686] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6210682999260925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 867915.5715122559, 867915.5715122552, 204727.0840123425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4768200.0000, 
sim time next is 4768800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6307489154912073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 881449.4186900445, 881449.4186900451, 206604.2197345603], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5551191752906112, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24484706074723459, 0.24484706074723475, 0.3083645070665079], 
reward next is 0.6916, 
noisyNet noise sample is [array([0.35340765], dtype=float32), -1.439018]. 
=============================================
[2019-03-26 10:49:36,856] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.5765828e-18 1.0000000e+00 6.2499513e-21 5.3375232e-17 5.8100540e-23], sum to 1.0000
[2019-03-26 10:49:36,865] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6566
[2019-03-26 10:49:36,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2188101.26327327 W.
[2019-03-26 10:49:36,876] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 65.5, 1.0, 2.0, 0.7824088079046113, 1.0, 2.0, 0.7824088079046113, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2188101.26327327, 2188101.26327327, 411396.7516086947], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4795800.0000, 
sim time next is 4796400.0000, 
raw observation next is [31.33333333333334, 65.0, 1.0, 2.0, 0.4070361835676181, 1.0, 2.0, 0.4070361835676181, 1.0, 1.0, 0.7031675640265542, 6.9112, 6.9112, 170.5573041426782, 1707106.288058611, 1707106.288058611, 356287.964805691], 
processed observation next is [1.0, 0.5217391304347826, 0.6840442338072673, 0.65, 1.0, 1.0, 0.28558576333447966, 1.0, 1.0, 0.28558576333447966, 1.0, 0.5, 0.6380092244226271, 0.0, 0.0, 0.8375144448122397, 0.474196191127392, 0.474196191127392, 0.5317730817995387], 
reward next is 0.4682, 
noisyNet noise sample is [array([-1.4470266], dtype=float32), 0.57846516]. 
=============================================
[2019-03-26 10:49:39,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.6678632e-30 1.0000000e+00 1.0076247e-36 0.0000000e+00 1.1527684e-37], sum to 1.0000
[2019-03-26 10:49:39,625] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1080
[2019-03-26 10:49:39,634] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.4935206361137114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 689615.4727992949, 689615.4727992954, 182586.8451089793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4828200.0000, 
sim time next is 4828800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4922288899963707, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 687809.8816305388, 687809.8816305388, 182387.2570110616], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.74, 1.0, 1.0, 0.38822757830888033, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19105830045292746, 0.19105830045292746, 0.272219786583674], 
reward next is 0.7278, 
noisyNet noise sample is [array([0.17655703], dtype=float32), 1.336444]. 
=============================================
[2019-03-26 10:49:44,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0146472e-27 1.0000000e+00 9.1758460e-32 4.4949857e-33 4.2083547e-32], sum to 1.0000
[2019-03-26 10:49:44,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2948
[2019-03-26 10:49:44,605] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5096187058562838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712117.4681467947, 712117.4681467941, 185116.8829735978], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4924800.0000, 
sim time next is 4925400.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5095729359178413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712053.4899285479, 712053.4899285479, 185109.5844097558], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 1.0, 1.0, 0.40912401917812197, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1977926360912633, 0.1977926360912633, 0.2762829618056057], 
reward next is 0.7237, 
noisyNet noise sample is [array([0.5380444], dtype=float32), 1.2655599]. 
=============================================
[2019-03-26 10:49:48,836] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6575018e-30 1.0000000e+00 4.7747400e-37 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 10:49:48,848] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1859
[2019-03-26 10:49:48,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 59.0, 1.0, 2.0, 0.5230332995882274, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730868.8459204002, 730868.8459204008, 187284.1077407033], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5065200.0000, 
sim time next is 5065800.0000, 
raw observation next is [31.83333333333334, 59.66666666666667, 1.0, 2.0, 0.5228005374421864, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730543.4802124075, 730543.4802124068, 187246.0124310103], 
processed observation next is [0.0, 0.6521739130434783, 0.7077409162717223, 0.5966666666666667, 1.0, 1.0, 0.42506088848456186, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20292874450344653, 0.20292874450344633, 0.27947166034479154], 
reward next is 0.7205, 
noisyNet noise sample is [array([0.10380265], dtype=float32), -0.24892737]. 
=============================================
[2019-03-26 10:49:58,673] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5005221e-27 1.0000000e+00 1.3411418e-31 1.0049967e-33 1.6216856e-32], sum to 1.0000
[2019-03-26 10:49:58,682] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4104
[2019-03-26 10:49:58,687] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5159126785277046, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720915.3571234473, 720915.3571234473, 186126.441042029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5189400.0000, 
sim time next is 5190000.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5163661980249745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721549.3020272445, 721549.3020272438, 186199.6390236945], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4173086723192464, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2004303616742346, 0.2004303616742344, 0.2779099089905888], 
reward next is 0.7221, 
noisyNet noise sample is [array([1.5882419], dtype=float32), -0.7967047]. 
=============================================
[2019-03-26 10:49:58,705] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[65.39277 ]
 [65.79434 ]
 [66.06514 ]
 [66.43895 ]
 [66.779236]], R is [[65.23435211]
 [65.30420685]
 [65.3734436 ]
 [65.44195557]
 [65.50967407]].
[2019-03-26 10:50:07,317] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.01835536e-14 1.00000000e+00 4.92908483e-16 1.67392905e-10
 3.77125108e-17], sum to 1.0000
[2019-03-26 10:50:07,325] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4210
[2019-03-26 10:50:07,331] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.65, 55.16666666666666, 1.0, 2.0, 0.4636948057075373, 1.0, 2.0, 0.4636948057075373, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1296239.745852025, 1296239.745852025, 289379.4826818188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5332200.0000, 
sim time next is 5332800.0000, 
raw observation next is [35.4, 56.33333333333334, 1.0, 2.0, 0.5836980534567927, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564927918, 815672.2466524948, 815672.2466524953, 197750.9113372591], 
processed observation next is [1.0, 0.7391304347826086, 0.8767772511848341, 0.5633333333333335, 1.0, 1.0, 0.49843138970697914, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399450656862, 0.22657562407013743, 0.2265756240701376, 0.2951506139362076], 
reward next is 0.7048, 
noisyNet noise sample is [array([0.5339079], dtype=float32), 0.22223024]. 
=============================================
[2019-03-26 10:50:08,033] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2645461e-25 1.0000000e+00 1.5009553e-29 7.1503935e-29 8.7468493e-30], sum to 1.0000
[2019-03-26 10:50:08,040] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2836
[2019-03-26 10:50:08,049] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.65, 59.83333333333334, 1.0, 2.0, 0.5850136715667648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 817511.4272832045, 817511.4272832045, 197989.9596420928], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5334600.0000, 
sim time next is 5335200.0000, 
raw observation next is [34.4, 61.0, 1.0, 2.0, 0.5935858059098682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 829495.0005679061, 829495.0005679068, 199559.2392521478], 
processed observation next is [1.0, 0.782608695652174, 0.8293838862559241, 0.61, 1.0, 1.0, 0.5103443444697207, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23041527793552946, 0.23041527793552966, 0.29784961082410116], 
reward next is 0.7022, 
noisyNet noise sample is [array([0.28327087], dtype=float32), 0.58678955]. 
=============================================
[2019-03-26 10:50:26,359] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 10:50:26,362] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:50:26,363] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:50:26,363] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:50:26,364] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:50:26,365] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:50:26,365] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:50:26,367] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:50:26,366] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:50:26,368] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:50:26,368] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:50:26,393] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-26 10:50:26,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-26 10:50:26,394] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-26 10:50:26,448] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-26 10:50:26,466] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-26 10:50:32,523] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:50:32,526] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.777937685, 78.73254029, 1.0, 2.0, 0.3969760910682033, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611147.7550559776, 611147.7550559776, 175994.9756319255]
[2019-03-26 10:50:32,527] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:50:32,535] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.5207427e-28 1.0000000e+00 5.9675518e-34 3.8746924e-36 3.2170046e-35], sampled 0.8812452642294367
[2019-03-26 10:51:14,827] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:51:14,830] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.86055850333334, 67.07851366833333, 1.0, 2.0, 0.5499227990215405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 768456.9043994003, 768456.9043994003, 191787.2163173938]
[2019-03-26 10:51:14,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:51:14,833] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.4979529e-28 1.0000000e+00 8.1089262e-35 1.1138593e-36 3.7368742e-36], sampled 0.030608321186083143
[2019-03-26 10:52:00,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:52:00,337] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.85, 72.0, 1.0, 2.0, 0.5625610030599346, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9769824205485096, 6.911199999999999, 6.9112, 168.9129478254969, 1572830.136615853, 1572830.136615853, 344168.0484014893]
[2019-03-26 10:52:00,339] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:52:00,344] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.2190823e-21 1.0000000e+00 1.2893794e-24 1.7336894e-21 3.2594633e-26], sampled 0.8752265486766762
[2019-03-26 10:52:02,182] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:52:02,185] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.99794004, 82.74259268666667, 1.0, 2.0, 0.5509480324053726, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769890.0750066381, 769890.0750066374, 191962.6064433061]
[2019-03-26 10:52:02,186] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:52:02,189] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5459275e-28 1.0000000e+00 4.9726657e-34 2.3599502e-34 1.2692806e-35], sampled 0.04165254774116278
[2019-03-26 10:52:05,119] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:52:05,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.2, 73.5, 1.0, 2.0, 0.3324294445221038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520206.5995089056, 520206.599508905, 168454.4481746392]
[2019-03-26 10:52:05,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:52:05,125] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.4215951e-29 1.0000000e+00 3.7684986e-35 4.1582384e-36 6.0519758e-37], sampled 0.31056937218080527
[2019-03-26 10:52:18,689] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.21818481], dtype=float32), 0.081460305]
[2019-03-26 10:52:18,690] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.95308301666667, 90.15936380666668, 1.0, 2.0, 0.4469084511501462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 635869.4840202212, 635869.4840202219, 177168.7487516751]
[2019-03-26 10:52:18,691] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:52:18,693] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0807958e-28 1.0000000e+00 1.9008795e-34 7.9543225e-37 1.8239264e-35], sampled 0.35627479431398756
[2019-03-26 10:52:21,251] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.2300 2927457024.3359 1338.0000
[2019-03-26 10:52:21,467] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164134907.6624 1778.0000
[2019-03-26 10:52:21,686] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.1725 2779322230.8975 933.0000
[2019-03-26 10:52:21,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 10:52:21,765] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 10:52:22,780] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 575000, evaluation results [575000.0, 7883.418813853433, 3164134907.662386, 1778.0, 8254.230042292205, 2927457024.3359056, 1338.0, 8661.172501768742, 2779322230.897455, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 10:52:23,165] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9469362e-28 1.0000000e+00 4.4982596e-34 3.7701088e-35 6.0164608e-36], sum to 1.0000
[2019-03-26 10:52:23,173] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7209
[2019-03-26 10:52:23,182] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.53333333333333, 87.0, 1.0, 2.0, 0.514571793229529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719041.0244809346, 719041.0244809346, 185910.3212599573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5701200.0000, 
sim time next is 5701800.0000, 
raw observation next is [26.51666666666667, 87.0, 1.0, 2.0, 0.5142109877555255, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718536.6795371415, 718536.6795371415, 185852.2360275718], 
processed observation next is [0.0, 1.0, 0.45576619273301755, 0.87, 1.0, 1.0, 0.4147120334403922, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19959352209365042, 0.19959352209365042, 0.27739139705607735], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.86057734], dtype=float32), -0.41987276]. 
=============================================
[2019-03-26 10:52:24,803] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7271012e-29 1.0000000e+00 9.8082412e-36 9.9227872e-38 3.6186555e-37], sum to 1.0000
[2019-03-26 10:52:24,811] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3208
[2019-03-26 10:52:24,818] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 53.0, 1.0, 2.0, 0.5179315487928451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723737.4052203717, 723737.4052203717, 186453.8137669691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 0.5210283406326912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728066.2247017447, 728066.2247017447, 186957.1641838482], 
processed observation next is [0.0, 0.6086956521739131, 0.7819905213270142, 0.53, 1.0, 1.0, 0.422925711605652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20224061797270687, 0.20224061797270687, 0.27904054355798236], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.3879798], dtype=float32), 0.22423702]. 
=============================================
[2019-03-26 10:52:30,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.27082625e-20 1.00000000e+00 3.04365390e-25 2.04466889e-24
 4.47235865e-25], sum to 1.0000
[2019-03-26 10:52:30,064] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0272
[2019-03-26 10:52:30,074] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.46666666666667, 81.33333333333334, 1.0, 2.0, 0.971369365972964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1357758.842865163, 1357758.842865164, 290324.7584659207], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5815200.0000, 
sim time next is 5815800.0000, 
raw observation next is [28.65, 80.5, 1.0, 2.0, 1.030111933655643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9128842521867, 1439923.60576418, 1439923.60576418, 308235.99370558], 
processed observation next is [1.0, 0.30434782608695654, 0.5568720379146919, 0.805, 1.0, 1.0, 1.036279438139329, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294395903312431, 0.3999787793789389, 0.3999787793789389, 0.46005372194862687], 
reward next is 0.5399, 
noisyNet noise sample is [array([1.8920835], dtype=float32), -0.07493735]. 
=============================================
[2019-03-26 10:52:30,729] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.6583028e-26 1.0000000e+00 3.3561546e-31 7.9579621e-30 1.8560058e-31], sum to 1.0000
[2019-03-26 10:52:30,735] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2705
[2019-03-26 10:52:30,746] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.26666666666667, 72.0, 1.0, 2.0, 0.5582309294339238, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 780070.8701151449, 780070.8701151442, 193222.2889117747], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5768400.0000, 
sim time next is 5769000.0000, 
raw observation next is [30.05, 73.0, 1.0, 2.0, 0.5556177029862147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 776417.8176715361, 776417.8176715361, 192768.8500099145], 
processed observation next is [0.0, 0.782608695652174, 0.6232227488151659, 0.73, 1.0, 1.0, 0.4645996421520659, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21567161601987114, 0.21567161601987114, 0.2877147015073351], 
reward next is 0.7123, 
noisyNet noise sample is [array([-0.55858755], dtype=float32), -0.73045355]. 
=============================================
[2019-03-26 10:52:30,775] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.41367 ]
 [68.45552 ]
 [68.614426]
 [68.62503 ]
 [68.66845 ]], R is [[68.40840149]
 [68.43592834]
 [68.45965576]
 [68.48671722]
 [68.51334381]].
[2019-03-26 10:52:31,801] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.3971976e-23 1.0000000e+00 2.8916126e-28 4.6887034e-27 2.4194374e-27], sum to 1.0000
[2019-03-26 10:52:31,809] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3295
[2019-03-26 10:52:31,813] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.76666666666667, 87.0, 1.0, 2.0, 0.5567330500304989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777976.9696666499, 777976.9696666499, 192961.9888492085], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5865600.0000, 
sim time next is 5866200.0000, 
raw observation next is [27.7, 87.0, 1.0, 2.0, 0.5536812715813269, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773710.871128941, 773710.871128941, 192433.9467760243], 
processed observation next is [1.0, 0.9130434782608695, 0.5118483412322274, 0.87, 1.0, 1.0, 0.46226659226665884, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21491968642470582, 0.21491968642470582, 0.28721484593436464], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.13548113], dtype=float32), -0.8315208]. 
=============================================
[2019-03-26 10:52:33,256] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.03041185e-19 1.00000000e+00 1.10799301e-23 2.06162853e-21
 7.05558140e-23], sum to 1.0000
[2019-03-26 10:52:33,268] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8122
[2019-03-26 10:52:33,276] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.55, 84.5, 1.0, 2.0, 0.750790183519081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1049285.739953067, 1049285.739953067, 232192.690745666], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5989800.0000, 
sim time next is 5990400.0000, 
raw observation next is [28.7, 84.0, 1.0, 2.0, 0.751059915969747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1049662.897646974, 1049662.897646974, 232255.1746011922], 
processed observation next is [1.0, 0.34782608695652173, 0.5592417061611374, 0.84, 1.0, 1.0, 0.7000721879153577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29157302712415945, 0.29157302712415945, 0.34664951433013763], 
reward next is 0.6534, 
noisyNet noise sample is [array([0.19057791], dtype=float32), 1.175589]. 
=============================================
[2019-03-26 10:52:46,258] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7184413e-24 1.0000000e+00 7.2732301e-28 2.5465130e-26 1.9946734e-28], sum to 1.0000
[2019-03-26 10:52:46,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2653
[2019-03-26 10:52:46,272] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.05, 86.83333333333333, 1.0, 2.0, 0.526665413189181, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735945.9954423974, 735945.9954423974, 187879.5086847345], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6213000.0000, 
sim time next is 6213600.0000, 
raw observation next is [27.0, 87.0, 1.0, 2.0, 0.5257972362066528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734732.412153903, 734732.4121539037, 187736.7214196131], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.87, 1.0, 1.0, 0.42867136892367796, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2040923367094175, 0.2040923367094177, 0.2802040618203181], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.8803714], dtype=float32), -2.0733852]. 
=============================================
[2019-03-26 10:52:50,418] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.1239641e-23 1.0000000e+00 2.3676401e-28 7.1493410e-26 1.8338527e-29], sum to 1.0000
[2019-03-26 10:52:50,428] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4776
[2019-03-26 10:52:50,433] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.75, 77.0, 1.0, 2.0, 0.5252405013827002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733954.1797674065, 733954.1797674065, 187645.8684115328], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6114600.0000, 
sim time next is 6115200.0000, 
raw observation next is [28.56666666666666, 78.0, 1.0, 2.0, 0.5257320437657211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 734641.2827991112, 734641.2827991118, 187726.511673101], 
processed observation next is [1.0, 0.782608695652174, 0.5529225908372825, 0.78, 1.0, 1.0, 0.42859282381412184, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20406702299975313, 0.20406702299975327, 0.280188823392688], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.6882068], dtype=float32), 2.3744948]. 
=============================================
[2019-03-26 10:52:51,495] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.1004186e-25 1.0000000e+00 3.4536821e-30 3.0345487e-28 3.7696853e-31], sum to 1.0000
[2019-03-26 10:52:51,503] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3669
[2019-03-26 10:52:51,515] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.3, 85.0, 1.0, 2.0, 0.5277896534109376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 737517.5194075225, 737517.5194075225, 188064.6001796792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6306600.0000, 
sim time next is 6307200.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5281840973461742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 738068.8950873374, 738068.8950873368, 188129.6472705961], 
processed observation next is [0.0, 0.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4315471052363545, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20501913752426038, 0.2050191375242602, 0.2807905183143225], 
reward next is 0.7192, 
noisyNet noise sample is [array([1.2439182], dtype=float32), 0.749156]. 
=============================================
[2019-03-26 10:52:59,496] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1746552e-26 1.0000000e+00 4.5835015e-33 1.6159248e-31 2.2462691e-34], sum to 1.0000
[2019-03-26 10:52:59,503] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7744
[2019-03-26 10:52:59,509] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 62.0, 1.0, 2.0, 0.5055397170101268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706415.7837007756, 706415.783700775, 184468.7126058145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6274800.0000, 
sim time next is 6275400.0000, 
raw observation next is [30.68333333333333, 62.16666666666667, 1.0, 2.0, 0.5065657792210737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707850.029151847, 707850.0291518463, 184631.288402571], 
processed observation next is [0.0, 0.6521739130434783, 0.6532385466034754, 0.6216666666666667, 1.0, 1.0, 0.4055009388205707, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19662500809773528, 0.1966250080977351, 0.2755690871680164], 
reward next is 0.7244, 
noisyNet noise sample is [array([1.1570817], dtype=float32), -0.99104565]. 
=============================================
[2019-03-26 10:53:03,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.9671643e-24 1.0000000e+00 3.1540800e-30 2.4361155e-28 7.1279457e-31], sum to 1.0000
[2019-03-26 10:53:03,058] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-26 10:53:03,065] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.85, 75.0, 1.0, 2.0, 0.5235939093401797, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731652.492605104, 731652.4926051034, 187375.4744279057], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6337800.0000, 
sim time next is 6338400.0000, 
raw observation next is [29.0, 74.33333333333333, 1.0, 2.0, 0.5242594921444128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732582.8763112919, 732582.8763112926, 187484.5307922745], 
processed observation next is [0.0, 0.34782608695652173, 0.5734597156398105, 0.7433333333333333, 1.0, 1.0, 0.4268186652342323, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20349524341980332, 0.20349524341980352, 0.27982765789891717], 
reward next is 0.7202, 
noisyNet noise sample is [array([0.20772661], dtype=float32), 1.4345182]. 
=============================================
[2019-03-26 10:53:05,436] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.9579429e-18 1.0000000e+00 1.5607119e-20 3.3845552e-16 1.7841363e-21], sum to 1.0000
[2019-03-26 10:53:05,442] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1704
[2019-03-26 10:53:05,453] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 85.5, 1.0, 2.0, 0.8555036380411289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1195713.064414454, 1195713.064414453, 257989.2224765212], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6406200.0000, 
sim time next is 6406800.0000, 
raw observation next is [26.76666666666667, 85.66666666666666, 1.0, 2.0, 0.8356262942694533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1167915.787792461, 1167915.787792461, 252841.8606759489], 
processed observation next is [1.0, 0.13043478260869565, 0.46761453396524505, 0.8566666666666666, 1.0, 1.0, 0.8019593906860883, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3244210521645725, 0.3244210521645725, 0.3773759114566402], 
reward next is 0.6226, 
noisyNet noise sample is [array([-2.5208123], dtype=float32), 0.600533]. 
=============================================
[2019-03-26 10:53:07,068] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.2437514e-11 8.9096068e-04 7.0445091e-12 9.9910897e-01 4.3151241e-13], sum to 1.0000
[2019-03-26 10:53:07,076] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2927
[2019-03-26 10:53:07,080] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.83333333333334, 69.0, 1.0, 2.0, 0.8426735423521152, 1.0, 2.0, 0.8426735423521152, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2356801.68442423, 2356801.68442423, 441173.9034593781], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6434400.0000, 
sim time next is 6435000.0000, 
raw observation next is [29.85, 69.0, 1.0, 2.0, 0.851975153282298, 1.0, 2.0, 0.851975153282298, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2382841.368627954, 2382841.368627954, 445960.6960989384], 
processed observation next is [1.0, 0.4782608695652174, 0.613744075829384, 0.69, 1.0, 1.0, 0.8216568111834915, 1.0, 1.0, 0.8216568111834915, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6619003801744316, 0.6619003801744316, 0.6656129792521469], 
reward next is 0.3344, 
noisyNet noise sample is [array([0.39233357], dtype=float32), 1.792684]. 
=============================================
[2019-03-26 10:53:07,092] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[36.515865]
 [36.66135 ]
 [36.622997]
 [35.831524]
 [35.55415 ]], R is [[36.23804474]
 [36.2171936 ]
 [36.21532059]
 [36.23640823]
 [36.24876022]].
[2019-03-26 10:53:12,549] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6640345e-19 1.0000000e+00 4.5608858e-23 3.1052605e-17 2.1545167e-23], sum to 1.0000
[2019-03-26 10:53:12,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7770
[2019-03-26 10:53:12,564] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.25, 91.5, 1.0, 2.0, 0.7653272860402697, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1069612.665953984, 1069612.665953983, 235576.9830237671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6492600.0000, 
sim time next is 6493200.0000, 
raw observation next is [26.23333333333333, 91.66666666666666, 1.0, 2.0, 0.7544219088537768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1054363.868967868, 1054363.868967868, 233029.7328824497], 
processed observation next is [1.0, 0.13043478260869565, 0.44233807266982617, 0.9166666666666665, 1.0, 1.0, 0.7041227817515383, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2928788524910744, 0.2928788524910744, 0.34780557146634283], 
reward next is 0.6522, 
noisyNet noise sample is [array([-1.2692902], dtype=float32), -0.44155785]. 
=============================================
[2019-03-26 10:53:15,316] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.7689691e-22 1.0000000e+00 1.6962785e-26 1.9788180e-21 3.7269527e-28], sum to 1.0000
[2019-03-26 10:53:15,329] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2442
[2019-03-26 10:53:15,334] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 67.0, 1.0, 2.0, 0.4775000144673019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667222.2081572168, 667222.2081572161, 180146.5940535892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6544800.0000, 
sim time next is 6545400.0000, 
raw observation next is [29.18333333333333, 67.5, 1.0, 2.0, 0.4822364814289826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673842.6860054275, 673842.6860054282, 180860.1301192249], 
processed observation next is [1.0, 0.782608695652174, 0.5821484992101105, 0.675, 1.0, 1.0, 0.3761885318421478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18717852389039652, 0.18717852389039671, 0.26994049271526105], 
reward next is 0.7301, 
noisyNet noise sample is [array([0.82210314], dtype=float32), -1.2407705]. 
=============================================
[2019-03-26 10:53:17,293] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 10:53:17,296] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:53:17,297] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:53:17,298] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:53:17,299] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:53:17,299] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:53:17,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:53:17,301] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:53:17,302] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:53:17,303] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:53:17,304] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:53:17,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-26 10:53:17,344] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-26 10:53:17,346] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-26 10:53:17,397] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-26 10:53:17,397] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-26 10:53:51,764] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:53:51,768] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.26666666666667, 94.0, 1.0, 2.0, 0.3632075003202397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 554938.5541369878, 554938.5541369871, 170931.6114918442]
[2019-03-26 10:53:51,769] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:53:51,774] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.8429239e-24 1.0000000e+00 1.1101176e-29 2.1157831e-28 1.7245130e-30], sampled 0.8725630727471535
[2019-03-26 10:53:56,067] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:53:56,067] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.6, 73.5, 1.0, 2.0, 0.5807755017547738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811586.6495855168, 811586.6495855168, 197218.7664125005]
[2019-03-26 10:53:56,071] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:53:56,074] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.7263416e-23 1.0000000e+00 3.8766004e-28 7.7064354e-25 3.6676724e-29], sampled 0.8550082453070753
[2019-03-26 10:54:39,496] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:54:39,497] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.629162915, 61.44376099999999, 1.0, 2.0, 0.5668349928138148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 792098.6554565208, 792098.6554565208, 194730.0045149706]
[2019-03-26 10:54:39,498] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:54:39,501] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2559942e-23 1.0000000e+00 6.9506270e-29 5.1687837e-26 5.2721053e-30], sampled 0.22464130759918255
[2019-03-26 10:54:41,062] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:54:41,064] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.40000000000001, 53.33333333333334, 1.0, 2.0, 0.5977498074384857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835316.1920841552, 835316.1920841552, 200327.4667491166]
[2019-03-26 10:54:41,064] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:54:41,067] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9274122e-23 1.0000000e+00 1.1975204e-28 1.6895310e-25 1.0661409e-29], sampled 0.31683652680234575
[2019-03-26 10:54:48,324] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:54:48,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 74.33333333333333, 1.0, 2.0, 0.5242594921444128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732582.8763112919, 732582.8763112926, 187484.5307922745]
[2019-03-26 10:54:48,327] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:54:48,331] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.8224353e-23 1.0000000e+00 4.4500218e-29 6.9245132e-27 5.4530476e-30], sampled 0.10218527506687125
[2019-03-26 10:54:54,436] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:54:54,438] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.12952763166667, 61.38760331166667, 1.0, 2.0, 0.815993796325709, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1140461.627726643, 1140461.627726644, 247871.1331040964]
[2019-03-26 10:54:54,438] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:54:54,440] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0306508e-20 1.0000000e+00 8.7975681e-25 1.5054750e-20 1.4779361e-25], sampled 0.5974577388806299
[2019-03-26 10:54:55,989] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24435711], dtype=float32), 0.08382444]
[2019-03-26 10:54:55,992] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.51900941, 49.27688489499999, 1.0, 2.0, 0.7344922393281793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104009, 1140585.102779724, 1140585.102779725, 242829.8475684938]
[2019-03-26 10:54:55,992] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:54:55,996] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.7503472e-18 1.0000000e+00 1.1775788e-21 2.2530608e-16 1.7117396e-22], sampled 0.8850914933034368
[2019-03-26 10:55:11,557] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7922.4178 3160619405.6814 1692.0000
[2019-03-26 10:55:12,240] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.2300 2778972597.0663 925.0000
[2019-03-26 10:55:12,262] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8256.2784 2927236583.8158 1333.0000
[2019-03-26 10:55:12,296] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8503.3015 2841830861.1563 1118.0000
[2019-03-26 10:55:12,397] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8005.6583 3006928259.8903 1751.0000
[2019-03-26 10:55:13,411] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 600000, evaluation results [600000.0, 7922.417837597056, 3160619405.6813836, 1692.0, 8256.278391812195, 2927236583.8158174, 1333.0, 8664.229988354273, 2778972597.0663304, 925.0, 8005.658336260348, 3006928259.8902545, 1751.0, 8503.301521710155, 2841830861.1563163, 1118.0]
[2019-03-26 10:55:22,298] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.4706834e-22 1.0000000e+00 6.8948003e-29 3.2484811e-24 5.5642490e-30], sum to 1.0000
[2019-03-26 10:55:22,309] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7340
[2019-03-26 10:55:22,318] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.61666666666667, 68.66666666666666, 1.0, 2.0, 0.3943057301243676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 589150.8722051202, 589150.8722051202, 173563.4790899167], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6727800.0000, 
sim time next is 6728400.0000, 
raw observation next is [26.5, 69.0, 1.0, 2.0, 0.3923439752622888, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 587336.6333422939, 587336.6333422939, 173431.3393785041], 
processed observation next is [1.0, 0.9130434782608695, 0.4549763033175356, 0.69, 1.0, 1.0, 0.26788430754492626, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16314906481730387, 0.16314906481730387, 0.2588527453410509], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.2760528], dtype=float32), -1.2255324]. 
=============================================
[2019-03-26 10:55:23,269] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4192938e-21 1.0000000e+00 3.6045542e-26 1.6666124e-20 1.0577529e-26], sum to 1.0000
[2019-03-26 10:55:23,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0867
[2019-03-26 10:55:23,284] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.11666666666667, 71.66666666666666, 1.0, 2.0, 0.3588082607352506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 552194.5937708472, 552194.5937708472, 170815.5840962378], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6735000.0000, 
sim time next is 6735600.0000, 
raw observation next is [25.0, 72.0, 1.0, 2.0, 0.3550359818122086, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547326.3541794426, 547326.3541794426, 170434.4798124389], 
processed observation next is [1.0, 1.0, 0.38388625592417064, 0.72, 1.0, 1.0, 0.22293491784603442, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1520350983831785, 0.1520350983831785, 0.25437982061558045], 
reward next is 0.7456, 
noisyNet noise sample is [array([-1.8611155], dtype=float32), -2.0008502]. 
=============================================
[2019-03-26 10:55:24,304] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.7153226e-21 1.0000000e+00 1.6322484e-25 9.6617426e-21 4.2636305e-26], sum to 1.0000
[2019-03-26 10:55:24,312] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5515
[2019-03-26 10:55:24,315] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.25, 83.5, 1.0, 2.0, 0.3659360682601785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 579438.8657669369, 579438.8657669376, 173408.5297280036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6748200.0000, 
sim time next is 6748800.0000, 
raw observation next is [22.2, 83.66666666666667, 1.0, 2.0, 0.3422726798846468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542331.6899244603, 542331.6899244603, 170328.2951468949], 
processed observation next is [1.0, 0.08695652173913043, 0.2511848341232228, 0.8366666666666667, 1.0, 1.0, 0.2075574456441528, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1506476916456834, 0.1506476916456834, 0.25422133604014163], 
reward next is 0.7458, 
noisyNet noise sample is [array([-1.1646636], dtype=float32), 1.2500457]. 
=============================================
[2019-03-26 10:55:28,792] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.4450363e-26 1.0000000e+00 1.1188781e-32 9.6984716e-31 2.3685284e-33], sum to 1.0000
[2019-03-26 10:55:28,794] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7987
[2019-03-26 10:55:28,803] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.08333333333334, 82.33333333333334, 1.0, 2.0, 0.3384398181616116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527583.3709242905, 527583.3709242905, 168987.0938982597], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6840600.0000, 
sim time next is 6841200.0000, 
raw observation next is [23.06666666666667, 82.66666666666667, 1.0, 2.0, 0.3399067465857903, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 529475.2795447053, 529475.279544706, 169128.0409553437], 
processed observation next is [0.0, 0.17391304347826086, 0.29225908372827825, 0.8266666666666667, 1.0, 1.0, 0.2047069235973377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1470764665401959, 0.1470764665401961, 0.25242991187364733], 
reward next is 0.7476, 
noisyNet noise sample is [array([1.9302254], dtype=float32), 1.0840602]. 
=============================================
[2019-03-26 10:55:38,821] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.9720177e-18 1.0000000e+00 3.8915641e-21 4.5616875e-15 7.7100054e-22], sum to 1.0000
[2019-03-26 10:55:38,830] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5899
[2019-03-26 10:55:38,835] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 84.0, 1.0, 2.0, 0.7592688839500246, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1083429.940984696, 1083429.940984696, 237220.5036518948], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7009200.0000, 
sim time next is 7009800.0000, 
raw observation next is [25.46666666666667, 84.33333333333333, 1.0, 2.0, 0.7629382917603506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1088594.82446674, 1088594.82446674, 238089.1137964427], 
processed observation next is [1.0, 0.13043478260869565, 0.40600315955766203, 0.8433333333333333, 1.0, 1.0, 0.7143834840486151, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3023874512407611, 0.3023874512407611, 0.35535688626334727], 
reward next is 0.6446, 
noisyNet noise sample is [array([1.0049921], dtype=float32), 1.2560078]. 
=============================================
[2019-03-26 10:55:48,399] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.2635150e-19 1.0000000e+00 3.4284258e-23 4.4905663e-17 6.5431619e-25], sum to 1.0000
[2019-03-26 10:55:48,405] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-26 10:55:48,409] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 90.16666666666667, 1.0, 2.0, 0.531586835600501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742825.443834168, 742825.443834168, 188690.8426545402], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7186200.0000, 
sim time next is 7186800.0000, 
raw observation next is [25.8, 90.33333333333334, 1.0, 2.0, 0.5001853017388527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 698931.3315636899, 698931.3315636904, 183625.0480110853], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9033333333333334, 1.0, 1.0, 0.39781361655283454, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19414759210102497, 0.1941475921010251, 0.27406723583744075], 
reward next is 0.7259, 
noisyNet noise sample is [array([-0.11845498], dtype=float32), 1.1469504]. 
=============================================
[2019-03-26 10:55:53,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.2146059e-19 1.0000000e+00 1.3682775e-23 5.7048940e-17 1.4917568e-25], sum to 1.0000
[2019-03-26 10:55:53,485] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8271
[2019-03-26 10:55:53,491] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.95, 88.5, 1.0, 2.0, 0.3271061895200982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 513743.2461474621, 513743.2461474627, 167996.220911652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7263000.0000, 
sim time next is 7263600.0000, 
raw observation next is [21.93333333333333, 88.33333333333334, 1.0, 2.0, 0.3261194198805615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512668.71813455, 512668.71813455, 167924.1603654595], 
processed observation next is [1.0, 0.043478260869565216, 0.23854660347551332, 0.8833333333333334, 1.0, 1.0, 0.18809568660308612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14240797725959722, 0.14240797725959722, 0.25063307517232764], 
reward next is 0.7494, 
noisyNet noise sample is [array([0.46707794], dtype=float32), 0.21384798]. 
=============================================
[2019-03-26 10:55:55,722] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.6641289e-17 1.0000000e+00 3.3540471e-21 7.5042652e-13 9.7941406e-22], sum to 1.0000
[2019-03-26 10:55:55,733] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3382
[2019-03-26 10:55:55,739] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 58.0, 1.0, 2.0, 0.8507066443807985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1298762.07436315, 1298762.07436315, 271718.1958380652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306800.0000, 
sim time next is 7307400.0000, 
raw observation next is [27.91666666666667, 57.5, 1.0, 2.0, 0.8455115838807973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1291356.832935789, 1291356.83293579, 270301.6421230914], 
processed observation next is [1.0, 0.5652173913043478, 0.5221169036334916, 0.575, 1.0, 1.0, 0.8138693781696352, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35871023137105246, 0.3587102313710528, 0.40343528675088264], 
reward next is 0.5966, 
noisyNet noise sample is [array([0.19763537], dtype=float32), -0.5323506]. 
=============================================
[2019-03-26 10:55:59,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.3249145e-20 1.0000000e+00 9.9497596e-26 4.8064951e-17 9.5901088e-27], sum to 1.0000
[2019-03-26 10:55:59,357] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6831
[2019-03-26 10:55:59,364] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 74.5, 1.0, 2.0, 0.4143424388512938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636987.9260370054, 636987.9260370047, 178372.5192024837], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7353000.0000, 
sim time next is 7353600.0000, 
raw observation next is [24.66666666666666, 75.33333333333333, 1.0, 2.0, 0.4143900331792998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 636312.9102827344, 636312.9102827339, 178298.6179107785], 
processed observation next is [1.0, 0.08695652173913043, 0.36808846761453373, 0.7533333333333333, 1.0, 1.0, 0.2944458231075901, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17675358618964845, 0.1767535861896483, 0.26611734016534105], 
reward next is 0.7339, 
noisyNet noise sample is [array([-0.7330308], dtype=float32), -0.07805684]. 
=============================================
[2019-03-26 10:56:08,016] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 10:56:08,017] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:56:08,017] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:56:08,018] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:56:08,020] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:56:08,020] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:56:08,021] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:56:08,023] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:56:08,024] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:56:08,025] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:56:08,022] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:56:08,047] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-26 10:56:08,047] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-26 10:56:08,069] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-26 10:56:08,088] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-26 10:56:08,089] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-26 10:56:16,856] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:56:16,857] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.53524594666667, 63.59337137000001, 1.0, 2.0, 0.3252901321977286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509660.054571909, 509660.054571909, 167651.3682820049]
[2019-03-26 10:56:16,860] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 10:56:16,862] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.2885893e-18 1.0000000e+00 1.6571900e-22 1.3219779e-15 9.4194986e-24], sampled 0.9856952273025953
[2019-03-26 10:56:35,818] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:56:35,819] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.3, 93.66666666666667, 1.0, 2.0, 0.4534448325885058, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644639.3238196954, 644639.3238196954, 178046.5088244711]
[2019-03-26 10:56:35,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:56:35,827] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.5587982e-18 1.0000000e+00 2.0833607e-22 2.2242206e-14 1.2597807e-23], sampled 0.7157535439617146
[2019-03-26 10:56:37,736] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:56:37,737] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.43045617666667, 91.16334881, 1.0, 2.0, 0.4571602342445064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 652680.8589400653, 652680.858940066, 178940.6080383647]
[2019-03-26 10:56:37,738] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:56:37,743] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.4737151e-20 1.0000000e+00 1.3888647e-24 3.4515035e-18 7.8251329e-26], sampled 0.7320636321698669
[2019-03-26 10:56:41,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:56:41,130] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.53333333333333, 83.83333333333334, 1.0, 2.0, 0.7371720842473377, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1030244.189916009, 1030244.189916009, 229070.5233628539]
[2019-03-26 10:56:41,131] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 10:56:41,133] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.2956127e-18 1.0000000e+00 3.9104889e-23 4.9606779e-17 7.1406261e-24], sampled 0.457699742623229
[2019-03-26 10:57:11,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:57:11,838] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.15, 50.0, 1.0, 2.0, 0.8355523022441282, 1.0, 2.0, 0.8355523022441282, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 169.0403247858759, 2336885.882004767, 2336885.882004766, 437275.8675361115]
[2019-03-26 10:57:11,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:57:11,841] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2213587e-12 1.5398445e-02 1.0141138e-15 9.8460150e-01 1.1730299e-18], sampled 0.9502139274989394
[2019-03-26 10:57:21,069] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:57:21,070] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.45480931666667, 91.73756012666666, 1.0, 2.0, 0.5450475830959862, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 761641.8814486362, 761641.8814486368, 190953.9775263828]
[2019-03-26 10:57:21,072] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:57:21,074] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9053223e-20 1.0000000e+00 2.7113810e-25 2.2323272e-20 2.6723902e-26], sampled 0.46756238013332463
[2019-03-26 10:57:32,324] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:57:32,325] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.31666666666667, 82.50000000000001, 1.0, 2.0, 0.5965542515749793, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 833644.825443736, 833644.8254437367, 200104.9095421369]
[2019-03-26 10:57:32,326] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 10:57:32,329] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.7717281e-18 1.0000000e+00 3.3286421e-22 1.2078846e-13 1.6706391e-23], sampled 0.9228571511908085
[2019-03-26 10:57:36,789] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24264516], dtype=float32), 0.086101905]
[2019-03-26 10:57:36,791] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.25, 90.0, 1.0, 2.0, 0.7566088930432338, 1.0, 2.0, 0.7566088930432338, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 2115849.541332962, 2115849.541332962, 399785.1082926184]
[2019-03-26 10:57:36,792] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 10:57:36,794] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.7163089e-11 1.2999697e-02 3.0153687e-13 9.8700029e-01 3.1810966e-15], sampled 0.96206953708506
[2019-03-26 10:58:02,822] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8340.8821 2919901682.7520 1147.0000
[2019-03-26 10:58:03,034] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8713.9455 2774338102.9790 806.0000
[2019-03-26 10:58:03,086] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8103.5773 3144689040.1164 1247.0000
[2019-03-26 10:58:03,134] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8597.1774 2834550039.8816 900.0000
[2019-03-26 10:58:03,211] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8185.8555 2992040889.1347 1338.0000
[2019-03-26 10:58:04,229] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 625000, evaluation results [625000.0, 8103.577252533478, 3144689040.116427, 1247.0, 8340.882102064215, 2919901682.752019, 1147.0, 8713.945490288477, 2774338102.979028, 806.0, 8185.855524234841, 2992040889.134671, 1338.0, 8597.177413044432, 2834550039.881553, 900.0]
[2019-03-26 10:58:18,336] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7605014e-14 9.9995291e-01 3.7019840e-19 4.7064772e-05 1.3168736e-21], sum to 1.0000
[2019-03-26 10:58:18,345] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4353
[2019-03-26 10:58:18,351] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.96666666666667, 65.33333333333334, 1.0, 2.0, 0.4605356573126653, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 643510.3258140581, 643510.3258140587, 177646.0505530992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7752000.0000, 
sim time next is 7752600.0000, 
raw observation next is [29.8, 66.5, 1.0, 2.0, 0.4536057991173154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 633824.2883353025, 633824.2883353019, 176648.9047012652], 
processed observation next is [1.0, 0.7391304347826086, 0.6113744075829385, 0.665, 1.0, 1.0, 0.34169373387628366, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1760623023153618, 0.17606230231536163, 0.2636550816436794], 
reward next is 0.7363, 
noisyNet noise sample is [array([-1.1624578], dtype=float32), -0.67801064]. 
=============================================
[2019-03-26 10:58:18,851] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.376669e-17 1.000000e+00 3.653751e-21 7.525080e-12 4.520029e-22], sum to 1.0000
[2019-03-26 10:58:18,862] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3204
[2019-03-26 10:58:18,869] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 88.33333333333334, 1.0, 2.0, 0.5117471010429623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715092.5896172201, 715092.5896172201, 185457.0375287665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777200.0000, 
sim time next is 7777800.0000, 
raw observation next is [26.4, 88.0, 1.0, 2.0, 0.5101332702930573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712836.7378048967, 712836.737804896, 185198.9423960287], 
processed observation next is [1.0, 0.0, 0.45023696682464454, 0.88, 1.0, 1.0, 0.4097991208350088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19801020494580462, 0.19801020494580443, 0.2764163319343712], 
reward next is 0.7236, 
noisyNet noise sample is [array([0.06095191], dtype=float32), 1.2686396]. 
=============================================
[2019-03-26 10:58:20,266] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:20,267] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:20,297] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-26 10:58:22,992] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6502226e-18 1.0000000e+00 7.7040623e-23 9.0854958e-17 7.1073898e-24], sum to 1.0000
[2019-03-26 10:58:23,001] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8213
[2019-03-26 10:58:23,006] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 87.66666666666667, 1.0, 2.0, 0.6062125849977412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 847147.0855077576, 847147.0855077576, 201902.2198677936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7882800.0000, 
sim time next is 7883400.0000, 
raw observation next is [26.55, 87.33333333333333, 1.0, 2.0, 0.6027447994734746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 842299.1339300844, 842299.1339300844, 201251.8063687376], 
processed observation next is [1.0, 0.21739130434782608, 0.4573459715639811, 0.8733333333333333, 1.0, 1.0, 0.5213792764740658, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23397198164724567, 0.23397198164724567, 0.3003758304011009], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.42191982], dtype=float32), -0.86503977]. 
=============================================
[2019-03-26 10:58:25,825] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:25,826] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:25,853] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-26 10:58:26,644] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8546702e-18 1.0000000e+00 6.2286700e-22 8.2073141e-16 2.8502778e-23], sum to 1.0000
[2019-03-26 10:58:26,655] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-26 10:58:26,658] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.46666666666667, 89.66666666666667, 1.0, 2.0, 0.3878659190502755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598953.3325073369, 598953.3325073362, 174934.9719188603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 96000.0000, 
sim time next is 96600.0000, 
raw observation next is [22.48333333333333, 89.83333333333333, 1.0, 2.0, 0.3817879508531122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 588945.2340165173, 588945.2340165167, 174030.2213120737], 
processed observation next is [1.0, 0.08695652173913043, 0.26461295418641384, 0.8983333333333333, 1.0, 1.0, 0.25516620584712313, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16359589833792146, 0.16359589833792132, 0.2597465989732443], 
reward next is 0.7403, 
noisyNet noise sample is [array([-0.6335453], dtype=float32), 2.4147427]. 
=============================================
[2019-03-26 10:58:26,921] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:26,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:26,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-26 10:58:27,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:27,566] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:27,591] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-26 10:58:27,721] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:27,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:27,728] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-26 10:58:28,077] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,077] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-26 10:58:28,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,279] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,288] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-26 10:58:28,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-26 10:58:28,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,412] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-26 10:58:28,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,443] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,443] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,452] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-26 10:58:28,452] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-26 10:58:28,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,475] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,502] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-26 10:58:28,525] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-26 10:58:28,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-26 10:58:28,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,630] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-26 10:58:28,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 10:58:28,691] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:28,694] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-26 10:58:36,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.6393608e-19 1.0000000e+00 1.0147864e-24 1.2742323e-15 2.5445903e-26], sum to 1.0000
[2019-03-26 10:58:36,872] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1961
[2019-03-26 10:58:36,912] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.68333333333333, 86.0, 1.0, 2.0, 0.2684175566462462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 435523.5626446234, 435523.5626446228, 162636.5003922702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 342600.0000, 
sim time next is 343200.0000, 
raw observation next is [20.66666666666667, 86.0, 1.0, 2.0, 0.2677749890158124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 434603.4281754196, 434603.4281754189, 162575.8184142708], 
processed observation next is [0.0, 1.0, 0.17851500789889443, 0.86, 1.0, 1.0, 0.11780119158531617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12072317449317212, 0.12072317449317192, 0.2426504752451803], 
reward next is 0.7573, 
noisyNet noise sample is [array([1.0116831], dtype=float32), -0.26633647]. 
=============================================
[2019-03-26 10:58:36,956] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.10902797e-15 9.99999881e-01 1.75285714e-18 1.00288055e-07
 2.79150942e-19], sum to 1.0000
[2019-03-26 10:58:36,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1570
[2019-03-26 10:58:36,969] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 95.5, 1.0, 2.0, 0.9552732516788897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1425884.400256732, 1425884.400256732, 298995.2809642474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 127800.0000, 
sim time next is 128400.0000, 
raw observation next is [22.8, 95.66666666666667, 1.0, 2.0, 0.9088440893745711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1355578.060794108, 1355578.060794109, 284677.1901405191], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.9566666666666667, 1.0, 1.0, 0.8901736016561097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3765494613316967, 0.3765494613316969, 0.424891328567939], 
reward next is 0.5751, 
noisyNet noise sample is [array([1.0468234], dtype=float32), -1.1649088]. 
=============================================
[2019-03-26 10:58:39,584] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.8316622e-22 1.0000000e+00 3.5031253e-28 1.1741961e-22 2.7263106e-29], sum to 1.0000
[2019-03-26 10:58:39,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2817
[2019-03-26 10:58:39,601] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 95.66666666666666, 1.0, 2.0, 0.283503165940434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 457312.1752977503, 457312.1752977503, 164090.6126821286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 192000.0000, 
sim time next is 192600.0000, 
raw observation next is [19.9, 95.5, 1.0, 2.0, 0.2835464524042191, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 457260.8337850788, 457260.8337850795, 164087.344172261], 
processed observation next is [0.0, 0.21739130434782608, 0.14218009478672985, 0.955, 1.0, 1.0, 0.13680295470387843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.127016898273633, 0.1270168982736332, 0.2449064838391955], 
reward next is 0.7551, 
noisyNet noise sample is [array([-0.6794086], dtype=float32), 1.5655197]. 
=============================================
[2019-03-26 10:58:49,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4419319e-19 1.0000000e+00 1.8411966e-24 1.3391379e-16 1.7525895e-26], sum to 1.0000
[2019-03-26 10:58:49,067] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0418
[2019-03-26 10:58:49,072] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.96666666666667, 86.0, 1.0, 2.0, 0.275679208189076, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 445079.7360947166, 445079.736094716, 163273.9126578792], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 337200.0000, 
sim time next is 337800.0000, 
raw observation next is [20.93333333333333, 86.0, 1.0, 2.0, 0.2746407143913493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 443667.5745969001, 443667.5745969001, 163180.4369165069], 
processed observation next is [0.0, 0.9130434782608695, 0.19115323854660338, 0.86, 1.0, 1.0, 0.1260731498690955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.12324099294358336, 0.12324099294358336, 0.24355289092015955], 
reward next is 0.7564, 
noisyNet noise sample is [array([0.29713264], dtype=float32), 0.38025555]. 
=============================================
[2019-03-26 10:58:53,126] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1293226e-19 1.0000000e+00 1.4444285e-23 5.6079781e-14 2.4988026e-26], sum to 1.0000
[2019-03-26 10:58:53,138] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7470
[2019-03-26 10:58:53,142] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.83333333333334, 80.66666666666667, 1.0, 2.0, 0.2606400843770779, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 426190.2617188799, 426190.2617188799, 161959.4254899148], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 415200.0000, 
sim time next is 415800.0000, 
raw observation next is [20.75, 80.5, 1.0, 2.0, 0.258218662365886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 422845.9374365239, 422845.9374365233, 161724.5171099112], 
processed observation next is [1.0, 0.8260869565217391, 0.18246445497630337, 0.805, 1.0, 1.0, 0.10628754501913971, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11745720484347887, 0.1174572048434787, 0.24137987628344953], 
reward next is 0.7586, 
noisyNet noise sample is [array([2.8885415], dtype=float32), 0.19812082]. 
=============================================
[2019-03-26 10:58:53,288] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.0368748e-18 1.0000000e+00 2.3114855e-23 1.8556644e-14 2.6174669e-24], sum to 1.0000
[2019-03-26 10:58:53,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3150
[2019-03-26 10:58:53,301] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 81.0, 1.0, 2.0, 0.28165705529294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455468.6955350673, 455468.6955350667, 163961.1921212406], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 410400.0000, 
sim time next is 411000.0000, 
raw observation next is [21.41666666666667, 81.0, 1.0, 2.0, 0.2815007482903867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 455917.5421540022, 455917.5421540016, 163984.7839345743], 
processed observation next is [1.0, 0.782608695652174, 0.2140600315955769, 0.81, 1.0, 1.0, 0.1343382509522731, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12664376170944505, 0.12664376170944489, 0.2447534088575736], 
reward next is 0.7552, 
noisyNet noise sample is [array([0.04088401], dtype=float32), 0.39072928]. 
=============================================
[2019-03-26 10:58:53,320] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.90179 ]
 [76.60019 ]
 [76.292244]
 [75.899956]
 [75.3196  ]], R is [[77.04399872]
 [77.02883911]
 [77.01335907]
 [76.99750519]
 [76.98164368]].
[2019-03-26 10:58:53,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.1526603e-19 1.0000000e+00 2.3253948e-25 9.7288413e-19 2.6573536e-27], sum to 1.0000
[2019-03-26 10:58:53,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4394
[2019-03-26 10:58:53,716] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.7, 82.83333333333334, 1.0, 2.0, 0.2293239952763556, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379049.5574255372, 379049.5574255366, 158867.9655074656], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 447000.0000, 
sim time next is 447600.0000, 
raw observation next is [19.7, 82.66666666666667, 1.0, 2.0, 0.2282594086308865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 377369.7702676977, 377369.7702676977, 158765.3333167458], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.8266666666666667, 1.0, 1.0, 0.07019205859142952, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10482493618547158, 0.10482493618547158, 0.23696318405484446], 
reward next is 0.7630, 
noisyNet noise sample is [array([0.07480002], dtype=float32), 0.6145702]. 
=============================================
[2019-03-26 10:58:53,749] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2120247e-19 1.0000000e+00 4.0310500e-24 9.1536555e-15 5.8452616e-25], sum to 1.0000
[2019-03-26 10:58:53,760] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8394
[2019-03-26 10:58:53,764] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.13333333333333, 82.66666666666667, 1.0, 2.0, 0.2477173492624626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 407609.5446955056, 407609.5446955056, 160678.679043628], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 422400.0000, 
sim time next is 423000.0000, 
raw observation next is [20.1, 83.0, 1.0, 2.0, 0.2473756437698603, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 407003.4940160592, 407003.4940160592, 160646.0970583777], 
processed observation next is [1.0, 0.9130434782608695, 0.15165876777251197, 0.83, 1.0, 1.0, 0.09322366719260275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.113056526115572, 0.113056526115572, 0.23977029411698164], 
reward next is 0.7602, 
noisyNet noise sample is [array([-1.0143017], dtype=float32), -0.1786737]. 
=============================================
[2019-03-26 10:58:53,779] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.18586]
 [76.13604]
 [76.11583]
 [76.04767]
 [76.03286]], R is [[76.24308014]
 [76.24082947]
 [76.23844147]
 [76.23603058]
 [76.23377991]].
[2019-03-26 10:58:56,563] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.0117267e-19 1.0000000e+00 7.9157547e-23 1.1620405e-14 4.3296540e-24], sum to 1.0000
[2019-03-26 10:58:56,571] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1182
[2019-03-26 10:58:56,574] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.78333333333333, 71.66666666666667, 1.0, 2.0, 0.425089116994559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 698069.3188745037, 698069.3188745037, 183255.727158108], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 467400.0000, 
sim time next is 468000.0000, 
raw observation next is [21.9, 71.0, 1.0, 2.0, 0.4744885287901079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779014.4280267974, 779014.4280267974, 191333.3936493586], 
processed observation next is [1.0, 0.43478260869565216, 0.23696682464454974, 0.71, 1.0, 1.0, 0.36685364914470836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21639289667411038, 0.21639289667411038, 0.2855722293274009], 
reward next is 0.7144, 
noisyNet noise sample is [array([0.583431], dtype=float32), -0.19821471]. 
=============================================
[2019-03-26 10:58:56,589] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.60428]
 [68.53904]
 [68.46229]
 [68.60252]
 [68.61155]], R is [[68.31378174]
 [68.35713196]
 [68.3990097 ]
 [68.4354248 ]
 [68.47494507]].
[2019-03-26 10:58:56,951] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 10:58:56,956] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 10:58:56,957] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 10:58:56,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:56,958] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:56,958] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 10:58:56,960] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 10:58:56,964] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:56,961] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 10:58:56,966] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:56,967] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 10:58:56,976] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-26 10:58:56,997] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-26 10:58:57,019] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-26 10:58:57,020] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-26 10:58:57,039] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-26 10:59:01,914] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.25079116], dtype=float32), 0.09950052]
[2019-03-26 10:59:01,915] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.47328382, 86.660539915, 1.0, 2.0, 0.3219433112673067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 503281.7015843342, 503281.7015843342, 167133.579116966]
[2019-03-26 10:59:01,916] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 10:59:01,919] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8845060e-21 1.0000000e+00 1.5335946e-26 5.1767887e-21 9.0862072e-28], sampled 0.943532607995707
[2019-03-26 11:00:20,757] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.25079116], dtype=float32), 0.09950052]
[2019-03-26 11:00:20,758] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.52647434, 82.49014244, 1.0, 2.0, 0.5194009684328547, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725791.416559206, 725791.416559206, 186691.7512401233]
[2019-03-26 11:00:20,759] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:00:20,762] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2317422e-20 1.0000000e+00 7.2844313e-25 5.6478182e-16 2.1966219e-26], sampled 0.4263630531982413
[2019-03-26 11:00:27,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.25079116], dtype=float32), 0.09950052]
[2019-03-26 11:00:27,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.45, 69.83333333333333, 1.0, 2.0, 0.5424559411854882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758019.0650255098, 758019.0650255098, 190515.8971393639]
[2019-03-26 11:00:27,752] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:00:27,755] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.8791587e-21 1.0000000e+00 2.5339254e-26 4.8882006e-19 1.1095430e-27], sampled 0.4212579091896037
[2019-03-26 11:00:31,188] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.25079116], dtype=float32), 0.09950052]
[2019-03-26 11:00:31,189] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.03266342333334, 90.48173900333333, 1.0, 2.0, 0.5288377608071659, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738982.6228735502, 738982.6228735502, 188234.0255112198]
[2019-03-26 11:00:31,189] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:00:31,192] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.5758601e-20 1.0000000e+00 9.9860731e-26 1.0387832e-18 6.9153535e-27], sampled 0.9972055511651663
[2019-03-26 11:00:50,808] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.25079116], dtype=float32), 0.09950052]
[2019-03-26 11:00:50,811] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.18477251, 65.98209884, 1.0, 2.0, 0.5427172270351567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 758384.3119417519, 758384.3119417513, 190557.6781832533]
[2019-03-26 11:00:50,812] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:00:50,814] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.1961732e-20 1.0000000e+00 2.0109958e-25 1.5597620e-17 8.2070801e-27], sampled 0.18936787463643134
[2019-03-26 11:00:52,237] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8042.5824 3149772642.4208 1390.0000
[2019-03-26 11:00:52,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8300.2169 2922857658.2080 1230.0000
[2019-03-26 11:00:52,320] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8561.5628 2836836001.1521 978.0000
[2019-03-26 11:00:52,325] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8093.0248 2999143196.5901 1542.0000
[2019-03-26 11:00:52,387] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8697.9606 2775900205.8396 847.0000
[2019-03-26 11:00:53,402] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 650000, evaluation results [650000.0, 8042.5823938557, 3149772642.42078, 1390.0, 8300.21690617978, 2922857658.20797, 1230.0, 8697.960583591697, 2775900205.8395734, 847.0, 8093.024807331817, 2999143196.5901017, 1542.0, 8561.562831621459, 2836836001.1520762, 978.0]
[2019-03-26 11:00:53,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2410615e-19 1.0000000e+00 1.7836991e-23 1.5952729e-15 1.2630425e-24], sum to 1.0000
[2019-03-26 11:00:53,670] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7142
[2019-03-26 11:00:53,673] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.66666666666667, 93.0, 1.0, 2.0, 0.2334899960315701, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 388733.2498148087, 388733.2498148087, 158874.2273807432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 699600.0000, 
sim time next is 700200.0000, 
raw observation next is [17.65, 93.0, 1.0, 2.0, 0.2227443206335127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 370888.6993214728, 370888.6993214734, 157886.9921243822], 
processed observation next is [1.0, 0.08695652173913043, 0.035545023696682464, 0.93, 1.0, 1.0, 0.06354737425724422, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10302463870040911, 0.10302463870040929, 0.23565222705131672], 
reward next is 0.7643, 
noisyNet noise sample is [array([-0.66216266], dtype=float32), -1.1136113]. 
=============================================
[2019-03-26 11:00:55,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.9197983e-18 1.0000000e+00 1.1993344e-22 1.9713735e-14 2.1037394e-24], sum to 1.0000
[2019-03-26 11:00:55,838] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8979
[2019-03-26 11:00:55,845] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.4, 53.5, 1.0, 2.0, 0.3199653316179308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 521473.4997377692, 521473.4997377686, 168572.948524397], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 736200.0000, 
sim time next is 736800.0000, 
raw observation next is [25.46666666666667, 53.0, 1.0, 2.0, 0.3799757414094503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619555.0437125406, 619555.0437125413, 176515.8637444389], 
processed observation next is [1.0, 0.5217391304347826, 0.40600315955766203, 0.53, 1.0, 1.0, 0.25298282097524133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17209862325348352, 0.1720986232534837, 0.26345651305140133], 
reward next is 0.7365, 
noisyNet noise sample is [array([0.16042417], dtype=float32), 0.3693763]. 
=============================================
[2019-03-26 11:00:55,876] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2225625e-18 1.0000000e+00 6.6918736e-23 1.6213517e-13 1.9203710e-24], sum to 1.0000
[2019-03-26 11:00:55,886] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6423
[2019-03-26 11:00:55,892] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.63333333333333, 87.0, 1.0, 2.0, 0.2240645058779399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 372263.3600338448, 372263.3600338448, 158175.7977826523], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 524400.0000, 
sim time next is 525000.0000, 
raw observation next is [18.61666666666667, 87.0, 1.0, 2.0, 0.2235750763371721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 371500.0341577611, 371500.0341577617, 158123.462648002], 
processed observation next is [1.0, 0.043478260869565216, 0.081358609794629, 0.87, 1.0, 1.0, 0.06454828474358085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10319445393271141, 0.1031944539327116, 0.23600516813134625], 
reward next is 0.7640, 
noisyNet noise sample is [array([1.3957138], dtype=float32), -0.5969366]. 
=============================================
[2019-03-26 11:00:55,909] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.154655]
 [72.16781 ]
 [72.21342 ]
 [72.2181  ]
 [72.27727 ]], R is [[72.18618011]
 [72.22823334]
 [72.26979828]
 [72.31088257]
 [72.35148621]].
[2019-03-26 11:00:57,606] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3828105e-18 1.0000000e+00 4.2827744e-23 1.8877796e-14 7.9403642e-25], sum to 1.0000
[2019-03-26 11:00:57,616] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8823
[2019-03-26 11:00:57,621] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.91666666666666, 56.5, 1.0, 2.0, 0.6107905061670916, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1006836.955491657, 1006836.955491657, 217927.6554883869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 558600.0000, 
sim time next is 559200.0000, 
raw observation next is [24.13333333333333, 56.00000000000001, 1.0, 2.0, 0.6120043508527482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1007447.090773712, 1007447.090773713, 218210.8620675619], 
processed observation next is [1.0, 0.4782608695652174, 0.3428120063191152, 0.56, 1.0, 1.0, 0.5325353624731906, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2798464141038089, 0.27984641410380917, 0.3256878538321819], 
reward next is 0.6743, 
noisyNet noise sample is [array([-0.27760068], dtype=float32), -0.6415024]. 
=============================================
[2019-03-26 11:01:01,202] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.1991389e-20 1.0000000e+00 7.8581615e-25 9.9384195e-18 5.2733054e-25], sum to 1.0000
[2019-03-26 11:01:01,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7107
[2019-03-26 11:01:01,214] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.2090172e-18 1.0000000e+00 2.5041131e-22 7.6633630e-12 3.0557924e-22], sum to 1.0000
[2019-03-26 11:01:01,220] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.86666666666667, 72.0, 1.0, 2.0, 0.4187583075914904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 686689.8810980052, 686689.8810980045, 182272.7719313551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 721200.0000, 
sim time next is 721800.0000, 
raw observation next is [22.05, 71.0, 1.0, 2.0, 0.4842114114022496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793551.9730142583, 793551.9730142589, 193007.2105690312], 
processed observation next is [1.0, 0.34782608695652173, 0.24407582938388633, 0.71, 1.0, 1.0, 0.3785679655448791, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22043110361507176, 0.22043110361507193, 0.28807046353586746], 
reward next is 0.7119, 
noisyNet noise sample is [array([0.5333071], dtype=float32), -1.7799004]. 
=============================================
[2019-03-26 11:01:01,229] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-26 11:01:01,236] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 53.0, 1.0, 2.0, 0.5758176870902904, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 947255.4411877558, 947255.4411877552, 210515.0070299353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 655200.0000, 
sim time next is 655800.0000, 
raw observation next is [24.7, 53.0, 1.0, 2.0, 0.5379671656988837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 885088.8569347081, 885088.8569347075, 202939.2965670972], 
processed observation next is [1.0, 0.6086956521739131, 0.3696682464454976, 0.53, 1.0, 1.0, 0.4433339345769683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2458580158151967, 0.24585801581519653, 0.3028944724882048], 
reward next is 0.6971, 
noisyNet noise sample is [array([-2.5675478], dtype=float32), -1.099386]. 
=============================================
[2019-03-26 11:01:07,254] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5638340e-21 1.0000000e+00 6.4764294e-27 2.7531828e-20 3.3190971e-28], sum to 1.0000
[2019-03-26 11:01:07,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0864
[2019-03-26 11:01:07,272] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 83.66666666666667, 1.0, 2.0, 0.2273105243081364, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 377038.4691451734, 377038.4691451727, 158558.7234487081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 714000.0000, 
sim time next is 714600.0000, 
raw observation next is [19.5, 82.5, 1.0, 2.0, 0.2281350297106171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 378105.1292275349, 378105.1292275355, 158669.3260739864], 
processed observation next is [1.0, 0.2608695652173913, 0.12322274881516594, 0.825, 1.0, 1.0, 0.07004220447062301, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10502920256320415, 0.1050292025632043, 0.23681988966266626], 
reward next is 0.7632, 
noisyNet noise sample is [array([0.7515477], dtype=float32), -0.040655073]. 
=============================================
[2019-03-26 11:01:08,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.8854556e-18 1.0000000e+00 4.5128426e-23 6.9165897e-13 3.1793368e-24], sum to 1.0000
[2019-03-26 11:01:08,942] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8008
[2019-03-26 11:01:08,948] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.75, 48.5, 1.0, 2.0, 0.5667411950691573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 930732.9112582929, 930732.9112582929, 208653.4123552284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 743400.0000, 
sim time next is 744000.0000, 
raw observation next is [25.66666666666667, 48.66666666666666, 1.0, 2.0, 0.5705225740678224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 937448.0702151209, 937448.0702151209, 209427.0785945094], 
processed observation next is [1.0, 0.6086956521739131, 0.4154818325434442, 0.4866666666666666, 1.0, 1.0, 0.4825573181540028, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26040224172642246, 0.26040224172642246, 0.3125777292455364], 
reward next is 0.6874, 
noisyNet noise sample is [array([-1.4623035], dtype=float32), -0.074652165]. 
=============================================
[2019-03-26 11:01:08,960] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[72.679436]
 [72.503334]
 [72.20382 ]
 [72.18356 ]
 [72.33461 ]], R is [[72.70944977]
 [72.67092896]
 [72.63145447]
 [72.57964325]
 [72.52236176]].
[2019-03-26 11:01:14,597] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9089722e-20 1.0000000e+00 4.2112302e-24 1.0708843e-16 4.3327393e-26], sum to 1.0000
[2019-03-26 11:01:14,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5261
[2019-03-26 11:01:14,611] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.3, 76.33333333333334, 1.0, 2.0, 0.3101469496316649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 490613.1999019503, 490613.1999019509, 166332.5888356419], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 841200.0000, 
sim time next is 841800.0000, 
raw observation next is [23.15, 77.16666666666666, 1.0, 2.0, 0.3103404121180225, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491231.2380670637, 491231.2380670637, 166384.4380141593], 
processed observation next is [0.0, 0.7391304347826086, 0.2962085308056872, 0.7716666666666666, 1.0, 1.0, 0.16908483387713552, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13645312168529547, 0.13645312168529547, 0.24833498211068553], 
reward next is 0.7517, 
noisyNet noise sample is [array([0.60548085], dtype=float32), 0.09473528]. 
=============================================
[2019-03-26 11:01:15,699] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.1916553e-18 1.0000000e+00 3.4605801e-22 5.9052244e-14 3.0941125e-23], sum to 1.0000
[2019-03-26 11:01:15,708] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7073
[2019-03-26 11:01:15,714] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 83.16666666666667, 1.0, 2.0, 0.5932656126963484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 943452.3655298231, 943452.3655298224, 212566.1425890614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1073400.0000, 
sim time next is 1074000.0000, 
raw observation next is [22.2, 82.33333333333334, 1.0, 2.0, 0.5205601970345691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 827988.8692706674, 827988.8692706674, 198243.4293223979], 
processed observation next is [1.0, 0.43478260869565216, 0.2511848341232228, 0.8233333333333335, 1.0, 1.0, 0.42236168317417966, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22999690813074095, 0.22999690813074095, 0.295885715406564], 
reward next is 0.7041, 
noisyNet noise sample is [array([-0.24925077], dtype=float32), -0.38555047]. 
=============================================
[2019-03-26 11:01:15,732] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.674675]
 [68.38544 ]
 [68.552185]
 [68.46667 ]
 [68.389915]], R is [[67.92827606]
 [67.93173218]
 [67.9577179 ]
 [67.99274445]
 [68.02597046]].
[2019-03-26 11:01:16,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6219400e-16 1.0000000e+00 3.7952727e-21 6.1895911e-10 5.0903045e-24], sum to 1.0000
[2019-03-26 11:01:16,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0838
[2019-03-26 11:01:16,046] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 61.16666666666667, 1.0, 2.0, 0.333174704884044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513966.7101941255, 513966.7101941248, 167747.2171463742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1187400.0000, 
sim time next is 1188000.0000, 
raw observation next is [26.7, 62.0, 1.0, 2.0, 0.3364016361731424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 518897.0400071052, 518897.0400071052, 168134.409013522], 
processed observation next is [1.0, 0.782608695652174, 0.46445497630331756, 0.62, 1.0, 1.0, 0.20048389900378602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14413806666864035, 0.14413806666864035, 0.2509468791246597], 
reward next is 0.7491, 
noisyNet noise sample is [array([-1.2924875], dtype=float32), 0.05177676]. 
=============================================
[2019-03-26 11:01:16,069] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.96461 ]
 [73.64751 ]
 [73.09888 ]
 [72.07715 ]
 [69.853584]], R is [[74.22039032]
 [74.22782135]
 [74.23594666]
 [74.24465179]
 [74.25249481]].
[2019-03-26 11:01:20,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.1269226e-17 1.0000000e+00 4.9079427e-22 1.9423825e-12 9.7654095e-23], sum to 1.0000
[2019-03-26 11:01:20,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7034
[2019-03-26 11:01:20,832] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.83333333333333, 1.0, 2.0, 0.341666743957812, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527903.3872326761, 527903.3872326761, 168880.8325417688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 953400.0000, 
sim time next is 954000.0000, 
raw observation next is [21.8, 95.0, 1.0, 2.0, 0.3431374915803272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 529872.0780038765, 529872.0780038759, 169030.1340209157], 
processed observation next is [1.0, 0.043478260869565216, 0.23222748815165886, 0.95, 1.0, 1.0, 0.20859938744617734, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14718668833441015, 0.14718668833440998, 0.2522837821207697], 
reward next is 0.7477, 
noisyNet noise sample is [array([-1.8648015], dtype=float32), -0.8134925]. 
=============================================
[2019-03-26 11:01:20,846] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[69.27714 ]
 [69.171684]
 [69.170616]
 [69.21684 ]
 [69.68557 ]], R is [[69.46619415]
 [69.51947021]
 [69.5723877 ]
 [69.62478638]
 [69.67654419]].
[2019-03-26 11:01:25,842] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.1569249e-19 1.0000000e+00 7.5549619e-24 9.0102283e-15 1.6094159e-24], sum to 1.0000
[2019-03-26 11:01:25,848] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8286
[2019-03-26 11:01:25,854] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 96.83333333333334, 1.0, 2.0, 0.3536621284433131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 540985.6306283177, 540985.630628317, 169780.1251379909], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1047000.0000, 
sim time next is 1047600.0000, 
raw observation next is [21.7, 97.0, 1.0, 2.0, 0.3497808518227349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 537152.0915332764, 537152.091533277, 169531.2477243921], 
processed observation next is [1.0, 0.13043478260869565, 0.2274881516587678, 0.97, 1.0, 1.0, 0.21660343593100587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.149208914314799, 0.14920891431479916, 0.25303171302148075], 
reward next is 0.7470, 
noisyNet noise sample is [array([-1.4377635], dtype=float32), 0.6584519]. 
=============================================
[2019-03-26 11:01:27,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.8420968e-18 1.0000000e+00 6.7145291e-23 8.9201141e-15 6.3683747e-24], sum to 1.0000
[2019-03-26 11:01:27,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2769
[2019-03-26 11:01:27,998] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.3304369664384131, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522451.8271187349, 522451.8271187343, 168738.7956749833], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1066200.0000, 
sim time next is 1066800.0000, 
raw observation next is [21.1, 93.0, 1.0, 2.0, 0.4328314631610836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684621.5134002778, 684621.5134002785, 182991.014045255], 
processed observation next is [1.0, 0.34782608695652173, 0.1990521327014219, 0.93, 1.0, 1.0, 0.31666441344708873, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1901726426111883, 0.1901726426111885, 0.2731209164854552], 
reward next is 0.7269, 
noisyNet noise sample is [array([1.2533901], dtype=float32), 1.079311]. 
=============================================
[2019-03-26 11:01:28,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3045646e-16 1.0000000e+00 1.8548200e-20 1.6232519e-09 1.2591046e-21], sum to 1.0000
[2019-03-26 11:01:28,848] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4796
[2019-03-26 11:01:28,852] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 74.66666666666667, 1.0, 2.0, 0.3513624789805923, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 541945.5373656523, 541945.5373656517, 169996.6903790539], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1196400.0000, 
sim time next is 1197000.0000, 
raw observation next is [24.5, 75.5, 1.0, 2.0, 0.3516749710018386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 542032.8963588405, 542032.8963588398, 169992.5359783983], 
processed observation next is [1.0, 0.8695652173913043, 0.3601895734597157, 0.755, 1.0, 1.0, 0.21888550723113082, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15056469343301127, 0.15056469343301107, 0.25372020295283326], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.2977076], dtype=float32), -0.7882246]. 
=============================================
[2019-03-26 11:01:28,866] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.000496]
 [69.03069 ]
 [69.16323 ]
 [69.165306]
 [69.22409 ]], R is [[69.02867889]
 [69.08467102]
 [69.13994598]
 [69.19469452]
 [69.24914551]].
[2019-03-26 11:01:33,161] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3134613e-17 1.0000000e+00 7.5210137e-21 1.8813142e-09 1.2733531e-22], sum to 1.0000
[2019-03-26 11:01:33,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6170
[2019-03-26 11:01:33,179] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.7, 87.66666666666667, 1.0, 2.0, 0.3536174830784391, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546127.3581518098, 546127.3581518098, 170362.154002153], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1208400.0000, 
sim time next is 1209000.0000, 
raw observation next is [22.65, 87.83333333333334, 1.0, 2.0, 0.3526292549418842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 545029.5503396417, 545029.5503396412, 170282.855050377], 
processed observation next is [1.0, 1.0, 0.2725118483412322, 0.8783333333333334, 1.0, 1.0, 0.22003524691793275, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15139709731656714, 0.151397097316567, 0.25415351500056266], 
reward next is 0.7458, 
noisyNet noise sample is [array([1.8568615], dtype=float32), -0.49571186]. 
=============================================
[2019-03-26 11:01:33,191] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.95887]
 [71.99356]
 [72.0124 ]
 [72.06245]
 [72.12284]], R is [[71.96302795]
 [71.98912811]
 [72.01545715]
 [72.04104614]
 [72.06616974]].
[2019-03-26 11:01:47,527] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7110849e-22 1.0000000e+00 1.6592470e-28 2.8124753e-23 3.7489812e-29], sum to 1.0000
[2019-03-26 11:01:47,534] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7903
[2019-03-26 11:01:47,541] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 90.0, 1.0, 2.0, 0.3356613628532751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 522892.3927221135, 522892.3927221135, 168605.2287218404], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1411200.0000, 
sim time next is 1411800.0000, 
raw observation next is [22.25, 89.33333333333333, 1.0, 2.0, 0.336753372377344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 523885.4917722377, 523885.4917722377, 168664.6677373519], 
processed observation next is [0.0, 0.34782608695652173, 0.2535545023696683, 0.8933333333333333, 1.0, 1.0, 0.20090767756306505, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14552374771451046, 0.14552374771451046, 0.2517383100557491], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.8352582], dtype=float32), 0.63335633]. 
=============================================
[2019-03-26 11:01:47,902] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 11:01:47,903] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:01:47,903] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:01:47,906] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:01:47,906] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:01:47,907] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:01:47,908] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:01:47,910] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:01:47,910] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:01:47,911] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:01:47,914] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:01:47,934] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-26 11:01:47,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-26 11:01:47,977] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-26 11:01:47,996] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-26 11:01:47,998] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-26 11:01:51,733] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:01:51,737] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.61462879666667, 95.18025144666667, 1.0, 2.0, 0.2716661155674043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 441810.929716791, 441810.929716791, 163024.9574786051]
[2019-03-26 11:01:51,738] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:01:51,740] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.2266827e-22 1.0000000e+00 2.0468431e-27 3.4825899e-22 1.3655260e-28], sampled 0.964565028555251
[2019-03-26 11:01:59,653] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:01:59,654] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.36666666666667, 66.0, 1.0, 2.0, 0.2917691551458272, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466682.7730041854, 466682.7730041848, 164711.4541141483]
[2019-03-26 11:01:59,655] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:01:59,658] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3488739e-21 1.0000000e+00 7.9439618e-27 6.7423847e-21 3.4952229e-28], sampled 0.7643705357162579
[2019-03-26 11:02:10,316] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:02:10,317] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.66912425833333, 53.60349921833333, 1.0, 2.0, 0.3275356989453341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 514631.8070702758, 514631.8070702758, 168070.0296144037]
[2019-03-26 11:02:10,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:02:10,322] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.8521914e-21 1.0000000e+00 2.2873603e-26 3.5150818e-19 5.8644379e-28], sampled 0.19564280161431136
[2019-03-26 11:02:14,148] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:02:14,148] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.4, 91.66666666666667, 1.0, 2.0, 0.3680851459023657, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565221.28799966, 565221.28799966, 171890.5590601529]
[2019-03-26 11:02:14,149] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:02:14,152] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3331039e-21 1.0000000e+00 8.2649835e-27 1.1929203e-20 5.9175623e-28], sampled 0.8626083306537943
[2019-03-26 11:02:50,099] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:02:50,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [37.5, 46.5, 1.0, 2.0, 0.858331033568296, 1.0, 2.0, 0.7497555562984106, 1.0, 1.0, 1.03, 7.00511021973327, 6.9112, 170.5573041426782, 3146384.019725051, 3079112.309306609, 576002.872696265]
[2019-03-26 11:02:50,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:02:50,103] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1244568e-15 1.1418185e-03 2.1673342e-20 9.9885821e-01 1.1621344e-24], sampled 0.02070371791927761
[2019-03-26 11:03:16,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.24719258], dtype=float32), 0.100358635]
[2019-03-26 11:03:16,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.98038827, 79.39469509, 1.0, 2.0, 0.7863270649750469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1098976.90407318, 1098976.904073181, 240589.0054064606]
[2019-03-26 11:03:16,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:03:16,590] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3461278e-20 1.0000000e+00 1.0988118e-25 2.0909048e-18 1.0830185e-26], sampled 0.44762204087086344
[2019-03-26 11:03:42,738] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8288.9786 2923999229.9048 1260.0000
[2019-03-26 11:03:42,880] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8017.0445 3151937978.2666 1460.0000
[2019-03-26 11:03:42,958] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8681.8713 2777267506.1477 884.0000
[2019-03-26 11:03:43,186] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8065.6548 3001567085.6971 1607.0000
[2019-03-26 11:03:43,190] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8548.5319 2838259112.6818 1015.0000
[2019-03-26 11:03:44,204] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 675000, evaluation results [675000.0, 8017.044470227165, 3151937978.266562, 1460.0, 8288.978632725444, 2923999229.904835, 1260.0, 8681.87130653195, 2777267506.1476607, 884.0, 8065.654800258402, 3001567085.6971016, 1607.0, 8548.531921426236, 2838259112.68185, 1015.0]
[2019-03-26 11:03:44,698] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.34475075e-20 1.00000000e+00 1.52422121e-27 8.96330408e-21
 1.62078060e-27], sum to 1.0000
[2019-03-26 11:03:44,703] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9221
[2019-03-26 11:03:44,712] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 84.0, 1.0, 2.0, 0.4177568822889548, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 609179.9531312601, 609179.9531312594, 174987.1664184877], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1427400.0000, 
sim time next is 1428000.0000, 
raw observation next is [25.33333333333333, 82.33333333333334, 1.0, 2.0, 0.4220432983190036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 613200.330282592, 613200.3302825913, 175305.1974712079], 
processed observation next is [0.0, 0.5217391304347826, 0.3996840442338071, 0.8233333333333335, 1.0, 1.0, 0.3036666244807273, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17033342507849777, 0.17033342507849758, 0.2616495484644894], 
reward next is 0.7384, 
noisyNet noise sample is [array([1.4641583], dtype=float32), 0.1991762]. 
=============================================
[2019-03-26 11:03:44,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.625656]
 [76.62976 ]
 [76.64837 ]
 [76.67222 ]
 [76.64174 ]], R is [[76.61361694]
 [76.58630371]
 [76.55979919]
 [76.53414154]
 [76.5092926 ]].
[2019-03-26 11:03:52,982] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1115877e-18 1.0000000e+00 3.0338863e-22 1.6173820e-14 6.3609730e-23], sum to 1.0000
[2019-03-26 11:03:52,990] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7499
[2019-03-26 11:03:52,996] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.45, 85.0, 1.0, 2.0, 0.5584358961648915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 852950.3846322736, 852950.3846322736, 202073.3479479912], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1585800.0000, 
sim time next is 1586400.0000, 
raw observation next is [23.46666666666667, 85.0, 1.0, 2.0, 0.6278567526424211, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 958441.4162134654, 958441.4162134654, 216058.5645501286], 
processed observation next is [1.0, 0.34782608695652173, 0.31121642969984215, 0.85, 1.0, 1.0, 0.5516346417378568, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2662337267259626, 0.2662337267259626, 0.32247546947780387], 
reward next is 0.6775, 
noisyNet noise sample is [array([-0.43509582], dtype=float32), 0.41649246]. 
=============================================
[2019-03-26 11:03:55,768] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.4901921e-18 1.0000000e+00 4.1225391e-23 1.4393686e-11 5.1551035e-24], sum to 1.0000
[2019-03-26 11:03:55,775] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1916
[2019-03-26 11:03:55,782] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 95.66666666666666, 1.0, 2.0, 0.4117705017689461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 607493.277684888, 607493.2776848886, 175036.1080805592], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1621200.0000, 
sim time next is 1621800.0000, 
raw observation next is [23.1, 95.5, 1.0, 2.0, 0.4116340556942512, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607754.4664720419, 607754.4664720419, 175073.8917299772], 
processed observation next is [1.0, 0.782608695652174, 0.2938388625592418, 0.955, 1.0, 1.0, 0.29112536830632674, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16882068513112275, 0.16882068513112275, 0.26130431601489135], 
reward next is 0.7387, 
noisyNet noise sample is [array([0.4570834], dtype=float32), 0.30415165]. 
=============================================
[2019-03-26 11:04:00,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.9307591e-15 1.0000000e+00 3.9892963e-20 1.5641388e-09 2.5036560e-21], sum to 1.0000
[2019-03-26 11:04:00,623] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2531
[2019-03-26 11:04:00,628] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 94.0, 1.0, 2.0, 0.5637764497705771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790397.620084555, 790397.620084555, 194518.8143751693], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1737000.0000, 
sim time next is 1737600.0000, 
raw observation next is [24.53333333333333, 94.0, 1.0, 2.0, 0.5277877554670948, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740526.6961008434, 740526.6961008434, 188449.1569334539], 
processed observation next is [1.0, 0.08695652173913043, 0.36176935229067925, 0.94, 1.0, 1.0, 0.43106958490011416, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20570186002801205, 0.20570186002801205, 0.28126739840814013], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.6357437], dtype=float32), 1.4063203]. 
=============================================
[2019-03-26 11:04:10,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.4217315e-16 1.0000000e+00 1.0515724e-20 2.8512481e-10 9.8533124e-22], sum to 1.0000
[2019-03-26 11:04:10,244] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1605
[2019-03-26 11:04:10,249] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.55, 96.83333333333334, 1.0, 2.0, 0.5637536282232145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 787791.14109876, 787791.14109876, 194182.0596976558], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2177400.0000, 
sim time next is 2178000.0000, 
raw observation next is [24.5, 97.0, 1.0, 2.0, 0.558473430911198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780409.8657194518, 780409.8657194518, 193259.4443489104], 
processed observation next is [1.0, 0.21739130434782608, 0.3601895734597157, 0.97, 1.0, 1.0, 0.4680402782062627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2167805182554033, 0.2167805182554033, 0.28844693186404535], 
reward next is 0.7116, 
noisyNet noise sample is [array([0.8494289], dtype=float32), 0.7482071]. 
=============================================
[2019-03-26 11:04:10,263] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.92606 ]
 [65.832306]
 [65.882545]
 [65.97784 ]
 [65.90596 ]], R is [[65.98793793]
 [66.0382309 ]
 [66.08535767]
 [66.12794495]
 [66.16937256]].
[2019-03-26 11:04:11,076] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2489305e-15 9.9999940e-01 2.7295085e-18 6.4620423e-07 1.4409632e-19], sum to 1.0000
[2019-03-26 11:04:11,082] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1199
[2019-03-26 11:04:11,091] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.45, 91.66666666666667, 1.0, 2.0, 0.4515776399186808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644592.5742515107, 644592.5742515113, 178107.702219366], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896600.0000, 
sim time next is 1897200.0000, 
raw observation next is [24.4, 92.0, 1.0, 2.0, 0.4513999253238355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644504.4327146407, 644504.4327146407, 178102.8765773601], 
processed observation next is [1.0, 1.0, 0.3554502369668246, 0.92, 1.0, 1.0, 0.33903605460703073, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17902900908740021, 0.17902900908740021, 0.265825188921433], 
reward next is 0.7342, 
noisyNet noise sample is [array([-0.08406425], dtype=float32), 0.052648142]. 
=============================================
[2019-03-26 11:04:17,329] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1861009e-19 1.0000000e+00 2.1822752e-24 2.0641363e-16 1.5696452e-26], sum to 1.0000
[2019-03-26 11:04:17,337] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8611
[2019-03-26 11:04:17,347] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.86666666666667, 97.66666666666666, 1.0, 2.0, 0.456011304302776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 645689.8343248379, 645689.8343248379, 178088.6605319775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2090400.0000, 
sim time next is 2091000.0000, 
raw observation next is [23.83333333333334, 97.83333333333334, 1.0, 2.0, 0.4552583366142032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644983.9256269227, 644983.9256269227, 178025.2266158016], 
processed observation next is [0.0, 0.17391304347826086, 0.32859399684044266, 0.9783333333333334, 1.0, 1.0, 0.34368474290867856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17916220156303408, 0.17916220156303408, 0.2657092934564203], 
reward next is 0.7343, 
noisyNet noise sample is [array([-0.42232123], dtype=float32), -0.54747444]. 
=============================================
[2019-03-26 11:04:17,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[73.17876 ]
 [73.26761 ]
 [73.302155]
 [73.40047 ]
 [73.46139 ]], R is [[73.21360779]
 [73.21567535]
 [73.21757507]
 [73.21921539]
 [73.22055817]].
[2019-03-26 11:04:22,336] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4993314e-17 1.0000000e+00 1.8018098e-21 3.6966592e-09 3.2665133e-23], sum to 1.0000
[2019-03-26 11:04:22,346] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4346
[2019-03-26 11:04:22,352] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.65, 93.66666666666667, 1.0, 2.0, 0.4727235308802371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661211.2445657701, 661211.2445657701, 179518.6265454997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2069400.0000, 
sim time next is 2070000.0000, 
raw observation next is [24.6, 94.0, 1.0, 2.0, 0.472007039567803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660407.1712579873, 660407.1712579873, 179437.8043038484], 
processed observation next is [0.0, 1.0, 0.36492890995260674, 0.94, 1.0, 1.0, 0.3638639030937385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18344643646055203, 0.18344643646055203, 0.2678176183639528], 
reward next is 0.7322, 
noisyNet noise sample is [array([2.8724651], dtype=float32), -1.6437074]. 
=============================================
[2019-03-26 11:04:22,366] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.54228 ]
 [73.5231  ]
 [73.502235]
 [73.48977 ]
 [73.491104]], R is [[73.58065033]
 [73.5769043 ]
 [73.57315063]
 [73.56949615]
 [73.5658493 ]].
[2019-03-26 11:04:35,090] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3560634e-13 9.9820530e-01 3.9928993e-16 1.7946467e-03 2.2956750e-18], sum to 1.0000
[2019-03-26 11:04:35,100] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5712
[2019-03-26 11:04:35,109] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.01666666666667, 80.16666666666667, 1.0, 2.0, 0.5599498469338116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782473.7669935346, 782473.7669935353, 193521.8926222118], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2326200.0000, 
sim time next is 2326800.0000, 
raw observation next is [28.93333333333334, 80.33333333333334, 1.0, 2.0, 0.5577583194506925, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779410.203494566, 779410.203494566, 193140.3106760197], 
processed observation next is [1.0, 0.9565217391304348, 0.5703001579778835, 0.8033333333333335, 1.0, 1.0, 0.4671786981333645, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21650283430404613, 0.21650283430404613, 0.28826912041196967], 
reward next is 0.7117, 
noisyNet noise sample is [array([-0.79284817], dtype=float32), 0.45655587]. 
=============================================
[2019-03-26 11:04:38,756] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 11:04:38,760] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:04:38,760] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:04:38,762] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:04:38,763] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:04:38,764] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:04:38,767] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:04:38,767] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:04:38,768] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:04:38,769] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:04:38,771] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:04:38,784] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-26 11:04:38,804] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-26 11:04:38,828] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-26 11:04:38,828] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-26 11:04:38,865] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-26 11:04:50,277] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:04:50,280] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.13333333333333, 91.66666666666667, 1.0, 2.0, 0.4444644619803292, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 642955.604353909, 642955.604353909, 178155.7095884191]
[2019-03-26 11:04:50,281] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:04:50,283] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.8344499e-19 1.0000000e+00 1.2183647e-23 1.2277655e-16 1.0630693e-24], sampled 0.672740720331983
[2019-03-26 11:05:01,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:05:01,210] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.23200773166667, 52.48536661166667, 1.0, 2.0, 0.2856984539642531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462473.3868948107, 462473.3868948113, 164430.2826368814]
[2019-03-26 11:05:01,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:05:01,217] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.55772771e-18 1.00000000e+00 6.00258525e-23 1.38022045e-14
 1.92857874e-24], sampled 0.27173766278455225
[2019-03-26 11:05:15,783] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:05:15,786] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.77646186333333, 70.40460981333334, 1.0, 2.0, 0.7970313324018539, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1113945.119693033, 1113945.119693033, 243180.6996198174]
[2019-03-26 11:05:15,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:05:15,789] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.4832232e-15 1.0000000e+00 3.3698891e-19 3.5837793e-09 3.9638876e-20], sampled 0.9281024353678322
[2019-03-26 11:05:43,958] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:05:43,961] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 89.0, 1.0, 2.0, 0.507745637686434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709499.2557531429, 709499.2557531429, 184818.0670325271]
[2019-03-26 11:05:43,962] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:05:43,964] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2944848e-17 1.0000000e+00 3.2562900e-21 1.2210754e-11 1.3941849e-22], sampled 0.026747301776068877
[2019-03-26 11:05:52,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:05:52,616] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.46666666666667, 82.00000000000001, 1.0, 2.0, 0.5896341547900229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 823970.7002144251, 823970.7002144251, 198830.4935755036]
[2019-03-26 11:05:52,619] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:05:52,621] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.4313969e-17 1.0000000e+00 7.6108307e-21 8.7412633e-11 2.8753422e-22], sampled 0.4873296143732182
[2019-03-26 11:06:26,521] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23729764], dtype=float32), 0.09698596]
[2019-03-26 11:06:26,522] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.75, 57.0, 1.0, 2.0, 0.402967527249368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 602243.899963057, 602243.8999630576, 174769.2033544951]
[2019-03-26 11:06:26,523] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:06:26,527] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.61354241e-18 1.00000000e+00 3.77158690e-22 6.28973978e-13
 1.24828545e-23], sampled 0.018805267551596505
[2019-03-26 11:06:33,108] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8570.3765 2965458432.8339 514.0000
[2019-03-26 11:06:33,306] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8660.5633 2904588138.7039 514.0000
[2019-03-26 11:06:33,521] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8360.9899 3126076239.8078 600.0000
[2019-03-26 11:06:33,656] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8899.7861 2767516400.2128 431.0000
[2019-03-26 11:06:33,723] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8809.5061 2825340250.6360 433.0000
[2019-03-26 11:06:34,740] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 700000, evaluation results [700000.0, 8360.989866126913, 3126076239.8077803, 600.0, 8660.56330972791, 2904588138.7039413, 514.0, 8899.786107983873, 2767516400.2128158, 431.0, 8570.37645467645, 2965458432.833915, 514.0, 8809.506086406778, 2825340250.636047, 433.0]
[2019-03-26 11:06:34,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.7404187e-17 6.9763834e-13 1.3593171e-18 1.0000000e+00 5.2377736e-20], sum to 1.0000
[2019-03-26 11:06:34,953] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1780
[2019-03-26 11:06:34,961] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 67.0, 1.0, 2.0, 0.7649884219516139, 1.0, 2.0, 0.7649884219516139, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2139334.387328004, 2139334.387328004, 403186.0365638599], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2367600.0000, 
sim time next is 2368200.0000, 
raw observation next is [31.15, 66.5, 1.0, 2.0, 0.7720122109692515, 1.0, 2.0, 0.7720122109692515, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2158996.614972929, 2158996.614972929, 406475.7160006902], 
processed observation next is [1.0, 0.391304347826087, 0.6753554502369667, 0.665, 1.0, 1.0, 0.7253159168304235, 1.0, 1.0, 0.7253159168304235, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5997212819369248, 0.5997212819369248, 0.6066801731353585], 
reward next is 0.3933, 
noisyNet noise sample is [array([-0.65423614], dtype=float32), -2.6125157]. 
=============================================
[2019-03-26 11:06:54,026] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4735149e-22 1.0000000e+00 4.3155160e-27 3.3245924e-23 2.4419212e-28], sum to 1.0000
[2019-03-26 11:06:54,037] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3312
[2019-03-26 11:06:54,042] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3839574923437666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578313.4703016501, 578313.4703016507, 172724.3242511957], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2726400.0000, 
sim time next is 2727000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.384584214123953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579257.4708017122, 579257.4708017122, 172808.7553396233], 
processed observation next is [0.0, 0.5652173913043478, 0.2417061611374408, 1.0, 1.0, 1.0, 0.2585351977397024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16090485300047563, 0.16090485300047563, 0.2579235154322736], 
reward next is 0.7421, 
noisyNet noise sample is [array([-0.9763942], dtype=float32), 0.82736605]. 
=============================================
[2019-03-26 11:06:54,054] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.69568]
 [72.71342]
 [72.73865]
 [72.7136 ]
 [72.71122]], R is [[72.70571136]
 [72.72085571]
 [72.73582458]
 [72.75062561]
 [72.76525116]].
[2019-03-26 11:06:55,048] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7516638e-25 1.0000000e+00 9.4896903e-30 1.3047163e-26 2.5933166e-31], sum to 1.0000
[2019-03-26 11:06:55,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7212
[2019-03-26 11:06:55,063] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4791437419458264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 669519.7517283816, 669519.7517283816, 180392.6398217088], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2706000.0000, 
sim time next is 2706600.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4794286468688249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669917.9821609448, 669917.9821609443, 180435.5140849939], 
processed observation next is [0.0, 0.30434782608695654, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3728055986371384, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18608832837804024, 0.18608832837804007, 0.2693067374402894], 
reward next is 0.7307, 
noisyNet noise sample is [array([0.5049721], dtype=float32), -2.0468235]. 
=============================================
[2019-03-26 11:06:55,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7280001e-23 1.0000000e+00 1.3375987e-27 5.5734089e-21 2.6942075e-30], sum to 1.0000
[2019-03-26 11:06:55,455] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6063
[2019-03-26 11:06:55,459] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 97.0, 1.0, 2.0, 0.3618353811237724, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 552027.6834196736, 552027.6834196736, 170659.8012869209], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2755800.0000, 
sim time next is 2756400.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.3659199661941329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 556163.915749069, 556163.9157490697, 170946.395624512], 
processed observation next is [0.0, 0.9130434782608695, 0.2417061611374408, 0.98, 1.0, 1.0, 0.236048152041124, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1544899765969636, 0.15448997659696379, 0.2551438740664358], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.2331015], dtype=float32), -1.3517423]. 
=============================================
[2019-03-26 11:06:55,997] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.7178111e-22 1.0000000e+00 6.9060212e-27 1.5450976e-19 1.2367888e-27], sum to 1.0000
[2019-03-26 11:06:56,007] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0066
[2019-03-26 11:06:56,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.349903153279406, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 538978.7727720743, 538978.772772075, 169731.5328070277], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2761800.0000, 
sim time next is 2762400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3488612530156051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 537408.1714995031, 537408.1714995025, 169603.7349907542], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21549548556097, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14928004763875086, 0.1492800476387507, 0.2531399029712749], 
reward next is 0.7469, 
noisyNet noise sample is [array([-0.90718585], dtype=float32), -0.92582685]. 
=============================================
[2019-03-26 11:06:56,585] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3617328e-22 1.0000000e+00 3.7551560e-26 2.5660809e-21 4.5217917e-28], sum to 1.0000
[2019-03-26 11:06:56,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2090
[2019-03-26 11:06:56,603] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 98.0, 1.0, 2.0, 0.3373982223982597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 522797.1969140139, 522797.1969140145, 168518.1553707968], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3050400.0000, 
sim time next is 3051000.0000, 
raw observation next is [21.5, 97.0, 1.0, 2.0, 0.3374536420638731, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 522158.545047688, 522158.5450476874, 168445.3945084656], 
processed observation next is [1.0, 0.30434782608695654, 0.21800947867298584, 0.97, 1.0, 1.0, 0.20175137598057002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14504404029102444, 0.14504404029102427, 0.2514110365797994], 
reward next is 0.7486, 
noisyNet noise sample is [array([-0.9201854], dtype=float32), 0.63639456]. 
=============================================
[2019-03-26 11:06:56,613] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.83583 ]
 [70.801216]
 [70.839615]
 [70.78124 ]
 [70.73271 ]], R is [[70.91622925]
 [70.95555115]
 [70.99300385]
 [71.03125   ]
 [71.069664  ]].
[2019-03-26 11:06:56,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3555750e-23 1.0000000e+00 2.0253266e-29 1.7835017e-23 1.2903202e-30], sum to 1.0000
[2019-03-26 11:06:56,747] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4148
[2019-03-26 11:06:56,751] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3941241737290491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588092.7812811035, 588092.7812811041, 173442.9314072613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2738400.0000, 
sim time next is 2739000.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3942585765178038, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 588293.0676393362, 588293.0676393369, 173461.2461105632], 
processed observation next is [0.0, 0.6956521739130435, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2701910560455468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16341474101092673, 0.16341474101092693, 0.25889738225457193], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.5259648], dtype=float32), 0.32911628]. 
=============================================
[2019-03-26 11:06:56,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[76.543564]
 [76.50961 ]
 [76.483154]
 [76.46852 ]
 [76.46009 ]], R is [[76.54777527]
 [76.52342224]
 [76.49944305]
 [76.47575378]
 [76.45220184]].
[2019-03-26 11:06:59,856] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.9752992e-23 1.0000000e+00 3.1008381e-29 4.5963940e-23 1.3036105e-28], sum to 1.0000
[2019-03-26 11:06:59,863] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7426
[2019-03-26 11:06:59,868] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3411634716109478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 525558.265805555, 525558.2658055545, 168643.2708117133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2790000.0000, 
sim time next is 2790600.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.3761291680270729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579419.5824085322, 579419.5824085322, 173170.0991402411], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.24834839521334084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16094988400237004, 0.16094988400237004, 0.25846283453767327], 
reward next is 0.7415, 
noisyNet noise sample is [array([0.91032183], dtype=float32), 0.59093577]. 
=============================================
[2019-03-26 11:06:59,876] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.13216905e-20 1.00000000e+00 1.47958332e-25 3.26383301e-17
 1.03712443e-25], sum to 1.0000
[2019-03-26 11:06:59,884] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9311
[2019-03-26 11:06:59,888] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 89.0, 1.0, 2.0, 0.412121919392743, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607224.7099600784, 607224.7099600784, 174988.1797634892], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2831400.0000, 
sim time next is 2832000.0000, 
raw observation next is [24.0, 89.0, 1.0, 2.0, 0.4140642209017884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 610085.4948599548, 610085.4948599555, 175257.3911826799], 
processed observation next is [1.0, 0.782608695652174, 0.3364928909952607, 0.89, 1.0, 1.0, 0.29405327819492577, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1694681930166541, 0.1694681930166543, 0.2615781957950446], 
reward next is 0.7384, 
noisyNet noise sample is [array([1.8113312], dtype=float32), 0.46851698]. 
=============================================
[2019-03-26 11:06:59,913] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[72.85881 ]
 [72.78399 ]
 [72.75884 ]
 [72.70817 ]
 [72.531296]], R is [[72.9493103 ]
 [72.95864105]
 [72.96827698]
 [72.97819519]
 [72.9890976 ]].
[2019-03-26 11:07:15,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4306780e-19 1.0000000e+00 5.8111372e-24 4.2685464e-18 2.5580821e-24], sum to 1.0000
[2019-03-26 11:07:15,142] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9772
[2019-03-26 11:07:15,147] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.33333333333334, 98.0, 1.0, 2.0, 0.6486595879903222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 974129.8355814173, 974129.8355814167, 218717.7123971211], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3061200.0000, 
sim time next is 3061800.0000, 
raw observation next is [22.5, 97.0, 1.0, 2.0, 0.6609350207209435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 990986.3569492468, 990986.3569492475, 221214.5477177738], 
processed observation next is [1.0, 0.43478260869565216, 0.2654028436018958, 0.97, 1.0, 1.0, 0.591487976772221, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2752739880414575, 0.27527398804145764, 0.33017096674294594], 
reward next is 0.6698, 
noisyNet noise sample is [array([1.4290847], dtype=float32), 0.60137355]. 
=============================================
[2019-03-26 11:07:18,849] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9218634e-22 1.0000000e+00 3.4982946e-26 2.7914564e-19 2.8368105e-27], sum to 1.0000
[2019-03-26 11:07:18,856] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3376
[2019-03-26 11:07:18,860] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 96.0, 1.0, 2.0, 0.3742363454517803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 571630.6657486432, 571630.6657486426, 172365.7004848244], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3123600.0000, 
sim time next is 3124200.0000, 
raw observation next is [22.0, 95.0, 1.0, 2.0, 0.3673401473100638, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563160.8548989792, 563160.8548989792, 171688.6325612299], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.95, 1.0, 1.0, 0.2377592136265829, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.156433570805272, 0.156433570805272, 0.25625169038989537], 
reward next is 0.7437, 
noisyNet noise sample is [array([-0.4625678], dtype=float32), 1.5834451]. 
=============================================
[2019-03-26 11:07:19,811] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.4696285e-18 1.0000000e+00 6.2917116e-23 2.5609314e-14 2.2676000e-22], sum to 1.0000
[2019-03-26 11:07:19,816] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7883
[2019-03-26 11:07:19,823] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.5, 81.0, 1.0, 2.0, 0.864593050523171, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1256843.383140942, 1256843.383140942, 267330.9319995774], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3151800.0000, 
sim time next is 3152400.0000, 
raw observation next is [25.66666666666666, 80.33333333333334, 1.0, 2.0, 0.8477329814321128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1229115.629818144, 1229115.629818144, 262270.1081799117], 
processed observation next is [1.0, 0.4782608695652174, 0.4154818325434437, 0.8033333333333335, 1.0, 1.0, 0.8165457607615817, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3414210082828178, 0.3414210082828178, 0.3914479226565846], 
reward next is 0.6086, 
noisyNet noise sample is [array([0.74339825], dtype=float32), -1.2842069]. 
=============================================
[2019-03-26 11:07:25,027] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6991329e-24 1.0000000e+00 8.4373799e-29 1.1851565e-25 1.0834461e-30], sum to 1.0000
[2019-03-26 11:07:25,036] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8302
[2019-03-26 11:07:25,044] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 66.33333333333334, 1.0, 2.0, 0.5679490367116142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793656.0087628865, 793656.0087628871, 194927.5879631847], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3240600.0000, 
sim time next is 3241200.0000, 
raw observation next is [32.0, 65.66666666666667, 1.0, 2.0, 0.5659146935608056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790812.1449620173, 790812.1449620173, 194568.3191767216], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.6566666666666667, 1.0, 1.0, 0.4770056548925368, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21967004026722703, 0.21967004026722703, 0.2904004763831666], 
reward next is 0.7096, 
noisyNet noise sample is [array([-0.5131201], dtype=float32), -0.88499206]. 
=============================================
[2019-03-26 11:07:28,551] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 11:07:28,555] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:07:28,555] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:07:28,557] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:07:28,558] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:07:28,558] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:07:28,559] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:07:28,559] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:07:28,560] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:07:28,561] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:07:28,562] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:07:28,575] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-26 11:07:28,576] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-26 11:07:28,576] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-26 11:07:28,576] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-26 11:07:28,610] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-26 11:08:52,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.23892613], dtype=float32), 0.09656883]
[2019-03-26 11:08:52,192] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.02914139, 58.78765249, 1.0, 2.0, 0.5583869732555141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780289.0055557345, 780289.0055557345, 193249.8274957413]
[2019-03-26 11:08:52,193] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:08:52,195] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9262415e-23 1.0000000e+00 8.4250299e-29 3.5727279e-25 1.1003027e-29], sampled 0.11731361507375282
[2019-03-26 11:09:04,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23892613], dtype=float32), 0.09656883]
[2019-03-26 11:09:04,983] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.41298964333333, 60.01714489333334, 1.0, 2.0, 0.6599379449205842, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 943168.228585662, 943168.228585662, 215186.7247724855]
[2019-03-26 11:09:04,985] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:09:04,990] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3280448e-20 1.0000000e+00 6.3041499e-25 3.9411847e-18 1.1997169e-25], sampled 0.43703908546691617
[2019-03-26 11:09:07,276] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.23892613], dtype=float32), 0.09656883]
[2019-03-26 11:09:07,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.02882115, 52.08439544, 1.0, 2.0, 0.2397456596874434, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399031.9647276126, 399031.9647276132, 159486.5327102922]
[2019-03-26 11:09:07,278] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:09:07,281] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.7027764e-24 1.0000000e+00 3.8939076e-30 3.1964912e-27 3.7286107e-31], sampled 0.47875317028386943
[2019-03-26 11:09:09,061] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.23892613], dtype=float32), 0.09656883]
[2019-03-26 11:09:09,063] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.25, 61.5, 1.0, 2.0, 0.4478497822007853, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 639732.0855265777, 639732.0855265782, 177625.4804319562]
[2019-03-26 11:09:09,063] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:09:09,066] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4659766e-24 1.0000000e+00 1.7250601e-29 2.6048042e-26 2.0448811e-30], sampled 0.05089413742674853
[2019-03-26 11:09:19,338] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.23892613], dtype=float32), 0.09656883]
[2019-03-26 11:09:19,339] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.4, 54.0, 1.0, 2.0, 0.8946239028727809, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005987438800302, 6.9112, 168.9123159667295, 2147511.483698261, 2080266.267286544, 432567.3092036555]
[2019-03-26 11:09:19,341] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:09:19,345] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3486434e-19 1.0000000e+00 5.7005227e-24 2.1714321e-11 4.1506506e-27], sampled 0.4644744815659707
[2019-03-26 11:09:19,347] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2147511.483698261 W.
[2019-03-26 11:09:22,605] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.6388 2927389838.3989 1336.0000
[2019-03-26 11:09:22,880] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.3195 2842344797.2864 1129.0000
[2019-03-26 11:09:23,265] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.5665 3007608435.3115 1765.0000
[2019-03-26 11:09:23,269] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7897.4533 3162582360.9124 1746.0000
[2019-03-26 11:09:23,400] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8662.9122 2779142111.5619 928.0000
[2019-03-26 11:09:24,413] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 725000, evaluation results [725000.0, 7897.453263506643, 3162582360.9124146, 1746.0, 8255.638796961714, 2927389838.398896, 1336.0, 8662.912171120392, 2779142111.561914, 928.0, 7999.5664741980645, 3007608435.31148, 1765.0, 8499.31948517829, 2842344797.286356, 1129.0]
[2019-03-26 11:09:26,913] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.8396747e-20 1.0000000e+00 2.6006567e-24 5.5066813e-17 1.5139493e-24], sum to 1.0000
[2019-03-26 11:09:26,921] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3826
[2019-03-26 11:09:26,933] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1848552.030041358 W.
[2019-03-26 11:09:26,938] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.467326388646963, 6.9112, 168.90939050433, 1848552.030041358, 1454025.15877248, 311349.6983082551], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3378000.0000, 
sim time next is 3378600.0000, 
raw observation next is [26.15, 93.0, 1.0, 2.0, 0.5181004932398242, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8806120735705447, 6.911200000000001, 6.9112, 168.9125036384808, 1448440.888877579, 1448440.888877579, 314467.586356498], 
processed observation next is [1.0, 0.08695652173913043, 0.43838862559241704, 0.93, 1.0, 1.0, 0.4193981846262942, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.854404967768957, 8.881784197001253e-17, 0.0, 0.8294377213437016, 0.40234469135488304, 0.40234469135488304, 0.4693546065022358], 
reward next is 0.5306, 
noisyNet noise sample is [array([0.47888908], dtype=float32), -0.13134344]. 
=============================================
[2019-03-26 11:09:35,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.8492213e-12 1.4036083e-02 1.9550445e-13 9.8596394e-01 4.2999064e-15], sum to 1.0000
[2019-03-26 11:09:35,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6365
[2019-03-26 11:09:35,469] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.7542911363858472, 1.0, 2.0, 0.7542911363858472, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2109389.354361011, 2109389.354361012, 398224.452378284], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3491400.0000, 
sim time next is 3492000.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.7669166333044443, 1.0, 2.0, 0.7669166333044443, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2144732.140312088, 2144732.140312088, 404078.6064727858], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.66, 1.0, 1.0, 0.7191766666318605, 1.0, 1.0, 0.7191766666318605, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5957589278644689, 0.5957589278644689, 0.6031023977205758], 
reward next is 0.3969, 
noisyNet noise sample is [array([0.99932456], dtype=float32), -0.43764475]. 
=============================================
[2019-03-26 11:09:35,481] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[49.0679  ]
 [48.796555]
 [49.246292]
 [49.35112 ]
 [50.47351 ]], R is [[49.18264008]
 [48.69081497]
 [48.20390701]
 [47.72186661]
 [47.64060974]].
[2019-03-26 11:09:37,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.8920378e-24 1.0000000e+00 3.8024286e-30 1.8353952e-26 2.5455450e-31], sum to 1.0000
[2019-03-26 11:09:37,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3485
[2019-03-26 11:09:37,938] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.556248390816755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777299.4606370268, 777299.4606370262, 192878.5460170452], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525600.0000, 
sim time next is 3526200.0000, 
raw observation next is [29.5, 77.0, 1.0, 2.0, 0.5552167309940984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775857.2964768948, 775857.2964768953, 192699.7982324186], 
processed observation next is [1.0, 0.8260869565217391, 0.5971563981042655, 0.77, 1.0, 1.0, 0.4641165433663836, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21551591568802633, 0.21551591568802647, 0.2876116391528636], 
reward next is 0.7124, 
noisyNet noise sample is [array([-0.4843235], dtype=float32), 1.0895033]. 
=============================================
[2019-03-26 11:09:42,920] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.4493898e-24 1.0000000e+00 6.6103376e-28 9.8961269e-25 8.8701072e-28], sum to 1.0000
[2019-03-26 11:09:42,930] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4755
[2019-03-26 11:09:42,934] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5219144311735413, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729304.8407424163, 729304.8407424163, 187100.5978990221], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3621600.0000, 
sim time next is 3622200.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5201811884542626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726882.0397544084, 726882.0397544084, 186818.3332392653], 
processed observation next is [1.0, 0.9565217391304348, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.4219050463304369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2019116777095579, 0.2019116777095579, 0.2788333331929333], 
reward next is 0.7212, 
noisyNet noise sample is [array([-0.6390649], dtype=float32), -0.10913423]. 
=============================================
[2019-03-26 11:09:45,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.0314221e-16 1.0000000e+00 1.5517147e-17 5.0016341e-10 1.1617811e-18], sum to 1.0000
[2019-03-26 11:09:45,625] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3437
[2019-03-26 11:09:45,633] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1893346.882057774 W.
[2019-03-26 11:09:45,639] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333333, 65.33333333333334, 1.0, 2.0, 0.4514035119271945, 1.0, 2.0, 0.4514035119271945, 1.0, 2.0, 0.772344467121733, 6.911199999999999, 6.9112, 170.5573041426782, 1893346.882057774, 1893346.882057774, 381288.3710543618], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3750000.0000, 
sim time next is 3750600.0000, 
raw observation next is [30.66666666666667, 64.16666666666666, 1.0, 2.0, 0.4598542617893213, 1.0, 2.0, 0.4598542617893213, 1.0, 2.0, 0.7880183590590053, 6.911199999999999, 6.9112, 170.5573041426782, 1928824.238528999, 1928824.238528999, 386742.7532309571], 
processed observation next is [1.0, 0.391304347826087, 0.6524486571879939, 0.6416666666666666, 1.0, 1.0, 0.3492220021558088, 1.0, 1.0, 0.3492220021558088, 1.0, 1.0, 0.7414858037304943, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5357845107024998, 0.5357845107024998, 0.5772279898969509], 
reward next is 0.4228, 
noisyNet noise sample is [array([1.827449], dtype=float32), -1.5992749]. 
=============================================
[2019-03-26 11:09:48,945] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0933005e-26 1.0000000e+00 2.2214063e-32 1.0910574e-29 3.3930856e-32], sum to 1.0000
[2019-03-26 11:09:48,952] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5481
[2019-03-26 11:09:48,958] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5172292827914047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722755.7521721631, 722755.7521721631, 186339.6530535103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3807600.0000, 
sim time next is 3808200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5169078942163573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 722306.5037944618, 722306.5037944611, 186287.6925481673], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4179613183329606, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2006406954984616, 0.20064069549846142, 0.2780413321614437], 
reward next is 0.7220, 
noisyNet noise sample is [array([-0.94984907], dtype=float32), -1.1027529]. 
=============================================
[2019-03-26 11:09:57,223] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1616422e-28 1.0000000e+00 1.0641385e-35 5.2207751e-36 7.8710820e-35], sum to 1.0000
[2019-03-26 11:09:57,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0578
[2019-03-26 11:09:57,234] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 73.66666666666667, 1.0, 2.0, 0.6309860994818122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 881781.0125658162, 881781.0125658168, 206660.805679261], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3957600.0000, 
sim time next is 3958200.0000, 
raw observation next is [32.0, 73.0, 1.0, 2.0, 0.6216255229113851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868694.5845196096, 868694.5845196096, 204844.3145208912], 
processed observation next is [0.0, 0.8260869565217391, 0.7156398104265403, 0.73, 1.0, 1.0, 0.5441271360378133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2413040512554471, 0.2413040512554471, 0.3057377828670018], 
reward next is 0.6943, 
noisyNet noise sample is [array([1.0862008], dtype=float32), -0.4301575]. 
=============================================
[2019-03-26 11:09:59,379] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2036672e-27 1.0000000e+00 1.7952596e-34 7.7421047e-36 4.1707792e-33], sum to 1.0000
[2019-03-26 11:09:59,388] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2410
[2019-03-26 11:09:59,394] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 81.5, 1.0, 2.0, 0.5868360361909778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 820059.02419977, 820059.02419977, 198319.0129669711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3915000.0000, 
sim time next is 3915600.0000, 
raw observation next is [29.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5873009691091451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820708.9838378612, 820708.9838378606, 198403.9046008279], 
processed observation next is [0.0, 0.30434782608695654, 0.6050552922590839, 0.8066666666666668, 1.0, 1.0, 0.502772251938729, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22797471773273922, 0.22797471773273906, 0.2961252307475043], 
reward next is 0.7039, 
noisyNet noise sample is [array([-0.1302454], dtype=float32), 1.0026678]. 
=============================================
[2019-03-26 11:09:59,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.3308798e-28 1.0000000e+00 5.8214025e-34 6.9546598e-36 1.8009879e-33], sum to 1.0000
[2019-03-26 11:09:59,792] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8913
[2019-03-26 11:09:59,797] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.56965823253359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 796045.3461265904, 796045.3461265898, 195228.8253098582], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3906000.0000, 
sim time next is 3906600.0000, 
raw observation next is [27.0, 93.16666666666667, 1.0, 2.0, 0.5674161613056328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 792911.0869564826, 792911.0869564819, 194831.853932362], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.9316666666666668, 1.0, 1.0, 0.47881465217546115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22025307971013405, 0.22025307971013386, 0.2907938118393463], 
reward next is 0.7092, 
noisyNet noise sample is [array([-1.139539], dtype=float32), 0.09440943]. 
=============================================
[2019-03-26 11:10:03,351] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.1071383e-26 1.0000000e+00 4.7783620e-31 1.6319835e-29 2.4083929e-30], sum to 1.0000
[2019-03-26 11:10:03,365] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0614
[2019-03-26 11:10:03,371] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.5919392236872658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 827193.1200939014, 827193.1200939008, 199253.0817238713], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3978000.0000, 
sim time next is 3978600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.5909416752724208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 825798.5749622694, 825798.5749622694, 199069.8323283244], 
processed observation next is [1.0, 0.043478260869565216, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5071586449065311, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22938849304507483, 0.22938849304507483, 0.29711915272884243], 
reward next is 0.7029, 
noisyNet noise sample is [array([0.04646694], dtype=float32), -0.321985]. 
=============================================
[2019-03-26 11:10:08,234] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3283007e-24 1.0000000e+00 3.1900333e-28 4.0099843e-28 3.1924088e-27], sum to 1.0000
[2019-03-26 11:10:08,243] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4059
[2019-03-26 11:10:08,247] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.53333333333333, 86.33333333333334, 1.0, 2.0, 0.5552209691416199, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9500166879224022, 6.9112, 6.9112, 168.912413409552, 1552293.578945326, 1552293.578945326, 336798.199211334], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4069200.0000, 
sim time next is 4069800.0000, 
raw observation next is [27.5, 86.5, 1.0, 2.0, 0.9830752668192215, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129563748145, 1374131.684517156, 1374131.684517155, 293811.9642964303], 
processed observation next is [1.0, 0.08695652173913043, 0.5023696682464456, 0.865, 1.0, 1.0, 0.9796087552038814, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399444863636, 0.38170324569921005, 0.3817032456992097, 0.43852531984541837], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19385658], dtype=float32), 0.68131185]. 
=============================================
[2019-03-26 11:10:08,751] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7854509e-31 1.0000000e+00 1.9375982e-38 0.0000000e+00 2.6182499e-36], sum to 1.0000
[2019-03-26 11:10:08,759] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5579
[2019-03-26 11:10:08,766] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5435760300077559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759584.8184712358, 759584.8184712352, 190705.3339932352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4049400.0000, 
sim time next is 4050000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5430151983184947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758800.8409369349, 758800.8409369349, 190610.3056436918], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4494159015885478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2107780113713708, 0.2107780113713708, 0.28449299349804746], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.65003735], dtype=float32), -0.47697443]. 
=============================================
[2019-03-26 11:10:08,781] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.79105]
 [65.5875 ]
 [65.48174]
 [65.25486]
 [65.24205]], R is [[66.19371796]
 [66.24714661]
 [66.29980469]
 [66.35166931]
 [66.4029007 ]].
[2019-03-26 11:10:11,135] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5252942e-16 1.0000000e+00 1.3694610e-18 1.4830238e-11 8.3087046e-19], sum to 1.0000
[2019-03-26 11:10:11,141] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7916
[2019-03-26 11:10:11,148] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2815728.880003625 W.
[2019-03-26 11:10:11,152] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.0, 65.5, 1.0, 2.0, 1.006578097356563, 1.0, 2.0, 1.006578097356563, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2815728.880003625, 2815728.880003625, 532990.2296726438], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4113000.0000, 
sim time next is 4113600.0000, 
raw observation next is [35.33333333333334, 65.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.310128173674946, 6.9112, 170.5573041426782, 3195431.082221909, 2909662.604057954, 551538.6015575159], 
processed observation next is [1.0, 0.6086956521739131, 0.8736176935229073, 0.65, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.039892817367494615, 0.0, 0.8375144448122397, 0.8876197450616414, 0.8082396122383206, 0.8231919426231581], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.421965], dtype=float32), -0.4181543]. 
=============================================
[2019-03-26 11:10:11,650] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.9820742e-15 9.9999988e-01 4.3592845e-17 1.6658399e-07 1.7408368e-17], sum to 1.0000
[2019-03-26 11:10:11,659] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6031
[2019-03-26 11:10:11,668] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2499874.50039413 W.
[2019-03-26 11:10:11,673] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.83333333333333, 71.0, 1.0, 2.0, 0.8937780542717919, 1.0, 2.0, 0.8937780542717919, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2499874.50039413, 2499874.50039413, 468121.8823685332], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4103400.0000, 
sim time next is 4104000.0000, 
raw observation next is [33.0, 71.0, 1.0, 2.0, 0.6431150492850486, 1.0, 2.0, 0.6421475641567868, 1.0, 1.0, 1.03, 7.005093247259266, 6.9112, 170.5573041426782, 2694315.048210035, 2627055.495865118, 503963.927027899], 
processed observation next is [1.0, 0.5217391304347826, 0.7630331753554502, 0.71, 1.0, 1.0, 0.5700181316687333, 1.0, 1.0, 0.5688524869358876, 1.0, 0.5, 1.0365853658536586, 0.009389324725926596, 0.0, 0.8375144448122397, 0.7484208467250097, 0.7297376377403106, 0.7521849657132821], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25133106], dtype=float32), -1.2261546]. 
=============================================
[2019-03-26 11:10:11,682] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[42.814987]
 [42.68449 ]
 [41.59757 ]
 [41.53972 ]
 [41.07152 ]], R is [[41.47021484]
 [41.35682297]
 [41.24497223]
 [40.83252335]
 [40.45906448]].
[2019-03-26 11:10:13,253] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9555204e-26 1.0000000e+00 2.6218447e-31 1.0607824e-28 2.6354245e-29], sum to 1.0000
[2019-03-26 11:10:13,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-26 11:10:13,268] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 88.16666666666667, 1.0, 2.0, 0.5735233691821542, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 801448.5592447157, 801448.559244715, 195917.0501734224], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4150200.0000, 
sim time next is 4150800.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.5718945443550654, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 799171.5632612206, 799171.5632612206, 195626.7505424489], 
processed observation next is [1.0, 0.043478260869565216, 0.5260663507109005, 0.89, 1.0, 1.0, 0.4842102944036932, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2219921009058946, 0.2219921009058946, 0.2919802246902222], 
reward next is 0.7080, 
noisyNet noise sample is [array([0.2941112], dtype=float32), -1.4727011]. 
=============================================
[2019-03-26 11:10:17,489] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1092892e-22 1.0000000e+00 7.3650145e-25 6.2029635e-23 4.7530704e-25], sum to 1.0000
[2019-03-26 11:10:17,499] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7059
[2019-03-26 11:10:17,503] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.099001508838299, 6.9112, 168.9117969979622, 1587078.111141096, 1453846.171726512, 311352.5926285861], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4246200.0000, 
sim time next is 4246800.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.422536979390854, 6.9112, 168.9098553411121, 1816756.78196211, 1454003.390040335, 311352.6397203595], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.05113369793908538, 0.0, 0.8294247169912253, 0.5046546616561417, 0.4038898305667597, 0.46470543241844703], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.276311], dtype=float32), -0.42804995]. 
=============================================
[2019-03-26 11:10:17,912] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2317571e-32 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.5217673e-38], sum to 1.0000
[2019-03-26 11:10:17,923] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5289
[2019-03-26 11:10:17,932] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.5, 65.5, 1.0, 2.0, 0.6084434744291457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 850265.8725331981, 850265.8725331975, 202330.8089788183], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4217400.0000, 
sim time next is 4218000.0000, 
raw observation next is [33.33333333333334, 67.33333333333333, 1.0, 2.0, 0.616656230138146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861747.397183462, 861747.397183462, 203891.3357227084], 
processed observation next is [1.0, 0.8260869565217391, 0.7788309636650873, 0.6733333333333333, 1.0, 1.0, 0.5381400363110193, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23937427699540612, 0.23937427699540612, 0.3043154264518036], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.17254663], dtype=float32), -0.1117001]. 
=============================================
[2019-03-26 11:10:17,948] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[64.11317 ]
 [64.236565]
 [64.309166]
 [64.51742 ]
 [64.678665]], R is [[64.05217743]
 [64.10967255]
 [64.16836548]
 [64.2273407 ]
 [64.28843689]].
[2019-03-26 11:10:18,956] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 11:10:18,959] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:10:18,960] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:10:18,962] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:10:18,963] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:10:18,963] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:10:18,965] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:10:18,964] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:10:18,966] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:10:18,967] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:10:18,969] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:10:18,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-26 11:10:18,989] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-26 11:10:19,024] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-26 11:10:19,042] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-26 11:10:19,065] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-26 11:10:26,294] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2389097], dtype=float32), 0.09093522]
[2019-03-26 11:10:26,296] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.4, 89.16666666666667, 1.0, 2.0, 0.3401904145298535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 527453.4630382175, 527453.4630382181, 168899.1419570072]
[2019-03-26 11:10:26,297] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:10:26,300] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3516054e-31 1.0000000e+00 9.9525845e-38 0.0000000e+00 6.7885001e-37], sampled 0.8077673256014333
[2019-03-26 11:11:15,401] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2389097], dtype=float32), 0.09093522]
[2019-03-26 11:11:15,404] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.88333333333333, 47.33333333333334, 1.0, 2.0, 0.6152117240026111, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 859727.9523993992, 859727.9523993998, 203612.8204805707]
[2019-03-26 11:11:15,405] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:11:15,407] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.7001873e-31 1.0000000e+00 2.5252652e-37 0.0000000e+00 1.1739235e-36], sampled 0.5910899209558922
[2019-03-26 11:11:22,606] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2389097], dtype=float32), 0.09093522]
[2019-03-26 11:11:22,607] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 59.00000000000001, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.846459392308724, 6.9112, 170.5573041426782, 3580074.542773947, 2910110.196143506, 548303.3970677062]
[2019-03-26 11:11:22,609] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:11:22,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4494812e-20 1.0000000e+00 8.2882608e-25 2.4394348e-21 2.8884876e-24], sampled 0.03278803828839849
[2019-03-26 11:11:22,614] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3580074.542773947 W.
[2019-03-26 11:11:49,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2389097], dtype=float32), 0.09093522]
[2019-03-26 11:11:49,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.5, 85.0, 1.0, 2.0, 0.5310323353892278, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742050.3291968158, 742050.3291968158, 188601.2464162806]
[2019-03-26 11:11:49,234] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:11:49,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7170880e-31 1.0000000e+00 3.3337742e-38 0.0000000e+00 3.1641557e-37], sampled 0.7035823638307612
[2019-03-26 11:12:02,339] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2389097], dtype=float32), 0.09093522]
[2019-03-26 11:12:02,340] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.93205788833334, 70.84272046166667, 1.0, 2.0, 0.7261012616176405, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1059298.690074257, 1059298.690074257, 232530.6576509632]
[2019-03-26 11:12:02,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:12:02,345] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.0310219e-28 1.0000000e+00 5.7264735e-34 6.2040825e-36 6.6910226e-33], sampled 0.5896232589811666
[2019-03-26 11:12:13,730] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 11:12:14,057] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 11:12:14,242] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.8892 2779214977.1528 933.0000
[2019-03-26 11:12:14,315] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164071917.9177 1778.0000
[2019-03-26 11:12:14,322] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 11:12:15,341] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 750000, evaluation results [750000.0, 7884.168443086554, 3164071917.9176674, 1778.0, 8255.065342017213, 2927317329.746172, 1338.0, 8659.889248757021, 2779214977.1528425, 933.0, 7998.955910945021, 3007647868.858331, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 11:12:19,387] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.9865717e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.1668821e-38], sum to 1.0000
[2019-03-26 11:12:19,398] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0395
[2019-03-26 11:12:19,409] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.33333333333334, 54.33333333333334, 1.0, 2.0, 0.5835988815907122, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815533.6085446333, 815533.6085446333, 197731.589412702], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4303200.0000, 
sim time next is 4303800.0000, 
raw observation next is [35.0, 56.5, 1.0, 2.0, 0.5881749164391958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821930.732113032, 821930.732113032, 198565.1163955955], 
processed observation next is [1.0, 0.8260869565217391, 0.8578199052132701, 0.565, 1.0, 1.0, 0.5038252005291516, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22831409225362, 0.22831409225362, 0.29636584536656047], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.9674803], dtype=float32), -0.84368944]. 
=============================================
[2019-03-26 11:12:39,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6549802e-29 1.0000000e+00 3.1483757e-34 2.8146876e-37 2.5291071e-33], sum to 1.0000
[2019-03-26 11:12:39,532] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1333
[2019-03-26 11:12:39,537] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 86.5, 1.0, 2.0, 0.5172810214406194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722828.0743134439, 722828.0743134439, 186348.385325485], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671000.0000, 
sim time next is 4671600.0000, 
raw observation next is [27.0, 87.33333333333333, 1.0, 2.0, 0.5210692160865329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728123.3621637849, 728123.3621637849, 186963.5268261094], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.8733333333333333, 1.0, 1.0, 0.42297495914040106, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20225648948994027, 0.20225648948994027, 0.2790500400389692], 
reward next is 0.7209, 
noisyNet noise sample is [array([1.6861748], dtype=float32), -0.8250356]. 
=============================================
[2019-03-26 11:12:39,983] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.0398946e-35 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 11:12:39,992] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7491
[2019-03-26 11:12:39,997] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666666, 94.0, 1.0, 2.0, 0.4558572356147115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650958.3237914713, 650958.3237914713, 178766.5752197482], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4656000.0000, 
sim time next is 4656600.0000, 
raw observation next is [24.25, 94.0, 1.0, 2.0, 0.4596692198115073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 654075.6781767484, 654075.6781767484, 179033.3958349618], 
processed observation next is [1.0, 0.9130434782608695, 0.3483412322274882, 0.94, 1.0, 1.0, 0.3489990600138642, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18168768838243013, 0.18168768838243013, 0.2672140236342713], 
reward next is 0.7328, 
noisyNet noise sample is [array([2.2603364], dtype=float32), -0.687415]. 
=============================================
[2019-03-26 11:12:40,261] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.0422594e-32 1.0000000e+00 1.0211716e-37 0.0000000e+00 7.6290559e-36], sum to 1.0000
[2019-03-26 11:12:40,270] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5139
[2019-03-26 11:12:40,276] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.75, 94.0, 1.0, 2.0, 0.4832657363366631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675281.3501446685, 675281.3501446685, 181015.265353408], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4660200.0000, 
sim time next is 4660800.0000, 
raw observation next is [24.83333333333333, 94.0, 1.0, 2.0, 0.485225621398558, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 678020.8288486532, 678020.8288486532, 181313.2733322842], 
processed observation next is [1.0, 0.9565217391304348, 0.3759873617693521, 0.94, 1.0, 1.0, 0.37978990529946755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1883391191246259, 0.1883391191246259, 0.2706168258690809], 
reward next is 0.7294, 
noisyNet noise sample is [array([-0.39694622], dtype=float32), -0.053872064]. 
=============================================
[2019-03-26 11:12:46,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.0741517e-31 1.0000000e+00 2.3326316e-36 0.0000000e+00 1.1099121e-33], sum to 1.0000
[2019-03-26 11:12:46,964] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8041
[2019-03-26 11:12:46,974] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6311768945550326, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 882047.7527259204, 882047.7527259204, 206687.8484651671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4769400.0000, 
sim time next is 4770000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.5970820639323688, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 834382.6977638899, 834382.6977638893, 200195.5653108609], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5145567035329744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23177297160108054, 0.23177297160108037, 0.29879935121024015], 
reward next is 0.7012, 
noisyNet noise sample is [array([1.234395], dtype=float32), -0.7199341]. 
=============================================
[2019-03-26 11:12:46,991] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[62.363823]
 [62.447063]
 [62.67536 ]
 [62.746353]
 [62.585766]], R is [[62.61943054]
 [62.68474579]
 [62.74953461]
 [62.81647873]
 [62.88367844]].
[2019-03-26 11:12:47,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6848047e-20 1.0000000e+00 8.3332600e-22 2.9315767e-19 1.4448376e-21], sum to 1.0000
[2019-03-26 11:12:47,803] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-26 11:12:47,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2107066.951155386 W.
[2019-03-26 11:12:47,813] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8657284829482178, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990314234689772, 6.9112, 168.9124159547557, 2107066.951155386, 2050940.76978037, 425314.4390392008], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4791600.0000, 
sim time next is 4792200.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.736806148972326, 1.0, 1.0, 0.736806148972326, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2060445.232803079, 2060445.232803079, 390278.3269511515], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.682898974665453, 1.0, 0.5, 0.682898974665453, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5723458980008553, 0.5723458980008553, 0.5825049655987335], 
reward next is 0.4175, 
noisyNet noise sample is [array([0.27303255], dtype=float32), 1.008795]. 
=============================================
[2019-03-26 11:12:50,116] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.2329683e-30 1.0000000e+00 9.4230394e-35 0.0000000e+00 4.6057760e-34], sum to 1.0000
[2019-03-26 11:12:50,126] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5313
[2019-03-26 11:12:50,129] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.9061958704639533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266606.414811186, 1266606.414811186, 271644.1817014953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4846800.0000, 
sim time next is 4847400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7957369330861369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1112135.096893048, 1112135.096893047, 242863.5803199192], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.7538999193808879, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3089264158036244, 0.3089264158036242, 0.3624829557013719], 
reward next is 0.6375, 
noisyNet noise sample is [array([0.06394145], dtype=float32), -0.9809924]. 
=============================================
[2019-03-26 11:12:50,356] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.5909675e-31 1.0000000e+00 3.9334412e-37 0.0000000e+00 1.3740226e-35], sum to 1.0000
[2019-03-26 11:12:50,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2404
[2019-03-26 11:12:50,370] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.7784100719663944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1087906.384181408, 1087906.384181408, 238677.8849038491], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4936200.0000, 
sim time next is 4936800.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.7022977460847524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 981482.5938460127, 981482.5938460134, 221339.6337884504], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.6413225856442799, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27263405384611467, 0.27263405384611483, 0.3303576623708215], 
reward next is 0.6696, 
noisyNet noise sample is [array([0.39550373], dtype=float32), 0.593501]. 
=============================================
[2019-03-26 11:12:52,204] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.2051739e-25 1.0000000e+00 2.2313379e-29 2.3334575e-30 8.0334028e-27], sum to 1.0000
[2019-03-26 11:12:52,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4075
[2019-03-26 11:12:52,222] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1796271.616554048 W.
[2019-03-26 11:12:52,224] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.4282786341173825, 1.0, 2.0, 0.4282786341173825, 1.0, 1.0, 0.7341734124890902, 6.9112, 6.9112, 170.5573041426782, 1796271.616554048, 1796271.616554048, 367632.040165932], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4870200.0000, 
sim time next is 4870800.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.6456467086087625, 1.0, 2.0, 0.6456467086087625, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1805307.184545545, 1805307.184545545, 351720.5067997251], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.74, 1.0, 1.0, 0.573068323625015, 1.0, 1.0, 0.573068323625015, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.501474217929318, 0.501474217929318, 0.5249559802980972], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2932793], dtype=float32), -0.624135]. 
=============================================
[2019-03-26 11:12:53,615] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6835640e-21 1.0000000e+00 6.7955890e-25 6.9694990e-23 1.9034371e-23], sum to 1.0000
[2019-03-26 11:12:53,622] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8162
[2019-03-26 11:12:53,628] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1924889.077629518 W.
[2019-03-26 11:12:53,633] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.6883753731455702, 1.0, 2.0, 0.6883753731455702, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1924889.077629518, 1924889.077629518, 369187.6531181111], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4885200.0000, 
sim time next is 4885800.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.7267366777366098, 1.0, 2.0, 0.7267366777366098, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2032259.70023027, 2032259.70023027, 385780.1116544378], 
processed observation next is [1.0, 0.5652173913043478, 0.6761453396524489, 0.655, 1.0, 1.0, 0.6707670816103732, 1.0, 1.0, 0.6707670816103732, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5645165833972972, 0.5645165833972972, 0.575791211424534], 
reward next is 0.4242, 
noisyNet noise sample is [array([1.4925836], dtype=float32), -1.5176167]. 
=============================================
[2019-03-26 11:12:56,732] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5220362e-20 1.0000000e+00 6.5814192e-23 3.2987991e-21 6.7740175e-21], sum to 1.0000
[2019-03-26 11:12:56,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5663
[2019-03-26 11:12:56,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2053230.575807936 W.
[2019-03-26 11:12:56,755] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 69.33333333333333, 1.0, 2.0, 0.7342286894251856, 1.0, 2.0, 0.7342286894251856, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2053230.575807936, 2053230.575807936, 389118.5422096689], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4960200.0000, 
sim time next is 4960800.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.6487090859519588, 1.0, 2.0, 0.6487090859519588, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1813877.213913962, 1813877.213913963, 352938.5178165791], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.7, 1.0, 1.0, 0.576757934881878, 1.0, 1.0, 0.576757934881878, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5038547816427672, 0.5038547816427675, 0.526773907188924], 
reward next is 0.4732, 
noisyNet noise sample is [array([-1.0227481], dtype=float32), 1.5066354]. 
=============================================
[2019-03-26 11:13:05,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6179018e-34 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 11:13:05,584] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9318
[2019-03-26 11:13:05,587] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5121259760916383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 715622.1910551882, 715622.1910551875, 185517.6304398416], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5131200.0000, 
sim time next is 5131800.0000, 
raw observation next is [30.0, 66.0, 1.0, 2.0, 0.5104630775478667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713297.7500051999, 713297.7500052005, 185251.6245727143], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 1.0, 1.0, 0.41019647897333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813826389033332, 0.19813826389033348, 0.2764949620488273], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.59031457], dtype=float32), 0.4648954]. 
=============================================
[2019-03-26 11:13:09,937] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 11:13:09,939] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:13:09,940] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:13:09,941] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:13:09,944] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:13:09,944] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:13:09,946] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:13:09,947] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:13:09,948] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:13:09,950] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:13:09,951] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:13:09,963] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-26 11:13:09,964] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-26 11:13:09,965] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-26 11:13:09,984] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-26 11:13:10,042] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-26 11:13:16,072] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:13:16,073] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.0, 71.0, 1.0, 2.0, 0.2672205707260763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 442857.4662677969, 442857.4662677969, 162494.1515938813]
[2019-03-26 11:13:16,073] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:13:16,075] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3183416e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6051559e-38], sampled 0.587864197822271
[2019-03-26 11:13:29,177] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:13:29,178] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [19.23333333333333, 84.33333333333333, 1.0, 2.0, 0.232489832919233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 385477.745498446, 385477.745498446, 159051.1961745219]
[2019-03-26 11:13:29,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:13:29,183] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.796286e-33 1.000000e+00 0.000000e+00 0.000000e+00 1.882374e-38], sampled 0.43577296815549904
[2019-03-26 11:13:30,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:13:30,831] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.15605391, 87.76808881, 1.0, 2.0, 0.5867553907552943, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819946.2847973249, 819946.2847973249, 198305.9806321736]
[2019-03-26 11:13:30,834] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:13:30,838] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.5003731e-33 1.0000000e+00 0.0000000e+00 0.0000000e+00 6.2313523e-38], sampled 0.6775718244386258
[2019-03-26 11:13:59,687] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:13:59,689] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.71857388, 58.71101154, 1.0, 2.0, 0.5672254165944928, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9850829643129098, 6.911200000000001, 6.9112, 168.9129243487254, 1585880.829870811, 1585880.829870811, 347045.1873903847]
[2019-03-26 11:13:59,690] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:13:59,692] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.9426946e-26 1.0000000e+00 2.5174353e-30 3.7001345e-29 1.3673028e-29], sampled 0.6384205301662091
[2019-03-26 11:14:24,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:14:24,418] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 67.0, 1.0, 2.0, 0.6215377155814633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 868571.8274275868, 868571.8274275868, 204826.2818455796]
[2019-03-26 11:14:24,420] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:14:24,422] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.358651e-33 1.000000e+00 0.000000e+00 0.000000e+00 7.051949e-38], sampled 0.9952731951751727
[2019-03-26 11:14:44,229] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:14:44,230] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.48116917, 53.27137458, 1.0, 2.0, 0.7801186617888414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1133961.424820707, 1133961.424820708, 245087.9053865278]
[2019-03-26 11:14:44,231] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:14:44,235] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8824760e-29 1.0000000e+00 5.8785055e-35 2.0028902e-38 4.0524936e-33], sampled 0.4536545592696034
[2019-03-26 11:14:47,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2520864], dtype=float32), 0.09003056]
[2019-03-26 11:14:47,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.9, 70.5, 1.0, 2.0, 0.713258225599343, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.002632588021792, 6.9112, 168.9123780048363, 1893681.908368297, 1828816.705714728, 387673.9720721609]
[2019-03-26 11:14:47,888] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:14:47,890] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9604293e-26 1.0000000e+00 1.5954616e-30 8.0611641e-32 4.3283055e-29], sampled 0.6967305960439908
[2019-03-26 11:14:47,891] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1893681.908368297 W.
[2019-03-26 11:15:04,699] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4791 3007658023.9129 1766.0000
[2019-03-26 11:15:04,785] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.6119 2842427357.4275 1131.0000
[2019-03-26 11:15:04,925] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.1610 2927253227.7716 1338.0000
[2019-03-26 11:15:04,986] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164131021.0653 1778.0000
[2019-03-26 11:15:05,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4676 2779124528.0117 933.0000
[2019-03-26 11:15:06,085] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 775000, evaluation results [775000.0, 7883.4188199173295, 3164131021.06526, 1778.0, 8255.161016606155, 2927253227.7715816, 1338.0, 8661.467580702742, 2779124528.011676, 933.0, 7997.4790539186915, 3007658023.9129057, 1766.0, 8497.61193292354, 2842427357.427519, 1131.0]
[2019-03-26 11:15:13,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5477375e-14 1.0000000e+00 1.3633913e-14 2.3908946e-08 1.0623561e-12], sum to 1.0000
[2019-03-26 11:15:13,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2323
[2019-03-26 11:15:13,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2823620.527666676 W.
[2019-03-26 11:15:13,549] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.85, 48.5, 1.0, 2.0, 1.009396050559058, 1.0, 2.0, 1.009396050559058, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2823620.527666676, 2823620.527666676, 534687.0272431601], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5499000.0000, 
sim time next is 5499600.0000, 
raw observation next is [35.73333333333333, 48.66666666666666, 1.0, 2.0, 1.019575627402072, 1.0, 2.0, 1.019575627402072, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2852128.738575005, 2852128.738575005, 540924.497431259], 
processed observation next is [1.0, 0.6521739130434783, 0.8925750394944705, 0.4866666666666666, 1.0, 1.0, 1.0235850932555084, 1.0, 1.0, 1.0235850932555084, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7922579829375014, 0.7922579829375014, 0.8073499961660583], 
reward next is 0.1927, 
noisyNet noise sample is [array([-0.75254333], dtype=float32), 0.8441844]. 
=============================================
[2019-03-26 11:15:14,853] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.62240597e-13 1.00000000e+00 1.04434046e-13 4.38969252e-08
 4.98281659e-11], sum to 1.0000
[2019-03-26 11:15:14,866] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1493
[2019-03-26 11:15:14,875] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3341145.081005411 W.
[2019-03-26 11:15:14,884] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.93333333333333, 53.66666666666667, 1.0, 2.0, 0.9510267135692662, 1.0, 2.0, 0.7961033962988955, 1.0, 1.0, 1.03, 7.005117533732413, 6.9112, 170.5573041426782, 3341145.081005411, 3273868.131271867, 612351.2710487803], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5330400.0000, 
sim time next is 5331000.0000, 
raw observation next is [35.91666666666666, 53.83333333333333, 1.0, 2.0, 0.8412236323287141, 1.0, 2.0, 0.7412018556786196, 1.0, 2.0, 1.03, 7.00510887015128, 6.9112, 170.5573041426782, 3110443.316972394, 3043172.573314428, 569645.7487954247], 
processed observation next is [1.0, 0.6956521739130435, 0.9012638230647705, 0.5383333333333333, 1.0, 1.0, 0.8087031714803784, 1.0, 1.0, 0.6881950068417104, 1.0, 1.0, 1.0365853658536586, 0.00939088701512798, 0.0, 0.8375144448122397, 0.8640120324923317, 0.8453257148095633, 0.8502175355155592], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.43354255], dtype=float32), 1.4043612]. 
=============================================
[2019-03-26 11:15:14,904] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[20.507473]
 [21.709873]
 [21.324936]
 [21.15279 ]
 [19.75419 ]], R is [[21.657547  ]
 [21.44097137]
 [21.2265625 ]
 [21.01429749]
 [20.80415535]].
[2019-03-26 11:15:24,992] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4167438e-14 1.0000000e+00 4.4933467e-15 3.1104760e-10 2.4524059e-12], sum to 1.0000
[2019-03-26 11:15:25,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9856
[2019-03-26 11:15:25,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2771780.591495756 W.
[2019-03-26 11:15:25,016] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.7, 51.0, 1.0, 2.0, 0.9908846965212647, 1.0, 2.0, 0.9908846965212647, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2771780.591495756, 2771780.591495756, 523496.5940699243], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5504400.0000, 
sim time next is 5505000.0000, 
raw observation next is [34.45, 52.33333333333333, 1.0, 2.0, 0.2764270823450214, 1.0, 2.0, 0.2764270823450214, 1.0, 1.0, 0.4800624262002549, 6.9112, 6.9112, 170.5573041426782, 1159036.673120629, 1159036.673120629, 295038.9127081134], 
processed observation next is [1.0, 0.7391304347826086, 0.8317535545023698, 0.5233333333333333, 1.0, 1.0, 0.12822540041568842, 1.0, 1.0, 0.12822540041568842, 1.0, 0.5, 0.3659297880490913, 0.0, 0.0, 0.8375144448122397, 0.32195463142239694, 0.32195463142239694, 0.4403565861315125], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35956576], dtype=float32), -1.2954999]. 
=============================================
[2019-03-26 11:15:25,033] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[24.24105 ]
 [24.0158  ]
 [23.290743]
 [22.826561]
 [21.89323 ]], R is [[32.84169769]
 [32.73194504]
 [32.40462494]
 [32.08057785]
 [31.96921158]].
[2019-03-26 11:15:26,086] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.2079524e-30 1.0000000e+00 7.1274655e-36 0.0000000e+00 7.2706635e-32], sum to 1.0000
[2019-03-26 11:15:26,094] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8379
[2019-03-26 11:15:26,099] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.13333333333333, 65.0, 1.0, 2.0, 0.5551705497552017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775792.7394602232, 775792.7394602232, 192692.963921618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5510400.0000, 
sim time next is 5511000.0000, 
raw observation next is [31.86666666666667, 66.5, 1.0, 2.0, 0.5590068765013044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 781155.5758262539, 781155.5758262544, 193358.7407476227], 
processed observation next is [1.0, 0.782608695652174, 0.7093206951026858, 0.665, 1.0, 1.0, 0.46868298373651135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2169876599517372, 0.21698765995173735, 0.288595135444213], 
reward next is 0.7114, 
noisyNet noise sample is [array([-0.17080641], dtype=float32), -0.4909029]. 
=============================================
[2019-03-26 11:15:26,116] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[57.780174]
 [57.496105]
 [56.84504 ]
 [55.85572 ]
 [54.701576]], R is [[57.9274292 ]
 [58.0605545 ]
 [58.19290161]
 [58.32440948]
 [58.45471954]].
[2019-03-26 11:15:28,058] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1777552e-28 1.0000000e+00 1.3982896e-32 2.9189975e-36 6.7776378e-28], sum to 1.0000
[2019-03-26 11:15:28,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9139
[2019-03-26 11:15:28,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 95.0, 1.0, 2.0, 0.543770311091435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759856.4009861683, 759856.4009861677, 190737.9164334008], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5536800.0000, 
sim time next is 5537400.0000, 
raw observation next is [26.26666666666667, 95.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.693277045166149, 6.9112, 169.6884640040826, 2011510.098922495, 1454130.398308694, 311494.5481175783], 
processed observation next is [1.0, 0.08695652173913043, 0.44391785150079005, 0.95, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.07820770451661492, 0.0, 0.8332480419749988, 0.5587528052562486, 0.4039251106413039, 0.46491723599638557], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34847453], dtype=float32), 0.39524037]. 
=============================================
[2019-03-26 11:15:28,671] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6246097e-30 1.0000000e+00 2.7729020e-36 0.0000000e+00 3.8984348e-33], sum to 1.0000
[2019-03-26 11:15:28,677] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3084
[2019-03-26 11:15:28,680] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 82.0, 1.0, 2.0, 0.5623294158321821, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 785800.2059291066, 785800.2059291066, 193938.4094615908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5859000.0000, 
sim time next is 5859600.0000, 
raw observation next is [28.8, 83.33333333333333, 1.0, 2.0, 0.5640999593079109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788275.2848574909, 788275.2848574909, 194248.8795101233], 
processed observation next is [1.0, 0.8260869565217391, 0.5639810426540285, 0.8333333333333333, 1.0, 1.0, 0.47481922808182037, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21896535690485858, 0.21896535690485858, 0.2899237007613781], 
reward next is 0.7101, 
noisyNet noise sample is [array([0.78966534], dtype=float32), -0.3990676]. 
=============================================
[2019-03-26 11:15:29,757] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0357259e-12 1.0000000e+00 1.5508457e-12 3.6414605e-08 2.1518953e-09], sum to 1.0000
[2019-03-26 11:15:29,764] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0211
[2019-03-26 11:15:29,780] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3550038.062989537 W.
[2019-03-26 11:15:29,785] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.6, 61.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 8.693007491140753, 6.9112, 168.9027523337341, 3550038.062989537, 2286038.867582874, 471512.6998431375], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5569800.0000, 
sim time next is 5570400.0000, 
raw observation next is [32.7, 60.33333333333334, 1.0, 2.0, 0.640606792573821, 1.0, 1.0, 0.640606792573821, 1.0, 2.0, 1.03, 7.003973712777273, 6.9112, 170.5573041426782, 2687843.343031603, 2621385.758775888, 503170.7242356401], 
processed observation next is [1.0, 0.4782608695652174, 0.7488151658767774, 0.6033333333333334, 1.0, 1.0, 0.5669961356311096, 1.0, 0.5, 0.5669961356311096, 1.0, 1.0, 1.0365853658536586, 0.009277371277727297, 0.0, 0.8375144448122397, 0.746623150842112, 0.72816271077108, 0.7510010809487165], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8453927], dtype=float32), 0.43493655]. 
=============================================
[2019-03-26 11:15:36,443] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.1233709e-28 1.0000000e+00 1.2496649e-34 2.3477361e-36 2.0366049e-31], sum to 1.0000
[2019-03-26 11:15:36,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9492
[2019-03-26 11:15:36,458] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 83.33333333333334, 1.0, 2.0, 0.5397235394968363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 754199.4960513122, 754199.4960513128, 190053.7427501841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5688600.0000, 
sim time next is 5689200.0000, 
raw observation next is [27.76666666666667, 83.66666666666667, 1.0, 2.0, 0.5383356371834498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 752259.380780187, 752259.3807801863, 189820.2847899604], 
processed observation next is [0.0, 0.8695652173913043, 0.515007898894155, 0.8366666666666667, 1.0, 1.0, 0.44377787612463826, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20896093910560748, 0.20896093910560729, 0.28331385789546326], 
reward next is 0.7167, 
noisyNet noise sample is [array([-0.3923453], dtype=float32), 0.27912614]. 
=============================================
[2019-03-26 11:15:36,653] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0703590e-28 1.0000000e+00 1.1723405e-34 4.0344521e-38 1.7688871e-30], sum to 1.0000
[2019-03-26 11:15:36,663] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4026
[2019-03-26 11:15:36,672] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.61666666666667, 81.0, 1.0, 2.0, 0.5182035140574606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 724117.5684371626, 724117.5684371626, 186497.1799061705], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5727000.0000, 
sim time next is 5727600.0000, 
raw observation next is [27.8, 80.0, 1.0, 2.0, 0.5186626171841852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724759.320264166, 724759.3202641654, 186571.6622047571], 
processed observation next is [0.0, 0.30434782608695654, 0.5165876777251186, 0.8, 1.0, 1.0, 0.4200754423905845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20132203340671279, 0.20132203340671262, 0.2784651674697867], 
reward next is 0.7215, 
noisyNet noise sample is [array([0.16673253], dtype=float32), 0.4695888]. 
=============================================
[2019-03-26 11:15:36,800] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.21427784e-29 1.00000000e+00 1.50407510e-34 4.30581091e-36
 2.28923237e-30], sum to 1.0000
[2019-03-26 11:15:36,811] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5335
[2019-03-26 11:15:36,817] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.86666666666667, 86.33333333333334, 1.0, 2.0, 0.5247479654636504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733265.6883661287, 733265.6883661287, 187563.9209040839], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5696400.0000, 
sim time next is 5697000.0000, 
raw observation next is [26.8, 86.5, 1.0, 2.0, 0.52292946623043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 730723.7028315716, 730723.7028315709, 187266.1559191874], 
processed observation next is [0.0, 0.9565217391304348, 0.4691943127962086, 0.865, 1.0, 1.0, 0.425216224374012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20297880634210322, 0.20297880634210302, 0.27950172525251854], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.38966522], dtype=float32), -0.5148893]. 
=============================================
[2019-03-26 11:15:36,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.05244]
 [74.01985]
 [73.9983 ]
 [73.90294]
 [73.86973]], R is [[74.08158875]
 [74.06082916]
 [74.03967285]
 [74.01870728]
 [73.99727631]].
[2019-03-26 11:15:37,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5532029e-29 1.0000000e+00 3.0305829e-34 0.0000000e+00 6.9212208e-32], sum to 1.0000
[2019-03-26 11:15:37,831] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-26 11:15:37,837] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.7, 92.0, 1.0, 2.0, 0.5098087760177125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712383.1524053011, 712383.1524053011, 185146.8211706242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5720400.0000, 
sim time next is 5721000.0000, 
raw observation next is [25.86666666666667, 91.0, 1.0, 2.0, 0.5095889781190139, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 712075.9140668063, 712075.9140668063, 185111.8365138987], 
processed observation next is [0.0, 0.21739130434782608, 0.42496050552922615, 0.91, 1.0, 1.0, 0.40914334713134204, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1977988650185573, 0.1977988650185573, 0.27628632315507273], 
reward next is 0.7237, 
noisyNet noise sample is [array([-2.1317956], dtype=float32), 0.9310454]. 
=============================================
[2019-03-26 11:15:37,847] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.550575]
 [69.447044]
 [69.40517 ]
 [69.681404]
 [69.84839 ]], R is [[69.6135025 ]
 [69.64102936]
 [69.66805267]
 [69.69467163]
 [69.72117615]].
[2019-03-26 11:15:38,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1836072e-28 1.0000000e+00 3.9637857e-33 3.4267425e-36 1.6325813e-29], sum to 1.0000
[2019-03-26 11:15:38,061] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2830
[2019-03-26 11:15:38,065] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 89.16666666666667, 1.0, 2.0, 0.5113257757610636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714503.6504446712, 714503.6504446717, 185389.3033097809], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5713800.0000, 
sim time next is 5714400.0000, 
raw observation next is [26.1, 89.33333333333334, 1.0, 2.0, 0.5114946839534134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714739.7545637256, 714739.7545637263, 185416.266998658], 
processed observation next is [0.0, 0.13043478260869565, 0.4360189573459717, 0.8933333333333334, 1.0, 1.0, 0.4114393782571245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19853882071214599, 0.19853882071214618, 0.27674069701292237], 
reward next is 0.7233, 
noisyNet noise sample is [array([-0.34378913], dtype=float32), 2.2547426]. 
=============================================
[2019-03-26 11:15:39,638] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.0443387e-31 1.0000000e+00 1.2705735e-36 0.0000000e+00 6.4518437e-35], sum to 1.0000
[2019-03-26 11:15:39,649] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4932
[2019-03-26 11:15:39,653] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 78.0, 1.0, 2.0, 0.5512923579204319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770371.4070233355, 770371.4070233355, 192022.4183767498], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772000.0000, 
sim time next is 5772600.0000, 
raw observation next is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
processed observation next is [0.0, 0.8260869565217391, 0.5639810426540285, 0.79, 1.0, 1.0, 0.4572473611967298, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.213302021386744, 0.21330202138674417, 0.2861454829262731], 
reward next is 0.7139, 
noisyNet noise sample is [array([-1.655582], dtype=float32), 1.0851322]. 
=============================================
[2019-03-26 11:15:40,729] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.7166444e-29 1.0000000e+00 9.5493612e-36 1.8609548e-38 2.5290602e-32], sum to 1.0000
[2019-03-26 11:15:40,736] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0348
[2019-03-26 11:15:40,740] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.73333333333333, 59.16666666666667, 1.0, 2.0, 0.5643201405193947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788583.0810784464, 788583.0810784464, 194286.3640795134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5760600.0000, 
sim time next is 5761200.0000, 
raw observation next is [32.56666666666666, 60.33333333333334, 1.0, 2.0, 0.5521515385808276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771572.4550705901, 771572.4550705901, 192170.8571111246], 
processed observation next is [0.0, 0.6956521739130435, 0.7424960505529224, 0.6033333333333334, 1.0, 1.0, 0.46042354045882833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21432568196405283, 0.21432568196405283, 0.2868221747927233], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.90970796], dtype=float32), -2.5067391]. 
=============================================
[2019-03-26 11:15:48,388] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.5192507e-11 9.9977785e-01 2.6956189e-11 2.1964182e-04 2.4517049e-06], sum to 1.0000
[2019-03-26 11:15:48,399] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-26 11:15:48,407] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2164563.119325303 W.
[2019-03-26 11:15:48,411] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.6, 71.0, 1.0, 2.0, 0.7740006678426914, 1.0, 2.0, 0.7740006678426914, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2164563.119325303, 2164563.119325303, 407420.8667962864], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6001200.0000, 
sim time next is 6001800.0000, 
raw observation next is [31.83333333333334, 70.33333333333334, 1.0, 2.0, 0.8066568513469341, 1.0, 2.0, 0.8066568513469341, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2255978.755588196, 2255978.755588196, 423133.4486799908], 
processed observation next is [1.0, 0.4782608695652174, 0.7077409162717223, 0.7033333333333335, 1.0, 1.0, 0.7670564474059447, 1.0, 1.0, 0.7670564474059447, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6266607654411657, 0.6266607654411657, 0.6315424607164042], 
reward next is 0.3685, 
noisyNet noise sample is [array([-1.121248], dtype=float32), -0.9989347]. 
=============================================
[2019-03-26 11:15:50,671] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.3600328e-23 1.0000000e+00 1.7754754e-26 5.9421598e-25 8.8876790e-22], sum to 1.0000
[2019-03-26 11:15:50,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5491
[2019-03-26 11:15:50,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.95, 91.16666666666667, 1.0, 2.0, 0.5459869711336645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 762955.0406100419, 762955.0406100419, 191114.8963855663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5961000.0000, 
sim time next is 5961600.0000, 
raw observation next is [26.9, 91.0, 1.0, 2.0, 0.5434065583132508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 759347.9166735118, 759347.9166735118, 190676.3978049479], 
processed observation next is [1.0, 0.0, 0.4739336492890995, 0.91, 1.0, 1.0, 0.449887419654519, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21092997685375328, 0.21092997685375328, 0.2845916385148476], 
reward next is 0.7154, 
noisyNet noise sample is [array([-1.5514406], dtype=float32), -0.1883175]. 
=============================================
[2019-03-26 11:15:56,653] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0931949e-21 1.0000000e+00 5.1318671e-26 6.7720627e-26 6.6155611e-20], sum to 1.0000
[2019-03-26 11:15:56,663] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6471
[2019-03-26 11:15:56,670] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.2, 83.0, 1.0, 2.0, 0.7095382681428593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 991606.1691697689, 991606.1691697689, 222918.5250526618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6075000.0000, 
sim time next is 6075600.0000, 
raw observation next is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.7013784734207615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 980197.2892790865, 980197.2892790865, 221144.1413560637], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.8233333333333335, 1.0, 1.0, 0.640215028217785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27227702479974625, 0.27227702479974625, 0.33006588262099057], 
reward next is 0.6699, 
noisyNet noise sample is [array([1.4348308], dtype=float32), 1.0339842]. 
=============================================
[2019-03-26 11:16:00,703] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 11:16:00,704] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:16:00,705] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:16:00,706] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:16:00,707] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:16:00,708] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:16:00,709] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:16:00,710] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:16:00,711] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:16:00,713] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:16:00,713] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:16:00,730] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-26 11:16:00,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-26 11:16:00,752] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-26 11:16:00,784] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-26 11:16:00,803] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-26 11:16:07,125] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:07,126] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.81339436333333, 67.729254595, 1.0, 2.0, 0.2267070107472545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 379102.4367715198, 379102.4367715198, 157520.2573530523]
[2019-03-26 11:16:07,126] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:16:07,129] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0323710e-27 1.0000000e+00 3.1792376e-33 8.1745473e-36 2.4956266e-29], sampled 0.18033410837861763
[2019-03-26 11:16:11,577] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:11,579] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.27634814666667, 49.71535363333334, 1.0, 2.0, 0.252936645075344, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 417328.4009198048, 417328.4009198041, 161161.0424115498]
[2019-03-26 11:16:11,579] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:16:11,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5902263e-27 1.0000000e+00 4.8346830e-33 8.1483957e-36 2.3443348e-29], sampled 0.027755977579193125
[2019-03-26 11:16:11,681] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:11,683] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.73836380666667, 54.15649985666667, 1.0, 2.0, 0.2998600860771113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 491420.3875098098, 491420.3875098098, 166247.6313509438]
[2019-03-26 11:16:11,684] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:16:11,686] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.2943852e-27 1.0000000e+00 8.7988074e-33 4.4626900e-35 4.7197077e-29], sampled 0.9509368692967726
[2019-03-26 11:16:30,310] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:30,313] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.46666666666667, 82.33333333333334, 1.0, 2.0, 0.5145363521768074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718991.4838812008, 718991.4838812008, 185905.1807914067]
[2019-03-26 11:16:30,314] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:16:30,317] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.3112745e-27 1.0000000e+00 1.8155228e-32 2.6965257e-34 3.5382992e-28], sampled 0.579021494971835
[2019-03-26 11:16:51,038] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:51,039] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 81.16666666666666, 1.0, 2.0, 0.5106250491987964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 713524.1577941555, 713524.1577941562, 185276.5599778855]
[2019-03-26 11:16:51,041] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:16:51,044] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3063646e-26 1.0000000e+00 1.9494898e-31 6.1794833e-32 5.6707135e-27], sampled 0.19092155110834397
[2019-03-26 11:16:53,204] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:16:53,205] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.77938646, 67.09598423, 1.0, 2.0, 0.4334262593779281, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 633768.4090318771, 633768.4090318771, 177412.7996544422]
[2019-03-26 11:16:53,206] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:16:53,209] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.9412541e-27 1.0000000e+00 2.1438488e-32 1.0021026e-33 8.4095577e-28], sampled 0.5353781152652073
[2019-03-26 11:17:18,978] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:17:18,980] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.0, 78.66666666666667, 1.0, 2.0, 0.7988086252561264, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1116430.401519018, 1116430.401519018, 243619.7748618626]
[2019-03-26 11:17:18,982] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:17:18,984] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.3289618e-23 1.0000000e+00 2.1027091e-27 2.8560499e-28 8.4512253e-23], sampled 0.0536846562685831
[2019-03-26 11:17:20,649] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:17:20,650] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.57004437666667, 53.00307048333333, 1.0, 2.0, 0.8357206945751702, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990330809416456, 6.9112, 168.9124079752128, 2065067.084853558, 2008929.147486601, 417437.3975033457]
[2019-03-26 11:17:20,651] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:17:20,655] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.9713577e-18 1.0000000e+00 2.4694427e-21 2.4039216e-16 2.2438136e-17], sampled 0.8031017329407479
[2019-03-26 11:17:20,656] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2065067.084853558 W.
[2019-03-26 11:17:22,415] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:17:22,417] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.668800815, 55.56725851, 1.0, 2.0, 0.4686092542587157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667836.9125571004, 667836.9125571004, 180497.5010710414]
[2019-03-26 11:17:22,418] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:17:22,422] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.9326309e-27 1.0000000e+00 1.4662449e-32 1.4004983e-34 2.0618178e-28], sampled 0.20514740338854764
[2019-03-26 11:17:32,908] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.2784224], dtype=float32), 0.0958317]
[2019-03-26 11:17:32,911] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.75, 87.5, 1.0, 2.0, 0.7515444956223633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1050340.469198364, 1050340.469198365, 232365.9935205186]
[2019-03-26 11:17:32,913] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:17:32,915] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3643788e-23 1.0000000e+00 5.8796253e-28 3.2536444e-29 3.8457673e-23], sampled 0.0006802245172523591
[2019-03-26 11:17:55,084] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.1218 3007784093.2705 1766.0000
[2019-03-26 11:17:55,114] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7887.8857 3163726272.7694 1768.0000
[2019-03-26 11:17:55,284] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 11:17:55,325] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.4908 2779253292.2187 934.0000
[2019-03-26 11:17:55,501] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.7981 2842249995.2357 1131.0000
[2019-03-26 11:17:56,516] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 800000, evaluation results [800000.0, 7887.885658000561, 3163726272.769353, 1768.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8660.490775701042, 2779253292.2186956, 934.0, 7998.121812721697, 3007784093.270549, 1766.0, 8497.798055015193, 2842249995.2356563, 1131.0]
[2019-03-26 11:17:57,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6531779e-29 1.0000000e+00 1.6912893e-35 1.9027992e-37 2.0013861e-30], sum to 1.0000
[2019-03-26 11:17:57,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1813
[2019-03-26 11:17:57,958] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 67.33333333333334, 1.0, 2.0, 0.5388889283201594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753032.8127313006, 753032.8127312999, 189913.72367448], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6345600.0000, 
sim time next is 6346200.0000, 
raw observation next is [30.85, 66.66666666666666, 1.0, 2.0, 0.539469530378493, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 753844.4225476262, 753844.4225476262, 190011.4529554805], 
processed observation next is [0.0, 0.43478260869565216, 0.661137440758294, 0.6666666666666665, 1.0, 1.0, 0.4451440125042084, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20940122848545173, 0.20940122848545173, 0.2835991835156425], 
reward next is 0.7164, 
noisyNet noise sample is [array([-1.2499564], dtype=float32), -0.9210442]. 
=============================================
[2019-03-26 11:17:58,757] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.3946811e-28 1.0000000e+00 2.9662252e-33 1.0124023e-36 2.3642003e-29], sum to 1.0000
[2019-03-26 11:17:58,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5845
[2019-03-26 11:17:58,769] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.9, 85.0, 1.0, 2.0, 0.5414856253530441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756662.6786049658, 756662.6786049658, 190351.7511277204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6249600.0000, 
sim time next is 6250200.0000, 
raw observation next is [28.05, 84.00000000000001, 1.0, 2.0, 0.5419119864910849, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757258.6806813597, 757258.680681359, 190423.7908543491], 
processed observation next is [0.0, 0.34782608695652173, 0.528436018957346, 0.8400000000000002, 1.0, 1.0, 0.4480867307121504, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21034963352259992, 0.21034963352259972, 0.2842146132154464], 
reward next is 0.7158, 
noisyNet noise sample is [array([0.831529], dtype=float32), 0.26811004]. 
=============================================
[2019-03-26 11:18:10,081] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1433709e-28 1.0000000e+00 4.3727214e-34 1.2720660e-38 1.8881638e-30], sum to 1.0000
[2019-03-26 11:18:10,090] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7084
[2019-03-26 11:18:10,097] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.8, 87.66666666666667, 1.0, 2.0, 0.5242918556501751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732628.1155994362, 732628.1155994355, 187489.5026628953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6326400.0000, 
sim time next is 6327000.0000, 
raw observation next is [26.9, 87.0, 1.0, 2.0, 0.5242368870535852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732551.2778130334, 732551.2778130334, 187480.5095918376], 
processed observation next is [0.0, 0.21739130434782608, 0.4739336492890995, 0.87, 1.0, 1.0, 0.42679143018504234, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20348646605917595, 0.20348646605917595, 0.27982165610722026], 
reward next is 0.7202, 
noisyNet noise sample is [array([1.6516804], dtype=float32), -0.098859586]. 
=============================================
[2019-03-26 11:18:10,112] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.124  ]
 [76.09668]
 [76.06623]
 [75.96337]
 [75.91824]], R is [[76.11712646]
 [76.07611847]
 [76.03556824]
 [75.99546051]
 [75.95574188]].
[2019-03-26 11:18:13,095] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0050889e-26 1.0000000e+00 5.3890597e-32 2.7900329e-32 3.3976147e-27], sum to 1.0000
[2019-03-26 11:18:13,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7621
[2019-03-26 11:18:13,108] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.13333333333333, 82.66666666666666, 1.0, 2.0, 0.5122698657261385, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715823.3238133806, 715823.3238133806, 185540.5564482097], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6392400.0000, 
sim time next is 6393000.0000, 
raw observation next is [27.11666666666667, 82.83333333333334, 1.0, 2.0, 0.5123660861901176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 715957.8233583921, 715957.8233583928, 185555.9964617115], 
processed observation next is [0.0, 1.0, 0.4842022116903636, 0.8283333333333335, 1.0, 1.0, 0.41248926047002116, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19887717315510892, 0.1988771731551091, 0.27694924845031565], 
reward next is 0.7231, 
noisyNet noise sample is [array([-1.4209758], dtype=float32), 0.46677858]. 
=============================================
[2019-03-26 11:18:13,120] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.20134 ]
 [76.153114]
 [76.11452 ]
 [76.083015]
 [76.04783 ]], R is [[76.19927979]
 [76.16036224]
 [76.12181854]
 [76.0836792 ]
 [76.04595184]].
[2019-03-26 11:18:18,085] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2079567e-23 1.0000000e+00 1.6475293e-27 4.1397735e-26 3.0788080e-22], sum to 1.0000
[2019-03-26 11:18:18,096] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2610
[2019-03-26 11:18:18,101] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 87.66666666666667, 1.0, 2.0, 0.5308826972178836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741841.1558172234, 741841.1558172228, 188576.1381549454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6478800.0000, 
sim time next is 6479400.0000, 
raw observation next is [26.95, 87.83333333333334, 1.0, 2.0, 0.5296403702742243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740104.556893132, 740104.5568931315, 188370.3616267271], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.8783333333333334, 1.0, 1.0, 0.4333016509328003, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20558459913698113, 0.20558459913698096, 0.281149793472727], 
reward next is 0.7189, 
noisyNet noise sample is [array([1.3037597], dtype=float32), 0.16412596]. 
=============================================
[2019-03-26 11:18:24,118] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.8177968e-16 1.0000000e+00 1.5636932e-18 8.0248765e-15 3.3767775e-13], sum to 1.0000
[2019-03-26 11:18:24,126] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4140
[2019-03-26 11:18:24,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1815485.057264405 W.
[2019-03-26 11:18:24,144] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.36666666666667, 83.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.420743729793116, 6.9112, 168.9104721418153, 1815485.057264405, 1454002.514964126, 311349.2610396264], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6685800.0000, 
sim time next is 6686400.0000, 
raw observation next is [27.53333333333333, 82.0, 1.0, 2.0, 0.4468270129437196, 1.0, 1.0, 0.4468270129437196, 1.0, 1.0, 0.7640908633853001, 6.911200000000001, 6.9112, 170.5573041426782, 1874134.629333471, 1874134.62933347, 378416.6615674449], 
processed observation next is [1.0, 0.391304347826087, 0.5039494470774091, 0.82, 1.0, 1.0, 0.33352652161893925, 1.0, 0.5, 0.33352652161893925, 1.0, 0.5, 0.712305930957683, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5205929525926308, 0.5205929525926306, 0.5648009874140969], 
reward next is 0.4352, 
noisyNet noise sample is [array([-0.7724659], dtype=float32), -0.4568386]. 
=============================================
[2019-03-26 11:18:35,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.2050803e-27 1.0000000e+00 1.2270339e-33 2.3879064e-33 3.3536751e-29], sum to 1.0000
[2019-03-26 11:18:35,563] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1669
[2019-03-26 11:18:35,568] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.18333333333333, 70.16666666666667, 1.0, 2.0, 0.4255749638259517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619419.4547144264, 619419.454714427, 175935.4265831896], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6991800.0000, 
sim time next is 6992400.0000, 
raw observation next is [27.06666666666667, 71.33333333333334, 1.0, 2.0, 0.430716646286219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 625065.2306058331, 625065.2306058324, 176433.5325010216], 
processed observation next is [0.0, 0.9565217391304348, 0.48183254344391807, 0.7133333333333334, 1.0, 1.0, 0.31411644130869754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17362923072384254, 0.17362923072384234, 0.2633336305985397], 
reward next is 0.7367, 
noisyNet noise sample is [array([-0.20800345], dtype=float32), -1.0131834]. 
=============================================
[2019-03-26 11:18:36,518] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.5793706e-18 1.0000000e+00 2.2093159e-22 3.5023547e-18 5.8093215e-16], sum to 1.0000
[2019-03-26 11:18:36,527] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1894
[2019-03-26 11:18:36,537] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 50.66666666666667, 1.0, 2.0, 0.3253137773952314, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 503269.5484397367, 503269.5484397367, 166966.0851520679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6801600.0000, 
sim time next is 6802200.0000, 
raw observation next is [28.65, 51.0, 1.0, 2.0, 0.3186079987081588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 493879.8458758697, 493879.8458758697, 166286.6180074074], 
processed observation next is [1.0, 0.7391304347826086, 0.5568720379146919, 0.51, 1.0, 1.0, 0.17904578157609494, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13718884607663046, 0.13718884607663046, 0.24818898210060808], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.44717807], dtype=float32), -0.8980722]. 
=============================================
[2019-03-26 11:18:41,346] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.7537576e-21 1.0000000e+00 4.3579038e-25 1.7758573e-23 2.2087367e-20], sum to 1.0000
[2019-03-26 11:18:41,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5215
[2019-03-26 11:18:41,362] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 88.0, 1.0, 2.0, 0.6885796863193041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 962302.4996188185, 962302.4996188191, 218396.3702338618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7180200.0000, 
sim time next is 7180800.0000, 
raw observation next is [25.8, 88.33333333333333, 1.0, 2.0, 0.6130224763090107, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 856667.3532408532, 856667.3532408539, 203188.4528057531], 
processed observation next is [1.0, 0.08695652173913043, 0.42180094786729866, 0.8833333333333333, 1.0, 1.0, 0.5337620196494105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23796315367801477, 0.23796315367801496, 0.3032663474712733], 
reward next is 0.6967, 
noisyNet noise sample is [array([-1.7266289], dtype=float32), -0.39998353]. 
=============================================
[2019-03-26 11:18:41,680] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.7908793e-28 1.0000000e+00 6.5866350e-33 6.2663790e-35 1.4531894e-29], sum to 1.0000
[2019-03-26 11:18:41,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3892
[2019-03-26 11:18:41,695] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 33.5, 1.0, 2.0, 0.2550798168264485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417784.0872494703, 417784.0872494703, 161409.9279549222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6877800.0000, 
sim time next is 6878400.0000, 
raw observation next is [29.76666666666667, 34.66666666666666, 1.0, 2.0, 0.2555223416276268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 417128.1149687485, 417128.1149687485, 161425.1264053406], 
processed observation next is [0.0, 0.6086956521739131, 0.6097946287519749, 0.34666666666666657, 1.0, 1.0, 0.10303896581641785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11586892082465235, 0.11586892082465235, 0.24093302448558296], 
reward next is 0.7591, 
noisyNet noise sample is [array([0.20516405], dtype=float32), 0.82060695]. 
=============================================
[2019-03-26 11:18:42,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.02241106e-22 1.00000000e+00 4.33154741e-27 6.26509325e-26
 1.17417307e-23], sum to 1.0000
[2019-03-26 11:18:42,874] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8563
[2019-03-26 11:18:42,879] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333333, 74.83333333333334, 1.0, 2.0, 0.4031931511826403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598859.5032036089, 598859.5032036083, 174351.9116547568], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6905400.0000, 
sim time next is 6906000.0000, 
raw observation next is [25.76666666666667, 75.66666666666667, 1.0, 2.0, 0.4053210920412618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 600730.3323681555, 600730.3323681548, 174486.7626591024], 
processed observation next is [0.0, 0.9565217391304348, 0.42022116903633505, 0.7566666666666667, 1.0, 1.0, 0.28351938800152027, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16686953676893207, 0.16686953676893188, 0.26042800396880955], 
reward next is 0.7396, 
noisyNet noise sample is [array([0.2757163], dtype=float32), -1.1000909]. 
=============================================
[2019-03-26 11:18:42,897] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.65408]
 [72.70005]
 [72.67952]
 [72.72358]
 [72.75925]], R is [[72.63182068]
 [72.64527893]
 [72.65885162]
 [72.67263031]
 [72.68665314]].
[2019-03-26 11:18:44,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.9183188e-24 1.0000000e+00 4.4350408e-29 5.1010409e-29 1.4828952e-24], sum to 1.0000
[2019-03-26 11:18:44,383] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5420
[2019-03-26 11:18:44,390] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333333, 52.33333333333334, 1.0, 2.0, 0.471694100601146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659106.9488606076, 659106.9488606076, 179279.9763761303], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6958200.0000, 
sim time next is 6958800.0000, 
raw observation next is [32.0, 52.0, 1.0, 2.0, 0.4749011103075036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663589.5628702575, 663589.5628702568, 179757.0766193429], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.52, 1.0, 1.0, 0.36735073531024526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18433043413062708, 0.18433043413062689, 0.2682941442079745], 
reward next is 0.7317, 
noisyNet noise sample is [array([0.03817634], dtype=float32), -0.35664728]. 
=============================================
[2019-03-26 11:18:45,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.2465404e-26 1.0000000e+00 7.6916390e-31 9.7768075e-32 6.8810388e-27], sum to 1.0000
[2019-03-26 11:18:45,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8998
[2019-03-26 11:18:45,272] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 71.16666666666667, 1.0, 2.0, 0.4315112207539734, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 625496.4139470931, 625496.4139470936, 176455.85753759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6940200.0000, 
sim time next is 6940800.0000, 
raw observation next is [27.3, 70.0, 1.0, 2.0, 0.4317475600795346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 625741.220320253, 625741.2203202525, 176477.1497145662], 
processed observation next is [0.0, 0.34782608695652173, 0.4928909952606636, 0.7, 1.0, 1.0, 0.3153585061199212, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17381700564451474, 0.17381700564451458, 0.263398730917263], 
reward next is 0.7366, 
noisyNet noise sample is [array([-0.8425579], dtype=float32), -1.487013]. 
=============================================
[2019-03-26 11:18:47,111] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.5143463e-25 1.0000000e+00 3.1818996e-30 1.6222388e-29 2.1325342e-26], sum to 1.0000
[2019-03-26 11:18:47,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5845
[2019-03-26 11:18:47,133] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.26666666666667, 57.33333333333334, 1.0, 2.0, 0.4195635980727933, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 615679.3197189064, 615679.3197189071, 175717.7498376389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6979200.0000, 
sim time next is 6979800.0000, 
raw observation next is [29.18333333333334, 57.16666666666666, 1.0, 2.0, 0.4145545211978685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610668.623297392, 610668.6232973915, 175308.3842482005], 
processed observation next is [0.0, 0.782608695652174, 0.5821484992101109, 0.5716666666666665, 1.0, 1.0, 0.29464400144321506, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16963017313816445, 0.16963017313816428, 0.26165430484806046], 
reward next is 0.7383, 
noisyNet noise sample is [array([-0.13283604], dtype=float32), 0.22708447]. 
=============================================
[2019-03-26 11:18:49,233] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4912484e-19 1.0000000e+00 1.8156923e-21 2.7078336e-19 6.9643679e-16], sum to 1.0000
[2019-03-26 11:18:49,243] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2394
[2019-03-26 11:18:49,248] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.6654128531676959, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 947290.1127677842, 947290.1127677842, 215851.9789133081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7012200.0000, 
sim time next is 7012800.0000, 
raw observation next is [25.3, 86.0, 1.0, 2.0, 0.6550394125009066, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 931995.9920461454, 931995.9920461461, 213622.7756947928], 
processed observation next is [1.0, 0.17391304347826086, 0.39810426540284366, 0.86, 1.0, 1.0, 0.5843848343384417, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2588877755683737, 0.2588877755683739, 0.3188399637235713], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.00598262], dtype=float32), 2.308381]. 
=============================================
[2019-03-26 11:18:50,915] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 11:18:50,917] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:18:50,918] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:18:50,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:18:50,922] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:18:50,922] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:18:50,924] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:18:50,927] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:18:50,926] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:18:50,929] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:18:50,930] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:18:50,948] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-26 11:18:50,949] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-26 11:18:50,949] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-26 11:18:51,015] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-26 11:18:51,035] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-26 11:18:59,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:18:59,473] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [17.95468401, 94.81173112, 1.0, 2.0, 0.2372281640222721, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 393278.7165018379, 393278.7165018385, 159499.3778542028]
[2019-03-26 11:18:59,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:18:59,478] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5377367e-26 1.0000000e+00 3.7744338e-31 1.2000646e-33 2.1096107e-27], sampled 0.07905879850618425
[2019-03-26 11:19:20,925] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:19:20,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.13333333333333, 96.0, 1.0, 2.0, 0.4602961970323435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 649894.0932472008, 649894.0932472001, 178476.709614409]
[2019-03-26 11:19:20,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:19:20,930] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.9570033e-25 1.0000000e+00 2.5410458e-29 3.5390652e-30 3.4514124e-25], sampled 0.2173754527629066
[2019-03-26 11:19:32,355] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:19:32,357] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.33333333333334, 79.66666666666666, 1.0, 2.0, 0.9968069171261519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104117, 1393338.228857445, 1393338.228857445, 297951.985969049]
[2019-03-26 11:19:32,358] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:19:32,361] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.2293407e-19 1.0000000e+00 4.1711049e-22 2.7049133e-18 4.9263353e-18], sampled 0.7637122550912947
[2019-03-26 11:19:35,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:19:35,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.33333333333334, 73.0, 1.0, 2.0, 0.5144209629898898, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 718830.1893225913, 718830.1893225919, 185887.5422339175]
[2019-03-26 11:19:35,034] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:19:35,037] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7886186e-23 1.0000000e+00 1.9142465e-27 1.2551109e-27 9.2098337e-23], sampled 0.5274566376660517
[2019-03-26 11:20:06,516] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:20:06,518] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.960278468192385, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005991233573839, 6.9112, 168.9123159561543, 2239405.774451214, 2172157.865910963, 451312.2140777347]
[2019-03-26 11:20:06,521] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:20:06,525] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0268947e-13 1.0000000e+00 9.4697966e-16 1.6699127e-08 5.7854846e-11], sampled 0.3950350845267312
[2019-03-26 11:20:06,526] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2239405.774451214 W.
[2019-03-26 11:20:38,921] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:20:38,922] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.36666666666667, 62.0, 1.0, 2.0, 0.3823906341297102, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579361.4377463019, 579361.4377463019, 172917.8647584523]
[2019-03-26 11:20:38,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:20:38,929] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.0521268e-26 1.0000000e+00 7.5266584e-31 1.4229452e-32 8.3465374e-27], sampled 0.9945351292075496
[2019-03-26 11:20:44,079] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28240415], dtype=float32), 0.10283815]
[2019-03-26 11:20:44,081] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.886665195, 67.8990194, 1.0, 2.0, 0.7814495256228154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1092156.510973968, 1092156.510973967, 239407.069596042]
[2019-03-26 11:20:44,083] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:20:44,086] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.5994634e-21 1.0000000e+00 2.4896044e-24 1.3953288e-22 1.7491226e-19], sampled 0.17942376259339454
[2019-03-26 11:20:45,846] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.7266 3007242677.4765 1753.0000
[2019-03-26 11:20:46,054] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7913.2091 3161389342.8089 1715.0000
[2019-03-26 11:20:46,121] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8257.7536 2927043629.8832 1332.0000
[2019-03-26 11:20:46,333] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8500.3757 2842189966.2477 1125.0000
[2019-03-26 11:20:46,365] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8663.5609 2778882136.7727 926.0000
[2019-03-26 11:20:47,379] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 825000, evaluation results [825000.0, 7913.209107544733, 3161389342.808894, 1715.0, 8257.753616226, 2927043629.883191, 1332.0, 8663.56090109727, 2778882136.7726636, 926.0, 8003.7266233236805, 3007242677.476532, 1753.0, 8500.375705811939, 2842189966.2476907, 1125.0]
[2019-03-26 11:20:47,602] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6107536e-12 9.9950206e-01 3.5879706e-13 4.9794599e-04 2.5898106e-09], sum to 1.0000
[2019-03-26 11:20:47,611] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3792
[2019-03-26 11:20:47,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1906420.221571862 W.
[2019-03-26 11:20:47,628] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.11666666666667, 50.66666666666667, 1.0, 2.0, 0.67360241913297, 1.0, 1.0, 0.67360241913297, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1906420.221571862, 1906420.221571862, 365864.4549643769], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7051800.0000, 
sim time next is 7052400.0000, 
raw observation next is [30.9, 52.0, 1.0, 2.0, 0.6755791366039259, 1.0, 2.0, 0.6755791366039259, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1901190.200176409, 1901190.200176409, 365345.5731236028], 
processed observation next is [1.0, 0.6521739130434783, 0.6635071090047393, 0.52, 1.0, 1.0, 0.609131489884248, 1.0, 1.0, 0.609131489884248, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5281083889378914, 0.5281083889378914, 0.5452919001844817], 
reward next is 0.4547, 
noisyNet noise sample is [array([-0.25513902], dtype=float32), -0.11627052]. 
=============================================
[2019-03-26 11:20:50,418] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.1293849e-24 1.0000000e+00 8.4473358e-28 3.5048913e-27 3.1461260e-22], sum to 1.0000
[2019-03-26 11:20:50,427] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2421
[2019-03-26 11:20:50,436] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.46666666666667, 93.16666666666667, 1.0, 2.0, 0.5610581789113944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 793405.3547818691, 793405.3547818697, 194919.1804359521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7096200.0000, 
sim time next is 7096800.0000, 
raw observation next is [24.43333333333334, 93.33333333333334, 1.0, 2.0, 0.51575168316069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 729712.0174479375, 729712.0174479381, 187256.1625409744], 
processed observation next is [1.0, 0.13043478260869565, 0.3570300157977887, 0.9333333333333335, 1.0, 1.0, 0.41656829296468667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2026977826244271, 0.20269778262442725, 0.27948680976264834], 
reward next is 0.7205, 
noisyNet noise sample is [array([-0.5249079], dtype=float32), -0.75558335]. 
=============================================
[2019-03-26 11:20:50,669] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.7905391e-24 1.0000000e+00 1.6617174e-28 4.7978743e-29 1.6902547e-23], sum to 1.0000
[2019-03-26 11:20:50,678] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6211
[2019-03-26 11:20:50,686] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.33333333333334, 85.66666666666667, 1.0, 2.0, 0.5065954625839889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721175.2415038793, 721175.2415038793, 186333.5788862473], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7107600.0000, 
sim time next is 7108200.0000, 
raw observation next is [25.5, 84.5, 1.0, 2.0, 0.5052259938965823, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719182.4200182089, 719182.4200182089, 186106.7225950922], 
processed observation next is [1.0, 0.2608695652173913, 0.40758293838862564, 0.845, 1.0, 1.0, 0.40388673963443644, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19977289444950247, 0.19977289444950247, 0.277771227753869], 
reward next is 0.7222, 
noisyNet noise sample is [array([-2.2078676], dtype=float32), 0.7194427]. 
=============================================
[2019-03-26 11:20:57,629] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.6661625e-10 3.8735643e-02 2.8441952e-11 9.6125555e-01 8.8068755e-06], sum to 1.0000
[2019-03-26 11:20:57,643] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8258
[2019-03-26 11:20:57,649] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.41666666666667, 74.0, 1.0, 2.0, 0.6780324489491809, 1.0, 2.0, 0.6780324489491809, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1895941.794043299, 1895941.794043299, 364861.1514039198], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7211400.0000, 
sim time next is 7212000.0000, 
raw observation next is [29.33333333333334, 75.0, 1.0, 2.0, 0.6666830497202387, 1.0, 2.0, 0.6666830497202387, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1864178.536000221, 1864178.536000221, 360187.5534976171], 
processed observation next is [1.0, 0.4782608695652174, 0.5892575039494474, 0.75, 1.0, 1.0, 0.5984133129159502, 1.0, 1.0, 0.5984133129159502, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5178273711111725, 0.5178273711111725, 0.5375933634292792], 
reward next is 0.4624, 
noisyNet noise sample is [array([-0.87143314], dtype=float32), 0.5035642]. 
=============================================
[2019-03-26 11:20:57,669] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[52.199142]
 [52.958332]
 [53.532974]
 [54.09022 ]
 [53.744698]], R is [[52.35605621]
 [52.28792953]
 [51.76504898]
 [51.29009628]
 [51.25370407]].
[2019-03-26 11:20:59,566] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5681035e-27 1.0000000e+00 1.0677888e-30 4.3038779e-34 6.0659898e-27], sum to 1.0000
[2019-03-26 11:20:59,575] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3294
[2019-03-26 11:20:59,584] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 93.33333333333333, 1.0, 2.0, 0.3469143773739593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534445.9834828508, 534445.9834828508, 169362.8886042231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7462200.0000, 
sim time next is 7462800.0000, 
raw observation next is [22.2, 93.0, 1.0, 2.0, 0.3488492505742917, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 536509.7112452202, 536509.7112452195, 169503.3445936645], 
processed observation next is [0.0, 0.391304347826087, 0.2511848341232228, 0.93, 1.0, 1.0, 0.21548102478830328, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14903047534589448, 0.14903047534589428, 0.25299006655770817], 
reward next is 0.7470, 
noisyNet noise sample is [array([-0.5221272], dtype=float32), -0.15928608]. 
=============================================
[2019-03-26 11:21:00,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9059758e-20 1.0000000e+00 1.0710112e-23 5.8087274e-22 1.2154710e-18], sum to 1.0000
[2019-03-26 11:21:00,196] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5210
[2019-03-26 11:21:00,200] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 89.0, 1.0, 2.0, 0.3311891285617504, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 518613.2219775501, 518613.2219775495, 168338.2084394119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7261200.0000, 
sim time next is 7261800.0000, 
raw observation next is [21.98333333333333, 88.83333333333334, 1.0, 2.0, 0.3297064896064213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 516851.6012024212, 516851.6012024212, 168214.3994703708], 
processed observation next is [1.0, 0.043478260869565216, 0.24091627172195884, 0.8883333333333334, 1.0, 1.0, 0.1924174573571341, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14356988922289476, 0.14356988922289476, 0.25106626786622505], 
reward next is 0.7489, 
noisyNet noise sample is [array([0.3758635], dtype=float32), 0.22724517]. 
=============================================
[2019-03-26 11:21:02,954] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7332952e-17 1.0000000e+00 2.4352996e-19 6.5349354e-16 1.2512900e-14], sum to 1.0000
[2019-03-26 11:21:02,963] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8768
[2019-03-26 11:21:02,969] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.81666666666667, 63.66666666666666, 1.0, 2.0, 0.7866281003577029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1199196.73302138, 1199196.733021379, 253857.3074249674], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7300200.0000, 
sim time next is 7300800.0000, 
raw observation next is [26.9, 63.0, 1.0, 2.0, 0.8548144265830148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1304457.208512261, 1304457.208512261, 272824.3850225583], 
processed observation next is [1.0, 0.5217391304347826, 0.4739336492890995, 0.63, 1.0, 1.0, 0.8250776223891744, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3623492245867392, 0.3623492245867392, 0.4072005746605347], 
reward next is 0.5928, 
noisyNet noise sample is [array([0.29188624], dtype=float32), -0.2569126]. 
=============================================
[2019-03-26 11:21:04,000] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.8792716e-22 1.0000000e+00 1.9138321e-25 1.5865152e-23 1.6324642e-20], sum to 1.0000
[2019-03-26 11:21:04,007] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5922
[2019-03-26 11:21:04,012] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.96666666666667, 76.66666666666667, 1.0, 2.0, 0.3793609202977866, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 573736.363949075, 573736.3639490744, 172388.2977895759], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7338000.0000, 
sim time next is 7338600.0000, 
raw observation next is [24.9, 77.0, 1.0, 2.0, 0.3784420564184537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572631.7549308765, 572631.7549308765, 172299.2814736773], 
processed observation next is [1.0, 0.9565217391304348, 0.3791469194312796, 0.77, 1.0, 1.0, 0.25113500773307673, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15906437636968793, 0.15906437636968793, 0.2571631066771303], 
reward next is 0.7428, 
noisyNet noise sample is [array([0.7295534], dtype=float32), 1.8651997]. 
=============================================
[2019-03-26 11:21:04,619] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0040575e-25 1.0000000e+00 1.4024471e-30 7.4861934e-32 3.3062378e-25], sum to 1.0000
[2019-03-26 11:21:04,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7733
[2019-03-26 11:21:04,634] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 80.66666666666667, 1.0, 2.0, 0.4435107975055667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 630477.9918413503, 630477.991841351, 176610.359753923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7551600.0000, 
sim time next is 7552200.0000, 
raw observation next is [26.36666666666667, 79.83333333333334, 1.0, 2.0, 0.4495581731745067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636197.6621211666, 636197.6621211666, 177109.231693985], 
processed observation next is [0.0, 0.391304347826087, 0.4486571879936811, 0.7983333333333335, 1.0, 1.0, 0.3368170761138635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17672157281143516, 0.17672157281143516, 0.26434213685669405], 
reward next is 0.7357, 
noisyNet noise sample is [array([-0.46762255], dtype=float32), 1.6569885]. 
=============================================
[2019-03-26 11:21:09,736] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6361642e-24 1.0000000e+00 5.5714279e-30 1.1119692e-30 1.3367489e-24], sum to 1.0000
[2019-03-26 11:21:09,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8046
[2019-03-26 11:21:09,755] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 93.66666666666667, 1.0, 2.0, 0.3452236390077541, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 532743.9537262849, 532743.9537262843, 169251.9696557469], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7461600.0000, 
sim time next is 7462200.0000, 
raw observation next is [22.1, 93.33333333333333, 1.0, 2.0, 0.3469143773739593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 534445.9834828508, 534445.9834828508, 169362.8886042231], 
processed observation next is [0.0, 0.34782608695652173, 0.24644549763033188, 0.9333333333333332, 1.0, 1.0, 0.2131498522577823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14845721763412523, 0.14845721763412523, 0.2527804307525718], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.2838256], dtype=float32), -0.32811007]. 
=============================================
[2019-03-26 11:21:17,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.1871387e-24 1.0000000e+00 3.0853136e-27 6.8265983e-29 2.3122604e-24], sum to 1.0000
[2019-03-26 11:21:17,210] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8092
[2019-03-26 11:21:17,213] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.13333333333333, 80.66666666666667, 1.0, 2.0, 0.4435107975055667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 630477.9918413503, 630477.991841351, 176610.359753923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7551600.0000, 
sim time next is 7552200.0000, 
raw observation next is [26.36666666666667, 79.83333333333334, 1.0, 2.0, 0.4495581731745067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 636197.6621211666, 636197.6621211666, 177109.231693985], 
processed observation next is [0.0, 0.391304347826087, 0.4486571879936811, 0.7983333333333335, 1.0, 1.0, 0.3368170761138635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17672157281143516, 0.17672157281143516, 0.26434213685669405], 
reward next is 0.7357, 
noisyNet noise sample is [array([-0.19670287], dtype=float32), -0.7304708]. 
=============================================
[2019-03-26 11:21:20,843] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.7290150e-11 1.9536651e-04 2.3164137e-11 9.9980444e-01 2.6077049e-07], sum to 1.0000
[2019-03-26 11:21:20,854] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3639
[2019-03-26 11:21:20,861] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.96666666666667, 73.0, 1.0, 2.0, 0.6417429913502845, 1.0, 2.0, 0.6417429913502845, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1794382.774039249, 1794382.774039249, 350177.1858435895], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7663200.0000, 
sim time next is 7663800.0000, 
raw observation next is [28.83333333333333, 74.0, 1.0, 2.0, 0.6417154401020341, 1.0, 2.0, 0.6417154401020341, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1794305.673270725, 1794305.673270724, 350166.5784937459], 
processed observation next is [1.0, 0.6956521739130435, 0.5655608214849919, 0.74, 1.0, 1.0, 0.5683318555446193, 1.0, 1.0, 0.5683318555446193, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4984182425752014, 0.4984182425752011, 0.5226366843190237], 
reward next is 0.4774, 
noisyNet noise sample is [array([-1.7287403], dtype=float32), 0.3309326]. 
=============================================
[2019-03-26 11:21:23,315] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:23,316] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:23,348] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-26 11:21:24,387] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.2961731e-18 1.0000000e+00 1.8713431e-21 9.9193255e-19 3.0050998e-16], sum to 1.0000
[2019-03-26 11:21:24,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9913
[2019-03-26 11:21:24,401] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 85.0, 1.0, 2.0, 0.616453280075016, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861463.6692218971, 861463.6692218971, 203843.7886059519], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7801200.0000, 
sim time next is 7801800.0000, 
raw observation next is [27.03333333333333, 84.50000000000001, 1.0, 2.0, 0.7565199476128736, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1057297.502628378, 1057297.502628377, 233516.4975966799], 
processed observation next is [1.0, 0.30434782608695654, 0.48025276461295413, 0.8450000000000002, 1.0, 1.0, 0.7066505392926187, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.293693750730105, 0.29369375073010473, 0.34853208596519386], 
reward next is 0.6515, 
noisyNet noise sample is [array([2.0270555], dtype=float32), 0.07423487]. 
=============================================
[2019-03-26 11:21:28,290] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:28,290] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:28,324] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-26 11:21:33,079] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.4342131e-19 1.0000000e+00 6.9667146e-21 1.2943065e-18 8.7896874e-17], sum to 1.0000
[2019-03-26 11:21:33,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2964
[2019-03-26 11:21:33,095] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 90.0, 1.0, 2.0, 0.7379057646237581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031270.052102532, 1031270.052102532, 229238.3073111918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7876800.0000, 
sim time next is 7877400.0000, 
raw observation next is [26.21666666666667, 89.83333333333333, 1.0, 2.0, 0.6508600437936357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 909566.0474464631, 909566.0474464631, 210594.4513989143], 
processed observation next is [1.0, 0.17391304347826086, 0.44154818325434453, 0.8983333333333333, 1.0, 1.0, 0.5793494503537779, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2526572354017953, 0.2526572354017953, 0.31432007671479745], 
reward next is 0.6857, 
noisyNet noise sample is [array([-0.5954499], dtype=float32), 0.7279458]. 
=============================================
[2019-03-26 11:21:33,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:33,638] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:33,672] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-26 11:21:37,119] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:37,120] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:37,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-26 11:21:37,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:37,195] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:37,228] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-26 11:21:37,776] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:37,776] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:37,796] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-26 11:21:38,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,360] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,361] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,369] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-26 11:21:38,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,387] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,398] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-26 11:21:38,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-26 11:21:38,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-26 11:21:38,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,642] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,651] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-26 11:21:38,674] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,675] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,681] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-26 11:21:38,705] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,706] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,708] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-26 11:21:38,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,735] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-26 11:21:38,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-26 11:21:38,973] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:21:38,973] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:38,974] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-26 11:21:40,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.4207487e-13 1.0000000e+00 2.3773838e-16 8.0787380e-18 1.0930909e-13], sum to 1.0000
[2019-03-26 11:21:40,357] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6067
[2019-03-26 11:21:40,360] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.6, 85.0, 1.0, 2.0, 0.2698905337457244, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 439649.4341560845, 439649.4341560845, 162867.4799246197], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7200.0000, 
sim time next is 7800.0000, 
raw observation next is [20.66666666666667, 85.00000000000001, 1.0, 2.0, 0.3754134674260543, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610838.981024439, 610838.9810244383, 175835.0636500246], 
processed observation next is [1.0, 0.08695652173913043, 0.17851500789889443, 0.8500000000000001, 1.0, 1.0, 0.24748610533259555, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16967749472901084, 0.16967749472901064, 0.26244039350749937], 
reward next is 0.7376, 
noisyNet noise sample is [array([-1.0950441], dtype=float32), -0.3669947]. 
=============================================
[2019-03-26 11:21:40,456] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 11:21:40,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:21:40,460] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:40,460] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:21:40,461] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:21:40,461] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:40,462] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:40,462] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:21:40,464] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:21:40,464] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:40,465] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:21:40,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-26 11:21:40,480] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-26 11:21:40,496] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-26 11:21:40,496] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-26 11:21:40,529] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-26 11:21:43,380] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.2794037], dtype=float32), 0.08908205]
[2019-03-26 11:21:43,380] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.69515999, 97.36447638, 1.0, 2.0, 0.3941912630994666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 621311.2892962687, 621311.2892962687, 177062.1388321098]
[2019-03-26 11:21:43,381] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:21:43,383] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.7298085e-24 1.0000000e+00 8.8478031e-28 5.8555666e-27 1.3655041e-22], sampled 0.11933855662670212
[2019-03-26 11:21:47,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.2794037], dtype=float32), 0.08908205]
[2019-03-26 11:21:47,037] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.1, 89.66666666666667, 1.0, 2.0, 0.3271820811583991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510491.2262006814, 510491.2262006814, 167658.6260182079]
[2019-03-26 11:21:47,038] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:21:47,041] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.6447553e-25 1.0000000e+00 1.7969840e-29 1.5736170e-30 1.1007757e-24], sampled 0.23620886209722536
[2019-03-26 11:23:02,774] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.2794037], dtype=float32), 0.08908205]
[2019-03-26 11:23:02,776] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.717995055, 87.74489213666666, 1.0, 2.0, 0.5359318901134168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748899.248933418, 748899.2489334173, 189416.1806228543]
[2019-03-26 11:23:02,777] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:23:02,778] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6184563e-21 1.0000000e+00 7.3026274e-25 1.1932194e-22 1.5918107e-19], sampled 0.20398212349013012
[2019-03-26 11:23:34,845] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.2794037], dtype=float32), 0.08908205]
[2019-03-26 11:23:34,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.66666666666667, 63.33333333333334, 1.0, 2.0, 0.9394202013947874, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976979717807801, 6.9112, 168.9125114092506, 2210212.491604193, 2163546.218798422, 446234.4589900644]
[2019-03-26 11:23:34,848] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:23:34,852] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4018177e-13 9.9992585e-01 8.7948421e-16 7.4138072e-05 1.7358502e-10], sampled 0.20439968089448213
[2019-03-26 11:23:34,853] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2210212.491604193 W.
[2019-03-26 11:23:34,867] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8266.1517 2926476560.6092 1316.0000
[2019-03-26 11:23:35,104] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8667.7929 2778600839.0305 914.0000
[2019-03-26 11:23:35,143] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7947.2635 3158436084.3584 1634.0000
[2019-03-26 11:23:35,143] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8514.1132 2840773991.5612 1095.0000
[2019-03-26 11:23:35,205] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8020.8670 3005336769.0270 1712.0000
[2019-03-26 11:23:36,225] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 850000, evaluation results [850000.0, 7947.263458076671, 3158436084.358416, 1634.0, 8266.151658354815, 2926476560.6091733, 1316.0, 8667.792866910646, 2778600839.030544, 914.0, 8020.8669726295275, 3005336769.0270066, 1712.0, 8514.113207081218, 2840773991.5611744, 1095.0]
[2019-03-26 11:23:40,792] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5907190e-18 1.0000000e+00 1.7595810e-21 4.2172136e-15 1.4546682e-13], sum to 1.0000
[2019-03-26 11:23:40,802] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7899
[2019-03-26 11:23:40,810] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.43333333333333, 96.0, 1.0, 2.0, 0.3820765904361098, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576234.0410331846, 576234.0410331846, 172561.660346285], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 153600.0000, 
sim time next is 154200.0000, 
raw observation next is [22.41666666666667, 96.0, 1.0, 2.0, 0.3845326749506683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 580258.5197760034, 580258.5197760027, 172930.3252149941], 
processed observation next is [1.0, 0.782608695652174, 0.26145339652448685, 0.96, 1.0, 1.0, 0.25847310235020277, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16118292216000096, 0.16118292216000077, 0.2581049630074539], 
reward next is 0.7419, 
noisyNet noise sample is [array([1.0990092], dtype=float32), 0.6137246]. 
=============================================
[2019-03-26 11:23:41,538] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4851071e-19 1.0000000e+00 8.1325501e-23 1.1229617e-17 1.9088974e-16], sum to 1.0000
[2019-03-26 11:23:41,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5026
[2019-03-26 11:23:41,554] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.21666666666667, 78.5, 1.0, 2.0, 0.2401342701356224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397080.5500383901, 397080.5500383901, 159864.9659576104], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 504600.0000, 
sim time next is 505200.0000, 
raw observation next is [20.13333333333333, 79.0, 1.0, 2.0, 0.2404901571515648, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 397739.4148161089, 397739.4148161095, 159893.8413064448], 
processed observation next is [1.0, 0.8695652173913043, 0.15323854660347538, 0.79, 1.0, 1.0, 0.08492790018260818, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11048317078225246, 0.11048317078225264, 0.23864752433797734], 
reward next is 0.7614, 
noisyNet noise sample is [array([-0.11158351], dtype=float32), -0.72010726]. 
=============================================
[2019-03-26 11:23:44,333] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1707884e-15 1.0000000e+00 5.5324503e-18 4.0377619e-12 5.3127364e-11], sum to 1.0000
[2019-03-26 11:23:44,342] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8154
[2019-03-26 11:23:44,348] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.65, 96.0, 1.0, 2.0, 0.7174834026803589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1073897.236046703, 1073897.236046703, 233953.9649880056], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 142200.0000, 
sim time next is 142800.0000, 
raw observation next is [22.63333333333333, 96.0, 1.0, 2.0, 0.7330645965442325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1097865.417183944, 1097865.417183944, 237780.0226941984], 
processed observation next is [1.0, 0.6521739130434783, 0.27172195892575024, 0.96, 1.0, 1.0, 0.6783910801737741, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3049626158844289, 0.3049626158844289, 0.3548955562599976], 
reward next is 0.6451, 
noisyNet noise sample is [array([0.3043471], dtype=float32), -1.247651]. 
=============================================
[2019-03-26 11:23:45,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.1168253e-20 1.0000000e+00 2.1118453e-23 1.3126028e-20 1.0806499e-18], sum to 1.0000
[2019-03-26 11:23:45,828] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3517
[2019-03-26 11:23:45,832] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 75.0, 1.0, 2.0, 0.407138167310761, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663157.342125536, 663157.3421255352, 180406.5290903884], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 381600.0000, 
sim time next is 382200.0000, 
raw observation next is [21.98333333333333, 74.5, 1.0, 2.0, 0.478043141022105, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 778574.8402033462, 778574.8402033462, 191805.6140737044], 
processed observation next is [1.0, 0.43478260869565216, 0.24091627172195884, 0.745, 1.0, 1.0, 0.3711363144844638, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21627078894537394, 0.21627078894537394, 0.2862770359309021], 
reward next is 0.7137, 
noisyNet noise sample is [array([-1.6977322], dtype=float32), -0.018865997]. 
=============================================
[2019-03-26 11:23:51,637] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.2088104e-22 1.0000000e+00 4.6410181e-25 3.1379498e-23 2.4225398e-20], sum to 1.0000
[2019-03-26 11:23:51,644] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9698
[2019-03-26 11:23:51,647] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 85.0, 1.0, 2.0, 0.2886586707403454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 462513.7222599693, 462513.72225997, 164432.0790236724], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 329400.0000, 
sim time next is 330000.0000, 
raw observation next is [21.43333333333333, 85.33333333333333, 1.0, 2.0, 0.2878063677158854, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461361.9366500977, 461361.9366500982, 164355.0262740652], 
processed observation next is [0.0, 0.8260869565217391, 0.21484992101105835, 0.8533333333333333, 1.0, 1.0, 0.14193538279022339, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12815609351391602, 0.12815609351391616, 0.2453060093642764], 
reward next is 0.7547, 
noisyNet noise sample is [array([0.5453992], dtype=float32), -0.76757914]. 
=============================================
[2019-03-26 11:23:51,653] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.04381 ]
 [77.014435]
 [76.98833 ]
 [76.9658  ]
 [76.877625]], R is [[77.06082153]
 [77.04479218]
 [77.02880096]
 [77.01280975]
 [76.99672699]].
[2019-03-26 11:24:03,935] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7112820e-17 1.0000000e+00 1.0666309e-18 7.0716870e-14 8.2091587e-13], sum to 1.0000
[2019-03-26 11:24:03,944] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1013
[2019-03-26 11:24:03,949] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 53.33333333333334, 1.0, 2.0, 0.5701738353817984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 936418.0374867588, 936418.0374867594, 209354.1819427049], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 490800.0000, 
sim time next is 491400.0000, 
raw observation next is [24.75, 53.5, 1.0, 2.0, 0.5747622264378489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944144.329170262, 944144.329170262, 210297.642093279], 
processed observation next is [1.0, 0.6956521739130435, 0.3720379146919432, 0.535, 1.0, 1.0, 0.48766533305764925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2622623136584061, 0.2622623136584061, 0.3138770777511627], 
reward next is 0.6861, 
noisyNet noise sample is [array([-1.0288877], dtype=float32), -1.8804781]. 
=============================================
[2019-03-26 11:24:11,485] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.1115047e-19 1.0000000e+00 6.3438195e-22 6.4856102e-17 1.0635001e-15], sum to 1.0000
[2019-03-26 11:24:11,496] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6686
[2019-03-26 11:24:11,501] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.26666666666667, 81.5, 1.0, 2.0, 0.2289954706381522, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380504.1474334769, 380504.1474334762, 158613.0745081647], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [19.13333333333333, 82.0, 1.0, 2.0, 0.2283519834090758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 379638.9429128517, 379638.9429128511, 158517.9449274642], 
processed observation next is [1.0, 0.9565217391304348, 0.10584518167456543, 0.82, 1.0, 1.0, 0.07030359446876602, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10545526192023658, 0.10545526192023642, 0.23659394765293165], 
reward next is 0.7634, 
noisyNet noise sample is [array([0.767524], dtype=float32), 0.72769994]. 
=============================================
[2019-03-26 11:24:12,173] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.4513133e-21 1.0000000e+00 3.3939907e-25 4.3544830e-24 1.2063238e-20], sum to 1.0000
[2019-03-26 11:24:12,184] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2183
[2019-03-26 11:24:12,192] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 77.0, 1.0, 2.0, 0.239321091635534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 396326.0416068228, 396326.0416068222, 159740.0358387126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631800.0000, 
sim time next is 632400.0000, 
raw observation next is [20.53333333333333, 76.0, 1.0, 2.0, 0.2415907449897015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399704.3218930089, 399704.3218930089, 159988.1921951164], 
processed observation next is [1.0, 0.30434782608695654, 0.17219589257503945, 0.76, 1.0, 1.0, 0.08625390962614639, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11102897830361358, 0.11102897830361358, 0.23878834655987521], 
reward next is 0.7612, 
noisyNet noise sample is [array([1.7996637], dtype=float32), 0.620425]. 
=============================================
[2019-03-26 11:24:12,956] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4375594e-20 1.0000000e+00 1.7444556e-22 3.9913036e-21 6.1233534e-17], sum to 1.0000
[2019-03-26 11:24:12,965] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8874
[2019-03-26 11:24:12,971] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.33333333333334, 72.33333333333334, 1.0, 2.0, 0.3499500078984439, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 577136.3519913014, 577136.351991302, 172492.5667516778], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 634800.0000, 
sim time next is 635400.0000, 
raw observation next is [21.5, 71.5, 1.0, 2.0, 0.3807037680022441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 627504.771609925, 627504.771609925, 176693.1715568655], 
processed observation next is [1.0, 0.34782608695652173, 0.21800947867298584, 0.715, 1.0, 1.0, 0.2538599614484869, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17430688100275693, 0.17430688100275693, 0.2637211515774112], 
reward next is 0.7363, 
noisyNet noise sample is [array([-0.11531197], dtype=float32), 0.7771767]. 
=============================================
[2019-03-26 11:24:14,547] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.4420625e-21 1.0000000e+00 2.1531353e-24 1.2391383e-23 1.7319708e-21], sum to 1.0000
[2019-03-26 11:24:14,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0187
[2019-03-26 11:24:14,560] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.03333333333333, 89.0, 1.0, 2.0, 0.2905845694615148, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 465239.306335016, 465239.3063350153, 164616.4221326529], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 873600.0000, 
sim time next is 874200.0000, 
raw observation next is [21.01666666666667, 89.0, 1.0, 2.0, 0.2899520473730447, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 464383.0859698807, 464383.0859698813, 164558.8641335424], 
processed observation next is [0.0, 0.08695652173913043, 0.1951026856240128, 0.89, 1.0, 1.0, 0.1445205390036683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1289953016583002, 0.12899530165830037, 0.24561024497543643], 
reward next is 0.7544, 
noisyNet noise sample is [array([1.2784798], dtype=float32), -1.8806196]. 
=============================================
[2019-03-26 11:24:15,059] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.9900949e-19 1.0000000e+00 2.5517704e-21 1.5885913e-17 1.8141253e-16], sum to 1.0000
[2019-03-26 11:24:15,067] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4144
[2019-03-26 11:24:15,072] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.61666666666667, 59.0, 1.0, 2.0, 0.2432724582250208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400281.1823143181, 400281.1823143174, 160248.1785644904], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 669000.0000, 
sim time next is 669600.0000, 
raw observation next is [23.4, 60.0, 1.0, 2.0, 0.246842079243286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 406347.7311477184, 406347.7311477184, 160589.7111319035], 
processed observation next is [1.0, 0.782608695652174, 0.30805687203791465, 0.6, 1.0, 1.0, 0.0925808183654048, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1128743697632551, 0.1128743697632551, 0.2396861360177664], 
reward next is 0.7603, 
noisyNet noise sample is [array([1.3280185], dtype=float32), 0.17176637]. 
=============================================
[2019-03-26 11:24:16,706] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0097790e-17 1.0000000e+00 1.2719223e-20 1.5365017e-15 8.9437646e-14], sum to 1.0000
[2019-03-26 11:24:16,715] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0965
[2019-03-26 11:24:16,722] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 56.0, 1.0, 2.0, 0.5410158222457473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879874.7795319294, 879874.7795319294, 203320.0198753377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 733200.0000, 
sim time next is 733800.0000, 
raw observation next is [25.13333333333333, 55.5, 1.0, 2.0, 0.5358969499269023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 871885.0325699777, 871885.0325699777, 202343.5722974583], 
processed observation next is [1.0, 0.4782608695652174, 0.3902053712480251, 0.555, 1.0, 1.0, 0.44083969870711115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2421902868249938, 0.2421902868249938, 0.3020053317872512], 
reward next is 0.6980, 
noisyNet noise sample is [array([0.53272754], dtype=float32), 2.5261993]. 
=============================================
[2019-03-26 11:24:18,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.8887498e-18 1.0000000e+00 5.6793870e-22 1.3736212e-17 2.5158692e-16], sum to 1.0000
[2019-03-26 11:24:18,281] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4771
[2019-03-26 11:24:18,286] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 56.0, 1.0, 2.0, 0.5410158222457473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 879874.7795319294, 879874.7795319294, 203320.0198753377], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 733200.0000, 
sim time next is 733800.0000, 
raw observation next is [25.13333333333333, 55.5, 1.0, 2.0, 0.5358969499269023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 871885.0325699777, 871885.0325699777, 202343.5722974583], 
processed observation next is [1.0, 0.4782608695652174, 0.3902053712480251, 0.555, 1.0, 1.0, 0.44083969870711115, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2421902868249938, 0.2421902868249938, 0.3020053317872512], 
reward next is 0.6980, 
noisyNet noise sample is [array([-0.67621326], dtype=float32), 0.024408622]. 
=============================================
[2019-03-26 11:24:24,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.0972906e-22 1.0000000e+00 1.6693942e-26 3.9930315e-25 5.2190823e-21], sum to 1.0000
[2019-03-26 11:24:24,604] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8007
[2019-03-26 11:24:24,610] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 71.5, 1.0, 2.0, 0.3073976139881159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 486794.0238675697, 486794.0238675704, 166064.0744667145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 837000.0000, 
sim time next is 837600.0000, 
raw observation next is [23.96666666666667, 72.0, 1.0, 2.0, 0.3088691677278808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 488660.4118502186, 488660.4118502192, 166190.8060545051], 
processed observation next is [0.0, 0.6956521739130435, 0.33491311216429714, 0.72, 1.0, 1.0, 0.16731225027455518, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1357390032917274, 0.13573900329172756, 0.24804597918582852], 
reward next is 0.7520, 
noisyNet noise sample is [array([1.4643285], dtype=float32), 2.6085684]. 
=============================================
[2019-03-26 11:24:31,309] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 11:24:31,311] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:24:31,312] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:24:31,313] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:24:31,314] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:24:31,315] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:24:31,316] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:24:31,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:24:31,318] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:24:31,318] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:24:31,319] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:24:31,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-26 11:24:31,355] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-26 11:24:31,356] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-26 11:24:31,395] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-26 11:24:31,412] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-26 11:24:51,935] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28270566], dtype=float32), 0.08993523]
[2019-03-26 11:24:51,936] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.43865014666667, 89.38530317333334, 1.0, 2.0, 0.6022555185310174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 841615.1227295261, 841615.1227295261, 201166.1272106528]
[2019-03-26 11:24:51,937] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:24:51,941] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3955496e-20 1.0000000e+00 3.0200287e-23 4.4451535e-21 1.9775004e-18], sampled 0.4840790136299893
[2019-03-26 11:25:09,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.28270566], dtype=float32), 0.08993523]
[2019-03-26 11:25:09,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.8, 70.0, 1.0, 2.0, 0.5414099804074658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 756556.936017947, 756556.9360179463, 190337.5117750817]
[2019-03-26 11:25:09,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:25:09,918] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5065432e-20 1.0000000e+00 3.7171650e-23 5.8052776e-20 3.3229653e-18], sampled 0.10341141085596894
[2019-03-26 11:25:18,599] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.28270566], dtype=float32), 0.08993523]
[2019-03-26 11:25:18,599] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.44410271333334, 53.09233669666667, 1.0, 2.0, 0.5537093244207936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 773750.086275552, 773750.0862755514, 192439.7837747267]
[2019-03-26 11:25:18,600] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:25:18,603] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5870140e-20 1.0000000e+00 1.8254061e-23 1.8902130e-20 1.4504837e-18], sampled 0.5838453286310058
[2019-03-26 11:25:28,261] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28270566], dtype=float32), 0.08993523]
[2019-03-26 11:25:28,262] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.83333333333334, 60.5, 1.0, 2.0, 0.5913252310518421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826334.7751314177, 826334.7751314177, 199141.6164013741]
[2019-03-26 11:25:28,263] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:25:28,266] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4905599e-21 1.0000000e+00 5.4985802e-24 1.1043020e-21 3.9953902e-19], sampled 0.3103719796601023
[2019-03-26 11:25:29,880] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.28270566], dtype=float32), 0.08993523]
[2019-03-26 11:25:29,881] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 79.0, 1.0, 2.0, 0.5654753550618963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790197.9826860642, 790197.9826860642, 194492.0020716172]
[2019-03-26 11:25:29,883] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:25:29,887] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3768133e-21 1.0000000e+00 3.6790266e-27 1.0352643e-22 1.3566058e-21], sampled 0.7932458968028303
[2019-03-26 11:26:26,470] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8685.4193 2776924068.6823 874.0000
[2019-03-26 11:26:26,708] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8006.2739 3153272274.8645 1503.0000
[2019-03-26 11:26:26,716] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8295.5023 2923238920.3075 1243.0000
[2019-03-26 11:26:26,744] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8542.1957 2838426779.6097 1025.0000
[2019-03-26 11:26:26,814] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8055.6300 3002355825.5504 1636.0000
[2019-03-26 11:26:27,834] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 875000, evaluation results [875000.0, 8006.2738846029715, 3153272274.8644834, 1503.0, 8295.50225983824, 2923238920.307536, 1243.0, 8685.41933702138, 2776924068.68231, 874.0, 8055.6300139912155, 3002355825.550427, 1636.0, 8542.195706034578, 2838426779.6096625, 1025.0]
[2019-03-26 11:26:30,212] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1069096e-19 1.0000000e+00 9.1290033e-22 6.2244787e-18 3.1539566e-17], sum to 1.0000
[2019-03-26 11:26:30,220] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8114
[2019-03-26 11:26:30,227] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.572083840880808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 881354.7436216968, 881354.7436216968, 205522.3976105014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 986400.0000, 
sim time next is 987000.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.654795584693358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1008446.270262785, 1008446.270262785, 222905.818017141], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.584091065895612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2801239639618847, 0.2801239639618847, 0.33269525077185225], 
reward next is 0.6673, 
noisyNet noise sample is [array([1.2954835], dtype=float32), 0.6071612]. 
=============================================
[2019-03-26 11:26:30,238] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.91683 ]
 [68.87961 ]
 [69.122185]
 [69.40846 ]
 [69.854065]], R is [[68.09899139]
 [68.11125183]
 [68.11897278]
 [68.12862396]
 [68.14094543]].
[2019-03-26 11:26:32,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4611880e-19 1.0000000e+00 1.1456153e-20 1.0743013e-15 9.7650769e-15], sum to 1.0000
[2019-03-26 11:26:32,282] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4666
[2019-03-26 11:26:32,294] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.98333333333333, 97.83333333333334, 1.0, 2.0, 0.3643513155949491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553924.9319534462, 553924.9319534457, 170759.8298645259], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1032600.0000, 
sim time next is 1033200.0000, 
raw observation next is [22.0, 98.0, 1.0, 2.0, 0.3695972679602647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561246.9547247476, 561246.9547247476, 171367.356081686], 
processed observation next is [1.0, 1.0, 0.2417061611374408, 0.98, 1.0, 1.0, 0.24047863609670447, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15590193186798543, 0.15590193186798543, 0.2557721732562478], 
reward next is 0.7442, 
noisyNet noise sample is [array([0.02226461], dtype=float32), -1.4766808]. 
=============================================
[2019-03-26 11:26:43,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.1306078e-18 1.0000000e+00 3.1662099e-21 7.1446495e-19 3.2466363e-16], sum to 1.0000
[2019-03-26 11:26:43,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1371
[2019-03-26 11:26:43,464] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.85, 92.5, 1.0, 2.0, 0.3702202436027319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 575654.3116356224, 575654.311635623, 172952.9782742802], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1222200.0000, 
sim time next is 1222800.0000, 
raw observation next is [21.83333333333334, 92.66666666666667, 1.0, 2.0, 0.354959699653924, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 551870.001663338, 551870.001663338, 170931.3663231286], 
processed observation next is [1.0, 0.13043478260869565, 0.23380726698262277, 0.9266666666666667, 1.0, 1.0, 0.2228430116312337, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15329722268426058, 0.15329722268426058, 0.2551214422733263], 
reward next is 0.7449, 
noisyNet noise sample is [array([0.22628881], dtype=float32), 1.8072007]. 
=============================================
[2019-03-26 11:26:47,996] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2106274e-16 1.0000000e+00 7.8179704e-19 1.6448438e-13 2.9745499e-13], sum to 1.0000
[2019-03-26 11:26:48,007] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2321
[2019-03-26 11:26:48,014] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.43333333333333, 93.83333333333334, 1.0, 2.0, 0.4652921092080324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 656526.3596905082, 656526.3596905082, 179158.3157068784], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1291800.0000, 
sim time next is 1292400.0000, 
raw observation next is [24.4, 94.0, 1.0, 2.0, 0.4646238933654218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655924.6479070106, 655924.6479070106, 179103.355951271], 
processed observation next is [1.0, 1.0, 0.3554502369668246, 0.94, 1.0, 1.0, 0.3549685462233998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18220129108528074, 0.18220129108528074, 0.2673184417183149], 
reward next is 0.7327, 
noisyNet noise sample is [array([0.93117017], dtype=float32), -1.66481]. 
=============================================
[2019-03-26 11:26:52,955] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4148619e-20 1.0000000e+00 6.4268271e-23 4.8247894e-18 9.1717472e-18], sum to 1.0000
[2019-03-26 11:26:52,963] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5693
[2019-03-26 11:26:52,966] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 97.0, 1.0, 2.0, 0.3088412434139835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490359.6519182649, 490359.6519182649, 166348.5116356953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1383600.0000, 
sim time next is 1384200.0000, 
raw observation next is [20.45, 97.0, 1.0, 2.0, 0.3113004068474109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 494451.5192349766, 494451.5192349772, 166652.224787149], 
processed observation next is [0.0, 0.0, 0.16824644549763035, 0.97, 1.0, 1.0, 0.17024145403302515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13734764423193796, 0.1373476442319381, 0.2487346638614164], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.17675383], dtype=float32), 0.15805338]. 
=============================================
[2019-03-26 11:27:07,754] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3506541e-18 1.0000000e+00 1.8271568e-21 5.2657087e-17 8.6222863e-15], sum to 1.0000
[2019-03-26 11:27:07,762] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6116
[2019-03-26 11:27:07,770] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.16666666666667, 96.33333333333333, 1.0, 2.0, 0.4164400034122114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611138.6189723732, 611138.6189723732, 175287.062005289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1632000.0000, 
sim time next is 1632600.0000, 
raw observation next is [23.15, 96.5, 1.0, 2.0, 0.4165286868239017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 611177.3138799083, 611177.3138799083, 175288.096109286], 
processed observation next is [1.0, 0.9130434782608695, 0.2962085308056872, 0.965, 1.0, 1.0, 0.2970225142456647, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1697714760777523, 0.1697714760777523, 0.26162402404371043], 
reward next is 0.7384, 
noisyNet noise sample is [array([1.1913571], dtype=float32), 0.36052707]. 
=============================================
[2019-03-26 11:27:15,385] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.9315056e-18 1.0000000e+00 3.2174725e-19 2.1864267e-15 9.2933008e-15], sum to 1.0000
[2019-03-26 11:27:15,394] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5003
[2019-03-26 11:27:15,397] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.13333333333333, 96.66666666666666, 1.0, 2.0, 0.4178358495282614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 613399.0595182208, 613399.0595182214, 175507.790073486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1978800.0000, 
sim time next is 1979400.0000, 
raw observation next is [23.16666666666666, 96.83333333333334, 1.0, 2.0, 0.4200953839593341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 615447.9821304696, 615447.9821304696, 175667.3530107417], 
processed observation next is [1.0, 0.9130434782608695, 0.2969984202211688, 0.9683333333333334, 1.0, 1.0, 0.30131973971004106, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17095777281401933, 0.17095777281401933, 0.26219007912051], 
reward next is 0.7378, 
noisyNet noise sample is [array([-1.0259116], dtype=float32), -0.6674798]. 
=============================================
[2019-03-26 11:27:18,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9763552e-17 1.0000000e+00 1.0143246e-19 2.8318556e-14 3.4032780e-15], sum to 1.0000
[2019-03-26 11:27:18,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8919
[2019-03-26 11:27:18,472] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.15, 87.0, 1.0, 2.0, 0.4957861015139746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 692782.1274833999, 692782.1274833992, 182938.405005409], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1881000.0000, 
sim time next is 1881600.0000, 
raw observation next is [26.06666666666667, 87.0, 1.0, 2.0, 0.4928728000745627, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 688709.9329947385, 688709.9329947378, 182486.8250618642], 
processed observation next is [1.0, 0.782608695652174, 0.4344391785150081, 0.87, 1.0, 1.0, 0.38900337358381043, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19130831472076068, 0.1913083147207605, 0.27236839561472265], 
reward next is 0.7276, 
noisyNet noise sample is [array([0.10858117], dtype=float32), 0.7469727]. 
=============================================
[2019-03-26 11:27:18,992] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4139299e-18 1.0000000e+00 9.8577866e-22 2.5259157e-18 2.8090649e-16], sum to 1.0000
[2019-03-26 11:27:19,003] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0248
[2019-03-26 11:27:19,013] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.1, 88.0, 1.0, 2.0, 0.4644061241375815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 658324.6432128618, 658324.6432128613, 179418.0188848631], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1890000.0000, 
sim time next is 1890600.0000, 
raw observation next is [25.03333333333333, 88.33333333333334, 1.0, 2.0, 0.4619212663082412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 655440.5529497884, 655440.5529497884, 179131.7906215914], 
processed observation next is [1.0, 0.9130434782608695, 0.38546603475513425, 0.8833333333333334, 1.0, 1.0, 0.3517123690460738, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18206682026383011, 0.18206682026383011, 0.2673608815247633], 
reward next is 0.7326, 
noisyNet noise sample is [array([-0.5183587], dtype=float32), 1.2952675]. 
=============================================
[2019-03-26 11:27:22,180] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 11:27:22,183] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:27:22,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:27:22,187] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:27:22,188] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:27:22,189] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:27:22,191] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:27:22,192] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:27:22,194] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:27:22,195] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:27:22,193] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:27:22,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-26 11:27:22,235] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-26 11:27:22,254] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-26 11:27:22,257] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-26 11:27:22,297] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-26 11:27:32,879] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.27758545], dtype=float32), 0.09138199]
[2019-03-26 11:27:32,880] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.65, 72.5, 1.0, 2.0, 0.3864823999198497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 625870.9885391039, 625870.9885391039, 177241.9732308179]
[2019-03-26 11:27:32,883] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:27:32,888] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8875904e-19 1.0000000e+00 1.3366344e-20 2.1075048e-18 1.7167868e-16], sampled 0.5403018573988788
[2019-03-26 11:27:54,860] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.27758545], dtype=float32), 0.09138199]
[2019-03-26 11:27:54,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.35803462, 90.97467919666667, 1.0, 2.0, 0.5214556960734658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728663.60061294, 728663.60061294, 187026.1435642265]
[2019-03-26 11:27:54,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:27:54,864] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.0254686e-17 1.0000000e+00 1.5576445e-18 7.7155235e-14 1.6747377e-13], sampled 0.3777119663507682
[2019-03-26 11:28:56,069] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.27758545], dtype=float32), 0.09138199]
[2019-03-26 11:28:56,070] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.54213997333333, 77.04473359333333, 1.0, 2.0, 0.5067306274573077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 708080.4567181981, 708080.4567181976, 184656.3789586912]
[2019-03-26 11:28:56,071] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:28:56,075] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2497902e-17 1.0000000e+00 1.7721391e-19 6.4078568e-15 1.4083640e-14], sampled 0.43069071503475287
[2019-03-26 11:29:16,650] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8201.3757 3137320892.4507 1010.0000
[2019-03-26 11:29:17,117] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8661.6952 2828967321.3467 744.0000
[2019-03-26 11:29:17,180] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8460.1708 2911802382.3707 890.0000
[2019-03-26 11:29:17,185] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8324.7493 2981305497.0674 1028.0000
[2019-03-26 11:29:17,207] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8775.6851 2769714929.0871 678.0000
[2019-03-26 11:29:18,222] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 900000, evaluation results [900000.0, 8201.375670665459, 3137320892.4507303, 1010.0, 8460.170813390445, 2911802382.370719, 890.0, 8775.685111044158, 2769714929.087115, 678.0, 8324.749250812156, 2981305497.0674486, 1028.0, 8661.695234111925, 2828967321.3467135, 744.0]
[2019-03-26 11:29:18,740] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.6446696e-15 1.0000000e+00 2.9829182e-17 1.5115838e-12 1.1002200e-12], sum to 1.0000
[2019-03-26 11:29:18,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3102
[2019-03-26 11:29:18,752] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.28333333333333, 95.16666666666667, 1.0, 2.0, 0.463167910437884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 653043.0560201956, 653043.0560201956, 178782.3635346329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1905000.0000, 
sim time next is 1905600.0000, 
raw observation next is [24.26666666666667, 95.33333333333334, 1.0, 2.0, 0.4635317561565127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 653402.7227129347, 653402.7227129353, 178816.2047037553], 
processed observation next is [1.0, 0.043478260869565216, 0.34913112164297017, 0.9533333333333335, 1.0, 1.0, 0.3536527182608587, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18150075630914853, 0.1815007563091487, 0.26688985776679897], 
reward next is 0.7331, 
noisyNet noise sample is [array([0.48603928], dtype=float32), 0.6349928]. 
=============================================
[2019-03-26 11:29:31,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0423376e-17 1.0000000e+00 5.4223985e-19 4.4758590e-13 2.2932903e-13], sum to 1.0000
[2019-03-26 11:29:31,220] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5269
[2019-03-26 11:29:31,226] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.9, 93.0, 1.0, 2.0, 0.552380441864277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771892.4390403318, 771892.4390403318, 192209.9112043129], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2498400.0000, 
sim time next is 2499000.0000, 
raw observation next is [26.88333333333333, 93.16666666666667, 1.0, 2.0, 0.5519965502658011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771355.7969124786, 771355.7969124786, 192143.8699131767], 
processed observation next is [1.0, 0.9565217391304348, 0.47314375987361756, 0.9316666666666668, 1.0, 1.0, 0.4602368075491579, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21426549914235518, 0.21426549914235518, 0.286781895392801], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.58389497], dtype=float32), -1.2634172]. 
=============================================
[2019-03-26 11:29:31,241] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[73.75935 ]
 [73.50294 ]
 [73.717094]
 [73.54425 ]
 [73.06014 ]], R is [[73.83995819]
 [73.81468201]
 [73.78960419]
 [73.76461029]
 [73.73960876]].
[2019-03-26 11:29:31,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.9461052e-17 1.0000000e+00 4.6966886e-19 1.4489425e-12 3.6708323e-12], sum to 1.0000
[2019-03-26 11:29:31,522] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3688
[2019-03-26 11:29:31,529] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.76666666666667, 94.0, 1.0, 2.0, 0.552070865847513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771459.6826550601, 771459.6826550601, 192156.6470472417], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2503200.0000, 
sim time next is 2503800.0000, 
raw observation next is [26.75, 94.0, 1.0, 2.0, 0.551534643858489, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770710.0982300511, 770710.0982300511, 192064.3922580315], 
processed observation next is [1.0, 1.0, 0.4668246445497631, 0.94, 1.0, 1.0, 0.4596802938054085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21408613839723642, 0.21408613839723642, 0.28666327202691266], 
reward next is 0.7133, 
noisyNet noise sample is [array([-1.4616505], dtype=float32), -0.5281208]. 
=============================================
[2019-03-26 11:29:42,630] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.3627974e-23 1.0000000e+00 4.2275769e-27 3.3129350e-29 6.3243622e-24], sum to 1.0000
[2019-03-26 11:29:42,638] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5073
[2019-03-26 11:29:42,642] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 100.0, 1.0, 2.0, 0.4755042199235282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 664432.5644943232, 664432.5644943238, 179847.056403567], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2700000.0000, 
sim time next is 2700600.0000, 
raw observation next is [24.0, 100.0, 1.0, 2.0, 0.4758230458241832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 664878.2063941116, 664878.206394111, 179894.6935287791], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 1.0, 1.0, 0.3684615009929918, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.184688390665031, 0.18468839066503084, 0.2684995425802673], 
reward next is 0.7315, 
noisyNet noise sample is [array([1.3364239], dtype=float32), 1.2919378]. 
=============================================
[2019-03-26 11:29:44,127] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.5193936e-23 1.0000000e+00 9.7271644e-28 1.7714297e-26 2.0742434e-20], sum to 1.0000
[2019-03-26 11:29:44,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5040
[2019-03-26 11:29:44,136] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666666, 70.66666666666667, 1.0, 2.0, 0.5678245230785808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793481.9475389589, 793481.9475389589, 194905.5421730985], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2313600.0000, 
sim time next is 2314200.0000, 
raw observation next is [31.03333333333333, 71.33333333333333, 1.0, 2.0, 0.5675287176369502, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793068.4326352568, 793068.4326352568, 194853.256522012], 
processed observation next is [1.0, 0.782608695652174, 0.669826224328594, 0.7133333333333333, 1.0, 1.0, 0.47895026221319303, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2202967868431269, 0.2202967868431269, 0.290825756003003], 
reward next is 0.7092, 
noisyNet noise sample is [array([1.1106609], dtype=float32), -0.15815215]. 
=============================================
[2019-03-26 11:29:56,206] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2541681e-15 1.0000000e+00 7.4728694e-17 5.9834724e-12 7.0045009e-10], sum to 1.0000
[2019-03-26 11:29:56,213] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8521
[2019-03-26 11:29:56,221] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2047395.058302915 W.
[2019-03-26 11:29:56,226] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 80.66666666666667, 1.0, 2.0, 0.7321439192233185, 1.0, 2.0, 0.7321439192233185, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2047395.058302915, 2047395.058302915, 388186.905215153], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2544600.0000, 
sim time next is 2545200.0000, 
raw observation next is [28.4, 80.0, 1.0, 2.0, 0.8109891286223954, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.989006294857438, 6.9112, 168.9124932721617, 2030453.238044517, 1975254.925966634, 411201.2977661993], 
processed observation next is [1.0, 0.4782608695652174, 0.5450236966824644, 0.8, 1.0, 1.0, 0.7722760585811992, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0077806294857437844, 0.0, 0.829437670440329, 0.5640147883456992, 0.5486819238796206, 0.6137332802480586], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.27669135], dtype=float32), -1.4009857]. 
=============================================
[2019-03-26 11:29:57,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.4880134e-11 9.9991679e-01 2.4701530e-12 3.7594411e-05 4.5684879e-05], sum to 1.0000
[2019-03-26 11:29:57,141] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9521
[2019-03-26 11:29:57,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2189109.528702948 W.
[2019-03-26 11:29:57,155] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.21666666666667, 75.16666666666667, 1.0, 2.0, 0.7827689696842959, 1.0, 2.0, 0.7827689696842959, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2189109.528702948, 2189109.528702948, 411566.9946727767], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2549400.0000, 
sim time next is 2550000.0000, 
raw observation next is [29.33333333333334, 74.33333333333334, 1.0, 2.0, 0.4378972207382142, 1.0, 2.0, 0.4378972207382142, 1.0, 1.0, 0.7556279107183493, 6.9112, 6.9112, 170.5573041426782, 1836648.138904179, 1836648.138904179, 374104.5564244547], 
processed observation next is [1.0, 0.5217391304347826, 0.5892575039494474, 0.7433333333333334, 1.0, 1.0, 0.32276773582917373, 1.0, 1.0, 0.32276773582917373, 1.0, 0.5, 0.7019852569735966, 0.0, 0.0, 0.8375144448122397, 0.5101800385844941, 0.5101800385844941, 0.5583650095887384], 
reward next is 0.4416, 
noisyNet noise sample is [array([-0.8788495], dtype=float32), -0.07953394]. 
=============================================
[2019-03-26 11:29:57,165] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[56.336273]
 [57.800232]
 [59.05339 ]
 [59.467354]
 [61.041878]], R is [[56.64157486]
 [56.46088028]
 [55.89627075]
 [55.3391571 ]
 [54.7857666 ]].
[2019-03-26 11:30:03,111] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.8716080e-27 1.0000000e+00 1.0060564e-31 6.1285285e-36 1.0666840e-25], sum to 1.0000
[2019-03-26 11:30:03,119] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3815
[2019-03-26 11:30:03,124] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4973365272773845, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 694949.3092605183, 694949.3092605177, 183179.9553532848], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2651400.0000, 
sim time next is 2652000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4972636705872457, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 694847.4702376963, 694847.4702376963, 183168.6027589912], 
processed observation next is [0.0, 0.6956521739130435, 0.4312796208530806, 0.89, 1.0, 1.0, 0.394293579020778, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19301318617713786, 0.19301318617713786, 0.27338597426715106], 
reward next is 0.7266, 
noisyNet noise sample is [array([-0.02534786], dtype=float32), -1.0366496]. 
=============================================
[2019-03-26 11:30:03,139] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[78.43969]
 [78.41733]
 [78.39948]
 [78.40042]
 [78.34184]], R is [[78.40650177]
 [78.34903717]
 [78.29205322]
 [78.2355423 ]
 [78.17980194]].
[2019-03-26 11:30:05,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4274286e-27 1.0000000e+00 8.8465025e-32 0.0000000e+00 4.0212300e-27], sum to 1.0000
[2019-03-26 11:30:05,718] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4836
[2019-03-26 11:30:05,722] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 97.0, 1.0, 2.0, 0.4589323563858841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648904.8517526209, 648904.8517526215, 178397.4658526214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2694600.0000, 
sim time next is 2695200.0000, 
raw observation next is [24.0, 97.33333333333333, 1.0, 2.0, 0.4605251161129595, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 649945.3692947906, 649945.3692947912, 178475.3750857814], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.9733333333333333, 1.0, 1.0, 0.35003026037705964, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18054038035966405, 0.18054038035966424, 0.26638115684444985], 
reward next is 0.7336, 
noisyNet noise sample is [array([-0.7445512], dtype=float32), 1.5785823]. 
=============================================
[2019-03-26 11:30:08,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.7562871e-23 1.0000000e+00 5.9213169e-26 6.1679760e-29 2.0383116e-19], sum to 1.0000
[2019-03-26 11:30:08,785] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1509
[2019-03-26 11:30:08,790] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.66666666666666, 85.0, 1.0, 2.0, 0.7398663022558563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1085476.948340733, 1085476.948340732, 236579.1987460428], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2814000.0000, 
sim time next is 2814600.0000, 
raw observation next is [24.83333333333334, 84.0, 1.0, 2.0, 0.7553082718076954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1107020.553110888, 1107020.553110888, 240178.0434369872], 
processed observation next is [1.0, 0.5652173913043478, 0.3759873617693526, 0.84, 1.0, 1.0, 0.7051906889249343, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3075057091974689, 0.3075057091974689, 0.35847469169699586], 
reward next is 0.6415, 
noisyNet noise sample is [array([0.40621093], dtype=float32), 2.3466177]. 
=============================================
[2019-03-26 11:30:13,078] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 11:30:13,079] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:30:13,082] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:30:13,083] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:30:13,084] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:30:13,085] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:30:13,088] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:30:13,090] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:30:13,083] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:30:13,092] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:30:13,092] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:30:13,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-26 11:30:13,128] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-26 11:30:13,146] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-26 11:30:13,147] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-26 11:30:13,167] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-26 11:30:36,931] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.26531422], dtype=float32), 0.08931981]
[2019-03-26 11:30:36,932] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.20278739666667, 97.76462864333334, 1.0, 2.0, 0.4945529777331496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 691058.4728875804, 691058.4728875804, 182745.8546945596]
[2019-03-26 11:30:36,933] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:30:36,937] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.0851385e-26 1.0000000e+00 3.5604332e-30 4.5771564e-34 3.4077182e-24], sampled 0.44182806272650044
[2019-03-26 11:31:00,987] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.26531422], dtype=float32), 0.08931981]
[2019-03-26 11:31:00,988] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.33333333333333, 78.33333333333334, 1.0, 2.0, 0.5638418887388965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 787914.5223730415, 787914.5223730408, 194202.8663751448]
[2019-03-26 11:31:00,989] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:31:00,991] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.6511400e-27 1.0000000e+00 8.0736319e-31 1.5679811e-34 9.5485775e-25], sampled 0.3424804649006913
[2019-03-26 11:31:42,280] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.26531422], dtype=float32), 0.08931981]
[2019-03-26 11:31:42,282] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.37913477, 56.19944414, 1.0, 2.0, 0.5482524272422493, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9156649850198707, 6.911200000000001, 6.9112, 168.9129563661014, 1540908.774531239, 1540908.774531238, 328563.7285757774]
[2019-03-26 11:31:42,286] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:31:42,290] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8407929e-20 1.0000000e+00 5.8230091e-24 5.3589436e-25 1.9628984e-17], sampled 0.04146797341705577
[2019-03-26 11:31:46,447] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.26531422], dtype=float32), 0.08931981]
[2019-03-26 11:31:46,448] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.5, 73.0, 1.0, 2.0, 0.5848989090452403, 0.0, 2.0, 0.0, 1.0, 1.0, 1.01318584294645, 6.911200000000001, 6.9112, 168.9125615057737, 1635331.447421445, 1635331.447421444, 357506.5420857159]
[2019-03-26 11:31:46,449] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:31:46,454] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.2214869e-20 1.0000000e+00 4.8763828e-23 6.5560103e-23 9.2799712e-17], sampled 0.11704099725355588
[2019-03-26 11:32:07,534] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.26531422], dtype=float32), 0.08931981]
[2019-03-26 11:32:07,535] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.355052, 69.32982231333334, 1.0, 2.0, 0.4510285934981372, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 655391.9905304951, 655391.9905304956, 179484.7273662864]
[2019-03-26 11:32:07,536] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:32:07,538] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.5785165e-26 1.0000000e+00 1.8291080e-30 4.3942922e-34 2.5149858e-24], sampled 0.8726012356969175
[2019-03-26 11:32:08,386] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2953 3007596012.4260 1766.0000
[2019-03-26 11:32:08,567] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1684 3164027848.4855 1778.0000
[2019-03-26 11:32:08,582] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3874 2927351590.9513 1338.0000
[2019-03-26 11:32:08,742] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7167 2779131942.0695 933.0000
[2019-03-26 11:32:08,789] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 11:32:09,803] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 925000, evaluation results [925000.0, 7884.16835844559, 3164027848.485504, 1778.0, 8254.387405552809, 2927351590.9513006, 1338.0, 8660.716715102415, 2779131942.069542, 933.0, 7998.295259250187, 3007596012.4259605, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 11:32:15,412] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6421403e-26 1.0000000e+00 1.9849090e-31 1.4158168e-36 2.6221727e-25], sum to 1.0000
[2019-03-26 11:32:15,428] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3243
[2019-03-26 11:32:15,435] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 71.66666666666667, 1.0, 2.0, 0.6043945498142296, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844605.4761597177, 844605.4761597177, 201567.878803986], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3334200.0000, 
sim time next is 3334800.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.5994192432148906, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837650.039134775, 837650.039134775, 200638.384614923], 
processed observation next is [0.0, 0.6086956521739131, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5173725821866152, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2326805664263264, 0.2326805664263264, 0.2994602755446612], 
reward next is 0.7005, 
noisyNet noise sample is [array([-0.6490334], dtype=float32), -0.72902054]. 
=============================================
[2019-03-26 11:32:16,874] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7524826e-25 1.0000000e+00 1.2417371e-29 5.6467816e-32 3.1641193e-22], sum to 1.0000
[2019-03-26 11:32:16,883] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4821
[2019-03-26 11:32:16,887] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.3022952447846516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481388.7555171007, 481388.7555171007, 165721.4112967301], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2941200.0000, 
sim time next is 2941800.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3024168540965771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 481582.4135163953, 481582.4135163959, 165735.312117779], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 1.0, 1.0, 0.15953837842961094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13377289264344314, 0.1337728926434433, 0.24736613748922237], 
reward next is 0.7526, 
noisyNet noise sample is [array([0.7044393], dtype=float32), 1.3624983]. 
=============================================
[2019-03-26 11:32:18,030] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.8870291e-27 1.0000000e+00 2.7138356e-31 1.0371791e-34 1.5305670e-26], sum to 1.0000
[2019-03-26 11:32:18,040] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2937
[2019-03-26 11:32:18,046] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.4875924157084424, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 681329.0846189507, 681329.0846189507, 181674.5114991432], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3280800.0000, 
sim time next is 3281400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.4870881078076754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 680624.172679582, 680624.172679582, 181597.4172454706], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.79, 1.0, 1.0, 0.3820338648285246, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18906227018877278, 0.18906227018877278, 0.27104092126189644], 
reward next is 0.7290, 
noisyNet noise sample is [array([0.74599314], dtype=float32), 0.111279234]. 
=============================================
[2019-03-26 11:32:20,061] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0803587e-23 1.0000000e+00 2.4317145e-28 3.0415190e-32 8.0266270e-21], sum to 1.0000
[2019-03-26 11:32:20,069] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7474
[2019-03-26 11:32:20,073] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5609949487648926, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 886911.2213742542, 886911.2213742542, 205547.0908245246], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2989800.0000, 
sim time next is 2990400.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.5570100737043119, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 880588.1501533274, 880588.1501533274, 204759.978187945], 
processed observation next is [1.0, 0.6086956521739131, 0.19431279620853087, 0.94, 1.0, 1.0, 0.46627719723411065, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2446078194870354, 0.2446078194870354, 0.3056119077432015], 
reward next is 0.6944, 
noisyNet noise sample is [array([0.794535], dtype=float32), -0.7971217]. 
=============================================
[2019-03-26 11:32:22,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7142700e-23 1.0000000e+00 3.0808106e-26 2.8013860e-28 9.3406589e-19], sum to 1.0000
[2019-03-26 11:32:22,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0618
[2019-03-26 11:32:22,674] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 94.0, 1.0, 2.0, 0.8214801701034867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1180295.802366947, 1180295.802366947, 253793.5278438263], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3081600.0000, 
sim time next is 3082200.0000, 
raw observation next is [23.83333333333333, 95.0, 1.0, 2.0, 0.8370665503745157, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1203420.733259079, 1203420.73325908, 257979.0417563959], 
processed observation next is [1.0, 0.6956521739130435, 0.32859399684044216, 0.95, 1.0, 1.0, 0.8036946390054406, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33428353701641084, 0.3342835370164111, 0.3850433459050685], 
reward next is 0.6150, 
noisyNet noise sample is [array([-0.7123334], dtype=float32), 2.177263]. 
=============================================
[2019-03-26 11:32:27,098] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.2983297e-20 1.0000000e+00 1.6534319e-23 3.6770099e-25 4.2915576e-15], sum to 1.0000
[2019-03-26 11:32:27,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0009
[2019-03-26 11:32:27,115] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1913186.009117882 W.
[2019-03-26 11:32:27,122] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.558373670276964, 6.9112, 168.9090291440716, 1913186.009117882, 1454069.408514715, 311346.4045581208], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3159600.0000, 
sim time next is 3160200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.58380277799898, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9731725580768933, 6.911199999999999, 6.9112, 168.912429498609, 1632264.395358518, 1632264.395358519, 348314.2133796609], 
processed observation next is [1.0, 0.5652173913043478, 0.4312796208530806, 0.84, 1.0, 1.0, 0.4985575638541927, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9672836074108455, -8.881784197001253e-17, 0.0, 0.8294373572829895, 0.4534067764884772, 0.4534067764884775, 0.5198719602681506], 
reward next is 0.4801, 
noisyNet noise sample is [array([-1.0395125], dtype=float32), -1.37447]. 
=============================================
[2019-03-26 11:32:35,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0468372e-27 1.0000000e+00 8.0109517e-32 1.8740647e-36 6.0448171e-24], sum to 1.0000
[2019-03-26 11:32:35,592] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5549
[2019-03-26 11:32:35,597] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 73.33333333333334, 1.0, 2.0, 0.5209711584512375, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727986.2930018047, 727986.2930018047, 186947.8906946398], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3319800.0000, 
sim time next is 3320400.0000, 
raw observation next is [29.66666666666667, 72.66666666666667, 1.0, 2.0, 0.5287594422156511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 738873.1446716838, 738873.1446716838, 188225.5981751533], 
processed observation next is [0.0, 0.43478260869565216, 0.6050552922590839, 0.7266666666666667, 1.0, 1.0, 0.4322402918260856, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20524254018657884, 0.20524254018657884, 0.2809337286196318], 
reward next is 0.7191, 
noisyNet noise sample is [array([-1.0882889], dtype=float32), 2.900073]. 
=============================================
[2019-03-26 11:32:38,292] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.0658746e-26 1.0000000e+00 7.7319753e-30 7.4928639e-36 8.2200332e-24], sum to 1.0000
[2019-03-26 11:32:38,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4340
[2019-03-26 11:32:38,308] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 81.5, 1.0, 2.0, 0.5522574443033643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 771720.5007004391, 771720.5007004397, 192188.5110260873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3353400.0000, 
sim time next is 3354000.0000, 
raw observation next is [28.33333333333333, 82.33333333333334, 1.0, 2.0, 0.5512434416487011, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 770303.0270419847, 770303.0270419847, 192014.0610615548], 
processed observation next is [0.0, 0.8260869565217391, 0.541864139020537, 0.8233333333333335, 1.0, 1.0, 0.45932944776951934, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21397306306721797, 0.21397306306721797, 0.2865881508381415], 
reward next is 0.7134, 
noisyNet noise sample is [array([1.4735738], dtype=float32), 0.07780221]. 
=============================================
[2019-03-26 11:32:38,321] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.28078 ]
 [75.22569 ]
 [75.18251 ]
 [75.11709 ]
 [74.970406]], R is [[75.28741455]
 [75.24768829]
 [75.20792389]
 [75.16819763]
 [75.12836456]].
[2019-03-26 11:32:38,337] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.3539908e-27 1.0000000e+00 1.1815737e-30 4.2276405e-35 5.0357597e-25], sum to 1.0000
[2019-03-26 11:32:38,344] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-26 11:32:38,348] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 74.33333333333333, 1.0, 2.0, 0.5975090512203506, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834979.618799215, 834979.618799215, 200283.1510616608], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3336600.0000, 
sim time next is 3337200.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.595696175992508, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832445.2520829113, 832445.2520829113, 199947.2292352715], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5128869590271181, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23123479224525315, 0.23123479224525315, 0.2984287003511515], 
reward next is 0.7016, 
noisyNet noise sample is [array([-0.5903421], dtype=float32), 0.16916525]. 
=============================================
[2019-03-26 11:32:41,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.8072360e-09 9.9252206e-01 8.3216317e-10 2.9989667e-04 7.1779666e-03], sum to 1.0000
[2019-03-26 11:32:41,645] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7905
[2019-03-26 11:32:41,654] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2598053.92007828 W.
[2019-03-26 11:32:41,660] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 65.5, 1.0, 2.0, 0.9288436042516538, 1.0, 1.0, 0.9288436042516538, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2598053.92007828, 2598053.92007828, 487468.095851099], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3755400.0000, 
sim time next is 3756000.0000, 
raw observation next is [31.66666666666667, 65.0, 1.0, 2.0, 0.9078933265510862, 1.0, 2.0, 0.9078933265510862, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2539394.676523753, 2539394.676523753, 475814.2366570885], 
processed observation next is [1.0, 0.4782608695652174, 0.6998420221169038, 0.65, 1.0, 1.0, 0.8890281042784172, 1.0, 1.0, 0.8890281042784172, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7053874101454869, 0.7053874101454869, 0.7101705024732664], 
reward next is 0.2898, 
noisyNet noise sample is [array([0.14543045], dtype=float32), -0.5356629]. 
=============================================
[2019-03-26 11:32:41,688] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[48.102875]
 [48.770386]
 [48.86607 ]
 [48.79854 ]
 [48.87048 ]], R is [[48.18593216]
 [47.97650909]
 [47.49674606]
 [47.02177811]
 [46.55155945]].
[2019-03-26 11:32:45,671] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.3590247e-13 9.9998486e-01 2.3844935e-14 3.2594527e-10 1.5192288e-05], sum to 1.0000
[2019-03-26 11:32:45,679] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3863
[2019-03-26 11:32:45,691] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2709655.220730109 W.
[2019-03-26 11:32:45,697] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.66666666666667, 61.00000000000001, 1.0, 2.0, 0.9686995382073242, 1.0, 2.0, 0.9686995382073242, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2709655.220730109, 2709655.220730109, 510361.7117122805], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3424800.0000, 
sim time next is 3425400.0000, 
raw observation next is [33.5, 61.5, 1.0, 2.0, 0.9639278046043537, 1.0, 2.0, 0.9639278046043537, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2696293.280327972, 2696293.280327971, 507572.3240798386], 
processed observation next is [1.0, 0.6521739130434783, 0.7867298578199052, 0.615, 1.0, 1.0, 0.9565395236197032, 1.0, 1.0, 0.9565395236197032, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7489703556466589, 0.7489703556466586, 0.757570632954983], 
reward next is 0.2424, 
noisyNet noise sample is [array([3.0494814], dtype=float32), -0.6229103]. 
=============================================
[2019-03-26 11:32:49,330] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.9645038e-27 1.0000000e+00 7.3715611e-33 4.8503542e-38 5.0950834e-24], sum to 1.0000
[2019-03-26 11:32:49,338] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9608
[2019-03-26 11:32:49,342] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.83333333333333, 75.66666666666667, 1.0, 2.0, 0.5581109252399513, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779903.114912132, 779903.114912132, 193201.9338440468], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3525000.0000, 
sim time next is 3525600.0000, 
raw observation next is [29.66666666666667, 76.33333333333334, 1.0, 2.0, 0.556248390816755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777299.4606370268, 777299.4606370262, 192878.5460170452], 
processed observation next is [1.0, 0.8260869565217391, 0.6050552922590839, 0.7633333333333334, 1.0, 1.0, 0.46535950700813855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21591651684361857, 0.2159165168436184, 0.28787842689111226], 
reward next is 0.7121, 
noisyNet noise sample is [array([0.35295552], dtype=float32), 0.8672451]. 
=============================================
[2019-03-26 11:33:04,496] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 11:33:04,499] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:33:04,501] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:33:04,501] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:33:04,503] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:33:04,502] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:33:04,505] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:33:04,507] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:33:04,503] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:33:04,504] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:33:04,510] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:33:04,531] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-26 11:33:04,532] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-26 11:33:04,552] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-26 11:33:04,593] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-26 11:33:04,593] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-26 11:33:31,799] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:33:31,800] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.98333333333333, 86.33333333333334, 1.0, 2.0, 0.5742467566167546, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9749848148142802, 6.9112, 6.9112, 168.9129014216093, 1605526.336263712, 1605526.336263712, 346582.3730743309]
[2019-03-26 11:33:31,801] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:33:31,803] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.3230591e-21 1.0000000e+00 2.4201241e-24 5.9594576e-25 3.7154753e-17], sampled 0.49909410679111554
[2019-03-26 11:33:42,250] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:33:42,250] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.21808607666667, 85.06517164333334, 1.0, 2.0, 0.5354435755032482, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748216.64868361, 748216.64868361, 189334.8236977877]
[2019-03-26 11:33:42,255] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:33:42,258] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.7216710e-27 1.0000000e+00 9.3106076e-32 5.6761845e-36 1.5266909e-24], sampled 0.32711201063966333
[2019-03-26 11:33:42,505] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:33:42,507] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.55, 94.0, 1.0, 2.0, 0.4884136833719727, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684781.0828366879, 684781.0828366879, 182096.8427798822]
[2019-03-26 11:33:42,508] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:33:42,511] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.6855029e-27 1.0000000e+00 2.0803890e-31 3.6023363e-36 1.1143676e-24], sampled 0.9899401771957255
[2019-03-26 11:33:42,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:33:42,799] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.96099559333334, 86.78543689, 1.0, 2.0, 0.3865891396142223, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 580184.9741799444, 580184.9741799444, 172829.1406189108]
[2019-03-26 11:33:42,801] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:33:42,805] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.1884745e-29 1.0000000e+00 1.9078389e-34 0.0000000e+00 1.7984593e-28], sampled 0.34505321083828233
[2019-03-26 11:33:43,147] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:33:43,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.45195381, 83.78726217, 1.0, 2.0, 0.4803421945409142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 681821.30972649, 681821.3097264895, 181936.2285101424]
[2019-03-26 11:33:43,150] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:33:43,153] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1744346e-28 1.0000000e+00 2.5624752e-33 0.0000000e+00 7.4776503e-27], sampled 0.3031416325601053
[2019-03-26 11:34:45,735] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.26297477], dtype=float32), 0.08689636]
[2019-03-26 11:34:45,736] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.15, 78.0, 1.0, 2.0, 0.5011653561224155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 700301.2568763281, 700301.2568763288, 183777.7068280495]
[2019-03-26 11:34:45,737] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:34:45,740] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.9655992e-28 1.0000000e+00 4.8235933e-33 1.4543307e-38 1.8734309e-26], sampled 0.791668907577411
[2019-03-26 11:34:59,963] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 11:35:00,039] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.9677 3164071843.1080 1779.0000
[2019-03-26 11:35:00,201] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7411 2779287197.8403 935.0000
[2019-03-26 11:35:00,212] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7626 2842571369.0137 1131.0000
[2019-03-26 11:35:00,298] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9173 2927278990.0411 1339.0000
[2019-03-26 11:35:01,315] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 950000, evaluation results [950000.0, 7883.967662562098, 3164071843.1079817, 1779.0, 8254.917301856813, 2927278990.0411496, 1339.0, 8660.741073244868, 2779287197.840301, 935.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8496.762600242775, 2842571369.0137076, 1131.0]
[2019-03-26 11:35:01,515] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.9735161e-16 1.0000000e+00 4.3017954e-18 5.2888393e-17 4.2193506e-09], sum to 1.0000
[2019-03-26 11:35:01,523] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2232
[2019-03-26 11:35:01,530] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2524460.149157951 W.
[2019-03-26 11:35:01,535] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.83333333333334, 60.5, 1.0, 2.0, 0.6017061801383082, 1.0, 2.0, 0.6017061801383082, 1.0, 1.0, 1.03, 6.928022577908757, 6.9112, 170.5573041426782, 2524460.149157951, 2512409.45230319, 488598.4434414193], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3769800.0000, 
sim time next is 3770400.0000, 
raw observation next is [33.66666666666667, 61.00000000000001, 1.0, 2.0, 0.6877453645570738, 1.0, 2.0, 0.6644627217927996, 1.0, 2.0, 1.03, 7.005096765909276, 6.9112, 170.5573041426782, 2788049.19723169, 2720787.124334641, 517486.473835696], 
processed observation next is [1.0, 0.6521739130434783, 0.7946287519747238, 0.6100000000000001, 1.0, 1.0, 0.6237895958518961, 1.0, 1.0, 0.5957382190274694, 1.0, 1.0, 1.0365853658536586, 0.009389676590927643, 0.0, 0.8375144448122397, 0.7744581103421361, 0.7557742012040669, 0.7723678713965612], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5461973], dtype=float32), -0.97124636]. 
=============================================
[2019-03-26 11:35:02,907] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.9517458e-29 1.0000000e+00 3.5089457e-34 0.0000000e+00 4.8636636e-28], sum to 1.0000
[2019-03-26 11:35:02,914] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5893
[2019-03-26 11:35:02,921] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5426236123804976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 758253.4496400048, 758253.4496400041, 190543.3025044145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3817200.0000, 
sim time next is 3817800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5418825655360843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 757217.5536805951, 757217.5536805957, 190417.9670020627], 
processed observation next is [0.0, 0.17391304347826086, 0.4786729857819906, 0.89, 1.0, 1.0, 0.44805128377841474, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21033820935572087, 0.21033820935572103, 0.2842059208986011], 
reward next is 0.7158, 
noisyNet noise sample is [array([1.4042286], dtype=float32), -1.3611968]. 
=============================================
[2019-03-26 11:35:03,062] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.7003843e-28 1.0000000e+00 7.2678832e-34 0.0000000e+00 1.5419471e-27], sum to 1.0000
[2019-03-26 11:35:03,069] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2861
[2019-03-26 11:35:03,081] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.5372182014358915, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 750697.3467929722, 750697.3467929728, 189632.8018916804], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3819600.0000, 
sim time next is 3820200.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.5367293006554279, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750013.925996794, 750013.9259967934, 189550.8769393339], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.4418425309101541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20833720166577613, 0.20833720166577596, 0.2829117566258715], 
reward next is 0.7171, 
noisyNet noise sample is [array([-0.95129126], dtype=float32), 2.7435088]. 
=============================================
[2019-03-26 11:35:10,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.7748975e-24 1.0000000e+00 4.8751454e-27 2.5084436e-30 3.5134998e-19], sum to 1.0000
[2019-03-26 11:35:10,372] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0829
[2019-03-26 11:35:10,377] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.66666666666667, 84.0, 1.0, 2.0, 0.6130253333528325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 856671.347422672, 856671.347422672, 203197.3067250598], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3975600.0000, 
sim time next is 3976200.0000, 
raw observation next is [29.5, 84.0, 1.0, 2.0, 0.6049915084141082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 845440.0223513092, 845440.0223513092, 201679.2590424644], 
processed observation next is [1.0, 0.0, 0.5971563981042655, 0.84, 1.0, 1.0, 0.524086154715793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23484445065314144, 0.23484445065314144, 0.3010138194663648], 
reward next is 0.6990, 
noisyNet noise sample is [array([0.09480899], dtype=float32), -0.21903042]. 
=============================================
[2019-03-26 11:35:10,909] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4222542e-27 1.0000000e+00 6.8709232e-32 0.0000000e+00 8.0767641e-26], sum to 1.0000
[2019-03-26 11:35:10,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8089
[2019-03-26 11:35:10,924] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.16666666666667, 66.33333333333334, 1.0, 2.0, 0.5918863171088204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 827119.1581125371, 827119.1581125365, 199243.5834757283], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3924600.0000, 
sim time next is 3925200.0000, 
raw observation next is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.5855827289608689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 818306.9473715558, 818306.9473715564, 198090.7564418991], 
processed observation next is [0.0, 0.43478260869565216, 0.7314375987361774, 0.6566666666666667, 1.0, 1.0, 0.5007020830853842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22730748538098774, 0.22730748538098788, 0.2956578454356703], 
reward next is 0.7043, 
noisyNet noise sample is [array([0.48069862], dtype=float32), -0.66500163]. 
=============================================
[2019-03-26 11:35:16,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3785567e-23 1.0000000e+00 9.5740578e-28 2.7773114e-32 4.9177144e-19], sum to 1.0000
[2019-03-26 11:35:16,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8343
[2019-03-26 11:35:16,731] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.6942198967818454, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970188.3956380525, 970188.3956380525, 219602.720940052], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4079400.0000, 
sim time next is 4080000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.6541168429467781, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 914119.3285823171, 914119.3285823165, 211253.337682386], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.5832733047551543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2539220357173103, 0.25392203571731015, 0.31530348907818806], 
reward next is 0.6847, 
noisyNet noise sample is [array([0.02201637], dtype=float32), 0.062728986]. 
=============================================
[2019-03-26 11:35:16,748] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[55.682266]
 [54.90601 ]
 [54.707897]
 [54.708874]
 [54.834206]], R is [[56.19932556]
 [56.3095665 ]
 [56.4004631 ]
 [56.48218155]
 [56.56022644]].
[2019-03-26 11:35:20,543] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0630405e-25 1.0000000e+00 1.6043791e-29 1.2840535e-32 2.7046320e-20], sum to 1.0000
[2019-03-26 11:35:20,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6427
[2019-03-26 11:35:20,561] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.5806682511980742, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 811436.7183846717, 811436.7183846717, 197199.6546098688], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4147800.0000, 
sim time next is 4148400.0000, 
raw observation next is [28.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5785132676295686, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 808424.1578612714, 808424.1578612714, 196811.2420558016], 
processed observation next is [1.0, 0.0, 0.5576619273301741, 0.8566666666666667, 1.0, 1.0, 0.4921846597946609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2245622660725754, 0.2245622660725754, 0.29374812247134563], 
reward next is 0.7063, 
noisyNet noise sample is [array([1.1271552], dtype=float32), -1.8712661]. 
=============================================
[2019-03-26 11:35:24,654] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.8155209e-22 1.0000000e+00 1.1661288e-24 6.2962092e-28 6.9612069e-16], sum to 1.0000
[2019-03-26 11:35:24,664] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8668
[2019-03-26 11:35:24,672] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.9794442522346938, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1369053.020016599, 1369053.020016599, 292728.666948068], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4158600.0000, 
sim time next is 4159200.0000, 
raw observation next is [28.66666666666667, 85.66666666666667, 1.0, 2.0, 0.9084117563382776, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1269705.450704207, 1269705.450704207, 272265.2237851036], 
processed observation next is [1.0, 0.13043478260869565, 0.5576619273301741, 0.8566666666666667, 1.0, 1.0, 0.8896527184798526, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35269595852894636, 0.35269595852894636, 0.40636600564940834], 
reward next is 0.5936, 
noisyNet noise sample is [array([-0.38296616], dtype=float32), -1.4363097]. 
=============================================
[2019-03-26 11:35:34,105] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2932802e-12 9.9996090e-01 1.2544240e-14 2.1708470e-14 3.9077437e-05], sum to 1.0000
[2019-03-26 11:35:34,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1221
[2019-03-26 11:35:34,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3325925.328090373 W.
[2019-03-26 11:35:34,129] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.0, 57.0, 1.0, 2.0, 0.9437834591019678, 1.0, 2.0, 0.7924817690652467, 1.0, 1.0, 1.03, 7.005116962133291, 6.9112, 170.5573041426782, 3325925.328090373, 3258648.787816532, 609396.1709147342], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4377600.0000, 
sim time next is 4378200.0000, 
raw observation next is [35.5, 58.0, 1.0, 2.0, 0.878954669321995, 1.0, 2.0, 0.7600673741752599, 1.0, 2.0, 1.03, 7.005111846809912, 6.9112, 170.5573041426782, 3189713.306064439, 3122440.430104813, 583813.1457308199], 
processed observation next is [1.0, 0.6956521739130435, 0.8815165876777251, 0.58, 1.0, 1.0, 0.8541622521951746, 1.0, 1.0, 0.7109245471991084, 1.0, 1.0, 1.0365853658536586, 0.009391184680991227, 0.0, 0.8375144448122397, 0.8860314739067886, 0.8673445639180036, 0.8713629040758506], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17722401], dtype=float32), 0.8197783]. 
=============================================
[2019-03-26 11:35:40,990] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1129441e-32 1.0000000e+00 1.1262794e-37 0.0000000e+00 2.2576034e-31], sum to 1.0000
[2019-03-26 11:35:40,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2577
[2019-03-26 11:35:41,005] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.00000000000001, 1.0, 2.0, 0.5152865481673516, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720040.1315345133, 720040.131534514, 186026.0277832874], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4741800.0000, 
sim time next is 4742400.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5164198616967963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721624.3149491311, 721624.3149491318, 186208.848346045], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.79, 1.0, 1.0, 0.4173733273455377, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20045119859698085, 0.20045119859698105, 0.2779236542478284], 
reward next is 0.7221, 
noisyNet noise sample is [array([-0.32849488], dtype=float32), -0.23149744]. 
=============================================
[2019-03-26 11:35:54,464] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.791786e-28 1.000000e+00 3.071156e-32 6.439620e-36 3.534610e-24], sum to 1.0000
[2019-03-26 11:35:54,472] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4273
[2019-03-26 11:35:54,476] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 87.33333333333333, 1.0, 2.0, 0.5210692160865329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728123.3621637849, 728123.3621637849, 186963.5268261094], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4671600.0000, 
sim time next is 4672200.0000, 
raw observation next is [27.0, 88.16666666666667, 1.0, 2.0, 0.5249932849139376, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733608.6081372208, 733608.6081372208, 187605.2002836865], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.8816666666666667, 1.0, 1.0, 0.4277027529083585, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2037801689270058, 0.2037801689270058, 0.28000776161744256], 
reward next is 0.7200, 
noisyNet noise sample is [array([1.0213135], dtype=float32), 0.70599616]. 
=============================================
[2019-03-26 11:35:54,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.1513494e-26 1.0000000e+00 3.7816849e-30 4.2842819e-36 8.0812760e-23], sum to 1.0000
[2019-03-26 11:35:54,695] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7038
[2019-03-26 11:35:54,702] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 89.83333333333333, 1.0, 2.0, 0.7809152526721664, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1091409.425548674, 1091409.425548674, 239280.5506307053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4679400.0000, 
sim time next is 4680000.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.7650871540744784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1069276.89129477, 1069276.89129477, 235521.5928027905], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.89, 1.0, 1.0, 0.7169724747885281, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2970213586929917, 0.2970213586929917, 0.3515247653772992], 
reward next is 0.6485, 
noisyNet noise sample is [array([0.5656986], dtype=float32), -0.6459469]. 
=============================================
[2019-03-26 11:35:54,719] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[59.974983]
 [59.70294 ]
 [59.573788]
 [59.59858 ]
 [59.406113]], R is [[60.1706543 ]
 [60.21181107]
 [60.24597931]
 [60.27452469]
 [60.30379868]].
[2019-03-26 11:35:56,207] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 11:35:56,208] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:35:56,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:35:56,210] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:35:56,211] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:35:56,212] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:35:56,214] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:35:56,214] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:35:56,216] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:35:56,213] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:35:56,219] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:35:56,240] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-26 11:35:56,240] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-26 11:35:56,283] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-26 11:35:56,284] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-26 11:35:56,321] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-26 11:35:57,301] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.27251294], dtype=float32), 0.08699032]
[2019-03-26 11:35:57,301] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.66666666666667, 85.00000000000001, 1.0, 2.0, 0.3754134674139015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 610838.981024439, 610838.9810244383, 175835.0636491581]
[2019-03-26 11:35:57,302] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:35:57,302] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.0075523e-20 1.0000000e+00 1.0921683e-23 2.3979341e-29 2.8490306e-21], sampled 0.24364121182434118
[2019-03-26 11:36:00,093] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.27251294], dtype=float32), 0.08699032]
[2019-03-26 11:36:00,095] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.06666666666667, 86.0, 1.0, 2.0, 0.3163282975316293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499282.2942377378, 499282.2942377378, 166952.4391187992]
[2019-03-26 11:36:00,097] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:36:00,101] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.6382480e-31 1.0000000e+00 6.4939398e-36 0.0000000e+00 2.5425087e-30], sampled 0.6585971880672007
[2019-03-26 11:37:00,115] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.27251294], dtype=float32), 0.08699032]
[2019-03-26 11:37:00,116] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.83333333333334, 61.0, 1.0, 2.0, 0.5820174898314836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 813322.8916605702, 813322.8916605702, 197442.7890554515]
[2019-03-26 11:37:00,117] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:37:00,119] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.9232024e-30 1.0000000e+00 1.3067475e-35 0.0000000e+00 9.2914269e-29], sampled 0.32748416750012355
[2019-03-26 11:37:51,526] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.4791 3007658023.9129 1766.0000
[2019-03-26 11:37:51,634] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7883.4188 3164131021.0653 1778.0000
[2019-03-26 11:37:51,637] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3799 2842570825.1253 1131.0000
[2019-03-26 11:37:51,646] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.7345 2927388635.0840 1339.0000
[2019-03-26 11:37:51,733] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.7475 2779285453.0567 935.0000
[2019-03-26 11:37:52,750] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 975000, evaluation results [975000.0, 7883.4188199173295, 3164131021.06526, 1778.0, 8254.734498592194, 2927388635.0840125, 1339.0, 8660.747503834677, 2779285453.0567074, 935.0, 7997.4790539186915, 3007658023.9129057, 1766.0, 8495.379861994354, 2842570825.125265, 1131.0]
[2019-03-26 11:37:54,338] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0396128e-11 9.9978763e-01 4.1911401e-12 5.8844574e-09 2.1244066e-04], sum to 1.0000
[2019-03-26 11:37:54,349] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8829
[2019-03-26 11:37:54,359] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2565789.35892922 W.
[2019-03-26 11:37:54,362] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 68.0, 1.0, 2.0, 0.6115469113820624, 1.0, 2.0, 0.6115469113820624, 1.0, 1.0, 1.03, 6.947235083573744, 6.9112, 170.5573041426782, 2565789.35892922, 2539975.962751865, 492203.3072536471], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4724400.0000, 
sim time next is 4725000.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.5814800302389969, 1.0, 2.0, 0.5814800302389969, 1.0, 2.0, 1.009838514140646, 6.911199999999999, 6.9112, 170.5573041426782, 2439518.437601128, 2439518.437601129, 476062.9155757562], 
processed observation next is [1.0, 0.6956521739130435, 0.6919431279620853, 0.685, 1.0, 1.0, 0.4957590725771046, 1.0, 1.0, 0.4957590725771046, 1.0, 1.0, 1.0119981879763977, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6776440104447579, 0.6776440104447581, 0.7105416650384422], 
reward next is 0.2895, 
noisyNet noise sample is [array([1.3648345], dtype=float32), -0.36515784]. 
=============================================
[2019-03-26 11:37:54,377] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[41.28285 ]
 [42.070824]
 [40.719124]
 [42.118164]
 [42.370663]], R is [[42.31299591]
 [41.88986588]
 [41.47096634]
 [41.05625534]
 [40.91555786]].
[2019-03-26 11:37:55,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1934889e-28 1.0000000e+00 1.7040731e-35 0.0000000e+00 1.1639672e-27], sum to 1.0000
[2019-03-26 11:37:55,045] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2978
[2019-03-26 11:37:55,051] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 0.5161334735872127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 721223.9918837352, 721223.9918837352, 186162.8632412496], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4735800.0000, 
sim time next is 4736400.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 1.0, 2.0, 0.5168451136438941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722218.7469001882, 722218.7469001882, 186277.7166453443], 
processed observation next is [1.0, 0.8260869565217391, 0.541864139020537, 0.7733333333333333, 1.0, 1.0, 0.41788567908902896, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2006163185833856, 0.2006163185833856, 0.2780264427542452], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.43821713], dtype=float32), 0.6421841]. 
=============================================
[2019-03-26 11:37:56,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.7038845e-24 1.0000000e+00 2.4779196e-26 1.9579133e-29 4.1074448e-20], sum to 1.0000
[2019-03-26 11:37:56,403] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0648
[2019-03-26 11:37:56,408] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7545645603778484, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1054563.334669906, 1054563.334669906, 233060.318162231], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4762200.0000, 
sim time next is 4762800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.7526746236852463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1051920.691221194, 1051920.691221194, 232622.368919132], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.702017618897887, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29220019200588726, 0.29220019200588726, 0.3471975655509433], 
reward next is 0.6528, 
noisyNet noise sample is [array([-1.7409745], dtype=float32), -0.7864252]. 
=============================================
[2019-03-26 11:38:01,530] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.4018068e-28 1.0000000e+00 6.5213811e-33 0.0000000e+00 6.4692656e-28], sum to 1.0000
[2019-03-26 11:38:01,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8427
[2019-03-26 11:38:01,548] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.83333333333334, 63.5, 1.0, 2.0, 0.5556764701865975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 776499.9687244205, 776499.9687244212, 192778.9960582308], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5155800.0000, 
sim time next is 5156400.0000, 
raw observation next is [31.66666666666667, 64.0, 1.0, 2.0, 0.5497218410204334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 768175.986051796, 768175.9860517967, 191753.2879752476], 
processed observation next is [0.0, 0.6956521739130435, 0.6998420221169038, 0.64, 1.0, 1.0, 0.45749619400052216, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21338221834772111, 0.2133822183477213, 0.28619893727648893], 
reward next is 0.7138, 
noisyNet noise sample is [array([0.32776463], dtype=float32), 0.7691158]. 
=============================================
[2019-03-26 11:38:06,376] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0277433e-13 1.0000000e+00 1.0852631e-13 1.7979793e-09 4.1295987e-08], sum to 1.0000
[2019-03-26 11:38:06,387] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1771
[2019-03-26 11:38:06,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1893028.223373447 W.
[2019-03-26 11:38:06,399] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 65.0, 1.0, 2.0, 0.7127911012471033, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.97517578689108, 6.9112, 168.9125241227506, 1893028.223373447, 1847641.714458099, 388512.0094726948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4969200.0000, 
sim time next is 4969800.0000, 
raw observation next is [30.3, 65.0, 1.0, 2.0, 0.615866919473526, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.925604798615884, 6.9112, 168.912790096432, 1721985.815746436, 1711766.565901494, 368597.0395449749], 
processed observation next is [1.0, 0.5217391304347826, 0.6350710900473934, 0.65, 1.0, 1.0, 0.5371890596066579, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0014404798615884396, 0.0, 0.8294391279833829, 0.47832939326289886, 0.475490712750415, 0.5501448351417536], 
reward next is 0.3778, 
noisyNet noise sample is [array([-0.1432212], dtype=float32), 1.59656]. 
=============================================
[2019-03-26 11:38:07,385] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.1162754e-28 1.0000000e+00 4.2050905e-35 0.0000000e+00 4.4895112e-29], sum to 1.0000
[2019-03-26 11:38:07,396] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7222
[2019-03-26 11:38:07,404] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 78.0, 1.0, 2.0, 0.545697812507305, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762550.829095166, 762550.8290951665, 191065.5801851521], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5252400.0000, 
sim time next is 5253000.0000, 
raw observation next is [28.88333333333333, 78.16666666666667, 1.0, 2.0, 0.5455422302992248, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 762333.342581263, 762333.3425812636, 191039.1378951606], 
processed observation next is [1.0, 0.8260869565217391, 0.5679304897314374, 0.7816666666666667, 1.0, 1.0, 0.4524605184328009, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21175926182812863, 0.2117592618281288, 0.28513304163456804], 
reward next is 0.7149, 
noisyNet noise sample is [array([-0.09059612], dtype=float32), 0.4163265]. 
=============================================
[2019-03-26 11:38:07,419] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[75.470024]
 [75.384636]
 [75.35624 ]
 [75.100296]
 [74.71346 ]], R is [[75.55673981]
 [75.51599884]
 [75.47561646]
 [75.4352417 ]
 [75.39398193]].
[2019-03-26 11:38:11,955] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.226530e-30 1.000000e+00 9.938448e-35 0.000000e+00 3.691124e-30], sum to 1.0000
[2019-03-26 11:38:11,966] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2169
[2019-03-26 11:38:11,971] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.00000000000001, 1.0, 2.0, 0.517809345509258, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723566.5849451869, 723566.5849451869, 186433.9142561213], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5052000.0000, 
sim time next is 5052600.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5180843330622806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723950.9727686801, 723950.9727686801, 186478.4444092323], 
processed observation next is [0.0, 0.4782608695652174, 0.6682464454976303, 0.63, 1.0, 1.0, 0.4193787145328682, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20109749243574446, 0.20109749243574446, 0.27832603643169], 
reward next is 0.7217, 
noisyNet noise sample is [array([-1.7100104], dtype=float32), -0.76819056]. 
=============================================
[2019-03-26 11:38:15,308] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.4832175e-27 1.0000000e+00 5.4364315e-30 2.2646126e-34 5.5770956e-26], sum to 1.0000
[2019-03-26 11:38:15,318] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1283
[2019-03-26 11:38:15,327] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5162498980852747, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721386.7339989959, 721386.7339989964, 186180.6622535018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5098800.0000, 
sim time next is 5099400.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.5146236257301708, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719113.4775577422, 719113.4775577415, 185918.4154986019], 
processed observation next is [0.0, 0.0, 0.4549763033175356, 0.865, 1.0, 1.0, 0.41520918762671183, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1997537437660395, 0.1997537437660393, 0.277490172385973], 
reward next is 0.7225, 
noisyNet noise sample is [array([-1.6050594], dtype=float32), -0.07523297]. 
=============================================
[2019-03-26 11:38:18,980] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.5265418e-30 1.0000000e+00 1.2969358e-33 0.0000000e+00 8.9696979e-29], sum to 1.0000
[2019-03-26 11:38:18,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7868
[2019-03-26 11:38:18,992] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 63.00000000000001, 1.0, 2.0, 0.5531671280705132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772992.1486628582, 772992.1486628582, 192345.7008323532], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5145600.0000, 
sim time next is 5146200.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.5524797156795057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 772031.213966883, 772031.213966883, 192227.284804925], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.46081893455362133, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21445311499080083, 0.21445311499080083, 0.28690639523123135], 
reward next is 0.7131, 
noisyNet noise sample is [array([-1.2631515], dtype=float32), 1.103645]. 
=============================================
[2019-03-26 11:38:20,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.6722152e-29 1.0000000e+00 2.1466055e-33 1.4916794e-37 5.1421497e-28], sum to 1.0000
[2019-03-26 11:38:20,300] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1765
[2019-03-26 11:38:20,308] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 79.0, 1.0, 2.0, 0.5212672859450231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728400.2327483637, 728400.232748363, 186995.1039861079], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169600.0000, 
sim time next is 5170200.0000, 
raw observation next is [28.0, 79.00000000000001, 1.0, 2.0, 0.5226573742461251, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 730343.3601159235, 730343.3601159242, 187221.8609097044], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.7900000000000001, 1.0, 1.0, 0.42488840270617484, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2028731555877565, 0.2028731555877567, 0.27943561329806627], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.02956727], dtype=float32), -1.4324756]. 
=============================================
[2019-03-26 11:38:21,037] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.9909863e-28 1.0000000e+00 8.9795097e-32 8.5193655e-37 3.2768388e-28], sum to 1.0000
[2019-03-26 11:38:21,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6650
[2019-03-26 11:38:21,051] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 82.33333333333334, 1.0, 2.0, 0.5056631574720717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706588.3305639104, 706588.3305639104, 184487.849993399], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5182800.0000, 
sim time next is 5183400.0000, 
raw observation next is [27.0, 83.16666666666666, 1.0, 2.0, 0.5090934949786691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 711383.3171582368, 711383.3171582373, 185032.8877888426], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.8316666666666666, 1.0, 1.0, 0.4085463794923723, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1976064769883991, 0.19760647698839925, 0.27616848923707854], 
reward next is 0.7238, 
noisyNet noise sample is [array([-1.5448669], dtype=float32), 0.8187033]. 
=============================================
[2019-03-26 11:38:26,152] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.2130771e-27 1.0000000e+00 5.3389336e-30 2.1234337e-34 1.7490906e-25], sum to 1.0000
[2019-03-26 11:38:26,160] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3057
[2019-03-26 11:38:26,167] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.53333333333334, 84.66666666666667, 1.0, 2.0, 0.5661469796991381, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 791136.8637080308, 791136.8637080308, 194608.7906780089], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5271600.0000, 
sim time next is 5272200.0000, 
raw observation next is [28.55, 85.0, 1.0, 2.0, 0.5678159465288047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 793469.958131984, 793469.958131984, 194903.4707997384], 
processed observation next is [1.0, 0.0, 0.552132701421801, 0.85, 1.0, 1.0, 0.4792963211190418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22040832170332889, 0.22040832170332889, 0.29090070268617674], 
reward next is 0.7091, 
noisyNet noise sample is [array([1.1567948], dtype=float32), 0.6749302]. 
=============================================
[2019-03-26 11:38:26,962] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.5264899e-31 1.0000000e+00 7.4854934e-36 0.0000000e+00 6.3101248e-30], sum to 1.0000
[2019-03-26 11:38:26,969] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1052
[2019-03-26 11:38:26,977] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.9, 79.33333333333334, 1.0, 2.0, 0.6252346842520463, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873740.3048395718, 873740.3048395718, 205541.5433098654], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5346600.0000, 
sim time next is 5347200.0000, 
raw observation next is [30.8, 79.66666666666667, 1.0, 2.0, 0.6217062605328083, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 868807.4579748324, 868807.457974833, 204859.7899359629], 
processed observation next is [1.0, 0.9130434782608695, 0.6587677725118484, 0.7966666666666667, 1.0, 1.0, 0.544224410280492, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24133540499300898, 0.24133540499300915, 0.3057608805014372], 
reward next is 0.6942, 
noisyNet noise sample is [array([-0.3866074], dtype=float32), -0.44126984]. 
=============================================
[2019-03-26 11:38:38,685] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8195689e-13 1.0000000e+00 1.9701379e-13 4.6691082e-11 2.4993117e-08], sum to 1.0000
[2019-03-26 11:38:38,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7951
[2019-03-26 11:38:38,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2685996.206793279 W.
[2019-03-26 11:38:38,703] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.09999999999999, 54.0, 1.0, 2.0, 0.9602505425026062, 1.0, 2.0, 0.9602505425026062, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2685996.206793279, 2685996.206793279, 505437.6903092251], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5488800.0000, 
sim time next is 5489400.0000, 
raw observation next is [36.2, 53.0, 1.0, 2.0, 0.6514507253267945, 1.0, 2.0, 0.6463154021776599, 1.0, 1.0, 1.03, 7.005093904403134, 6.9112, 170.5573041426782, 2711821.392464525, 2644561.369380724, 506433.0220854506], 
processed observation next is [1.0, 0.5217391304347826, 0.9146919431279622, 0.53, 1.0, 1.0, 0.5800611148515596, 1.0, 1.0, 0.573873978527301, 1.0, 0.5, 1.0365853658536586, 0.009389390440313417, 0.0, 0.8375144448122397, 0.7532837201290348, 0.7346003803835345, 0.7558701822170905], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.11398175], dtype=float32), 0.5723559]. 
=============================================
[2019-03-26 11:38:44,397] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.0057366e-27 1.0000000e+00 1.7011425e-29 7.5615804e-35 8.3854849e-24], sum to 1.0000
[2019-03-26 11:38:44,404] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-26 11:38:44,410] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.46666666666667, 88.0, 1.0, 2.0, 0.7525521493816683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1051749.439195432, 1051749.439195433, 232598.4663221888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5985600.0000, 
sim time next is 5986200.0000, 
raw observation next is [27.63333333333333, 87.5, 1.0, 2.0, 0.7724593662494886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1079585.446619537, 1079585.446619537, 237264.1381100006], 
processed observation next is [1.0, 0.2608695652173913, 0.5086887835703, 0.875, 1.0, 1.0, 0.725854658131914, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2998848462832047, 0.2998848462832047, 0.3541255792686576], 
reward next is 0.6459, 
noisyNet noise sample is [array([-1.2262356], dtype=float32), -1.0179479]. 
=============================================
[2019-03-26 11:38:47,413] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 11:38:47,417] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:38:47,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:38:47,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:38:47,423] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:38:47,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:38:47,425] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:38:47,425] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:38:47,420] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:38:47,425] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:38:47,459] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:38:47,812] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-26 11:38:47,833] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-26 11:38:48,017] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-26 11:38:48,028] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-26 11:38:48,110] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-26 11:39:28,628] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:28,629] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.3476887940397863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 535605.8759647226, 535605.8759647219, 169456.450300268]
[2019-03-26 11:39:28,630] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:39:28,634] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2840664e-30 1.0000000e+00 2.0045999e-33 2.7127185e-38 2.7684079e-30], sampled 0.4881168286736296
[2019-03-26 11:39:32,245] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:32,246] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.1, 90.0, 1.0, 2.0, 0.5183757408309665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 724358.3135318041, 724358.3135318048, 186524.6274331459]
[2019-03-26 11:39:32,247] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:39:32,248] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0164437e-31 1.0000000e+00 1.9257596e-35 0.0000000e+00 8.8516335e-32], sampled 0.7170384278033758
[2019-03-26 11:39:32,690] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:32,691] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 86.66666666666667, 1.0, 2.0, 0.5419482250164467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 757309.3378379536, 757309.3378379529, 190427.4065848169]
[2019-03-26 11:39:32,692] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:39:32,694] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2138928e-30 1.0000000e+00 9.7817546e-35 0.0000000e+00 1.6973164e-31], sampled 0.8752806388281936
[2019-03-26 11:39:42,634] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:42,635] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.3, 64.5, 1.0, 2.0, 0.8733184751478068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1220626.667201983, 1220626.667201984, 262704.2639433469]
[2019-03-26 11:39:42,636] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:39:42,639] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9550703e-27 1.0000000e+00 7.2763868e-30 9.5011489e-35 3.4718918e-26], sampled 0.6247917122199134
[2019-03-26 11:39:50,316] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:50,317] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [38.2228978, 49.99141409, 1.0, 2.0, 0.789371969052178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1103234.696699035, 1103234.696699034, 241327.8922103018]
[2019-03-26 11:39:50,320] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:39:50,322] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6079335e-28 1.0000000e+00 7.3870193e-32 2.1574397e-35 3.6194175e-28], sampled 0.017548765739782035
[2019-03-26 11:39:59,104] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:39:59,105] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.1, 80.33333333333333, 1.0, 2.0, 0.9238904296659721, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001330600452786, 6.9112, 168.9123458283955, 2188477.019782112, 2124535.500937823, 440940.2621895008]
[2019-03-26 11:39:59,106] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:39:59,109] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3478059e-15 1.0000000e+00 7.8211185e-15 1.7662055e-13 1.7319739e-10], sampled 0.7513107896303448
[2019-03-26 11:39:59,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2188477.019782112 W.
[2019-03-26 11:40:03,519] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:40:03,520] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.4, 68.0, 1.0, 2.0, 0.6144903713833411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 858719.4902875677, 858719.4902875684, 203475.9695027515]
[2019-03-26 11:40:03,521] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:40:03,525] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.8477788e-30 1.0000000e+00 4.8338509e-34 0.0000000e+00 1.1229329e-30], sampled 0.6897605255994955
[2019-03-26 11:40:10,949] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:40:10,951] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.46666666666667, 93.33333333333334, 1.0, 2.0, 0.6235810764292079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 871428.506462046, 871428.506462046, 205220.872884154]
[2019-03-26 11:40:10,952] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:40:10,954] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.2594939e-30 1.0000000e+00 8.3641970e-34 1.3069101e-38 3.5369865e-30], sampled 0.8909607306026697
[2019-03-26 11:40:13,974] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:40:13,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.5, 95.5, 1.0, 2.0, 0.6966061196248113, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 973524.7258630883, 973524.7258630883, 220115.6130667465]
[2019-03-26 11:40:13,979] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:40:13,982] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.4205509e-29 1.0000000e+00 9.4266441e-33 0.0000000e+00 3.5180285e-29], sampled 0.42873273078636576
[2019-03-26 11:40:16,471] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:40:16,473] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.22466548333333, 85.47975693333333, 1.0, 2.0, 0.5757431965889047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 804551.7480017577, 804551.7480017577, 196312.877922445]
[2019-03-26 11:40:16,473] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:40:16,476] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.4432846e-28 1.0000000e+00 1.1708629e-31 5.7583181e-36 4.1361228e-28], sampled 0.1343910508712185
[2019-03-26 11:40:37,576] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.31712753], dtype=float32), 0.088159174]
[2019-03-26 11:40:37,577] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.81407223666667, 89.00637177666667, 1.0, 2.0, 0.3573461927907114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549016.3366287426, 549016.3366287426, 170522.7235448683]
[2019-03-26 11:40:37,579] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:40:37,581] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5698406e-32 1.0000000e+00 1.4628229e-36 0.0000000e+00 8.3826596e-34], sampled 0.30818536858004275
[2019-03-26 11:40:43,485] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.2711 2779256177.9474 933.0000
[2019-03-26 11:40:43,782] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.8607 3007711637.9330 1766.0000
[2019-03-26 11:40:43,863] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 11:40:43,915] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.8302 3164026345.7598 1777.0000
[2019-03-26 11:40:43,943] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5886 2927456187.7328 1338.0000
[2019-03-26 11:40:44,959] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1000000, evaluation results [1000000.0, 7882.830207570134, 3164026345.759798, 1777.0, 8253.588552262909, 2927456187.7328076, 1338.0, 8661.271088261434, 2779256177.947352, 933.0, 7998.86073322157, 3007711637.9330444, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 11:40:47,090] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1404863e-32 1.0000000e+00 1.6090745e-36 0.0000000e+00 4.2905525e-33], sum to 1.0000
[2019-03-26 11:40:47,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6387
[2019-03-26 11:40:47,110] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.06666666666667, 59.83333333333333, 1.0, 2.0, 0.5413215084498287, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756433.2628154951, 756433.2628154951, 190323.2964620353], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5674200.0000, 
sim time next is 5674800.0000, 
raw observation next is [32.03333333333333, 59.66666666666667, 1.0, 2.0, 0.5327549306845658, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 744458.2811267487, 744458.2811267494, 188887.4690280051], 
processed observation next is [0.0, 0.6956521739130435, 0.7172195892575038, 0.5966666666666667, 1.0, 1.0, 0.4370541333548985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2067939669796524, 0.2067939669796526, 0.2819215955641867], 
reward next is 0.7181, 
noisyNet noise sample is [array([-0.61591786], dtype=float32), 1.1752596]. 
=============================================
[2019-03-26 11:40:49,103] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9284038e-28 1.0000000e+00 2.0446784e-30 9.9362821e-36 2.5176505e-27], sum to 1.0000
[2019-03-26 11:40:49,109] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2847
[2019-03-26 11:40:49,116] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.5, 87.0, 1.0, 2.0, 0.5168852551501861, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 722274.8581099614, 722274.8581099614, 186283.3548427695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5706000.0000, 
sim time next is 5706600.0000, 
raw observation next is [26.48333333333333, 87.0, 1.0, 2.0, 0.5148031346994155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719364.4008000082, 719364.4008000082, 185947.4449789666], 
processed observation next is [0.0, 0.043478260869565216, 0.4541864139020536, 0.87, 1.0, 1.0, 0.4154254634932717, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19982344466666896, 0.19982344466666896, 0.2775334999686069], 
reward next is 0.7225, 
noisyNet noise sample is [array([0.6970196], dtype=float32), 0.8047209]. 
=============================================
[2019-03-26 11:40:53,108] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.7235544e-29 1.0000000e+00 3.2261297e-31 1.3221958e-36 4.9201339e-27], sum to 1.0000
[2019-03-26 11:40:53,115] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7868
[2019-03-26 11:40:53,124] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 79.0, 1.0, 2.0, 0.5495153097932858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767887.2769922784, 767887.276992279, 191717.473560603], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5772600.0000, 
sim time next is 5773200.0000, 
raw observation next is [28.6, 80.0, 1.0, 2.0, 0.5487683742202893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 766843.1398199901, 766843.1398199908, 191589.5144488959], 
processed observation next is [0.0, 0.8260869565217391, 0.5545023696682465, 0.8, 1.0, 1.0, 0.4563474388196257, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2130119832833306, 0.2130119832833308, 0.2859544991774566], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.62894464], dtype=float32), -2.436086]. 
=============================================
[2019-03-26 11:40:59,543] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.9741894e-12 9.9999988e-01 2.5031623e-11 5.9647057e-08 5.4126943e-08], sum to 1.0000
[2019-03-26 11:40:59,552] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6110
[2019-03-26 11:40:59,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1967065.950963202 W.
[2019-03-26 11:40:59,564] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.46666666666667, 70.0, 1.0, 2.0, 0.468963171250383, 1.0, 2.0, 0.468963171250383, 1.0, 2.0, 0.8138375324086893, 6.911199999999999, 6.9112, 170.5573041426782, 1967065.950963202, 1967065.950963202, 394246.7892507803], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6182400.0000, 
sim time next is 6183000.0000, 
raw observation next is [30.55, 69.5, 1.0, 2.0, 0.7292272977127737, 1.0, 2.0, 0.7292272977127737, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2039231.144286893, 2039231.144286893, 386888.1920038747], 
processed observation next is [1.0, 0.5652173913043478, 0.6469194312796209, 0.695, 1.0, 1.0, 0.6737678285696069, 1.0, 1.0, 0.6737678285696069, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.566453095635248, 0.566453095635248, 0.5774450626923503], 
reward next is 0.4226, 
noisyNet noise sample is [array([1.5512447], dtype=float32), -0.9459316]. 
=============================================
[2019-03-26 11:40:59,575] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[42.61579 ]
 [44.09352 ]
 [43.93677 ]
 [46.2389  ]
 [45.995823]], R is [[41.87730026]
 [41.87009811]
 [41.90444565]
 [41.93328094]
 [42.01205826]].
[2019-03-26 11:41:01,045] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4607807e-10 9.9918896e-01 1.4366974e-09 3.2655254e-05 7.7843294e-04], sum to 1.0000
[2019-03-26 11:41:01,054] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4861
[2019-03-26 11:41:01,061] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2287070.598705158 W.
[2019-03-26 11:41:01,064] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.35, 77.33333333333333, 1.0, 2.0, 0.5451760085298845, 1.0, 2.0, 0.5451760085298845, 1.0, 2.0, 0.946790434355358, 6.911199999999999, 6.9112, 170.5573041426782, 2287070.598705158, 2287070.598705159, 447792.6830187229], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5908200.0000, 
sim time next is 5908800.0000, 
raw observation next is [30.5, 76.66666666666667, 1.0, 2.0, 0.582547281758068, 1.0, 2.0, 0.582547281758068, 1.0, 2.0, 1.011691977083802, 6.9112, 6.9112, 170.5573041426782, 2444000.321327969, 2444000.321327969, 476921.9078204815], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.7666666666666667, 1.0, 1.0, 0.49704491778080484, 1.0, 1.0, 0.49704491778080484, 1.0, 1.0, 1.014258508638783, 0.0, 0.0, 0.8375144448122397, 0.678888978146658, 0.678888978146658, 0.7118237430156441], 
reward next is 0.2882, 
noisyNet noise sample is [array([-0.99451965], dtype=float32), 1.2899506]. 
=============================================
[2019-03-26 11:41:01,700] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.4272285e-26 1.0000000e+00 2.3533510e-27 3.7725499e-30 1.3479645e-22], sum to 1.0000
[2019-03-26 11:41:01,710] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6229
[2019-03-26 11:41:01,713] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.18333333333333, 92.16666666666667, 1.0, 2.0, 0.7914261599237846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1106107.151097853, 1106107.151097853, 241816.2047291317], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5973000.0000, 
sim time next is 5973600.0000, 
raw observation next is [26.16666666666667, 92.33333333333334, 1.0, 2.0, 0.7584175582281312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1059950.889748078, 1059950.889748078, 233959.0162763501], 
processed observation next is [1.0, 0.13043478260869565, 0.4391785150078992, 0.9233333333333335, 1.0, 1.0, 0.7089368171423267, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2944308027077995, 0.2944308027077995, 0.3491925616064927], 
reward next is 0.6508, 
noisyNet noise sample is [array([-0.6761057], dtype=float32), 1.4831104]. 
=============================================
[2019-03-26 11:41:01,843] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.63711924e-13 9.99999642e-01 4.79408776e-13 1.96329339e-07
 1.03659964e-07], sum to 1.0000
[2019-03-26 11:41:01,852] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6269
[2019-03-26 11:41:01,860] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2273842.530342248 W.
[2019-03-26 11:41:01,868] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.1, 77.33333333333334, 1.0, 2.0, 0.8130384891158295, 1.0, 2.0, 0.8130384891158295, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2273842.530342248, 2273842.530342248, 426273.7671064062], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5931600.0000, 
sim time next is 5932200.0000, 
raw observation next is [30.15, 77.66666666666666, 1.0, 2.0, 1.002238294088772, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005993437176125, 6.9112, 168.912393128131, 2298134.933039006, 2230885.430468712, 463985.8828065758], 
processed observation next is [1.0, 0.6521739130434783, 0.6279620853080569, 0.7766666666666666, 1.0, 1.0, 1.0026967398659903, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009479343717612476, 0.0, 0.829437178687292, 0.6383708147330572, 0.61969039735242, 0.6925162429948892], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.81037885], dtype=float32), 0.6215504]. 
=============================================
[2019-03-26 11:41:09,979] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.3452127e-29 1.0000000e+00 1.2862737e-33 1.7268175e-37 2.7725218e-28], sum to 1.0000
[2019-03-26 11:41:09,990] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9640
[2019-03-26 11:41:09,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 85.33333333333333, 1.0, 2.0, 0.5379872024702902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 751772.3128294167, 751772.3128294161, 189762.2583688775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6036000.0000, 
sim time next is 6036600.0000, 
raw observation next is [27.65, 85.66666666666667, 1.0, 2.0, 0.5382854674684588, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 752189.2498083162, 752189.2498083162, 189812.3401488796], 
processed observation next is [1.0, 0.8695652173913043, 0.509478672985782, 0.8566666666666667, 1.0, 1.0, 0.44371743068489017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20894145828008784, 0.20894145828008784, 0.28330200022220836], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.66338587], dtype=float32), 0.5209309]. 
=============================================
[2019-03-26 11:41:10,078] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8390759e-25 1.0000000e+00 4.9451170e-29 5.3280633e-32 1.2226148e-24], sum to 1.0000
[2019-03-26 11:41:10,084] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9025
[2019-03-26 11:41:10,088] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.1, 93.0, 1.0, 2.0, 0.7299022786947874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1020079.30127493, 1020079.30127493, 227431.2087076436], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6064200.0000, 
sim time next is 6064800.0000, 
raw observation next is [26.1, 93.0, 1.0, 2.0, 0.7133067839727418, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 996875.2823695963, 996875.2823695963, 223742.9300283698], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.93, 1.0, 1.0, 0.6545864867141468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2769098006582212, 0.2769098006582212, 0.333944671684134], 
reward next is 0.6661, 
noisyNet noise sample is [array([-0.74639565], dtype=float32), -1.3094975]. 
=============================================
[2019-03-26 11:41:15,071] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9684929e-11 9.9998963e-01 4.5089342e-11 7.1647996e-06 3.1996944e-06], sum to 1.0000
[2019-03-26 11:41:15,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1480
[2019-03-26 11:41:15,091] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2013660.016551277 W.
[2019-03-26 11:41:15,097] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.46666666666667, 76.0, 1.0, 2.0, 0.798990093376964, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994772649148414, 6.9112, 168.9123916228299, 2013660.016551277, 1954370.901175237, 408015.1373165401], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6175200.0000, 
sim time next is 6175800.0000, 
raw observation next is [29.55, 75.5, 1.0, 2.0, 0.7221486035216926, 1.0, 1.0, 0.7221486035216926, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2019417.43315067, 2019417.43315067, 383751.6759152268], 
processed observation next is [1.0, 0.4782608695652174, 0.5995260663507109, 0.755, 1.0, 1.0, 0.6652392813514368, 1.0, 0.5, 0.6652392813514368, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5609492869862972, 0.5609492869862972, 0.5727636953958609], 
reward next is 0.4272, 
noisyNet noise sample is [array([1.1185501], dtype=float32), 0.59399116]. 
=============================================
[2019-03-26 11:41:29,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.5062269e-10 9.9981397e-01 2.1808999e-09 1.6264526e-04 2.3315049e-05], sum to 1.0000
[2019-03-26 11:41:29,957] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2248
[2019-03-26 11:41:29,969] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2280415.937258442 W.
[2019-03-26 11:41:29,975] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666666, 62.0, 1.0, 2.0, 0.5435911624950739, 1.0, 2.0, 0.5435911624950739, 1.0, 1.0, 0.9338135591284656, 6.911199999999999, 6.9112, 170.5573041426782, 2280415.937258442, 2280415.937258443, 444563.7296943563], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6619200.0000, 
sim time next is 6619800.0000, 
raw observation next is [31.08333333333334, 62.5, 1.0, 2.0, 0.5388421661107765, 1.0, 2.0, 0.5388421661107765, 1.0, 2.0, 0.9262567305777035, 6.9112, 6.9112, 170.5573041426782, 2260475.434400595, 2260475.434400595, 441166.8414765453], 
processed observation next is [1.0, 0.6086956521739131, 0.6721958925750398, 0.625, 1.0, 1.0, 0.4443881519406946, 1.0, 1.0, 0.4443881519406946, 1.0, 1.0, 0.9100691836313456, 0.0, 0.0, 0.8375144448122397, 0.6279098428890542, 0.6279098428890542, 0.6584579723530527], 
reward next is 0.3415, 
noisyNet noise sample is [array([-0.53686225], dtype=float32), 1.0546434]. 
=============================================
[2019-03-26 11:41:35,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.4876857e-25 1.0000000e+00 3.9576936e-27 4.1396429e-28 5.4940903e-25], sum to 1.0000
[2019-03-26 11:41:35,395] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1084
[2019-03-26 11:41:35,401] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 53.33333333333334, 1.0, 2.0, 0.3273122151796651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 513037.9967472595, 513037.9967472589, 167917.2721204622], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6806400.0000, 
sim time next is 6807000.0000, 
raw observation next is [27.53333333333333, 53.66666666666666, 1.0, 2.0, 0.3255585290151589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 511002.1262415127, 511002.1262415127, 167777.710908791], 
processed observation next is [1.0, 0.782608695652174, 0.5039494470774091, 0.5366666666666666, 1.0, 1.0, 0.18741991447609507, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14194503506708686, 0.14194503506708686, 0.2504144938937179], 
reward next is 0.7496, 
noisyNet noise sample is [array([-0.48052487], dtype=float32), -0.5548701]. 
=============================================
[2019-03-26 11:41:35,422] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.88755 ]
 [65.40071 ]
 [64.89905 ]
 [64.351685]
 [63.985764]], R is [[66.42575073]
 [66.51087189]
 [66.59503174]
 [66.67835236]
 [66.76130676]].
[2019-03-26 11:41:39,884] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 11:41:39,886] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:41:39,888] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:41:39,888] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:41:39,890] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:41:39,894] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:41:39,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:41:39,895] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:41:39,894] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:41:39,896] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:41:39,898] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:41:39,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-26 11:41:39,941] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-26 11:41:39,942] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-26 11:41:39,983] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-26 11:41:40,000] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-26 11:41:52,683] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34279305], dtype=float32), 0.09070682]
[2019-03-26 11:41:52,685] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.91977433, 76.666867595, 1.0, 2.0, 0.4120290737605611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 603336.7920764349, 603336.7920764344, 174511.4583700796]
[2019-03-26 11:41:52,686] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:41:52,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.2420154e-29 1.0000000e+00 7.0087158e-31 1.8977124e-35 6.6183261e-31], sampled 0.9275370734477983
[2019-03-26 11:42:30,183] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34279305], dtype=float32), 0.09070682]
[2019-03-26 11:42:30,184] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.06079249, 65.27602099, 1.0, 2.0, 0.9417977133996689, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1316398.607006631, 1316398.607006631, 281689.7951104146]
[2019-03-26 11:42:30,185] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:42:30,188] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6185868e-20 1.0000000e+00 2.6409917e-20 1.1505226e-16 2.7168030e-20], sampled 0.9606896224514252
[2019-03-26 11:42:42,793] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.34279305], dtype=float32), 0.09070682]
[2019-03-26 11:42:42,795] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.65, 63.16666666666666, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 13.49649331254892, 6.9112, 172.6738921899021, 6232339.858280148, 1456485.302822334, 290780.3521273056]
[2019-03-26 11:42:42,796] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:42:42,800] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.0404122e-20 1.0000000e+00 8.4557853e-20 1.5168594e-21 2.4385824e-18], sampled 0.5466840628630099
[2019-03-26 11:42:42,803] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 6232339.858280148 W.
[2019-03-26 11:43:03,325] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34279305], dtype=float32), 0.09070682]
[2019-03-26 11:43:03,326] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.24462369333334, 53.03650284000001, 1.0, 2.0, 0.588880555936705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822917.1928590076, 822917.1928590076, 198692.7768982243]
[2019-03-26 11:43:03,327] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:43:03,330] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4088816e-28 1.0000000e+00 3.4297348e-30 1.0361351e-34 6.1831206e-30], sampled 0.08022560360219555
[2019-03-26 11:43:29,912] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34279305], dtype=float32), 0.09070682]
[2019-03-26 11:43:29,913] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.16666666666667, 80.83333333333334, 1.0, 2.0, 0.7651102237382023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1069309.149421432, 1069309.149421432, 235526.8941728419]
[2019-03-26 11:43:29,914] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:43:29,917] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5879855e-24 1.0000000e+00 9.0657202e-26 9.8008330e-29 1.3972662e-24], sampled 0.8585847973637614
[2019-03-26 11:43:34,347] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.9275 2927313089.3005 1338.0000
[2019-03-26 11:43:34,555] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7905.9561 3161995194.8914 1729.0000
[2019-03-26 11:43:34,592] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8006.5841 3006951724.0713 1749.0000
[2019-03-26 11:43:34,702] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.7270 2779210869.9453 931.0000
[2019-03-26 11:43:34,818] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8499.9697 2842285187.7617 1129.0000
[2019-03-26 11:43:35,840] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1025000, evaluation results [1025000.0, 7905.9561368109935, 3161995194.891438, 1729.0, 8253.927451207956, 2927313089.3004775, 1338.0, 8661.72697761145, 2779210869.9453197, 931.0, 8006.584065690328, 3006951724.071316, 1749.0, 8499.96972153282, 2842285187.761715, 1129.0]
[2019-03-26 11:43:47,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.1491568e-19 1.0000000e+00 3.6025463e-19 3.4945057e-19 1.5528938e-16], sum to 1.0000
[2019-03-26 11:43:47,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8229
[2019-03-26 11:43:47,358] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 48.33333333333333, 1.0, 2.0, 0.9685269977396771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1502575.608151765, 1502575.608151765, 310683.3331273543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6795600.0000, 
sim time next is 6796200.0000, 
raw observation next is [29.21666666666667, 48.66666666666666, 1.0, 2.0, 0.9774103882051074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1514285.958566208, 1514285.958566209, 313365.614815757], 
processed observation next is [1.0, 0.6521739130434783, 0.5837282780410744, 0.4866666666666666, 1.0, 1.0, 0.9727836002471173, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4206349884906133, 0.42063498849061365, 0.46770987285933885], 
reward next is 0.5323, 
noisyNet noise sample is [array([-1.6645756], dtype=float32), 0.22441205]. 
=============================================
[2019-03-26 11:43:55,038] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.4344007e-27 1.0000000e+00 1.5104570e-27 2.0970095e-31 3.0882441e-28], sum to 1.0000
[2019-03-26 11:43:55,047] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1025
[2019-03-26 11:43:55,052] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 65.66666666666667, 1.0, 2.0, 0.3727971163437828, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 565719.840333914, 565719.840333914, 171743.2627513431], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6898800.0000, 
sim time next is 6899400.0000, 
raw observation next is [26.6, 66.5, 1.0, 2.0, 0.3763526246168568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 569809.6062249024, 569809.606224903, 172061.2672329463], 
processed observation next is [0.0, 0.8695652173913043, 0.4597156398104266, 0.665, 1.0, 1.0, 0.2486176200203094, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.158280446173584, 0.15828044617358417, 0.25680786154171087], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.80584985], dtype=float32), 0.38940564]. 
=============================================
[2019-03-26 11:44:08,573] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.6199691e-13 1.0000000e+00 1.5858791e-09 3.1756522e-09 9.9364468e-11], sum to 1.0000
[2019-03-26 11:44:08,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9791
[2019-03-26 11:44:08,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1909356.565295047 W.
[2019-03-26 11:44:08,600] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.48333333333333, 81.33333333333333, 1.0, 2.0, 0.7244592990361394, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.958894876374721, 6.9112, 168.9123030293628, 1909356.565295047, 1875520.309368196, 391493.6504767076], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7135800.0000, 
sim time next is 7136400.0000, 
raw observation next is [26.46666666666667, 81.66666666666667, 1.0, 2.0, 0.6674237493620767, 1.0, 1.0, 0.6674237493620767, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1866251.483423219, 1866251.483423218, 360478.7630265908], 
processed observation next is [1.0, 0.6086956521739131, 0.45339652448657203, 0.8166666666666668, 1.0, 1.0, 0.5993057221229839, 1.0, 0.5, 0.5993057221229839, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5184031898397831, 0.5184031898397827, 0.5380280045172997], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5600499], dtype=float32), -0.2104376]. 
=============================================
[2019-03-26 11:44:15,079] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.0370510e-17 1.0000000e+00 3.9813856e-15 6.6668507e-16 1.6162256e-14], sum to 1.0000
[2019-03-26 11:44:15,090] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3246
[2019-03-26 11:44:15,096] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.23333333333333, 85.16666666666667, 1.0, 2.0, 0.8516326166423127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1266186.331566902, 1266186.331566902, 267617.8927819007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7229400.0000, 
sim time next is 7230000.0000, 
raw observation next is [24.26666666666667, 84.33333333333334, 1.0, 2.0, 0.8717743004496021, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1299764.766944017, 1299764.766944018, 273784.398038345], 
processed observation next is [1.0, 0.6956521739130435, 0.34913112164297017, 0.8433333333333334, 1.0, 1.0, 0.8455112053609665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3610457685955603, 0.36104576859556053, 0.4086334299079776], 
reward next is 0.5914, 
noisyNet noise sample is [array([0.9002762], dtype=float32), 0.10051392]. 
=============================================
[2019-03-26 11:44:15,105] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.796307]
 [60.840202]
 [61.0155  ]
 [61.37628 ]
 [61.717453]], R is [[60.35330963]
 [60.35034943]
 [60.33691406]
 [60.31372452]
 [60.29944229]].
[2019-03-26 11:44:15,659] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.0324119e-18 1.0000000e+00 4.1505965e-15 1.1572391e-17 5.9259791e-16], sum to 1.0000
[2019-03-26 11:44:15,666] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5596
[2019-03-26 11:44:15,674] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333333, 58.0, 1.0, 2.0, 0.8507066443807985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1298762.07436315, 1298762.07436315, 271718.1958380652], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7306800.0000, 
sim time next is 7307400.0000, 
raw observation next is [27.91666666666667, 57.5, 1.0, 2.0, 0.8455115838807973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1291356.832935789, 1291356.83293579, 270301.6421230914], 
processed observation next is [1.0, 0.5652173913043478, 0.5221169036334916, 0.575, 1.0, 1.0, 0.8138693781696352, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35871023137105246, 0.3587102313710528, 0.40343528675088264], 
reward next is 0.5966, 
noisyNet noise sample is [array([-0.26151294], dtype=float32), -0.82674664]. 
=============================================
[2019-03-26 11:44:21,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.0596666e-25 1.0000000e+00 1.3728259e-23 2.8823209e-26 1.2113800e-24], sum to 1.0000
[2019-03-26 11:44:21,743] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8338
[2019-03-26 11:44:21,747] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.58333333333333, 72.16666666666667, 1.0, 2.0, 0.4528783460931059, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 640800.7608636237, 640800.7608636237, 177575.6038553252], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7582200.0000, 
sim time next is 7582800.0000, 
raw observation next is [27.46666666666667, 73.33333333333334, 1.0, 2.0, 0.4558510037865461, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 642940.3347757935, 642940.3347757929, 177741.299175611], 
processed observation next is [0.0, 0.782608695652174, 0.500789889415482, 0.7333333333333334, 1.0, 1.0, 0.34439879974282656, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1785945374377204, 0.17859453743772025, 0.2652855211576284], 
reward next is 0.7347, 
noisyNet noise sample is [array([1.3438891], dtype=float32), 0.9797609]. 
=============================================
[2019-03-26 11:44:25,273] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.2559444e-21 1.0000000e+00 6.8632112e-20 2.2595794e-21 1.2014473e-19], sum to 1.0000
[2019-03-26 11:44:25,281] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2771
[2019-03-26 11:44:25,287] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 89.33333333333333, 1.0, 2.0, 0.5318350685422644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 859660.5847458986, 859660.5847458986, 201295.2674595128], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7404000.0000, 
sim time next is 7404600.0000, 
raw observation next is [20.43333333333333, 89.16666666666667, 1.0, 2.0, 0.537329516017936, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 869358.8287553352, 869358.8287553352, 202392.1847829527], 
processed observation next is [1.0, 0.6956521739130435, 0.1674565560821484, 0.8916666666666667, 1.0, 1.0, 0.44256568194932044, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24148856354314865, 0.24148856354314865, 0.30207788773575034], 
reward next is 0.6979, 
noisyNet noise sample is [array([-0.18521746], dtype=float32), -0.37865788]. 
=============================================
[2019-03-26 11:44:30,589] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 11:44:30,592] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:44:30,592] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:44:30,593] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:44:30,594] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:44:30,595] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:44:30,595] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:44:30,596] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:44:30,597] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:44:30,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:44:30,599] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:44:30,610] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-26 11:44:30,625] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-26 11:44:30,650] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-26 11:44:30,664] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-26 11:44:30,665] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-26 11:44:41,627] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:44:41,629] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.36666666666667, 66.0, 1.0, 2.0, 0.4906791434088416, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727447.572502186, 727447.572502186, 187361.2762664908]
[2019-03-26 11:44:41,631] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:44:41,634] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4889838e-23 1.0000000e+00 5.1007645e-23 3.4370612e-27 9.5322773e-24], sampled 0.9948692914343699
[2019-03-26 11:44:49,476] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:44:49,478] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.05, 95.0, 1.0, 2.0, 0.732035705460625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1085236.327081783, 1085236.327081784, 236145.6492130463]
[2019-03-26 11:44:49,479] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:44:49,481] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.43864942e-23 1.00000000e+00 1.76904292e-22 1.25973075e-26
 7.94594788e-23], sampled 0.887294615346301
[2019-03-26 11:44:57,412] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:44:57,413] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.4, 85.0, 1.0, 2.0, 0.3768640902091879, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576435.1828555646, 576435.1828555646, 172807.9652348085]
[2019-03-26 11:44:57,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:44:57,417] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.7097462e-25 1.0000000e+00 1.2628210e-24 1.5322647e-29 2.1342117e-25], sampled 0.27487781135197753
[2019-03-26 11:44:57,456] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:44:57,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.23333333333333, 87.0, 1.0, 2.0, 0.4979567869974339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695816.3081932284, 695816.3081932284, 183276.5572540125]
[2019-03-26 11:44:57,457] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:44:57,459] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.7410517e-22 1.0000000e+00 4.0963018e-21 9.1867151e-22 1.1278917e-22], sampled 0.23998208887227412
[2019-03-26 11:45:30,630] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:45:30,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.39998078, 68.279516315, 1.0, 2.0, 0.6156465358504309, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.955651547993814, 6.9112, 168.912586012398, 1721369.117235504, 1689833.728355169, 367501.8171290536]
[2019-03-26 11:45:30,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:45:30,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.1702030e-13 9.9945885e-01 9.0179624e-09 5.4116605e-04 5.1466342e-10], sampled 0.4995988744518869
[2019-03-26 11:45:30,635] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1721369.117235504 W.
[2019-03-26 11:45:32,214] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:45:32,217] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.86042234, 70.47083848, 1.0, 2.0, 1.006522249624964, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.987156176766696, 6.9112, 168.9125046833486, 2304131.13588433, 2250245.354016228, 466011.3819386913]
[2019-03-26 11:45:32,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:45:32,221] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7706951e-09 9.7043747e-01 3.5236655e-05 2.9450681e-02 7.6613294e-05], sampled 0.34766925551550465
[2019-03-26 11:45:32,222] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2304131.13588433 W.
[2019-03-26 11:45:32,592] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:45:32,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.3, 67.0, 1.0, 2.0, 0.8627630687134924, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998376180336092, 6.9112, 168.9123677750311, 2102916.388505625, 2041070.821362184, 424228.0510667486]
[2019-03-26 11:45:32,596] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:45:32,601] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.7353461e-11 9.9155867e-01 4.0222087e-08 8.4412992e-03 7.0914727e-09], sampled 0.11891031968839494
[2019-03-26 11:45:32,602] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2102916.388505625 W.
[2019-03-26 11:45:51,476] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:45:51,477] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.65, 91.5, 1.0, 2.0, 0.5052430708611095, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 706001.12753763, 706001.12753763, 184421.2921938944]
[2019-03-26 11:45:51,478] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:45:51,479] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.2046404e-24 1.0000000e+00 1.7538429e-23 8.4361615e-28 2.8021503e-24], sampled 0.18785438500525065
[2019-03-26 11:45:56,842] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:45:56,843] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.94931505666667, 93.00289017666668, 1.0, 2.0, 0.6819765317947732, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 953070.3316591337, 953070.3316591337, 217004.5500996029]
[2019-03-26 11:45:56,844] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:45:56,847] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.4468642e-22 1.0000000e+00 1.5522325e-21 2.9098308e-25 1.0593344e-21], sampled 0.3461120738154475
[2019-03-26 11:46:03,812] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34644452], dtype=float32), 0.09491364]
[2019-03-26 11:46:03,812] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.53333333333333, 69.66666666666667, 1.0, 2.0, 0.5435840029039505, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9440256470674165, 6.911200000000001, 6.9112, 168.9126887935513, 1519735.513187714, 1519735.513187713, 332797.9542140772]
[2019-03-26 11:46:03,814] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:46:03,817] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6788567e-12 9.9938965e-01 4.3174012e-08 6.1034475e-04 1.3929560e-08], sampled 0.7316539728739079
[2019-03-26 11:46:25,105] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8023.4717 3151178370.4402 1447.0000
[2019-03-26 11:46:25,531] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8682.7643 2777216073.9349 876.0000
[2019-03-26 11:46:25,605] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8080.5788 2999412032.0033 1558.0000
[2019-03-26 11:46:25,877] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8295.7400 2923223101.2771 1242.0000
[2019-03-26 11:46:25,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8550.2626 2837669860.3485 1001.0000
[2019-03-26 11:46:26,972] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1050000, evaluation results [1050000.0, 8023.471705744948, 3151178370.4402285, 1447.0, 8295.739958365613, 2923223101.277136, 1242.0, 8682.764296905398, 2777216073.9349055, 876.0, 8080.578824548085, 2999412032.003278, 1558.0, 8550.26258935156, 2837669860.348533, 1001.0]
[2019-03-26 11:46:29,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:29,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:29,953] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-26 11:46:31,469] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.5377078e-18 1.0000000e+00 6.6146915e-16 6.8087499e-16 1.8631714e-15], sum to 1.0000
[2019-03-26 11:46:31,477] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-26 11:46:31,483] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 94.33333333333334, 1.0, 2.0, 0.4568600848926832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 650005.2741146933, 650005.2741146926, 178610.5267381745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7608000.0000, 
sim time next is 7608600.0000, 
raw observation next is [24.1, 94.5, 1.0, 2.0, 0.4544063925774371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647771.0579292617, 647771.0579292617, 178411.5992356181], 
processed observation next is [1.0, 0.043478260869565216, 0.3412322274881518, 0.945, 1.0, 1.0, 0.34265830431016514, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17993640498035046, 0.17993640498035046, 0.26628596900838525], 
reward next is 0.7337, 
noisyNet noise sample is [array([0.54735255], dtype=float32), -0.31878945]. 
=============================================
[2019-03-26 11:46:34,920] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.7865644e-19 1.0000000e+00 1.1986023e-15 2.4322966e-15 5.5664538e-16], sum to 1.0000
[2019-03-26 11:46:34,926] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3353
[2019-03-26 11:46:34,932] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.6, 95.0, 1.0, 2.0, 0.4779032091172766, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 667785.7787807185, 667785.7787807178, 180206.1727179014], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7696800.0000, 
sim time next is 7697400.0000, 
raw observation next is [24.6, 95.0, 1.0, 2.0, 0.7894754521107419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1103379.400868978, 1103379.400868978, 241340.0167837304], 
processed observation next is [1.0, 0.08695652173913043, 0.36492890995260674, 0.95, 1.0, 1.0, 0.7463559663984842, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3064942780191605, 0.3064942780191605, 0.3602089802742245], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.81581175], dtype=float32), -0.46615684]. 
=============================================
[2019-03-26 11:46:34,971] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:34,972] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:35,054] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-26 11:46:38,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.9901312e-09 1.5778802e-01 1.3579020e-06 8.4214181e-01 6.8739435e-05], sum to 1.0000
[2019-03-26 11:46:38,465] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0828
[2019-03-26 11:46:38,474] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1964664.489529205 W.
[2019-03-26 11:46:38,479] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.81666666666667, 76.83333333333333, 1.0, 2.0, 0.702586754154242, 1.0, 2.0, 0.702586754154242, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1964664.489529205, 1964664.489529206, 375232.0110798744], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7722600.0000, 
sim time next is 7723200.0000, 
raw observation next is [29.03333333333333, 75.66666666666667, 1.0, 2.0, 0.7903967123985393, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.987766825342512, 6.9112, 168.9125008507741, 2001633.331750357, 1947314.337156963, 406153.094017627], 
processed observation next is [1.0, 0.391304347826087, 0.5750394944707741, 0.7566666666666667, 1.0, 1.0, 0.7474659185524569, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.007656682534251225, 0.0, 0.8294377076547854, 0.5560092588195437, 0.5409206492102675, 0.606198647787503], 
reward next is 0.0110, 
noisyNet noise sample is [array([1.0010848], dtype=float32), 1.8700601]. 
=============================================
[2019-03-26 11:46:39,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1055924: loss 0.3679
[2019-03-26 11:46:39,716] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1055925: learning rate 0.0001
[2019-03-26 11:46:39,843] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:39,844] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:39,928] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-26 11:46:40,012] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6526364e-21 1.0000000e+00 1.7695653e-19 8.5641688e-22 4.6217217e-19], sum to 1.0000
[2019-03-26 11:46:40,022] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5284
[2019-03-26 11:46:40,025] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 84.0, 1.0, 2.0, 0.6687241109450456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 934541.766919579, 934541.766919579, 214237.9198633613], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7802400.0000, 
sim time next is 7803000.0000, 
raw observation next is [27.3, 83.5, 1.0, 2.0, 0.7140558042943365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 997922.5606028958, 997922.5606028958, 223907.2392876085], 
processed observation next is [1.0, 0.30434782608695654, 0.4928909952606636, 0.835, 1.0, 1.0, 0.65548892083655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27720071127858215, 0.27720071127858215, 0.33418990938449034], 
reward next is 0.6658, 
noisyNet noise sample is [array([-0.5897742], dtype=float32), -0.050579853]. 
=============================================
[2019-03-26 11:46:40,036] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.33281 ]
 [64.02242 ]
 [65.38994 ]
 [65.310036]
 [65.37201 ]], R is [[64.00123596]
 [64.04146576]
 [64.05252075]
 [64.10774994]
 [64.16529846]].
[2019-03-26 11:46:44,540] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1058298: loss 0.3314
[2019-03-26 11:46:44,542] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1058298: learning rate 0.0001
[2019-03-26 11:46:48,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:48,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:48,715] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-26 11:46:48,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:48,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:48,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-26 11:46:49,103] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1060558: loss 0.3382
[2019-03-26 11:46:49,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1060558: learning rate 0.0001
[2019-03-26 11:46:49,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:49,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:49,636] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-26 11:46:50,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:50,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:50,453] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-26 11:46:50,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:50,740] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:50,800] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-26 11:46:50,833] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:50,834] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:50,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-26 11:46:50,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:50,978] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,039] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-26 11:46:51,128] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,131] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,159] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,160] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-26 11:46:51,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-26 11:46:51,273] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,274] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,292] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-26 11:46:51,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,362] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-26 11:46:51,389] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,389] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-26 11:46:51,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 11:46:51,446] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:46:51,450] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-26 11:46:51,813] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1062030: loss 0.0360
[2019-03-26 11:46:51,815] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1062030: learning rate 0.0001
[2019-03-26 11:46:54,010] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1063265: loss 0.1573
[2019-03-26 11:46:54,015] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1063266: learning rate 0.0001
[2019-03-26 11:46:54,517] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1063563: loss 0.1770
[2019-03-26 11:46:54,519] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1063564: learning rate 0.0001
[2019-03-26 11:46:55,421] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1063938: loss 0.0032
[2019-03-26 11:46:55,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1063938: learning rate 0.0001
[2019-03-26 11:46:56,876] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1064604: loss 0.3023
[2019-03-26 11:46:56,879] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1064605: learning rate 0.0001
[2019-03-26 11:46:57,004] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.0305731e-20 1.0000000e+00 9.1911460e-19 1.8095842e-16 9.5012306e-18], sum to 1.0000
[2019-03-26 11:46:57,008] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7400
[2019-03-26 11:46:57,014] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 96.0, 1.0, 2.0, 0.3819850059386324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 576836.0541452381, 576836.0541452381, 172637.409321775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 157800.0000, 
sim time next is 158400.0000, 
raw observation next is [22.4, 96.0, 1.0, 2.0, 0.3803188587064071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 574320.0518680543, 574320.0518680537, 172414.0207110183], 
processed observation next is [1.0, 0.8695652173913043, 0.2606635071090047, 0.96, 1.0, 1.0, 0.2533962153089242, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1595333477411262, 0.15953334774112604, 0.25733435927017656], 
reward next is 0.7427, 
noisyNet noise sample is [array([-0.15278445], dtype=float32), -1.0589703]. 
=============================================
[2019-03-26 11:46:57,051] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.4475615e-22 1.0000000e+00 2.8565503e-21 3.9369092e-22 1.6049068e-20], sum to 1.0000
[2019-03-26 11:46:57,059] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9817
[2019-03-26 11:46:57,062] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.03333333333334, 85.33333333333334, 1.0, 2.0, 0.3577738573223444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 552198.1601016809, 552198.1601016803, 170859.2472245966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 76200.0000, 
sim time next is 76800.0000, 
raw observation next is [22.96666666666667, 85.66666666666667, 1.0, 2.0, 0.3557073192929176, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 549347.9638717785, 549347.9638717785, 170629.8965344804], 
processed observation next is [1.0, 0.9130434782608695, 0.2875197472353872, 0.8566666666666667, 1.0, 1.0, 0.22374375818423806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15259665663104957, 0.15259665663104957, 0.2546714873648961], 
reward next is 0.7453, 
noisyNet noise sample is [array([0.8056763], dtype=float32), -1.3129889]. 
=============================================
[2019-03-26 11:46:58,898] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1065529: loss 0.2392
[2019-03-26 11:46:58,901] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1065529: learning rate 0.0001
[2019-03-26 11:46:59,809] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1065962: loss 0.2775
[2019-03-26 11:46:59,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1065962: learning rate 0.0001
[2019-03-26 11:47:00,095] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066093: loss 0.2827
[2019-03-26 11:47:00,098] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066093: learning rate 0.0001
[2019-03-26 11:47:00,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1066360: loss 0.2399
[2019-03-26 11:47:00,683] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1066362: learning rate 0.0001
[2019-03-26 11:47:01,159] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1066584: loss 0.0050
[2019-03-26 11:47:01,161] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1066584: learning rate 0.0001
[2019-03-26 11:47:01,275] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1066639: loss 0.0764
[2019-03-26 11:47:01,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1066639: learning rate 0.0001
[2019-03-26 11:47:01,437] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1066716: loss 0.0542
[2019-03-26 11:47:01,438] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1066716: learning rate 0.0001
[2019-03-26 11:47:01,455] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1066724: loss 0.0502
[2019-03-26 11:47:01,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1066724: learning rate 0.0001
[2019-03-26 11:47:01,533] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1891444e-21 1.0000000e+00 1.4034076e-19 8.0807993e-19 1.1931894e-19], sum to 1.0000
[2019-03-26 11:47:01,535] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066756: loss 0.0582
[2019-03-26 11:47:01,540] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066761: learning rate 0.0001
[2019-03-26 11:47:01,543] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3469
[2019-03-26 11:47:01,548] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.56666666666667, 96.0, 1.0, 2.0, 0.3148618225490976, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 500013.017037639, 500013.0170376384, 167063.0082945245], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 169800.0000, 
sim time next is 170400.0000, 
raw observation next is [20.53333333333333, 96.0, 1.0, 2.0, 0.3128135820312611, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 497148.8268888287, 497148.8268888287, 166856.0252595158], 
processed observation next is [1.0, 1.0, 0.17219589257503945, 0.96, 1.0, 1.0, 0.17206455666416998, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13809689635800798, 0.13809689635800798, 0.2490388436709191], 
reward next is 0.7510, 
noisyNet noise sample is [array([-0.83818907], dtype=float32), 0.17422268]. 
=============================================
[2019-03-26 11:47:01,604] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066792: loss 0.0722
[2019-03-26 11:47:01,606] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066792: loss 0.0568
[2019-03-26 11:47:01,606] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066792: learning rate 0.0001
[2019-03-26 11:47:01,608] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066792: learning rate 0.0001
[2019-03-26 11:47:01,717] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.2779108e-25 1.0000000e+00 4.6572810e-25 1.4590391e-28 1.1029273e-25], sum to 1.0000
[2019-03-26 11:47:01,731] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9984
[2019-03-26 11:47:01,737] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.48333333333333, 93.0, 1.0, 2.0, 0.292651773939553, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469284.2277431712, 469284.2277431712, 164903.6525903517], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 204600.0000, 
sim time next is 205200.0000, 
raw observation next is [20.5, 93.0, 1.0, 2.0, 0.2927604075809669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469301.1687311629, 469301.1687311629, 164903.6486414795], 
processed observation next is [0.0, 0.391304347826087, 0.1706161137440759, 0.93, 1.0, 1.0, 0.14790410551923722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13036143575865636, 0.13036143575865636, 0.2461248487186261], 
reward next is 0.7539, 
noisyNet noise sample is [array([0.21580365], dtype=float32), -0.08879267]. 
=============================================
[2019-03-26 11:47:02,441] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3058116e-25 1.0000000e+00 4.7848315e-26 7.9792406e-30 8.2355297e-26], sum to 1.0000
[2019-03-26 11:47:02,444] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4912
[2019-03-26 11:47:02,451] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 96.0, 1.0, 2.0, 0.2856944411826112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460424.7653101006, 460424.7653101006, 164302.1342669122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 188400.0000, 
sim time next is 189000.0000, 
raw observation next is [19.85, 96.0, 1.0, 2.0, 0.2850920325991209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 459598.5327173639, 459598.5327173633, 164245.8599323117], 
processed observation next is [0.0, 0.17391304347826086, 0.1398104265402845, 0.96, 1.0, 1.0, 0.13866509951701314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12766625908815665, 0.1276662590881565, 0.24514307452583836], 
reward next is 0.7549, 
noisyNet noise sample is [array([-0.36943355], dtype=float32), 0.49093038]. 
=============================================
[2019-03-26 11:47:02,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[76.94713 ]
 [77.01183 ]
 [77.05905 ]
 [77.08619 ]
 [77.129524]], R is [[77.04051971]
 [77.02489471]
 [77.00934601]
 [76.993927  ]
 [76.97872162]].
[2019-03-26 11:47:03,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4457200e-26 1.0000000e+00 2.4046167e-25 5.2003975e-30 9.9740812e-26], sum to 1.0000
[2019-03-26 11:47:03,036] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7274
[2019-03-26 11:47:03,040] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.86666666666667, 96.0, 1.0, 2.0, 0.2856944411826112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 460424.7653101006, 460424.7653101006, 164302.1342669122], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 188400.0000, 
sim time next is 189000.0000, 
raw observation next is [19.85, 96.0, 1.0, 2.0, 0.2850920325991209, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 459598.5327173639, 459598.5327173633, 164245.8599323117], 
processed observation next is [0.0, 0.17391304347826086, 0.1398104265402845, 0.96, 1.0, 1.0, 0.13866509951701314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12766625908815665, 0.1276662590881565, 0.24514307452583836], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.43699205], dtype=float32), -1.0475508]. 
=============================================
[2019-03-26 11:47:03,047] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.78303]
 [77.82215]
 [77.83808]
 [77.82901]
 [77.83968]], R is [[77.88542175]
 [77.86134338]
 [77.83743286]
 [77.81373596]
 [77.79032898]].
[2019-03-26 11:47:06,730] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1069541: loss 4.9369
[2019-03-26 11:47:06,736] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1069542: learning rate 0.0001
[2019-03-26 11:47:09,929] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.6658716e-20 1.0000000e+00 1.8265541e-17 2.8809173e-16 1.7893755e-16], sum to 1.0000
[2019-03-26 11:47:09,936] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6786
[2019-03-26 11:47:09,939] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.65, 85.5, 1.0, 2.0, 0.2416396750564468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398145.4098398074, 398145.4098398067, 160078.15637442], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 433800.0000, 
sim time next is 434400.0000, 
raw observation next is [19.63333333333333, 85.33333333333334, 1.0, 2.0, 0.2408108809142203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 396950.562634402, 396950.5626344027, 159993.4607243839], 
processed observation next is [1.0, 0.0, 0.1295418641390204, 0.8533333333333334, 1.0, 1.0, 0.08531431435448227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11026404517622278, 0.11026404517622297, 0.2387962100363939], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.69639856], dtype=float32), -1.0564296]. 
=============================================
[2019-03-26 11:47:10,160] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1071135: loss 0.0190
[2019-03-26 11:47:10,164] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1071135: learning rate 0.0001
[2019-03-26 11:47:11,183] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1071613: loss 0.0247
[2019-03-26 11:47:11,186] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1071614: learning rate 0.0001
[2019-03-26 11:47:11,864] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1071921: loss 4.5632
[2019-03-26 11:47:11,868] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1071922: learning rate 0.0001
[2019-03-26 11:47:12,752] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.4021184e-23 1.0000000e+00 1.2271437e-22 1.7364667e-24 7.3113073e-22], sum to 1.0000
[2019-03-26 11:47:12,766] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0426
[2019-03-26 11:47:12,772] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.36666666666667, 86.5, 1.0, 2.0, 0.2609633783394137, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 425208.3495388778, 425208.3495388784, 161948.2201520966], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 367800.0000, 
sim time next is 368400.0000, 
raw observation next is [20.43333333333333, 86.0, 1.0, 2.0, 0.258034591050252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 420407.3492760002, 420407.3492760009, 161650.391173464], 
processed observation next is [1.0, 0.2608695652173913, 0.1674565560821484, 0.86, 1.0, 1.0, 0.1060657723497012, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1167798192433334, 0.1167798192433336, 0.24126924055740898], 
reward next is 0.7587, 
noisyNet noise sample is [array([0.34579667], dtype=float32), -0.37103096]. 
=============================================
[2019-03-26 11:47:13,209] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1072543: loss 0.0109
[2019-03-26 11:47:13,212] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1072543: learning rate 0.0001
[2019-03-26 11:47:15,449] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1073588: loss 0.0068
[2019-03-26 11:47:15,451] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1073588: learning rate 0.0001
[2019-03-26 11:47:16,269] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1073963: loss 0.0034
[2019-03-26 11:47:16,270] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1073963: learning rate 0.0001
[2019-03-26 11:47:16,540] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4131114e-24 1.0000000e+00 1.5579420e-25 7.2646108e-27 7.5966059e-24], sum to 1.0000
[2019-03-26 11:47:16,548] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5782
[2019-03-26 11:47:16,555] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 81.66666666666667, 1.0, 2.0, 0.2308156578175492, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 380968.9817660752, 380968.9817660752, 159036.7521455919], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 454800.0000, 
sim time next is 455400.0000, 
raw observation next is [20.05, 81.5, 1.0, 2.0, 0.2323528972158815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 383386.1076044721, 383386.1076044721, 159184.1578109189], 
processed observation next is [1.0, 0.2608695652173913, 0.14928909952606645, 0.815, 1.0, 1.0, 0.07512397254925482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10649614100124224, 0.10649614100124224, 0.23758829524017747], 
reward next is 0.7624, 
noisyNet noise sample is [array([-0.58210593], dtype=float32), -0.10523755]. 
=============================================
[2019-03-26 11:47:16,606] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074119: loss 0.0016
[2019-03-26 11:47:16,609] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074119: learning rate 0.0001
[2019-03-26 11:47:16,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.6738886e-21 1.0000000e+00 6.1828895e-21 5.2144484e-20 4.3218600e-19], sum to 1.0000
[2019-03-26 11:47:16,646] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8172
[2019-03-26 11:47:16,654] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 59.66666666666667, 1.0, 2.0, 0.3549737870922561, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 581411.1921034836, 581411.1921034836, 173166.289050024], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 476400.0000, 
sim time next is 477000.0000, 
raw observation next is [24.05, 59.0, 1.0, 2.0, 0.3219002911610787, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527073.9086395872, 527073.9086395872, 168879.8558512364], 
processed observation next is [1.0, 0.5217391304347826, 0.3388625592417062, 0.59, 1.0, 1.0, 0.18301239898925145, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.146409419066552, 0.146409419066552, 0.252059486345129], 
reward next is 0.7479, 
noisyNet noise sample is [array([-1.7251488], dtype=float32), 0.266224]. 
=============================================
[2019-03-26 11:47:16,666] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.16088 ]
 [72.60277 ]
 [72.4223  ]
 [72.51036 ]
 [72.823006]], R is [[75.10484314]
 [75.09534454]
 [75.05285645]
 [75.00396729]
 [74.95705414]].
[2019-03-26 11:47:17,246] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1074405: loss 0.0134
[2019-03-26 11:47:17,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1074405: learning rate 0.0001
[2019-03-26 11:47:17,452] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1074499: loss 4.7138
[2019-03-26 11:47:17,453] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1074500: learning rate 0.0001
[2019-03-26 11:47:17,850] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1074684: loss 0.0018
[2019-03-26 11:47:17,854] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1074685: learning rate 0.0001
[2019-03-26 11:47:17,869] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1074693: loss 0.0021
[2019-03-26 11:47:17,871] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1074693: learning rate 0.0001
[2019-03-26 11:47:17,954] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1074727: loss 0.0038
[2019-03-26 11:47:17,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1074728: learning rate 0.0001
[2019-03-26 11:47:18,004] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074751: loss 0.0024
[2019-03-26 11:47:18,006] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1074753: loss 0.0039
[2019-03-26 11:47:18,009] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074753: learning rate 0.0001
[2019-03-26 11:47:18,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1074754: learning rate 0.0001
[2019-03-26 11:47:18,232] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074858: loss 0.0018
[2019-03-26 11:47:18,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074859: learning rate 0.0001
[2019-03-26 11:47:18,545] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 11:47:18,546] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:47:18,547] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:47:18,548] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:47:18,549] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:47:18,549] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:47:18,550] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:47:18,551] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:47:18,550] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:47:18,554] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:47:18,554] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:47:18,578] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-26 11:47:18,578] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-26 11:47:18,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-26 11:47:18,647] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-26 11:47:18,664] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-26 11:47:31,620] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:47:31,621] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.9, 86.5, 1.0, 2.0, 0.277683325061373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 448518.5441800884, 448518.5441800891, 163500.584891153]
[2019-03-26 11:47:31,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:47:31,627] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.6750877e-26 1.0000000e+00 8.9197188e-27 2.5943371e-30 2.2288827e-26], sampled 0.913451339102174
[2019-03-26 11:47:39,284] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:47:39,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.1, 48.0, 1.0, 2.0, 0.2903364515562042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 469356.2669158006, 469356.2669158006, 164907.5162068237]
[2019-03-26 11:47:39,287] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:47:39,289] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0919480e-24 1.0000000e+00 1.0538437e-23 9.1331002e-25 2.4607042e-23], sampled 0.23961835021788291
[2019-03-26 11:48:08,217] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:48:08,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [35.89304777166667, 62.11871677333333, 1.0, 2.0, 0.6788013934140141, 1.0, 1.0, 0.6788013934140141, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 172.86236624, 1898071.433138574, 1898071.433138575, 365693.3091463472]
[2019-03-26 11:48:08,220] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:48:08,222] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [6.1405343e-12 2.0330854e-01 5.8618741e-09 7.9669136e-01 1.2869991e-07], sampled 0.5102315069896723
[2019-03-26 11:48:16,624] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:48:16,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.3, 47.0, 1.0, 2.0, 0.8059776432754523, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990182784576272, 6.9112, 168.9124232210797, 2023439.393534825, 1967406.464685613, 409911.6137252116]
[2019-03-26 11:48:16,626] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:48:16,628] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.5366173e-13 9.9803108e-01 7.0582186e-11 1.9688564e-03 5.5211480e-10], sampled 0.1464498472240906
[2019-03-26 11:48:16,630] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2023439.393534825 W.
[2019-03-26 11:48:21,585] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:48:21,588] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.78259422333333, 79.02929846833334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.034212436233718, 6.9112, 168.9068330368703, 3081087.702432312, 2284412.91135823, 473575.3215092542]
[2019-03-26 11:48:21,590] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:48:21,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8418937e-10 8.3946902e-01 1.5912167e-07 1.6049379e-01 3.7074107e-05], sampled 0.29722974794485624
[2019-03-26 11:48:21,593] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3081087.702432312 W.
[2019-03-26 11:48:40,579] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:48:40,581] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.85, 85.5, 1.0, 2.0, 0.6262462503933902, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 875154.5102116175, 875154.5102116168, 205737.4827199949]
[2019-03-26 11:48:40,582] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:48:40,584] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0556584e-23 1.0000000e+00 3.9791205e-24 9.4947064e-26 4.3670945e-23], sampled 0.6295431735075819
[2019-03-26 11:48:56,036] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3553683], dtype=float32), 0.107545845]
[2019-03-26 11:48:56,039] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 77.0, 1.0, 2.0, 0.5542027222173227, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774439.8087398477, 774439.8087398477, 192523.7935242351]
[2019-03-26 11:48:56,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:48:56,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5734912e-22 1.0000000e+00 1.1666461e-22 2.3369145e-22 2.2156047e-21], sampled 0.15521716569310406
[2019-03-26 11:49:13,619] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8549.8348 2837921522.9810 1012.0000
[2019-03-26 11:49:13,762] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8688.5206 2776716315.3605 862.0000
[2019-03-26 11:49:13,770] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8069.2974 3000428907.0651 1580.0000
[2019-03-26 11:49:13,774] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8007.2608 3152513764.7050 1477.0000
[2019-03-26 11:49:13,825] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8296.0819 2923016950.7021 1235.0000
[2019-03-26 11:49:14,841] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1075000, evaluation results [1075000.0, 8007.260800885626, 3152513764.7049756, 1477.0, 8296.081907526484, 2923016950.7020507, 1235.0, 8688.52061772505, 2776716315.36051, 862.0, 8069.297399241542, 3000428907.0651197, 1580.0, 8549.834763143364, 2837921522.9809885, 1012.0]
[2019-03-26 11:49:15,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8012569e-19 1.0000000e+00 1.0971659e-17 9.0042752e-17 2.0960740e-16], sum to 1.0000
[2019-03-26 11:49:15,326] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1144
[2019-03-26 11:49:15,330] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.9, 57.5, 1.0, 2.0, 0.2428323260854071, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399503.9608848941, 399503.9608848948, 160206.8695239888], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 495000.0000, 
sim time next is 495600.0000, 
raw observation next is [23.66666666666666, 58.66666666666667, 1.0, 2.0, 0.2441484281831629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401794.9482600507, 401794.9482600507, 160331.1385596043], 
processed observation next is [1.0, 0.7391304347826086, 0.3206951026856238, 0.5866666666666667, 1.0, 1.0, 0.08933545564236493, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11160970785001408, 0.11160970785001408, 0.23930020680537956], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.5084485], dtype=float32), 0.6863198]. 
=============================================
[2019-03-26 11:49:16,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [6.2613372e-20 1.0000000e+00 2.9247088e-18 1.3087913e-15 4.2898860e-16], sum to 1.0000
[2019-03-26 11:49:16,427] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8470
[2019-03-26 11:49:16,430] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.36666666666667, 55.16666666666666, 1.0, 2.0, 0.3100019470312426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509637.4464753962, 509637.4464753969, 167449.2733693903], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 493800.0000, 
sim time next is 494400.0000, 
raw observation next is [24.13333333333333, 56.33333333333334, 1.0, 2.0, 0.2452469301751609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 403336.2076768128, 403336.2076768128, 160441.8359325455], 
processed observation next is [1.0, 0.7391304347826086, 0.3428120063191152, 0.5633333333333335, 1.0, 1.0, 0.09065895201826613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11203783546578133, 0.11203783546578133, 0.2394654267649933], 
reward next is 0.7605, 
noisyNet noise sample is [array([-0.07368346], dtype=float32), 0.014555484]. 
=============================================
[2019-03-26 11:49:18,397] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3692357e-19 1.0000000e+00 4.3608776e-19 1.4126906e-17 1.4296818e-16], sum to 1.0000
[2019-03-26 11:49:18,407] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2338
[2019-03-26 11:49:18,413] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.03333333333333, 58.66666666666667, 1.0, 2.0, 0.5545895935895162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 908492.3237519702, 908492.3237519709, 206181.3662040037], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 645000.0000, 
sim time next is 645600.0000, 
raw observation next is [24.06666666666667, 58.33333333333334, 1.0, 2.0, 0.5886806297422197, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 964628.6644423761, 964628.6644423761, 213178.2764068074], 
processed observation next is [1.0, 0.4782608695652174, 0.3396524486571882, 0.5833333333333335, 1.0, 1.0, 0.5044344936653249, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2679524067895489, 0.2679524067895489, 0.3181765319504588], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.47197112], dtype=float32), -1.45773]. 
=============================================
[2019-03-26 11:49:20,501] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1077544: loss 0.0186
[2019-03-26 11:49:20,504] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1077544: learning rate 0.0001
[2019-03-26 11:49:24,042] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1079135: loss 3.9542
[2019-03-26 11:49:24,043] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1079135: learning rate 0.0001
[2019-03-26 11:49:24,820] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1079489: loss 4.5742
[2019-03-26 11:49:24,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1079490: learning rate 0.0001
[2019-03-26 11:49:25,786] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1079925: loss 0.0118
[2019-03-26 11:49:25,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1079925: learning rate 0.0001
[2019-03-26 11:49:27,167] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1080550: loss 4.1245
[2019-03-26 11:49:27,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1080550: learning rate 0.0001
[2019-03-26 11:49:29,586] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1081583: loss 3.9819
[2019-03-26 11:49:29,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1081584: learning rate 0.0001
[2019-03-26 11:49:30,366] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1081944: loss 3.5521
[2019-03-26 11:49:30,370] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1081944: learning rate 0.0001
[2019-03-26 11:49:30,712] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082110: loss 3.6086
[2019-03-26 11:49:30,715] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082112: learning rate 0.0001
[2019-03-26 11:49:31,474] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1082462: loss 3.1579
[2019-03-26 11:49:31,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1082463: learning rate 0.0001
[2019-03-26 11:49:31,541] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1082493: loss 0.0101
[2019-03-26 11:49:31,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1082493: learning rate 0.0001
[2019-03-26 11:49:31,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1082669: loss 3.2843
[2019-03-26 11:49:31,920] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1082669: learning rate 0.0001
[2019-03-26 11:49:32,012] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1082710: loss 3.1933
[2019-03-26 11:49:32,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1082711: learning rate 0.0001
[2019-03-26 11:49:32,025] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1082718: loss 3.2605
[2019-03-26 11:49:32,026] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1082718: learning rate 0.0001
[2019-03-26 11:49:32,127] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082762: loss 3.2577
[2019-03-26 11:49:32,129] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082762: learning rate 0.0001
[2019-03-26 11:49:32,163] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1082774: loss 3.1648
[2019-03-26 11:49:32,167] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1082776: learning rate 0.0001
[2019-03-26 11:49:32,453] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082911: loss 3.2625
[2019-03-26 11:49:32,455] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082912: learning rate 0.0001
[2019-03-26 11:49:38,540] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1085592: loss 1.3477
[2019-03-26 11:49:38,543] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1085593: learning rate 0.0001
[2019-03-26 11:49:41,270] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.0811388e-20 1.0000000e+00 1.0783480e-18 1.1354060e-17 1.5024996e-17], sum to 1.0000
[2019-03-26 11:49:41,280] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7323
[2019-03-26 11:49:41,285] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.3, 96.33333333333333, 1.0, 2.0, 0.397315129270448, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 600258.6993975863, 600258.6993975863, 174760.7903989587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045200.0000, 
sim time next is 1045800.0000, 
raw observation next is [22.15, 96.5, 1.0, 2.0, 0.3606971938124785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547255.1984593577, 547255.1984593577, 170157.3581204329], 
processed observation next is [1.0, 0.08695652173913043, 0.24881516587677724, 0.965, 1.0, 1.0, 0.22975565519575722, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15201533290537714, 0.15201533290537714, 0.25396620614989984], 
reward next is 0.7460, 
noisyNet noise sample is [array([0.38129818], dtype=float32), -0.26554257]. 
=============================================
[2019-03-26 11:49:41,848] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1087136: loss 0.0108
[2019-03-26 11:49:41,850] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1087137: learning rate 0.0001
[2019-03-26 11:49:42,493] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1087434: loss 0.0186
[2019-03-26 11:49:42,496] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1087435: learning rate 0.0001
[2019-03-26 11:49:43,578] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1087934: loss 1.4197
[2019-03-26 11:49:43,584] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1087935: learning rate 0.0001
[2019-03-26 11:49:44,199] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.4491301e-23 1.0000000e+00 1.4783676e-21 6.9122588e-22 3.9038603e-21], sum to 1.0000
[2019-03-26 11:49:44,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1344
[2019-03-26 11:49:44,212] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 94.16666666666667, 1.0, 2.0, 0.3442852464206104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 532953.7233094486, 532953.7233094486, 169317.6355052818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 960600.0000, 
sim time next is 961200.0000, 
raw observation next is [21.8, 94.0, 1.0, 2.0, 0.3433815576369807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531856.691001625, 531856.6910016245, 169237.5690268535], 
processed observation next is [1.0, 0.13043478260869565, 0.23222748815165886, 0.94, 1.0, 1.0, 0.2088934429361213, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1477379697226736, 0.14773796972267345, 0.25259338660724406], 
reward next is 0.7474, 
noisyNet noise sample is [array([-0.14439145], dtype=float32), -0.55887574]. 
=============================================
[2019-03-26 11:49:45,032] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1088619: loss 0.0038
[2019-03-26 11:49:45,034] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1088620: learning rate 0.0001
[2019-03-26 11:49:46,696] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2280073e-19 1.0000000e+00 2.9059490e-17 3.8537702e-16 9.5033742e-17], sum to 1.0000
[2019-03-26 11:49:46,706] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5924
[2019-03-26 11:49:46,711] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.7, 97.0, 1.0, 2.0, 0.3573041311786649, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549303.5648226578, 549303.5648226573, 170556.7196522344], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1015200.0000, 
sim time next is 1015800.0000, 
raw observation next is [21.71666666666667, 96.83333333333334, 1.0, 2.0, 0.3598122273471944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 553296.8323661025, 553296.8323661019, 170896.1081969232], 
processed observation next is [1.0, 0.782608695652174, 0.22827804107424976, 0.9683333333333334, 1.0, 1.0, 0.22868943053878846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15369356454613958, 0.15369356454613942, 0.25506881820436295], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.4244192], dtype=float32), -0.1720493]. 
=============================================
[2019-03-26 11:49:47,089] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1089565: loss 0.0088
[2019-03-26 11:49:47,096] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1089567: learning rate 0.0001
[2019-03-26 11:49:47,405] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2433298e-21 1.0000000e+00 1.4966975e-19 1.2146553e-18 4.4236941e-18], sum to 1.0000
[2019-03-26 11:49:47,412] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4836
[2019-03-26 11:49:47,416] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.9, 96.16666666666666, 1.0, 2.0, 0.3564194821925666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 546522.4986521256, 546522.4986521256, 170282.1450057607], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1026600.0000, 
sim time next is 1027200.0000, 
raw observation next is [21.9, 96.33333333333333, 1.0, 2.0, 0.3566509502024217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 546549.2769441827, 546549.2769441821, 170274.4045019448], 
processed observation next is [1.0, 0.9130434782608695, 0.23696682464454974, 0.9633333333333333, 1.0, 1.0, 0.224880662894484, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1518192435956063, 0.15181924359560614, 0.25414090224170865], 
reward next is 0.7459, 
noisyNet noise sample is [array([1.1241236], dtype=float32), -2.5656698]. 
=============================================
[2019-03-26 11:49:47,874] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1089930: loss 0.0035
[2019-03-26 11:49:47,878] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1089932: learning rate 0.0001
[2019-03-26 11:49:48,104] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.28713625e-20 1.00000000e+00 2.83500604e-18 1.70725168e-16
 1.13944606e-16], sum to 1.0000
[2019-03-26 11:49:48,112] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3711
[2019-03-26 11:49:48,118] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 98.0, 1.0, 2.0, 0.3695972679602647, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 561246.9547247476, 561246.9547247476, 171367.356081686], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1033200.0000, 
sim time next is 1033800.0000, 
raw observation next is [22.03333333333333, 97.83333333333334, 1.0, 2.0, 0.3713452241191626, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 563523.7318817053, 563523.731881706, 171552.6863757075], 
processed observation next is [1.0, 1.0, 0.2432859399684044, 0.9783333333333334, 1.0, 1.0, 0.24258460737248505, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15653436996714037, 0.15653436996714057, 0.25604878563538436], 
reward next is 0.7440, 
noisyNet noise sample is [array([0.2020256], dtype=float32), 0.8477093]. 
=============================================
[2019-03-26 11:49:48,432] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090183: loss 0.0056
[2019-03-26 11:49:48,433] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090183: learning rate 0.0001
[2019-03-26 11:49:49,071] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1090476: loss 0.0038
[2019-03-26 11:49:49,073] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1090477: learning rate 0.0001
[2019-03-26 11:49:49,081] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1090483: loss 1.3710
[2019-03-26 11:49:49,083] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1090483: learning rate 0.0001
[2019-03-26 11:49:49,394] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1090637: loss 0.0063
[2019-03-26 11:49:49,397] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1090638: learning rate 0.0001
[2019-03-26 11:49:49,403] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.2598961e-23 1.0000000e+00 4.3851907e-23 9.0365200e-24 1.3662343e-21], sum to 1.0000
[2019-03-26 11:49:49,413] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4160
[2019-03-26 11:49:49,419] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.3, 96.5, 1.0, 2.0, 0.3325613554506282, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 517316.5723982737, 517316.5723982743, 168145.1584687701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1049400.0000, 
sim time next is 1050000.0000, 
raw observation next is [21.16666666666666, 96.33333333333334, 1.0, 2.0, 0.3280387250889422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 512374.4978643529, 512374.4978643529, 167819.2174377652], 
processed observation next is [1.0, 0.13043478260869565, 0.2022116903633489, 0.9633333333333334, 1.0, 1.0, 0.19040810251679785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1423262494067647, 0.1423262494067647, 0.250476443936963], 
reward next is 0.7495, 
noisyNet noise sample is [array([-2.0805492], dtype=float32), -1.5118203]. 
=============================================
[2019-03-26 11:49:49,429] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[76.33457 ]
 [76.30005 ]
 [76.36314 ]
 [76.19524 ]
 [76.159904]], R is [[76.33589935]
 [76.32157898]
 [76.30691528]
 [76.28952789]
 [76.27360535]].
[2019-03-26 11:49:49,495] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1090682: loss 0.0130
[2019-03-26 11:49:49,498] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1090682: learning rate 0.0001
[2019-03-26 11:49:49,598] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1090728: loss 0.0120
[2019-03-26 11:49:49,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1090730: learning rate 0.0001
[2019-03-26 11:49:49,611] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1090733: loss 0.0157
[2019-03-26 11:49:49,612] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1090733: learning rate 0.0001
[2019-03-26 11:49:49,816] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090828: loss 0.0057
[2019-03-26 11:49:49,821] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090828: learning rate 0.0001
[2019-03-26 11:49:50,018] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090918: loss 0.0029
[2019-03-26 11:49:50,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090919: learning rate 0.0001
[2019-03-26 11:49:56,140] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1093668: loss 0.1371
[2019-03-26 11:49:56,142] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1093671: learning rate 0.0001
[2019-03-26 11:49:59,336] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1095148: loss 1.3610
[2019-03-26 11:49:59,341] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1095150: learning rate 0.0001
[2019-03-26 11:49:59,428] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.9107336e-11 9.3852073e-01 4.8455133e-09 6.1477974e-02 1.3634365e-06], sum to 1.0000
[2019-03-26 11:49:59,436] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8043
[2019-03-26 11:49:59,445] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2080851.601529628 W.
[2019-03-26 11:49:59,451] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.1, 74.66666666666667, 1.0, 2.0, 0.7440962962189647, 1.0, 2.0, 0.7440962962189647, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2080851.601529628, 2080851.601529627, 393563.2735557885], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1266000.0000, 
sim time next is 1266600.0000, 
raw observation next is [28.05, 74.83333333333333, 1.0, 2.0, 0.7391214862426245, 1.0, 2.0, 0.7391214862426245, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2066926.21561116, 2066926.21561116, 391311.921754625], 
processed observation next is [1.0, 0.6521739130434783, 0.528436018957346, 0.7483333333333333, 1.0, 1.0, 0.6856885376417163, 1.0, 1.0, 0.6856885376417163, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5741461710031001, 0.5741461710031001, 0.584047644409888], 
reward next is 0.4160, 
noisyNet noise sample is [array([-0.34721783], dtype=float32), 1.3462044]. 
=============================================
[2019-03-26 11:49:59,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1095351: loss 1.4251
[2019-03-26 11:49:59,785] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1095352: learning rate 0.0001
[2019-03-26 11:50:00,840] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1095837: loss 0.0622
[2019-03-26 11:50:00,842] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1095838: learning rate 0.0001
[2019-03-26 11:50:00,962] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7067048e-11 5.8028847e-01 2.8910688e-07 4.1970482e-01 6.4903898e-06], sum to 1.0000
[2019-03-26 11:50:00,969] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7777
[2019-03-26 11:50:00,974] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.2, 72.0, 1.0, 2.0, 0.6252322445942974, 1.0, 2.0, 0.6252322445942974, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1748179.282523686, 1748179.282523686, 343748.3191501441], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1252800.0000, 
sim time next is 1253400.0000, 
raw observation next is [28.23333333333333, 72.16666666666667, 1.0, 2.0, 0.6790187053719742, 1.0, 2.0, 0.6790187053719742, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1898702.047809245, 1898702.047809244, 365261.2683330406], 
processed observation next is [1.0, 0.5217391304347826, 0.537124802527646, 0.7216666666666667, 1.0, 1.0, 0.6132755486409327, 1.0, 1.0, 0.6132755486409327, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.527417235502568, 0.5274172355025678, 0.5451660721388666], 
reward next is 0.4548, 
noisyNet noise sample is [array([-1.6284887], dtype=float32), 1.6823244]. 
=============================================
[2019-03-26 11:50:02,640] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1096672: loss 1.4567
[2019-03-26 11:50:02,648] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1096674: learning rate 0.0001
[2019-03-26 11:50:04,517] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1097553: loss 1.1921
[2019-03-26 11:50:04,521] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1097555: learning rate 0.0001
[2019-03-26 11:50:05,400] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1097961: loss 1.3090
[2019-03-26 11:50:05,402] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1097961: learning rate 0.0001
[2019-03-26 11:50:05,861] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098173: loss 1.3279
[2019-03-26 11:50:05,864] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098175: learning rate 0.0001
[2019-03-26 11:50:06,375] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1098412: loss 0.0013
[2019-03-26 11:50:06,378] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1098413: learning rate 0.0001
[2019-03-26 11:50:06,445] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1098443: loss 1.1776
[2019-03-26 11:50:06,446] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1098443: learning rate 0.0001
[2019-03-26 11:50:06,903] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1098657: loss 1.2092
[2019-03-26 11:50:06,906] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1098657: learning rate 0.0001
[2019-03-26 11:50:06,975] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1098686: loss 1.1615
[2019-03-26 11:50:06,979] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1098686: learning rate 0.0001
[2019-03-26 11:50:07,116] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1098752: loss 1.2261
[2019-03-26 11:50:07,119] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1098752: learning rate 0.0001
[2019-03-26 11:50:07,199] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.4177966e-25 1.0000000e+00 1.0480297e-25 4.0635104e-28 2.6092810e-25], sum to 1.0000
[2019-03-26 11:50:07,205] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098789: loss 1.2374
[2019-03-26 11:50:07,207] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9744
[2019-03-26 11:50:07,208] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098790: learning rate 0.0001
[2019-03-26 11:50:07,212] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.85, 96.5, 1.0, 2.0, 0.3181855972912074, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501507.0583683559, 501507.0583683565, 167104.0824172663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1402200.0000, 
sim time next is 1402800.0000, 
raw observation next is [20.93333333333333, 96.0, 1.0, 2.0, 0.3200696130948363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 504170.4427427043, 504170.4427427043, 167298.2966800714], 
processed observation next is [0.0, 0.21739130434782608, 0.19115323854660338, 0.96, 1.0, 1.0, 0.180806762764863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.14004734520630674, 0.14004734520630674, 0.24969895026876326], 
reward next is 0.7503, 
noisyNet noise sample is [array([0.35960814], dtype=float32), 0.74725115]. 
=============================================
[2019-03-26 11:50:07,326] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1098846: loss 1.2325
[2019-03-26 11:50:07,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1098846: learning rate 0.0001
[2019-03-26 11:50:07,527] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098936: loss 1.0402
[2019-03-26 11:50:07,532] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098936: learning rate 0.0001
[2019-03-26 11:50:08,178] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.4872199e-20 1.0000000e+00 1.1577154e-18 1.4316302e-16 1.5622691e-17], sum to 1.0000
[2019-03-26 11:50:08,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0353
[2019-03-26 11:50:08,194] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.18333333333333, 94.0, 1.0, 2.0, 0.3236282865383968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509589.5633018786, 509589.5633018792, 167706.4437487769], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1367400.0000, 
sim time next is 1368000.0000, 
raw observation next is [21.2, 94.0, 1.0, 2.0, 0.3239144034887438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509831.6226230711, 509831.6226230717, 167720.4217062879], 
processed observation next is [1.0, 0.8695652173913043, 0.20379146919431282, 0.94, 1.0, 1.0, 0.18543904034788408, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1416198951730753, 0.14161989517307547, 0.2503289876213252], 
reward next is 0.7497, 
noisyNet noise sample is [array([-0.17580242], dtype=float32), 0.67096454]. 
=============================================
[2019-03-26 11:50:08,216] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.30443 ]
 [76.353165]
 [76.47865 ]
 [76.56569 ]
 [76.71793 ]], R is [[76.37537384]
 [76.36131287]
 [76.34745026]
 [76.33383942]
 [76.3204422 ]].
[2019-03-26 11:50:09,801] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-26 11:50:09,804] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:50:09,805] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:50:09,805] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:50:09,806] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:50:09,808] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:50:09,811] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:50:09,807] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:50:09,813] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:50:09,815] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:50:09,815] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:50:09,832] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-26 11:50:09,855] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-26 11:50:09,855] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-26 11:50:09,856] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-26 11:50:09,911] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-26 11:50:14,997] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.34670812], dtype=float32), 0.10667063]
[2019-03-26 11:50:15,001] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.68333333333333, 86.0, 1.0, 2.0, 0.2684175566462462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 435523.5626446234, 435523.5626446228, 162636.5003922702]
[2019-03-26 11:50:15,003] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:50:15,005] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.2681661e-22 1.0000000e+00 9.3026363e-21 1.2690635e-19 5.5272551e-20], sampled 0.4992555501603789
[2019-03-26 11:50:42,307] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34670812], dtype=float32), 0.10667063]
[2019-03-26 11:50:42,307] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.40360526333333, 64.38245497999999, 1.0, 2.0, 0.7718483196401477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1078731.017084777, 1078731.017084777, 237114.2763827132]
[2019-03-26 11:50:42,309] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:50:42,313] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5265492e-19 1.0000000e+00 7.1080592e-19 5.9924683e-17 1.7902827e-17], sampled 0.645343553079244
[2019-03-26 11:51:04,298] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34670812], dtype=float32), 0.10667063]
[2019-03-26 11:51:04,299] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.19361222, 83.25061265666668, 1.0, 2.0, 0.5693570474481219, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795624.309849986, 795624.309849986, 195177.1253412096]
[2019-03-26 11:51:04,301] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:51:04,303] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.71970483e-21 1.00000000e+00 1.29930154e-20 3.75618632e-19
 3.20982293e-19], sampled 0.5654804458182734
[2019-03-26 11:51:34,101] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.34670812], dtype=float32), 0.10667063]
[2019-03-26 11:51:34,102] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.32146926666667, 69.03787986666667, 1.0, 2.0, 0.4864215385189593, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 684276.6234197166, 684276.6234197172, 182085.7884168462]
[2019-03-26 11:51:34,103] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:51:34,105] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.0964877e-22 1.0000000e+00 3.4205651e-21 7.4655920e-20 3.2241794e-20], sampled 0.042667049327748785
[2019-03-26 11:52:03,136] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34670812], dtype=float32), 0.10667063]
[2019-03-26 11:52:03,138] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.65363062833334, 60.31625411666667, 1.0, 2.0, 0.9095393345885056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1271282.433167664, 1271282.433167664, 272581.8843403936]
[2019-03-26 11:52:03,140] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:52:03,142] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6045648e-19 1.0000000e+00 9.6490453e-19 5.5003828e-17 2.4491182e-17], sampled 0.09971901020325824
[2019-03-26 11:52:04,309] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8067.8379 3147058469.6507 1330.0000
[2019-03-26 11:52:05,018] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8146.0946 2993893522.9607 1402.0000
[2019-03-26 11:52:05,111] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8324.7118 2920895663.0806 1175.0000
[2019-03-26 11:52:05,246] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8585.6680 2835197046.7583 926.0000
[2019-03-26 11:52:05,339] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8704.0392 2775386615.0734 833.0000
[2019-03-26 11:52:06,356] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1100000, evaluation results [1100000.0, 8067.837878259079, 3147058469.6506863, 1330.0, 8324.711790228826, 2920895663.080584, 1175.0, 8704.039186902113, 2775386615.0733595, 833.0, 8146.094559387607, 2993893522.9607077, 1402.0, 8585.667974158572, 2835197046.7583222, 926.0]
[2019-03-26 11:52:08,829] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.0854772e-21 1.0000000e+00 2.7279564e-20 7.5618687e-20 1.7391891e-19], sum to 1.0000
[2019-03-26 11:52:08,838] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4410
[2019-03-26 11:52:08,843] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.83333333333334, 77.33333333333334, 1.0, 2.0, 0.4147932769288407, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 607054.8536704936, 607054.8536704936, 174851.578997805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1447800.0000, 
sim time next is 1448400.0000, 
raw observation next is [25.56666666666667, 78.66666666666667, 1.0, 2.0, 0.4147886821953669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 608421.2986899934, 608421.2986899934, 175021.3092074438], 
processed observation next is [0.0, 0.782608695652174, 0.41074249605055313, 0.7866666666666667, 1.0, 1.0, 0.2949261231269481, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16900591630277595, 0.16900591630277595, 0.26122583463797583], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.52307945], dtype=float32), -0.7799941]. 
=============================================
[2019-03-26 11:52:10,073] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1101675: loss 0.3752
[2019-03-26 11:52:10,076] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1101676: learning rate 0.0001
[2019-03-26 11:52:13,239] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1103107: loss 0.0143
[2019-03-26 11:52:13,242] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1103107: learning rate 0.0001
[2019-03-26 11:52:13,658] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1103296: loss 0.0101
[2019-03-26 11:52:13,662] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1103299: learning rate 0.0001
[2019-03-26 11:52:14,945] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1103890: loss 1.6739
[2019-03-26 11:52:14,947] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1103890: learning rate 0.0001
[2019-03-26 11:52:16,688] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1104666: loss 0.0246
[2019-03-26 11:52:16,693] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1104667: learning rate 0.0001
[2019-03-26 11:52:18,583] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1105514: loss 0.0006
[2019-03-26 11:52:18,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1105517: learning rate 0.0001
[2019-03-26 11:52:19,377] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1105928: loss 0.0041
[2019-03-26 11:52:19,380] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1105928: learning rate 0.0001
[2019-03-26 11:52:20,060] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106173: loss 0.0007
[2019-03-26 11:52:20,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106174: learning rate 0.0001
[2019-03-26 11:52:20,538] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.04457634e-19 1.00000000e+00 3.42160117e-18 4.40495249e-14
 4.19380518e-16], sum to 1.0000
[2019-03-26 11:52:20,545] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6304
[2019-03-26 11:52:20,550] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.1, 97.66666666666666, 1.0, 2.0, 0.4186766743579723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 612263.0367881114, 612263.0367881114, 175331.7074861569], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1636800.0000, 
sim time next is 1637400.0000, 
raw observation next is [23.1, 97.83333333333334, 1.0, 2.0, 0.4194867575474115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 612962.5116811729, 612962.5116811722, 175384.3472161093], 
processed observation next is [1.0, 0.9565217391304348, 0.2938388625592418, 0.9783333333333334, 1.0, 1.0, 0.3005864548763994, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17026736435588136, 0.17026736435588116, 0.26176768241210346], 
reward next is 0.7382, 
noisyNet noise sample is [array([1.537755], dtype=float32), -0.48384422]. 
=============================================
[2019-03-26 11:52:20,693] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1106460: loss -35.4891
[2019-03-26 11:52:20,698] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1106462: learning rate 0.0001
[2019-03-26 11:52:20,700] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1106462: loss 0.0007
[2019-03-26 11:52:20,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1106462: learning rate 0.0001
[2019-03-26 11:52:21,149] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1106669: loss 0.0006
[2019-03-26 11:52:21,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1106669: learning rate 0.0001
[2019-03-26 11:52:21,162] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1106672: loss 0.0006
[2019-03-26 11:52:21,163] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1106672: learning rate 0.0001
[2019-03-26 11:52:21,286] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1106728: loss 0.0013
[2019-03-26 11:52:21,287] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1106728: learning rate 0.0001
[2019-03-26 11:52:21,382] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1106776: loss 0.0011
[2019-03-26 11:52:21,383] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1106776: learning rate 0.0001
[2019-03-26 11:52:21,400] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1106783: loss 0.0017
[2019-03-26 11:52:21,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1106783: learning rate 0.0001
[2019-03-26 11:52:21,627] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106885: loss 0.0013
[2019-03-26 11:52:21,629] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106885: learning rate 0.0001
[2019-03-26 11:52:27,662] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1109696: loss 6.0626
[2019-03-26 11:52:27,665] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1109696: learning rate 0.0001
[2019-03-26 11:52:30,841] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1111161: loss 4.8135
[2019-03-26 11:52:30,844] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1111162: learning rate 0.0001
[2019-03-26 11:52:31,242] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1111348: loss 5.1352
[2019-03-26 11:52:31,243] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1111348: learning rate 0.0001
[2019-03-26 11:52:32,525] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1111939: loss 6.5450
[2019-03-26 11:52:32,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1111942: learning rate 0.0001
[2019-03-26 11:52:34,108] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1112673: loss 0.9356
[2019-03-26 11:52:34,110] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1112674: learning rate 0.0001
[2019-03-26 11:52:35,821] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1113477: loss 3.0203
[2019-03-26 11:52:35,823] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1113477: learning rate 0.0001
[2019-03-26 11:52:36,288] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1810644e-21 1.0000000e+00 1.6476985e-20 9.5568739e-20 3.3146838e-19], sum to 1.0000
[2019-03-26 11:52:36,293] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9665
[2019-03-26 11:52:36,299] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.1, 83.66666666666667, 1.0, 2.0, 0.508118286132569, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 710020.1507385301, 710020.1507385301, 184878.0600177137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2042400.0000, 
sim time next is 2043000.0000, 
raw observation next is [27.05, 84.0, 1.0, 2.0, 0.5078796389559456, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709686.5652108587, 709686.5652108587, 184840.1169328549], 
processed observation next is [0.0, 0.6521739130434783, 0.4810426540284361, 0.84, 1.0, 1.0, 0.4070839023565609, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19713515700301631, 0.19713515700301631, 0.2758807715415745], 
reward next is 0.7241, 
noisyNet noise sample is [array([-0.245025], dtype=float32), -0.6608012]. 
=============================================
[2019-03-26 11:52:36,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[77.36621 ]
 [77.33261 ]
 [77.29859 ]
 [77.16842 ]
 [77.096954]], R is [[77.35148621]
 [77.30203247]
 [77.25288391]
 [77.20407867]
 [77.15548706]].
[2019-03-26 11:52:36,808] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1113934: loss -10.5776
[2019-03-26 11:52:36,810] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1113935: learning rate 0.0001
[2019-03-26 11:52:37,338] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114182: loss 0.9854
[2019-03-26 11:52:37,339] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114182: learning rate 0.0001
[2019-03-26 11:52:37,799] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1114392: loss 0.2889
[2019-03-26 11:52:37,800] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1114392: learning rate 0.0001
[2019-03-26 11:52:37,928] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1114452: loss 6.3262
[2019-03-26 11:52:37,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1114453: learning rate 0.0001
[2019-03-26 11:52:38,377] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1114657: loss 3.5048
[2019-03-26 11:52:38,380] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1114658: learning rate 0.0001
[2019-03-26 11:52:38,504] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1114714: loss 5.4095
[2019-03-26 11:52:38,508] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1114714: learning rate 0.0001
[2019-03-26 11:52:38,549] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1114734: loss 1.5548
[2019-03-26 11:52:38,550] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1114734: learning rate 0.0001
[2019-03-26 11:52:38,637] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1114776: loss 2.1700
[2019-03-26 11:52:38,639] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1114777: learning rate 0.0001
[2019-03-26 11:52:38,646] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1114780: loss 6.3694
[2019-03-26 11:52:38,647] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1114780: learning rate 0.0001
[2019-03-26 11:52:38,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.0009048e-11 9.4725502e-01 2.7842770e-10 5.2744128e-02 9.1006910e-07], sum to 1.0000
[2019-03-26 11:52:38,767] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0302
[2019-03-26 11:52:38,772] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.93333333333334, 81.33333333333333, 1.0, 2.0, 0.5908008915599036, 1.0, 2.0, 0.5908008915599036, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1651833.372700269, 1651833.372700269, 330864.4174310933], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1957200.0000, 
sim time next is 1957800.0000, 
raw observation next is [25.76666666666667, 82.16666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.592170438817478, 6.9112, 168.9094913965396, 1956257.425885736, 1473163.469883434, 314407.8647544161], 
processed observation next is [1.0, 0.6521739130434783, 0.42022116903633505, 0.8216666666666668, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.06809704388174778, 0.0, 0.8294229298567599, 0.5434048405238155, 0.4092120749676206, 0.4692654697827106], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01552797], dtype=float32), 1.2497002]. 
=============================================
[2019-03-26 11:52:38,773] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114838: loss -2.3676
[2019-03-26 11:52:38,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114838: learning rate 0.0001
[2019-03-26 11:52:38,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [6.0634838e-22 1.0000000e+00 2.3757277e-21 3.1374606e-22 1.9531928e-20], sum to 1.0000
[2019-03-26 11:52:38,948] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1603
[2019-03-26 11:52:38,956] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 96.0, 1.0, 2.0, 0.4763922924712487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 665673.8767111677, 665673.8767111677, 179979.8213440143], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [24.58333333333334, 95.83333333333333, 1.0, 2.0, 0.478267751760229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 668295.3233105448, 668295.3233105455, 180261.1107287601], 
processed observation next is [0.0, 0.2608695652173913, 0.3641390205371251, 0.9583333333333333, 1.0, 1.0, 0.37140692983160123, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1856375898084847, 0.18563758980848488, 0.26904643392352257], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.44660535], dtype=float32), -1.1484461]. 
=============================================
[2019-03-26 11:52:45,130] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1117746: loss 16.4890
[2019-03-26 11:52:45,135] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1117746: learning rate 0.0001
[2019-03-26 11:52:45,212] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6009201e-10 2.1546574e-01 1.8600192e-08 7.8452784e-01 6.3717116e-06], sum to 1.0000
[2019-03-26 11:52:45,220] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8274
[2019-03-26 11:52:45,226] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.5, 67.0, 1.0, 2.0, 0.6158407762155087, 1.0, 2.0, 0.6158407762155087, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1721899.189899639, 1721899.189899639, 340181.6593109683], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2206800.0000, 
sim time next is 2207400.0000, 
raw observation next is [31.6, 66.66666666666667, 1.0, 2.0, 0.6782688978827719, 1.0, 2.0, 0.6782688978827719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1896603.547320803, 1896603.547320803, 364964.9569968081], 
processed observation next is [1.0, 0.5652173913043478, 0.6966824644549764, 0.6666666666666667, 1.0, 1.0, 0.6123721661238215, 1.0, 1.0, 0.6123721661238215, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.526834318700223, 0.526834318700223, 0.5447238164131465], 
reward next is 0.4553, 
noisyNet noise sample is [array([0.05293016], dtype=float32), -0.5166139]. 
=============================================
[2019-03-26 11:52:48,021] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1119080: loss 5.9636
[2019-03-26 11:52:48,022] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1119080: learning rate 0.0001
[2019-03-26 11:52:48,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1119397: loss 5.6649
[2019-03-26 11:52:48,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1119397: learning rate 0.0001
[2019-03-26 11:52:50,064] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1120027: loss 14.9845
[2019-03-26 11:52:50,066] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1120027: learning rate 0.0001
[2019-03-26 11:52:51,375] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1120637: loss 5.2026
[2019-03-26 11:52:51,377] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1120637: learning rate 0.0001
[2019-03-26 11:52:51,776] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1357129e-15 1.0000000e+00 1.6017679e-14 5.9642194e-11 4.7060580e-12], sum to 1.0000
[2019-03-26 11:52:51,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1463
[2019-03-26 11:52:51,793] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.23333333333333, 79.33333333333334, 1.0, 2.0, 0.5582713141869784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780127.3244184323, 780127.3244184323, 193229.8405992058], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2230800.0000, 
sim time next is 2231400.0000, 
raw observation next is [29.06666666666666, 80.16666666666666, 1.0, 2.0, 0.5576038116014002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779194.2153856759, 779194.2153856759, 193113.7596043959], 
processed observation next is [1.0, 0.8260869565217391, 0.5766192733017375, 0.8016666666666665, 1.0, 1.0, 0.46699254409807245, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2164428376071322, 0.2164428376071322, 0.28822949194685954], 
reward next is 0.7118, 
noisyNet noise sample is [array([-0.99845445], dtype=float32), 0.47985134]. 
=============================================
[2019-03-26 11:52:52,743] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0451460e-14 9.9998784e-01 7.8858794e-12 1.2116751e-05 3.3153431e-09], sum to 1.0000
[2019-03-26 11:52:52,751] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5001
[2019-03-26 11:52:52,755] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.1, 80.0, 1.0, 2.0, 0.5613385714576048, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 784415.086834244, 784415.086834244, 193764.4831830124], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2325600.0000, 
sim time next is 2326200.0000, 
raw observation next is [29.01666666666667, 80.16666666666667, 1.0, 2.0, 0.5599498469338116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 782473.7669935346, 782473.7669935353, 193521.8926222118], 
processed observation next is [1.0, 0.9565217391304348, 0.5742496050552924, 0.8016666666666667, 1.0, 1.0, 0.4698190926913392, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21735382416487073, 0.21735382416487092, 0.28883864570479373], 
reward next is 0.7112, 
noisyNet noise sample is [array([-0.6031265], dtype=float32), -0.84615004]. 
=============================================
[2019-03-26 11:52:52,962] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.7219212e-17 7.6120664e-13 7.3165623e-12 1.0000000e+00 4.9730895e-09], sum to 1.0000
[2019-03-26 11:52:52,970] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0935
[2019-03-26 11:52:52,977] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.5, 71.5, 1.0, 2.0, 0.6997570664017484, 1.0, 2.0, 0.6997570664017484, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1956744.522487693, 1956744.522487693, 374023.7684413011], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2201400.0000, 
sim time next is 2202000.0000, 
raw observation next is [30.6, 71.0, 1.0, 2.0, 0.7327671429376258, 1.0, 2.0, 0.7327671429376258, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2049139.531601125, 2049139.531601125, 388470.0609971031], 
processed observation next is [1.0, 0.4782608695652174, 0.6492890995260664, 0.71, 1.0, 1.0, 0.6780327023344889, 1.0, 1.0, 0.6780327023344889, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5692054254447569, 0.5692054254447569, 0.5798060611897061], 
reward next is 0.4202, 
noisyNet noise sample is [array([0.08771583], dtype=float32), 0.4873619]. 
=============================================
[2019-03-26 11:52:52,999] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[52.803997]
 [52.165535]
 [51.79944 ]
 [51.28749 ]
 [51.50509 ]], R is [[52.45664215]
 [52.3738327 ]
 [52.27074051]
 [52.15823746]
 [52.01789856]].
[2019-03-26 11:52:53,193] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1121472: loss 5.0794
[2019-03-26 11:52:53,197] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1121472: learning rate 0.0001
[2019-03-26 11:52:54,050] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1121870: loss 5.2831
[2019-03-26 11:52:54,060] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1121874: learning rate 0.0001
[2019-03-26 11:52:54,868] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122208: loss 5.5231
[2019-03-26 11:52:54,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122209: learning rate 0.0001
[2019-03-26 11:52:55,306] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1122405: loss 5.7330
[2019-03-26 11:52:55,309] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1122407: learning rate 0.0001
[2019-03-26 11:52:55,411] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1122462: loss 13.5983
[2019-03-26 11:52:55,414] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1122463: learning rate 0.0001
[2019-03-26 11:52:55,743] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1122611: loss 5.7412
[2019-03-26 11:52:55,746] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1122613: learning rate 0.0001
[2019-03-26 11:52:55,935] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1122701: loss 5.4393
[2019-03-26 11:52:55,938] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1122701: learning rate 0.0001
[2019-03-26 11:52:55,982] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1122717: loss 5.5998
[2019-03-26 11:52:55,986] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1122718: learning rate 0.0001
[2019-03-26 11:52:56,134] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1122790: loss 5.6060
[2019-03-26 11:52:56,136] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1122790: learning rate 0.0001
[2019-03-26 11:52:56,153] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1122796: loss 5.3705
[2019-03-26 11:52:56,154] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1122796: learning rate 0.0001
[2019-03-26 11:52:56,246] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122839: loss 5.3366
[2019-03-26 11:52:56,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122839: learning rate 0.0001
[2019-03-26 11:52:56,934] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [8.22544866e-10 4.31554496e-01 3.76002305e-07 5.68334460e-01
 1.10635985e-04], sum to 1.0000
[2019-03-26 11:52:56,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6997
[2019-03-26 11:52:56,950] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 72.0, 1.0, 2.0, 0.7701609500371259, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.977583935344518, 6.9112, 168.9119908363926, 1973313.344982142, 1926218.565732034, 401598.9140287075], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2277000.0000, 
sim time next is 2277600.0000, 
raw observation next is [29.4, 71.33333333333333, 1.0, 2.0, 0.5878398519148471, 1.0, 1.0, 0.5878398519148471, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1643548.187635473, 1643548.187635473, 329800.8884522849], 
processed observation next is [1.0, 0.34782608695652173, 0.5924170616113744, 0.7133333333333333, 1.0, 1.0, 0.5034215083311411, 1.0, 0.5, 0.5034215083311411, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45654116323207583, 0.45654116323207583, 0.49224013201833566], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1490097], dtype=float32), -0.43069667]. 
=============================================
[2019-03-26 11:52:57,801] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3370204e-14 9.9986613e-01 1.7928846e-11 1.3384791e-04 3.9131418e-09], sum to 1.0000
[2019-03-26 11:52:57,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4800
[2019-03-26 11:52:57,816] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.13333333333333, 81.0, 1.0, 2.0, 0.535701711687252, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 748577.4894066376, 748577.489406637, 189378.745355205], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2335800.0000, 
sim time next is 2336400.0000, 
raw observation next is [28.1, 81.0, 1.0, 2.0, 0.5344076175475718, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746768.5157886085, 746768.5157886085, 189162.5425645207], 
processed observation next is [1.0, 0.043478260869565216, 0.5308056872037916, 0.81, 1.0, 1.0, 0.43904532234647203, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20743569883016902, 0.20743569883016902, 0.28233215308137416], 
reward next is 0.7177, 
noisyNet noise sample is [array([1.1517797], dtype=float32), 0.095550515]. 
=============================================
[2019-03-26 11:53:00,769] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 11:53:00,773] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:53:00,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:53:00,774] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:53:00,775] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:53:00,775] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:53:00,777] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:53:00,777] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:53:00,776] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:53:00,780] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:53:00,782] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:53:00,795] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-26 11:53:00,818] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-26 11:53:00,819] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-26 11:53:00,839] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-26 11:53:00,858] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-26 11:53:40,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34121776], dtype=float32), 0.10631806]
[2019-03-26 11:53:40,009] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.4, 86.0, 1.0, 2.0, 0.5078105219803178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 709589.9522173873, 709589.9522173873, 184828.3220821704]
[2019-03-26 11:53:40,012] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:53:40,014] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9588931e-22 1.0000000e+00 3.4378831e-22 3.7892960e-22 3.0415708e-21], sampled 0.9168789308009624
[2019-03-26 11:53:54,698] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.34121776], dtype=float32), 0.10631806]
[2019-03-26 11:53:54,699] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.13333333333334, 62.33333333333334, 1.0, 2.0, 0.5610334981850477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 783988.6198070841, 783988.6198070834, 193710.7564236449]
[2019-03-26 11:53:54,700] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:53:54,705] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.04606561e-18 1.00000000e+00 1.42165454e-16 1.21865565e-11
 3.38761828e-15], sampled 0.740656733317246
[2019-03-26 11:54:09,534] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.34121776], dtype=float32), 0.10631806]
[2019-03-26 11:54:09,535] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.73890229333333, 73.56294404166667, 1.0, 2.0, 0.4652380296227373, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 676743.072698032, 676743.072698032, 181711.2614394125]
[2019-03-26 11:54:09,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:54:09,540] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.1671915e-18 1.0000000e+00 8.6867166e-18 1.0214158e-13 2.3618272e-16], sampled 0.9592681291421681
[2019-03-26 11:54:39,095] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.34121776], dtype=float32), 0.10631806]
[2019-03-26 11:54:39,097] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.16666666666666, 72.0, 1.0, 2.0, 0.5233238836344907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 731275.0378983855, 731275.0378983861, 187330.8146423479]
[2019-03-26 11:54:39,098] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:54:39,101] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5272838e-18 1.0000000e+00 3.2180406e-17 7.1630375e-13 5.8468048e-16], sampled 0.5218028106293187
[2019-03-26 11:54:55,481] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8602.5031 2903825144.9619 601.0000
[2019-03-26 11:54:55,732] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8863.1990 2765224275.8960 502.0000
[2019-03-26 11:54:55,768] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8775.0676 2821626548.9238 492.0000
[2019-03-26 11:54:55,786] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8327.3030 3125234843.5443 664.0000
[2019-03-26 11:54:55,832] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8545.1075 2963913587.7592 541.0000
[2019-03-26 11:54:56,847] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1125000, evaluation results [1125000.0, 8327.302995884938, 3125234843.544305, 664.0, 8602.503145637173, 2903825144.961902, 601.0, 8863.199024094843, 2765224275.896019, 502.0, 8545.107475887113, 2963913587.759184, 541.0, 8775.067555053985, 2821626548.9237537, 492.0]
[2019-03-26 11:54:58,381] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1125697: loss 0.0283
[2019-03-26 11:54:58,383] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1125697: learning rate 0.0001
[2019-03-26 11:55:01,537] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1127118: loss -35.7429
[2019-03-26 11:55:01,539] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1127118: learning rate 0.0001
[2019-03-26 11:55:02,206] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1127419: loss -32.1385
[2019-03-26 11:55:02,210] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1127421: learning rate 0.0001
[2019-03-26 11:55:02,528] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7309461e-22 1.0000000e+00 9.4564879e-21 3.6902580e-19 2.4620401e-21], sum to 1.0000
[2019-03-26 11:55:02,538] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1638
[2019-03-26 11:55:02,542] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3812954273964836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 573988.3278223346, 573988.3278223339, 172329.3308357447], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2750400.0000, 
sim time next is 2751000.0000, 
raw observation next is [22.0, 99.00000000000001, 1.0, 2.0, 0.3778508458407415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 570630.7573937539, 570630.7573937539, 172089.1806005195], 
processed observation next is [0.0, 0.8695652173913043, 0.2417061611374408, 0.9900000000000001, 1.0, 1.0, 0.2504227058322187, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15850854372048717, 0.15850854372048717, 0.25684952328435745], 
reward next is 0.7432, 
noisyNet noise sample is [array([-0.8872677], dtype=float32), -0.08672595]. 
=============================================
[2019-03-26 11:55:02,555] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.36078 ]
 [77.22227 ]
 [77.153824]
 [77.07655 ]
 [77.016266]], R is [[77.37899017]
 [77.34799194]
 [77.31708527]
 [77.28619385]
 [77.25528717]].
[2019-03-26 11:55:03,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1932458e-20 1.0000000e+00 1.2096706e-18 1.6942492e-17 1.3468057e-18], sum to 1.0000
[2019-03-26 11:55:03,558] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8159
[2019-03-26 11:55:03,570] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.3479686845064236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 536037.1310052006, 536037.1310052006, 169491.6814487811], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2767200.0000, 
sim time next is 2767800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3482858314377635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 536525.5723650093, 536525.57236501, 169531.6095425041], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.94, 1.0, 1.0, 0.21480220655152227, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1490348812125026, 0.1490348812125028, 0.25303225304851357], 
reward next is 0.7470, 
noisyNet noise sample is [array([-1.7596371], dtype=float32), 0.54763675]. 
=============================================
[2019-03-26 11:55:03,679] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1128048: loss 0.1097
[2019-03-26 11:55:03,681] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1128049: learning rate 0.0001
[2019-03-26 11:55:04,930] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.2395107e-20 1.0000000e+00 2.1965293e-19 4.7946393e-20 4.5238828e-19], sum to 1.0000
[2019-03-26 11:55:04,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6421
[2019-03-26 11:55:04,946] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3761291680270729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 579419.5824085322, 579419.5824085322, 173170.0991402411], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2790600.0000, 
sim time next is 2791200.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3665892650802927, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 564709.399389607, 564709.399389607, 171892.6060205585], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 1.0, 1.0, 0.23685453624131653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1568637220526686, 0.1568637220526686, 0.2565561283888933], 
reward next is 0.7434, 
noisyNet noise sample is [array([-1.3268816], dtype=float32), 1.5859128]. 
=============================================
[2019-03-26 11:55:04,968] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1128636: loss -39.5168
[2019-03-26 11:55:04,972] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1128637: learning rate 0.0001
[2019-03-26 11:55:06,803] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1129460: loss -13.9368
[2019-03-26 11:55:06,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1129460: learning rate 0.0001
[2019-03-26 11:55:07,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8970062e-13 1.8969437e-04 9.3624379e-09 9.9980992e-01 3.4118895e-07], sum to 1.0000
[2019-03-26 11:55:07,098] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-26 11:55:07,104] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.68333333333333, 84.83333333333333, 1.0, 2.0, 0.7429646854199574, 1.0, 2.0, 0.7429646854199574, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2077684.003915774, 2077684.003915773, 393057.8830517399], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2541000.0000, 
sim time next is 2541600.0000, 
raw observation next is [27.8, 84.0, 1.0, 2.0, 0.7158471444278142, 1.0, 2.0, 0.7158471444278142, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2001779.560337878, 2001779.560337878, 380981.0012979966], 
processed observation next is [1.0, 0.43478260869565216, 0.5165876777251186, 0.84, 1.0, 1.0, 0.6576471619612219, 1.0, 1.0, 0.6576471619612219, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5560498778716328, 0.5560498778716328, 0.5686283601462636], 
reward next is 0.4314, 
noisyNet noise sample is [array([-0.68431634], dtype=float32), 2.2004058]. 
=============================================
[2019-03-26 11:55:07,466] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.1592926e-17 1.0000000e+00 4.3888253e-14 2.9433810e-12 9.2284626e-14], sum to 1.0000
[2019-03-26 11:55:07,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-26 11:55:07,482] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.3, 96.0, 1.0, 2.0, 0.7202641454632446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1006603.086568345, 1006603.086568346, 225280.8807705682], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2517000.0000, 
sim time next is 2517600.0000, 
raw observation next is [26.3, 96.0, 1.0, 2.0, 0.691170751088145, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 965925.2059823722, 965925.2059823722, 218951.8724617126], 
processed observation next is [1.0, 0.13043478260869565, 0.4454976303317536, 0.96, 1.0, 1.0, 0.6279165675760783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2683125572173256, 0.2683125572173256, 0.32679383949509344], 
reward next is 0.6732, 
noisyNet noise sample is [array([-0.77673125], dtype=float32), -0.6076442]. 
=============================================
[2019-03-26 11:55:07,938] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1129965: loss -40.6864
[2019-03-26 11:55:07,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1129966: learning rate 0.0001
[2019-03-26 11:55:08,634] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130285: loss -25.8944
[2019-03-26 11:55:08,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130285: learning rate 0.0001
[2019-03-26 11:55:08,799] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1130358: loss 0.0539
[2019-03-26 11:55:08,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1130358: learning rate 0.0001
[2019-03-26 11:55:08,937] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1130415: loss -47.6344
[2019-03-26 11:55:08,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1130417: learning rate 0.0001
[2019-03-26 11:55:09,377] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1130618: loss 23.8119
[2019-03-26 11:55:09,384] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1130618: learning rate 0.0001
[2019-03-26 11:55:09,661] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1130756: loss -74.0969
[2019-03-26 11:55:09,664] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1130756: learning rate 0.0001
[2019-03-26 11:55:09,691] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1130769: loss -28.1596
[2019-03-26 11:55:09,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1130769: learning rate 0.0001
[2019-03-26 11:55:09,744] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1130791: loss -30.8019
[2019-03-26 11:55:09,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1130792: learning rate 0.0001
[2019-03-26 11:55:09,787] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1130807: loss -54.5752
[2019-03-26 11:55:09,789] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1130808: learning rate 0.0001
[2019-03-26 11:55:09,945] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130869: loss -46.4645
[2019-03-26 11:55:09,948] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130869: learning rate 0.0001
[2019-03-26 11:55:11,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.07564035e-26 1.00000000e+00 1.65858896e-28 1.10853020e-30
 1.58822574e-27], sum to 1.0000
[2019-03-26 11:55:11,216] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5030
[2019-03-26 11:55:11,224] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 100.0, 1.0, 2.0, 0.409181697380103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 174749.847841923], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2716200.0000, 
sim time next is 2716800.0000, 
raw observation next is [22.33333333333334, 100.0, 1.0, 2.0, 0.4027813427192451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 598459.2025114512, 598459.2025114506, 174321.1179528341], 
processed observation next is [0.0, 0.43478260869565216, 0.2575039494470777, 1.0, 1.0, 1.0, 0.28045944905933146, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.166238667364292, 0.16623866736429185, 0.26018077306393145], 
reward next is 0.7398, 
noisyNet noise sample is [array([-0.5655732], dtype=float32), -0.27423394]. 
=============================================
[2019-03-26 11:55:15,964] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1133580: loss 10.2652
[2019-03-26 11:55:15,968] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1133580: learning rate 0.0001
[2019-03-26 11:55:17,595] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.3172471e-26 1.0000000e+00 1.7370280e-26 7.0298766e-29 1.2810980e-25], sum to 1.0000
[2019-03-26 11:55:17,609] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0765
[2019-03-26 11:55:17,613] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3841677938209312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 578629.998411667, 578629.998411667, 172752.6128654845], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2722200.0000, 
sim time next is 2722800.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3846842565863893, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 579408.028672534, 579408.0286725335, 172822.2291624052], 
processed observation next is [0.0, 0.5217391304347826, 0.2417061611374408, 1.0, 1.0, 1.0, 0.258655730826975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16094667463125945, 0.1609466746312593, 0.25794362561553014], 
reward next is 0.7421, 
noisyNet noise sample is [array([-1.2475408], dtype=float32), -0.2297325]. 
=============================================
[2019-03-26 11:55:19,269] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1135064: loss 0.0903
[2019-03-26 11:55:19,271] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1135064: learning rate 0.0001
[2019-03-26 11:55:19,848] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1135338: loss 0.0853
[2019-03-26 11:55:19,854] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1135339: learning rate 0.0001
[2019-03-26 11:55:21,225] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1135969: loss 10.3166
[2019-03-26 11:55:21,228] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1135969: learning rate 0.0001
[2019-03-26 11:55:22,672] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1136635: loss 0.0522
[2019-03-26 11:55:22,674] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1136635: learning rate 0.0001
[2019-03-26 11:55:24,329] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1137398: loss 0.2011
[2019-03-26 11:55:24,331] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1137399: learning rate 0.0001
[2019-03-26 11:55:25,300] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1137856: loss 0.0893
[2019-03-26 11:55:25,302] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1137856: learning rate 0.0001
[2019-03-26 11:55:26,251] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1138297: loss 9.8549
[2019-03-26 11:55:26,253] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1138297: learning rate 0.0001
[2019-03-26 11:55:26,286] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138314: loss 0.1460
[2019-03-26 11:55:26,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138314: learning rate 0.0001
[2019-03-26 11:55:26,475] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1138401: loss 0.2387
[2019-03-26 11:55:26,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1138401: learning rate 0.0001
[2019-03-26 11:55:27,113] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1138695: loss 0.2384
[2019-03-26 11:55:27,122] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1138696: learning rate 0.0001
[2019-03-26 11:55:27,194] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138732: loss 0.1522
[2019-03-26 11:55:27,195] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138732: learning rate 0.0001
[2019-03-26 11:55:27,225] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1138744: loss 0.1444
[2019-03-26 11:55:27,226] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1138744: learning rate 0.0001
[2019-03-26 11:55:27,344] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1138803: loss 0.1323
[2019-03-26 11:55:27,345] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1138803: learning rate 0.0001
[2019-03-26 11:55:27,612] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1138923: loss 0.0639
[2019-03-26 11:55:27,616] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1138925: learning rate 0.0001
[2019-03-26 11:55:27,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3806630e-21 1.0000000e+00 4.2087334e-20 2.7666286e-19 6.7547969e-20], sum to 1.0000
[2019-03-26 11:55:27,656] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2875
[2019-03-26 11:55:27,661] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 91.5, 1.0, 2.0, 0.527734823461151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 796695.6009873647, 796695.6009873652, 195321.1992612997], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2896200.0000, 
sim time next is 2896800.0000, 
raw observation next is [23.0, 92.33333333333334, 1.0, 2.0, 0.516654771935371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 777291.1511361116, 777291.1511361116, 193052.4794744494], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.9233333333333335, 1.0, 1.0, 0.41765635172936266, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2159142086489199, 0.2159142086489199, 0.2881380290663424], 
reward next is 0.7119, 
noisyNet noise sample is [array([1.1347107], dtype=float32), -2.6255624]. 
=============================================
[2019-03-26 11:55:27,732] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138978: loss 0.0916
[2019-03-26 11:55:27,735] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138979: learning rate 0.0001
[2019-03-26 11:55:30,671] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.8036727e-22 1.0000000e+00 9.9312807e-21 2.0263482e-20 1.3344494e-19], sum to 1.0000
[2019-03-26 11:55:30,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5618
[2019-03-26 11:55:30,687] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.5458538625052386, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 862938.1936454087, 862938.1936454081, 202589.1821842346], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2994600.0000, 
sim time next is 2995200.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.5993207983065164, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 947479.7354895928, 947479.7354895921, 213367.7240488339], 
processed observation next is [1.0, 0.6956521739130435, 0.19431279620853087, 0.94, 1.0, 1.0, 0.5172539738632728, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26318881541377576, 0.2631888154137756, 0.3184592896251252], 
reward next is 0.6815, 
noisyNet noise sample is [array([-2.598821], dtype=float32), 1.4691927]. 
=============================================
[2019-03-26 11:55:32,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0853316e-24 1.0000000e+00 2.3937361e-24 5.0824190e-27 5.2270444e-24], sum to 1.0000
[2019-03-26 11:55:32,770] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7282
[2019-03-26 11:55:32,777] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.0, 1.0, 2.0, 0.309942844654496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 490120.9203563386, 490120.9203563379, 166292.8501386649], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2951400.0000, 
sim time next is 2952000.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.309755161853096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 489824.2734502368, 489824.2734502368, 166271.065492433], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 1.0, 1.0, 0.16837971307601926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13606229818062135, 0.13606229818062135, 0.24816576939169105], 
reward next is 0.7518, 
noisyNet noise sample is [array([0.32867512], dtype=float32), -0.6623497]. 
=============================================
[2019-03-26 11:55:32,797] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.5924 ]
 [74.63062]
 [74.70405]
 [74.79601]
 [74.99825]], R is [[74.6938324 ]
 [74.69869232]
 [74.70343781]
 [74.70814514]
 [74.71318817]].
[2019-03-26 11:55:33,798] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1141776: loss 6.2235
[2019-03-26 11:55:33,800] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1141776: learning rate 0.0001
[2019-03-26 11:55:36,440] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.5456483e-25 1.0000000e+00 9.8601411e-25 7.7253361e-24 1.0575326e-23], sum to 1.0000
[2019-03-26 11:55:36,443] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8060
[2019-03-26 11:55:36,449] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.0, 100.0, 1.0, 2.0, 0.304628873137007, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485103.6508356546, 485103.6508356546, 165988.9401123832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3015600.0000, 
sim time next is 3016200.0000, 
raw observation next is [20.0, 100.0, 1.0, 2.0, 0.3051706029095784, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 485966.2386615312, 485966.2386615312, 166051.3320179218], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 1.0, 1.0, 1.0, 0.16285614808382942, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13499062185042532, 0.13499062185042532, 0.24783780898197286], 
reward next is 0.7522, 
noisyNet noise sample is [array([-1.0064265], dtype=float32), 1.3721709]. 
=============================================
[2019-03-26 11:55:36,651] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1143101: loss 9.6605
[2019-03-26 11:55:36,655] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1143102: learning rate 0.0001
[2019-03-26 11:55:37,069] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1143293: loss 9.9624
[2019-03-26 11:55:37,074] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1143294: learning rate 0.0001
[2019-03-26 11:55:37,976] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1391625e-23 1.0000000e+00 7.2767736e-23 5.4694623e-23 6.0492953e-23], sum to 1.0000
[2019-03-26 11:55:37,982] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1371
[2019-03-26 11:55:37,995] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 82.33333333333334, 1.0, 2.0, 0.5256096394887132, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 734470.1798115391, 734470.1798115385, 187705.8302518916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3360000.0000, 
sim time next is 3360600.0000, 
raw observation next is [27.5, 84.0, 1.0, 2.0, 0.5275971288506445, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 737248.39796888, 737248.3979688807, 188032.9957858825], 
processed observation next is [0.0, 0.9130434782608695, 0.5023696682464456, 0.84, 1.0, 1.0, 0.4308399142778849, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20479122165802222, 0.2047912216580224, 0.2806462623669888], 
reward next is 0.7194, 
noisyNet noise sample is [array([-0.26949233], dtype=float32), -0.8098465]. 
=============================================
[2019-03-26 11:55:38,919] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1144064: loss 5.7210
[2019-03-26 11:55:38,922] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1144064: learning rate 0.0001
[2019-03-26 11:55:39,980] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1144560: loss 10.6933
[2019-03-26 11:55:39,983] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1144560: learning rate 0.0001
[2019-03-26 11:55:41,801] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1145400: loss 10.1655
[2019-03-26 11:55:41,805] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1145400: learning rate 0.0001
[2019-03-26 11:55:42,888] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1145899: loss 11.0183
[2019-03-26 11:55:42,890] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1145899: learning rate 0.0001
[2019-03-26 11:55:43,573] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146212: loss 10.8517
[2019-03-26 11:55:43,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146212: learning rate 0.0001
[2019-03-26 11:55:43,878] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1146348: loss 5.0737
[2019-03-26 11:55:43,882] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1146348: learning rate 0.0001
[2019-03-26 11:55:43,892] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1146354: loss 10.5562
[2019-03-26 11:55:43,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1146355: learning rate 0.0001
[2019-03-26 11:55:44,413] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1146603: loss 11.0380
[2019-03-26 11:55:44,415] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1146603: learning rate 0.0001
[2019-03-26 11:55:44,587] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1146683: loss 11.0886
[2019-03-26 11:55:44,592] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1146683: learning rate 0.0001
[2019-03-26 11:55:44,610] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1146693: loss 11.1501
[2019-03-26 11:55:44,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1146694: learning rate 0.0001
[2019-03-26 11:55:44,710] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146738: loss 11.3214
[2019-03-26 11:55:44,713] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146739: learning rate 0.0001
[2019-03-26 11:55:44,966] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1146860: loss 11.2207
[2019-03-26 11:55:44,969] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1146860: learning rate 0.0001
[2019-03-26 11:55:45,009] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146874: loss 11.1143
[2019-03-26 11:55:45,015] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146876: learning rate 0.0001
[2019-03-26 11:55:51,760] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-26 11:55:51,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:55:51,762] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:55:51,764] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:55:51,765] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1150000: loss 4.9043
[2019-03-26 11:55:51,767] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1150000: learning rate 0.0001
[2019-03-26 11:55:51,769] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:55:51,770] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:55:51,770] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:55:51,771] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:55:51,772] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:55:51,773] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:55:51,773] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:55:51,801] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-26 11:55:51,820] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-26 11:55:51,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-26 11:55:51,869] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-26 11:55:51,888] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-26 11:55:57,387] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:55:57,389] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.89503451666667, 87.08353895333333, 1.0, 2.0, 0.3031984358795841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 481223.1338028054, 481223.1338028054, 165682.462692441]
[2019-03-26 11:55:57,389] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:55:57,391] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6947797e-25 1.0000000e+00 5.7744963e-25 4.3321918e-27 3.2892944e-24], sampled 0.12000118123371428
[2019-03-26 11:56:03,335] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:03,336] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.73836408, 75.23726520666666, 1.0, 2.0, 0.2702351157040425, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 442112.0578571876, 442112.0578571882, 162958.7851888743]
[2019-03-26 11:56:03,337] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:56:03,339] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.6192401e-25 1.0000000e+00 5.8422743e-25 1.4490502e-27 2.9783937e-24], sampled 0.933938104628075
[2019-03-26 11:56:08,661] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:08,662] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 67.5, 1.0, 2.0, 0.7703337635636975, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1179546.461599536, 1179546.461599536, 250196.8001682638]
[2019-03-26 11:56:08,667] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:56:08,670] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.2173452e-22 1.0000000e+00 1.1936844e-21 2.0939805e-23 3.4526722e-20], sampled 0.4759502560168345
[2019-03-26 11:56:10,864] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:10,868] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.86666666666667, 48.66666666666667, 1.0, 2.0, 0.289633149338981, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 474859.5319223051, 474859.5319223044, 165083.4154468953]
[2019-03-26 11:56:10,868] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 11:56:10,870] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5766726e-26 1.0000000e+00 2.4316044e-27 5.2315511e-32 7.8012258e-27], sampled 0.6172209770338486
[2019-03-26 11:56:32,803] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:32,804] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.66746608333333, 87.49665469333334, 1.0, 2.0, 0.3283851581490884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520702.0233573543, 520702.0233573536, 168624.3501570859]
[2019-03-26 11:56:32,805] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:56:32,808] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3042331e-25 1.0000000e+00 4.4840604e-25 3.4302503e-27 5.1123137e-24], sampled 0.9953344722690691
[2019-03-26 11:56:35,392] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:35,392] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.65357601166667, 98.89422487166668, 1.0, 2.0, 0.3172650799310637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 508388.5883127149, 508388.5883127155, 167728.427689134]
[2019-03-26 11:56:35,393] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 11:56:35,396] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1061319e-26 1.0000000e+00 1.2276469e-26 2.1485340e-30 7.2128116e-26], sampled 0.48245551725483693
[2019-03-26 11:56:46,169] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:56:46,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.81987091666667, 68.66555419333334, 1.0, 2.0, 0.732844528049885, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1024193.24237363, 1024193.24237363, 228095.8824389385]
[2019-03-26 11:56:46,171] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 11:56:46,173] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5324516e-25 1.0000000e+00 7.4862167e-26 6.6934582e-30 2.3024024e-24], sampled 0.6723876688987241
[2019-03-26 11:57:05,582] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:57:05,582] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.96666666666667, 73.66666666666667, 1.0, 2.0, 0.6379421256995631, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 891505.8957998027, 891505.8957998034, 208027.1656575155]
[2019-03-26 11:57:05,583] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:57:05,585] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.6454758e-24 1.0000000e+00 1.2778097e-23 2.1086797e-25 2.4334387e-22], sampled 0.608504719450943
[2019-03-26 11:57:44,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.33719856], dtype=float32), 0.105592325]
[2019-03-26 11:57:44,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.63333333333333, 87.33333333333334, 1.0, 2.0, 0.7982269042739804, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1115616.949915154, 1115616.949915153, 243479.8556068726]
[2019-03-26 11:57:44,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 11:57:44,116] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.7087167e-23 1.0000000e+00 6.8333372e-24 9.7998334e-27 3.7400097e-22], sampled 0.6021365055102454
[2019-03-26 11:57:46,947] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7903.2054 3162876058.9388 1742.0000
[2019-03-26 11:57:47,128] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8664.9449 2778970020.4718 924.0000
[2019-03-26 11:57:47,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8258.0769 2927095057.4997 1332.0000
[2019-03-26 11:57:47,248] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8003.7970 3007158950.9285 1758.0000
[2019-03-26 11:57:47,299] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8501.4155 2842330641.4002 1122.0000
[2019-03-26 11:57:48,317] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1150000, evaluation results [1150000.0, 7903.205370353313, 3162876058.938765, 1742.0, 8258.076940282052, 2927095057.4996905, 1332.0, 8664.944934400699, 2778970020.471791, 924.0, 8003.79704503708, 3007158950.9284787, 1758.0, 8501.415500232024, 2842330641.4002194, 1122.0]
[2019-03-26 11:57:50,820] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1151145: loss 4.5512
[2019-03-26 11:57:50,822] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1151145: learning rate 0.0001
[2019-03-26 11:57:51,216] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1151322: loss 4.6701
[2019-03-26 11:57:51,222] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1151324: learning rate 0.0001
[2019-03-26 11:57:51,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.9841169e-21 1.0000000e+00 1.6393867e-18 6.4541050e-21 2.5711028e-17], sum to 1.0000
[2019-03-26 11:57:51,481] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7531
[2019-03-26 11:57:51,486] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.7239280371469882, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1011725.986990375, 1011725.986990374, 226091.4214379836], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3466800.0000, 
sim time next is 3467400.0000, 
raw observation next is [27.0, 79.00000000000001, 1.0, 2.0, 0.7126459838344051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 995951.3542207689, 995951.3542207689, 223595.1156155694], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.7900000000000001, 1.0, 1.0, 0.6537903419691627, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.27665315395021356, 0.27665315395021356, 0.33372405315756626], 
reward next is 0.6663, 
noisyNet noise sample is [array([0.88873607], dtype=float32), -0.31750455]. 
=============================================
[2019-03-26 11:57:52,756] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5537329e-19 1.0000000e+00 6.7857891e-20 1.4204443e-18 3.8340900e-17], sum to 1.0000
[2019-03-26 11:57:52,765] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2262
[2019-03-26 11:57:52,769] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5191847671936283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 725489.2018950442, 725489.2018950435, 186660.2055763614], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5296032490179703, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740052.6666240442, 740052.6666240436, 188367.2146083275], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.433256926527675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2055701851733456, 0.20557018517334544, 0.2811450964303395], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.05114063], dtype=float32), 1.3425707]. 
=============================================
[2019-03-26 11:57:53,501] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1152344: loss -12.2371
[2019-03-26 11:57:53,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1152345: learning rate 0.0001
[2019-03-26 11:57:54,008] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1152570: loss 4.8175
[2019-03-26 11:57:54,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1152572: learning rate 0.0001
[2019-03-26 11:57:55,953] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1153453: loss 4.2587
[2019-03-26 11:57:55,954] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1153454: learning rate 0.0001
[2019-03-26 11:57:56,813] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1153837: loss 4.3233
[2019-03-26 11:57:56,813] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1153837: learning rate 0.0001
[2019-03-26 11:57:57,496] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154145: loss 4.8426
[2019-03-26 11:57:57,497] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154145: learning rate 0.0001
[2019-03-26 11:57:57,914] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1154328: loss 4.6094
[2019-03-26 11:57:57,917] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1154328: learning rate 0.0001
[2019-03-26 11:57:58,319] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1154511: loss -23.3798
[2019-03-26 11:57:58,323] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1154512: learning rate 0.0001
[2019-03-26 11:57:58,438] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1154564: loss 4.3553
[2019-03-26 11:57:58,441] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1154564: learning rate 0.0001
[2019-03-26 11:57:58,507] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1154591: loss 4.6054
[2019-03-26 11:57:58,511] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1154593: learning rate 0.0001
[2019-03-26 11:57:58,692] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.3910074e-23 1.0000000e+00 1.2781949e-23 2.7133133e-27 1.4123428e-21], sum to 1.0000
[2019-03-26 11:57:58,704] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4886
[2019-03-26 11:57:58,709] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.6365150962584207, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 889510.8278179949, 889510.8278179955, 207735.5091796269], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3476400.0000, 
sim time next is 3477000.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.6314400152950168, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 882415.6075562012, 882415.6075562018, 206739.2901925117], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.79, 1.0, 1.0, 0.5559518256566467, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2451154465433892, 0.24511544654338938, 0.30856610476494284], 
reward next is 0.6914, 
noisyNet noise sample is [array([-0.11296901], dtype=float32), -1.3934631]. 
=============================================
[2019-03-26 11:57:58,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[63.479336]
 [63.378647]
 [63.35829 ]
 [63.02522 ]
 [63.51316 ]], R is [[63.61001587]
 [63.66386032]
 [63.71605301]
 [63.77319717]
 [63.80918121]].
[2019-03-26 11:57:58,780] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1154711: loss 4.5596
[2019-03-26 11:57:58,784] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1154711: learning rate 0.0001
[2019-03-26 11:57:58,823] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154731: loss 4.5687
[2019-03-26 11:57:58,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154731: learning rate 0.0001
[2019-03-26 11:57:59,053] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1154829: loss 4.9614
[2019-03-26 11:57:59,055] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1154829: learning rate 0.0001
[2019-03-26 11:57:59,074] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154841: loss 4.8360
[2019-03-26 11:57:59,075] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154841: learning rate 0.0001
[2019-03-26 11:58:03,438] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.6783094e-26 1.0000000e+00 3.4686468e-27 1.7552998e-33 3.6155609e-24], sum to 1.0000
[2019-03-26 11:58:03,447] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8283
[2019-03-26 11:58:03,451] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.5552167309940984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 775857.2964768948, 775857.2964768953, 192699.7982324186], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3526200.0000, 
sim time next is 3526800.0000, 
raw observation next is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5547762969872104, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 775241.6114318797, 775241.611431879, 192623.499144762], 
processed observation next is [1.0, 0.8260869565217391, 0.5892575039494474, 0.7766666666666667, 1.0, 1.0, 0.4635858999845909, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21534489206441101, 0.21534489206441082, 0.2874977599175552], 
reward next is 0.7125, 
noisyNet noise sample is [array([-0.3020267], dtype=float32), -0.46635285]. 
=============================================
[2019-03-26 11:58:05,936] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1157903: loss 0.0294
[2019-03-26 11:58:05,938] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1157904: learning rate 0.0001
[2019-03-26 11:58:06,686] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.49513471e-12 9.99927282e-01 3.32093930e-09 1.35402615e-05
 5.91118878e-05], sum to 1.0000
[2019-03-26 11:58:06,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9601
[2019-03-26 11:58:06,700] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1790858.446522013 W.
[2019-03-26 11:58:06,706] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.6404836034039337, 1.0, 2.0, 0.6404836034039337, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1790858.446522013, 1790858.446522012, 349694.5425752212], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3586800.0000, 
sim time next is 3587400.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5733873140902773, 1.0, 2.0, 0.5733873140902773, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1603109.948736498, 1603109.948736497, 324639.1232480456], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4860088121569606, 1.0, 1.0, 0.4860088121569606, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4453083190934716, 0.4453083190934714, 0.48453600484782927], 
reward next is 0.5155, 
noisyNet noise sample is [array([-1.6742977], dtype=float32), 0.024672957]. 
=============================================
[2019-03-26 11:58:08,735] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1159203: loss -260.1544
[2019-03-26 11:58:08,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1159203: learning rate 0.0001
[2019-03-26 11:58:09,176] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1159404: loss -38.5896
[2019-03-26 11:58:09,181] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1159404: learning rate 0.0001
[2019-03-26 11:58:10,681] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1160110: loss 0.0318
[2019-03-26 11:58:10,686] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1160112: learning rate 0.0001
[2019-03-26 11:58:10,904] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.3259351e-30 1.0000000e+00 2.2106946e-33 0.0000000e+00 1.0429272e-28], sum to 1.0000
[2019-03-26 11:58:10,912] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7008
[2019-03-26 11:58:10,916] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 0.5542721353531355, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 774536.8416353217, 774536.8416353212, 192536.3966542327], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3789600.0000, 
sim time next is 3790200.0000, 
raw observation next is [29.16666666666667, 78.33333333333334, 1.0, 2.0, 0.5521197630675306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771528.0360784814, 771528.0360784814, 192165.2362340161], 
processed observation next is [1.0, 0.8695652173913043, 0.581358609794629, 0.7833333333333334, 1.0, 1.0, 0.46038525670786823, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21431334335513372, 0.21431334335513372, 0.2868137854239046], 
reward next is 0.7132, 
noisyNet noise sample is [array([0.16320804], dtype=float32), -0.73281366]. 
=============================================
[2019-03-26 11:58:11,626] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1160545: loss -251.0762
[2019-03-26 11:58:11,629] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1160545: learning rate 0.0001
[2019-03-26 11:58:13,230] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.7184742e-27 1.0000000e+00 2.8717350e-30 3.1038920e-36 2.1089370e-25], sum to 1.0000
[2019-03-26 11:58:13,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0851
[2019-03-26 11:58:13,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 79.0, 1.0, 2.0, 0.486988359873998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 702015.3451218415, 702015.3451218408, 184320.2300252992], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3736800.0000, 
sim time next is 3737400.0000, 
raw observation next is [26.33333333333334, 78.16666666666667, 1.0, 2.0, 0.7734726480349765, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1108856.419180989, 1108856.419180989, 241347.843446347], 
processed observation next is [1.0, 0.2608695652173913, 0.44707740916271754, 0.7816666666666667, 1.0, 1.0, 0.7270754795602127, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3080156719947192, 0.3080156719947192, 0.3602206618602194], 
reward next is 0.6398, 
noisyNet noise sample is [array([-3.6005256], dtype=float32), 0.264718]. 
=============================================
[2019-03-26 11:58:13,867] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1161569: loss -137.6441
[2019-03-26 11:58:13,870] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1161571: learning rate 0.0001
[2019-03-26 11:58:14,417] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1161833: loss -197.3769
[2019-03-26 11:58:14,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1161833: learning rate 0.0001
[2019-03-26 11:58:15,192] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162187: loss -61.8996
[2019-03-26 11:58:15,194] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162187: learning rate 0.0001
[2019-03-26 11:58:15,521] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1162338: loss -319.4066
[2019-03-26 11:58:15,524] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1162338: learning rate 0.0001
[2019-03-26 11:58:15,666] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1162404: loss 0.0063
[2019-03-26 11:58:15,670] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1162406: learning rate 0.0001
[2019-03-26 11:58:16,050] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1162581: loss -345.3379
[2019-03-26 11:58:16,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1162581: learning rate 0.0001
[2019-03-26 11:58:16,112] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1162607: loss -38.6230
[2019-03-26 11:58:16,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1162607: learning rate 0.0001
[2019-03-26 11:58:16,470] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1162773: loss -156.4191
[2019-03-26 11:58:16,474] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1162773: learning rate 0.0001
[2019-03-26 11:58:16,612] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1162840: loss -187.4469
[2019-03-26 11:58:16,618] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1162841: learning rate 0.0001
[2019-03-26 11:58:16,652] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162857: loss -102.1145
[2019-03-26 11:58:16,657] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162859: learning rate 0.0001
[2019-03-26 11:58:16,693] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162876: loss -241.5939
[2019-03-26 11:58:16,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162876: learning rate 0.0001
[2019-03-26 11:58:21,612] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.3171171e-17 1.0000000e+00 4.8207837e-16 6.3889309e-18 6.7602222e-09], sum to 1.0000
[2019-03-26 11:58:21,617] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9612
[2019-03-26 11:58:21,622] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1718871.265037627 W.
[2019-03-26 11:58:21,627] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 76.33333333333334, 1.0, 2.0, 0.6147539037922838, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.953892443840362, 6.9112, 168.9126726331322, 1718871.265037627, 1688583.826918302, 367316.294322655], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4243200.0000, 
sim time next is 4243800.0000, 
raw observation next is [30.0, 75.66666666666666, 1.0, 2.0, 0.5724180686850763, 1.0, 1.0, 0.5724180686850763, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1600398.052135231, 1600398.052135231, 324293.8521821153], 
processed observation next is [1.0, 0.08695652173913043, 0.6208530805687204, 0.7566666666666666, 1.0, 1.0, 0.4848410466085256, 1.0, 0.5, 0.4848410466085256, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4445550144820086, 0.4445550144820086, 0.48402067489867956], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.08501309], dtype=float32), 1.4583662]. 
=============================================
[2019-03-26 11:58:23,555] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1166014: loss 6.6727
[2019-03-26 11:58:23,557] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1166014: learning rate 0.0001
[2019-03-26 11:58:23,628] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.6382435e-13 9.9994910e-01 2.9974096e-11 2.1381641e-11 5.0844523e-05], sum to 1.0000
[2019-03-26 11:58:23,633] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9456
[2019-03-26 11:58:23,640] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2698769.655115785 W.
[2019-03-26 11:58:23,651] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 72.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.47404289174929, 6.9112, 168.9103350414107, 2698769.655115785, 2299475.733147379, 475600.7397777432], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4011000.0000, 
sim time next is 4011600.0000, 
raw observation next is [29.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6188401750253145, 1.0, 1.0, 0.6188401750253145, 1.0, 2.0, 1.03, 6.953194324298858, 6.9112, 170.5573041426782, 2596420.568719221, 2566338.326004053, 495251.5309485686], 
processed observation next is [1.0, 0.43478260869565216, 0.6050552922590839, 0.7133333333333334, 1.0, 1.0, 0.5407712952112222, 1.0, 0.5, 0.5407712952112222, 1.0, 1.0, 1.0365853658536586, 0.004199432429885785, 0.0, 0.8375144448122397, 0.7212279357553392, 0.7128717572233481, 0.7391813894754755], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.77267635], dtype=float32), 0.17810774]. 
=============================================
[2019-03-26 11:58:25,097] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.4921643e-30 1.0000000e+00 2.6402402e-32 0.0000000e+00 1.2078062e-28], sum to 1.0000
[2019-03-26 11:58:25,108] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8087
[2019-03-26 11:58:25,113] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 69.0, 1.0, 2.0, 0.5953357711821696, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 831941.4134097829, 831941.4134097835, 199880.3410702076], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3922200.0000, 
sim time next is 3922800.0000, 
raw observation next is [32.0, 68.33333333333333, 1.0, 2.0, 0.5914683292971014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 826534.8225144135, 826534.8225144135, 199167.3267850265], 
processed observation next is [0.0, 0.391304347826087, 0.7156398104265403, 0.6833333333333332, 1.0, 1.0, 0.5077931678278329, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22959300625400375, 0.22959300625400375, 0.29726466684332314], 
reward next is 0.7027, 
noisyNet noise sample is [array([-0.66557395], dtype=float32), 1.0728757]. 
=============================================
[2019-03-26 11:58:26,164] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1167220: loss 0.0737
[2019-03-26 11:58:26,169] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1167225: learning rate 0.0001
[2019-03-26 11:58:26,418] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1167336: loss 0.0242
[2019-03-26 11:58:26,419] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1167336: learning rate 0.0001
[2019-03-26 11:58:28,547] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1168329: loss -12.8789
[2019-03-26 11:58:28,551] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1168329: learning rate 0.0001
[2019-03-26 11:58:29,098] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1168580: loss 0.1126
[2019-03-26 11:58:29,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1168581: learning rate 0.0001
[2019-03-26 11:58:31,220] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1169568: loss 0.1720
[2019-03-26 11:58:31,223] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1169568: learning rate 0.0001
[2019-03-26 11:58:31,590] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1169738: loss 0.0869
[2019-03-26 11:58:31,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1169738: learning rate 0.0001
[2019-03-26 11:58:32,501] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170157: loss 0.0702
[2019-03-26 11:58:32,504] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170158: learning rate 0.0001
[2019-03-26 11:58:32,851] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1170321: loss 0.0197
[2019-03-26 11:58:32,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1170321: learning rate 0.0001
[2019-03-26 11:58:33,222] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1170483: loss 0.0036
[2019-03-26 11:58:33,229] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1170488: learning rate 0.0001
[2019-03-26 11:58:33,401] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1170569: loss 0.0043
[2019-03-26 11:58:33,404] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1170569: learning rate 0.0001
[2019-03-26 11:58:33,624] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1170665: loss -42.8986
[2019-03-26 11:58:33,628] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1170666: learning rate 0.0001
[2019-03-26 11:58:33,778] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8334411e-14 9.9998558e-01 3.1489182e-12 1.3988500e-11 1.4389488e-05], sum to 1.0000
[2019-03-26 11:58:33,787] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3914
[2019-03-26 11:58:33,798] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2811590.931263604 W.
[2019-03-26 11:58:33,801] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1170748: loss 0.0034
[2019-03-26 11:58:33,802] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 1.005100509589556, 1.0, 2.0, 1.005100509589556, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2811590.931263604, 2811590.931263604, 532079.9124078221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4100400.0000, 
sim time next is 4101000.0000, 
raw observation next is [32.16666666666667, 71.0, 1.0, 2.0, 0.6103859183938833, 1.0, 2.0, 0.6103859183938833, 1.0, 1.0, 1.03, 6.944968391305406, 6.9112, 170.5573041426782, 2560913.3368612, 2536723.664558803, 491776.1570676533], 
processed observation next is [1.0, 0.4782608695652174, 0.7235387045813588, 0.71, 1.0, 1.0, 0.5305854438480522, 1.0, 1.0, 0.5305854438480522, 1.0, 0.5, 1.0365853658536586, 0.00337683913054061, 0.0, 0.8375144448122397, 0.7113648157947778, 0.7046454623774453, 0.7339942642800795], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6112579], dtype=float32), 1.6088871]. 
=============================================
[2019-03-26 11:58:33,805] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1170748: learning rate 0.0001
[2019-03-26 11:58:33,818] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[46.91097 ]
 [47.053894]
 [48.81412 ]
 [49.57254 ]
 [49.204636]], R is [[47.32464981]
 [46.85140228]
 [46.38288879]
 [46.16093445]
 [45.97478104]].
[2019-03-26 11:58:33,906] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170796: loss 0.0046
[2019-03-26 11:58:33,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170797: learning rate 0.0001
[2019-03-26 11:58:33,933] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1170806: loss 0.0085
[2019-03-26 11:58:33,936] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1170808: learning rate 0.0001
[2019-03-26 11:58:33,979] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170826: loss 0.0045
[2019-03-26 11:58:33,982] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1170828: learning rate 0.0001
[2019-03-26 11:58:40,684] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1173862: loss 0.7860
[2019-03-26 11:58:40,687] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1173863: learning rate 0.0001
[2019-03-26 11:58:41,476] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.205660e-28 1.000000e+00 7.075559e-29 1.483498e-35 7.992852e-24], sum to 1.0000
[2019-03-26 11:58:41,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6298
[2019-03-26 11:58:41,488] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.6229624248749964, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 870563.612440204, 870563.612440204, 205102.2556775321], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4315800.0000, 
sim time next is 4316400.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6239946049151847, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 872006.63247808, 872006.6324780794, 205301.6594285692], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5469814517050418, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24222406457724444, 0.24222406457724427, 0.3064203872068197], 
reward next is 0.6936, 
noisyNet noise sample is [array([1.4065278], dtype=float32), -2.5679624]. 
=============================================
[2019-03-26 11:58:42,239] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1601681e-27 1.0000000e+00 1.6927087e-28 2.0008020e-34 5.2235814e-22], sum to 1.0000
[2019-03-26 11:58:42,246] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7014
[2019-03-26 11:58:42,249] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.598794308316437, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836776.3885920225, 836776.3885920225, 200521.6796239286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4236000.0000, 
sim time next is 4236600.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.5983498642354573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 836155.0622102371, 836155.0622102377, 200439.0969074108], 
processed observation next is [1.0, 0.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5160841737776594, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2322652950583992, 0.23226529505839938, 0.29916283120509074], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.07463449], dtype=float32), 0.0715849]. 
=============================================
[2019-03-26 11:58:43,167] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-26 11:58:43,170] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 11:58:43,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:58:43,172] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 11:58:43,173] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:58:43,173] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 11:58:43,174] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 11:58:43,175] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:58:43,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 11:58:43,176] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:58:43,180] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 11:58:43,196] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-26 11:58:43,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-26 11:58:43,218] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-26 11:58:43,239] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-26 11:58:43,283] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-26 11:59:23,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33246607], dtype=float32), 0.10194616]
[2019-03-26 11:59:23,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.66666666666666, 84.66666666666666, 1.0, 2.0, 0.6201661007753495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 969315.0156245605, 969315.0156245598, 216795.5202452995]
[2019-03-26 11:59:23,788] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:59:23,794] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.6084171e-30 1.0000000e+00 1.2645608e-32 0.0000000e+00 4.3716674e-28], sampled 0.3190212747538814
[2019-03-26 11:59:48,895] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33246607], dtype=float32), 0.10194616]
[2019-03-26 11:59:48,895] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.0, 1.0, 2.0, 0.5150205109398079, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719668.2561756148, 719668.2561756148, 185983.1662604543]
[2019-03-26 11:59:48,896] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 11:59:48,899] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.2697772e-31 1.0000000e+00 5.6558916e-35 0.0000000e+00 9.5329705e-31], sampled 0.518531250877371
[2019-03-26 12:00:04,674] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33246607], dtype=float32), 0.10194616]
[2019-03-26 12:00:04,675] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.78786084, 79.09409268, 1.0, 2.0, 0.640049186405562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 894451.6928570555, 894451.692857056, 208445.9379569085]
[2019-03-26 12:00:04,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:00:04,678] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.4685294e-29 1.0000000e+00 2.4921421e-31 0.0000000e+00 3.7052393e-26], sampled 0.6416558222129907
[2019-03-26 12:00:38,138] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9559 3007647868.8583 1766.0000
[2019-03-26 12:00:38,194] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.8309 2927324051.3161 1339.0000
[2019-03-26 12:00:38,409] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7885.0009 3164023441.2214 1776.0000
[2019-03-26 12:00:38,543] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.3000 2779253841.1793 937.0000
[2019-03-26 12:00:38,557] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.7626 2842571369.0137 1131.0000
[2019-03-26 12:00:39,574] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1175000, evaluation results [1175000.0, 7885.000937191054, 3164023441.2214384, 1776.0, 8254.83089227559, 2927324051.316136, 1339.0, 8660.299964155278, 2779253841.17935, 937.0, 7998.955910945021, 3007647868.858331, 1766.0, 8496.762600242775, 2842571369.0137076, 1131.0]
[2019-03-26 12:00:40,204] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1175283: loss -80.5127
[2019-03-26 12:00:40,205] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1175283: learning rate 0.0001
[2019-03-26 12:00:40,471] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1175407: loss -223.5356
[2019-03-26 12:00:40,472] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1175407: learning rate 0.0001
[2019-03-26 12:00:41,943] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1176062: loss 0.0346
[2019-03-26 12:00:41,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1176062: learning rate 0.0001
[2019-03-26 12:00:43,104] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1176583: loss -24.9133
[2019-03-26 12:00:43,106] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1176584: learning rate 0.0001
[2019-03-26 12:00:45,337] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1177589: loss -235.6256
[2019-03-26 12:00:45,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1177590: learning rate 0.0001
[2019-03-26 12:00:45,824] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1177806: loss -119.7866
[2019-03-26 12:00:45,827] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1177806: learning rate 0.0001
[2019-03-26 12:00:46,898] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178285: loss -77.0349
[2019-03-26 12:00:46,900] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178285: learning rate 0.0001
[2019-03-26 12:00:46,933] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1178297: loss -81.8465
[2019-03-26 12:00:46,936] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1178299: learning rate 0.0001
[2019-03-26 12:00:47,210] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1178422: loss 0.4719
[2019-03-26 12:00:47,212] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1178422: learning rate 0.0001
[2019-03-26 12:00:47,337] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1178476: loss -229.6760
[2019-03-26 12:00:47,339] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1178476: learning rate 0.0001
[2019-03-26 12:00:47,570] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1178582: loss -179.6949
[2019-03-26 12:00:47,572] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1178583: learning rate 0.0001
[2019-03-26 12:00:48,141] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178841: loss -92.4276
[2019-03-26 12:00:48,143] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178842: learning rate 0.0001
[2019-03-26 12:00:48,159] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178847: loss -57.1777
[2019-03-26 12:00:48,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178847: learning rate 0.0001
[2019-03-26 12:00:48,178] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1178856: loss -119.6068
[2019-03-26 12:00:48,179] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1178856: learning rate 0.0001
[2019-03-26 12:00:48,238] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1178882: loss -127.1310
[2019-03-26 12:00:48,240] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1178883: learning rate 0.0001
[2019-03-26 12:00:48,670] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3729088e-32 1.0000000e+00 4.0241445e-35 0.0000000e+00 6.2482715e-32], sum to 1.0000
[2019-03-26 12:00:48,680] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7497
[2019-03-26 12:00:48,686] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.0, 70.33333333333334, 1.0, 2.0, 0.6710449508241483, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 937786.5720021, 937786.5720021005, 214727.2930612], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4450200.0000, 
sim time next is 4450800.0000, 
raw observation next is [33.0, 69.66666666666667, 1.0, 2.0, 0.6439446792931339, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 899897.8467283173, 899897.8467283173, 209218.5528079979], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.6966666666666668, 1.0, 1.0, 0.5710176858953421, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.24997162409119925, 0.24997162409119925, 0.3122664967283551], 
reward next is 0.6877, 
noisyNet noise sample is [array([0.90036035], dtype=float32), 0.34955522]. 
=============================================
[2019-03-26 12:00:53,090] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2641213e-33 1.0000000e+00 2.5853078e-37 0.0000000e+00 1.9389332e-34], sum to 1.0000
[2019-03-26 12:00:53,103] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-26 12:00:53,111] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.497565174219769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 695268.9118359083, 695268.9118359083, 183214.9644337025], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4525200.0000, 
sim time next is 4525800.0000, 
raw observation next is [28.0, 74.83333333333334, 1.0, 2.0, 0.498187785142159, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 696139.1975420427, 696139.1975420427, 183312.3870787389], 
processed observation next is [0.0, 0.391304347826087, 0.5260663507109005, 0.7483333333333334, 1.0, 1.0, 0.39540697005079395, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1933719993172341, 0.1933719993172341, 0.273600577729461], 
reward next is 0.7264, 
noisyNet noise sample is [array([-0.2543356], dtype=float32), 1.4077816]. 
=============================================
[2019-03-26 12:00:55,075] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1181920: loss 74.6542
[2019-03-26 12:00:55,077] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1181920: learning rate 0.0001
[2019-03-26 12:00:56,143] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.3687134e-14 9.9999976e-01 2.5111201e-14 9.6681840e-15 1.8345918e-07], sum to 1.0000
[2019-03-26 12:00:56,151] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3858
[2019-03-26 12:00:56,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2541825.33062487 W.
[2019-03-26 12:00:56,167] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 63.0, 1.0, 2.0, 0.9087614595368141, 1.0, 1.0, 0.9087614595368141, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2541825.33062487, 2541825.33062487, 476291.7608957086], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4888800.0000, 
sim time next is 4889400.0000, 
raw observation next is [31.91666666666667, 63.33333333333333, 1.0, 2.0, 0.5283253734924694, 1.0, 2.0, 0.5283253734924694, 1.0, 1.0, 0.9175264538855292, 6.911199999999999, 6.9112, 170.5573041426782, 2216317.734853533, 2216317.734853534, 435286.0516185556], 
processed observation next is [1.0, 0.6086956521739131, 0.7116903633491314, 0.6333333333333333, 1.0, 1.0, 0.43171731746080655, 1.0, 1.0, 0.43171731746080655, 1.0, 0.5, 0.8994225047384503, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6156438152370926, 0.6156438152370928, 0.6496806740575457], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3212464], dtype=float32), 1.6247152]. 
=============================================
[2019-03-26 12:00:57,790] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1183148: loss 0.0348
[2019-03-26 12:00:57,793] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1183149: learning rate 0.0001
[2019-03-26 12:00:58,062] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1183270: loss 0.0485
[2019-03-26 12:00:58,066] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1183271: learning rate 0.0001
[2019-03-26 12:00:58,547] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1245097e-28 1.0000000e+00 9.1894468e-30 1.6510000e-37 2.1880854e-24], sum to 1.0000
[2019-03-26 12:00:58,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9957
[2019-03-26 12:00:58,561] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666666, 85.66666666666666, 1.0, 2.0, 0.5049403936174067, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 705578.0411922628, 705578.0411922622, 184373.8777602233], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4668600.0000, 
sim time next is 4669200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5069772357225876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708425.1698864554, 708425.169886456, 184696.6834716284], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4059966695452862, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1967847694129043, 0.19678476941290443, 0.2756666917486991], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.3076739], dtype=float32), 1.38663]. 
=============================================
[2019-03-26 12:01:00,099] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1184216: loss 86.9547
[2019-03-26 12:01:00,102] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1184216: learning rate 0.0001
[2019-03-26 12:01:00,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1430960e-12 9.9617457e-01 4.0836598e-10 1.5078463e-10 3.8253702e-03], sum to 1.0000
[2019-03-26 12:01:00,493] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7896
[2019-03-26 12:01:00,503] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2711652.370637225 W.
[2019-03-26 12:01:00,509] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.9694127436591465, 1.0, 2.0, 0.9694127436591465, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2711652.370637225, 2711652.370637225, 510786.6471657577], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4614000.0000, 
sim time next is 4614600.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.9673722387736899, 1.0, 2.0, 0.9673722387736899, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2705938.465800845, 2705938.465800845, 509591.5371192993], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.9606894443056505, 1.0, 1.0, 0.9606894443056505, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7516495738335681, 0.7516495738335681, 0.7605843837601481], 
reward next is 0.2394, 
noisyNet noise sample is [array([0.50819165], dtype=float32), 1.2972045]. 
=============================================
[2019-03-26 12:01:01,038] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1184649: loss 0.0376
[2019-03-26 12:01:01,040] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1184649: learning rate 0.0001
[2019-03-26 12:01:03,021] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1185563: loss 0.0451
[2019-03-26 12:01:03,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1185563: learning rate 0.0001
[2019-03-26 12:01:03,340] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1185710: loss 0.0804
[2019-03-26 12:01:03,344] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1185711: learning rate 0.0001
[2019-03-26 12:01:04,505] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186250: loss 0.0938
[2019-03-26 12:01:04,508] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186252: learning rate 0.0001
[2019-03-26 12:01:04,520] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1186258: loss 0.0752
[2019-03-26 12:01:04,526] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1186258: learning rate 0.0001
[2019-03-26 12:01:04,986] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1186470: loss 0.0240
[2019-03-26 12:01:04,988] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1186470: learning rate 0.0001
[2019-03-26 12:01:05,190] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1186565: loss 100.0943
[2019-03-26 12:01:05,193] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1186567: learning rate 0.0001
[2019-03-26 12:01:05,295] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1186611: loss 0.0154
[2019-03-26 12:01:05,296] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1186611: learning rate 0.0001
[2019-03-26 12:01:05,699] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186796: loss 0.0451
[2019-03-26 12:01:05,701] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186796: learning rate 0.0001
[2019-03-26 12:01:05,758] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1186823: loss 0.0340
[2019-03-26 12:01:05,761] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1186823: learning rate 0.0001
[2019-03-26 12:01:05,771] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1186829: loss 0.0110
[2019-03-26 12:01:05,776] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1186829: learning rate 0.0001
[2019-03-26 12:01:06,037] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1186947: loss 0.0654
[2019-03-26 12:01:06,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1186948: learning rate 0.0001
[2019-03-26 12:01:12,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1189807: loss 0.0978
[2019-03-26 12:01:12,311] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1189808: learning rate 0.0001
[2019-03-26 12:01:13,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1919237e-28 1.0000000e+00 1.2423286e-30 0.0000000e+00 5.7888074e-26], sum to 1.0000
[2019-03-26 12:01:13,151] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7025
[2019-03-26 12:01:13,156] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.6163231255190609, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 861281.7107726893, 861281.7107726893, 203821.3754249572], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4777200.0000, 
sim time next is 4777800.0000, 
raw observation next is [28.33333333333334, 82.5, 1.0, 2.0, 0.7697310751617751, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1075770.468842834, 1075770.468842834, 236617.6538215202], 
processed observation next is [1.0, 0.30434782608695654, 0.5418641390205374, 0.825, 1.0, 1.0, 0.7225675604358736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.29882513023412055, 0.29882513023412055, 0.3531606773455525], 
reward next is 0.6468, 
noisyNet noise sample is [array([1.0013956], dtype=float32), 0.03038178]. 
=============================================
[2019-03-26 12:01:15,030] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1191063: loss 98.8326
[2019-03-26 12:01:15,032] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1191063: learning rate 0.0001
[2019-03-26 12:01:15,461] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1191265: loss 71.6191
[2019-03-26 12:01:15,464] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1191265: learning rate 0.0001
[2019-03-26 12:01:16,292] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.4127435e-10 8.5567135e-01 6.0445839e-09 3.5445215e-08 1.4432874e-01], sum to 1.0000
[2019-03-26 12:01:16,298] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6959
[2019-03-26 12:01:16,304] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 3135686.047368099 W.
[2019-03-26 12:01:16,310] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.06666666666667, 53.0, 1.0, 2.0, 0.8532389612941436, 1.0, 2.0, 0.7472095201613345, 1.0, 2.0, 1.03, 7.005109818017793, 6.9112, 170.5573041426782, 3135686.047368099, 3068414.624714793, 574099.4264460172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5325600.0000, 
sim time next is 5326200.0000, 
raw observation next is [36.05, 53.0, 1.0, 2.0, 0.8420930502155699, 1.0, 2.0, 0.7416365646220475, 1.0, 2.0, 1.03, 7.005108938736724, 6.9112, 170.5573041426782, 3112269.840044767, 3044999.047256258, 569966.134085911], 
processed observation next is [1.0, 0.6521739130434783, 0.9075829383886255, 0.53, 1.0, 1.0, 0.8097506629103252, 1.0, 1.0, 0.6887187525566838, 1.0, 1.0, 1.0365853658536586, 0.009390893873672378, 0.0, 0.8375144448122397, 0.8645194000124353, 0.8458330686822938, 0.850695722516285], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8857824], dtype=float32), -0.8218716]. 
=============================================
[2019-03-26 12:01:17,091] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1192012: loss 0.7599
[2019-03-26 12:01:17,094] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1192014: learning rate 0.0001
[2019-03-26 12:01:18,431] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1192633: loss 100.8081
[2019-03-26 12:01:18,433] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1192633: learning rate 0.0001
[2019-03-26 12:01:20,472] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1193586: loss 96.4951
[2019-03-26 12:01:20,474] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1193586: learning rate 0.0001
[2019-03-26 12:01:20,820] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1193744: loss 100.5776
[2019-03-26 12:01:20,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1193744: learning rate 0.0001
[2019-03-26 12:01:21,937] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1194255: loss 76.7813
[2019-03-26 12:01:21,940] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1194256: learning rate 0.0001
[2019-03-26 12:01:22,169] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194365: loss 88.4915
[2019-03-26 12:01:22,174] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194365: learning rate 0.0001
[2019-03-26 12:01:22,230] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1194393: loss 0.2424
[2019-03-26 12:01:22,231] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1194393: learning rate 0.0001
[2019-03-26 12:01:22,415] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1194475: loss 97.2982
[2019-03-26 12:01:22,418] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1194477: learning rate 0.0001
[2019-03-26 12:01:22,687] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1194605: loss 97.1172
[2019-03-26 12:01:22,690] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1194605: learning rate 0.0001
[2019-03-26 12:01:23,073] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194779: loss 75.1475
[2019-03-26 12:01:23,077] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194781: learning rate 0.0001
[2019-03-26 12:01:23,103] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1194793: loss 75.5342
[2019-03-26 12:01:23,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1194793: learning rate 0.0001
[2019-03-26 12:01:23,120] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1194799: loss 88.0363
[2019-03-26 12:01:23,122] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1194800: learning rate 0.0001
[2019-03-26 12:01:23,425] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1194936: loss 75.1683
[2019-03-26 12:01:23,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1194937: learning rate 0.0001
[2019-03-26 12:01:25,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.6799533e-32 1.0000000e+00 1.3778392e-34 0.0000000e+00 6.7126288e-32], sum to 1.0000
[2019-03-26 12:01:25,559] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6470
[2019-03-26 12:01:25,566] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 75.0, 1.0, 2.0, 0.5296682617982389, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740143.5453028558, 740143.5453028558, 188375.121748588], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5041800.0000, 
sim time next is 5042400.0000, 
raw observation next is [29.33333333333334, 72.0, 1.0, 2.0, 0.5249969805333947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 733613.7740593866, 733613.774059386, 187605.231820317], 
processed observation next is [0.0, 0.34782608695652173, 0.5892575039494474, 0.72, 1.0, 1.0, 0.4277072054619213, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20378160390538516, 0.203781603905385, 0.28000780868704034], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.8378234], dtype=float32), -0.9865014]. 
=============================================
[2019-03-26 12:01:29,634] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1197823: loss 2.5059
[2019-03-26 12:01:29,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1197823: learning rate 0.0001
[2019-03-26 12:01:30,036] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0980254e-30 1.0000000e+00 4.9862713e-32 0.0000000e+00 9.6708059e-30], sum to 1.0000
[2019-03-26 12:01:30,047] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2151
[2019-03-26 12:01:30,054] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5419611494005354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757327.4045932451, 757327.4045932451, 190431.7740785881], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5158800.0000, 
sim time next is 5159400.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5504419427918837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 769182.6136442873, 769182.6136442866, 191876.0730203338], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.45836378649624543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21366183712341316, 0.21366183712341297, 0.28638219853781166], 
reward next is 0.7136, 
noisyNet noise sample is [array([0.12301151], dtype=float32), -0.0605718]. 
=============================================
[2019-03-26 12:01:31,523] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1226328e-12 9.9899405e-01 2.6740108e-09 2.4118194e-11 1.0059908e-03], sum to 1.0000
[2019-03-26 12:01:31,531] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6037
[2019-03-26 12:01:31,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2845960.353188504 W.
[2019-03-26 12:01:31,545] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 68.0, 1.0, 2.0, 0.7153173466740568, 1.0, 2.0, 0.678248712851291, 1.0, 2.0, 1.03, 7.005098939945588, 6.9112, 170.5573041426782, 2845960.353188504, 2778696.72294081, 526210.306487095], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5242800.0000, 
sim time next is 5243400.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.7206318219717143, 1.0, 2.0, 0.6809059505001198, 1.0, 2.0, 1.03, 7.005099359012335, 6.9112, 170.5573041426782, 2857122.986169916, 2789859.055727665, 527924.3353950145], 
processed observation next is [1.0, 0.6956521739130435, 0.6919431279620853, 0.685, 1.0, 1.0, 0.6634118337008605, 1.0, 1.0, 0.6155493379519515, 1.0, 1.0, 1.0365853658536586, 0.009389935901233493, 0.0, 0.8375144448122397, 0.7936452739360879, 0.7749608488132402, 0.7879467692462903], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17603742], dtype=float32), 0.17162764]. 
=============================================
[2019-03-26 12:01:32,256] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1199027: loss 0.2561
[2019-03-26 12:01:32,261] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1199028: learning rate 0.0001
[2019-03-26 12:01:32,619] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1199198: loss 0.8339
[2019-03-26 12:01:32,623] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1199199: learning rate 0.0001
[2019-03-26 12:01:34,364] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-26 12:01:34,366] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:01:34,367] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:01:34,367] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:01:34,368] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:01:34,368] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:01:34,369] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:01:34,369] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:01:34,370] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:01:34,370] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:01:34,373] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:01:34,394] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-26 12:01:34,413] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-26 12:01:34,432] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-26 12:01:34,433] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-26 12:01:34,450] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-26 12:01:43,767] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:01:43,769] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [12.77948221833333, 91.71200810333333, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 269553.7780973426, 269553.7780973426, 101254.0727401691]
[2019-03-26 12:01:43,770] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:01:43,772] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.7433318e-33 1.0000000e+00 1.3727083e-34 0.0000000e+00 4.2069562e-33], sampled 0.18665105879189425
[2019-03-26 12:01:47,740] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:01:47,741] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.5, 79.0, 1.0, 2.0, 0.2936097048136517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 468681.2068542926, 468681.2068542932, 164838.3568301626]
[2019-03-26 12:01:47,742] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:01:47,743] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.4108801e-33 1.0000000e+00 9.3401148e-36 0.0000000e+00 3.8103778e-34], sampled 0.8589618419930138
[2019-03-26 12:01:51,305] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:01:51,306] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.83333333333334, 86.33333333333334, 1.0, 2.0, 0.2850796513709253, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 461102.7688939435, 461102.7688939441, 164340.6630516481]
[2019-03-26 12:01:51,307] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:01:51,309] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1466483e-33 1.0000000e+00 2.6218880e-36 0.0000000e+00 1.1824100e-34], sampled 0.9152911194079724
[2019-03-26 12:01:55,798] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:01:55,800] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.54858134666667, 91.36700389666667, 1.0, 2.0, 0.5015527975617619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 700842.8251008783, 700842.8251008788, 183839.3310477958]
[2019-03-26 12:01:55,802] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:01:55,805] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.2901516e-32 1.0000000e+00 5.1507304e-35 0.0000000e+00 4.1236665e-33], sampled 0.9760683050347861
[2019-03-26 12:01:59,045] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:01:59,046] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.000487295, 84.45046656, 1.0, 2.0, 0.5257219684857017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 766886.9827056231, 766886.9827056224, 191792.2679096402]
[2019-03-26 12:01:59,047] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:01:59,051] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.2865091e-32 1.0000000e+00 2.5953019e-34 0.0000000e+00 6.1446934e-32], sampled 0.46662414561501164
[2019-03-26 12:02:09,819] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:02:09,821] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.8, 89.0, 1.0, 2.0, 0.6041490373855988, 0.0, 2.0, 0.0, 1.0, 2.0, 1.014287537624286, 6.9112, 6.9112, 168.9129565097906, 1689196.124512094, 1689196.124512094, 362477.5421470437]
[2019-03-26 12:02:09,821] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:02:09,824] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7545805e-23 1.0000000e+00 1.2111647e-21 2.8144043e-25 1.1902895e-18], sampled 0.7076683899601088
[2019-03-26 12:02:09,825] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1689196.124512094 W.
[2019-03-26 12:02:20,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:02:20,596] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.9, 72.0, 1.0, 2.0, 0.6595544715604877, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990145076975463, 6.9112, 168.9124225031882, 1818532.69496008, 1762526.517334251, 376722.831474055]
[2019-03-26 12:02:20,597] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:02:20,601] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.0200391e-22 1.0000000e+00 2.6303831e-21 1.5546716e-24 2.0982878e-18], sampled 0.8539346344146218
[2019-03-26 12:02:20,602] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1818532.69496008 W.
[2019-03-26 12:02:31,627] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:02:31,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.528628935, 77.464412825, 1.0, 2.0, 0.6741607778434169, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 942142.8775015966, 942142.8775015973, 215376.7259668743]
[2019-03-26 12:02:31,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:02:31,636] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3189301e-31 1.0000000e+00 2.1292831e-33 0.0000000e+00 6.0587852e-31], sampled 0.45840979817327154
[2019-03-26 12:03:09,676] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:03:09,677] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.2, 80.0, 1.0, 2.0, 0.5393354437723719, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753656.9860131231, 753656.9860131225, 189988.0124541844]
[2019-03-26 12:03:09,678] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:03:09,679] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.5239794e-30 1.0000000e+00 5.4474938e-31 0.0000000e+00 2.8318031e-28], sampled 0.1085777082267767
[2019-03-26 12:03:13,059] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:03:13,060] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.33333333333333, 74.16666666666667, 1.0, 2.0, 0.5816627638604156, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812827.0008164948, 812827.0008164948, 197378.6975744794]
[2019-03-26 12:03:13,061] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:03:13,065] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.5883972e-29 1.0000000e+00 1.2070956e-30 0.0000000e+00 2.3811189e-27], sampled 0.2896124734997666
[2019-03-26 12:03:20,533] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:03:20,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.51462958, 65.26564836666667, 1.0, 2.0, 0.364893379058673, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 557730.6231139664, 557730.6231139664, 171175.9582531506]
[2019-03-26 12:03:20,539] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:03:20,546] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3684688e-30 1.0000000e+00 8.5781195e-32 0.0000000e+00 3.3319717e-29], sampled 0.7859052629023495
[2019-03-26 12:03:28,294] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.33111084], dtype=float32), 0.10215257]
[2019-03-26 12:03:28,294] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.32120553, 72.878673285, 1.0, 2.0, 0.8874824939359014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1272187.215837908, 1272187.215837907, 271167.4744725774]
[2019-03-26 12:03:28,296] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:03:28,300] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.4534285e-28 1.0000000e+00 4.5938735e-29 2.1134664e-37 8.5025955e-26], sampled 0.065725338988054
[2019-03-26 12:03:29,461] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2178 3007719775.7786 1766.0000
[2019-03-26 12:03:29,582] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.9668 3164042122.6916 1780.0000
[2019-03-26 12:03:29,618] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.0224 2779271766.9493 938.0000
[2019-03-26 12:03:29,786] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5752 2842451949.6408 1131.0000
[2019-03-26 12:03:29,945] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.4033 2927329517.0614 1341.0000
[2019-03-26 12:03:30,962] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1200000, evaluation results [1200000.0, 7882.966789005949, 3164042122.6915903, 1780.0, 8254.403345880972, 2927329517.0613775, 1341.0, 8660.022428690709, 2779271766.949257, 938.0, 7998.217808978373, 3007719775.7785764, 1766.0, 8497.575228127671, 2842451949.640752, 1131.0]
[2019-03-26 12:03:31,095] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1200065: loss 1.7296
[2019-03-26 12:03:31,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1200065: learning rate 0.0001
[2019-03-26 12:03:32,446] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1200666: loss 0.9071
[2019-03-26 12:03:32,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1200666: learning rate 0.0001
[2019-03-26 12:03:34,714] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1201688: loss 0.1641
[2019-03-26 12:03:34,716] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1201689: learning rate 0.0001
[2019-03-26 12:03:34,904] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1201771: loss 0.1336
[2019-03-26 12:03:34,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1201772: learning rate 0.0001
[2019-03-26 12:03:36,050] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1202284: loss 0.0109
[2019-03-26 12:03:36,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1202286: learning rate 0.0001
[2019-03-26 12:03:36,335] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202406: loss 0.2241
[2019-03-26 12:03:36,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202406: learning rate 0.0001
[2019-03-26 12:03:36,569] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1202512: loss 1.4681
[2019-03-26 12:03:36,572] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1202512: learning rate 0.0001
[2019-03-26 12:03:36,618] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1202527: loss 2.2727
[2019-03-26 12:03:36,619] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1202527: learning rate 0.0001
[2019-03-26 12:03:36,702] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1202572: loss 0.3882
[2019-03-26 12:03:36,704] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1202572: learning rate 0.0001
[2019-03-26 12:03:37,178] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202775: loss 1.5521
[2019-03-26 12:03:37,181] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202775: learning rate 0.0001
[2019-03-26 12:03:37,240] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1202806: loss 0.9269
[2019-03-26 12:03:37,243] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1202806: learning rate 0.0001
[2019-03-26 12:03:37,282] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202822: loss 0.9895
[2019-03-26 12:03:37,287] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202822: learning rate 0.0001
[2019-03-26 12:03:37,626] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1202974: loss 0.0560
[2019-03-26 12:03:37,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1202974: learning rate 0.0001
[2019-03-26 12:03:38,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5984414e-29 1.0000000e+00 3.8858055e-30 2.7169971e-37 2.7868185e-26], sum to 1.0000
[2019-03-26 12:03:38,365] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0288
[2019-03-26 12:03:38,373] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.8, 84.0, 1.0, 2.0, 0.6096307443207217, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 851925.6814915441, 851925.6814915447, 202554.0961907282], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5355000.0000, 
sim time next is 5355600.0000, 
raw observation next is [29.76666666666667, 84.0, 1.0, 2.0, 0.6082961798061985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 850059.9541302391, 850059.9541302391, 202301.9235507029], 
processed observation next is [1.0, 1.0, 0.6097946287519749, 0.84, 1.0, 1.0, 0.5280676865134922, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23612776503617752, 0.23612776503617752, 0.301943169478661], 
reward next is 0.6981, 
noisyNet noise sample is [array([-0.6740113], dtype=float32), -0.15263505]. 
=============================================
[2019-03-26 12:03:38,485] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2663921e-31 1.0000000e+00 1.2910378e-32 0.0000000e+00 5.6354868e-31], sum to 1.0000
[2019-03-26 12:03:38,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5864
[2019-03-26 12:03:38,498] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 70.0, 1.0, 2.0, 0.558050477635908, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 779818.614541369, 779818.614541369, 193191.1023807659], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5767200.0000, 
sim time next is 5767800.0000, 
raw observation next is [30.48333333333333, 71.0, 1.0, 2.0, 0.5716510713747606, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 798831.2035700041, 798831.2035700041, 195582.3402300803], 
processed observation next is [0.0, 0.782608695652174, 0.6437598736176934, 0.71, 1.0, 1.0, 0.48391695346356695, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22189755654722335, 0.22189755654722335, 0.2919139406419109], 
reward next is 0.7081, 
noisyNet noise sample is [array([0.35867956], dtype=float32), 0.27309185]. 
=============================================
[2019-03-26 12:03:43,795] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1205747: loss 1.8295
[2019-03-26 12:03:43,797] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1205747: learning rate 0.0001
[2019-03-26 12:03:44,656] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.8421821e-22 1.0000000e+00 2.7013312e-21 1.8684413e-27 6.1452530e-18], sum to 1.0000
[2019-03-26 12:03:44,667] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0980
[2019-03-26 12:03:44,673] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.5, 86.0, 1.0, 2.0, 0.8926081449586144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247603.445734231, 1247603.445734231, 267918.0238271734], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5378400.0000, 
sim time next is 5379000.0000, 
raw observation next is [29.68333333333334, 84.83333333333334, 1.0, 2.0, 0.9271896082850597, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1295967.652439482, 1295967.652439482, 277531.9163570391], 
processed observation next is [1.0, 0.2608695652173913, 0.6058451816745659, 0.8483333333333334, 1.0, 1.0, 0.9122766364880237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.35999101456652277, 0.35999101456652277, 0.41422674083140165], 
reward next is 0.5858, 
noisyNet noise sample is [array([-1.3664129], dtype=float32), 0.6339973]. 
=============================================
[2019-03-26 12:03:44,685] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[50.2781  ]
 [50.131172]
 [49.877228]
 [49.15474 ]
 [48.449295]], R is [[50.06820297]
 [50.16764069]
 [50.27007675]
 [50.37506866]
 [50.48104477]].
[2019-03-26 12:03:46,987] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1207126: loss 1.7626
[2019-03-26 12:03:46,990] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1207128: learning rate 0.0001
[2019-03-26 12:03:47,327] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1207280: loss 1.0976
[2019-03-26 12:03:47,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1207280: learning rate 0.0001
[2019-03-26 12:03:47,748] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.3339816e-31 1.0000000e+00 1.2280078e-33 0.0000000e+00 2.6418348e-30], sum to 1.0000
[2019-03-26 12:03:47,757] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5137
[2019-03-26 12:03:47,763] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.13333333333333, 65.0, 1.0, 2.0, 0.5551705497552017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775792.7394602232, 775792.7394602232, 192692.963921618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5510400.0000, 
sim time next is 5511000.0000, 
raw observation next is [31.86666666666667, 66.5, 1.0, 2.0, 0.5590068765013044, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 781155.5758262539, 781155.5758262544, 193358.7407476227], 
processed observation next is [1.0, 0.782608695652174, 0.7093206951026858, 0.665, 1.0, 1.0, 0.46868298373651135, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2169876599517372, 0.21698765995173735, 0.288595135444213], 
reward next is 0.7114, 
noisyNet noise sample is [array([1.8025047], dtype=float32), -0.46277526]. 
=============================================
[2019-03-26 12:03:47,771] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.60982 ]
 [67.44623 ]
 [67.40121 ]
 [67.34785 ]
 [66.848236]], R is [[67.54434204]
 [67.58129883]
 [67.61843872]
 [67.65569305]
 [67.69268799]].
[2019-03-26 12:03:48,758] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1207934: loss 5.6900
[2019-03-26 12:03:48,759] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1207934: learning rate 0.0001
[2019-03-26 12:03:50,277] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1208650: loss 1.2906
[2019-03-26 12:03:50,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1208650: learning rate 0.0001
[2019-03-26 12:03:52,790] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1209672: loss 1.9889
[2019-03-26 12:03:52,793] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1209672: learning rate 0.0001
[2019-03-26 12:03:52,914] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1209733: loss 1.6091
[2019-03-26 12:03:52,916] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1209733: learning rate 0.0001
[2019-03-26 12:03:53,914] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1210195: loss 2.1752
[2019-03-26 12:03:53,916] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1210195: learning rate 0.0001
[2019-03-26 12:03:54,202] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210328: loss 1.7852
[2019-03-26 12:03:54,203] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210328: learning rate 0.0001
[2019-03-26 12:03:54,242] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1210347: loss 2.4887
[2019-03-26 12:03:54,245] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1210347: learning rate 0.0001
[2019-03-26 12:03:54,485] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1210469: loss 1.4535
[2019-03-26 12:03:54,486] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1210469: learning rate 0.0001
[2019-03-26 12:03:54,568] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1210506: loss 1.6254
[2019-03-26 12:03:54,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1210507: learning rate 0.0001
[2019-03-26 12:03:55,217] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210816: loss 2.2972
[2019-03-26 12:03:55,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210817: learning rate 0.0001
[2019-03-26 12:03:55,266] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210839: loss 1.6614
[2019-03-26 12:03:55,268] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210839: learning rate 0.0001
[2019-03-26 12:03:55,276] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1210845: loss 1.9569
[2019-03-26 12:03:55,277] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1210845: learning rate 0.0001
[2019-03-26 12:03:55,634] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1211011: loss 1.4524
[2019-03-26 12:03:55,637] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1211013: learning rate 0.0001
[2019-03-26 12:04:00,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2636603e-32 1.0000000e+00 2.1722405e-33 0.0000000e+00 2.0934518e-32], sum to 1.0000
[2019-03-26 12:04:00,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1842
[2019-03-26 12:04:00,849] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.33333333333333, 1.0, 2.0, 0.51893795364967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 725144.1962427127, 725144.1962427133, 186616.5906831961], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5643600.0000, 
sim time next is 5644200.0000, 
raw observation next is [28.33333333333333, 77.66666666666667, 1.0, 2.0, 0.5208447252183488, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 727809.5592404157, 727809.5592404157, 186926.6160775571], 
processed observation next is [0.0, 0.30434782608695654, 0.541864139020537, 0.7766666666666667, 1.0, 1.0, 0.42270448821487805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2021693220112266, 0.2021693220112266, 0.2789949493694882], 
reward next is 0.7210, 
noisyNet noise sample is [array([0.03891885], dtype=float32), -0.68097436]. 
=============================================
[2019-03-26 12:04:01,807] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1213885: loss 2.2017
[2019-03-26 12:04:01,814] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1213886: learning rate 0.0001
[2019-03-26 12:04:04,162] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1089144e-31 1.0000000e+00 2.1143415e-33 0.0000000e+00 3.9503983e-32], sum to 1.0000
[2019-03-26 12:04:04,171] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1068
[2019-03-26 12:04:04,176] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.88333333333333, 85.0, 1.0, 2.0, 0.5134387797655146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 717457.2643590256, 717457.2643590256, 185728.3047453293], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5724600.0000, 
sim time next is 5725200.0000, 
raw observation next is [27.06666666666667, 84.0, 1.0, 2.0, 0.5147484859798462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719288.0111071462, 719288.0111071462, 185938.9786653985], 
processed observation next is [0.0, 0.2608695652173913, 0.48183254344391807, 0.84, 1.0, 1.0, 0.4153596216624653, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1998022253075406, 0.1998022253075406, 0.27752086367969925], 
reward next is 0.7225, 
noisyNet noise sample is [array([1.6179497], dtype=float32), -1.2809271]. 
=============================================
[2019-03-26 12:04:04,351] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1215062: loss 0.2707
[2019-03-26 12:04:04,354] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1215062: learning rate 0.0001
[2019-03-26 12:04:04,559] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1215171: loss 0.2587
[2019-03-26 12:04:04,561] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1215173: learning rate 0.0001
[2019-03-26 12:04:05,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.07467734e-32 1.00000000e+00 1.04560544e-33 0.00000000e+00
 2.74423105e-33], sum to 1.0000
[2019-03-26 12:04:05,439] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4436
[2019-03-26 12:04:05,443] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.2, 57.5, 1.0, 2.0, 0.5215649810163725, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728816.3638848484, 728816.3638848478, 187044.1820415007], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5743800.0000, 
sim time next is 5744400.0000, 
raw observation next is [32.4, 56.66666666666667, 1.0, 2.0, 0.5211209160873153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728195.6306460764, 728195.6306460764, 186971.8663684944], 
processed observation next is [0.0, 0.4782608695652174, 0.7345971563981042, 0.5666666666666668, 1.0, 1.0, 0.4230372482979702, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20227656406835456, 0.20227656406835456, 0.2790624871171558], 
reward next is 0.7209, 
noisyNet noise sample is [array([0.7332247], dtype=float32), 0.32878163]. 
=============================================
[2019-03-26 12:04:05,544] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.9286689e-28 1.0000000e+00 1.8341555e-27 1.8621028e-33 4.8209272e-25], sum to 1.0000
[2019-03-26 12:04:05,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0188
[2019-03-26 12:04:05,560] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.93333333333333, 89.83333333333333, 1.0, 2.0, 0.5360785903220822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 749104.3168114576, 749104.3168114576, 189442.0911609878], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6137400.0000, 
sim time next is 6138000.0000, 
raw observation next is [26.9, 90.0, 1.0, 2.0, 0.5359879313480116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748977.5873112571, 748977.5873112571, 189426.8981917034], 
processed observation next is [1.0, 0.043478260869565216, 0.4739336492890995, 0.9, 1.0, 1.0, 0.44094931487712236, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20804932980868254, 0.20804932980868254, 0.2827267137189603], 
reward next is 0.7173, 
noisyNet noise sample is [array([-0.77291703], dtype=float32), 1.1209986]. 
=============================================
[2019-03-26 12:04:05,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.69803]
 [67.85226]
 [68.01595]
 [68.22797]
 [68.711  ]], R is [[67.68113708]
 [67.72157288]
 [67.76156616]
 [67.8010788 ]
 [67.84010315]].
[2019-03-26 12:04:06,607] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1216127: loss 2.1560
[2019-03-26 12:04:06,611] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1216127: learning rate 0.0001
[2019-03-26 12:04:07,504] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.0319330e-12 9.9960119e-01 1.5852376e-09 1.2756974e-09 3.9884108e-04], sum to 1.0000
[2019-03-26 12:04:07,512] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9894
[2019-03-26 12:04:07,523] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2241152.306570999 W.
[2019-03-26 12:04:07,528] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 80.0, 1.0, 2.0, 0.9615263305505211, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994889558599338, 6.9112, 168.9123890957739, 2241152.306570999, 2181780.252772382, 452113.1473790406], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [28.88333333333333, 79.5, 1.0, 2.0, 0.5003861165238702, 1.0, 1.0, 0.5003861165238702, 1.0, 2.0, 0.8689267425436363, 6.9112, 6.9112, 170.5573041426782, 2098998.613731604, 2098998.613731604, 415398.5262549141], 
processed observation next is [1.0, 0.43478260869565216, 0.5679304897314374, 0.795, 1.0, 1.0, 0.39805556207695203, 1.0, 0.5, 0.39805556207695203, 1.0, 1.0, 0.8401545640776051, 0.0, 0.0, 0.8375144448122397, 0.5830551704810011, 0.5830551704810011, 0.6199978003804688], 
reward next is 0.3800, 
noisyNet noise sample is [array([-1.5274541], dtype=float32), -0.030524805]. 
=============================================
[2019-03-26 12:04:07,537] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[37.97867 ]
 [36.464676]
 [36.941734]
 [36.6673  ]
 [36.85769 ]], R is [[38.49087524]
 [38.10596848]
 [37.72491074]
 [37.74263382]
 [37.7326889 ]].
[2019-03-26 12:04:07,774] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1216663: loss 1.8294
[2019-03-26 12:04:07,779] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1216664: learning rate 0.0001
[2019-03-26 12:04:09,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1080975e-15 1.0000000e+00 6.1863709e-13 4.5666867e-14 2.4537339e-09], sum to 1.0000
[2019-03-26 12:04:09,468] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3440
[2019-03-26 12:04:09,474] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.2, 79.33333333333334, 1.0, 2.0, 0.5585684835667567, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 780542.740949457, 780542.740949457, 193284.0644730782], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5937600.0000, 
sim time next is 5938200.0000, 
raw observation next is [30.1, 79.5, 1.0, 2.0, 0.5539095570806589, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 774029.9921404026, 774029.9921404033, 192476.6007790357], 
processed observation next is [1.0, 0.7391304347826086, 0.6255924170616115, 0.795, 1.0, 1.0, 0.46254163503693846, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2150083311501118, 0.215008331150112, 0.2872785086254264], 
reward next is 0.7127, 
noisyNet noise sample is [array([-2.351602], dtype=float32), -0.6906115]. 
=============================================
[2019-03-26 12:04:09,932] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1217660: loss 0.4209
[2019-03-26 12:04:09,933] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1217660: learning rate 0.0001
[2019-03-26 12:04:10,037] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1217705: loss 0.2367
[2019-03-26 12:04:10,042] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1217707: learning rate 0.0001
[2019-03-26 12:04:11,136] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1218221: loss 0.1439
[2019-03-26 12:04:11,138] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1218221: learning rate 0.0001
[2019-03-26 12:04:11,633] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218346: loss 0.3069
[2019-03-26 12:04:11,636] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218347: learning rate 0.0001
[2019-03-26 12:04:11,822] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1218431: loss 0.1246
[2019-03-26 12:04:11,824] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1218431: learning rate 0.0001
[2019-03-26 12:04:12,011] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1218517: loss 2.1319
[2019-03-26 12:04:12,015] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1218517: learning rate 0.0001
[2019-03-26 12:04:12,169] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1218590: loss 0.8012
[2019-03-26 12:04:12,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1218591: learning rate 0.0001
[2019-03-26 12:04:12,681] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218823: loss 0.3234
[2019-03-26 12:04:12,682] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218824: learning rate 0.0001
[2019-03-26 12:04:12,782] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218873: loss 0.4168
[2019-03-26 12:04:12,783] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218874: learning rate 0.0001
[2019-03-26 12:04:12,814] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1218882: loss 0.3532
[2019-03-26 12:04:12,817] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1218882: learning rate 0.0001
[2019-03-26 12:04:12,953] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1218946: loss 0.4136
[2019-03-26 12:04:12,958] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1218948: learning rate 0.0001
[2019-03-26 12:04:15,014] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0895902e-27 1.0000000e+00 9.6988514e-29 2.6095635e-37 1.5461609e-24], sum to 1.0000
[2019-03-26 12:04:15,024] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5178
[2019-03-26 12:04:15,028] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 91.83333333333334, 1.0, 2.0, 0.6992387478547796, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 977205.583323247, 977205.5833232463, 220681.1643941478], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5896200.0000, 
sim time next is 5896800.0000, 
raw observation next is [26.8, 91.0, 1.0, 2.0, 0.680065376765337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950398.2746481972, 950398.2746481972, 216601.6165847068], 
processed observation next is [1.0, 0.2608695652173913, 0.4691943127962086, 0.91, 1.0, 1.0, 0.6145365985124541, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.26399952073561034, 0.26399952073561034, 0.32328599490254745], 
reward next is 0.6767, 
noisyNet noise sample is [array([-0.23700987], dtype=float32), -0.32154617]. 
=============================================
[2019-03-26 12:04:15,943] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.2502405e-10 2.9751167e-01 4.0816763e-06 3.0361034e-06 7.0248121e-01], sum to 1.0000
[2019-03-26 12:04:15,952] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5672
[2019-03-26 12:04:15,958] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.5, 76.66666666666667, 1.0, 2.0, 0.5825468666183545, 1.0, 2.0, 0.5825468666183545, 1.0, 1.0, 1.011691256123408, 6.9112, 6.9112, 170.5573041426782, 2443998.577960798, 2443998.577960798, 476921.5804972271], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5908800.0000, 
sim time next is 5909400.0000, 
raw observation next is [30.65, 76.0, 1.0, 2.0, 0.5913946341503558, 1.0, 2.0, 0.5913946341503558, 1.0, 2.0, 1.02705690232506, 6.911199999999999, 6.9112, 170.5573041426782, 2481155.073177639, 2481155.07317764, 484099.2684274125], 
processed observation next is [1.0, 0.391304347826087, 0.6516587677725119, 0.76, 1.0, 1.0, 0.5077043784944045, 1.0, 1.0, 0.5077043784944045, 1.0, 1.0, 1.032996222347634, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6892097425493442, 0.6892097425493444, 0.7225362215334514], 
reward next is 0.2775, 
noisyNet noise sample is [array([0.23596278], dtype=float32), -0.24697609]. 
=============================================
[2019-03-26 12:04:19,381] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1221910: loss 745.9305
[2019-03-26 12:04:19,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1221912: learning rate 0.0001
[2019-03-26 12:04:21,527] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0945311e-11 9.9608010e-01 1.5666473e-08 2.8677953e-06 3.9170887e-03], sum to 1.0000
[2019-03-26 12:04:21,535] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8683
[2019-03-26 12:04:21,541] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1747684.777586405 W.
[2019-03-26 12:04:21,547] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 71.66666666666666, 1.0, 2.0, 0.4167036867757657, 1.0, 2.0, 0.4167036867757657, 1.0, 2.0, 0.7126875065563419, 6.9112, 6.9112, 170.5573041426782, 1747684.777586405, 1747684.777586405, 360703.0475295815], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6007200.0000, 
sim time next is 6007800.0000, 
raw observation next is [28.0, 72.83333333333334, 1.0, 2.0, 0.5855795778972163, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9843834779800622, 6.911199999999999, 6.9112, 168.912956510431, 1637236.009046657, 1637236.009046658, 351280.6848040765], 
processed observation next is [1.0, 0.5217391304347826, 0.5260663507109005, 0.7283333333333334, 1.0, 1.0, 0.5006982866231521, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9809554609512954, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4547877802907381, 0.4547877802907383, 0.5242995295583232], 
reward next is 0.4757, 
noisyNet noise sample is [array([0.3662723], dtype=float32), -0.23799911]. 
=============================================
[2019-03-26 12:04:22,014] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1223132: loss 1.9653
[2019-03-26 12:04:22,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1223132: learning rate 0.0001
[2019-03-26 12:04:22,319] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1223273: loss 2.3015
[2019-03-26 12:04:22,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1223273: learning rate 0.0001
[2019-03-26 12:04:23,881] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1223991: loss 1103.0920
[2019-03-26 12:04:23,885] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1223991: learning rate 0.0001
[2019-03-26 12:04:25,275] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1224646: loss 2.3082
[2019-03-26 12:04:25,277] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1224646: learning rate 0.0001
[2019-03-26 12:04:26,056] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-26 12:04:26,058] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:04:26,059] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:04:26,062] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:04:26,063] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:04:26,063] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:04:26,065] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:04:26,066] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:04:26,067] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:04:26,068] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:04:26,070] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:04:26,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-26 12:04:26,113] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-26 12:04:26,137] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-26 12:04:26,138] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-26 12:04:26,184] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-26 12:04:42,452] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3629312], dtype=float32), 0.1029348]
[2019-03-26 12:04:42,453] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.57613656666667, 75.84668869166667, 1.0, 2.0, 0.3233125876419607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 510701.7316404877, 510701.7316404877, 167824.1226847084]
[2019-03-26 12:04:42,455] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:04:42,458] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5656653e-30 1.0000000e+00 3.0132154e-31 0.0000000e+00 8.1423300e-30], sampled 0.30261615920177354
[2019-03-26 12:05:48,282] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3629312], dtype=float32), 0.1029348]
[2019-03-26 12:05:48,284] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.31666666666667, 94.0, 1.0, 2.0, 0.6213633068150072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 868327.9991581514, 868327.9991581509, 204792.9361684334]
[2019-03-26 12:05:48,286] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:05:48,288] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.2377717e-29 1.0000000e+00 3.4249905e-29 6.7948510e-36 5.2109301e-27], sampled 0.3787993667264753
[2019-03-26 12:06:10,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3629312], dtype=float32), 0.1029348]
[2019-03-26 12:06:10,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.466920975, 77.447682855, 1.0, 2.0, 0.5411374589779672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 773923.9422861103, 773923.9422861097, 192557.3672472984]
[2019-03-26 12:06:10,662] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:06:10,664] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.1722957e-31 1.0000000e+00 2.5555553e-32 0.0000000e+00 7.2017409e-31], sampled 0.8020135735922841
[2019-03-26 12:06:20,907] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.2178 3007719775.7786 1766.0000
[2019-03-26 12:06:20,929] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.7461 3164321861.2743 1815.0000
[2019-03-26 12:06:21,095] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8660.2581 2779335232.8270 937.0000
[2019-03-26 12:06:21,186] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.3535 2842555284.7523 1136.0000
[2019-03-26 12:06:21,262] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8250.8355 2927617722.7889 1355.0000
[2019-03-26 12:06:22,278] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1225000, evaluation results [1225000.0, 7882.746100696212, 3164321861.2742863, 1815.0, 8250.835483051878, 2927617722.7888856, 1355.0, 8660.258078322151, 2779335232.8269696, 937.0, 7998.217808978373, 3007719775.7785764, 1766.0, 8495.35345557986, 2842555284.752268, 1136.0]
[2019-03-26 12:06:23,712] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1225646: loss 2.5498
[2019-03-26 12:06:23,713] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1225646: learning rate 0.0001
[2019-03-26 12:06:23,806] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1225687: loss 2.2518
[2019-03-26 12:06:23,807] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1225687: learning rate 0.0001
[2019-03-26 12:06:24,745] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1226120: loss 2.2859
[2019-03-26 12:06:24,747] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1226121: learning rate 0.0001
[2019-03-26 12:06:25,124] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226291: loss 2.6327
[2019-03-26 12:06:25,126] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226292: learning rate 0.0001
[2019-03-26 12:06:25,271] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1226360: loss 1019.9473
[2019-03-26 12:06:25,274] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1226361: learning rate 0.0001
[2019-03-26 12:06:25,460] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1226444: loss 2.3103
[2019-03-26 12:06:25,468] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1226444: learning rate 0.0001
[2019-03-26 12:06:25,651] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1226526: loss 2.1460
[2019-03-26 12:06:25,652] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1226526: learning rate 0.0001
[2019-03-26 12:06:26,134] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226742: loss 2.8232
[2019-03-26 12:06:26,137] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226742: learning rate 0.0001
[2019-03-26 12:06:26,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1226884: loss 2.4240
[2019-03-26 12:06:26,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1226884: learning rate 0.0001
[2019-03-26 12:06:26,467] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226889: loss 2.3884
[2019-03-26 12:06:26,468] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226890: learning rate 0.0001
[2019-03-26 12:06:26,666] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1226976: loss 2.3208
[2019-03-26 12:06:26,668] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1226976: learning rate 0.0001
[2019-03-26 12:06:28,993] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9621218e-30 1.0000000e+00 4.0046565e-32 0.0000000e+00 4.0987484e-32], sum to 1.0000
[2019-03-26 12:06:29,001] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4248
[2019-03-26 12:06:29,007] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.33333333333333, 1.0, 2.0, 0.5242594921444128, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 732582.8763112919, 732582.8763112926, 187484.5307922745], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6338400.0000, 
sim time next is 6339000.0000, 
raw observation next is [29.15, 73.66666666666667, 1.0, 2.0, 0.5251241461963687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733791.5326141464, 733791.5326141464, 187626.3691541659], 
processed observation next is [0.0, 0.34782608695652173, 0.5805687203791469, 0.7366666666666667, 1.0, 1.0, 0.42786041710405864, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20383098128170732, 0.20383098128170732, 0.28003935694651627], 
reward next is 0.7200, 
noisyNet noise sample is [array([-0.30464518], dtype=float32), -1.534589]. 
=============================================
[2019-03-26 12:06:29,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.345665]
 [74.31243 ]
 [74.29371 ]
 [74.26269 ]
 [74.250496]], R is [[74.34382629]
 [74.32055664]
 [74.29769135]
 [74.2754364 ]
 [74.25314331]].
[2019-03-26 12:06:29,605] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.8992924e-28 1.0000000e+00 1.4842675e-28 1.5106171e-36 2.2335289e-27], sum to 1.0000
[2019-03-26 12:06:29,613] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2383
[2019-03-26 12:06:29,618] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.41666666666666, 90.83333333333334, 1.0, 2.0, 0.5222044214293757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729710.2020953537, 729710.202095353, 187148.3660790444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6227400.0000, 
sim time next is 6228000.0000, 
raw observation next is [26.4, 91.0, 1.0, 2.0, 0.5218648377209403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729235.516811192, 729235.5168111913, 187092.9816656346], 
processed observation next is [0.0, 0.08695652173913043, 0.45023696682464454, 0.91, 1.0, 1.0, 0.4239335394228196, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20256542133644223, 0.20256542133644204, 0.27924325621736507], 
reward next is 0.7208, 
noisyNet noise sample is [array([1.0145304], dtype=float32), -0.6202571]. 
=============================================
[2019-03-26 12:06:29,628] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.72081]
 [72.65184]
 [72.64047]
 [72.53059]
 [72.4805 ]], R is [[72.957901  ]
 [72.9489975 ]
 [72.94023895]
 [72.93184662]
 [72.9237442 ]].
[2019-03-26 12:06:32,704] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3679959e-30 1.0000000e+00 7.6273256e-32 0.0000000e+00 1.0182339e-31], sum to 1.0000
[2019-03-26 12:06:32,715] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1522
[2019-03-26 12:06:32,720] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.7, 74.0, 1.0, 2.0, 0.5419591470242147, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757324.6055087395, 757324.6055087395, 190431.8515311663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6256800.0000, 
sim time next is 6257400.0000, 
raw observation next is [29.85, 73.16666666666667, 1.0, 2.0, 0.541994185220643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 757373.5847509764, 757373.5847509764, 190437.789080957], 
processed observation next is [0.0, 0.43478260869565216, 0.613744075829384, 0.7316666666666667, 1.0, 1.0, 0.4481857653260759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21038155131971567, 0.21038155131971567, 0.2842355060909806], 
reward next is 0.7158, 
noisyNet noise sample is [array([-1.103447], dtype=float32), -1.7040116]. 
=============================================
[2019-03-26 12:06:33,276] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1229941: loss 0.0850
[2019-03-26 12:06:33,278] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1229941: learning rate 0.0001
[2019-03-26 12:06:34,340] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.8644243e-28 1.0000000e+00 8.3157379e-28 6.6911909e-36 1.3676328e-27], sum to 1.0000
[2019-03-26 12:06:34,351] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3513
[2019-03-26 12:06:34,356] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333333, 85.0, 1.0, 2.0, 0.5317478955359676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 743050.5834638949, 743050.5834638949, 188719.5245679506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6303000.0000, 
sim time next is 6303600.0000, 
raw observation next is [27.3, 85.0, 1.0, 2.0, 0.5301995827677464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 740886.2572201214, 740886.2572201214, 188462.7370218643], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 1.0, 1.0, 0.4339754009249956, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2058017381167004, 0.2058017381167004, 0.2812876671968124], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.6698713], dtype=float32), -0.48577082]. 
=============================================
[2019-03-26 12:06:34,408] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0025099e-29 1.0000000e+00 1.5012350e-30 0.0000000e+00 1.1332435e-30], sum to 1.0000
[2019-03-26 12:06:34,419] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2868
[2019-03-26 12:06:34,427] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.3, 77.66666666666667, 1.0, 2.0, 0.5217901511080256, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729131.1165542592, 729131.1165542586, 187080.5620797796], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6335400.0000, 
sim time next is 6336000.0000, 
raw observation next is [28.4, 77.0, 1.0, 2.0, 0.5221943287481604, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729696.0940914345, 729696.0940914345, 187146.4758004152], 
processed observation next is [0.0, 0.34782608695652173, 0.5450236966824644, 0.77, 1.0, 1.0, 0.42433051656404863, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2026933594698429, 0.2026933594698429, 0.27932309820957496], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.6219123], dtype=float32), -0.70888495]. 
=============================================
[2019-03-26 12:06:34,438] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[71.831665]
 [71.81187 ]
 [71.774734]
 [71.747604]
 [71.72724 ]], R is [[71.94348145]
 [71.94481659]
 [71.9462204 ]
 [71.94754791]
 [71.9487915 ]].
[2019-03-26 12:06:35,842] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1231053: loss 1057.0090
[2019-03-26 12:06:35,845] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1231055: learning rate 0.0001
[2019-03-26 12:06:36,253] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1231214: loss 942.4382
[2019-03-26 12:06:36,257] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1231215: learning rate 0.0001
[2019-03-26 12:06:37,494] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.096790e-31 1.000000e+00 3.300530e-32 0.000000e+00 7.113162e-33], sum to 1.0000
[2019-03-26 12:06:37,504] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6313
[2019-03-26 12:06:37,508] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5250703621992528, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733716.3506362874, 733716.3506362874, 187617.2523374262], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [30.95, 62.83333333333333, 1.0, 2.0, 0.5292061733555125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739497.6111338534, 739497.611133854, 188298.0382992323], 
processed observation next is [0.0, 0.5652173913043478, 0.6658767772511848, 0.6283333333333333, 1.0, 1.0, 0.4327785221150752, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20541600309273705, 0.20541600309273722, 0.2810418482078094], 
reward next is 0.7190, 
noisyNet noise sample is [array([-0.9007006], dtype=float32), 1.2639139]. 
=============================================
[2019-03-26 12:06:38,538] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1232265: loss 0.0075
[2019-03-26 12:06:38,539] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1232265: learning rate 0.0001
[2019-03-26 12:06:39,401] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1232659: loss 782.3292
[2019-03-26 12:06:39,402] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1232659: learning rate 0.0001
[2019-03-26 12:06:39,443] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9443375e-29 1.0000000e+00 2.1695464e-28 1.5823698e-37 1.1072803e-28], sum to 1.0000
[2019-03-26 12:06:39,454] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2263
[2019-03-26 12:06:39,458] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 76.33333333333334, 1.0, 2.0, 0.5198048218945126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 726355.9391702501, 726355.9391702507, 186756.9989314036], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6373200.0000, 
sim time next is 6373800.0000, 
raw observation next is [28.3, 77.0, 1.0, 2.0, 0.522073797086498, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 729527.6095259741, 729527.6095259741, 187126.5448271005], 
processed observation next is [0.0, 0.782608695652174, 0.5402843601895735, 0.77, 1.0, 1.0, 0.4241852976945759, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20264655820165947, 0.20264655820165947, 0.2792933504882097], 
reward next is 0.7207, 
noisyNet noise sample is [array([0.20568281], dtype=float32), -0.38480347]. 
=============================================
[2019-03-26 12:06:41,535] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1233643: loss 344.4300
[2019-03-26 12:06:41,536] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1233643: learning rate 0.0001
[2019-03-26 12:06:41,726] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1233728: loss 611.4177
[2019-03-26 12:06:41,730] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1233729: learning rate 0.0001
[2019-03-26 12:06:41,994] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.7929409e-25 1.0000000e+00 2.9433911e-24 4.9043246e-32 6.5476377e-23], sum to 1.0000
[2019-03-26 12:06:42,001] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5544
[2019-03-26 12:06:42,007] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.08333333333333, 84.66666666666667, 1.0, 2.0, 0.8095661276354895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1131473.305538636, 1131473.305538636, 246271.0952812609], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6415800.0000, 
sim time next is 6416400.0000, 
raw observation next is [27.16666666666667, 84.33333333333334, 1.0, 2.0, 0.8174522797683645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1142501.152132035, 1142501.152132035, 248238.4832001137], 
processed observation next is [1.0, 0.2608695652173913, 0.4865718799368091, 0.8433333333333334, 1.0, 1.0, 0.7800629876727283, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3173614311477875, 0.3173614311477875, 0.37050519880613986], 
reward next is 0.6295, 
noisyNet noise sample is [array([0.86195374], dtype=float32), -0.27066326]. 
=============================================
[2019-03-26 12:06:42,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.1785783e-13 9.9999928e-01 4.7455782e-09 1.0928181e-11 6.6379090e-07], sum to 1.0000
[2019-03-26 12:06:42,564] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4144
[2019-03-26 12:06:42,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2291129.396702595 W.
[2019-03-26 12:06:42,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.9972332017286223, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.981911509563856, 6.9112, 168.9125357428748, 2291129.396702595, 2240964.343078717, 463317.7731946434], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6445800.0000, 
sim time next is 6446400.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.9872345351773456, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980327621072245, 6.9112, 168.9124880117847, 2277134.568723149, 2228093.191167424, 460315.255616829], 
processed observation next is [1.0, 0.6086956521739131, 0.6208530805687204, 0.68, 1.0, 1.0, 0.9846199219004164, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0069127621072245125, 0.0, 0.8294376446094697, 0.6325373802008748, 0.6189147753242844, 0.687037694950491], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2345213], dtype=float32), -0.6043888]. 
=============================================
[2019-03-26 12:06:42,609] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1234136: loss 946.2676
[2019-03-26 12:06:42,611] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1234136: learning rate 0.0001
[2019-03-26 12:06:43,222] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234421: loss 981.9231
[2019-03-26 12:06:43,223] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234421: learning rate 0.0001
[2019-03-26 12:06:43,372] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1234491: loss 1234.2821
[2019-03-26 12:06:43,376] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1234492: learning rate 0.0001
[2019-03-26 12:06:43,588] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1234587: loss 788.4689
[2019-03-26 12:06:43,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1234588: learning rate 0.0001
[2019-03-26 12:06:43,677] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1234632: loss 0.0092
[2019-03-26 12:06:43,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1234632: learning rate 0.0001
[2019-03-26 12:06:43,853] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234711: loss 1215.8801
[2019-03-26 12:06:43,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234711: learning rate 0.0001
[2019-03-26 12:06:44,346] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234941: loss 1079.8950
[2019-03-26 12:06:44,348] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234941: learning rate 0.0001
[2019-03-26 12:06:44,523] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1235025: loss 924.6813
[2019-03-26 12:06:44,525] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1235026: learning rate 0.0001
[2019-03-26 12:06:44,545] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1235036: loss 923.7933
[2019-03-26 12:06:44,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1235036: learning rate 0.0001
[2019-03-26 12:06:44,867] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.2818262e-26 1.0000000e+00 2.6402512e-24 5.6284828e-31 1.7665931e-24], sum to 1.0000
[2019-03-26 12:06:44,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2070
[2019-03-26 12:06:44,880] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 87.66666666666667, 1.0, 2.0, 0.5308826972178836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741841.1558172234, 741841.1558172228, 188576.1381549454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6478800.0000, 
sim time next is 6479400.0000, 
raw observation next is [26.95, 87.83333333333334, 1.0, 2.0, 0.5296403702742243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740104.556893132, 740104.5568931315, 188370.3616267271], 
processed observation next is [1.0, 1.0, 0.476303317535545, 0.8783333333333334, 1.0, 1.0, 0.4333016509328003, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20558459913698113, 0.20558459913698096, 0.281149793472727], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.9683954], dtype=float32), 1.0497829]. 
=============================================
[2019-03-26 12:06:47,112] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.6347327e-12 9.9995697e-01 3.8758853e-06 8.0412485e-07 3.8314629e-05], sum to 1.0000
[2019-03-26 12:06:47,121] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1981
[2019-03-26 12:06:47,136] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2165778.029596611 W.
[2019-03-26 12:06:47,141] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.4, 58.0, 1.0, 2.0, 0.7744346545746743, 1.0, 2.0, 0.7744346545746743, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2165778.029596611, 2165778.029596611, 407607.6663112813], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6534000.0000, 
sim time next is 6534600.0000, 
raw observation next is [31.26666666666667, 58.5, 1.0, 2.0, 0.4993925454120569, 1.0, 2.0, 0.4993925454120569, 1.0, 1.0, 0.8505083217712208, 6.9112, 6.9112, 170.5573041426782, 2094826.748290354, 2094826.748290354, 411664.8853358692], 
processed observation next is [1.0, 0.6521739130434783, 0.6808846761453398, 0.585, 1.0, 1.0, 0.3968584884482613, 1.0, 1.0, 0.3968584884482613, 1.0, 0.5, 0.8176930753307571, 0.0, 0.0, 0.8375144448122397, 0.5818963189695427, 0.5818963189695427, 0.6144252019938347], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.42334405], dtype=float32), 0.3375948]. 
=============================================
[2019-03-26 12:06:50,342] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1237710: loss -143.6606
[2019-03-26 12:06:50,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1237711: learning rate 0.0001
[2019-03-26 12:06:51,721] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.0450130e-22 1.0000000e+00 1.5771782e-18 1.6536961e-24 8.6478300e-19], sum to 1.0000
[2019-03-26 12:06:51,729] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7196
[2019-03-26 12:06:51,736] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1906747.598914323 W.
[2019-03-26 12:06:51,739] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 82.0, 1.0, 2.0, 0.6818934180291939, 1.0, 1.0, 0.6818934180291939, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1906747.598914323, 1906747.598914323, 366464.5331639742], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6597000.0000, 
sim time next is 6597600.0000, 
raw observation next is [27.66666666666666, 81.0, 1.0, 2.0, 0.7103633083424077, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.979288616688372, 6.9112, 168.9125566454835, 1889630.82960088, 1841326.535843073, 387856.3874338644], 
processed observation next is [1.0, 0.34782608695652173, 0.5102685624012636, 0.81, 1.0, 1.0, 0.6510401305330213, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006808861668837185, 0.0, 0.8294379816323515, 0.5248974526669111, 0.5114795932897425, 0.5788901304983051], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.285816], dtype=float32), 0.02023182]. 
=============================================
[2019-03-26 12:06:53,361] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1239100: loss 0.0677
[2019-03-26 12:06:53,367] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1239101: learning rate 0.0001
[2019-03-26 12:06:53,785] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1239299: loss 0.0851
[2019-03-26 12:06:53,787] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1239299: learning rate 0.0001
[2019-03-26 12:06:55,142] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1239933: loss -143.2350
[2019-03-26 12:06:55,144] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1239935: learning rate 0.0001
[2019-03-26 12:06:56,757] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1240677: loss 0.2442
[2019-03-26 12:06:56,759] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1240678: learning rate 0.0001
[2019-03-26 12:06:58,884] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1241657: loss 0.1925
[2019-03-26 12:06:58,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1241657: learning rate 0.0001
[2019-03-26 12:06:59,234] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1241815: loss 0.1505
[2019-03-26 12:06:59,237] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1241816: learning rate 0.0001
[2019-03-26 12:06:59,809] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1242083: loss 0.2939
[2019-03-26 12:06:59,812] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1242083: learning rate 0.0001
[2019-03-26 12:07:00,337] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1242326: loss 2.3902
[2019-03-26 12:07:00,340] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1242327: learning rate 0.0001
[2019-03-26 12:07:00,670] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242428: loss 0.3761
[2019-03-26 12:07:00,677] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242430: learning rate 0.0001
[2019-03-26 12:07:00,799] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1242484: loss 0.3826
[2019-03-26 12:07:00,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1242485: learning rate 0.0001
[2019-03-26 12:07:01,114] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1242630: loss 0.3043
[2019-03-26 12:07:01,116] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1242630: learning rate 0.0001
[2019-03-26 12:07:01,407] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242767: loss 0.3167
[2019-03-26 12:07:01,408] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242767: learning rate 0.0001
[2019-03-26 12:07:01,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.0543629e-27 1.0000000e+00 3.0659142e-23 2.0968725e-32 8.9799182e-25], sum to 1.0000
[2019-03-26 12:07:01,913] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2724
[2019-03-26 12:07:01,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.35, 91.0, 1.0, 2.0, 0.3538511214882691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545368.6149059576, 545368.6149059576, 170268.0646785123], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7252200.0000, 
sim time next is 7252800.0000, 
raw observation next is [22.33333333333334, 91.0, 1.0, 2.0, 0.353565798138615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 545187.9630247415, 545187.9630247422, 170260.4023362571], 
processed observation next is [1.0, 0.9565217391304348, 0.2575039494470777, 0.91, 1.0, 1.0, 0.22116361221519878, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15144110084020598, 0.15144110084020618, 0.2541200034869509], 
reward next is 0.7459, 
noisyNet noise sample is [array([-1.1283226], dtype=float32), 1.2063997]. 
=============================================
[2019-03-26 12:07:01,928] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1243005: loss 0.2213
[2019-03-26 12:07:01,932] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1243006: learning rate 0.0001
[2019-03-26 12:07:02,064] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1243069: loss 0.2208
[2019-03-26 12:07:02,066] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1243069: learning rate 0.0001
[2019-03-26 12:07:02,136] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1243102: loss 0.2468
[2019-03-26 12:07:02,138] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1243102: learning rate 0.0001
[2019-03-26 12:07:07,856] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1245761: loss 0.0771
[2019-03-26 12:07:07,859] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1245761: learning rate 0.0001
[2019-03-26 12:07:09,309] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.37674463e-12 9.99870300e-01 1.19481316e-04 3.92455746e-07
 9.87460589e-06], sum to 1.0000
[2019-03-26 12:07:09,316] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0085
[2019-03-26 12:07:09,325] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2031773.563577881 W.
[2019-03-26 12:07:09,330] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 83.16666666666667, 1.0, 2.0, 0.7265629998210865, 1.0, 2.0, 0.7265629998210865, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2031773.563577881, 2031773.563577881, 385709.019008117], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7204200.0000, 
sim time next is 7204800.0000, 
raw observation next is [29.0, 82.33333333333334, 1.0, 2.0, 0.6919540356938269, 1.0, 2.0, 0.6919540356938269, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1934905.050033623, 1934905.050033623, 370704.5650141688], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.8233333333333335, 1.0, 1.0, 0.628860283968466, 1.0, 1.0, 0.628860283968466, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5374736250093397, 0.5374736250093397, 0.5532903955435355], 
reward next is 0.4467, 
noisyNet noise sample is [array([-0.05283469], dtype=float32), -0.6674369]. 
=============================================
[2019-03-26 12:07:09,946] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6868815e-28 1.0000000e+00 2.8065321e-27 1.0668734e-36 1.9077055e-29], sum to 1.0000
[2019-03-26 12:07:09,957] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8287
[2019-03-26 12:07:09,965] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 60.5, 1.0, 2.0, 0.4520916020901946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 643256.9570040583, 643256.9570040583, 177918.9500055508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6949800.0000, 
sim time next is 6950400.0000, 
raw observation next is [29.7, 60.0, 1.0, 2.0, 0.4541582517543982, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 644943.6896082959, 644943.6896082959, 178059.7220311403], 
processed observation next is [0.0, 0.43478260869565216, 0.6066350710900474, 0.6, 1.0, 1.0, 0.3423593394631304, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1791510248911933, 0.1791510248911933, 0.26576077915095564], 
reward next is 0.7342, 
noisyNet noise sample is [array([0.30087125], dtype=float32), -0.7748282]. 
=============================================
[2019-03-26 12:07:10,694] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1247075: loss -11.2458
[2019-03-26 12:07:10,698] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1247076: learning rate 0.0001
[2019-03-26 12:07:11,176] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1247298: loss -40.8758
[2019-03-26 12:07:11,177] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1247298: learning rate 0.0001
[2019-03-26 12:07:12,267] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.2697306e-30 1.0000000e+00 1.5789891e-27 2.3748825e-38 2.0762030e-31], sum to 1.0000
[2019-03-26 12:07:12,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6073
[2019-03-26 12:07:12,282] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 52.0, 1.0, 2.0, 0.4749011103075036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 663589.5628702575, 663589.5628702568, 179757.0766193429], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [31.81666666666667, 52.0, 1.0, 2.0, 0.4724327452287946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660139.3914418204, 660139.3914418198, 179389.367344515], 
processed observation next is [0.0, 0.5652173913043478, 0.7069510268562403, 0.52, 1.0, 1.0, 0.3643768014804754, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18337205317828345, 0.18337205317828328, 0.2677453243947985], 
reward next is 0.7323, 
noisyNet noise sample is [array([0.4268887], dtype=float32), 0.7165584]. 
=============================================
[2019-03-26 12:07:12,650] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1247985: loss 0.1060
[2019-03-26 12:07:12,651] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1247985: learning rate 0.0001
[2019-03-26 12:07:14,197] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1248701: loss -70.5380
[2019-03-26 12:07:14,199] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1248702: learning rate 0.0001
[2019-03-26 12:07:15,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.7303464e-13 9.9999988e-01 5.9631923e-08 8.2848216e-12 4.9113931e-09], sum to 1.0000
[2019-03-26 12:07:15,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8695
[2019-03-26 12:07:15,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1842990.561737911 W.
[2019-03-26 12:07:15,560] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.45, 82.0, 1.0, 2.0, 0.6591121412017752, 1.0, 2.0, 0.6591121412017752, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1842990.561737911, 1842990.561737911, 357100.0929239188], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7137000.0000, 
sim time next is 7137600.0000, 
raw observation next is [26.43333333333333, 82.33333333333333, 1.0, 2.0, 0.4395079674397054, 1.0, 2.0, 0.4395079674397054, 1.0, 1.0, 0.7414127344523529, 6.911199999999999, 6.9112, 170.5573041426782, 1843409.816409786, 1843409.816409787, 372348.5344369742], 
processed observation next is [1.0, 0.6086956521739131, 0.4518167456556081, 0.8233333333333333, 1.0, 1.0, 0.3247083945056692, 1.0, 1.0, 0.3247083945056692, 1.0, 0.5, 0.684649676161406, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5120582823360517, 0.5120582823360519, 0.5557440812492153], 
reward next is 0.4443, 
noisyNet noise sample is [array([0.6584015], dtype=float32), 0.920212]. 
=============================================
[2019-03-26 12:07:16,266] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1249609: loss -73.3450
[2019-03-26 12:07:16,270] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1249611: learning rate 0.0001
[2019-03-26 12:07:16,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.7654995e-11 9.9927312e-01 6.0979422e-04 2.0524752e-05 9.6654476e-05], sum to 1.0000
[2019-03-26 12:07:16,706] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7182
[2019-03-26 12:07:16,714] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1883048.674485103 W.
[2019-03-26 12:07:16,721] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.93333333333334, 57.33333333333334, 1.0, 2.0, 0.6929242541029814, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.94824868298862, 6.9112, 168.9127035159229, 1883048.674485103, 1856765.103022791, 387021.0342192482], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7035600.0000, 
sim time next is 7036200.0000, 
raw observation next is [30.1, 56.5, 1.0, 2.0, 0.6821196906249958, 1.0, 1.0, 0.6821196906249958, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1910741.250701196, 1910741.250701196, 366970.8628326636], 
processed observation next is [1.0, 0.43478260869565216, 0.6255924170616115, 0.565, 1.0, 1.0, 0.6170116754518021, 1.0, 0.5, 0.6170116754518021, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.53076145852811, 0.53076145852811, 0.5477177057203934], 
reward next is 0.4523, 
noisyNet noise sample is [array([-0.09874472], dtype=float32), -0.9827107]. 
=============================================
[2019-03-26 12:07:16,798] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1249854: loss 57.9611
[2019-03-26 12:07:16,803] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1249856: learning rate 0.0001
[2019-03-26 12:07:17,113] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 12:07:17,116] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:07:17,116] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:07:17,117] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:07:17,117] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:07:17,118] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:07:17,120] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:07:17,118] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:07:17,121] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:07:17,121] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:07:17,124] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:07:17,155] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-26 12:07:17,157] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-26 12:07:17,157] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-26 12:07:17,176] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-26 12:07:17,196] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-26 12:07:42,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:07:42,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.34635961166666, 77.84694946833334, 1.0, 2.0, 0.7825798486140537, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1119184.835038544, 1119184.835038543, 243211.7376510573]
[2019-03-26 12:07:42,055] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:07:42,058] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.9462427e-24 1.0000000e+00 1.5605037e-20 1.0817374e-28 7.6392697e-23], sampled 0.03317795867442863
[2019-03-26 12:07:48,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:07:48,484] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.40436745166667, 80.85153826166668, 1.0, 2.0, 0.5154847112419803, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720317.1303127904, 720317.1303127898, 186055.035901317]
[2019-03-26 12:07:48,484] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:07:48,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.3372019e-27 1.0000000e+00 1.1798259e-23 1.7420859e-32 5.0118567e-27], sampled 0.007262669838350777
[2019-03-26 12:07:50,642] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:07:50,643] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.35, 73.33333333333334, 1.0, 2.0, 0.418100670773231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 614646.2122801897, 614646.2122801892, 175650.5568811536]
[2019-03-26 12:07:50,646] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:07:50,649] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.8009018e-26 1.0000000e+00 1.1113801e-22 2.8138161e-31 1.0808234e-25], sampled 0.5223827714026589
[2019-03-26 12:08:19,484] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:08:19,486] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.8, 43.66666666666667, 1.0, 2.0, 1.00232301254452, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1401053.723520481, 1401053.723520481, 299636.338993779]
[2019-03-26 12:08:19,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:08:19,489] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.3105955e-23 1.0000000e+00 1.2473931e-19 1.1921472e-27 6.9048533e-22], sampled 0.2165116080032763
[2019-03-26 12:08:38,147] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:08:38,150] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.16666666666667, 64.83333333333333, 1.0, 2.0, 0.8260740394397763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1154557.789508247, 1154557.789508246, 250419.5213239396]
[2019-03-26 12:08:38,151] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:08:38,156] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.6381612e-28 1.0000000e+00 4.4352526e-25 9.6607154e-35 2.2431666e-29], sampled 0.5993972786112725
[2019-03-26 12:08:45,028] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:08:45,029] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.36901949, 58.65620496833333, 1.0, 2.0, 0.4591156268121739, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 660733.2796347342, 660733.2796347347, 179893.8026053731]
[2019-03-26 12:08:45,030] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:08:45,033] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.8563977e-26 1.0000000e+00 2.8292634e-22 2.7235339e-30 6.5013596e-26], sampled 0.022822547221407308
[2019-03-26 12:09:01,177] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.37705076], dtype=float32), 0.10714436]
[2019-03-26 12:09:01,178] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.89845913, 72.65067182, 1.0, 2.0, 0.5566945528039188, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832614.073054932, 832614.073054932, 199740.6563562652]
[2019-03-26 12:09:01,180] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:09:01,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6400235e-27 1.0000000e+00 8.0647918e-25 1.6744770e-34 4.1805381e-28], sampled 0.794268652738269
[2019-03-26 12:09:12,486] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.2157 2842323572.9012 1129.0000
[2019-03-26 12:09:12,601] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7892.3937 3163307875.3497 1757.0000
[2019-03-26 12:09:12,613] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7997.2642 3007620498.3538 1765.0000
[2019-03-26 12:09:12,696] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0720 2927319351.6016 1338.0000
[2019-03-26 12:09:12,713] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.4816 2779214513.8830 932.0000
[2019-03-26 12:09:13,730] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1250000, evaluation results [1250000.0, 7892.393675143902, 3163307875.3497143, 1757.0, 8255.071999720065, 2927319351.601612, 1338.0, 8661.481550829723, 2779214513.8830447, 932.0, 7997.264214226578, 3007620498.3537755, 1765.0, 8497.215690473433, 2842323572.9012284, 1129.0]
[2019-03-26 12:09:13,856] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1250066: loss -26.0863
[2019-03-26 12:09:13,861] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1250068: learning rate 0.0001
[2019-03-26 12:09:14,582] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250401: loss -87.8441
[2019-03-26 12:09:14,583] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250402: learning rate 0.0001
[2019-03-26 12:09:14,767] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1250487: loss 0.3513
[2019-03-26 12:09:14,771] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1250487: learning rate 0.0001
[2019-03-26 12:09:14,797] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1250496: loss -69.6868
[2019-03-26 12:09:14,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1250496: learning rate 0.0001
[2019-03-26 12:09:14,997] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1250585: loss -85.3984
[2019-03-26 12:09:15,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1250586: learning rate 0.0001
[2019-03-26 12:09:15,450] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250786: loss -190.0522
[2019-03-26 12:09:15,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250787: learning rate 0.0001
[2019-03-26 12:09:15,961] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1251008: loss -17.6803
[2019-03-26 12:09:15,964] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1251009: learning rate 0.0001
[2019-03-26 12:09:15,975] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1251017: loss -104.7991
[2019-03-26 12:09:15,977] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1251019: learning rate 0.0001
[2019-03-26 12:09:16,036] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1251048: loss -41.9427
[2019-03-26 12:09:16,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1251048: learning rate 0.0001
[2019-03-26 12:09:21,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1253601: loss -11.6840
[2019-03-26 12:09:21,718] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1253602: learning rate 0.0001
[2019-03-26 12:09:24,034] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1298343e-09 7.6529086e-01 2.1554340e-01 3.5382826e-03 1.5627461e-02], sum to 1.0000
[2019-03-26 12:09:24,045] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3791
[2019-03-26 12:09:24,056] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1985426.792193775 W.
[2019-03-26 12:09:24,065] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 82.33333333333334, 1.0, 2.0, 0.7788165597136898, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005980161895797, 6.9112, 168.9123931892549, 1985426.792193775, 1918186.707508501, 402658.0618620425], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7204800.0000, 
sim time next is 7205400.0000, 
raw observation next is [29.0, 81.5, 1.0, 2.0, 0.4702039888381712, 1.0, 1.0, 0.4702039888381712, 1.0, 2.0, 0.8165888297766329, 6.9112, 6.9112, 170.5573041426782, 1972275.350817904, 1972275.350817904, 395153.0192963965], 
processed observation next is [1.0, 0.391304347826087, 0.5734597156398105, 0.815, 1.0, 1.0, 0.36169155281707377, 1.0, 0.5, 0.36169155281707377, 1.0, 1.0, 0.7763278411910156, 0.0, 0.0, 0.8375144448122397, 0.5478542641160845, 0.5478542641160845, 0.5897806258155172], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4416125], dtype=float32), 0.3417203]. 
=============================================
[2019-03-26 12:09:24,959] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1255065: loss 0.0547
[2019-03-26 12:09:24,962] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1255066: learning rate 0.0001
[2019-03-26 12:09:25,360] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1255245: loss 0.0366
[2019-03-26 12:09:25,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1255245: learning rate 0.0001
[2019-03-26 12:09:25,889] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.6500969e-28 1.0000000e+00 2.9231954e-23 2.5487766e-34 3.5825896e-28], sum to 1.0000
[2019-03-26 12:09:25,902] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9771
[2019-03-26 12:09:25,906] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.76666666666667, 88.66666666666666, 1.0, 2.0, 0.3197133659820682, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 504201.505626397, 504201.5056263963, 167313.5342132773], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7267200.0000, 
sim time next is 7267800.0000, 
raw observation next is [21.73333333333333, 88.83333333333334, 1.0, 2.0, 0.3181189687245081, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501836.8215141516, 501836.8215141523, 167138.3804371663], 
processed observation next is [1.0, 0.08695652173913043, 0.22906793048973137, 0.8883333333333334, 1.0, 1.0, 0.17845658882470858, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13939911708726432, 0.13939911708726452, 0.24946026930920345], 
reward next is 0.7505, 
noisyNet noise sample is [array([-1.9006239], dtype=float32), 1.0424562]. 
=============================================
[2019-03-26 12:09:26,662] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1255803: loss -0.8372
[2019-03-26 12:09:26,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1255804: learning rate 0.0001
[2019-03-26 12:09:28,626] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1256649: loss 0.0206
[2019-03-26 12:09:28,627] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1256649: learning rate 0.0001
[2019-03-26 12:09:30,542] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1257550: loss 0.0097
[2019-03-26 12:09:30,547] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1257552: learning rate 0.0001
[2019-03-26 12:09:31,073] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1257795: loss 0.0105
[2019-03-26 12:09:31,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1257796: learning rate 0.0001
[2019-03-26 12:09:31,558] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1258016: loss 0.0091
[2019-03-26 12:09:31,559] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1258017: learning rate 0.0001
[2019-03-26 12:09:32,266] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258342: loss 0.0171
[2019-03-26 12:09:32,268] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258342: learning rate 0.0001
[2019-03-26 12:09:32,302] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1258359: loss -94.8979
[2019-03-26 12:09:32,306] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1258360: learning rate 0.0001
[2019-03-26 12:09:32,684] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1258536: loss 0.0088
[2019-03-26 12:09:32,688] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1258537: learning rate 0.0001
[2019-03-26 12:09:32,868] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1258620: loss 0.0092
[2019-03-26 12:09:32,870] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1258620: learning rate 0.0001
[2019-03-26 12:09:33,141] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258745: loss 0.0125
[2019-03-26 12:09:33,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258745: learning rate 0.0001
[2019-03-26 12:09:33,861] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1259076: loss 0.0153
[2019-03-26 12:09:33,863] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1259076: learning rate 0.0001
[2019-03-26 12:09:33,880] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1259084: loss 0.0188
[2019-03-26 12:09:33,886] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1259084: learning rate 0.0001
[2019-03-26 12:09:33,933] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1259113: loss 0.0220
[2019-03-26 12:09:33,935] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1259114: learning rate 0.0001
[2019-03-26 12:09:35,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0582972e-27 1.0000000e+00 2.8032651e-22 4.8421448e-31 9.4233700e-26], sum to 1.0000
[2019-03-26 12:09:35,585] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8300
[2019-03-26 12:09:35,591] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 93.33333333333334, 1.0, 2.0, 0.3177128470433545, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 501348.4929683455, 501348.4929683455, 167104.9131622994], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7431600.0000, 
sim time next is 7432200.0000, 
raw observation next is [21.2, 93.0, 1.0, 2.0, 0.3175842133169536, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 501227.6205230787, 501227.6205230793, 167097.5703452879], 
processed observation next is [0.0, 0.0, 0.20379146919431282, 0.93, 1.0, 1.0, 0.17781230520114888, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13922989458974408, 0.13922989458974425, 0.24939935872431032], 
reward next is 0.7506, 
noisyNet noise sample is [array([0.10801611], dtype=float32), 2.1314056]. 
=============================================
[2019-03-26 12:09:40,437] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:09:40,438] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:09:40,506] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-26 12:09:41,699] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1262935: loss -39.2441
[2019-03-26 12:09:41,701] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1262935: learning rate 0.0001
[2019-03-26 12:09:42,116] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1263121: loss -213.6784
[2019-03-26 12:09:42,119] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1263122: learning rate 0.0001
[2019-03-26 12:09:44,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2336646e-27 1.0000000e+00 2.0156664e-24 2.7974474e-34 1.3274932e-27], sum to 1.0000
[2019-03-26 12:09:44,273] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5021
[2019-03-26 12:09:44,280] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 87.0, 1.0, 2.0, 0.4894267325398958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 683893.0615516657, 683893.0615516651, 181955.9810322973], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7590600.0000, 
sim time next is 7591200.0000, 
raw observation next is [25.93333333333333, 87.33333333333334, 1.0, 2.0, 0.488751183620441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 682948.7900184183, 682948.7900184183, 181852.3147598252], 
processed observation next is [0.0, 0.8695652173913043, 0.42812006319115314, 0.8733333333333334, 1.0, 1.0, 0.3840375706270373, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18970799722733842, 0.18970799722733842, 0.27142136531317196], 
reward next is 0.7286, 
noisyNet noise sample is [array([0.05106265], dtype=float32), 0.31919235]. 
=============================================
[2019-03-26 12:09:44,780] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:09:44,780] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:09:44,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-26 12:09:45,047] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1264480: loss 4.3593
[2019-03-26 12:09:45,049] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1264480: learning rate 0.0001
[2019-03-26 12:09:45,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1825656e-25 1.0000000e+00 2.9821076e-19 5.6922913e-30 1.5974876e-25], sum to 1.0000
[2019-03-26 12:09:45,152] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7773
[2019-03-26 12:09:45,156] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.46666666666667, 83.33333333333333, 1.0, 2.0, 0.4800767597871972, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670823.8929593457, 670823.8929593457, 180533.6597838228], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7587600.0000, 
sim time next is 7588200.0000, 
raw observation next is [26.33333333333333, 84.66666666666667, 1.0, 2.0, 0.4823736008480358, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674034.3476372827, 674034.3476372827, 180880.7620085391], 
processed observation next is [0.0, 0.8260869565217391, 0.44707740916271704, 0.8466666666666667, 1.0, 1.0, 0.3763537359614889, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18723176323257854, 0.18723176323257854, 0.2699712865799091], 
reward next is 0.7300, 
noisyNet noise sample is [array([-2.8620207], dtype=float32), 0.472259]. 
=============================================
[2019-03-26 12:09:46,704] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1265364: loss 8.1148
[2019-03-26 12:09:46,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1265364: learning rate 0.0001
[2019-03-26 12:09:47,186] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1265589: loss -181.4949
[2019-03-26 12:09:47,193] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1265589: learning rate 0.0001
[2019-03-26 12:09:47,611] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1265783: loss -14.6793
[2019-03-26 12:09:47,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1265783: learning rate 0.0001
[2019-03-26 12:09:48,462] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266176: loss 1.0393
[2019-03-26 12:09:48,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266176: learning rate 0.0001
[2019-03-26 12:09:48,763] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1266316: loss 3.0907
[2019-03-26 12:09:48,765] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1266316: learning rate 0.0001
[2019-03-26 12:09:49,021] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1266437: loss -39.1371
[2019-03-26 12:09:49,029] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1266437: learning rate 0.0001
[2019-03-26 12:09:49,046] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1266447: loss 2.4291
[2019-03-26 12:09:49,048] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1266448: learning rate 0.0001
[2019-03-26 12:09:49,790] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:09:49,791] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:09:49,856] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-26 12:09:49,932] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1266847: loss -40.5131
[2019-03-26 12:09:49,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1266847: learning rate 0.0001
[2019-03-26 12:09:49,975] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266869: loss 1.9543
[2019-03-26 12:09:49,977] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266870: learning rate 0.0001
[2019-03-26 12:09:50,047] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1266910: loss -61.6972
[2019-03-26 12:09:50,048] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1266911: learning rate 0.0001
[2019-03-26 12:09:51,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.29222194e-22 1.00000000e+00 7.79481816e-15 3.21396823e-24
 1.08989094e-17], sum to 1.0000
[2019-03-26 12:09:51,285] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7507
[2019-03-26 12:09:51,297] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 88.33333333333334, 1.0, 2.0, 0.5117471010429623, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 715092.5896172201, 715092.5896172201, 185457.0375287665], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7777200.0000, 
sim time next is 7777800.0000, 
raw observation next is [26.4, 88.0, 1.0, 2.0, 0.5101332702930573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 712836.7378048967, 712836.737804896, 185198.9423960287], 
processed observation next is [1.0, 0.0, 0.45023696682464454, 0.88, 1.0, 1.0, 0.4097991208350088, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19801020494580462, 0.19801020494580443, 0.2764163319343712], 
reward next is 0.7236, 
noisyNet noise sample is [array([1.5084321], dtype=float32), -0.0052502174]. 
=============================================
[2019-03-26 12:09:58,716] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:09:58,716] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:09:58,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-26 12:09:59,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:09:59,028] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:09:59,074] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-26 12:10:01,415] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:01,416] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:01,489] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-26 12:10:03,121] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:03,122] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:03,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-26 12:10:03,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:03,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:03,455] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-26 12:10:03,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:03,689] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:03,743] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-26 12:10:04,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:04,294] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:04,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-26 12:10:04,522] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:04,523] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:04,535] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-26 12:10:04,594] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:04,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:04,616] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-26 12:10:04,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:04,713] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:04,744] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-26 12:10:05,128] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:05,128] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,144] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-26 12:10:05,213] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:05,215] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,251] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-26 12:10:05,284] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:10:05,285] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,289] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-26 12:10:05,667] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 12:10:05,668] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:10:05,668] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,672] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:10:05,673] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:10:05,674] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,674] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:10:05,673] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,675] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:10:05,675] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,675] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:10:05,683] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-26 12:10:05,684] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-26 12:10:05,726] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-26 12:10:05,748] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-26 12:10:05,765] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-26 12:10:09,441] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.38985142], dtype=float32), 0.11779063]
[2019-03-26 12:10:09,444] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.06666666666667, 96.0, 1.0, 2.0, 0.2946152574974321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 472899.1159788866, 472899.1159788866, 165158.8503494025]
[2019-03-26 12:10:09,445] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:10:09,447] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.4192836e-28 1.0000000e+00 2.9081692e-23 2.0054545e-35 2.3959524e-27], sampled 0.8345449822515336
[2019-03-26 12:10:46,682] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.38985142], dtype=float32), 0.11779063]
[2019-03-26 12:10:46,685] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.05, 54.16666666666666, 1.0, 2.0, 0.8624966826163162, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1205492.592126484, 1205492.592126484, 259829.2104796269]
[2019-03-26 12:10:46,686] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:10:46,689] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7476726e-24 1.0000000e+00 7.1881437e-19 5.8826703e-30 5.4273777e-22], sampled 0.13476387664662637
[2019-03-26 12:11:05,845] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.38985142], dtype=float32), 0.11779063]
[2019-03-26 12:11:05,847] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [35.0, 59.33333333333333, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.757517079211045, 6.9112, 170.5573041426782, 3516287.31013674, 2910035.960320146, 548869.8148838688]
[2019-03-26 12:11:05,849] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:11:05,853] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.8755272e-10 1.1337348e-01 8.6936623e-01 1.7967728e-05 1.7242284e-02], sampled 0.10787274798852231
[2019-03-26 12:11:05,855] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3516287.31013674 W.
[2019-03-26 12:11:20,480] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.38985142], dtype=float32), 0.11779063]
[2019-03-26 12:11:20,481] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.2, 56.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.942698778287543, 6.9112, 168.9126374210967, 1476116.506197175, 1453770.230989591, 311355.9555017462]
[2019-03-26 12:11:20,483] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:11:20,486] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2561398e-21 1.0000000e+00 1.5744035e-15 1.4506888e-25 1.9497183e-18], sampled 0.10839392378730694
[2019-03-26 12:11:59,799] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0902 2927292587.5938 1338.0000
[2019-03-26 12:11:59,899] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7996.7984 3007744657.5932 1766.0000
[2019-03-26 12:12:00,304] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.6244 2779280347.8370 934.0000
[2019-03-26 12:12:00,355] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.5385 2842476554.9448 1131.0000
[2019-03-26 12:12:00,356] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.1371 3163997012.1027 1781.0000
[2019-03-26 12:12:01,374] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1275000, evaluation results [1275000.0, 7882.137142810602, 3163997012.102689, 1781.0, 8255.090159210982, 2927292587.593827, 1338.0, 8659.624355645092, 2779280347.8370476, 934.0, 7996.7983663685945, 3007744657.5931916, 1766.0, 8497.538503793214, 2842476554.944838, 1131.0]
[2019-03-26 12:12:07,388] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5677013e-25 1.0000000e+00 2.7872096e-20 3.2954726e-32 5.5343965e-24], sum to 1.0000
[2019-03-26 12:12:07,398] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1352
[2019-03-26 12:12:07,403] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.3892994580637094, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599667.7422333704, 599667.7422333698, 174970.4936730671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 99000.0000, 
sim time next is 99600.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.3837474741719324, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 591120.1740616008, 591120.1740616008, 174207.1257026495], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.25752707731558117, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16420004835044466, 0.16420004835044466, 0.2600106353770888], 
reward next is 0.7400, 
noisyNet noise sample is [array([-0.0591416], dtype=float32), 1.4954145]. 
=============================================
[2019-03-26 12:12:15,699] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.8772933e-25 1.0000000e+00 2.0516602e-18 7.5891641e-31 1.4638493e-22], sum to 1.0000
[2019-03-26 12:12:15,708] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3631
[2019-03-26 12:12:15,714] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.15, 72.5, 1.0, 2.0, 0.24277941807949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 400902.2784614968, 400902.2784614962, 160151.2920609879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 589800.0000, 
sim time next is 590400.0000, 
raw observation next is [21.0, 73.0, 1.0, 2.0, 0.2414860320580799, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 399087.1499936656, 399087.1499936663, 160008.93160913], 
processed observation next is [1.0, 0.8695652173913043, 0.19431279620853087, 0.73, 1.0, 1.0, 0.08612774946756613, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1108575416649071, 0.1108575416649073, 0.23881930090914924], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.16880107], dtype=float32), -0.421636]. 
=============================================
[2019-03-26 12:12:20,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.6481586e-26 1.0000000e+00 9.9413195e-22 1.2461382e-33 9.0386088e-27], sum to 1.0000
[2019-03-26 12:12:20,602] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4527
[2019-03-26 12:12:20,609] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.53333333333333, 79.33333333333334, 1.0, 2.0, 0.298073151873832, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 474982.3846607098, 474982.3846607105, 165269.4648284748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 321000.0000, 
sim time next is 321600.0000, 
raw observation next is [22.46666666666667, 79.66666666666667, 1.0, 2.0, 0.297148701371844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 473710.9967790074, 473710.9967790081, 165182.6205214337], 
processed observation next is [0.0, 0.7391304347826086, 0.2638230647709322, 0.7966666666666667, 1.0, 1.0, 0.15319120647210122, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13158638799416872, 0.1315863879941689, 0.24654122465885628], 
reward next is 0.7535, 
noisyNet noise sample is [array([-1.2598047], dtype=float32), -0.37234768]. 
=============================================
[2019-03-26 12:12:20,873] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8572469e-23 1.0000000e+00 6.2145881e-17 5.2021486e-28 1.4030644e-20], sum to 1.0000
[2019-03-26 12:12:20,883] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2720
[2019-03-26 12:12:20,889] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.35, 89.0, 1.0, 2.0, 0.3020354382085937, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 480360.7102689046, 480360.710268904, 165637.8022522679], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 865800.0000, 
sim time next is 866400.0000, 
raw observation next is [21.33333333333333, 89.0, 1.0, 2.0, 0.3015227486900099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 479719.5905491434, 479719.5905491434, 165594.7765265664], 
processed observation next is [0.0, 0.0, 0.21011058451816728, 0.89, 1.0, 1.0, 0.1584611430000119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13325544181920648, 0.13325544181920648, 0.24715638287547223], 
reward next is 0.7528, 
noisyNet noise sample is [array([1.7604481], dtype=float32), -1.3835337]. 
=============================================
[2019-03-26 12:12:21,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.3448654e-25 1.0000000e+00 1.7776843e-19 2.0921217e-29 7.5259178e-22], sum to 1.0000
[2019-03-26 12:12:21,771] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3173
[2019-03-26 12:12:21,776] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.4, 84.0, 1.0, 2.0, 0.2367450751573401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 391936.0690190203, 391936.0690190203, 159508.0170305053], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 511200.0000, 
sim time next is 511800.0000, 
raw observation next is [19.31666666666667, 84.5, 1.0, 2.0, 0.2362766085890909, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 391222.0854305044, 391222.0854305038, 159458.5156744316], 
processed observation next is [1.0, 0.9565217391304348, 0.11453396524486593, 0.845, 1.0, 1.0, 0.07985133564950708, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10867280150847344, 0.10867280150847329, 0.23799778458870388], 
reward next is 0.7620, 
noisyNet noise sample is [array([-0.44513208], dtype=float32), 0.20386761]. 
=============================================
[2019-03-26 12:12:24,011] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4158100e-23 1.0000000e+00 4.4432106e-18 5.5585633e-30 8.5673754e-21], sum to 1.0000
[2019-03-26 12:12:24,024] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-26 12:12:24,030] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.5, 72.5, 1.0, 2.0, 0.4965086228834334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805997.263182062, 805997.263182062, 194947.0584556145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 387000.0000, 
sim time next is 387600.0000, 
raw observation next is [22.53333333333333, 72.66666666666667, 1.0, 2.0, 0.5027148553256369, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815320.8419876557, 815320.8419876557, 196029.2655666828], 
processed observation next is [1.0, 0.4782608695652174, 0.26698262243285936, 0.7266666666666667, 1.0, 1.0, 0.4008612714766709, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2264780116632377, 0.2264780116632377, 0.29258099338310867], 
reward next is 0.7074, 
noisyNet noise sample is [array([1.55396], dtype=float32), 1.1085962]. 
=============================================
[2019-03-26 12:12:26,073] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2827372e-25 1.0000000e+00 2.5304763e-19 2.5029844e-31 9.5612300e-24], sum to 1.0000
[2019-03-26 12:12:26,083] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4184
[2019-03-26 12:12:26,087] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 57.0, 1.0, 2.0, 0.3635119540660886, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594544.1725442765, 594544.1725442759, 174315.8896779703], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 478800.0000, 
sim time next is 479400.0000, 
raw observation next is [24.65, 56.33333333333333, 1.0, 2.0, 0.4835530432168294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 790551.8589840526, 790551.8589840526, 192854.9999312984], 
processed observation next is [1.0, 0.5652173913043478, 0.3672985781990521, 0.5633333333333332, 1.0, 1.0, 0.3777747508636499, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21959773860668128, 0.21959773860668128, 0.28784328347954985], 
reward next is 0.7122, 
noisyNet noise sample is [array([-1.3282773], dtype=float32), 3.23445]. 
=============================================
[2019-03-26 12:12:26,892] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5492979e-29 1.0000000e+00 3.0960456e-25 3.5296130e-38 6.5623710e-29], sum to 1.0000
[2019-03-26 12:12:26,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3380
[2019-03-26 12:12:26,908] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 80.5, 1.0, 2.0, 0.2435427851892651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 401270.2285228275, 401270.2285228275, 160261.07886859], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 459000.0000, 
sim time next is 459600.0000, 
raw observation next is [20.33333333333333, 80.33333333333333, 1.0, 2.0, 0.2443283175102852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 402511.2493185347, 402511.249318534, 160338.3618880211], 
processed observation next is [1.0, 0.30434782608695654, 0.16271721958925733, 0.8033333333333332, 1.0, 1.0, 0.08955218977142793, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11180868036625963, 0.11180868036625945, 0.23931098789256883], 
reward next is 0.7607, 
noisyNet noise sample is [array([-2.3432224], dtype=float32), -0.3259864]. 
=============================================
[2019-03-26 12:12:27,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.8418266e-28 1.0000000e+00 3.0696004e-23 1.7300823e-36 5.8801665e-27], sum to 1.0000
[2019-03-26 12:12:27,781] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6276
[2019-03-26 12:12:27,786] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.68333333333333, 83.16666666666667, 1.0, 2.0, 0.2306033050243999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 381086.0892401392, 381086.0892401392, 158990.3042123528], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 445800.0000, 
sim time next is 446400.0000, 
raw observation next is [19.7, 83.0, 1.0, 2.0, 0.2300859453973368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 380247.7930478861, 380247.7930478854, 158941.7683913859], 
processed observation next is [1.0, 0.17391304347826086, 0.1327014218009479, 0.83, 1.0, 1.0, 0.07239270529799612, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10562438695774615, 0.10562438695774595, 0.23722651998714314], 
reward next is 0.7628, 
noisyNet noise sample is [array([0.38330877], dtype=float32), -0.21109536]. 
=============================================
[2019-03-26 12:12:31,109] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.3827039e-26 1.0000000e+00 6.5858275e-19 2.1501061e-32 3.7830673e-24], sum to 1.0000
[2019-03-26 12:12:31,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5839
[2019-03-26 12:12:31,132] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.1, 68.0, 1.0, 2.0, 0.2483964544502939, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 409016.1123429117, 409016.1123429111, 160739.05740801], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 673200.0000, 
sim time next is 673800.0000, 
raw observation next is [21.88333333333333, 69.16666666666667, 1.0, 2.0, 0.2474632813174532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 407621.5253254219, 407621.5253254219, 160644.1875541037], 
processed observation next is [1.0, 0.8260869565217391, 0.2361769352290678, 0.6916666666666668, 1.0, 1.0, 0.0933292545993412, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11322820147928386, 0.11322820147928386, 0.23976744411060255], 
reward next is 0.7602, 
noisyNet noise sample is [array([-0.25708959], dtype=float32), -0.22103168]. 
=============================================
[2019-03-26 12:12:39,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.3174226e-27 1.0000000e+00 5.3462054e-24 1.3192132e-36 1.7889347e-28], sum to 1.0000
[2019-03-26 12:12:39,486] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5624
[2019-03-26 12:12:39,490] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.53333333333333, 65.0, 1.0, 2.0, 0.291832647351383, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466766.9952571982, 466766.9952571976, 164717.0981647818], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 814800.0000, 
sim time next is 815400.0000, 
raw observation next is [24.7, 64.0, 1.0, 2.0, 0.2917469936813316, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466636.1393664615, 466636.1393664609, 164708.0811510054], 
processed observation next is [0.0, 0.43478260869565216, 0.3696682464454976, 0.64, 1.0, 1.0, 0.14668312491726698, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12962114982401707, 0.12962114982401693, 0.2458329569417991], 
reward next is 0.7542, 
noisyNet noise sample is [array([2.819546], dtype=float32), 0.9000549]. 
=============================================
[2019-03-26 12:12:41,262] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.6173004e-26 1.0000000e+00 1.5644247e-21 1.7431362e-32 1.9564999e-24], sum to 1.0000
[2019-03-26 12:12:41,271] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9717
[2019-03-26 12:12:41,276] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.46666666666667, 53.0, 1.0, 2.0, 0.3799757414094503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 619555.0437125406, 619555.0437125413, 176515.8637444389], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 736800.0000, 
sim time next is 737400.0000, 
raw observation next is [25.53333333333333, 52.5, 1.0, 2.0, 0.4037994560166214, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 658645.1152586079, 658645.1152586079, 179944.0940086785], 
processed observation next is [1.0, 0.5217391304347826, 0.4091627172195892, 0.525, 1.0, 1.0, 0.2816860915862909, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18295697646072442, 0.18295697646072442, 0.26857327463981867], 
reward next is 0.7314, 
noisyNet noise sample is [array([0.9272884], dtype=float32), -1.5144795]. 
=============================================
[2019-03-26 12:12:45,211] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1738871e-22 1.0000000e+00 4.5173538e-16 2.4201123e-26 1.2129096e-18], sum to 1.0000
[2019-03-26 12:12:45,219] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9396
[2019-03-26 12:12:45,225] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 50.0, 1.0, 2.0, 0.5764482826910733, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 952258.2389934983, 952258.2389934983, 210572.8166373943], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 750600.0000, 
sim time next is 751200.0000, 
raw observation next is [24.76666666666667, 50.0, 1.0, 2.0, 0.5855047432689141, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 967950.518668153, 967950.518668153, 212431.3586444625], 
processed observation next is [1.0, 0.6956521739130435, 0.3728278041074251, 0.5, 1.0, 1.0, 0.5006081244203784, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2688751440744869, 0.2688751440744869, 0.3170617293200933], 
reward next is 0.6829, 
noisyNet noise sample is [array([0.78690994], dtype=float32), 0.7649233]. 
=============================================
[2019-03-26 12:12:46,646] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4941007e-24 1.0000000e+00 9.6309937e-18 5.7034008e-29 4.7738451e-23], sum to 1.0000
[2019-03-26 12:12:46,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2270
[2019-03-26 12:12:46,662] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 87.66666666666667, 1.0, 2.0, 0.3384132657816531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 524183.5858627975, 524183.585862798, 168622.8294463988], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 937200.0000, 
sim time next is 937800.0000, 
raw observation next is [22.55, 88.0, 1.0, 2.0, 0.3387289176552802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 524766.1754814181, 524766.1754814174, 168672.0485317231], 
processed observation next is [0.0, 0.8695652173913043, 0.26777251184834133, 0.88, 1.0, 1.0, 0.2032878525967231, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14576838207817172, 0.14576838207817153, 0.2517493261667509], 
reward next is 0.7483, 
noisyNet noise sample is [array([0.33952913], dtype=float32), 0.50862044]. 
=============================================
[2019-03-26 12:12:47,428] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1478479e-28 1.0000000e+00 4.9138765e-24 9.9646648e-38 8.9716822e-29], sum to 1.0000
[2019-03-26 12:12:47,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4123
[2019-03-26 12:12:47,440] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.4, 79.33333333333334, 1.0, 2.0, 0.2910488064414485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 465268.5318146853, 465268.5318146859, 164610.1486551552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 892200.0000, 
sim time next is 892800.0000, 
raw observation next is [22.5, 79.0, 1.0, 2.0, 0.292241266409421, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466670.2044195034, 466670.204419504, 164700.6656892739], 
processed observation next is [0.0, 0.34782608695652173, 0.2654028436018958, 0.79, 1.0, 1.0, 0.14727863422821805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12963061233875095, 0.12963061233875112, 0.24582188908846853], 
reward next is 0.7542, 
noisyNet noise sample is [array([0.02993399], dtype=float32), -1.2506386]. 
=============================================
[2019-03-26 12:12:49,159] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.9240883e-30 1.0000000e+00 2.3669394e-25 0.0000000e+00 4.7176510e-31], sum to 1.0000
[2019-03-26 12:12:49,167] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8265
[2019-03-26 12:12:49,176] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.01666666666667, 68.0, 1.0, 2.0, 0.2904095887404655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 464791.6358541481, 464791.6358541474, 164583.6680689902], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 813000.0000, 
sim time next is 813600.0000, 
raw observation next is [24.2, 67.0, 1.0, 2.0, 0.2913297578531947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 466062.1251034755, 466062.1251034748, 164669.3506602364], 
processed observation next is [0.0, 0.43478260869565216, 0.3459715639810427, 0.67, 1.0, 1.0, 0.14618043114842735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12946170141763208, 0.12946170141763189, 0.24577515023915883], 
reward next is 0.7542, 
noisyNet noise sample is [array([-1.1080121], dtype=float32), 1.5451386]. 
=============================================
[2019-03-26 12:12:51,878] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.1864576e-28 1.0000000e+00 8.6007627e-24 2.2732209e-37 6.0691811e-28], sum to 1.0000
[2019-03-26 12:12:51,887] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6747
[2019-03-26 12:12:51,892] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 80.66666666666667, 1.0, 2.0, 0.2841501866107968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 456166.4625647859, 456166.4625647865, 164006.5777040067], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 889800.0000, 
sim time next is 890400.0000, 
raw observation next is [22.1, 80.33333333333334, 1.0, 2.0, 0.2853998061894472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 457698.5425917103, 457698.5425917097, 164106.6389629345], 
processed observation next is [0.0, 0.30434782608695654, 0.24644549763033188, 0.8033333333333335, 1.0, 1.0, 0.13903591107162314, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12713848405325287, 0.1271384840532527, 0.2449352820342306], 
reward next is 0.7551, 
noisyNet noise sample is [array([0.7358294], dtype=float32), -2.017166]. 
=============================================
[2019-03-26 12:12:56,262] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 12:12:56,264] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:12:56,265] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:12:56,266] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:12:56,266] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:12:56,268] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:12:56,268] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:12:56,272] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:12:56,269] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:12:56,276] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:12:56,278] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:12:56,302] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-26 12:12:56,323] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-26 12:12:56,346] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-26 12:12:56,364] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-26 12:12:56,384] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-26 12:12:59,803] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:12:59,805] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.9, 71.0, 1.0, 2.0, 0.2383669937457534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 395506.4290009755, 395506.4290009761, 159566.203846614]
[2019-03-26 12:12:59,807] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:12:59,809] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.894413e-27 1.000000e+00 5.503559e-22 9.088151e-35 7.417676e-27], sampled 0.920988444963221
[2019-03-26 12:13:19,129] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:19,130] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.28256612333334, 86.73427183333334, 1.0, 2.0, 0.347275153236409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542585.9650847991, 542585.9650847991, 170225.3265805646]
[2019-03-26 12:13:19,131] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:13:19,134] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.6851955e-25 1.0000000e+00 4.9436708e-19 8.8455282e-31 8.8746607e-24], sampled 0.7998460986461875
[2019-03-26 12:13:28,520] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:28,522] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.78333333333333, 83.83333333333334, 1.0, 2.0, 0.4505045115848335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 660977.4354925336, 660977.4354925329, 180189.043000163]
[2019-03-26 12:13:28,523] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:13:28,528] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2183634e-25 1.0000000e+00 6.5124001e-20 3.0439100e-32 2.3710524e-24], sampled 0.16938791552245747
[2019-03-26 12:13:33,555] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:33,556] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.88333333333333, 56.5, 1.0, 2.0, 0.5600645928574395, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9459793346601496, 6.911199999999999, 6.9112, 168.9124642650618, 1565845.429917012, 1565845.429917013, 337048.245620399]
[2019-03-26 12:13:33,556] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:13:33,558] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9380928e-16 1.0000000e+00 3.2104410e-08 2.8349859e-17 2.5107751e-11], sampled 0.4224342114101629
[2019-03-26 12:13:38,193] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:38,194] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.97517917, 98.53869047, 1.0, 2.0, 0.4119729646226343, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 603527.5933955895, 603527.5933955895, 174537.7960601649]
[2019-03-26 12:13:38,196] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:13:38,201] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.9278083e-28 1.0000000e+00 3.8404289e-24 4.0411060e-38 1.2204222e-28], sampled 0.7410599531237272
[2019-03-26 12:13:53,176] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:53,178] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.87776196333333, 73.10525736666668, 1.0, 2.0, 0.5270888536145618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 736537.9031651112, 736537.9031651106, 187948.3345121616]
[2019-03-26 12:13:53,180] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:13:53,182] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.29378415e-24 1.00000000e+00 5.66181224e-18 1.06384955e-29
 1.89122801e-22], sampled 0.05765174757287639
[2019-03-26 12:13:57,089] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:13:57,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.23333333333333, 66.66666666666667, 1.0, 2.0, 0.6463407161724791, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005971923140827, 6.9112, 168.9123340557505, 1800043.122302754, 1732808.905991944, 373446.7739281972]
[2019-03-26 12:13:57,091] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:13:57,095] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.9324443e-18 1.0000000e+00 6.4429698e-11 1.9473749e-20 5.7315115e-15], sampled 0.06045433692579594
[2019-03-26 12:13:57,096] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1800043.122302754 W.
[2019-03-26 12:14:12,749] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:14:12,750] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.71666666666667, 62.83333333333334, 1.0, 2.0, 0.585482930932431, 0.0, 2.0, 0.0, 1.0, 2.0, 1.016790228865653, 6.9112, 6.9112, 168.9129223050966, 1636965.583343709, 1636965.583343709, 358454.0413616586]
[2019-03-26 12:14:12,753] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:14:12,756] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.8704222e-15 9.9999285e-01 7.1644054e-06 6.9660654e-14 1.6098095e-09], sampled 0.14637360845778813
[2019-03-26 12:14:35,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.38239503], dtype=float32), 0.11991401]
[2019-03-26 12:14:35,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.4, 45.0, 1.0, 2.0, 0.9470836105389412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1487683.571324547, 1487683.571324547, 305814.7340321878]
[2019-03-26 12:14:35,575] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:14:35,579] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3659587e-20 1.0000000e+00 1.0469407e-14 3.4006783e-25 6.6004687e-18], sampled 0.14628550488843894
[2019-03-26 12:14:51,785] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.9780 3007633090.4407 1766.0000
[2019-03-26 12:14:51,791] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.5240 2842610635.1239 1132.0000
[2019-03-26 12:14:51,923] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.9689 2927381913.5140 1338.0000
[2019-03-26 12:14:52,097] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7882.6673 3164158714.3706 1778.0000
[2019-03-26 12:14:52,155] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 12:14:53,172] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1300000, evaluation results [1300000.0, 7882.667338680013, 3164158714.37059, 1778.0, 8254.968948333817, 2927381913.5140486, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.9779682847975, 3007633090.440681, 1766.0, 8495.524016460588, 2842610635.1238923, 1132.0]
[2019-03-26 12:14:56,759] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.3352265e-25 1.0000000e+00 3.7722277e-18 2.8475587e-32 1.3353792e-22], sum to 1.0000
[2019-03-26 12:14:56,767] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-26 12:14:56,774] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.15, 96.5, 1.0, 2.0, 0.3606971938124785, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 547255.1984593577, 547255.1984593577, 170157.3581204329], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1045800.0000, 
sim time next is 1046400.0000, 
raw observation next is [22.0, 96.66666666666666, 1.0, 2.0, 0.3577942907489665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 545108.0214218537, 545108.0214218537, 170052.4684641506], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.9666666666666666, 1.0, 1.0, 0.22625818162526085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1514188948394038, 0.1514188948394038, 0.25380965442410536], 
reward next is 0.7462, 
noisyNet noise sample is [array([-0.76660526], dtype=float32), -0.87365055]. 
=============================================
[2019-03-26 12:14:58,364] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0136804e-23 1.0000000e+00 2.3584676e-17 2.1733866e-31 3.7896719e-22], sum to 1.0000
[2019-03-26 12:14:58,372] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0284
[2019-03-26 12:14:58,379] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.91666666666667, 84.83333333333333, 1.0, 2.0, 0.481559489056565, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 765140.1450929537, 765140.1450929537, 191220.0249324001], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1072200.0000, 
sim time next is 1072800.0000, 
raw observation next is [22.0, 84.0, 1.0, 2.0, 0.5164311119203919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 821012.0469414337, 821012.0469414337, 197449.7681642453], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.84, 1.0, 1.0, 0.41738688183179745, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22805890192817602, 0.22805890192817602, 0.294701146513799], 
reward next is 0.7053, 
noisyNet noise sample is [array([-0.56834865], dtype=float32), 0.3704326]. 
=============================================
[2019-03-26 12:15:02,536] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.3610653e-22 1.0000000e+00 5.2816952e-12 1.7893555e-23 5.2674362e-17], sum to 1.0000
[2019-03-26 12:15:02,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3826
[2019-03-26 12:15:02,552] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 87.0, 1.0, 2.0, 0.3565731776975517, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549146.8796949072, 549146.8796949066, 170571.0982558838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1206000.0000, 
sim time next is 1206600.0000, 
raw observation next is [22.85, 87.16666666666667, 1.0, 2.0, 0.3557153872458308, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 548072.2460944823, 548072.2460944816, 170488.2475067229], 
processed observation next is [1.0, 1.0, 0.28199052132701435, 0.8716666666666667, 1.0, 1.0, 0.22375347860943468, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15224229058180064, 0.15224229058180044, 0.25446007090555656], 
reward next is 0.7455, 
noisyNet noise sample is [array([0.77829397], dtype=float32), -0.03446996]. 
=============================================
[2019-03-26 12:15:07,713] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6185467e-18 1.0000000e+00 5.1216903e-10 7.4160897e-20 2.7397141e-13], sum to 1.0000
[2019-03-26 12:15:07,723] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2128
[2019-03-26 12:15:07,730] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.6, 57.16666666666666, 1.0, 2.0, 0.8749218469490505, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1349022.648056325, 1349022.648056325, 280355.8618688554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1183800.0000, 
sim time next is 1184400.0000, 
raw observation next is [27.6, 57.0, 1.0, 2.0, 0.8641109400539346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333435.593337787, 1333435.593337787, 277297.3716745664], 
processed observation next is [1.0, 0.7391304347826086, 0.5071090047393366, 0.57, 1.0, 1.0, 0.8362782410288369, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3703987759271631, 0.3703987759271631, 0.4138766741411439], 
reward next is 0.5861, 
noisyNet noise sample is [array([0.7387128], dtype=float32), -0.30914956]. 
=============================================
[2019-03-26 12:15:09,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.4790517e-12 5.3863905e-02 9.4612521e-01 4.8111101e-08 1.0841012e-05], sum to 1.0000
[2019-03-26 12:15:09,183] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4268
[2019-03-26 12:15:09,190] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.15, 74.5, 1.0, 2.0, 0.8904611508253842, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.968849142427467, 6.9112, 168.9125660792904, 2141684.837278059, 2100786.646043344, 432652.9255252149], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1265400.0000, 
sim time next is 1266000.0000, 
raw observation next is [28.1, 74.66666666666667, 1.0, 2.0, 0.8759453051674225, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.968477002323437, 6.9112, 168.9125685373742, 2121367.121892302, 2080732.938453896, 428710.5342675335], 
processed observation next is [1.0, 0.6521739130434783, 0.5308056872037916, 0.7466666666666667, 1.0, 1.0, 0.8505365122499067, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005727700232343658, 0.0, 0.829438040026979, 0.5892686449700838, 0.5779813717927489, 0.6398664690560202], 
reward next is 0.0737, 
noisyNet noise sample is [array([-1.1585914], dtype=float32), 0.4472641]. 
=============================================
[2019-03-26 12:15:09,204] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[64.76492 ]
 [63.466244]
 [62.219063]
 [62.362343]
 [63.64867 ]], R is [[66.04636383]
 [65.4519043 ]
 [64.8592453 ]
 [64.26296234]
 [63.62033463]].
[2019-03-26 12:15:10,989] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.2784604e-24 1.0000000e+00 1.6627294e-16 9.6340169e-31 1.0719559e-22], sum to 1.0000
[2019-03-26 12:15:11,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8634
[2019-03-26 12:15:11,009] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.15, 84.66666666666666, 1.0, 2.0, 0.4420523263281333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661778.3851932376, 661778.3851932376, 180518.3583214897], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1237800.0000, 
sim time next is 1238400.0000, 
raw observation next is [24.3, 84.0, 1.0, 2.0, 0.4335734377921851, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 647834.1596891858, 647834.1596891858, 179108.9664061305], 
processed observation next is [1.0, 0.34782608695652173, 0.3507109004739337, 0.84, 1.0, 1.0, 0.3175583587857652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.17995393324699605, 0.17995393324699605, 0.26732681553153803], 
reward next is 0.7327, 
noisyNet noise sample is [array([0.07558171], dtype=float32), -0.905141]. 
=============================================
[2019-03-26 12:15:13,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0967942e-23 1.0000000e+00 7.4041193e-16 1.3331350e-29 5.7137404e-23], sum to 1.0000
[2019-03-26 12:15:13,221] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-26 12:15:13,226] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 81.33333333333334, 1.0, 2.0, 0.4799568484677325, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 670656.2848252951, 670656.2848252945, 180515.2154840048], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1275600.0000, 
sim time next is 1276200.0000, 
raw observation next is [26.45, 82.0, 1.0, 2.0, 0.478739987687154, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668955.3979834877, 668955.3979834877, 180331.9605838347], 
processed observation next is [1.0, 0.782608695652174, 0.45260663507109006, 0.82, 1.0, 1.0, 0.37197588877970356, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18582094388430215, 0.18582094388430215, 0.2691521799758727], 
reward next is 0.7308, 
noisyNet noise sample is [array([0.14678484], dtype=float32), 0.16141033]. 
=============================================
[2019-03-26 12:15:14,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [6.7029582e-24 1.0000000e+00 5.2628969e-17 1.7179152e-29 6.6689386e-23], sum to 1.0000
[2019-03-26 12:15:14,855] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2436
[2019-03-26 12:15:14,860] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.56666666666667, 96.0, 1.0, 2.0, 0.3443125666378619, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 533128.6773036971, 533128.6773036965, 169335.5641813663], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1473000.0000, 
sim time next is 1473600.0000, 
raw observation next is [21.53333333333333, 96.0, 1.0, 2.0, 0.3428002150982115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531282.5586665417, 531282.558666541, 169200.4993951761], 
processed observation next is [0.0, 0.043478260869565216, 0.21958925750394942, 0.96, 1.0, 1.0, 0.20819303023880906, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14757848851848382, 0.14757848851848362, 0.2525380587987703], 
reward next is 0.7475, 
noisyNet noise sample is [array([-0.21251668], dtype=float32), 0.8308941]. 
=============================================
[2019-03-26 12:15:15,635] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.7990582e-24 1.0000000e+00 1.6992349e-15 5.0129823e-28 9.1698440e-21], sum to 1.0000
[2019-03-26 12:15:15,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5286
[2019-03-26 12:15:15,652] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 94.0, 1.0, 2.0, 0.3231308022277213, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 509013.5723045908, 509013.5723045908, 167666.8986250857], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1366800.0000, 
sim time next is 1367400.0000, 
raw observation next is [21.18333333333333, 94.0, 1.0, 2.0, 0.3236282865383968, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 509589.5633018786, 509589.5633018792, 167706.4437487769], 
processed observation next is [1.0, 0.8260869565217391, 0.20300157977883085, 0.94, 1.0, 1.0, 0.18509432113059857, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14155265647274404, 0.14155265647274423, 0.25030812499817445], 
reward next is 0.7497, 
noisyNet noise sample is [array([0.35584003], dtype=float32), 0.89299625]. 
=============================================
[2019-03-26 12:15:16,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.4216352e-22 1.0000000e+00 1.0104228e-14 2.0620224e-28 2.6516520e-20], sum to 1.0000
[2019-03-26 12:15:16,288] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1479
[2019-03-26 12:15:16,292] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 95.0, 1.0, 2.0, 0.8223431819794218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1221404.104168523, 1221404.104168523, 259426.428015832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1329000.0000, 
sim time next is 1329600.0000, 
raw observation next is [23.0, 95.0, 1.0, 2.0, 0.7450749485453285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1106612.822111481, 1106612.82211148, 239564.1965244612], 
processed observation next is [1.0, 0.391304347826087, 0.28909952606635075, 0.95, 1.0, 1.0, 0.6928613837895524, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30739245058652254, 0.3073924505865222, 0.3575585022753152], 
reward next is 0.6424, 
noisyNet noise sample is [array([0.15879536], dtype=float32), 0.56956804]. 
=============================================
[2019-03-26 12:15:18,420] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6561312e-26 1.0000000e+00 1.9972408e-19 8.9200662e-33 8.2483888e-26], sum to 1.0000
[2019-03-26 12:15:18,431] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8260
[2019-03-26 12:15:18,437] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 66.0, 1.0, 2.0, 0.3449968494480293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 533414.5341833519, 533414.5341833519, 169336.5385145323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1533600.0000, 
sim time next is 1534200.0000, 
raw observation next is [25.71666666666667, 67.33333333333333, 1.0, 2.0, 0.3510396991243185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 542337.4698520551, 542337.4698520551, 170054.130770924], 
processed observation next is [0.0, 0.782608695652174, 0.41785150078988953, 0.6733333333333333, 1.0, 1.0, 0.21812011942688975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1506492971811264, 0.1506492971811264, 0.25381213547899106], 
reward next is 0.7462, 
noisyNet noise sample is [array([-1.4231583], dtype=float32), 0.54004437]. 
=============================================
[2019-03-26 12:15:18,508] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.0729248e-25 1.0000000e+00 2.0088025e-18 9.1549381e-32 9.8419951e-24], sum to 1.0000
[2019-03-26 12:15:18,520] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8118
[2019-03-26 12:15:18,524] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.35, 70.0, 1.0, 2.0, 0.3492938027926142, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 538561.1713245438, 538561.1713245438, 169712.7316469776], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1535400.0000, 
sim time next is 1536000.0000, 
raw observation next is [25.16666666666666, 71.33333333333333, 1.0, 2.0, 0.3508383085864997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 540471.1066668897, 540471.1066668897, 169855.8271450381], 
processed observation next is [0.0, 0.782608695652174, 0.3917851500789887, 0.7133333333333333, 1.0, 1.0, 0.21787748022469847, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15013086296302494, 0.15013086296302494, 0.25351615991796733], 
reward next is 0.7465, 
noisyNet noise sample is [array([-0.15926199], dtype=float32), 1.1386794]. 
=============================================
[2019-03-26 12:15:18,536] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[80.662544]
 [80.67992 ]
 [80.74253 ]
 [80.85895 ]
 [80.814865]], R is [[80.56218719]
 [80.50326538]
 [80.4444809 ]
 [80.38622284]
 [80.32962036]].
[2019-03-26 12:15:19,323] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.2699304e-23 1.0000000e+00 2.2125815e-13 1.6527422e-26 1.0732546e-19], sum to 1.0000
[2019-03-26 12:15:19,332] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2547
[2019-03-26 12:15:19,335] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.46666666666667, 97.0, 1.0, 2.0, 0.3088412434139835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 490359.6519182649, 490359.6519182649, 166348.5116356953], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1383600.0000, 
sim time next is 1384200.0000, 
raw observation next is [20.45, 97.0, 1.0, 2.0, 0.3113004068474109, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 494451.5192349766, 494451.5192349772, 166652.224787149], 
processed observation next is [0.0, 0.0, 0.16824644549763035, 0.97, 1.0, 1.0, 0.17024145403302515, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13734764423193796, 0.1373476442319381, 0.2487346638614164], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.07030576], dtype=float32), 0.18538003]. 
=============================================
[2019-03-26 12:15:24,979] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.8001191e-25 1.0000000e+00 5.4344767e-17 2.3956174e-32 1.2899698e-24], sum to 1.0000
[2019-03-26 12:15:24,991] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5314
[2019-03-26 12:15:24,995] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.7, 57.66666666666667, 1.0, 2.0, 0.3549844035424509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 544589.4044788288, 544589.4044788294, 170129.0385365109], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1527600.0000, 
sim time next is 1528200.0000, 
raw observation next is [27.55, 58.0, 1.0, 2.0, 0.3522676077483729, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541603.219326074, 541603.219326074, 169917.3253098239], 
processed observation next is [0.0, 0.6956521739130435, 0.504739336492891, 0.58, 1.0, 1.0, 0.21959952740767819, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15044533870168722, 0.15044533870168722, 0.25360794822361776], 
reward next is 0.7464, 
noisyNet noise sample is [array([-1.7036926], dtype=float32), 1.1725185]. 
=============================================
[2019-03-26 12:15:26,227] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.0815649e-26 1.0000000e+00 5.6960781e-20 2.1749933e-33 1.7401783e-26], sum to 1.0000
[2019-03-26 12:15:26,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1750
[2019-03-26 12:15:26,239] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 55.00000000000001, 1.0, 2.0, 0.3644598655128068, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 553951.0811976786, 553951.0811976792, 170757.5575697083], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1524000.0000, 
sim time next is 1524600.0000, 
raw observation next is [28.45, 55.5, 1.0, 2.0, 0.3641859483448473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 554235.9988482147, 554235.9988482147, 170804.1367881757], 
processed observation next is [0.0, 0.6521739130434783, 0.54739336492891, 0.555, 1.0, 1.0, 0.23395897390945458, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1539544441245041, 0.1539544441245041, 0.2549315474450384], 
reward next is 0.7451, 
noisyNet noise sample is [array([-1.0667714], dtype=float32), -0.23112024]. 
=============================================
[2019-03-26 12:15:31,006] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.7726479e-20 1.0000000e+00 1.4126140e-11 5.2085930e-24 5.2575596e-17], sum to 1.0000
[2019-03-26 12:15:31,014] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6238
[2019-03-26 12:15:31,020] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.65, 85.0, 1.0, 2.0, 0.748747083551946, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1136475.048702974, 1136475.048702975, 243473.5066725575], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1593000.0000, 
sim time next is 1593600.0000, 
raw observation next is [23.66666666666667, 85.0, 1.0, 2.0, 0.808003420546072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1225805.69447403, 1225805.694474031, 258861.4250405442], 
processed observation next is [1.0, 0.43478260869565216, 0.3206951026856243, 0.85, 1.0, 1.0, 0.7686788199350265, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.34050158179834167, 0.34050158179834195, 0.3863603358814093], 
reward next is 0.6136, 
noisyNet noise sample is [array([-2.4640098], dtype=float32), 0.43392873]. 
=============================================
[2019-03-26 12:15:39,388] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.06095316e-19 1.00000000e+00 5.26094146e-09 1.22392729e-22
 2.52311607e-16], sum to 1.0000
[2019-03-26 12:15:39,396] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5019
[2019-03-26 12:15:39,402] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.5, 91.33333333333333, 1.0, 2.0, 0.4519204511806106, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644920.737521176, 644920.7375211767, 178137.1501138371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1896000.0000, 
sim time next is 1896600.0000, 
raw observation next is [24.45, 91.66666666666667, 1.0, 2.0, 0.4515776399186808, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 644592.5742515107, 644592.5742515113, 178107.702219366], 
processed observation next is [1.0, 0.9565217391304348, 0.3578199052132702, 0.9166666666666667, 1.0, 1.0, 0.33925016857672385, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17905349284764185, 0.17905349284764202, 0.26583239137218806], 
reward next is 0.7342, 
noisyNet noise sample is [array([1.6179825], dtype=float32), -0.029658861]. 
=============================================
[2019-03-26 12:15:40,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.3996795e-24 1.0000000e+00 7.1834673e-16 1.6023102e-31 4.1323485e-23], sum to 1.0000
[2019-03-26 12:15:40,410] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7718
[2019-03-26 12:15:40,413] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.56666666666667, 92.66666666666667, 1.0, 2.0, 0.5490223477861003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775670.7534867938, 775670.7534867938, 192719.2377094287], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1750200.0000, 
sim time next is 1750800.0000, 
raw observation next is [24.63333333333333, 92.33333333333334, 1.0, 2.0, 0.5182720004318683, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731460.8390015797, 731460.839001579, 187437.0584605661], 
processed observation next is [1.0, 0.2608695652173913, 0.3665086887835701, 0.9233333333333335, 1.0, 1.0, 0.41960481979743164, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2031835663893277, 0.2031835663893275, 0.27975680367248673], 
reward next is 0.7202, 
noisyNet noise sample is [array([0.21229151], dtype=float32), 0.71264637]. 
=============================================
[2019-03-26 12:15:47,930] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 12:15:47,935] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:15:47,936] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:15:47,937] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:15:47,939] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:15:47,940] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:15:47,941] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:15:47,943] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:15:47,944] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:15:47,942] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:15:47,947] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:15:47,969] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-26 12:15:47,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-26 12:15:48,012] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-26 12:15:48,033] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-26 12:15:48,051] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-26 12:15:56,040] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:15:56,041] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.62810009333333, 64.75835274333335, 1.0, 2.0, 0.2768392228676117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 449310.3602034324, 449310.3602034324, 163532.1530095127]
[2019-03-26 12:15:56,041] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:15:56,044] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.3649520e-22 1.0000000e+00 5.8326648e-14 5.0743964e-28 1.2319613e-21], sampled 0.5799931100301519
[2019-03-26 12:16:00,260] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:00,261] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 85.0, 1.0, 2.0, 0.3024544091692027, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 480719.1836881607, 480719.1836881614, 165658.2429373475]
[2019-03-26 12:16:00,261] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:16:00,265] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.1204130e-22 1.0000000e+00 2.1929901e-13 1.9007268e-27 2.5546728e-21], sampled 0.4540382298856389
[2019-03-26 12:16:05,621] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:05,621] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.1, 74.66666666666667, 1.0, 2.0, 0.8759448220461297, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.968476871258149, 6.9112, 168.9125685401636, 2121366.445677658, 2080732.355220593, 428710.4071380539]
[2019-03-26 12:16:05,623] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:16:05,625] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0818623e-15 3.8623775e-06 9.9999619e-01 2.4397367e-10 1.1013518e-08], sampled 0.43594459678107544
[2019-03-26 12:16:29,550] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:29,551] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.63012097333333, 81.27383158333335, 1.0, 2.0, 0.4279504641444671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 616242.1677379619, 616242.1677379624, 175435.8130393703]
[2019-03-26 12:16:29,552] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:16:29,555] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0282070e-23 1.0000000e+00 9.4101274e-16 1.4849795e-30 4.1895210e-23], sampled 0.293337854193337
[2019-03-26 12:16:47,966] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:47,969] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.71666666666667, 55.66666666666667, 1.0, 2.0, 0.5434390161823249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759393.2890105458, 759393.2890105451, 190683.2645099963]
[2019-03-26 12:16:47,970] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:16:47,973] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.0867524e-18 9.9999964e-01 3.3422140e-07 8.9665881e-20 5.1133884e-15], sampled 0.17706068368606664
[2019-03-26 12:16:50,865] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:50,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [40.50012824666667, 50.27205557666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.623234290350299, 6.9112, 168.9031237104405, 3499304.137129659, 2284798.791063537, 471762.9496097896]
[2019-03-26 12:16:50,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:16:50,872] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.55834771e-15 3.45075843e-11 9.99999762e-01 1.01489706e-08
 2.06597676e-07], sampled 0.651781836247757
[2019-03-26 12:16:50,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3499304.137129659 W.
[2019-03-26 12:16:56,998] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:16:56,999] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 1.0, 2.0, 0.6546175374521693, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 914819.3436515267, 914819.3436515274, 211351.0746198205]
[2019-03-26 12:16:57,000] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:16:57,006] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0359088e-21 1.0000000e+00 4.3069620e-13 2.0854387e-27 3.1690633e-20], sampled 0.8047665277576529
[2019-03-26 12:17:18,185] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:17:18,186] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.58333333333333, 57.5, 1.0, 2.0, 0.5146174867952635, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 719104.8963638908, 719104.8963638915, 185917.4572541131]
[2019-03-26 12:17:18,188] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:17:18,192] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.6722055e-20 1.0000000e+00 1.7547178e-10 7.9610833e-24 1.1159030e-17], sampled 0.6952876555903958
[2019-03-26 12:17:43,253] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.37414372], dtype=float32), 0.120284304]
[2019-03-26 12:17:43,254] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.15, 72.5, 1.0, 2.0, 0.5063250630001301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 707513.5521628319, 707513.5521628319, 184594.0074733763]
[2019-03-26 12:17:43,255] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:17:43,257] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.1440125e-21 1.0000000e+00 1.3192811e-10 1.1765758e-24 3.6038109e-19], sampled 0.2633453453255341
[2019-03-26 12:17:43,321] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8087.8898 3011604304.4695 1645.0000
[2019-03-26 12:17:43,491] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8357.7246 2930834484.4853 1186.0000
[2019-03-26 12:17:43,500] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7920.3278 3167875885.5389 1722.0000
[2019-03-26 12:17:43,673] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8714.9000 2781276492.0826 866.0000
[2019-03-26 12:17:43,688] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8546.0640 2845544018.7327 1048.0000
[2019-03-26 12:17:44,705] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1325000, evaluation results [1325000.0, 7920.327845127607, 3167875885.5388594, 1722.0, 8357.724598966079, 2930834484.48528, 1186.0, 8714.90002670736, 2781276492.0826263, 866.0, 8087.8897506149015, 3011604304.4695406, 1645.0, 8546.064016675105, 2845544018.73272, 1048.0]
[2019-03-26 12:17:55,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1355064e-21 1.0000000e+00 5.5752475e-10 1.7871435e-25 9.2575097e-19], sum to 1.0000
[2019-03-26 12:17:55,981] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8471
[2019-03-26 12:17:55,987] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.51666666666667, 94.0, 1.0, 2.0, 0.4682872902829175, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657590.738664544, 657590.738664544, 179195.8874800015], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2073000.0000, 
sim time next is 2073600.0000, 
raw observation next is [24.5, 94.0, 1.0, 2.0, 0.4677171844808998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 657284.2766999168, 657284.2766999175, 179175.2532192061], 
processed observation next is [0.0, 0.0, 0.3601895734597157, 0.94, 1.0, 1.0, 0.3586954029890359, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1825789657499769, 0.1825789657499771, 0.2674257510734419], 
reward next is 0.7326, 
noisyNet noise sample is [array([-0.67799324], dtype=float32), -0.56275964]. 
=============================================
[2019-03-26 12:17:57,246] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.9720770e-25 1.0000000e+00 4.1154499e-17 5.8182943e-34 4.2171139e-24], sum to 1.0000
[2019-03-26 12:17:57,255] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7020
[2019-03-26 12:17:57,264] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 94.0, 1.0, 2.0, 0.4797412250532267, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 670354.8935108938, 670354.8935108938, 180482.9102815486], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2096400.0000, 
sim time next is 2097000.0000, 
raw observation next is [25.05, 93.5, 1.0, 2.0, 0.4820010316194018, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 673513.5810254433, 673513.5810254439, 180824.2370530177], 
processed observation next is [0.0, 0.2608695652173913, 0.3862559241706162, 0.935, 1.0, 1.0, 0.3759048573727732, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18708710584040092, 0.18708710584040106, 0.2698869209746533], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.94977015], dtype=float32), -0.9860113]. 
=============================================
[2019-03-26 12:17:57,281] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[72.51765 ]
 [72.51115 ]
 [72.503586]
 [72.4066  ]
 [72.43    ]], R is [[72.53302765]
 [72.53832245]
 [72.54389954]
 [72.54945374]
 [72.55486298]].
[2019-03-26 12:17:57,746] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.0757660e-24 1.0000000e+00 1.8475080e-16 5.4456179e-33 2.1754275e-23], sum to 1.0000
[2019-03-26 12:17:57,754] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2223
[2019-03-26 12:17:57,766] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.06666666666667, 97.0, 1.0, 2.0, 0.4631844348492491, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 653250.2282410933, 653250.2282410928, 178808.4811557962], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2092800.0000, 
sim time next is 2093400.0000, 
raw observation next is [24.2, 96.5, 1.0, 2.0, 0.470418714713117, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 661346.4960762226, 661346.4960762219, 179610.3312836227], 
processed observation next is [0.0, 0.21739130434782608, 0.3459715639810427, 0.965, 1.0, 1.0, 0.3619502586905024, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18370736002117294, 0.18370736002117274, 0.26807512131883987], 
reward next is 0.7319, 
noisyNet noise sample is [array([-0.98610806], dtype=float32), -1.4334031]. 
=============================================
[2019-03-26 12:18:06,999] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.0464074e-18 1.0000000e+00 1.5765350e-10 3.7463584e-25 4.2985046e-15], sum to 1.0000
[2019-03-26 12:18:07,009] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2136
[2019-03-26 12:18:07,013] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.86666666666667, 87.16666666666667, 1.0, 2.0, 0.6251125631082837, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 873569.57527318, 873569.5752731793, 205508.0825212715], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2265000.0000, 
sim time next is 2265600.0000, 
raw observation next is [26.03333333333333, 86.33333333333334, 1.0, 2.0, 0.5980096843371455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 835679.4958897944, 835679.4958897944, 200367.9193378125], 
processed observation next is [1.0, 0.21739130434782608, 0.4328593996840442, 0.8633333333333334, 1.0, 1.0, 0.5156743184784885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23213319330272067, 0.23213319330272067, 0.2990565960265858], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.48678148], dtype=float32), -0.17219386]. 
=============================================
[2019-03-26 12:18:07,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.2491107e-18 9.9999833e-01 1.6706364e-06 1.7949406e-20 2.6973437e-12], sum to 1.0000
[2019-03-26 12:18:07,209] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4792
[2019-03-26 12:18:07,217] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.9, 80.0, 1.0, 2.0, 0.5547100137790519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 775148.9538129104, 775148.9538129104, 192611.8932705215], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2421600.0000, 
sim time next is 2422200.0000, 
raw observation next is [28.85, 80.0, 1.0, 2.0, 0.5530945427769307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 772890.6815433354, 772890.681543336, 192332.9599338659], 
processed observation next is [1.0, 0.0, 0.5663507109004741, 0.8, 1.0, 1.0, 0.4615596900926876, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21469185598425986, 0.21469185598426, 0.28706411930427744], 
reward next is 0.7129, 
noisyNet noise sample is [array([-0.55434674], dtype=float32), 0.05341995]. 
=============================================
[2019-03-26 12:18:13,339] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6901460e-17 9.7249474e-17 9.9998009e-01 1.0790650e-11 1.9921001e-05], sum to 1.0000
[2019-03-26 12:18:13,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6231
[2019-03-26 12:18:13,354] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.3, 66.0, 1.0, 2.0, 0.9303156378375138, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994904932925825, 6.9112, 168.9123912420328, 2197469.939753486, 2138086.978160615, 443022.1435718716], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2368800.0000, 
sim time next is 2369400.0000, 
raw observation next is [31.45, 65.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.139555870387925, 6.9112, 168.9117507412356, 2452733.395339977, 2290731.037931073, 475941.1465535378], 
processed observation next is [1.0, 0.43478260869565216, 0.6895734597156398, 0.6566666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.022835587038792494, 0.0, 0.8294340242735497, 0.6813148320388825, 0.6363141772030758, 0.710359920229161], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3429147], dtype=float32), 0.636533]. 
=============================================
[2019-03-26 12:18:13,548] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.3058083e-19 1.1502309e-24 9.9978477e-01 3.0231834e-07 2.1484484e-04], sum to 1.0000
[2019-03-26 12:18:13,557] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1716
[2019-03-26 12:18:13,566] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 3057398.17312429 W.
[2019-03-26 12:18:13,572] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.26666666666667, 64.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.000856135833455, 6.9112, 168.9058615773423, 3057398.17312429, 2284391.077651144, 473521.5800123687], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2373600.0000, 
sim time next is 2374200.0000, 
raw observation next is [32.3, 64.0, 1.0, 2.0, 0.9978868560573128, 1.0, 1.0, 0.9978868560573128, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2791389.46613337, 2791389.46613337, 527707.7434854043], 
processed observation next is [1.0, 0.4782608695652174, 0.7298578199052131, 0.64, 1.0, 1.0, 0.9974540434425455, 1.0, 0.5, 0.9974540434425455, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.775385962814825, 0.775385962814825, 0.7876234977394094], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20106204], dtype=float32), -1.2341471]. 
=============================================
[2019-03-26 12:18:14,437] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7516133e-16 1.0963346e-07 9.9999988e-01 5.7614138e-14 2.0306706e-08], sum to 1.0000
[2019-03-26 12:18:14,438] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4184
[2019-03-26 12:18:14,445] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.86666666666667, 93.33333333333334, 1.0, 2.0, 0.2757441064083896, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4739321160452611, 6.911200000000001, 6.9112, 168.912956510431, 770645.1923271392, 770645.1923271385, 214040.415655857], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2499600.0000, 
sim time next is 2500200.0000, 
raw observation next is [26.85, 93.5, 1.0, 2.0, 0.2764210467169229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4751422866251607, 6.9112, 6.9112, 168.912956510431, 772537.7822034647, 772537.7822034647, 214241.7229393927], 
processed observation next is [1.0, 0.9565217391304348, 0.4715639810426541, 0.935, 1.0, 1.0, 0.1282181285746059, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3599296178355618, 0.0, 0.0, 0.8294399451523027, 0.2145938283898513, 0.2145938283898513, 0.31976376558118313], 
reward next is 0.6802, 
noisyNet noise sample is [array([0.7881693], dtype=float32), -0.8813536]. 
=============================================
[2019-03-26 12:18:17,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.3049122e-12 2.8621203e-03 9.9712211e-01 1.0191492e-12 1.5789223e-05], sum to 1.0000
[2019-03-26 12:18:17,109] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6736
[2019-03-26 12:18:17,114] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 83.33333333333334, 1.0, 2.0, 0.36220313124524, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6169787679310156, 6.911199999999999, 6.9112, 168.912956510431, 1012394.649632712, 1012394.649632712, 242516.6929672151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2436000.0000, 
sim time next is 2436600.0000, 
raw observation next is [27.65, 83.66666666666666, 1.0, 2.0, 0.3616433368958036, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6160316466518619, 6.9112, 6.9112, 168.912956510431, 1010829.222722952, 1010829.222722952, 242304.8222513781], 
processed observation next is [1.0, 0.17391304347826086, 0.509478672985782, 0.8366666666666666, 1.0, 1.0, 0.2308955866214501, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5317459105510511, 0.0, 0.0, 0.8294399451523027, 0.28078589520082, 0.28078589520082, 0.3616489884348927], 
reward next is 0.6384, 
noisyNet noise sample is [array([-1.0991098], dtype=float32), -0.3088054]. 
=============================================
[2019-03-26 12:18:29,228] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.3660021e-20 1.0000000e+00 1.9837958e-09 3.1993733e-25 4.4476731e-17], sum to 1.0000
[2019-03-26 12:18:29,235] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3183
[2019-03-26 12:18:29,243] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.3969508427242628, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 592308.4251204082, 592308.4251204075, 173829.7584087286], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2665800.0000, 
sim time next is 2666400.0000, 
raw observation next is [23.0, 94.0, 1.0, 2.0, 0.3968518920899767, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 592161.0428946876, 592161.042894687, 173816.1965682209], 
processed observation next is [0.0, 0.8695652173913043, 0.28909952606635075, 0.94, 1.0, 1.0, 0.2733155326385261, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16448917858185766, 0.16448917858185752, 0.25942715905704616], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.6894373], dtype=float32), -2.0645669]. 
=============================================
[2019-03-26 12:18:39,286] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 12:18:39,288] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:18:39,289] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:18:39,290] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:18:39,290] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:18:39,291] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:18:39,293] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:18:39,296] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:18:39,292] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:18:39,301] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:18:39,302] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:18:39,318] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-26 12:18:39,342] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-26 12:18:39,344] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-26 12:18:39,344] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-26 12:18:39,403] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-26 12:18:44,907] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:18:44,908] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.48555872, 82.74384547333332, 1.0, 2.0, 0.2876940047738814, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 464241.1182472106, 464241.1182472106, 164561.4120647691]
[2019-03-26 12:18:44,910] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:18:44,912] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8008073e-21 1.0000000e+00 8.2151300e-12 3.3991814e-28 2.4957727e-19], sampled 0.5913636228126399
[2019-03-26 12:19:08,318] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:19:08,319] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.3, 96.66666666666667, 1.0, 2.0, 0.4723316300925153, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660230.6871954617, 660230.6871954617, 179404.5169101899]
[2019-03-26 12:19:08,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:19:08,323] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1362999e-22 1.0000000e+00 3.3619436e-14 1.5842953e-31 5.1275165e-21], sampled 0.7002467139264364
[2019-03-26 12:19:09,028] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:19:09,030] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.50985306666666, 91.24886720666667, 1.0, 2.0, 0.4897413125986473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 684332.7768400114, 684332.7768400114, 182004.5005769795]
[2019-03-26 12:19:09,031] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:19:09,035] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1288274e-19 1.0000000e+00 1.0800492e-09 6.7789893e-26 6.5671192e-17], sampled 0.8209805543250492
[2019-03-26 12:19:28,198] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:19:28,198] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.657273155, 84.06103073, 1.0, 2.0, 0.4921952213401329, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 693034.3773995746, 693034.377399574, 183059.1769374423]
[2019-03-26 12:19:28,201] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:19:28,205] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.6316735e-18 9.9999869e-01 1.3397855e-06 2.2287908e-22 8.4738342e-14], sampled 0.5514863580457171
[2019-03-26 12:19:34,833] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:19:34,837] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.64921993, 80.98815841, 1.0, 2.0, 0.3184812474034184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5530966033817861, 6.911199999999999, 6.9112, 168.912956510431, 890136.3159248319, 890136.3159248325, 228115.0587983434]
[2019-03-26 12:19:34,839] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:19:34,841] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.6173599e-15 1.0176016e-04 9.9989820e-01 4.8947124e-14 3.4459141e-08], sampled 0.7532257025857014
[2019-03-26 12:19:55,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:19:55,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.5, 74.16666666666667, 1.0, 2.0, 0.2755951554380358, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4715108655029625, 6.9112, 6.9112, 168.912956510431, 770228.7556212682, 770228.7556212682, 213799.011866401]
[2019-03-26 12:19:55,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:19:55,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.5420122e-16 1.4202762e-06 9.9999857e-01 3.3087624e-14 6.3706493e-09], sampled 0.9568773619954803
[2019-03-26 12:20:29,042] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.3661366], dtype=float32), 0.12216152]
[2019-03-26 12:20:29,043] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.7, 69.0, 1.0, 2.0, 0.5839257228082229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 815990.5189219007, 815990.5189219007, 197789.707370799]
[2019-03-26 12:20:29,045] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:20:29,047] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.6935055e-19 1.0000000e+00 1.0865168e-08 8.8278239e-25 1.0301742e-15], sampled 0.6421795033451283
[2019-03-26 12:20:34,563] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8457.5232 2990182619.6476 889.0000
[2019-03-26 12:20:34,627] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8125.3869 3074975572.6765 1428.0000
[2019-03-26 12:20:34,692] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8752.8434 2823288105.7083 708.0000
[2019-03-26 12:20:34,765] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7920.9831 3202735743.0969 1633.0000
[2019-03-26 12:20:34,814] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8537.1584 2901798572.9298 900.0000
[2019-03-26 12:20:35,832] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1350000, evaluation results [1350000.0, 7920.983072873012, 3202735743.096925, 1633.0, 8457.52322112844, 2990182619.64763, 889.0, 8752.84338014076, 2823288105.7082543, 708.0, 8125.386865537994, 3074975572.676514, 1428.0, 8537.158430589338, 2901798572.9298067, 900.0]
[2019-03-26 12:20:38,191] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7622402e-22 1.0000000e+00 1.0356764e-12 9.1169596e-30 1.6612244e-19], sum to 1.0000
[2019-03-26 12:20:38,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4895
[2019-03-26 12:20:38,206] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 100.0, 1.0, 2.0, 0.3388692469458607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526324.1206999633, 526324.1206999633, 168834.9751701775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2965200.0000, 
sim time next is 2965800.0000, 
raw observation next is [21.0, 100.0, 1.0, 2.0, 0.3387240040536023, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526098.6374142431, 526098.6374142431, 168816.9948964921], 
processed observation next is [1.0, 0.30434782608695654, 0.19431279620853087, 1.0, 1.0, 1.0, 0.20328193259470156, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1461385103928453, 0.1461385103928453, 0.25196566402461507], 
reward next is 0.7480, 
noisyNet noise sample is [array([1.3015846], dtype=float32), 1.1167616]. 
=============================================
[2019-03-26 12:20:40,169] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.9385674e-20 1.0000000e+00 7.2436800e-11 1.4516063e-27 2.0793474e-18], sum to 1.0000
[2019-03-26 12:20:40,177] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-26 12:20:40,181] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 70.0, 1.0, 2.0, 0.5304637583312806, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 741255.5376612237, 741255.537661223, 188507.1194313451], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3236400.0000, 
sim time next is 3237000.0000, 
raw observation next is [30.33333333333333, 69.5, 1.0, 2.0, 0.5342622896260973, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 746565.3666367391, 746565.3666367391, 189139.0601715926], 
processed observation next is [0.0, 0.4782608695652174, 0.6366508688783569, 0.695, 1.0, 1.0, 0.4388702284651775, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2073792685102053, 0.2073792685102053, 0.2822971047337203], 
reward next is 0.7177, 
noisyNet noise sample is [array([-1.1405847], dtype=float32), -3.0783875]. 
=============================================
[2019-03-26 12:20:40,204] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.99295]
 [74.8352 ]
 [74.78498]
 [74.73033]
 [74.68083]], R is [[74.96648407]
 [74.93546295]
 [74.90422821]
 [74.87291718]
 [74.84152222]].
[2019-03-26 12:20:41,849] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8775730e-15 1.4863209e-06 9.9999797e-01 8.2729701e-14 6.0782929e-07], sum to 1.0000
[2019-03-26 12:20:41,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4125
[2019-03-26 12:20:41,868] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.66666666666667, 96.0, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2881972776300263, 6.9112, 6.9112, 168.912956510431, 504778.9420151696, 504778.9420151696, 191481.871742808], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2920800.0000, 
sim time next is 2921400.0000, 
raw observation next is [20.5, 97.0, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2858724132364898, 6.911200000000001, 6.9112, 168.912956510431, 500954.1734709943, 500954.1734709937, 190951.8103294224], 
processed observation next is [1.0, 0.8260869565217391, 0.1706161137440759, 0.97, 1.0, 1.0, 0.0, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.12911269906889003, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13915393707527618, 0.13915393707527604, 0.28500270198421257], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.12965311], dtype=float32), -0.37208638]. 
=============================================
[2019-03-26 12:20:49,532] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.6745055e-22 1.0000000e+00 1.1856148e-11 4.3603897e-29 1.0330060e-18], sum to 1.0000
[2019-03-26 12:20:49,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0317
[2019-03-26 12:20:49,554] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.0, 90.66666666666667, 1.0, 2.0, 0.4705692054495306, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 659226.4918818943, 659226.4918818943, 179331.9706583677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3206400.0000, 
sim time next is 3207000.0000, 
raw observation next is [25.0, 90.33333333333333, 1.0, 2.0, 0.4682276596196061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 657270.9418419404, 657270.9418419404, 179156.5997873862], 
processed observation next is [0.0, 0.08695652173913043, 0.38388625592417064, 0.9033333333333333, 1.0, 1.0, 0.3593104332766338, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18257526162276122, 0.18257526162276122, 0.26739791013042713], 
reward next is 0.7326, 
noisyNet noise sample is [array([0.7504332], dtype=float32), 0.03598734]. 
=============================================
[2019-03-26 12:20:49,569] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[75.72421 ]
 [75.935776]
 [76.412155]
 [76.74066 ]
 [76.475914]], R is [[75.78533173]
 [75.75981903]
 [75.73435974]
 [75.70890045]
 [75.6833725 ]].
[2019-03-26 12:20:49,917] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4274990e-20 1.0000000e+00 1.2711526e-10 2.4917968e-26 3.5731804e-16], sum to 1.0000
[2019-03-26 12:20:49,925] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4517
[2019-03-26 12:20:49,931] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.83333333333334, 95.0, 1.0, 2.0, 0.4005791927686967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 598270.7071811978, 598270.7071811978, 174393.3379000188], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3096600.0000, 
sim time next is 3097200.0000, 
raw observation next is [22.66666666666667, 96.0, 1.0, 2.0, 0.3975217528705691, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594620.1196329258, 594620.1196329253, 174085.4609062469], 
processed observation next is [1.0, 0.8695652173913043, 0.27330173775671435, 0.96, 1.0, 1.0, 0.2741225938199628, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16517225545359052, 0.16517225545359035, 0.2598290461287267], 
reward next is 0.7402, 
noisyNet noise sample is [array([-0.7271105], dtype=float32), -0.75661534]. 
=============================================
[2019-03-26 12:20:53,839] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.6400973e-20 1.0000000e+00 3.8391529e-10 4.8902562e-25 3.9111595e-16], sum to 1.0000
[2019-03-26 12:20:53,850] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8388
[2019-03-26 12:20:53,855] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.4792880274897444, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 669721.429146401, 669721.4291464004, 180414.0429977915], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3286800.0000, 
sim time next is 3287400.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.4782232211128876, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 668336.4610090401, 668336.4610090401, 180267.3459203605], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 1.0, 1.0, 0.37135327844926214, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1856490169469556, 0.1856490169469556, 0.26905574017964257], 
reward next is 0.7309, 
noisyNet noise sample is [array([-0.42909288], dtype=float32), -0.7807269]. 
=============================================
[2019-03-26 12:21:01,222] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8477123e-17 3.6583703e-25 9.9646533e-01 9.5623761e-04 2.5784213e-03], sum to 1.0000
[2019-03-26 12:21:01,232] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5278
[2019-03-26 12:21:01,239] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3013856.578232319 W.
[2019-03-26 12:21:01,244] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.33333333333334, 64.66666666666667, 1.0, 2.0, 0.7952469085007937, 1.0, 1.0, 0.7182134937646594, 1.0, 2.0, 1.03, 7.005105243488314, 6.9112, 170.5573041426782, 3013856.578232319, 2946588.432500558, 553101.5053541419], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3763200.0000, 
sim time next is 3763800.0000, 
raw observation next is [34.5, 63.5, 1.0, 2.0, 0.7976818252448177, 1.0, 2.0, 0.7194309521366715, 1.0, 2.0, 1.03, 7.005105435541496, 6.9112, 170.5573041426782, 3018971.602444283, 2951703.319137016, 553957.8783721346], 
processed observation next is [1.0, 0.5652173913043478, 0.8341232227488152, 0.635, 1.0, 1.0, 0.7562431629455635, 1.0, 1.0, 0.661965002574303, 1.0, 1.0, 1.0365853658536586, 0.009390543554149566, 0.0, 0.8375144448122397, 0.8386032229011898, 0.8199175886491711, 0.8268028035404995], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6042954], dtype=float32), 2.532712]. 
=============================================
[2019-03-26 12:21:01,473] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5507971e-16 8.3410715e-20 9.9563158e-01 9.8698265e-06 4.3585566e-03], sum to 1.0000
[2019-03-26 12:21:01,484] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2130
[2019-03-26 12:21:01,494] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2778307.999879687 W.
[2019-03-26 12:21:01,501] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.683107374043019, 1.0, 1.0, 0.6621437265357721, 1.0, 2.0, 1.03, 7.005096400225952, 6.9112, 170.5573041426782, 2778307.999879687, 2711046.188936478, 516046.3779150958], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3591600.0000, 
sim time next is 3592200.0000, 
raw observation next is [32.83333333333333, 63.66666666666666, 1.0, 2.0, 0.969187017815912, 1.0, 2.0, 0.969187017815912, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2711020.282657545, 2711020.282657545, 510645.6427017445], 
processed observation next is [1.0, 0.5652173913043478, 0.7551342812006318, 0.6366666666666666, 1.0, 1.0, 0.962875925079412, 1.0, 1.0, 0.962875925079412, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7530611896270959, 0.7530611896270959, 0.7621576756742455], 
reward next is 0.2378, 
noisyNet noise sample is [array([0.88362056], dtype=float32), -0.16981706]. 
=============================================
[2019-03-26 12:21:01,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.5066060e-21 1.0000000e+00 1.1102098e-12 1.8734372e-27 7.8299644e-20], sum to 1.0000
[2019-03-26 12:21:01,833] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5512
[2019-03-26 12:21:01,840] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.83333333333334, 64.33333333333333, 1.0, 2.0, 0.5874568731785758, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 820926.9322557616, 820926.9322557609, 198432.8783152514], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3255000.0000, 
sim time next is 3255600.0000, 
raw observation next is [32.66666666666667, 65.66666666666667, 1.0, 2.0, 0.5863683956701757, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819405.2798309708, 819405.2798309708, 198234.6409096399], 
processed observation next is [0.0, 0.6956521739130435, 0.7472353870458138, 0.6566666666666667, 1.0, 1.0, 0.5016486694821394, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22761257773082522, 0.22761257773082522, 0.29587259837259683], 
reward next is 0.7041, 
noisyNet noise sample is [array([0.4679009], dtype=float32), -0.62708426]. 
=============================================
[2019-03-26 12:21:03,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1318715e-22 1.0000000e+00 2.8240214e-12 2.7110370e-27 4.8342932e-19], sum to 1.0000
[2019-03-26 12:21:03,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1186
[2019-03-26 12:21:03,152] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 83.16666666666667, 1.0, 2.0, 0.5495049870031599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 767872.8468131485, 767872.846813149, 191715.3097223832], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3269400.0000, 
sim time next is 3270000.0000, 
raw observation next is [28.0, 82.33333333333334, 1.0, 2.0, 0.5391602199958581, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 753412.044838922, 753412.0448389213, 189958.9602197447], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.8233333333333335, 1.0, 1.0, 0.44477134939260005, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20928112356636722, 0.20928112356636702, 0.2835208361488727], 
reward next is 0.7165, 
noisyNet noise sample is [array([-0.6705086], dtype=float32), -0.1016022]. 
=============================================
[2019-03-26 12:21:03,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[78.138214]
 [78.19236 ]
 [78.0848  ]
 [78.05825 ]
 [78.01638 ]], R is [[78.13674927]
 [78.06924438]
 [78.003479  ]
 [77.93801117]
 [77.87281799]].
[2019-03-26 12:21:07,827] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4589193e-17 1.0000000e+00 4.9910494e-09 8.0306353e-22 8.3481095e-13], sum to 1.0000
[2019-03-26 12:21:07,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4727
[2019-03-26 12:21:07,843] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7899375170044503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104025.523458803, 1104025.523458803, 241455.0782144316], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3381600.0000, 
sim time next is 3382200.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7759260832202286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1084432.987340374, 1084432.987340373, 238086.6290498767], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.94, 1.0, 1.0, 0.7300314255665404, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3012313853723261, 0.30123138537232585, 0.35535317768638314], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.0474822], dtype=float32), -0.54341555]. 
=============================================
[2019-03-26 12:21:09,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.7912644e-17 1.0000000e+00 2.3382018e-08 4.4244175e-19 3.8623823e-11], sum to 1.0000
[2019-03-26 12:21:09,009] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6800
[2019-03-26 12:21:09,019] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7899375170044503, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104025.523458803, 1104025.523458803, 241455.0782142722], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3381600.0000, 
sim time next is 3382200.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.7759260832202286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1084432.987340374, 1084432.987340373, 238086.6290497706], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.94, 1.0, 1.0, 0.7300314255665404, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3012313853723261, 0.30123138537232585, 0.35535317768622476], 
reward next is 0.6446, 
noisyNet noise sample is [array([-0.1911853], dtype=float32), 1.1364142]. 
=============================================
[2019-03-26 12:21:13,721] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.9852897e-22 1.0000000e+00 2.4650067e-16 1.1963281e-29 1.0725016e-19], sum to 1.0000
[2019-03-26 12:21:13,730] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1574
[2019-03-26 12:21:13,738] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.5239995308192782, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 732219.4897511872, 732219.4897511872, 187441.802578741], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3615000.0000, 
sim time next is 3615600.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.5234008158471993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 731382.5773714219, 731382.5773714213, 187343.8294250153], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4257841154785534, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20316182704761718, 0.203161827047617, 0.2796176558582318], 
reward next is 0.7204, 
noisyNet noise sample is [array([-1.3801167], dtype=float32), 0.33538485]. 
=============================================
[2019-03-26 12:21:15,864] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4139517e-13 7.2942666e-15 5.1579839e-01 4.1339615e-01 7.0805468e-02], sum to 1.0000
[2019-03-26 12:21:15,872] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1746
[2019-03-26 12:21:15,877] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.8114491728616424, 1.0, 2.0, 0.8114491728616424, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2269393.619109331, 2269393.619109332, 425490.0108141552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3502800.0000, 
sim time next is 3503400.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.067309938467208, 6.9112, 168.9120137846243, 2394528.913947539, 2283779.768818722, 475729.384811776], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.63, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.015610993846720777, 0.0, 0.82943531593701, 0.665146920540983, 0.6343832691163117, 0.7100438579280238], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1597242], dtype=float32), -0.2937472]. 
=============================================
[2019-03-26 12:21:16,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.6083113e-11 1.8896887e-12 5.6454748e-01 7.9305684e-03 4.2752191e-01], sum to 1.0000
[2019-03-26 12:21:16,149] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2540
[2019-03-26 12:21:16,155] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 1.016821825676979, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005994218186961, 6.9112, 168.9123931057124, 2318547.456656924, 2251297.400021436, 468517.5021024283], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3502800.0000, 
sim time next is 3503400.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.172843608208121, 6.9112, 168.9113083876441, 2469466.028157987, 2283848.858544456, 475515.1600613885], 
processed observation next is [1.0, 0.5652173913043478, 0.7630331753554502, 0.63, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.026164360820812062, 0.0, 0.8294318521149052, 0.6859627855994409, 0.6344024607067933, 0.7097241194946097], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13301086], dtype=float32), 1.7035161]. 
=============================================
[2019-03-26 12:21:19,852] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.7292605e-25 1.0000000e+00 2.9579494e-21 4.5907459e-33 3.8886606e-26], sum to 1.0000
[2019-03-26 12:21:19,861] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4598
[2019-03-26 12:21:19,866] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 93.16666666666667, 1.0, 2.0, 0.5728608688741702, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 800522.4243562263, 800522.4243562256, 195798.149770918], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3905400.0000, 
sim time next is 3906000.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.56965823253359, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 796045.3461265904, 796045.3461265898, 195228.8253098582], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.94, 1.0, 1.0, 0.48151594281155424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22112370725738623, 0.22112370725738606, 0.29138630643262414], 
reward next is 0.7086, 
noisyNet noise sample is [array([0.73653173], dtype=float32), -0.67133576]. 
=============================================
[2019-03-26 12:21:19,880] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[70.75744 ]
 [70.702484]
 [70.85119 ]
 [70.91162 ]
 [71.0273  ]], R is [[70.91875458]
 [70.91732788]
 [70.91530609]
 [70.91308594]
 [70.91069031]].
[2019-03-26 12:21:28,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.0326447e-27 1.0000000e+00 2.9403515e-23 1.4595595e-32 1.2660272e-26], sum to 1.0000
[2019-03-26 12:21:28,963] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8448
[2019-03-26 12:21:28,972] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666667, 74.83333333333334, 1.0, 2.0, 0.7895435816668988, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1103474.668945929, 1103474.668945929, 241356.8499119864], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3739800.0000, 
sim time next is 3740400.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.8747429575698875, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1222618.795375424, 1222618.795375424, 263081.4571804818], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.74, 1.0, 1.0, 0.8490879006866114, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3396163320487289, 0.3396163320487289, 0.39265889131415194], 
reward next is 0.6073, 
noisyNet noise sample is [array([1.763041], dtype=float32), -0.48199126]. 
=============================================
[2019-03-26 12:21:30,851] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 12:21:30,853] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:21:30,853] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:21:30,854] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:21:30,854] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:21:30,856] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:21:30,856] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:21:30,859] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:21:30,859] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:21:30,855] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:21:30,861] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:21:30,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-26 12:21:30,910] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-26 12:21:30,911] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-26 12:21:30,951] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-26 12:21:30,970] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-26 12:21:52,923] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:21:52,924] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.732897495, 65.303204445, 1.0, 2.0, 0.4593750093511705, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651251.2244646619, 651251.2244646619, 178682.7370183774]
[2019-03-26 12:21:52,927] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:21:52,929] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.3000921e-33 1.0000000e+00 1.5189247e-31 0.0000000e+00 2.4313521e-36], sampled 0.9714000883693213
[2019-03-26 12:21:54,283] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:21:54,285] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.2, 95.0, 1.0, 2.0, 0.4105674953619807, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 605614.1123385016, 605614.1123385016, 174857.0122912386]
[2019-03-26 12:21:54,286] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:21:54,287] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.6931787e-31 1.0000000e+00 1.3293727e-28 1.2732268e-37 4.8452070e-33], sampled 0.759833088155068
[2019-03-26 12:22:12,209] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:22:12,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 1.0, 2.0, 0.3585533658802618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 552337.2054713342, 552337.2054713342, 170842.3505474839]
[2019-03-26 12:22:12,215] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:22:12,219] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5148328e-32 1.0000000e+00 1.1096894e-30 0.0000000e+00 1.3538871e-35], sampled 0.5458741852478417
[2019-03-26 12:22:23,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:22:23,271] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.1, 52.0, 1.0, 2.0, 0.977523792316472, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005992157048492, 6.9112, 168.9123159343439, 2263542.89173429, 2196294.328060504, 456452.5432935609]
[2019-03-26 12:22:23,272] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:22:23,275] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.9026976e-14 9.9999976e-01 2.1398453e-07 4.3487237e-08 7.1290263e-10], sampled 0.5565827917414562
[2019-03-26 12:22:23,276] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [0, 1, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2263542.89173429 W.
[2019-03-26 12:22:50,438] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:22:50,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.851187485, 84.73323801000001, 1.0, 2.0, 0.6389245377067275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 892879.3656050644, 892879.3656050644, 208212.7667708052]
[2019-03-26 12:22:50,440] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:22:50,445] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.2830056e-30 1.0000000e+00 3.3571312e-29 0.0000000e+00 4.5093436e-33], sampled 0.24986624530782064
[2019-03-26 12:23:10,756] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:23:10,757] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.98234002333334, 53.70889074000001, 1.0, 2.0, 0.2732221109544957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 444978.8305989597, 444978.8305989591, 163216.1021451098]
[2019-03-26 12:23:10,758] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:23:10,760] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2542264e-33 1.0000000e+00 1.4303793e-32 0.0000000e+00 1.0233164e-37], sampled 0.9700463054259703
[2019-03-26 12:23:21,050] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.3688654], dtype=float32), 0.11845569]
[2019-03-26 12:23:21,050] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.62992889, 58.25639924666667, 1.0, 2.0, 0.356385383223487, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 547531.6724380533, 547531.6724380526, 170398.2123940192]
[2019-03-26 12:23:21,054] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:23:21,057] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.5707007e-32 1.0000000e+00 6.8878007e-31 0.0000000e+00 7.6954056e-36], sampled 0.6778213803542245
[2019-03-26 12:23:26,063] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3940 2779173803.8581 933.0000
[2019-03-26 12:23:26,219] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7888.9030 3163632569.6908 1768.0000
[2019-03-26 12:23:26,353] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8497.4166 2842558242.3972 1131.0000
[2019-03-26 12:23:26,468] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.4622 3007575667.0416 1766.0000
[2019-03-26 12:23:26,483] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8253.5884 2927466011.8531 1338.0000
[2019-03-26 12:23:27,501] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1375000, evaluation results [1375000.0, 7888.903003365454, 3163632569.6908293, 1768.0, 8253.588413883566, 2927466011.853124, 1338.0, 8661.39403466329, 2779173803.858108, 933.0, 7999.462222096013, 3007575667.0416417, 1766.0, 8497.416582222564, 2842558242.397172, 1131.0]
[2019-03-26 12:23:32,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6339337e-21 1.0000000e+00 2.3327675e-19 9.8839795e-25 4.1756441e-21], sum to 1.0000
[2019-03-26 12:23:32,847] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2356
[2019-03-26 12:23:32,854] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.66666666666667, 84.0, 1.0, 2.0, 0.9280694841608178, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104099, 1297198.239250465, 1297198.239250465, 277778.0924400425], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4003800.0000, 
sim time next is 4004400.0000, 
raw observation next is [28.33333333333334, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.944486286505107, 6.9112, 168.9075041740807, 2187282.284948021, 1454257.092394317, 311352.3076941597], 
processed observation next is [1.0, 0.34782608695652173, 0.5418641390205374, 0.84, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.1033286286505107, 0.0, 0.8294131716847324, 0.6075784124855614, 0.4039603034428658, 0.46470493685695474], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.49874067], dtype=float32), 2.2251005]. 
=============================================
[2019-03-26 12:23:35,122] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6890399e-34 1.0000000e+00 3.6167860e-33 0.0000000e+00 5.9490383e-38], sum to 1.0000
[2019-03-26 12:23:35,130] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8227
[2019-03-26 12:23:35,134] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 89.83333333333334, 1.0, 2.0, 0.576277442121096, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805298.5933324341, 805298.5933324341, 196409.2361476552], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3903000.0000, 
sim time next is 3903600.0000, 
raw observation next is [27.66666666666667, 90.66666666666667, 1.0, 2.0, 0.576724529448313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 805923.5967779416, 805923.5967779416, 196489.2596508685], 
processed observation next is [0.0, 0.17391304347826086, 0.5102685624012641, 0.9066666666666667, 1.0, 1.0, 0.4900295535521843, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22386766577165043, 0.22386766577165043, 0.2932675517177142], 
reward next is 0.7067, 
noisyNet noise sample is [array([1.3159009], dtype=float32), -1.6264217]. 
=============================================
[2019-03-26 12:23:36,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.0671591e-33 1.0000000e+00 3.8837141e-31 0.0000000e+00 3.7939263e-36], sum to 1.0000
[2019-03-26 12:23:36,079] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7751
[2019-03-26 12:23:36,083] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.33333333333334, 73.66666666666666, 1.0, 2.0, 0.6007832373284243, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 839556.8869685862, 839556.8869685855, 200892.2111110543], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3919200.0000, 
sim time next is 3919800.0000, 
raw observation next is [31.66666666666667, 72.33333333333334, 1.0, 2.0, 0.6032727929619313, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843037.2654826796, 843037.2654826796, 201357.582725948], 
processed observation next is [0.0, 0.34782608695652173, 0.6998420221169038, 0.7233333333333334, 1.0, 1.0, 0.5220154132071461, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2341770181896332, 0.2341770181896332, 0.3005337055611164], 
reward next is 0.6995, 
noisyNet noise sample is [array([-3.159316], dtype=float32), -0.29678464]. 
=============================================
[2019-03-26 12:23:38,026] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3101713e-31 1.0000000e+00 2.4873282e-30 0.0000000e+00 1.5507900e-34], sum to 1.0000
[2019-03-26 12:23:38,034] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0529
[2019-03-26 12:23:38,040] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.5927436550983791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 828317.6943218128, 828317.6943218135, 199402.568686852], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3931200.0000, 
sim time next is 3931800.0000, 
raw observation next is [34.16666666666667, 59.33333333333333, 1.0, 2.0, 0.6513293883865268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 910222.2297468415, 910222.2297468421, 210695.5985835136], 
processed observation next is [0.0, 0.5217391304347826, 0.8183254344391787, 0.5933333333333333, 1.0, 1.0, 0.5799149257668997, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25283950826301155, 0.25283950826301166, 0.31447104266196063], 
reward next is 0.6855, 
noisyNet noise sample is [array([1.0027499], dtype=float32), 0.19012864]. 
=============================================
[2019-03-26 12:23:41,233] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.7732430e-13 9.9999988e-01 1.2168648e-07 1.5347672e-08 4.7807511e-08], sum to 1.0000
[2019-03-26 12:23:41,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8902
[2019-03-26 12:23:41,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2150496.272197678 W.
[2019-03-26 12:23:41,253] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.5126504757115304, 1.0, 2.0, 0.5126504757115304, 1.0, 1.0, 0.890304340207947, 6.911200000000001, 6.9112, 170.5573041426782, 2150496.272197678, 2150496.272197677, 424004.9616600471], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3985200.0000, 
sim time next is 3985800.0000, 
raw observation next is [29.83333333333333, 79.83333333333334, 1.0, 2.0, 0.6962518008012083, 1.0, 2.0, 0.6962518008012083, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1946933.772774822, 1946933.772774821, 372532.4547393019], 
processed observation next is [1.0, 0.13043478260869565, 0.6129541864139019, 0.7983333333333335, 1.0, 1.0, 0.6340383142183232, 1.0, 1.0, 0.6340383142183232, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.540814936881895, 0.5408149368818947, 0.5560185891631372], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0807842], dtype=float32), -0.8210824]. 
=============================================
[2019-03-26 12:23:46,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0789258e-30 1.0000000e+00 3.5673549e-29 1.0821989e-37 3.9373266e-31], sum to 1.0000
[2019-03-26 12:23:46,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0657
[2019-03-26 12:23:46,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.33333333333334, 83.16666666666667, 1.0, 2.0, 0.7867123272419863, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1099515.62842214, 1099515.62842214, 240676.6542889805], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4090200.0000, 
sim time next is 4090800.0000, 
raw observation next is [28.66666666666667, 82.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.64473704841129, 6.9112, 168.9032533276808, 2684309.508619515, 1454549.310208439, 310148.2285322465], 
processed observation next is [1.0, 0.34782608695652173, 0.5576619273301741, 0.8233333333333335, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.17335370484112902, 0.0, 0.829392298082863, 0.7456415301720876, 0.40404147505789967, 0.4629078037794724], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1413987], dtype=float32), 0.4194295]. 
=============================================
[2019-03-26 12:23:51,931] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2506130e-28 1.0000000e+00 1.8735639e-29 1.5182761e-38 9.7179198e-30], sum to 1.0000
[2019-03-26 12:23:51,938] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7431
[2019-03-26 12:23:51,949] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1707821.81482061 W.
[2019-03-26 12:23:51,954] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.33333333333334, 87.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.269084638573071, 6.9112, 168.9111733529958, 1707821.81482061, 1453928.815069771, 311356.1630318864], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4605600.0000, 
sim time next is 4606200.0000, 
raw observation next is [29.5, 86.5, 1.0, 2.0, 0.5922287983424038, 0.0, 2.0, 0.0, 1.0, 1.0, 1.028505569664333, 6.911200000000001, 6.9112, 168.9126543490887, 1655841.228878725, 1655841.228878724, 362763.2722736484], 
processed observation next is [1.0, 0.30434782608695654, 0.5971563981042655, 0.865, 1.0, 1.0, 0.5087093955932576, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0347628898345524, 8.881784197001253e-17, 0.0, 0.829438461401782, 0.45995589691075695, 0.45995589691075667, 0.5414377198114155], 
reward next is 0.4586, 
noisyNet noise sample is [array([-1.1551027], dtype=float32), 1.9793084]. 
=============================================
[2019-03-26 12:23:55,730] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1164669e-30 1.0000000e+00 2.5385668e-28 2.3381294e-35 5.2088780e-29], sum to 1.0000
[2019-03-26 12:23:55,739] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9427
[2019-03-26 12:23:55,746] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 75.0, 1.0, 2.0, 0.601006346581114, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 839868.7914228167, 839868.7914228167, 200933.5713125359], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4234200.0000, 
sim time next is 4234800.0000, 
raw observation next is [31.0, 75.0, 1.0, 2.0, 0.6011041619487852, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 840005.536335655, 840005.5363356543, 200951.8184427393], 
processed observation next is [1.0, 0.0, 0.6682464454976303, 0.75, 1.0, 1.0, 0.5194026047575726, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23333487120434862, 0.23333487120434843, 0.2999280872279691], 
reward next is 0.7001, 
noisyNet noise sample is [array([0.9694839], dtype=float32), -1.1271483]. 
=============================================
[2019-03-26 12:24:02,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2130695e-37 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00], sum to 1.0000
[2019-03-26 12:24:02,475] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5443
[2019-03-26 12:24:02,485] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 76.33333333333334, 1.0, 2.0, 0.5887426322615759, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 822724.3800377763, 822724.3800377763, 198668.8642275119], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4395000.0000, 
sim time next is 4395600.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.6045746050301529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844857.1927000735, 844857.1927000735, 201602.8412600016], 
processed observation next is [1.0, 0.9130434782608695, 0.6682464454976303, 0.79, 1.0, 1.0, 0.5235838614821119, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23468255352779818, 0.23468255352779818, 0.30089976307462923], 
reward next is 0.6991, 
noisyNet noise sample is [array([1.4133815], dtype=float32), 1.1848564]. 
=============================================
[2019-03-26 12:24:02,650] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.7685770e-30 1.0000000e+00 4.4867376e-29 0.0000000e+00 8.6804363e-30], sum to 1.0000
[2019-03-26 12:24:02,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8283
[2019-03-26 12:24:02,666] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 1915196.085861738 W.
[2019-03-26 12:24:02,669] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.5, 76.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.561204040691552, 6.9112, 168.9093175616714, 1915196.085861738, 1454070.782374474, 311349.5056219258], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4869000.0000, 
sim time next is 4869600.0000, 
raw observation next is [28.66666666666666, 75.66666666666666, 1.0, 2.0, 0.6968608884301223, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.97958502165887, 6.9112, 168.9120240186442, 1870736.080237522, 1822221.660069496, 384908.2422883371], 
processed observation next is [1.0, 0.34782608695652173, 0.5576619273301735, 0.7566666666666666, 1.0, 1.0, 0.6347721547350871, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.006838502165887039, 0.0, 0.8294353661907329, 0.5196489111770894, 0.5061726833526378, 0.5744899138631897], 
reward next is 0.0836, 
noisyNet noise sample is [array([0.03404303], dtype=float32), 1.1388937]. 
=============================================
[2019-03-26 12:24:16,516] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.8105211e-26 1.0000000e+00 1.0914051e-25 7.1736563e-33 8.6504436e-25], sum to 1.0000
[2019-03-26 12:24:16,524] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9674
[2019-03-26 12:24:16,530] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.16666666666666, 94.00000000000001, 1.0, 2.0, 0.9450630098866242, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1320965.517572562, 1320965.517572562, 282636.4787975872], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4597800.0000, 
sim time next is 4598400.0000, 
raw observation next is [27.33333333333334, 94.0, 1.0, 2.0, 0.9336194138699042, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1304960.355947803, 1304960.355947803, 279355.758820585], 
processed observation next is [1.0, 0.21739130434782608, 0.4944707740916275, 0.94, 1.0, 1.0, 0.9200233902047039, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3624889877632786, 0.3624889877632786, 0.4169488937620671], 
reward next is 0.5831, 
noisyNet noise sample is [array([-1.5200155], dtype=float32), -1.4481276]. 
=============================================
[2019-03-26 12:24:19,347] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.1415163e-31 1.0000000e+00 4.9496150e-34 0.0000000e+00 3.3921130e-33], sum to 1.0000
[2019-03-26 12:24:19,354] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3063
[2019-03-26 12:24:19,361] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.5589505377687268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 781076.8191990427, 781076.8191990422, 193348.4007264133], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4645200.0000, 
sim time next is 4645800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5595439798008855, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 781906.399618737, 781906.399618737, 193451.7580297513], 
processed observation next is [1.0, 0.782608695652174, 0.6682464454976303, 0.7, 1.0, 1.0, 0.4693300961456452, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21719622211631584, 0.21719622211631584, 0.288733967208584], 
reward next is 0.7113, 
noisyNet noise sample is [array([-0.16682243], dtype=float32), 0.99002904]. 
=============================================
[2019-03-26 12:24:22,367] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 12:24:22,372] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:24:22,373] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:24:22,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:24:22,374] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:24:22,374] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:24:22,377] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:24:22,378] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:24:22,381] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:24:22,379] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:24:22,386] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:24:22,405] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-26 12:24:22,425] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-26 12:24:22,449] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-26 12:24:22,450] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-26 12:24:22,489] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-26 12:24:25,916] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:24:25,917] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.8, 72.5, 1.0, 2.0, 0.2378780194009462, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 394294.3131115579, 394294.3131115579, 159567.5008656585]
[2019-03-26 12:24:25,918] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:24:25,921] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.5774616e-35 1.0000000e+00 1.2294262e-36 0.0000000e+00 1.8294634e-38], sampled 0.5528547885788836
[2019-03-26 12:24:42,111] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:24:42,113] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.20040141166667, 91.073798425, 1.0, 2.0, 0.5400709820497763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 812068.6913603131, 812068.6913603131, 197182.97859533]
[2019-03-26 12:24:42,114] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:24:42,119] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6081872e-33 1.0000000e+00 3.2596722e-35 0.0000000e+00 8.7461551e-36], sampled 0.6463754315605624
[2019-03-26 12:24:44,790] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:24:44,791] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.26666666666667, 85.0, 1.0, 2.0, 0.3581687164955957, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 549893.545817771, 549893.5458177704, 170584.802836403]
[2019-03-26 12:24:44,794] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:24:44,795] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9393376e-33 1.0000000e+00 6.1594256e-34 0.0000000e+00 1.0944936e-34], sampled 0.8141734563707133
[2019-03-26 12:24:58,607] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:24:58,609] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.03265484, 100.0, 1.0, 2.0, 0.6187271519338778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 864642.588689808, 864642.588689808, 204287.8250264528]
[2019-03-26 12:24:58,609] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:24:58,613] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5043816e-31 1.0000000e+00 4.2206051e-32 0.0000000e+00 6.8969204e-32], sampled 0.7623422921573685
[2019-03-26 12:25:11,026] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:25:11,027] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.573834901793472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 801884.0630500738, 801884.0630500738, 195973.3259548839]
[2019-03-26 12:25:11,029] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:25:11,033] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1070306e-33 1.0000000e+00 5.1344870e-35 0.0000000e+00 1.2176695e-35], sampled 0.7727901658778918
[2019-03-26 12:25:39,078] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:25:39,080] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.86666666666667, 75.0, 1.0, 2.0, 0.5699056299228997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 796391.1909850012, 796391.1909850012, 195272.5886169701]
[2019-03-26 12:25:39,081] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:25:39,086] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.0364029e-31 1.0000000e+00 4.8958755e-32 0.0000000e+00 7.6111655e-32], sampled 0.9351687997689245
[2019-03-26 12:26:05,769] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.35403693], dtype=float32), 0.1170701]
[2019-03-26 12:26:05,770] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.527814735, 94.811273325, 1.0, 2.0, 0.7085841158668151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 991645.7004076663, 991645.7004076657, 222891.5163660827]
[2019-03-26 12:26:05,772] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:26:05,774] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.168381e-32 1.000000e+00 7.440690e-34 0.000000e+00 6.891496e-34], sampled 0.6454543841040601
[2019-03-26 12:26:17,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8254.3522 2927339884.6415 1341.0000
[2019-03-26 12:26:18,027] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8659.7529 2779346042.1477 934.0000
[2019-03-26 12:26:18,135] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7999.2377 3007604634.4066 1766.0000
[2019-03-26 12:26:18,166] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7884.1010 3164061252.6727 1786.0000
[2019-03-26 12:26:18,193] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8495.8455 2842521113.3489 1135.0000
[2019-03-26 12:26:19,210] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1400000, evaluation results [1400000.0, 7884.101041635421, 3164061252.6726646, 1786.0, 8254.352174756372, 2927339884.6415243, 1341.0, 8659.752937403717, 2779346042.1477203, 934.0, 7999.237681330799, 3007604634.4066215, 1766.0, 8495.845525711007, 2842521113.3489027, 1135.0]
[2019-03-26 12:26:21,781] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.1181561e-29 1.0000000e+00 4.6955469e-32 1.1385996e-37 8.4905532e-30], sum to 1.0000
[2019-03-26 12:26:21,794] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1874
[2019-03-26 12:26:21,798] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5163743409950602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 721560.684549907, 721560.6845499076, 186201.8923903371], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4734600.0000, 
sim time next is 4735200.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 1.0, 2.0, 0.5158180632273026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720783.1007017494, 720783.10070175, 186112.0459839604], 
processed observation next is [1.0, 0.8260869565217391, 0.5576619273301741, 0.7566666666666667, 1.0, 1.0, 0.41664826894855733, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20021752797270817, 0.20021752797270834, 0.27777917311038863], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.25931635], dtype=float32), 0.22780946]. 
=============================================
[2019-03-26 12:26:32,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1763378e-27 1.0000000e+00 8.1177947e-31 6.3242610e-33 8.5205423e-28], sum to 1.0000
[2019-03-26 12:26:32,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7082
[2019-03-26 12:26:32,046] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.16666666666667, 69.33333333333333, 1.0, 2.0, 0.477786027618984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667621.9867698707, 667621.9867698707, 180190.1178117446], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4902600.0000, 
sim time next is 4903200.0000, 
raw observation next is [29.0, 70.0, 1.0, 2.0, 0.4822587121336495, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 673873.7594510508, 673873.7594510501, 180864.0671064213], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.7, 1.0, 1.0, 0.3762153158236741, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18718715540306965, 0.18718715540306946, 0.26994636881555417], 
reward next is 0.7301, 
noisyNet noise sample is [array([-0.04721593], dtype=float32), 0.23417816]. 
=============================================
[2019-03-26 12:26:37,118] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.1523999e-31 1.0000000e+00 5.3164274e-33 2.5744123e-38 8.6959959e-34], sum to 1.0000
[2019-03-26 12:26:37,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7987
[2019-03-26 12:26:37,126] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 74.0, 1.0, 2.0, 0.52713651146288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 736604.5218805672, 736604.5218805678, 187956.8702118441], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5166000.0000, 
sim time next is 5166600.0000, 
raw observation next is [28.83333333333334, 74.83333333333334, 1.0, 2.0, 0.5311699439436665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742242.6868791814, 742242.6868791814, 188623.3436413643], 
processed observation next is [0.0, 0.8260869565217391, 0.5655608214849924, 0.7483333333333334, 1.0, 1.0, 0.4351445107755017, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20617852413310594, 0.20617852413310594, 0.28152737856920046], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.32618007], dtype=float32), 0.73320717]. 
=============================================
[2019-03-26 12:26:39,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.2250693e-17 1.0000000e+00 1.1826785e-15 1.7454536e-15 2.9211567e-11], sum to 1.0000
[2019-03-26 12:26:39,110] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8306
[2019-03-26 12:26:39,119] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 2772518.10512884 W.
[2019-03-26 12:26:39,126] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.2, 87.0, 1.0, 2.0, 0.6803506653049258, 1.0, 1.0, 0.6607653721667255, 1.0, 1.0, 1.03, 7.005096182875381, 6.9112, 170.5573041426782, 2772518.10512884, 2705256.449882685, 515194.8643187703], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5365200.0000, 
sim time next is 5365800.0000, 
raw observation next is [29.15, 87.5, 1.0, 2.0, 0.6452569525449728, 1.0, 2.0, 0.6452569525449728, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1804216.461397768, 1804216.461397769, 351582.2034580917], 
processed observation next is [1.0, 0.08695652173913043, 0.5805687203791469, 0.875, 1.0, 1.0, 0.5725987380059914, 1.0, 1.0, 0.5725987380059914, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5011712392771578, 0.501171239277158, 0.5247495574001368], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.308354], dtype=float32), -0.39637703]. 
=============================================
[2019-03-26 12:26:41,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.2131187e-11 9.9972707e-01 6.8909606e-10 1.1302528e-05 2.6160281e-04], sum to 1.0000
[2019-03-26 12:26:41,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6589
[2019-03-26 12:26:41,597] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 2242353.583290078 W.
[2019-03-26 12:26:41,601] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.06666666666667, 48.66666666666666, 1.0, 2.0, 0.534526231023865, 1.0, 2.0, 0.534526231023865, 1.0, 1.0, 0.9171211615637679, 6.9112, 6.9112, 170.5573041426782, 2242353.583290078, 2242353.583290078, 437657.2104823263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5581200.0000, 
sim time next is 5581800.0000, 
raw observation next is [34.0, 49.0, 1.0, 2.0, 0.518312506507289, 1.0, 2.0, 0.518312506507289, 1.0, 2.0, 0.8896782832472143, 6.911199999999999, 6.9112, 170.5573041426782, 2174271.796776015, 2174271.796776015, 426064.2529862681], 
processed observation next is [1.0, 0.6086956521739131, 0.8104265402843602, 0.49, 1.0, 1.0, 0.4196536222979385, 1.0, 1.0, 0.4196536222979385, 1.0, 1.0, 0.8654613210331882, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6039643879933374, 0.6039643879933374, 0.6359167955018926], 
reward next is 0.3641, 
noisyNet noise sample is [array([1.077324], dtype=float32), 1.7703066]. 
=============================================
[2019-03-26 12:26:45,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.2843397e-33 1.0000000e+00 2.8970896e-35 0.0000000e+00 1.5345765e-35], sum to 1.0000
[2019-03-26 12:26:45,518] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1997
[2019-03-26 12:26:45,523] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 65.0, 1.0, 2.0, 0.5125044579218224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716151.2431057073, 716151.2431057073, 185578.5904867777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134800.0000, 
sim time next is 5135400.0000, 
raw observation next is [30.5, 64.5, 1.0, 2.0, 0.5153740946603607, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 720162.5068553776, 720162.506855377, 186040.0357613687], 
processed observation next is [0.0, 0.43478260869565216, 0.6445497630331753, 0.645, 1.0, 1.0, 0.4161133670606755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20004514079316044, 0.20004514079316027, 0.2776716951662219], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.39363477], dtype=float32), -0.7324413]. 
=============================================
[2019-03-26 12:26:47,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.6396360e-32 1.0000000e+00 2.1602231e-35 0.0000000e+00 3.6121651e-34], sum to 1.0000
[2019-03-26 12:26:47,514] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4069
[2019-03-26 12:26:47,518] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.01666666666667, 88.16666666666667, 1.0, 2.0, 0.5691164941061998, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 795288.0327493323, 795288.032749333, 195133.373759114], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5602200.0000, 
sim time next is 5602800.0000, 
raw observation next is [27.93333333333334, 88.33333333333334, 1.0, 2.0, 0.5678499471285307, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 793517.4885544695, 793517.4885544688, 194909.1621618885], 
processed observation next is [1.0, 0.8695652173913043, 0.5229067930489735, 0.8833333333333334, 1.0, 1.0, 0.4793372856970249, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22042152459846376, 0.22042152459846356, 0.29090919725655], 
reward next is 0.7091, 
noisyNet noise sample is [array([-0.54980433], dtype=float32), 1.2968625]. 
=============================================
[2019-03-26 12:26:48,367] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.4296072e-21 1.0000000e+00 8.8194950e-21 4.5130145e-23 7.7597943e-19], sum to 1.0000
[2019-03-26 12:26:48,379] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6955
[2019-03-26 12:26:48,386] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1702428.66006339 W.
[2019-03-26 12:26:48,391] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.4059217522745727, 1.0, 1.0, 0.4059217522745727, 1.0, 1.0, 0.6927382427246395, 6.9112, 6.9112, 170.5573041426782, 1702428.66006339, 1702428.66006339, 354435.8400159031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5192400.0000, 
sim time next is 5193000.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.3586940990072854, 1.0, 2.0, 0.3586940990072854, 1.0, 2.0, 0.6101828481071936, 6.911199999999999, 6.9112, 170.5573041426782, 1504217.71283254, 1504217.712832541, 329616.1813901248], 
processed observation next is [1.0, 0.08695652173913043, 0.4549763033175356, 0.865, 1.0, 1.0, 0.22734228796058478, 1.0, 1.0, 0.22734228796058478, 1.0, 1.0, 0.5246132293990166, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4178382535645945, 0.4178382535645947, 0.4919644498360071], 
reward next is 0.5080, 
noisyNet noise sample is [array([0.27485353], dtype=float32), -0.34521192]. 
=============================================
[2019-03-26 12:26:48,417] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.176575]
 [58.44386 ]
 [63.76279 ]
 [63.056885]
 [63.11775 ]], R is [[53.56987381]
 [53.50516891]
 [52.97011948]
 [53.1627121 ]
 [53.35322571]].
[2019-03-26 12:26:50,625] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.3171797e-32 1.0000000e+00 1.0233027e-33 0.0000000e+00 1.5185406e-33], sum to 1.0000
[2019-03-26 12:26:50,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3659
[2019-03-26 12:26:50,638] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.83333333333334, 1.0, 2.0, 0.7764288341535345, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1085135.990213606, 1085135.990213606, 238205.908052178], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5208600.0000, 
sim time next is 5209200.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.8338853739478573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1165481.24948663, 1165481.24948663, 252397.1261728504], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.79, 1.0, 1.0, 0.7998618963227196, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32374479152406394, 0.32374479152406394, 0.37671212861619463], 
reward next is 0.6233, 
noisyNet noise sample is [array([1.1112539], dtype=float32), -0.43268013]. 
=============================================
[2019-03-26 12:26:58,849] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9010986e-25 1.0000000e+00 5.1445263e-27 6.0437149e-30 2.2632585e-25], sum to 1.0000
[2019-03-26 12:26:58,858] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2919
[2019-03-26 12:26:58,866] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.3, 87.33333333333333, 1.0, 2.0, 0.8827643314145687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1233836.697391057, 1233836.697391058, 265246.1361687677], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5377800.0000, 
sim time next is 5378400.0000, 
raw observation next is [29.5, 86.0, 1.0, 2.0, 0.8926081449586144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247603.445734231, 1247603.445734231, 267918.0238271717], 
processed observation next is [1.0, 0.2608695652173913, 0.5971563981042655, 0.86, 1.0, 1.0, 0.8706122228417041, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.34655651270395305, 0.34655651270395305, 0.39987764750324134], 
reward next is 0.6001, 
noisyNet noise sample is [array([1.5003426], dtype=float32), -0.34584886]. 
=============================================
[2019-03-26 12:27:12,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.0386704e-18 1.0000000e+00 9.7113306e-21 4.9919077e-16 2.1426410e-15], sum to 1.0000
[2019-03-26 12:27:12,332] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2157
[2019-03-26 12:27:12,337] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.46666666666667, 58.33333333333334, 1.0, 2.0, 0.4924342611926723, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565095545, 688096.9474466015, 688096.9474466008, 182422.4000320038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5592000.0000, 
sim time next is 5592600.0000, 
raw observation next is [32.2, 60.0, 1.0, 2.0, 0.4871478794107215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104308, 680707.7202588201, 680707.7202588207, 181610.6447324999], 
processed observation next is [1.0, 0.7391304347826086, 0.7251184834123224, 0.6, 1.0, 1.0, 0.38210587880809826, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523017, 0.18908547784967225, 0.18908547784967242, 0.2710606637798506], 
reward next is 0.7289, 
noisyNet noise sample is [array([-0.86643225], dtype=float32), 1.6105902]. 
=============================================
[2019-03-26 12:27:14,441] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-26 12:27:14,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:27:14,444] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:27:14,445] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:27:14,445] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:27:14,446] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:27:14,445] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:27:14,447] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:27:14,449] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:27:14,449] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:27:14,452] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:27:14,482] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-26 12:27:14,483] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-26 12:27:14,502] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-26 12:27:14,551] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-26 12:27:14,576] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-26 12:27:32,242] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.39737216], dtype=float32), 0.11961413]
[2019-03-26 12:27:32,242] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.86666666666667, 92.33333333333334, 1.0, 2.0, 0.3665101887854174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 569940.3009527042, 569940.3009527042, 172461.4239260066]
[2019-03-26 12:27:32,243] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:27:32,247] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.3645099e-34 1.0000000e+00 6.3900359e-38 0.0000000e+00 5.5188195e-38], sampled 0.5501913228777982
[2019-03-26 12:29:04,676] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.39737216], dtype=float32), 0.11961413]
[2019-03-26 12:29:04,677] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.50330709666667, 74.10324871833335, 1.0, 2.0, 0.4801703519950087, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 670954.7131153286, 670954.7131153279, 180546.8803093506]
[2019-03-26 12:29:04,678] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:29:04,682] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.2814980e-33 1.0000000e+00 2.6932334e-36 0.0000000e+00 1.1892808e-35], sampled 0.5430732506608654
[2019-03-26 12:29:09,706] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7891.2577 3163538332.9404 1762.0000
[2019-03-26 12:29:09,906] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8661.3694 2779190338.1949 933.0000
[2019-03-26 12:29:10,036] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8255.0653 2927317329.7462 1338.0000
[2019-03-26 12:29:10,051] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7998.5013 3007529879.1007 1768.0000
[2019-03-26 12:29:10,104] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8496.0344 2842500170.3949 1131.0000
[2019-03-26 12:29:11,118] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1425000, evaluation results [1425000.0, 7891.2577367888525, 3163538332.9403734, 1762.0, 8255.065342017213, 2927317329.746172, 1338.0, 8661.369356548688, 2779190338.194891, 933.0, 7998.50133146889, 3007529879.1007094, 1768.0, 8496.034361333246, 2842500170.394918, 1131.0]
[2019-03-26 12:29:22,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.4684984e-21 1.0000000e+00 7.2883336e-22 4.8150161e-22 9.3985605e-19], sum to 1.0000
[2019-03-26 12:29:22,807] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4132
[2019-03-26 12:29:22,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 1 has been changed to 4 for the demand 1985223.271569236 W.
[2019-03-26 12:29:22,821] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.2, 81.5, 1.0, 2.0, 0.4732880046743647, 1.0, 1.0, 0.4732880046743647, 1.0, 1.0, 0.8219447453844791, 6.9112, 6.9112, 170.5573041426782, 1985223.271569236, 1985223.271569236, 397165.8105694154], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5992200.0000, 
sim time next is 5992800.0000, 
raw observation next is [29.36666666666667, 80.66666666666667, 1.0, 2.0, 0.4717976824473544, 1.0, 2.0, 0.4717976824473544, 1.0, 2.0, 0.8193565485332541, 6.9112, 6.9112, 170.5573041426782, 1978966.288670331, 1978966.288670331, 396191.6175872262], 
processed observation next is [1.0, 0.34782608695652173, 0.5908372827804109, 0.8066666666666668, 1.0, 1.0, 0.36361166559922214, 1.0, 1.0, 0.36361166559922214, 1.0, 1.0, 0.7797031079673831, 0.0, 0.0, 0.8375144448122397, 0.5497128579639808, 0.5497128579639808, 0.5913307725182481], 
reward next is 0.4087, 
noisyNet noise sample is [array([0.7463844], dtype=float32), 0.8155805]. 
=============================================
[2019-03-26 12:29:24,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.4793248e-25 1.0000000e+00 2.1033638e-30 1.8269770e-27 1.7311076e-26], sum to 1.0000
[2019-03-26 12:29:24,182] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2169
[2019-03-26 12:29:24,188] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.4, 68.0, 1.0, 2.0, 0.5145613744208694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 719026.4607476827, 719026.4607476827, 185913.0687880618], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5851800.0000, 
sim time next is 5852400.0000, 
raw observation next is [31.2, 69.0, 1.0, 2.0, 0.5264994225176146, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 735713.9648746852, 735713.9648746852, 187855.3627484704], 
processed observation next is [1.0, 0.7391304347826086, 0.6777251184834123, 0.69, 1.0, 1.0, 0.4295173765272465, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2043649902429681, 0.2043649902429681, 0.28038113843055285], 
reward next is 0.7196, 
noisyNet noise sample is [array([1.1629518], dtype=float32), 1.3101096]. 
=============================================
[2019-03-26 12:29:53,400] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8915233e-30 1.0000000e+00 4.2840575e-34 1.5572397e-34 7.0244471e-33], sum to 1.0000
[2019-03-26 12:29:53,409] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1815
[2019-03-26 12:29:53,415] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.95, 62.83333333333333, 1.0, 2.0, 0.5292061733555125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 739497.6111338534, 739497.611133854, 188298.0382992323], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6354600.0000, 
sim time next is 6355200.0000, 
raw observation next is [30.9, 62.66666666666667, 1.0, 2.0, 0.5197484419251602, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 726277.12896356, 726277.1289635594, 186748.0054003445], 
processed observation next is [0.0, 0.5652173913043478, 0.6635071090047393, 0.6266666666666667, 1.0, 1.0, 0.4213836649700725, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20174364693432223, 0.20174364693432206, 0.2787283662691709], 
reward next is 0.7213, 
noisyNet noise sample is [array([1.1126547], dtype=float32), -0.9269042]. 
=============================================
[2019-03-26 12:30:02,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.4370146e-23 1.0000000e+00 6.7087332e-26 1.7036227e-22 1.8411422e-22], sum to 1.0000
[2019-03-26 12:30:02,492] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5820
[2019-03-26 12:30:02,503] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 1 has been changed to 3 for the demand 1965114.921603189 W.
[2019-03-26 12:30:02,508] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.63333333333334, 83.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.631521474754371, 6.9112, 168.9093597728707, 1965114.921603189, 1454104.957251263, 311350.1458003531], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6510000.0000, 
sim time next is 6510600.0000, 
raw observation next is [27.85, 81.5, 1.0, 2.0, 0.6598305923268611, 1.0, 1.0, 0.6598305923268611, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1845001.203879803, 1845001.203879803, 357399.320526886], 
processed observation next is [1.0, 0.34782608695652173, 0.5189573459715641, 0.815, 1.0, 1.0, 0.5901573401528447, 1.0, 0.5, 0.5901573401528447, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5125003344110564, 0.5125003344110564, 0.5334318216819194], 
reward next is 0.4666, 
noisyNet noise sample is [array([0.4310114], dtype=float32), 0.5139041]. 
=============================================
[2019-03-26 12:30:03,249] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.6106663e-13 2.7579346e-03 4.3250712e-14 9.9724209e-01 3.3328273e-08], sum to 1.0000
[2019-03-26 12:30:03,256] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9297
[2019-03-26 12:30:03,266] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.35, 56.16666666666667, 1.0, 2.0, 0.6984642632545979, 1.0, 2.0, 0.6984642632545979, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1953126.136264089, 1953126.136264089, 373457.2837115703], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6522600.0000, 
sim time next is 6523200.0000, 
raw observation next is [31.4, 56.0, 1.0, 2.0, 0.728277648213785, 1.0, 2.0, 0.728277648213785, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2036572.994209036, 2036572.994209036, 386454.0150860671], 
processed observation next is [1.0, 0.5217391304347826, 0.6872037914691943, 0.56, 1.0, 1.0, 0.672623672546729, 1.0, 1.0, 0.672623672546729, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5657147206136212, 0.5657147206136212, 0.5767970374418911], 
reward next is 0.4232, 
noisyNet noise sample is [array([0.45308784], dtype=float32), 0.8490454]. 
=============================================
[2019-03-26 12:30:05,888] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 12:30:05,889] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:30:05,890] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:30:05,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:30:05,892] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:30:05,892] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:30:05,892] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:30:05,893] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:30:05,896] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:30:05,899] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:30:05,897] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:30:05,921] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run59
[2019-03-26 12:30:05,945] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run59
[2019-03-26 12:30:05,946] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run59
[2019-03-26 12:30:05,990] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run59
[2019-03-26 12:30:06,014] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run59
[2019-03-26 12:30:17,976] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:30:17,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.68140569, 91.98295214000001, 1.0, 2.0, 0.2835493652643822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 461247.9566507352, 461247.9566507352, 164307.2522047957]
[2019-03-26 12:30:17,980] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:30:17,983] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1928335e-28 1.0000000e+00 5.1319297e-32 1.9358054e-28 4.6016560e-31], sampled 0.3420638484782872
[2019-03-26 12:30:24,710] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:30:24,712] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.79357961, 76.26595044333334, 1.0, 2.0, 0.5368813528326328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 750226.4754569833, 750226.4754569827, 189575.9269703545]
[2019-03-26 12:30:24,714] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:30:24,717] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.0507248e-26 1.0000000e+00 1.9673618e-29 2.9246202e-25 1.6474601e-27], sampled 0.3186847121261436
[2019-03-26 12:30:27,355] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:30:27,357] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.53333333333333, 96.0, 1.0, 2.0, 0.3428002150982115, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 531282.5586665417, 531282.558666541, 169200.4993951761]
[2019-03-26 12:30:27,359] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:30:27,362] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.6367636e-28 1.0000000e+00 2.5810588e-31 1.2329255e-28 2.0883970e-30], sampled 0.38287882949768626
[2019-03-26 12:30:35,059] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:30:35,061] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.23333333333333, 95.83333333333333, 1.0, 2.0, 0.4650883855131099, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 654539.6954840053, 654539.6954840046, 178909.694666516]
[2019-03-26 12:30:35,063] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:30:35,066] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.8441529e-31 1.0000000e+00 2.2202422e-35 9.1386593e-36 2.7871031e-35], sampled 0.34970390380273
[2019-03-26 12:30:42,077] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:30:42,079] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.45, 92.16666666666667, 1.0, 2.0, 0.4629934070451671, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 658802.8018313923, 658802.8018313923, 179525.2513932549]
[2019-03-26 12:30:42,080] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:30:42,083] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [5.0924552e-26 1.0000000e+00 7.1222996e-29 3.1559793e-24 4.4699151e-27], sampled 0.310675602626616
[2019-03-26 12:31:08,342] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:31:08,344] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.21754239666667, 74.12776088333334, 1.0, 2.0, 0.5963511230095155, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833360.8554462717, 833360.8554462717, 200068.5944606708]
[2019-03-26 12:31:08,345] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:31:08,348] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.9019120e-26 1.0000000e+00 8.4071151e-29 1.9558740e-23 1.4674133e-26], sampled 0.8482421920531852
[2019-03-26 12:31:19,278] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:31:19,280] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.342849945, 86.80359025499999, 1.0, 2.0, 0.4777217553023215, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 674761.2598822634, 674761.2598822634, 181109.019985882]
[2019-03-26 12:31:19,282] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:31:19,284] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1071477e-31 1.0000000e+00 2.3867463e-36 2.3337785e-37 2.7110866e-36], sampled 0.5449624666347966
[2019-03-26 12:31:51,120] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4276826], dtype=float32), 0.122959815]
[2019-03-26 12:31:51,121] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.573748435, 91.469905645, 1.0, 2.0, 0.8621201477777467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1204966.019058918, 1204966.019058918, 259732.8622018991]
[2019-03-26 12:31:51,122] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:31:51,123] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6228246e-24 1.0000000e+00 1.0044785e-27 6.8062556e-24 1.2404424e-25], sampled 0.8705908928965167
[2019-03-26 12:32:01,241] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8301.0787 2923200128.0174 1230.0000
[2019-03-26 12:32:01,327] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8010.4351 3151649364.5515 1452.0000
[2019-03-26 12:32:01,374] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8123.3789 2994863597.7493 1436.0000
[2019-03-26 12:32:01,516] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8543.2688 2837360074.2376 996.0000
[2019-03-26 12:32:01,794] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8679.6493 2777496467.0049 891.0000
[2019-03-26 12:32:02,812] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1450000, evaluation results [1450000.0, 8010.435079882253, 3151649364.5515146, 1452.0, 8301.078651151034, 2923200128.0173783, 1230.0, 8679.649321751913, 2777496467.0049324, 891.0, 8123.378931785859, 2994863597.7493243, 1436.0, 8543.2687926383, 2837360074.2375636, 996.0]
[2019-03-26 12:32:06,332] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.4207864e-26 1.0000000e+00 8.9563836e-32 3.5678892e-27 7.7191340e-28], sum to 1.0000
[2019-03-26 12:32:06,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5392
[2019-03-26 12:32:06,349] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.26666666666667, 85.0, 1.0, 2.0, 0.518071380718566, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723932.8674980478, 723932.8674980478, 186476.4307149869], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6632400.0000, 
sim time next is 6633000.0000, 
raw observation next is [27.25, 85.0, 1.0, 2.0, 0.5196585907159637, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 726151.5313130427, 726151.5313130427, 186733.8434060933], 
processed observation next is [1.0, 0.782608695652174, 0.490521327014218, 0.85, 1.0, 1.0, 0.421275410501161, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20170875869806743, 0.20170875869806743, 0.2787072289643184], 
reward next is 0.7213, 
noisyNet noise sample is [array([0.25221714], dtype=float32), -0.28169754]. 
=============================================
[2019-03-26 12:32:06,369] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.89567 ]
 [75.55962 ]
 [75.549446]
 [75.95727 ]
 [76.251526]], R is [[74.31084442]
 [74.28941345]
 [74.2686615 ]
 [74.24938202]
 [74.23151398]].
[2019-03-26 12:32:08,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2270082e-29 1.0000000e+00 1.0697074e-33 3.5115202e-32 2.5710242e-32], sum to 1.0000
[2019-03-26 12:32:08,731] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9409
[2019-03-26 12:32:08,739] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.85, 94.5, 1.0, 2.0, 0.5110089708985874, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714060.8127822543, 714060.812782255, 185337.2870509841], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6672600.0000, 
sim time next is 6673200.0000, 
raw observation next is [24.93333333333334, 94.33333333333334, 1.0, 2.0, 0.5131583374818991, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 717065.2541081898, 717065.2541081905, 185681.7564081294], 
processed observation next is [1.0, 0.21739130434782608, 0.3807266982622437, 0.9433333333333335, 1.0, 1.0, 0.4134437800986736, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19918479280783052, 0.19918479280783072, 0.27713694986287973], 
reward next is 0.7229, 
noisyNet noise sample is [array([-0.17842314], dtype=float32), -3.3467662]. 
=============================================
[2019-03-26 12:32:13,496] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2255117e-21 1.0000000e+00 7.4571234e-24 7.9671271e-17 1.4576989e-20], sum to 1.0000
[2019-03-26 12:32:13,506] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8104
[2019-03-26 12:32:13,511] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.06666666666666, 90.33333333333334, 1.0, 2.0, 0.4734810867919897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 663170.6182680926, 663170.6182680926, 179747.5908438063], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7087200.0000, 
sim time next is 7087800.0000, 
raw observation next is [25.03333333333333, 90.66666666666667, 1.0, 2.0, 0.4733658023761965, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 662661.4765737271, 662661.4765737278, 179685.4985024148], 
processed observation next is [1.0, 0.0, 0.38546603475513425, 0.9066666666666667, 1.0, 1.0, 0.365500966718309, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18407263238159086, 0.18407263238159105, 0.268187311197634], 
reward next is 0.7318, 
noisyNet noise sample is [array([1.4695338], dtype=float32), -1.0107284]. 
=============================================
[2019-03-26 12:32:20,596] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6910604e-29 1.0000000e+00 7.0927552e-34 2.4769505e-30 2.1314866e-32], sum to 1.0000
[2019-03-26 12:32:20,603] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1836
[2019-03-26 12:32:20,608] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.55, 40.0, 1.0, 2.0, 0.2864170410564127, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 459727.3100937979, 459727.3100937979, 164248.2140410685], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6881400.0000, 
sim time next is 6882000.0000, 
raw observation next is [29.5, 41.0, 1.0, 2.0, 0.2924279107276614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 467815.3221836995, 467815.3221836995, 164791.1833375826], 
processed observation next is [0.0, 0.6521739130434783, 0.5971563981042655, 0.41, 1.0, 1.0, 0.14750350690079683, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1299487006065832, 0.1299487006065832, 0.24595699005609342], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.7963919], dtype=float32), -2.4066298]. 
=============================================
[2019-03-26 12:32:20,620] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[82.29114 ]
 [82.312416]
 [82.293816]
 [82.32878 ]
 [82.25578 ]], R is [[82.20065308]
 [82.13349915]
 [82.06799316]
 [82.0032959 ]
 [81.94001007]].
[2019-03-26 12:32:26,930] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0365402e-23 1.0000000e+00 5.1610353e-28 2.6967980e-23 3.0463604e-25], sum to 1.0000
[2019-03-26 12:32:26,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6085
[2019-03-26 12:32:26,944] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 71.0, 1.0, 2.0, 0.705546750514573, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1011798.27218437, 1011798.27218437, 225494.4398628975], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7026000.0000, 
sim time next is 7026600.0000, 
raw observation next is [27.55, 70.0, 1.0, 2.0, 0.6918252489627995, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 992878.5556813459, 992878.5556813465, 222552.263091632], 
processed observation next is [1.0, 0.30434782608695654, 0.504739336492891, 0.7, 1.0, 1.0, 0.6287051192322886, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27579959880037386, 0.275799598800374, 0.33216755685318206], 
reward next is 0.6678, 
noisyNet noise sample is [array([-0.23195118], dtype=float32), -0.25540057]. 
=============================================
[2019-03-26 12:32:33,498] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4018605e-24 1.0000000e+00 5.8051685e-27 7.1808664e-23 8.0500116e-24], sum to 1.0000
[2019-03-26 12:32:33,508] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0879
[2019-03-26 12:32:33,513] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 92.0, 1.0, 2.0, 0.4715724515352644, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 661588.0312807639, 661588.0312807639, 179604.2947353525], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7092000.0000, 
sim time next is 7092600.0000, 
raw observation next is [24.75, 92.16666666666667, 1.0, 2.0, 0.772374062045634, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1084727.429762709, 1084727.429762708, 237972.5326901757], 
processed observation next is [1.0, 0.08695652173913043, 0.3720379146919432, 0.9216666666666667, 1.0, 1.0, 0.7257518819826915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3013131749340858, 0.30131317493408555, 0.35518288461220254], 
reward next is 0.6448, 
noisyNet noise sample is [array([1.002576], dtype=float32), 0.51753324]. 
=============================================
[2019-03-26 12:32:33,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7971794e-27 1.0000000e+00 1.7550680e-30 9.0528252e-27 7.3281779e-28], sum to 1.0000
[2019-03-26 12:32:33,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7140
[2019-03-26 12:32:33,667] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.4, 93.5, 1.0, 2.0, 0.5059415729660321, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 716214.6686024184, 716214.6686024178, 185715.4746040754], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7097400.0000, 
sim time next is 7098000.0000, 
raw observation next is [24.36666666666667, 93.66666666666667, 1.0, 2.0, 0.4963683472389043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 703030.7176296974, 703030.717629698, 184238.2353270157], 
processed observation next is [1.0, 0.13043478260869565, 0.3538704581358612, 0.9366666666666668, 1.0, 1.0, 0.39321487619145096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19528631045269373, 0.19528631045269387, 0.27498244078659057], 
reward next is 0.7250, 
noisyNet noise sample is [array([-0.4071403], dtype=float32), -0.38011277]. 
=============================================
[2019-03-26 12:32:33,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[72.648346]
 [72.49199 ]
 [72.2867  ]
 [72.09912 ]
 [72.15984 ]], R is [[72.72602844]
 [72.72158813]
 [72.7148819 ]
 [72.69680786]
 [72.68070984]].
[2019-03-26 12:32:35,924] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2428369e-21 1.0000000e+00 4.6493841e-24 4.1265483e-17 1.2868128e-19], sum to 1.0000
[2019-03-26 12:32:35,934] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8973
[2019-03-26 12:32:35,937] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 86.5, 1.0, 2.0, 0.4774513151191754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 667154.1380232745, 667154.1380232745, 180138.4992762489], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7176600.0000, 
sim time next is 7177200.0000, 
raw observation next is [25.8, 86.66666666666667, 1.0, 2.0, 0.4781715024161082, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 668160.789432546, 668160.7894325453, 180246.6167092501], 
processed observation next is [1.0, 0.043478260869565216, 0.42180094786729866, 0.8666666666666667, 1.0, 1.0, 0.37129096676639534, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18560021928681833, 0.18560021928681814, 0.26902480105858223], 
reward next is 0.7310, 
noisyNet noise sample is [array([0.9593193], dtype=float32), -0.18697591]. 
=============================================
[2019-03-26 12:32:39,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6959545e-23 1.0000000e+00 3.7555696e-27 9.0076192e-22 9.2141163e-24], sum to 1.0000
[2019-03-26 12:32:39,053] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8980
[2019-03-26 12:32:39,059] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.8, 90.0, 1.0, 2.0, 0.5764029298571286, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 805474.0182349448, 805474.0182349454, 196426.5081277578], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7185600.0000, 
sim time next is 7186200.0000, 
raw observation next is [25.8, 90.16666666666667, 1.0, 2.0, 0.531586835600501, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 742825.443834168, 742825.443834168, 188690.8426545402], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9016666666666667, 1.0, 1.0, 0.4356467898801217, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20634040106504667, 0.20634040106504667, 0.2816281233649854], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.46306592], dtype=float32), -0.61837304]. 
=============================================
[2019-03-26 12:32:39,520] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0971465e-22 1.0000000e+00 3.8848204e-26 8.6943613e-21 1.6424254e-22], sum to 1.0000
[2019-03-26 12:32:39,525] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1895
[2019-03-26 12:32:39,529] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.56666666666667, 87.50000000000001, 1.0, 2.0, 0.5925288807123426, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 828017.4451896423, 828017.4451896416, 199356.4914869946], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7715400.0000, 
sim time next is 7716000.0000, 
raw observation next is [26.73333333333333, 87.0, 1.0, 2.0, 0.6034012002840791, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 843216.7781832678, 843216.7781832678, 201374.9563591422], 
processed observation next is [1.0, 0.30434782608695654, 0.4660347551342811, 0.87, 1.0, 1.0, 0.5221701208241917, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2342268828286855, 0.2342268828286855, 0.30055963635692867], 
reward next is 0.6994, 
noisyNet noise sample is [array([1.00962], dtype=float32), 0.30033818]. 
=============================================
[2019-03-26 12:32:39,542] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[70.9922  ]
 [70.856705]
 [70.69018 ]
 [70.805466]
 [71.091415]], R is [[70.77469635]
 [70.76940155]
 [70.76447296]
 [70.75687408]
 [70.75227356]].
[2019-03-26 12:32:46,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.9295393e-14 9.9996746e-01 3.2145144e-16 3.2571177e-05 1.3108106e-10], sum to 1.0000
[2019-03-26 12:32:46,071] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0383
[2019-03-26 12:32:46,077] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.33333333333334, 65.33333333333333, 1.0, 2.0, 1.01496839540297, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1418741.334761474, 1418741.334761474, 303516.3069718623], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7642200.0000, 
sim time next is 7642800.0000, 
raw observation next is [29.6, 64.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.492263708301662, 6.9112, 168.910132556517, 1866256.974862006, 1454037.273291343, 311347.1316064823], 
processed observation next is [1.0, 0.4782608695652174, 0.6018957345971565, 0.64, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.05810637083016621, 0.0, 0.8294260782457732, 0.5184047152394461, 0.4038992425809286, 0.46469721135295866], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02909956], dtype=float32), -0.7719022]. 
=============================================
[2019-03-26 12:32:46,277] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.6751700e-22 1.0000000e+00 5.6479459e-24 6.5703016e-17 3.7108521e-20], sum to 1.0000
[2019-03-26 12:32:46,284] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2388
[2019-03-26 12:32:46,289] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.91666666666667, 72.83333333333333, 1.0, 2.0, 0.5686544204305177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 876473.0143512196, 876473.0143512203, 204890.7498148936], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7351800.0000, 
sim time next is 7352400.0000, 
raw observation next is [24.83333333333334, 73.66666666666667, 1.0, 2.0, 0.4606569003450017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 709042.0398696957, 709042.0398696951, 185532.1371341849], 
processed observation next is [1.0, 0.08695652173913043, 0.3759873617693526, 0.7366666666666667, 1.0, 1.0, 0.350189036560243, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19695612218602657, 0.1969561221860264, 0.2769136375137088], 
reward next is 0.7231, 
noisyNet noise sample is [array([0.6397897], dtype=float32), 1.3533025]. 
=============================================
[2019-03-26 12:32:46,885] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.90409910e-11 8.57428133e-01 1.64498679e-15 1.42571718e-01
 1.05061225e-07], sum to 1.0000
[2019-03-26 12:32:46,896] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2544
[2019-03-26 12:32:46,901] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.75, 71.0, 1.0, 2.0, 0.3411253792427847, 1.0, 2.0, 0.3411253792427847, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 953449.6124774972, 953449.6124774972, 258314.9918265788], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7837800.0000, 
sim time next is 7838400.0000, 
raw observation next is [29.6, 72.0, 1.0, 2.0, 0.4854204658591975, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 678293.1779866568, 678293.1779866575, 181346.3967743807], 
processed observation next is [1.0, 0.7391304347826086, 0.6018957345971565, 0.72, 1.0, 1.0, 0.3800246576616837, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18841477166296022, 0.18841477166296042, 0.27066626384235926], 
reward next is 0.7293, 
noisyNet noise sample is [array([1.0873171], dtype=float32), 0.16353284]. 
=============================================
[2019-03-26 12:32:47,064] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.8685368e-24 1.0000000e+00 2.0694690e-28 2.9668159e-24 2.7700313e-25], sum to 1.0000
[2019-03-26 12:32:47,073] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8246
[2019-03-26 12:32:47,078] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.6, 89.83333333333333, 1.0, 2.0, 0.3908969466713055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 599718.7713122347, 599718.7713122341, 174926.9392147202], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7365000.0000, 
sim time next is 7365600.0000, 
raw observation next is [22.4, 90.0, 1.0, 2.0, 0.3846878198389174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 593244.4596555493, 593244.4596555493, 174411.0307059647], 
processed observation next is [1.0, 0.2608695652173913, 0.2606635071090047, 0.9, 1.0, 1.0, 0.25866002390231013, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.16479012768209703, 0.16479012768209703, 0.26031497120293234], 
reward next is 0.7397, 
noisyNet noise sample is [array([0.25701305], dtype=float32), 0.4270343]. 
=============================================
[2019-03-26 12:32:47,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0012117e-26 1.0000000e+00 1.1796873e-29 7.4535932e-25 2.7599254e-26], sum to 1.0000
[2019-03-26 12:32:47,467] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1951
[2019-03-26 12:32:47,473] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 91.83333333333333, 1.0, 2.0, 0.3227898399380061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 520166.1695543221, 520166.1695543215, 168607.2709799029], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7372200.0000, 
sim time next is 7372800.0000, 
raw observation next is [20.1, 92.0, 1.0, 2.0, 0.3077772176570869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 497613.4900006487, 497613.4900006493, 166909.734932802], 
processed observation next is [1.0, 0.34782608695652173, 0.15165876777251197, 0.92, 1.0, 1.0, 0.16599664777962272, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13822596944462465, 0.1382259694446248, 0.24911900736239107], 
reward next is 0.7509, 
noisyNet noise sample is [array([0.32510725], dtype=float32), -0.55656606]. 
=============================================
[2019-03-26 12:32:50,856] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.7333938e-20 1.0000000e+00 5.9330153e-23 1.6789898e-15 3.3742517e-18], sum to 1.0000
[2019-03-26 12:32:50,867] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4075
[2019-03-26 12:32:50,870] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.35, 86.0, 1.0, 2.0, 0.4029091002163428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594852.926062885, 594852.926062885, 173873.9932508516], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7504200.0000, 
sim time next is 7504800.0000, 
raw observation next is [24.3, 86.33333333333334, 1.0, 2.0, 0.4027598588474285, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 594720.212489671, 594720.2124896715, 173864.3419595282], 
processed observation next is [0.0, 0.8695652173913043, 0.3507109004739337, 0.8633333333333334, 1.0, 1.0, 0.28043356487641985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1652000590249086, 0.16520005902490875, 0.2594990178500421], 
reward next is 0.7405, 
noisyNet noise sample is [array([-0.8145987], dtype=float32), 0.91232187]. 
=============================================
[2019-03-26 12:32:54,060] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:32:54,061] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:54,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run8
[2019-03-26 12:32:57,217] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 12:32:57,218] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:32:57,219] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:32:57,219] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:57,220] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:57,220] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:32:57,221] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:32:57,222] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:32:57,223] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:57,222] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:57,225] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:57,239] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run60
[2019-03-26 12:32:57,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run60
[2019-03-26 12:32:57,283] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run60
[2019-03-26 12:32:57,284] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run60
[2019-03-26 12:32:57,319] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run60
[2019-03-26 12:32:58,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:32:58,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:32:58,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run8
[2019-03-26 12:33:19,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.41865155], dtype=float32), 0.12575808]
[2019-03-26 12:33:19,180] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.96666666666667, 57.0, 1.0, 2.0, 0.3308875048659061, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 518270.5186193026, 518270.5186193032, 168314.5926470887]
[2019-03-26 12:33:19,181] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:33:19,186] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.7898012e-25 1.0000000e+00 1.6237811e-28 3.8234705e-25 5.6106826e-26], sampled 0.6554777834604328
[2019-03-26 12:33:22,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.41865155], dtype=float32), 0.12575808]
[2019-03-26 12:33:22,948] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.51216257333333, 96.53403680500001, 1.0, 2.0, 0.7681423983909667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1101872.596573994, 1101872.596573993, 240138.4661649275]
[2019-03-26 12:33:22,951] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:33:22,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8337056e-20 1.0000000e+00 4.9386848e-23 1.0735429e-16 8.6443011e-19], sampled 0.3706654251966973
[2019-03-26 12:33:24,037] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.41865155], dtype=float32), 0.12575808]
[2019-03-26 12:33:24,038] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.0, 92.0, 1.0, 2.0, 0.4049227398893919, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 609376.0481549265, 609376.0481549259, 175536.9897668184]
[2019-03-26 12:33:24,039] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:33:24,042] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2777186e-21 1.0000000e+00 5.5109066e-24 1.0194155e-16 8.2505540e-20], sampled 0.8545488242097113
[2019-03-26 12:33:39,355] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.41865155], dtype=float32), 0.12575808]
[2019-03-26 12:33:39,356] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.96897916333334, 95.30675409, 1.0, 2.0, 0.4009987312014427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 594117.4535476015, 594117.4535476008, 173869.8392544144]
[2019-03-26 12:33:39,357] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:33:39,360] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.5197676e-26 1.0000000e+00 1.4713628e-29 7.8204735e-27 7.0491909e-27], sampled 0.00041982969323306474
[2019-03-26 12:34:13,069] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.41865155], dtype=float32), 0.12575808]
[2019-03-26 12:34:13,069] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.90000000000001, 76.0, 1.0, 2.0, 0.6104950466316846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 853133.9818667016, 853133.981866701, 202717.040576012]
[2019-03-26 12:34:13,070] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:34:13,073] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.1506410e-20 1.0000000e+00 2.3683236e-23 2.0817635e-15 1.7776105e-18], sampled 0.3867338070011924
[2019-03-26 12:34:52,113] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8245.3736 3130362391.5235 853.0000
[2019-03-26 12:34:52,218] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8813.8681 2766587044.4547 571.0000
[2019-03-26 12:34:52,339] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8525.0934 2907955534.7405 760.0000
[2019-03-26 12:34:52,406] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8433.9637 2970534563.1526 750.0000
[2019-03-26 12:34:52,536] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8736.5954 2822488422.6390 570.0000
[2019-03-26 12:34:53,553] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1475000, evaluation results [1475000.0, 8245.373560316742, 3130362391.5235133, 853.0, 8525.093397417562, 2907955534.7405324, 760.0, 8813.868149367932, 2766587044.454724, 571.0, 8433.963725154357, 2970534563.1526165, 750.0, 8736.59540680268, 2822488422.6390185, 570.0]
[2019-03-26 12:34:56,091] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5104759e-25 1.0000000e+00 4.6690094e-30 2.0637164e-26 1.9514367e-26], sum to 1.0000
[2019-03-26 12:34:56,099] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4647
[2019-03-26 12:34:56,106] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.8, 90.0, 1.0, 2.0, 0.3996088689809195, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 590598.5511635176, 590598.5511635176, 173498.3430802972], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7545600.0000, 
sim time next is 7546200.0000, 
raw observation next is [24.03333333333333, 89.0, 1.0, 2.0, 0.4032313478690614, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 594119.3487265224, 594119.3487265224, 173767.9098471192], 
processed observation next is [0.0, 0.34782608695652173, 0.3380726698262243, 0.89, 1.0, 1.0, 0.2810016239386282, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.165033152424034, 0.165033152424034, 0.25935508932405854], 
reward next is 0.7406, 
noisyNet noise sample is [array([-0.36598375], dtype=float32), 1.0102282]. 
=============================================
[2019-03-26 12:35:00,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:00,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:00,788] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run8
[2019-03-26 12:35:01,611] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8312201e-14 6.0879887e-05 1.2035049e-15 9.9993908e-01 1.0274582e-08], sum to 1.0000
[2019-03-26 12:35:01,617] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-26 12:35:01,626] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.85, 63.0, 1.0, 2.0, 0.6258454860135094, 1.0, 2.0, 0.6258454860135094, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1749895.3349209, 1749895.3349209, 343984.0922661521], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7644600.0000, 
sim time next is 7645200.0000, 
raw observation next is [29.93333333333334, 62.66666666666666, 1.0, 2.0, 0.6019957841723583, 1.0, 2.0, 0.6019957841723583, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1683158.002668298, 1683158.002668298, 334980.3228609567], 
processed observation next is [1.0, 0.4782608695652174, 0.6176935229067935, 0.6266666666666666, 1.0, 1.0, 0.5204768484004317, 1.0, 1.0, 0.5204768484004317, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4675438896300828, 0.4675438896300828, 0.4999706311357563], 
reward next is 0.5000, 
noisyNet noise sample is [array([-0.6109856], dtype=float32), -0.30141765]. 
=============================================
[2019-03-26 12:35:02,349] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3950269e-20 1.0000000e+00 1.1390459e-24 1.5820367e-16 6.8227015e-19], sum to 1.0000
[2019-03-26 12:35:02,362] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4566
[2019-03-26 12:35:02,371] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.9, 88.0, 1.0, 2.0, 0.494073798632051, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 690388.6793581739, 690388.6793581746, 182672.5519115474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7678800.0000, 
sim time next is 7679400.0000, 
raw observation next is [25.86666666666667, 88.00000000000001, 1.0, 2.0, 0.4925865389700069, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 688309.7998596545, 688309.7998596552, 182442.4780367959], 
processed observation next is [1.0, 0.9130434782608695, 0.42496050552922615, 0.8800000000000001, 1.0, 1.0, 0.3886584806867553, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1911971666276818, 0.191197166627682, 0.2723022060250685], 
reward next is 0.7277, 
noisyNet noise sample is [array([-0.73679084], dtype=float32), 1.2181671]. 
=============================================
[2019-03-26 12:35:10,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:10,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:10,244] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run8
[2019-03-26 12:35:10,278] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.54323972e-20 1.00000000e+00 3.97619375e-23 1.13298475e-14
 6.04689079e-17], sum to 1.0000
[2019-03-26 12:35:10,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-26 12:35:10,287] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.4, 85.0, 1.0, 2.0, 0.4936117968912466, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689742.8966346796, 689742.8966346796, 182601.2012829777], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [26.35, 85.33333333333334, 1.0, 2.0, 0.9537145800155455, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1333065.875792265, 1333065.875792265, 285137.617281171], 
processed observation next is [1.0, 0.08695652173913043, 0.4478672985781992, 0.8533333333333334, 1.0, 1.0, 0.9442344337536693, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37029607660896247, 0.37029607660896247, 0.4255785332554791], 
reward next is 0.5744, 
noisyNet noise sample is [array([-0.4650756], dtype=float32), 0.27028686]. 
=============================================
[2019-03-26 12:35:10,663] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.5551493e-20 1.0000000e+00 2.2214080e-23 2.4094073e-12 2.0135919e-16], sum to 1.0000
[2019-03-26 12:35:10,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6784
[2019-03-26 12:35:10,673] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.6, 87.66666666666667, 1.0, 2.0, 0.516575377439768, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 721841.7002209437, 721841.7002209431, 186233.7361037683], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7856400.0000, 
sim time next is 7857000.0000, 
raw observation next is [26.55, 87.5, 1.0, 2.0, 0.5141058886854403, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 718389.7688826051, 718389.7688826051, 185835.5765056036], 
processed observation next is [1.0, 0.9565217391304348, 0.4573459715639811, 0.875, 1.0, 1.0, 0.4145854080547473, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.19955271357850143, 0.19955271357850143, 0.2773665320979158], 
reward next is 0.7226, 
noisyNet noise sample is [array([0.84932995], dtype=float32), 1.0616225]. 
=============================================
[2019-03-26 12:35:10,687] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[74.80709 ]
 [74.82746 ]
 [74.850876]
 [74.98287 ]
 [75.39407 ]], R is [[74.79251862]
 [74.76663208]
 [74.74078369]
 [74.71498108]
 [74.68920135]].
[2019-03-26 12:35:11,041] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:11,042] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:11,109] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run8
[2019-03-26 12:35:12,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:12,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:12,705] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run8
[2019-03-26 12:35:15,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:15,828] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:15,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run8
[2019-03-26 12:35:15,937] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:15,937] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:15,983] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run8
[2019-03-26 12:35:17,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,317] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run8
[2019-03-26 12:35:17,485] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,486] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,559] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run8
[2019-03-26 12:35:17,624] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,626] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,640] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,640] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,678] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run8
[2019-03-26 12:35:17,720] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run8
[2019-03-26 12:35:17,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,810] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,836] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run8
[2019-03-26 12:35:17,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,862] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,875] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:17,877] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:17,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run8
[2019-03-26 12:35:17,942] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run8
[2019-03-26 12:35:18,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:35:18,153] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:18,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run8
[2019-03-26 12:35:18,992] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.5499099e-25 1.0000000e+00 2.8671202e-27 1.8506058e-22 1.7598333e-24], sum to 1.0000
[2019-03-26 12:35:19,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5294
[2019-03-26 12:35:19,004] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [17.96666666666667, 89.83333333333333, 1.0, 2.0, 0.2167860746051304, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 361039.2437686982, 361039.2437686975, 157344.371889368], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 532200.0000, 
sim time next is 532800.0000, 
raw observation next is [17.9, 90.0, 1.0, 2.0, 0.2157217044276788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 359379.3679825553, 359379.3679825547, 157220.5934770001], 
processed observation next is [1.0, 0.17391304347826086, 0.04739336492890995, 0.9, 1.0, 1.0, 0.05508639087672143, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09982760221737647, 0.09982760221737631, 0.23465760220447776], 
reward next is 0.7653, 
noisyNet noise sample is [array([0.19936118], dtype=float32), 0.5526908]. 
=============================================
[2019-03-26 12:35:25,265] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.3789901e-20 1.0000000e+00 9.4041005e-23 9.8500411e-15 4.1195335e-17], sum to 1.0000
[2019-03-26 12:35:25,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6770
[2019-03-26 12:35:25,278] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 93.0, 1.0, 2.0, 0.7745131948637836, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1164801.432218528, 1164801.432218527, 248736.2027919169], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 120600.0000, 
sim time next is 121200.0000, 
raw observation next is [22.9, 93.33333333333334, 1.0, 2.0, 0.6944983242685399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1042988.007843672, 1042988.007843671, 228991.4354119874], 
processed observation next is [1.0, 0.391304347826087, 0.2843601895734597, 0.9333333333333335, 1.0, 1.0, 0.6319256918898071, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28971889106768667, 0.2897188910676864, 0.3417782618089364], 
reward next is 0.6582, 
noisyNet noise sample is [array([-0.44783768], dtype=float32), -0.27163145]. 
=============================================
[2019-03-26 12:35:25,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.781136e-26 1.000000e+00 1.065718e-29 3.803802e-25 2.929466e-25], sum to 1.0000
[2019-03-26 12:35:25,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4145
[2019-03-26 12:35:25,349] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.4, 93.0, 1.0, 2.0, 0.2903677292345507, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 466384.9573950135, 466384.9573950141, 164707.2559364908], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 201600.0000, 
sim time next is 202200.0000, 
raw observation next is [20.41666666666667, 93.0, 1.0, 2.0, 0.2898629806330963, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 465430.5006459423, 465430.5006459423, 164640.5959671809], 
processed observation next is [0.0, 0.34782608695652173, 0.16666666666666693, 0.93, 1.0, 1.0, 0.14441322967842926, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1292862501794284, 0.1292862501794284, 0.24573223278683717], 
reward next is 0.7543, 
noisyNet noise sample is [array([0.73772776], dtype=float32), -0.22761582]. 
=============================================
[2019-03-26 12:35:27,082] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.1479464e-21 1.0000000e+00 5.2653282e-24 2.8654021e-13 4.8609244e-18], sum to 1.0000
[2019-03-26 12:35:27,089] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-26 12:35:27,093] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [19.5, 84.0, 1.0, 2.0, 0.2407599575040754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 398168.2722757019, 398168.2722757013, 159920.8054862081], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 684000.0000, 
sim time next is 684600.0000, 
raw observation next is [19.38333333333333, 84.66666666666667, 1.0, 2.0, 0.2412925513793596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 399165.0872869539, 399165.0872869533, 159963.1122620658], 
processed observation next is [1.0, 0.9565217391304348, 0.11769352290679291, 0.8466666666666667, 1.0, 1.0, 0.08589464021609589, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11087919091304274, 0.11087919091304257, 0.23875091382397884], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.924063], dtype=float32), 0.6083206]. 
=============================================
[2019-03-26 12:35:38,660] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.4165367e-19 1.0000000e+00 4.5264137e-22 1.0870266e-12 7.0015008e-16], sum to 1.0000
[2019-03-26 12:35:38,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6336
[2019-03-26 12:35:38,672] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.86666666666667, 73.66666666666667, 1.0, 2.0, 0.2404900417532672, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 397648.4020922547, 397648.4020922547, 159900.2461510204], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 591000.0000, 
sim time next is 591600.0000, 
raw observation next is [20.73333333333333, 74.33333333333334, 1.0, 2.0, 0.2391987161748259, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 395672.5005185914, 395672.5005185914, 159765.9931771098], 
processed observation next is [1.0, 0.8695652173913043, 0.18167456556082143, 0.7433333333333334, 1.0, 1.0, 0.08337194719858543, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.10990902792183094, 0.10990902792183094, 0.23845670623449225], 
reward next is 0.7615, 
noisyNet noise sample is [array([0.4144054], dtype=float32), -0.7599128]. 
=============================================
[2019-03-26 12:35:40,147] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2751418e-19 1.0000000e+00 4.0544359e-21 7.6939545e-13 1.1760292e-15], sum to 1.0000
[2019-03-26 12:35:40,158] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3741
[2019-03-26 12:35:40,167] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 73.0, 1.0, 2.0, 0.4791762917907562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 773024.1119324766, 773024.1119324766, 191641.6318986931], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 394200.0000, 
sim time next is 394800.0000, 
raw observation next is [22.83333333333333, 73.0, 1.0, 2.0, 0.5187384732909831, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836339.7480974811, 836339.7480974811, 198703.6201582337], 
processed observation next is [1.0, 0.5652173913043478, 0.2812006319115322, 0.73, 1.0, 1.0, 0.42016683529034105, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.23231659669374474, 0.23231659669374474, 0.2965725674003488], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.86886597], dtype=float32), 0.6951114]. 
=============================================
[2019-03-26 12:35:44,135] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-26 12:35:44,137] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:35:44,139] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.2649440e-25 1.0000000e+00 9.9140927e-29 2.2510769e-23 1.1201810e-24], sum to 1.0000
[2019-03-26 12:35:44,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:44,140] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:35:44,141] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:35:44,142] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:35:44,142] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:44,143] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:44,144] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:44,144] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:35:44,171] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3404
[2019-03-26 12:35:44,181] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:35:44,201] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.3, 77.0, 1.0, 2.0, 0.239321091635534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 396326.0416068228, 396326.0416068222, 159740.0358387126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 631800.0000, 
sim time next is 632400.0000, 
raw observation next is [20.53333333333333, 76.0, 1.0, 2.0, 0.2415907449897015, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 399704.3218930089, 399704.3218930089, 159988.1921951164], 
processed observation next is [1.0, 0.30434782608695654, 0.17219589257503945, 0.76, 1.0, 1.0, 0.08625390962614639, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.11102897830361358, 0.11102897830361358, 0.23878834655987521], 
reward next is 0.7612, 
noisyNet noise sample is [array([-1.3564993], dtype=float32), 1.456775]. 
=============================================
[2019-03-26 12:35:45,061] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run61
[2019-03-26 12:35:45,220] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run61
[2019-03-26 12:35:45,238] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run61
[2019-03-26 12:35:45,239] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run61
[2019-03-26 12:35:45,256] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run61
[2019-03-26 12:35:58,565] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:35:58,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 60.0, 1.0, 2.0, 0.3506199774943496, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541730.5856130508, 541730.5856130508, 170005.2913017939]
[2019-03-26 12:35:58,566] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:35:58,567] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.0128344e-24 1.0000000e+00 6.6766629e-27 1.1590044e-20 7.0889269e-23], sampled 0.9423757259268316
[2019-03-26 12:36:24,570] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:36:24,570] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.88729982166667, 88.69186432666667, 1.0, 2.0, 0.37262627781427, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 568201.0914727263, 568201.0914727256, 172039.4035069464]
[2019-03-26 12:36:24,571] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:36:24,576] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1277186e-22 1.0000000e+00 8.1548156e-25 2.3992859e-16 8.5298451e-20], sampled 0.9403462352869788
[2019-03-26 12:36:30,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:36:30,383] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.25, 79.83333333333334, 1.0, 2.0, 0.5740730818127622, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 802217.0244753498, 802217.0244753498, 196014.6354678962]
[2019-03-26 12:36:30,383] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:36:30,386] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.7045301e-19 1.0000000e+00 1.1162201e-21 2.8931037e-12 6.3008849e-16], sampled 0.05310776405575812
[2019-03-26 12:36:30,480] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:36:30,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.9353257, 92.83878997, 1.0, 2.0, 0.5112067441794412, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714337.2651379352, 714337.2651379359, 185370.9315299765]
[2019-03-26 12:36:30,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:36:30,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1146858e-19 1.0000000e+00 1.0366485e-20 5.4232302e-10 1.2621724e-14], sampled 0.6984789971253971
[2019-03-26 12:36:51,933] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:36:51,934] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.73180748833333, 85.03892808500001, 1.0, 2.0, 0.5136353355987093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717732.0158147009, 717732.0158147003, 185759.5367900772]
[2019-03-26 12:36:51,936] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:36:51,939] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.36404532e-19 1.00000000e+00 2.06145566e-21 1.02431015e-11
 1.05816237e-15], sampled 0.7612928979992678
[2019-03-26 12:36:54,815] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:36:54,816] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.6306835636937241, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 881358.0539590361, 881358.0539590361, 206593.155795314]
[2019-03-26 12:36:54,817] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:36:54,819] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3853949e-22 1.0000000e+00 4.8469250e-26 3.6227199e-20 1.6816126e-21], sampled 0.40871299518958304
[2019-03-26 12:37:37,323] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.43181744], dtype=float32), 0.13896821]
[2019-03-26 12:37:37,325] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.26666666666667, 88.33333333333333, 1.0, 2.0, 0.8186221549088816, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1144137.093247355, 1144137.093247355, 248536.4005579631]
[2019-03-26 12:37:37,326] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:37:37,328] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.0659464e-21 1.0000000e+00 3.1417332e-24 2.9655365e-17 4.0424557e-19], sampled 0.9880851133413839
[2019-03-26 12:37:39,701] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8203.0316 3133812694.8220 955.0000
[2019-03-26 12:37:39,772] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8795.9521 2767215151.1262 587.0000
[2019-03-26 12:37:40,196] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8498.5438 2909400397.5405 812.0000
[2019-03-26 12:37:40,279] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8376.2306 2974206503.4070 849.0000
[2019-03-26 12:37:40,363] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8710.7419 2823784801.3849 615.0000
[2019-03-26 12:37:41,381] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1500000, evaluation results [1500000.0, 8203.031573834427, 3133812694.8219647, 955.0, 8498.54377989923, 2909400397.5404944, 812.0, 8795.952094318833, 2767215151.126176, 587.0, 8376.230632311344, 2974206503.4069877, 849.0, 8710.741854452805, 2823784801.384858, 615.0]
[2019-03-26 12:37:45,458] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.48730230e-26 1.00000000e+00 7.07377047e-31 6.25919282e-26
 1.10647495e-26], sum to 1.0000
[2019-03-26 12:37:45,466] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3649
[2019-03-26 12:37:45,471] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [18.2, 88.5, 1.0, 2.0, 0.2141789626914568, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 356631.4660712971, 356631.4660712964, 157136.8971167101], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 538200.0000, 
sim time next is 538800.0000, 
raw observation next is [18.4, 87.66666666666666, 1.0, 2.0, 0.2158356069159676, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 359130.1103477972, 359130.1103477978, 157343.2921589192], 
processed observation next is [1.0, 0.21739130434782608, 0.07109004739336493, 0.8766666666666666, 1.0, 1.0, 0.05522362279032239, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09975836398549923, 0.0997583639854994, 0.23484073456555107], 
reward next is 0.7652, 
noisyNet noise sample is [array([-1.3850569], dtype=float32), -1.1858377]. 
=============================================
[2019-03-26 12:37:58,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.0926285e-22 1.0000000e+00 1.1833908e-24 3.3904479e-16 2.0185031e-19], sum to 1.0000
[2019-03-26 12:37:58,665] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0563
[2019-03-26 12:37:58,670] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.66666666666667, 71.66666666666667, 1.0, 2.0, 0.2502482864269294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 411660.5502184638, 411660.5502184638, 160928.9597454255], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 760800.0000, 
sim time next is 761400.0000, 
raw observation next is [21.45, 73.5, 1.0, 2.0, 0.2509682782545777, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 412607.3434961428, 412607.3434961434, 161003.1870389815], 
processed observation next is [1.0, 0.8260869565217391, 0.2156398104265403, 0.735, 1.0, 1.0, 0.09755214247539479, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11461315097115078, 0.11461315097115095, 0.24030326423728582], 
reward next is 0.7597, 
noisyNet noise sample is [array([-1.7073786], dtype=float32), 0.7555368]. 
=============================================
[2019-03-26 12:38:07,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.8926246e-18 9.9999845e-01 6.1065626e-20 1.5396528e-06 5.6502992e-12], sum to 1.0000
[2019-03-26 12:38:07,157] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6194
[2019-03-26 12:38:07,161] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.33333333333334, 94.0, 1.0, 2.0, 0.4601472896373651, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 651474.5764389839, 651474.5764389839, 178684.6456285214], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1294800.0000, 
sim time next is 1295400.0000, 
raw observation next is [24.31666666666667, 94.0, 1.0, 2.0, 0.4592063636277687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 650618.5539348436, 650618.5539348436, 178607.5266730238], 
processed observation next is [1.0, 1.0, 0.3515007898894157, 0.94, 1.0, 1.0, 0.3484414019611671, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18072737609301212, 0.18072737609301212, 0.2665783980194385], 
reward next is 0.7334, 
noisyNet noise sample is [array([1.0089291], dtype=float32), 0.32496527]. 
=============================================
[2019-03-26 12:38:08,101] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [6.7076133e-24 1.0000000e+00 9.1790199e-27 1.3683474e-20 4.7821223e-22], sum to 1.0000
[2019-03-26 12:38:08,107] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3727
[2019-03-26 12:38:08,111] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 68.0, 1.0, 2.0, 0.3132407388071468, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 493350.3158975887, 493350.3158975881, 166485.9569494055], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 916800.0000, 
sim time next is 917400.0000, 
raw observation next is [24.75, 68.5, 1.0, 2.0, 0.3146142390191519, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 495163.9308618236, 495163.9308618236, 166612.2068282489], 
processed observation next is [0.0, 0.6086956521739131, 0.3720379146919432, 0.685, 1.0, 1.0, 0.17423402291464085, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.13754553635050656, 0.13754553635050656, 0.2486749355645506], 
reward next is 0.7513, 
noisyNet noise sample is [array([-0.3278028], dtype=float32), -0.23888019]. 
=============================================
[2019-03-26 12:38:08,878] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.4107753e-23 1.0000000e+00 1.9503948e-26 1.0640608e-21 2.1027066e-22], sum to 1.0000
[2019-03-26 12:38:08,890] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9546
[2019-03-26 12:38:08,895] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.8, 51.0, 1.0, 2.0, 0.3406595343048348, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 526195.087827559, 526195.087827559, 168738.9939266162], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1508400.0000, 
sim time next is 1509000.0000, 
raw observation next is [28.85, 51.0, 1.0, 2.0, 0.3404076519279594, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 525745.5316471308, 525745.5316471303, 168701.1901762203], 
processed observation next is [0.0, 0.4782608695652174, 0.5663507109004741, 0.51, 1.0, 1.0, 0.20531042400958965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14604042545753634, 0.14604042545753618, 0.25179282115853774], 
reward next is 0.7482, 
noisyNet noise sample is [array([-0.8498658], dtype=float32), 1.097196]. 
=============================================
[2019-03-26 12:38:08,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.1093  ]
 [74.93221 ]
 [74.849686]
 [74.76888 ]
 [74.691826]], R is [[75.15193939]
 [75.14857483]
 [75.14472198]
 [75.14048767]
 [75.13602448]].
[2019-03-26 12:38:11,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.8173499e-26 1.0000000e+00 1.4307969e-28 1.4766640e-23 2.3115108e-24], sum to 1.0000
[2019-03-26 12:38:11,580] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8031
[2019-03-26 12:38:11,585] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [20.35, 91.83333333333334, 1.0, 2.0, 0.2786310879597411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 449255.712040299, 449255.7120402995, 163550.7635570573], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1144200.0000, 
sim time next is 1144800.0000, 
raw observation next is [20.5, 91.0, 1.0, 2.0, 0.2789237662727559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 449301.7335277609, 449301.7335277603, 163553.2581702353], 
processed observation next is [1.0, 0.2608695652173913, 0.1706161137440759, 0.91, 1.0, 1.0, 0.13123345334066974, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1248060370910447, 0.12480603709104453, 0.24410934055258998], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.21831752], dtype=float32), -0.498615]. 
=============================================
[2019-03-26 12:38:13,846] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.3661360e-18 1.0000000e+00 1.8431117e-20 3.5425878e-09 1.4289206e-13], sum to 1.0000
[2019-03-26 12:38:13,855] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0130
[2019-03-26 12:38:13,863] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.8, 96.0, 1.0, 2.0, 0.3567285750800349, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548838.7047987876, 548838.7047987876, 170529.861653184], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1020000.0000, 
sim time next is 1020600.0000, 
raw observation next is [21.8, 96.0, 1.0, 2.0, 0.356832011537996, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 548996.6058785615, 548996.6058785615, 170543.0319410249], 
processed observation next is [1.0, 0.8260869565217391, 0.23222748815165886, 0.96, 1.0, 1.0, 0.22509880908192287, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1524990571884893, 0.1524990571884893, 0.2545418387179476], 
reward next is 0.7455, 
noisyNet noise sample is [array([-0.25325888], dtype=float32), -0.74069214]. 
=============================================
[2019-03-26 12:38:13,925] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [7.5528530e-18 1.0000000e+00 1.2025884e-20 1.1066664e-12 8.3757083e-15], sum to 1.0000
[2019-03-26 12:38:13,933] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5481
[2019-03-26 12:38:13,941] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.16666666666667, 81.33333333333333, 1.0, 2.0, 0.7862657705120224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1155656.439618069, 1155656.43961807, 248331.3772217134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [25.38333333333333, 80.66666666666667, 1.0, 2.0, 0.790140451536843, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1156353.602854636, 1156353.602854637, 248658.5106076122], 
processed observation next is [1.0, 0.34782608695652173, 0.4020537124802526, 0.8066666666666668, 1.0, 1.0, 0.7471571705263168, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32120933412628777, 0.32120933412628805, 0.3711321053844958], 
reward next is 0.6289, 
noisyNet noise sample is [array([-0.06070036], dtype=float32), 1.444369]. 
=============================================
[2019-03-26 12:38:15,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.3802486e-17 9.9999940e-01 3.8637273e-19 6.3597651e-07 6.0108416e-12], sum to 1.0000
[2019-03-26 12:38:15,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8360
[2019-03-26 12:38:15,511] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.36666666666667, 97.0, 1.0, 2.0, 0.3802825846655978, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 572803.730547473, 572803.730547473, 172234.9270182879], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1039800.0000, 
sim time next is 1040400.0000, 
raw observation next is [22.4, 97.0, 1.0, 2.0, 0.3809588480346077, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 573181.2049272379, 573181.2049272379, 172248.3978779776], 
processed observation next is [1.0, 0.043478260869565216, 0.2606635071090047, 0.97, 1.0, 1.0, 0.254167286788684, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1592170013686772, 0.1592170013686772, 0.2570871610119069], 
reward next is 0.7429, 
noisyNet noise sample is [array([1.8576919], dtype=float32), -0.39952004]. 
=============================================
[2019-03-26 12:38:17,971] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5003574e-16 9.9999928e-01 2.8248780e-18 6.9944736e-07 1.8883041e-10], sum to 1.0000
[2019-03-26 12:38:17,982] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5448
[2019-03-26 12:38:17,988] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.7, 92.33333333333334, 1.0, 2.0, 0.4696578998260643, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660665.1396174054, 660665.1396174054, 179547.1106673018], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1287600.0000, 
sim time next is 1288200.0000, 
raw observation next is [24.65, 92.66666666666666, 1.0, 2.0, 0.469250363620599, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 660271.5983369732, 660271.5983369732, 179509.6665299839], 
processed observation next is [1.0, 0.9130434782608695, 0.3672985781990521, 0.9266666666666665, 1.0, 1.0, 0.360542606771806, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1834087773158259, 0.1834087773158259, 0.2679248754178864], 
reward next is 0.7321, 
noisyNet noise sample is [array([-2.0470397], dtype=float32), -0.66518736]. 
=============================================
[2019-03-26 12:38:24,014] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3014478e-18 1.0000000e+00 4.0536006e-21 8.3461710e-12 7.7380830e-15], sum to 1.0000
[2019-03-26 12:38:24,027] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9991
[2019-03-26 12:38:24,032] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.48333333333333, 85.0, 1.0, 2.0, 0.6512030949133567, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 993527.5107505558, 993527.5107505564, 221069.339980343], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1587000.0000, 
sim time next is 1587600.0000, 
raw observation next is [23.5, 85.0, 1.0, 2.0, 0.6640628917258884, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1012614.973353868, 1012614.973353868, 223877.5349002591], 
processed observation next is [1.0, 0.391304347826087, 0.31279620853080575, 0.85, 1.0, 1.0, 0.5952564960552872, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2812819370427411, 0.2812819370427411, 0.3341455744779987], 
reward next is 0.6659, 
noisyNet noise sample is [array([1.2136779], dtype=float32), 0.18607576]. 
=============================================
[2019-03-26 12:38:29,326] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.1289915e-17 9.9999988e-01 4.8060683e-19 9.0506845e-08 6.0690329e-12], sum to 1.0000
[2019-03-26 12:38:29,337] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7649
[2019-03-26 12:38:29,346] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 91.66666666666667, 1.0, 2.0, 0.4715397438129229, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 662967.2775267791, 662967.2775267785, 179783.0596463284], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1286400.0000, 
sim time next is 1287000.0000, 
raw observation next is [24.75, 92.0, 1.0, 2.0, 0.4708594676202532, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 662180.2061036015, 662180.2061036015, 179703.4527588577], 
processed observation next is [1.0, 0.9130434782608695, 0.3720379146919432, 0.92, 1.0, 1.0, 0.3624812862894617, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.18393894613988931, 0.18393894613988931, 0.26821410859531], 
reward next is 0.7318, 
noisyNet noise sample is [array([-0.8718163], dtype=float32), 1.2833279]. 
=============================================
[2019-03-26 12:38:29,363] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[72.45172]
 [72.62991]
 [72.71761]
 [72.65694]
 [72.78241]], R is [[72.38934326]
 [72.39711761]
 [72.40493774]
 [72.41287994]
 [72.4209671 ]].
[2019-03-26 12:38:36,222] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 12:38:36,224] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:38:36,225] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:38:36,226] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:38:36,228] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:38:36,228] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:38:36,229] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:38:36,231] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:38:36,230] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:38:36,232] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:38:36,233] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:38:36,259] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run62
[2019-03-26 12:38:36,283] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run62
[2019-03-26 12:38:36,284] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run62
[2019-03-26 12:38:36,333] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run62
[2019-03-26 12:38:36,357] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run62
[2019-03-26 12:38:50,428] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:38:50,429] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.9, 86.0, 1.0, 2.0, 0.3500322138924025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 541041.2213290139, 541041.2213290145, 169954.6828579213]
[2019-03-26 12:38:50,430] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:38:50,432] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0139366e-18 1.0000000e+00 2.1174631e-20 7.2785880e-09 5.1348259e-14], sampled 0.5742992038175928
[2019-03-26 12:39:08,481] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:39:08,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.43974788666667, 67.644910855, 1.0, 2.0, 0.567736603991124, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 834010.3206337802, 834010.3206337802, 200014.0360309349]
[2019-03-26 12:39:08,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:39:08,486] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1730551e-18 1.0000000e+00 1.0600378e-21 1.0422273e-09 6.0793702e-15], sampled 0.8167276096367896
[2019-03-26 12:39:21,189] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:39:21,191] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 100.0, 1.0, 2.0, 0.3837926002778032, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 578065.3288533741, 578065.3288533748, 172702.1588169946]
[2019-03-26 12:39:21,191] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:39:21,193] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.2449524e-18 1.0000000e+00 2.4538838e-20 1.6751573e-08 1.3026213e-13], sampled 0.9189734202155622
[2019-03-26 12:39:22,050] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:39:22,051] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.5, 58.0, 1.0, 2.0, 0.9285715475526608, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1297900.421419205, 1297900.421419204, 277922.9313022241]
[2019-03-26 12:39:22,053] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:39:22,055] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6841245e-19 1.0000000e+00 1.4525178e-23 1.6654345e-15 3.3504603e-17], sampled 0.19792212246379637
[2019-03-26 12:39:28,165] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:39:28,166] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.33333333333334, 60.66666666666667, 1.0, 2.0, 0.7672185919679577, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1072257.268026985, 1072257.268026985, 236027.0303476732]
[2019-03-26 12:39:28,168] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:39:28,170] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.1589917e-19 1.0000000e+00 6.2626385e-24 3.3710660e-15 8.3679990e-18], sampled 0.8578351968665875
[2019-03-26 12:40:24,966] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:40:24,968] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.3529969, 93.47975139333333, 1.0, 2.0, 0.3502704380563091, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 538730.3521742712, 538730.3521742707, 169687.1185659757]
[2019-03-26 12:40:24,968] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:40:24,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7969019e-24 1.0000000e+00 1.1950703e-27 5.8329749e-22 2.6684214e-23], sampled 0.07222926756993453
[2019-03-26 12:40:26,054] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.4212943], dtype=float32), 0.13989241]
[2019-03-26 12:40:26,055] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.02130576833333, 90.58328137166666, 1.0, 2.0, 0.4360832798884341, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 635841.4994385578, 635841.4994385571, 177571.362457323]
[2019-03-26 12:40:26,056] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:40:26,059] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.9314925e-17 9.9999964e-01 3.2796287e-19 3.7389242e-07 2.0663261e-12], sampled 0.5514502264247776
[2019-03-26 12:40:31,049] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8867.4423 2764672827.5629 460.0000
[2019-03-26 12:40:31,228] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8301.3539 3128231702.2173 742.0000
[2019-03-26 12:40:31,670] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8591.0574 2904970715.9277 604.0000
[2019-03-26 12:40:31,671] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8519.9159 2966811884.5627 564.0000
[2019-03-26 12:40:31,686] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8782.7577 2822903885.2982 451.0000
[2019-03-26 12:40:32,702] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1525000, evaluation results [1525000.0, 8301.353920685637, 3128231702.2172914, 742.0, 8591.057416644215, 2904970715.9276958, 604.0, 8867.442294712118, 2764672827.5628557, 460.0, 8519.915882902895, 2966811884.5627456, 564.0, 8782.757688113272, 2822903885.298167, 451.0]
[2019-03-26 12:40:32,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.9498382e-17 9.9999988e-01 8.0248856e-20 1.1913568e-07 9.1656361e-12], sum to 1.0000
[2019-03-26 12:40:32,767] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5652
[2019-03-26 12:40:32,774] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.5, 90.0, 1.0, 2.0, 0.3193609982216318, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 504755.2680794219, 504755.2680794225, 167377.8087205701], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1798200.0000, 
sim time next is 1798800.0000, 
raw observation next is [21.43333333333333, 90.33333333333334, 1.0, 2.0, 0.3184244464076827, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 503569.4127113277, 503569.4127113271, 167293.9681354432], 
processed observation next is [1.0, 0.8260869565217391, 0.21484992101105835, 0.9033333333333334, 1.0, 1.0, 0.1788246342261237, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13988039241981326, 0.13988039241981307, 0.24969248975439284], 
reward next is 0.7503, 
noisyNet noise sample is [array([-0.9847558], dtype=float32), 0.50665396]. 
=============================================
[2019-03-26 12:40:36,741] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.02415905e-16 3.22803381e-11 1.38999254e-18 1.00000000e+00
 2.12515325e-10], sum to 1.0000
[2019-03-26 12:40:36,752] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0700
[2019-03-26 12:40:36,760] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.06666666666667, 83.66666666666667, 1.0, 2.0, 0.5805027102170263, 1.0, 2.0, 0.5805027102170263, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1623018.655152488, 1623018.655152488, 327156.5907033619], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1866000.0000, 
sim time next is 1866600.0000, 
raw observation next is [27.05, 84.0, 1.0, 2.0, 0.566266683762235, 1.0, 2.0, 0.566266683762235, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1583186.967388166, 1583186.967388166, 322121.2513232874], 
processed observation next is [1.0, 0.6086956521739131, 0.4810426540284361, 0.84, 1.0, 1.0, 0.4774297394725723, 1.0, 1.0, 0.4774297394725723, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4397741576078239, 0.4397741576078239, 0.48077798704968266], 
reward next is 0.5192, 
noisyNet noise sample is [array([-1.9127637], dtype=float32), -0.43767178]. 
=============================================
[2019-03-26 12:40:41,984] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.6991686e-14 4.4337422e-02 9.3239629e-16 9.5566243e-01 1.5516908e-07], sum to 1.0000
[2019-03-26 12:40:41,997] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1785
[2019-03-26 12:40:42,002] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.7, 90.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 527698.5932538356, 527698.5932538356, 238872.2410504796], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1564800.0000, 
sim time next is 1565400.0000, 
raw observation next is [21.7, 90.16666666666666, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 518831.5914206022, 518831.5914206022, 237231.4929239286], 
processed observation next is [1.0, 0.08695652173913043, 0.2274881516587678, 0.9016666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.14411988650572283, 0.14411988650572283, 0.3540768551103412], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2604163], dtype=float32), 0.5211559]. 
=============================================
[2019-03-26 12:40:48,662] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.6246518e-18 1.0000000e+00 2.3886943e-22 4.4987477e-12 4.9458667e-16], sum to 1.0000
[2019-03-26 12:40:48,672] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7845
[2019-03-26 12:40:48,676] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.96666666666667, 93.0, 1.0, 2.0, 0.3782450286022301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 567841.1181293149, 567841.1181293143, 171735.9421542454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1838400.0000, 
sim time next is 1839000.0000, 
raw observation next is [23.08333333333333, 92.5, 1.0, 2.0, 0.3794882303649093, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 568677.0712151603, 568677.0712151603, 171775.8296207535], 
processed observation next is [1.0, 0.2608695652173913, 0.2930489731437597, 0.925, 1.0, 1.0, 0.2523954582709751, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1579658531153223, 0.1579658531153223, 0.25638183525485597], 
reward next is 0.7436, 
noisyNet noise sample is [array([0.97371906], dtype=float32), -0.39474657]. 
=============================================
[2019-03-26 12:40:48,689] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[67.93288 ]
 [67.65661 ]
 [67.38548 ]
 [67.057655]
 [66.73769 ]], R is [[68.3203125 ]
 [68.38078308]
 [68.44048309]
 [68.50045013]
 [68.55859375]].
[2019-03-26 12:40:53,037] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.5105485e-16 5.0978683e-11 6.6938278e-19 1.0000000e+00 1.4989107e-09], sum to 1.0000
[2019-03-26 12:40:53,046] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3324
[2019-03-26 12:40:53,050] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.03333333333333, 77.33333333333334, 1.0, 2.0, 0.2881135426110817, 1.0, 2.0, 0.2881135426110817, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 805225.2545437095, 805225.2545437095, 247629.1968278969], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2319600.0000, 
sim time next is 2320200.0000, 
raw observation next is [29.95, 77.5, 1.0, 2.0, 0.2877582888763738, 1.0, 2.0, 0.2877582888763738, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 804232.0123360823, 804232.0123360823, 247562.7068483686], 
processed observation next is [1.0, 0.8695652173913043, 0.6184834123222749, 0.775, 1.0, 1.0, 0.14187745647755876, 1.0, 1.0, 0.14187745647755876, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2233977812044673, 0.2233977812044673, 0.3694965773856248], 
reward next is 0.6305, 
noisyNet noise sample is [array([1.0747863], dtype=float32), -0.7083196]. 
=============================================
[2019-03-26 12:40:53,432] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.1374808e-17 6.1339510e-11 4.8691275e-18 1.0000000e+00 3.4409481e-10], sum to 1.0000
[2019-03-26 12:40:53,443] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1596
[2019-03-26 12:40:53,454] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.51666666666667, 87.33333333333333, 1.0, 2.0, 0.2730559894900243, 1.0, 2.0, 0.2730559894900243, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 763127.1447959223, 763127.1447959217, 244885.6749785233], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2146200.0000, 
sim time next is 2146800.0000, 
raw observation next is [27.43333333333334, 87.66666666666667, 1.0, 2.0, 0.2731441009558061, 1.0, 2.0, 0.2731441009558061, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 763373.4832120206, 763373.4832120206, 244901.0490858156], 
processed observation next is [0.0, 0.8695652173913043, 0.49921011058451853, 0.8766666666666667, 1.0, 1.0, 0.1242700011515736, 1.0, 1.0, 0.1242700011515736, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.21204818978111684, 0.21204818978111684, 0.36552395385942626], 
reward next is 0.6345, 
noisyNet noise sample is [array([1.6865618], dtype=float32), -0.5880243]. 
=============================================
[2019-03-26 12:41:00,752] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.0334457e-21 3.4255905e-22 2.2809356e-21 1.0000000e+00 2.2422718e-11], sum to 1.0000
[2019-03-26 12:41:00,759] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1857
[2019-03-26 12:41:00,766] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.16666666666667, 88.33333333333334, 1.0, 2.0, 0.6751223517654337, 1.0, 2.0, 0.6751223517654337, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1887797.293639712, 1887797.293639712, 363648.4729042446], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2456400.0000, 
sim time next is 2457000.0000, 
raw observation next is [26.05, 88.5, 1.0, 2.0, 0.6663726927601872, 1.0, 2.0, 0.6663726927601872, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1863309.961559127, 1863309.961559127, 360052.5898433544], 
processed observation next is [1.0, 0.43478260869565216, 0.43364928909952616, 0.885, 1.0, 1.0, 0.5980393888676954, 1.0, 1.0, 0.5980393888676954, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5175861004330908, 0.5175861004330908, 0.537391925139335], 
reward next is 0.4626, 
noisyNet noise sample is [array([-0.78838354], dtype=float32), -0.789876]. 
=============================================
[2019-03-26 12:41:00,784] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[50.03795 ]
 [50.3504  ]
 [50.231285]
 [50.008423]
 [49.725037]], R is [[49.99881363]
 [49.95606613]
 [49.92276382]
 [49.88479614]
 [49.841362  ]].
[2019-03-26 12:41:02,732] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9178500e-19 1.1362124e-16 9.0419171e-20 1.0000000e+00 1.5801686e-10], sum to 1.0000
[2019-03-26 12:41:02,745] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7717
[2019-03-26 12:41:02,751] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.95, 81.0, 1.0, 2.0, 0.5351659222033744, 1.0, 2.0, 0.5351659222033744, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1496173.746272729, 1496173.746272729, 311524.841318254], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1935000.0000, 
sim time next is 1935600.0000, 
raw observation next is [26.0, 80.66666666666666, 1.0, 2.0, 0.5383196548099443, 1.0, 2.0, 0.5383196548099443, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1504996.887873876, 1504996.887873876, 312572.5285378133], 
processed observation next is [1.0, 0.391304347826087, 0.4312796208530806, 0.8066666666666665, 1.0, 1.0, 0.4437586202529449, 1.0, 1.0, 0.4437586202529449, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4180546910760766, 0.4180546910760766, 0.46652616199673624], 
reward next is 0.5335, 
noisyNet noise sample is [array([0.53785235], dtype=float32), -0.62726545]. 
=============================================
[2019-03-26 12:41:17,257] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3826620e-17 1.0000000e+00 2.1496681e-20 1.2672786e-11 3.0282779e-15], sum to 1.0000
[2019-03-26 12:41:17,267] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5872
[2019-03-26 12:41:17,271] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.0, 96.66666666666666, 1.0, 2.0, 0.4566216178831848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 646834.9573899852, 646834.9573899852, 178213.686930405], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2694000.0000, 
sim time next is 2694600.0000, 
raw observation next is [24.0, 97.0, 1.0, 2.0, 0.4589323567405026, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 648904.8517526209, 648904.8517526215, 178397.4658401451], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.97, 1.0, 1.0, 0.3481112731813284, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18025134770906137, 0.1802513477090615, 0.2662648743882763], 
reward next is 0.7337, 
noisyNet noise sample is [array([-0.73145205], dtype=float32), -1.1537964]. 
=============================================
[2019-03-26 12:41:18,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.1320925e-18 3.8670276e-14 2.5423386e-19 1.0000000e+00 1.3863463e-11], sum to 1.0000
[2019-03-26 12:41:18,847] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9715
[2019-03-26 12:41:18,854] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.1761482242240397, 1.0, 2.0, 0.1761482242240397, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 538290.225131236, 538290.2251312354, 238560.7058760442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2764800.0000, 
sim time next is 2765400.0000, 
raw observation next is [22.0, 94.00000000000001, 1.0, 2.0, 0.1757446466140406, 1.0, 2.0, 0.1757446466140406, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 537063.7663719672, 537063.7663719677, 238508.7758617684], 
processed observation next is [1.0, 0.0, 0.2417061611374408, 0.9400000000000002, 1.0, 1.0, 0.006921260980771793, 1.0, 1.0, 0.006921260980771793, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.14918437954776864, 0.1491843795477688, 0.3559832475548782], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.09769753], dtype=float32), 1.9974082]. 
=============================================
[2019-03-26 12:41:21,607] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.3047904e-16 3.6393565e-08 5.0334949e-17 1.0000000e+00 1.1661155e-09], sum to 1.0000
[2019-03-26 12:41:21,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1002
[2019-03-26 12:41:21,628] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.1756488437067809, 1.0, 2.0, 0.1756488437067809, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 536775.2250795121, 536775.2250795115, 238496.8624788964], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2770200.0000, 
sim time next is 2770800.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.1753905100563719, 1.0, 2.0, 0.1753905100563719, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 535990.0264712968, 535990.0264712968, 238463.6750296397], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.006494590429363728, 1.0, 1.0, 0.006494590429363728, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.1488861184642491, 0.1488861184642491, 0.35591593288005924], 
reward next is 0.6441, 
noisyNet noise sample is [array([0.37329033], dtype=float32), -0.84096014]. 
=============================================
[2019-03-26 12:41:27,251] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5107266e-21 3.3778688e-19 7.5314854e-23 1.0000000e+00 2.3384189e-13], sum to 1.0000
[2019-03-26 12:41:27,261] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1909
[2019-03-26 12:41:27,269] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.76666666666667, 80.66666666666667, 1.0, 2.0, 0.2769935596716157, 1.0, 2.0, 0.2769935596716157, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 774135.6969712601, 774135.6969712595, 245590.1508149096], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2328000.0000, 
sim time next is 2328600.0000, 
raw observation next is [28.68333333333333, 80.83333333333333, 1.0, 2.0, 0.2762006614344132, 1.0, 2.0, 0.2762006614344132, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 771918.924447475, 771918.924447475, 245447.4915110255], 
processed observation next is [1.0, 0.9565217391304348, 0.5584518167456555, 0.8083333333333332, 1.0, 1.0, 0.1279526041378472, 1.0, 1.0, 0.1279526041378472, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.21442192345763195, 0.21442192345763195, 0.36633953956869475], 
reward next is 0.6337, 
noisyNet noise sample is [array([0.15380591], dtype=float32), -0.86488515]. 
=============================================
[2019-03-26 12:41:27,566] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-26 12:41:27,571] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:41:27,571] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:41:27,571] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:41:27,574] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:41:27,573] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:41:27,577] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:41:27,577] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:41:27,578] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:41:27,582] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:41:27,580] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:41:27,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run63
[2019-03-26 12:41:27,633] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run63
[2019-03-26 12:41:27,634] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run63
[2019-03-26 12:41:27,674] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run63
[2019-03-26 12:41:27,694] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run63
[2019-03-26 12:42:19,275] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:42:19,278] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.56280267, 73.17521152, 1.0, 2.0, 0.731216650749844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1021917.093646956, 1021917.093646956, 227727.944140452]
[2019-03-26 12:42:19,280] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:42:19,283] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.7948913e-16 1.0000000e+00 1.0303608e-19 4.3164591e-10 9.3774374e-14], sampled 0.4829552721039373
[2019-03-26 12:42:19,286] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:42:19,288] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.31464289, 76.67954593333334, 1.0, 2.0, 0.2633557420066958, 1.0, 2.0, 0.2633557420066958, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 736004.5700515439, 736004.5700515439, 243672.3316027044]
[2019-03-26 12:42:19,289] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:42:19,292] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.7648385e-16 4.5429829e-08 7.7877028e-18 1.0000000e+00 8.0825624e-10], sampled 0.4208361201806905
[2019-03-26 12:42:40,530] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:42:40,532] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.0, 84.0, 1.0, 2.0, 0.2388788526134438, 1.0, 2.0, 0.2388788526134438, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 667580.3764332955, 667580.3764332955, 239154.4493587005]
[2019-03-26 12:42:40,533] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:42:40,536] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5591859e-15 5.0432868e-07 1.7553266e-17 9.9999952e-01 1.0945154e-09], sampled 0.5063269398930849
[2019-03-26 12:42:42,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:42:42,422] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 63.00000000000001, 1.0, 2.0, 0.2766917201440823, 1.0, 2.0, 0.2766917201440823, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 773291.8181882377, 773291.8181882371, 245536.4242179331]
[2019-03-26 12:42:42,424] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:42:42,428] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.4172301e-15 9.8382054e-07 5.1179074e-17 9.9999905e-01 1.6559702e-09], sampled 0.75418393315965
[2019-03-26 12:42:44,642] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:42:44,644] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.61666666666667, 61.0, 1.0, 2.0, 0.5548977314929452, 1.0, 2.0, 0.5548977314929452, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 1551363.300484237, 1551363.300484237, 318686.9942063732]
[2019-03-26 12:42:44,644] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:42:44,649] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.4861413e-21 5.0921209e-20 2.0981565e-21 1.0000000e+00 9.0002806e-12], sampled 0.7150099170590654
[2019-03-26 12:43:14,159] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40378487], dtype=float32), 0.14021234]
[2019-03-26 12:43:14,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.76810859, 76.08559066333335, 1.0, 2.0, 0.2137081183642474, 1.0, 2.0, 0.2137081183642474, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 624900.72763115, 624900.72763115, 240342.5943598125]
[2019-03-26 12:43:14,161] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:43:14,163] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.1439714e-15 3.3184901e-06 4.7460441e-17 9.9999666e-01 2.5845619e-09], sampled 0.6124281170285258
[2019-03-26 12:43:22,762] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7889.9402 3242272276.3574 37.0000
[2019-03-26 12:43:23,092] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7904.2500 3166336822.3996 53.0000
[2019-03-26 12:43:23,105] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7468.1726 3461714041.8738 284.0000
[2019-03-26 12:43:23,107] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8020.2439 3121696413.8472 42.0000
[2019-03-26 12:43:23,135] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7760.0562 3295861747.8030 33.0000
[2019-03-26 12:43:24,151] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1550000, evaluation results [1550000.0, 7468.172635399372, 3461714041.873796, 284.0, 7889.940162595886, 3242272276.3574305, 37.0, 8020.243873730037, 3121696413.847205, 42.0, 7760.056183273806, 3295861747.8030133, 33.0, 7904.249983876029, 3166336822.3995886, 53.0]
[2019-03-26 12:43:24,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8749404e-13 1.8467195e-05 6.6246735e-15 9.9998152e-01 2.4618089e-08], sum to 1.0000
[2019-03-26 12:43:24,350] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4170
[2019-03-26 12:43:24,356] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 82.0, 1.0, 2.0, 0.3177883333680502, 1.0, 2.0, 0.3177883333680502, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 888195.271657195, 888195.271657195, 253397.8485674708], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2349000.0000, 
sim time next is 2349600.0000, 
raw observation next is [27.16666666666667, 82.0, 1.0, 2.0, 0.3329057345003863, 1.0, 2.0, 0.3329057345003863, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 930465.6378355626, 930465.6378355626, 256542.7087303672], 
processed observation next is [1.0, 0.17391304347826086, 0.4865718799368091, 0.82, 1.0, 1.0, 0.19627196927757384, 1.0, 1.0, 0.19627196927757384, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.25846267717654514, 0.25846267717654514, 0.38289956526920477], 
reward next is 0.6171, 
noisyNet noise sample is [array([0.34507865], dtype=float32), 1.5153006]. 
=============================================
[2019-03-26 12:43:37,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9215891e-18 1.1917232e-10 1.7942472e-18 1.0000000e+00 5.7891494e-11], sum to 1.0000
[2019-03-26 12:43:37,189] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-26 12:43:37,195] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.1893705978302678, 1.0, 2.0, 0.1893705978302678, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 565919.5130840867, 565919.5130840867, 238409.1851151735], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2757600.0000, 
sim time next is 2758200.0000, 
raw observation next is [22.0, 99.00000000000001, 1.0, 2.0, 0.1886545120718247, 1.0, 2.0, 0.1886545120718247, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 565032.1485722204, 565032.1485722204, 238509.9135559312], 
processed observation next is [0.0, 0.9565217391304348, 0.2417061611374408, 0.9900000000000001, 1.0, 1.0, 0.022475315749186382, 1.0, 1.0, 0.022475315749186382, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.15695337460339454, 0.15695337460339454, 0.35598494560586746], 
reward next is 0.6440, 
noisyNet noise sample is [array([-1.5288451], dtype=float32), -0.5753385]. 
=============================================
[2019-03-26 12:43:39,354] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2367863e-16 1.6127345e-09 1.0144683e-18 1.0000000e+00 1.1546422e-09], sum to 1.0000
[2019-03-26 12:43:39,364] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1074
[2019-03-26 12:43:39,368] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.5, 86.0, 1.0, 2.0, 0.3542937333018931, 1.0, 2.0, 0.3542937333018931, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1025103.821606108, 1025103.821606108, 265593.4913894442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2813400.0000, 
sim time next is 2814000.0000, 
raw observation next is [24.66666666666666, 85.0, 1.0, 2.0, 0.3760125313263803, 1.0, 2.0, 0.3760125313263803, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1085860.263696773, 1085860.263696773, 270550.2152032127], 
processed observation next is [1.0, 0.5652173913043478, 0.36808846761453373, 0.85, 1.0, 1.0, 0.24820786906792805, 1.0, 1.0, 0.24820786906792805, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.3016278510268814, 0.3016278510268814, 0.40380629134807866], 
reward next is 0.5962, 
noisyNet noise sample is [array([1.1798058], dtype=float32), -1.5789195]. 
=============================================
[2019-03-26 12:43:39,390] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.53018 ]
 [62.865444]
 [63.602173]
 [63.222424]
 [63.86364 ]], R is [[62.15214157]
 [62.13421249]
 [62.12392426]
 [62.1299324 ]
 [62.12840271]].
[2019-03-26 12:43:47,854] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2123302e-20 1.0000000e+00 1.2335730e-23 7.6884749e-15 1.9432139e-18], sum to 1.0000
[2019-03-26 12:43:47,860] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9912
[2019-03-26 12:43:47,867] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 73.33333333333334, 1.0, 2.0, 0.5131737203342397, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 717086.7566957298, 717086.7566957292, 185686.3818998642], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3318600.0000, 
sim time next is 3319200.0000, 
raw observation next is [29.0, 74.0, 1.0, 2.0, 0.516806662117134, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 722164.9980060417, 722164.9980060423, 186271.7918337891], 
processed observation next is [0.0, 0.43478260869565216, 0.5734597156398105, 0.74, 1.0, 1.0, 0.4178393519483542, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2006013883350116, 0.20060138833501176, 0.278017599751924], 
reward next is 0.7220, 
noisyNet noise sample is [array([0.14182153], dtype=float32), -0.47546396]. 
=============================================
[2019-03-26 12:43:50,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.9672424e-19 1.0000000e+00 2.9057420e-22 2.3002940e-14 4.3181917e-16], sum to 1.0000
[2019-03-26 12:43:50,620] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1064
[2019-03-26 12:43:50,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.3333950727343722, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 527203.1610932067, 527203.1610932067, 169111.7180486134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2956200.0000, 
sim time next is 2956800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.3112955111629772, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 492250.5029396613, 492250.5029396607, 166449.4174983875], 
processed observation next is [1.0, 0.21739130434782608, 0.19431279620853087, 0.94, 1.0, 1.0, 0.17023555561804482, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1367362508165726, 0.13673625081657242, 0.24843196641550375], 
reward next is 0.7516, 
noisyNet noise sample is [array([-0.9309509], dtype=float32), -0.2851017]. 
=============================================
[2019-03-26 12:43:50,883] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.3263223e-22 1.0000000e+00 2.4341858e-26 1.6064565e-20 7.5480312e-21], sum to 1.0000
[2019-03-26 12:43:50,895] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9419
[2019-03-26 12:43:50,904] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 94.00000000000001, 1.0, 2.0, 0.3835916465584354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 590912.58056965, 590912.5805696495, 174189.2145948113], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2869800.0000, 
sim time next is 2870400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.3648769842954, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 562068.2695467542, 562068.2695467548, 171666.4570487527], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 1.0, 1.0, 0.2347915473438554, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15613007487409838, 0.15613007487409855, 0.2562185926100786], 
reward next is 0.7438, 
noisyNet noise sample is [array([0.32906994], dtype=float32), 0.71321565]. 
=============================================
[2019-03-26 12:43:54,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.7760814e-18 1.0000000e+00 1.1771477e-21 1.0514238e-09 1.3923862e-14], sum to 1.0000
[2019-03-26 12:43:54,921] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7901
[2019-03-26 12:43:54,926] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 76.33333333333334, 1.0, 2.0, 0.5863564233374999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 819388.542952429, 819388.542952429, 198231.5427192179], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3262800.0000, 
sim time next is 3263400.0000, 
raw observation next is [30.0, 77.0, 1.0, 2.0, 0.578124993567868, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 807881.3708210465, 807881.3708210465, 196741.2898296856], 
processed observation next is [0.0, 0.782608695652174, 0.6208530805687204, 0.77, 1.0, 1.0, 0.4917168597203228, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.22441149189473514, 0.22441149189473514, 0.2936437161637098], 
reward next is 0.7064, 
noisyNet noise sample is [array([0.21278161], dtype=float32), 0.65114]. 
=============================================
[2019-03-26 12:43:56,901] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4219464e-15 2.6982936e-05 1.4620396e-16 9.9997306e-01 5.5922069e-08], sum to 1.0000
[2019-03-26 12:43:56,911] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4277
[2019-03-26 12:43:56,923] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.0, 99.00000000000001, 1.0, 2.0, 0.1729900661436602, 1.0, 2.0, 0.1729900661436602, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 534472.5533678412, 534472.5533678412, 239022.3897859971], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2916600.0000, 
sim time next is 2917200.0000, 
raw observation next is [21.0, 98.0, 1.0, 2.0, 0.1703738326243423, 1.0, 2.0, 0.1703738326243423, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 528073.6240682171, 528073.6240682171, 238926.3491588787], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.98, 1.0, 1.0, 0.00045040075221962735, 1.0, 1.0, 0.00045040075221962735, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.14668711779672697, 0.14668711779672697, 0.3566064912819085], 
reward next is 0.6434, 
noisyNet noise sample is [array([0.11509584], dtype=float32), -1.62034]. 
=============================================
[2019-03-26 12:44:01,604] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.5576945e-13 1.8181723e-02 6.0739845e-14 9.8181689e-01 1.4454815e-06], sum to 1.0000
[2019-03-26 12:44:01,613] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2577
[2019-03-26 12:44:01,623] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.15, 93.0, 1.0, 2.0, 0.345853763119632, 1.0, 1.0, 0.345853763119632, 1.0, 1.0, 0.5938074778789731, 6.9112, 6.9112, 170.5573041426782, 1450334.115792167, 1450334.115792167, 324137.710339089], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3378600.0000, 
sim time next is 3379200.0000, 
raw observation next is [26.1, 93.33333333333334, 1.0, 2.0, 0.481007890447079, 1.0, 2.0, 0.481007890447079, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1344668.116012458, 1344668.116012458, 294457.1933966846], 
processed observation next is [1.0, 0.08695652173913043, 0.4360189573459717, 0.9333333333333335, 1.0, 1.0, 0.3747083017434687, 1.0, 1.0, 0.3747083017434687, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3735189211145717, 0.3735189211145717, 0.4394883483532606], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60067433], dtype=float32), -0.9774583]. 
=============================================
[2019-03-26 12:44:02,533] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.2523714e-15 6.2993809e-06 2.0400210e-16 9.9999368e-01 1.4024460e-08], sum to 1.0000
[2019-03-26 12:44:02,543] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0640
[2019-03-26 12:44:02,552] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.33333333333334, 98.0, 1.0, 2.0, 0.4031676784879168, 1.0, 2.0, 0.4031676784879168, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1146374.697781772, 1146374.697781772, 275302.2007198484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3079200.0000, 
sim time next is 3079800.0000, 
raw observation next is [23.5, 97.0, 1.0, 2.0, 0.4138494736067033, 1.0, 2.0, 0.4138494736067033, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1174376.655443601, 1174376.655443601, 277807.352411951], 
processed observation next is [1.0, 0.6521739130434783, 0.31279620853080575, 0.97, 1.0, 1.0, 0.29379454651410036, 1.0, 1.0, 0.29379454651410036, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.32621573762322253, 0.32621573762322253, 0.4146378394208224], 
reward next is 0.5854, 
noisyNet noise sample is [array([-0.1668071], dtype=float32), -0.29911277]. 
=============================================
[2019-03-26 12:44:16,969] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.4458078e-17 1.0000000e+00 3.4421927e-19 2.1508171e-08 1.3737557e-12], sum to 1.0000
[2019-03-26 12:44:16,982] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9735
[2019-03-26 12:44:16,987] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.83333333333334, 79.83333333333334, 1.0, 2.0, 0.5566791690368277, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 777901.6489690338, 777901.6489690333, 192952.5473174102], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3265800.0000, 
sim time next is 3266400.0000, 
raw observation next is [28.66666666666667, 80.66666666666667, 1.0, 2.0, 0.5521977402739913, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771637.0404237891, 771637.0404237891, 192178.3293658529], 
processed observation next is [0.0, 0.8260869565217391, 0.5576619273301741, 0.8066666666666668, 1.0, 1.0, 0.46047920514938706, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21434362233994142, 0.21434362233994142, 0.28683332741172074], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.8168612], dtype=float32), 0.3156396]. 
=============================================
[2019-03-26 12:44:18,802] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.1136480e-19 1.0000000e+00 3.6960869e-21 1.1044366e-10 3.9638805e-16], sum to 1.0000
[2019-03-26 12:44:18,804] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5157
[2019-03-26 12:44:18,811] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.83333333333334, 79.00000000000001, 1.0, 2.0, 0.5146523632729149, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 719153.6477883166, 719153.647788316, 185923.4973853219], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3276600.0000, 
sim time next is 3277200.0000, 
raw observation next is [27.66666666666667, 79.0, 1.0, 2.0, 0.5115656084541126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 714838.8946300927, 714838.8946300927, 185427.6951711184], 
processed observation next is [0.0, 0.9565217391304348, 0.5102685624012641, 0.79, 1.0, 1.0, 0.41152482946278623, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1985663596194702, 0.1985663596194702, 0.27675775398674385], 
reward next is 0.7232, 
noisyNet noise sample is [array([2.3836925], dtype=float32), 0.9249394]. 
=============================================
[2019-03-26 12:44:18,986] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-26 12:44:18,987] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:44:18,988] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:44:18,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:44:18,989] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:44:18,990] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:44:18,991] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:44:18,992] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:44:18,994] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:44:18,995] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:44:18,995] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:44:19,020] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run64
[2019-03-26 12:44:19,045] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run64
[2019-03-26 12:44:19,071] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run64
[2019-03-26 12:44:19,091] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run64
[2019-03-26 12:44:19,092] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run64
[2019-03-26 12:44:22,559] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:44:22,563] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.61462879666667, 95.18025144666667, 1.0, 2.0, 0.274425550087057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 446297.0911335237, 446297.0911335243, 163317.2424634728]
[2019-03-26 12:44:22,563] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:44:22,565] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0579592e-25 1.0000000e+00 8.8646854e-30 1.2696213e-25 3.7707305e-26], sampled 0.25012625674376276
[2019-03-26 12:45:01,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:45:01,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.25, 72.83333333333333, 1.0, 2.0, 0.4967375519648041, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 694112.0623406153, 694112.0623406153, 183086.1705186634]
[2019-03-26 12:45:01,774] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:45:01,776] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0920831e-19 1.0000000e+00 1.5291696e-22 6.2626261e-13 1.1034457e-16], sampled 0.4562524225672554
[2019-03-26 12:45:17,423] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:45:17,426] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.66666666666667, 84.0, 1.0, 2.0, 0.9281840796983618, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565012471, 1297358.511685925, 1297358.511685925, 277810.5694177315]
[2019-03-26 12:45:17,427] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:45:17,430] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.1334992e-17 1.0000000e+00 1.2345400e-20 3.0382755e-11 2.8971651e-14], sampled 0.607596737247765
[2019-03-26 12:45:28,786] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:45:28,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.19284477666666, 77.59746506166667, 1.0, 2.0, 0.5599796725772204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 782515.4606919922, 782515.4606919922, 193526.4746094124]
[2019-03-26 12:45:28,789] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:45:28,793] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [5.5093678e-18 1.0000000e+00 1.1186034e-20 1.7062389e-09 8.7898350e-14], sampled 0.6142492886566796
[2019-03-26 12:46:10,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:46:10,947] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.45, 88.33333333333334, 1.0, 2.0, 0.4791598225705687, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 669542.2286759431, 669542.2286759437, 180394.9043858152]
[2019-03-26 12:46:10,948] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:46:10,953] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.0757943e-19 1.0000000e+00 1.8803952e-21 5.5828880e-10 7.9338044e-15], sampled 0.7427000722554497
[2019-03-26 12:46:11,415] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.412941], dtype=float32), 0.14110614]
[2019-03-26 12:46:11,416] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.31874623333334, 91.70237915000001, 1.0, 2.0, 0.573169870516478, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 800954.3896421612, 800954.3896421612, 195853.0940707065]
[2019-03-26 12:46:11,417] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:46:11,421] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.3869782e-17 9.9999976e-01 1.3232868e-19 2.2740096e-07 1.5150647e-12], sampled 0.2555805775122355
[2019-03-26 12:46:13,816] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8820.9045 2821533503.0260 380.0000
[2019-03-26 12:46:13,984] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8589.9186 2962357612.8607 437.0000
[2019-03-26 12:46:14,074] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8646.9234 2903746431.0056 519.0000
[2019-03-26 12:46:14,111] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8889.1485 2765460454.0725 409.0000
[2019-03-26 12:46:14,219] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8349.2202 3124988752.7010 614.0000
[2019-03-26 12:46:15,237] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1575000, evaluation results [1575000.0, 8349.220184754751, 3124988752.7009764, 614.0, 8646.923396373091, 2903746431.005642, 519.0, 8889.148477431074, 2765460454.072533, 409.0, 8589.918625021075, 2962357612.8607354, 437.0, 8820.904531084521, 2821533503.0260344, 380.0]
[2019-03-26 12:46:26,185] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.0640543e-18 4.6469131e-07 1.4640072e-19 9.9999952e-01 7.3548612e-10], sum to 1.0000
[2019-03-26 12:46:26,193] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0433
[2019-03-26 12:46:26,197] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.2540418120043025, 1.0, 2.0, 0.2540418120043025, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 709969.4119562854, 709969.4119562854, 241612.7234481939], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3459600.0000, 
sim time next is 3460200.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.2538283039146861, 1.0, 2.0, 0.2538283039146861, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 709372.5246285354, 709372.5246285354, 241576.9578607265], 
processed observation next is [1.0, 0.043478260869565216, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 0.10099795652371817, 1.0, 1.0, 0.10099795652371817, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.1970479235079265, 0.1970479235079265, 0.3605626236727261], 
reward next is 0.6394, 
noisyNet noise sample is [array([0.45306587], dtype=float32), -1.9049308]. 
=============================================
[2019-03-26 12:46:31,032] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1962057e-16 1.2968979e-08 3.1595080e-17 1.0000000e+00 2.8471154e-08], sum to 1.0000
[2019-03-26 12:46:31,041] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5177
[2019-03-26 12:46:31,046] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 79.00000000000001, 1.0, 2.0, 0.258934342733646, 1.0, 2.0, 0.258934342733646, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 723647.1561134402, 723647.1561134402, 242434.385162393], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3539400.0000, 
sim time next is 3540000.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.2595059007800047, 1.0, 2.0, 0.2595059007800047, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 725245.0368075195, 725245.0368075195, 242531.0971914122], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 1.0, 1.0, 0.10783843467470443, 1.0, 1.0, 0.10783843467470443, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2014569546687554, 0.2014569546687554, 0.3619867122259884], 
reward next is 0.6380, 
noisyNet noise sample is [array([0.09934971], dtype=float32), 0.1786599]. 
=============================================
[2019-03-26 12:46:31,058] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[63.788403]
 [63.782345]
 [63.63214 ]
 [63.616272]
 [63.683292]], R is [[63.80781937]
 [63.80789948]
 [63.80808258]
 [63.80820847]
 [63.80826569]].
[2019-03-26 12:46:32,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.9769959e-14 9.9999857e-01 1.7417654e-16 1.3980061e-06 7.4914380e-10], sum to 1.0000
[2019-03-26 12:46:32,447] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9142
[2019-03-26 12:46:32,453] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.7723456710232763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1079426.465963131, 1079426.465963132, 237233.2042361728], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3565200.0000, 
sim time next is 3565800.0000, 
raw observation next is [27.5, 79.0, 1.0, 2.0, 0.7904241305869535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1104705.973821616, 1104705.973821616, 241571.4832407911], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.79, 1.0, 1.0, 0.7474989525144018, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.30686277050600447, 0.30686277050600447, 0.3605544525981957], 
reward next is 0.6394, 
noisyNet noise sample is [array([0.6455249], dtype=float32), 0.30198944]. 
=============================================
[2019-03-26 12:46:36,456] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.5929666e-17 1.0000000e+00 1.4043334e-20 4.4045162e-10 2.0457638e-14], sum to 1.0000
[2019-03-26 12:46:36,463] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4697
[2019-03-26 12:46:36,469] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [35.0, 56.0, 1.0, 2.0, 0.5995248817101846, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 837797.7203946159, 837797.7203946159, 200657.9150921838], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3855600.0000, 
sim time next is 3856200.0000, 
raw observation next is [35.0, 55.83333333333334, 1.0, 2.0, 0.6496511776503019, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 907875.9551292253, 907875.9551292253, 210358.0386491946], 
processed observation next is [0.0, 0.6521739130434783, 0.8578199052132701, 0.5583333333333335, 1.0, 1.0, 0.5778929851208456, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2521877653136737, 0.2521877653136737, 0.31396722186446957], 
reward next is 0.6860, 
noisyNet noise sample is [array([0.4266202], dtype=float32), 0.23404562]. 
=============================================
[2019-03-26 12:46:38,484] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.6392570e-21 2.0943593e-20 1.5885828e-20 1.0000000e+00 1.0264816e-10], sum to 1.0000
[2019-03-26 12:46:38,490] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0219
[2019-03-26 12:46:38,499] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.7223708316005577, 1.0, 2.0, 0.7223708316005577, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2020039.457976431, 2020039.457976432, 383844.0005705354], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3751200.0000, 
sim time next is 3751800.0000, 
raw observation next is [31.0, 63.5, 1.0, 2.0, 0.8435355937556812, 1.0, 2.0, 0.8435355937556812, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2359214.9582415, 2359214.958241499, 441616.0619071171], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.635, 1.0, 1.0, 0.8114886671755195, 1.0, 1.0, 0.8114886671755195, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6553374884004166, 0.6553374884004164, 0.6591284506076375], 
reward next is 0.3409, 
noisyNet noise sample is [array([-0.954404], dtype=float32), 1.8056726]. 
=============================================
[2019-03-26 12:46:56,155] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5372340e-18 3.6461625e-21 2.8911281e-20 1.0000000e+00 3.4390816e-08], sum to 1.0000
[2019-03-26 12:46:56,165] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6447
[2019-03-26 12:46:56,178] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 3 has been changed to 4 for the demand 3603606.513353216 W.
[2019-03-26 12:46:56,182] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.66666666666666, 68.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.879271410064822, 6.9112, 170.5573041426782, 3603606.513353216, 2910137.583696536, 548095.1214249448], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4369200.0000, 
sim time next is 4369800.0000, 
raw observation next is [32.83333333333334, 71.5, 1.0, 2.0, 0.8882413589201699, 1.0, 2.0, 0.7647107189743477, 1.0, 1.0, 1.03, 7.00511257950883, 6.9112, 170.5573041426782, 3209224.693950029, 3141951.293128363, 587381.6595269259], 
processed observation next is [1.0, 0.5652173913043478, 0.7551342812006324, 0.715, 1.0, 1.0, 0.8653510348435781, 1.0, 1.0, 0.7165189385233105, 1.0, 0.5, 1.0365853658536586, 0.00939125795088298, 0.0, 0.8375144448122397, 0.891451303875008, 0.8727642480912119, 0.8766890440700387], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6626632], dtype=float32), -0.950482]. 
=============================================
[2019-03-26 12:46:56,508] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5101098e-14 1.0000000e+00 2.6555330e-17 1.3154416e-10 3.6978016e-09], sum to 1.0000
[2019-03-26 12:46:56,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2356
[2019-03-26 12:46:56,515] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 1 has been changed to 2 for the demand 2163188.607518746 W.
[2019-03-26 12:46:56,526] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.910547613206619, 6.9112, 168.9073387290074, 2163188.607518746, 1454240.595108701, 311356.2146085888], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4000200.0000, 
sim time next is 4000800.0000, 
raw observation next is [29.66666666666667, 84.0, 1.0, 2.0, 0.6750079240226964, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005974136652245, 6.9112, 168.9115794979966, 1840156.619567405, 1772921.133273948, 379329.0645748523], 
processed observation next is [1.0, 0.30434782608695654, 0.6050552922590839, 0.84, 1.0, 1.0, 0.6084432819550558, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009477413665224522, 0.0, 0.8294331833908507, 0.5111546165465014, 0.49247809257609665, 0.5661627829475407], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34418294], dtype=float32), 0.15577656]. 
=============================================
[2019-03-26 12:46:57,010] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.0263770e-19 3.5231067e-20 1.6566983e-20 9.9999976e-01 2.6036716e-07], sum to 1.0000
[2019-03-26 12:46:57,019] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9377
[2019-03-26 12:46:57,025] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.0, 53.0, 1.0, 2.0, 0.9409299774665092, 1.0, 2.0, 0.9409299774665092, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2631896.132834926, 2631896.132834927, 494321.1746196955], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4190400.0000, 
sim time next is 4191000.0000, 
raw observation next is [36.0, 53.0, 1.0, 2.0, 1.015235740386999, 1.0, 2.0, 1.015235740386999, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2839974.674988717, 2839974.674988716, 538265.6693776209], 
processed observation next is [1.0, 0.5217391304347826, 0.9052132701421801, 0.53, 1.0, 1.0, 1.018356313719276, 1.0, 1.0, 1.018356313719276, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7888818541635324, 0.7888818541635322, 0.8033815960860013], 
reward next is 0.1966, 
noisyNet noise sample is [array([0.65394324], dtype=float32), -0.47412065]. 
=============================================
[2019-03-26 12:46:57,042] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[42.898968]
 [41.818817]
 [41.483475]
 [40.881004]
 [39.689358]], R is [[41.58611298]
 [41.43246078]
 [41.26439285]
 [41.10489655]
 [40.96582031]].
[2019-03-26 12:47:00,318] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1133665e-21 1.0000000e+00 8.8979783e-25 3.1804836e-20 1.1547707e-15], sum to 1.0000
[2019-03-26 12:47:00,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0446
[2019-03-26 12:47:00,330] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5435760300077559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 759584.8184712358, 759584.8184712352, 190705.3339932352], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4049400.0000, 
sim time next is 4050000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.5430151983184947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 758800.8409369349, 758800.8409369349, 190610.3056436918], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 1.0, 1.0, 0.4494159015885478, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2107780113713708, 0.2107780113713708, 0.28449299349804746], 
reward next is 0.7155, 
noisyNet noise sample is [array([0.06696071], dtype=float32), -0.6502298]. 
=============================================
[2019-03-26 12:47:00,346] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[65.005875]
 [65.15289 ]
 [65.169525]
 [65.3227  ]
 [65.26581 ]], R is [[65.19587708]
 [65.25928497]
 [65.32181549]
 [65.38345337]
 [65.44436646]].
[2019-03-26 12:47:02,175] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.1557889e-13 2.1991670e-07 1.5411245e-13 8.2386595e-01 1.7613384e-01], sum to 1.0000
[2019-03-26 12:47:02,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-26 12:47:02,189] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.16666666666667, 88.16666666666667, 1.0, 2.0, 0.2877625795401553, 1.0, 2.0, 0.2877625795401553, 1.0, 2.0, 0.4997484361219964, 6.9112, 6.9112, 170.5573041426782, 1206592.252097244, 1206592.252097244, 299465.5985316525], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4161000.0000, 
sim time next is 4161600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.421210180940031, 1.0, 2.0, 0.421210180940031, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1177410.509442, 1177410.509442, 277609.1802494783], 
processed observation next is [1.0, 0.17391304347826086, 0.5260663507109005, 0.89, 1.0, 1.0, 0.302662868602447, 1.0, 1.0, 0.302662868602447, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.327058474845, 0.327058474845, 0.4143420600738482], 
reward next is 0.5857, 
noisyNet noise sample is [array([-0.47013167], dtype=float32), -1.1642835]. 
=============================================
[2019-03-26 12:47:02,483] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.9777821e-18 9.1322832e-21 1.4512746e-19 9.9955386e-01 4.4616373e-04], sum to 1.0000
[2019-03-26 12:47:02,495] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7742
[2019-03-26 12:47:02,501] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 71.0, 1.0, 2.0, 0.9580444506988026, 1.0, 2.0, 0.9580444506988026, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2679818.746736446, 2679818.746736445, 504162.1075943592], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4104600.0000, 
sim time next is 4105200.0000, 
raw observation next is [33.33333333333334, 71.0, 1.0, 2.0, 0.7968766502303379, 1.0, 2.0, 0.7968766502303379, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2228602.061087108, 2228602.061087109, 418372.9365844108], 
processed observation next is [1.0, 0.5217391304347826, 0.7788309636650873, 0.71, 1.0, 1.0, 0.7552730725666722, 1.0, 1.0, 0.7552730725666722, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6190561280797523, 0.6190561280797525, 0.6244372187827026], 
reward next is 0.3756, 
noisyNet noise sample is [array([-1.1807296], dtype=float32), -0.7179969]. 
=============================================
[2019-03-26 12:47:06,153] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.6885557e-17 9.2070678e-18 1.0173743e-16 4.8852739e-01 5.1147258e-01], sum to 1.0000
[2019-03-26 12:47:06,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6449
[2019-03-26 12:47:06,168] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.33333333333334, 69.66666666666667, 1.0, 2.0, 0.6156362824031963, 1.0, 2.0, 0.6156362824031963, 1.0, 2.0, 1.03, 6.955219134713484, 6.9112, 170.5573041426782, 2582964.345774621, 2551431.648995435, 493717.7189336118], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4722000.0000, 
sim time next is 4722600.0000, 
raw observation next is [31.66666666666667, 68.33333333333333, 1.0, 2.0, 0.6312562449875682, 1.0, 2.0, 0.6312562449875682, 1.0, 2.0, 1.03, 6.98571641820714, 6.9112, 170.5573041426782, 2648568.943104583, 2595189.801608714, 499589.8520815628], 
processed observation next is [1.0, 0.6521739130434783, 0.6998420221169038, 0.6833333333333332, 1.0, 1.0, 0.5557304156476724, 1.0, 1.0, 0.5557304156476724, 1.0, 1.0, 1.0365853658536586, 0.007451641820714006, 0.0, 0.8375144448122397, 0.7357135953068286, 0.7208860560024205, 0.7456564956441236], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10976107], dtype=float32), 0.5453248]. 
=============================================
[2019-03-26 12:47:10,145] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-26 12:47:10,148] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:47:10,149] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:47:10,152] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:47:10,152] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:47:10,154] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:47:10,155] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:47:10,156] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:47:10,153] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:47:10,156] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:47:10,158] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:47:10,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run65
[2019-03-26 12:47:10,209] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run65
[2019-03-26 12:47:10,210] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run65
[2019-03-26 12:47:10,210] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run65
[2019-03-26 12:47:10,230] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run65
[2019-03-26 12:47:34,633] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40305957], dtype=float32), 0.13419075]
[2019-03-26 12:47:34,636] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.45856632, 83.09930617, 1.0, 2.0, 0.4218372484007396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 627558.1287984118, 627558.1287984125, 177076.2661746401]
[2019-03-26 12:47:34,637] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:47:34,641] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.4833842e-20 1.0000000e+00 5.3633460e-23 3.4541063e-21 2.6374321e-13], sampled 0.913282545910322
[2019-03-26 12:47:39,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40305957], dtype=float32), 0.13419075]
[2019-03-26 12:47:39,061] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.6341624, 87.58073188333333, 1.0, 2.0, 0.3021579599397511, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 489750.6678780416, 489750.6678780421, 166323.4987345173]
[2019-03-26 12:47:39,064] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:47:39,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.5369154e-17 9.9999988e-01 3.2807058e-19 1.2940355e-13 1.0480111e-07], sampled 0.8542272987027201
[2019-03-26 12:48:24,994] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40305957], dtype=float32), 0.13419075]
[2019-03-26 12:48:24,996] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.59334358333333, 61.00914390333333, 1.0, 2.0, 0.5089288157377744, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 711153.1251005833, 711153.1251005827, 185006.1222403303]
[2019-03-26 12:48:24,997] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:48:25,000] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.8767303e-18 1.0000000e+00 5.7348404e-21 3.3526467e-17 3.0389899e-10], sampled 0.21510707722787237
[2019-03-26 12:48:32,000] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.40305957], dtype=float32), 0.13419075]
[2019-03-26 12:48:32,003] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.2, 88.0, 1.0, 2.0, 0.6169462553777941, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 862152.857992277, 862152.857992277, 203945.3090083327]
[2019-03-26 12:48:32,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:48:32,009] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.1148721e-19 1.0000000e+00 5.6314047e-23 1.7243961e-21 3.5151060e-13], sampled 0.8091318417560822
[2019-03-26 12:49:03,694] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.40305957], dtype=float32), 0.13419075]
[2019-03-26 12:49:03,695] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.05600981, 70.054361445, 1.0, 2.0, 0.8689755671740775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1214553.16546285, 1214553.165462849, 261543.8952949211]
[2019-03-26 12:49:03,696] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:49:03,697] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6968134e-17 1.0000000e+00 1.0882155e-19 5.6736199e-17 1.9893505e-09], sampled 0.9884130137750652
[2019-03-26 12:49:04,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8565.5966 3020188644.8602 202.0000
[2019-03-26 12:49:04,958] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8798.7973 2853163478.1157 189.0000
[2019-03-26 12:49:05,202] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8179.8020 3188487282.8538 676.0000
[2019-03-26 12:49:05,288] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8637.1581 2905865616.2554 225.0000
[2019-03-26 12:49:05,301] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8486.0953 3044217181.4154 187.0000
[2019-03-26 12:49:06,322] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1600000, evaluation results [1600000.0, 8179.801968525786, 3188487282.8537517, 676.0, 8565.596566330749, 3020188644.8602448, 202.0, 8798.79729155675, 2853163478.1157184, 189.0, 8486.095330902153, 3044217181.4154453, 187.0, 8637.158070131467, 2905865616.2553697, 225.0]
[2019-03-26 12:49:07,895] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.7937486e-17 1.0000000e+00 2.1435840e-20 2.0157746e-16 1.6407675e-09], sum to 1.0000
[2019-03-26 12:49:07,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6359
[2019-03-26 12:49:07,914] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5264601328612228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735659.0437157999, 735659.0437158006, 187844.5504560716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4460400.0000, 
sim time next is 4461000.0000, 
raw observation next is [30.33333333333333, 66.83333333333333, 1.0, 2.0, 0.5300821452160126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740722.0960106722, 740722.0960106716, 188443.2998642867], 
processed observation next is [0.0, 0.6521739130434783, 0.6366508688783569, 0.6683333333333333, 1.0, 1.0, 0.4338339098988103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20575613778074225, 0.20575613778074212, 0.2812586565138607], 
reward next is 0.7187, 
noisyNet noise sample is [array([0.03727701], dtype=float32), 0.5026659]. 
=============================================
[2019-03-26 12:49:07,937] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.04563 ]
 [63.80224 ]
 [63.621998]
 [63.43208 ]
 [63.232986]], R is [[64.12850952]
 [64.2068634 ]
 [64.28063202]
 [64.3497467 ]
 [64.41434479]].
[2019-03-26 12:49:08,623] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.6802862e-17 2.7865971e-14 2.7659848e-16 1.5035566e-04 9.9984968e-01], sum to 1.0000
[2019-03-26 12:49:08,636] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4268
[2019-03-26 12:49:08,642] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.16666666666667, 88.16666666666667, 1.0, 2.0, 0.4028599901900762, 1.0, 2.0, 0.4028599901900762, 1.0, 2.0, 0.6996345751255659, 6.9112, 6.9112, 170.5573041426782, 1689577.561033702, 1689577.561033702, 354478.6804736148], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4333800.0000, 
sim time next is 4334400.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.3484115291381257, 1.0, 2.0, 0.3484115291381257, 1.0, 2.0, 0.6050756046595513, 6.9112, 6.9112, 170.5573041426782, 1461067.391034784, 1461067.391034784, 326171.0150729644], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 0.21495364956400684, 1.0, 1.0, 0.21495364956400684, 1.0, 1.0, 0.5183848837311601, 0.0, 0.0, 0.8375144448122397, 0.40585205306521777, 0.40585205306521777, 0.4868224105566633], 
reward next is 0.5132, 
noisyNet noise sample is [array([0.65112644], dtype=float32), 1.0962903]. 
=============================================
[2019-03-26 12:49:09,133] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.5613726e-19 1.0000000e+00 5.2444285e-21 3.8440758e-18 1.5168389e-10], sum to 1.0000
[2019-03-26 12:49:09,147] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4054
[2019-03-26 12:49:09,152] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 66.0, 1.0, 2.0, 0.5264601328612228, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 735659.0437157999, 735659.0437158006, 187844.5504560716], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4460400.0000, 
sim time next is 4461000.0000, 
raw observation next is [30.33333333333333, 66.83333333333333, 1.0, 2.0, 0.5300821452160126, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 740722.0960106722, 740722.0960106716, 188443.2998642867], 
processed observation next is [0.0, 0.6521739130434783, 0.6366508688783569, 0.6683333333333333, 1.0, 1.0, 0.4338339098988103, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20575613778074225, 0.20575613778074212, 0.2812586565138607], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.01300844], dtype=float32), 0.72076386]. 
=============================================
[2019-03-26 12:49:09,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[64.92869]
 [64.6905 ]
 [64.51369]
 [64.3265 ]
 [64.1306 ]], R is [[65.00041199]
 [65.07004547]
 [65.13517761]
 [65.195755  ]
 [65.25189972]].
[2019-03-26 12:49:18,252] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.2259043e-15 6.0023080e-09 5.8528016e-18 4.5972599e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:49:18,261] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3648
[2019-03-26 12:49:18,266] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 72.66666666666666, 1.0, 2.0, 0.1726886744413127, 1.0, 2.0, 0.1726886744413127, 1.0, 2.0, 0.2949896921463827, 6.9112, 6.9112, 170.5573041426782, 723923.0004996991, 723923.0004996991, 262609.8626555796], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4992000.0000, 
sim time next is 4992600.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 1.0, 2.0, 0.1724006791228914, 1.0, 2.0, 0.1724006791228914, 1.0, 2.0, 0.2942827093731868, 6.9112, 6.9112, 170.5573041426782, 722715.2972435225, 722715.2972435225, 262533.1892378597], 
processed observation next is [1.0, 0.782608695652174, 0.581358609794629, 0.7333333333333334, 1.0, 1.0, 0.002892384485411302, 1.0, 1.0, 0.002892384485411302, 1.0, 1.0, 0.139369157772179, 0.0, 0.0, 0.8375144448122397, 0.2007542492343118, 0.2007542492343118, 0.3918405809520294], 
reward next is 0.6082, 
noisyNet noise sample is [array([1.3019742], dtype=float32), 0.4958322]. 
=============================================
[2019-03-26 12:49:19,336] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.5095941e-21 1.0000000e+00 6.4686338e-25 9.8012743e-23 2.1137894e-14], sum to 1.0000
[2019-03-26 12:49:19,348] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2512
[2019-03-26 12:49:19,351] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.16666666666667, 74.33333333333333, 1.0, 2.0, 0.645239582179994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 901708.2118517492, 901708.2118517499, 209476.9051486873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4446600.0000, 
sim time next is 4447200.0000, 
raw observation next is [32.33333333333334, 73.66666666666667, 1.0, 2.0, 0.638097030752201, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 891722.4620622793, 891722.4620622793, 208058.7000524227], 
processed observation next is [0.0, 0.4782608695652174, 0.7314375987361774, 0.7366666666666667, 1.0, 1.0, 0.5639723262074711, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2477006839061887, 0.2477006839061887, 0.3105353732125712], 
reward next is 0.6895, 
noisyNet noise sample is [array([0.6431152], dtype=float32), -0.9125601]. 
=============================================
[2019-03-26 12:49:25,774] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4338998e-21 1.3821923e-27 4.2133107e-20 2.0008790e-03 9.9799913e-01], sum to 1.0000
[2019-03-26 12:49:25,783] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6843
[2019-03-26 12:49:25,789] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 67.33333333333334, 1.0, 2.0, 0.4950554854345196, 1.0, 2.0, 0.4950554854345196, 1.0, 2.0, 0.8597476608489796, 6.9112, 6.9112, 170.5573041426782, 2076616.233314004, 2076616.233314004, 411743.0418510177], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4707600.0000, 
sim time next is 4708200.0000, 
raw observation next is [31.0, 66.66666666666666, 1.0, 2.0, 0.4930246756890754, 1.0, 2.0, 0.4930246756890754, 1.0, 2.0, 0.8554374929137825, 6.9112, 6.9112, 170.5573041426782, 2068089.34414196, 2068089.34414196, 410216.6598810084], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.6666666666666665, 1.0, 1.0, 0.389186356251898, 1.0, 1.0, 0.389186356251898, 1.0, 1.0, 0.8237042596509543, 0.0, 0.0, 0.8375144448122397, 0.5744692622616555, 0.5744692622616555, 0.6122636714641916], 
reward next is 0.3877, 
noisyNet noise sample is [array([0.45708597], dtype=float32), -1.0035379]. 
=============================================
[2019-03-26 12:49:27,816] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.2576093e-14 9.9668127e-01 9.5154748e-17 1.6848739e-11 3.3186465e-03], sum to 1.0000
[2019-03-26 12:49:27,825] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9712
[2019-03-26 12:49:27,831] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.5485688512610616, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 766564.2279348939, 766564.2279348939, 191555.4324358873], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4579200.0000, 
sim time next is 4579800.0000, 
raw observation next is [28.0, 84.83333333333333, 1.0, 2.0, 0.5508464621512057, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 769748.0901731236, 769748.0901731236, 191946.0132456327], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.8483333333333333, 1.0, 1.0, 0.4588511592183201, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2138189139369788, 0.2138189139369788, 0.28648658693378015], 
reward next is 0.7135, 
noisyNet noise sample is [array([-0.8348426], dtype=float32), -1.3473483]. 
=============================================
[2019-03-26 12:49:32,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7600757e-25 0.0000000e+00 5.0280146e-22 4.5474997e-05 9.9995458e-01], sum to 1.0000
[2019-03-26 12:49:32,482] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5488
[2019-03-26 12:49:32,487] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5909436186791219, 1.0, 2.0, 0.5909436186791219, 1.0, 2.0, 1.026273637604622, 6.9112, 6.9112, 170.5573041426782, 2479260.991919293, 2479260.991919293, 483730.4698421505], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5234400.0000, 
sim time next is 5235000.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5850475243887677, 1.0, 2.0, 0.5850475243887677, 1.0, 2.0, 1.016034071690454, 6.9112, 6.9112, 170.5573041426782, 2454500.061768839, 2454500.061768839, 478939.0277574258], 
processed observation next is [1.0, 0.6086956521739131, 0.7156398104265403, 0.67, 1.0, 1.0, 0.5000572582997201, 1.0, 1.0, 0.5000572582997201, 1.0, 1.0, 1.019553745963968, 0.0, 0.0, 0.8375144448122397, 0.6818055727135665, 0.6818055727135665, 0.7148343697872027], 
reward next is 0.2852, 
noisyNet noise sample is [array([0.2806481], dtype=float32), -1.258234]. 
=============================================
[2019-03-26 12:49:32,502] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[22.999784]
 [23.691843]
 [23.3136  ]
 [22.609509]
 [24.257406]], R is [[22.83151627]
 [22.88121605]
 [22.96106148]
 [23.022192  ]
 [22.79197121]].
[2019-03-26 12:49:33,999] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.8341002e-22 1.2804322e-27 8.5397429e-20 1.9085877e-05 9.9998093e-01], sum to 1.0000
[2019-03-26 12:49:34,009] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0963
[2019-03-26 12:49:34,014] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 67.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2661657878939657, 6.911200000000001, 6.9112, 170.5573041426782, 658381.9226873871, 658381.9226873864, 253836.7587529449], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4900800.0000, 
sim time next is 4901400.0000, 
raw observation next is [29.5, 68.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2619058593038984, 6.911199999999999, 6.9112, 170.5573041426782, 648764.450015094, 648764.4500150947, 252410.0386029509], 
processed observation next is [1.0, 0.7391304347826086, 0.5971563981042655, 0.68, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.09988519427304686, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.180212347226415, 0.1802123472264152, 0.3767314008999267], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.37022805], dtype=float32), -0.436619]. 
=============================================
[2019-03-26 12:49:37,745] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.9066481e-16 3.5188029e-12 5.1782623e-16 2.1925487e-07 9.9999976e-01], sum to 1.0000
[2019-03-26 12:49:37,756] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7163
[2019-03-26 12:49:37,762] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.0, 74.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2768888612690245, 6.911199999999999, 6.9112, 170.5573041426782, 689970.9153001802, 689970.9153001808, 258420.8224189968], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4827000.0000, 
sim time next is 4827600.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2772866509276009, 6.911200000000001, 6.9112, 170.5573041426782, 690957.7327918367, 690957.7327918361, 258567.1218016027], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.74, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11864225722878159, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.19193270355328798, 0.19193270355328781, 0.3859210773158249], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.30493638], dtype=float32), 0.055432756]. 
=============================================
[2019-03-26 12:49:38,870] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.5287244e-17 1.0000000e+00 4.0368425e-21 6.3915150e-18 2.7086844e-09], sum to 1.0000
[2019-03-26 12:49:38,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6126
[2019-03-26 12:49:38,886] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5363698225970476, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 749511.4219028318, 749511.4219028311, 189490.8007199865], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5163600.0000, 
sim time next is 5164200.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5340302231083116, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 746240.9685164052, 746240.9685164046, 189099.758521216], 
processed observation next is [0.0, 0.782608695652174, 0.6208530805687204, 0.7, 1.0, 1.0, 0.43859063025097783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20728915792122365, 0.20728915792122352, 0.2822384455540537], 
reward next is 0.7178, 
noisyNet noise sample is [array([-0.87526876], dtype=float32), -1.0752808]. 
=============================================
[2019-03-26 12:49:49,521] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4486538e-25 1.0000000e+00 9.0685684e-31 3.1805096e-34 8.1168366e-23], sum to 1.0000
[2019-03-26 12:49:49,530] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7534
[2019-03-26 12:49:49,536] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 85.66666666666667, 1.0, 2.0, 0.5073027453598399, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 708880.172886724, 708880.1728867247, 184748.1529400289], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5035200.0000, 
sim time next is 5035800.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 1.0, 2.0, 0.508664754023036, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 710784.0142643537, 710784.0142643544, 184964.7932893815], 
processed observation next is [0.0, 0.2608695652173913, 0.470774091627172, 0.8483333333333333, 1.0, 1.0, 0.40802982412413974, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19744000396232048, 0.19744000396232067, 0.27606685565579325], 
reward next is 0.7239, 
noisyNet noise sample is [array([-1.7810678], dtype=float32), 0.25041968]. 
=============================================
[2019-03-26 12:49:55,222] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.7900595e-23 1.0000000e+00 2.3930216e-26 3.3653970e-24 3.8047500e-15], sum to 1.0000
[2019-03-26 12:49:55,231] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3626
[2019-03-26 12:49:55,236] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.16666666666667, 62.33333333333333, 1.0, 2.0, 0.5208317382904694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 727791.405560802, 727791.4055608013, 186924.6560493465], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5068200.0000, 
sim time next is 5068800.0000, 
raw observation next is [31.0, 63.0, 1.0, 2.0, 0.5206810162924177, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727580.7199703257, 727580.7199703263, 186900.042869508], 
processed observation next is [0.0, 0.6956521739130435, 0.6682464454976303, 0.63, 1.0, 1.0, 0.42250724854508154, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2021057555473127, 0.20210575554731286, 0.27895528786493734], 
reward next is 0.7210, 
noisyNet noise sample is [array([-1.5764691], dtype=float32), 1.3563169]. 
=============================================
[2019-03-26 12:49:55,838] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.7497883e-22 8.4451163e-31 2.2393007e-19 3.6200741e-05 9.9996376e-01], sum to 1.0000
[2019-03-26 12:49:55,846] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3060
[2019-03-26 12:49:55,853] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.6241021871604564, 1.0, 2.0, 0.6241021871604564, 1.0, 2.0, 1.03, 6.971748239342964, 6.9112, 170.5573041426782, 2618521.127108811, 2575147.96032254, 496883.3071814512], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5227200.0000, 
sim time next is 5227800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.7007404825675476, 1.0, 2.0, 0.6709602807980365, 1.0, 2.0, 1.03, 7.005097790542409, 6.9112, 170.5573041426782, 2815343.320675695, 2748080.513792253, 521562.807153426], 
processed observation next is [1.0, 0.5217391304347826, 0.7156398104265403, 0.67, 1.0, 1.0, 0.639446364539214, 1.0, 1.0, 0.6035666033711283, 1.0, 1.0, 1.0365853658536586, 0.009389779054240942, 0.0, 0.8375144448122397, 0.7820398112988042, 0.7633556982756259, 0.7784519509752627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6059598], dtype=float32), -0.043964848]. 
=============================================
[2019-03-26 12:49:56,621] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2662255e-18 1.0000000e+00 5.8043005e-21 1.2468473e-17 1.1365460e-09], sum to 1.0000
[2019-03-26 12:49:56,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1703
[2019-03-26 12:49:56,636] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.5154788208681398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 720308.896555987, 720308.896555987, 186056.4734848038], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5092200.0000, 
sim time next is 5092800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.5158080809492204, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 720769.1471415638, 720769.1471415644, 186109.5676506199], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.84, 1.0, 1.0, 0.4166362421074944, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20021365198376773, 0.2002136519837679, 0.2777754741054028], 
reward next is 0.7222, 
noisyNet noise sample is [array([0.21052791], dtype=float32), -1.2963922]. 
=============================================
[2019-03-26 12:49:58,027] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [4.4765973e-21 6.4987478e-27 1.6891417e-19 3.8891667e-05 9.9996114e-01], sum to 1.0000
[2019-03-26 12:49:58,034] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6770
[2019-03-26 12:49:58,040] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.21666666666667, 52.0, 1.0, 2.0, 0.4844137862272285, 1.0, 2.0, 0.4844137862272285, 1.0, 2.0, 0.8412665485896204, 6.9112, 6.9112, 170.5573041426782, 2031935.012569896, 2031935.012569896, 404536.4012164326], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5316600.0000, 
sim time next is 5317200.0000, 
raw observation next is [36.2, 52.0, 1.0, 2.0, 0.5306088834222425, 1.0, 2.0, 0.5306088834222425, 1.0, 2.0, 0.9214921554652717, 6.911200000000001, 6.9112, 170.5573041426782, 2225905.55829815, 2225905.558298149, 436959.499493291], 
processed observation next is [1.0, 0.5652173913043478, 0.9146919431279622, 0.52, 1.0, 1.0, 0.4344685342436657, 1.0, 1.0, 0.4344685342436657, 1.0, 1.0, 0.9042587261771606, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6183070995272639, 0.6183070995272637, 0.6521783574526732], 
reward next is 0.3478, 
noisyNet noise sample is [array([2.5073848], dtype=float32), 0.40740517]. 
=============================================
[2019-03-26 12:49:58,763] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.3763193e-19 1.0000000e+00 4.5404905e-22 2.5825421e-19 2.2864268e-11], sum to 1.0000
[2019-03-26 12:49:58,770] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4611
[2019-03-26 12:49:58,774] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 77.0, 1.0, 2.0, 0.5349609614399293, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 747542.0174871245, 747542.0174871251, 189254.9854873544], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5685600.0000, 
sim time next is 5686200.0000, 
raw observation next is [28.55, 78.5, 1.0, 2.0, 0.535332250997685, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 748061.0315799187, 748061.0315799187, 189317.072221138], 
processed observation next is [0.0, 0.8260869565217391, 0.552132701421801, 0.785, 1.0, 1.0, 0.4401593385514277, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20779473099442186, 0.20779473099442186, 0.28256279435990744], 
reward next is 0.7174, 
noisyNet noise sample is [array([-0.11155294], dtype=float32), 0.14749852]. 
=============================================
[2019-03-26 12:50:00,206] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4359146e-23 1.0000000e+00 1.1116613e-27 5.1259925e-28 1.2628688e-17], sum to 1.0000
[2019-03-26 12:50:00,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-26 12:50:00,220] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.16666666666666, 65.5, 1.0, 2.0, 0.5112979475508288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714464.7514776031, 714464.7514776024, 185385.2241250137], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5134200.0000, 
sim time next is 5134800.0000, 
raw observation next is [30.33333333333334, 65.0, 1.0, 2.0, 0.5125044579218224, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 716151.2431057073, 716151.2431057073, 185578.5904867777], 
processed observation next is [0.0, 0.43478260869565216, 0.6366508688783573, 0.65, 1.0, 1.0, 0.41265597339978605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1989309008626965, 0.1989309008626965, 0.27698297087578766], 
reward next is 0.7230, 
noisyNet noise sample is [array([-0.5598531], dtype=float32), 0.33414304]. 
=============================================
[2019-03-26 12:50:00,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.1157705e-18 1.0000000e+00 1.6585062e-21 1.5102277e-18 9.6484216e-11], sum to 1.0000
[2019-03-26 12:50:00,632] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1321
[2019-03-26 12:50:00,647] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.16666666666667, 78.16666666666667, 1.0, 2.0, 0.5220866714079402, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 729545.6058289391, 729545.6058289384, 187128.7836591793], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5169000.0000, 
sim time next is 5169600.0000, 
raw observation next is [28.0, 79.0, 1.0, 2.0, 0.5212672859450231, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 728400.2327483637, 728400.232748363, 186995.1039861079], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 1.0, 1.0, 0.42321359752412424, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2023333979856566, 0.20233339798565642, 0.27909717012851926], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.34809053], dtype=float32), 0.4624907]. 
=============================================
[2019-03-26 12:50:01,273] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-26 12:50:01,275] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:50:01,276] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:50:01,277] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:50:01,278] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:50:01,278] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:50:01,280] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:50:01,282] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:50:01,282] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:50:01,283] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:50:01,283] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:50:01,315] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run66
[2019-03-26 12:50:01,339] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run66
[2019-03-26 12:50:01,341] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run66
[2019-03-26 12:50:01,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run66
[2019-03-26 12:50:01,416] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run66
[2019-03-26 12:50:26,436] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:50:26,439] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.96666666666667, 86.5, 1.0, 2.0, 0.5186107144103944, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 774420.4541830311, 774420.4541830311, 192722.4818808179]
[2019-03-26 12:50:26,441] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:50:26,446] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.2822453e-20 1.0000000e+00 1.2088003e-23 4.7913251e-22 1.1989511e-13], sampled 0.9086785124983103
[2019-03-26 12:50:29,283] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:50:29,284] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.95, 94.16666666666667, 1.0, 2.0, 0.4026170375167441, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 601556.8578685768, 601556.8578685768, 174701.5770433865]
[2019-03-26 12:50:29,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:50:29,287] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3449430e-24 1.0000000e+00 7.6230028e-29 2.5286191e-30 2.1808733e-20], sampled 0.3449179965230138
[2019-03-26 12:50:40,344] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:50:40,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.68333333333333, 84.33333333333333, 1.0, 2.0, 0.4781264432704945, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 675777.747081234, 675777.747081234, 181227.4315805254]
[2019-03-26 12:50:40,347] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:50:40,352] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.5420232e-20 1.0000000e+00 8.4063030e-24 6.5240801e-22 1.3301818e-13], sampled 0.3247621576147418
[2019-03-26 12:50:58,328] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:50:58,329] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.4, 45.33333333333333, 1.0, 2.0, 0.5956734346296559, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 832413.4601081595, 832413.4601081595, 199942.5382464258]
[2019-03-26 12:50:58,332] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:50:58,334] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.0667192e-21 1.0000000e+00 1.1873654e-24 2.1830257e-23 2.3115710e-14], sampled 0.5860664392189086
[2019-03-26 12:51:03,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:51:03,501] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.43022303333333, 66.58049874833334, 1.0, 2.0, 0.7556790757609895, 1.0, 2.0, 0.6984295773947574, 1.0, 2.0, 1.03, 7.0045737604934, 6.9112, 171.5212843490159, 2930720.132317695, 2863454.665555528, 539705.165892466]
[2019-03-26 12:51:03,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:51:03,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.2698547e-20 1.3033675e-24 1.8451579e-18 4.8155054e-03 9.9518448e-01], sampled 0.722669187113906
[2019-03-26 12:51:10,221] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:51:10,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.2, 47.0, 1.0, 2.0, 0.4081998288722754, 1.0, 2.0, 0.4081998288722754, 1.0, 2.0, 0.708908109004909, 6.9112, 6.9112, 178.6582176852504, 1711928.501130984, 1711928.501130984, 359509.1789320894]
[2019-03-26 12:51:10,224] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:51:10,225] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6614775e-16 1.5302711e-13 1.2446408e-16 5.4850302e-06 9.9999452e-01], sampled 0.8464837004183107
[2019-03-26 12:51:31,194] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:51:31,194] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.6, 74.83333333333334, 1.0, 2.0, 0.4158604531135933, 1.0, 2.0, 0.4158604531135933, 1.0, 2.0, 0.720576906282031, 6.9112, 6.9112, 178.6582176852504, 1744080.961057619, 1744080.961057619, 363639.0338348543]
[2019-03-26 12:51:31,195] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:51:31,198] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [3.192170e-13 1.771122e-06 8.187135e-15 3.561139e-08 9.999982e-01], sampled 0.7089509200089051
[2019-03-26 12:51:38,136] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:51:38,138] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.03333333333334, 94.33333333333334, 1.0, 2.0, 0.2490817026454564, 1.0, 2.0, 0.2490817026454564, 1.0, 2.0, 0.4202000546202346, 6.9112, 6.9112, 170.5573041426782, 1044323.843275208, 1044323.843275208, 284129.9514974732]
[2019-03-26 12:51:38,140] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:51:38,145] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.1172447e-13 1.7359958e-04 4.1042422e-14 9.5867586e-07 9.9982542e-01], sampled 0.7899645073272114
[2019-03-26 12:51:50,415] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.4093023], dtype=float32), 0.13929535]
[2019-03-26 12:51:50,416] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.40963658666666, 85.44560100999999, 1.0, 2.0, 0.3234386978549755, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 507756.7010069485, 507756.701006948, 167531.0434768629]
[2019-03-26 12:51:50,420] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:51:50,422] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.9143864e-22 1.0000000e+00 1.9215133e-25 6.5689248e-24 1.7486659e-15], sampled 0.3951791232740183
[2019-03-26 12:51:56,586] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8217.7540 3180341809.7464 178.0000
[2019-03-26 12:51:56,799] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8133.2064 3019455091.0065 292.0000
[2019-03-26 12:51:56,828] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7431.5449 3353683937.0051 718.0000
[2019-03-26 12:51:56,861] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8669.8077 2899182712.0160 197.0000
[2019-03-26 12:51:56,886] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8537.1835 3066979864.4254 182.0000
[2019-03-26 12:51:57,903] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1625000, evaluation results [1625000.0, 7431.544891924599, 3353683937.005127, 718.0, 8537.183476997581, 3066979864.425387, 182.0, 8669.807720587005, 2899182712.0159693, 197.0, 8217.754030725493, 3180341809.746412, 178.0, 8133.206355120498, 3019455091.006528, 292.0]
[2019-03-26 12:52:02,960] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.6907379e-19 1.0000000e+00 2.3034690e-21 3.3740293e-20 1.0326000e-11], sum to 1.0000
[2019-03-26 12:52:02,968] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0835
[2019-03-26 12:52:02,974] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.73333333333333, 59.16666666666667, 1.0, 2.0, 0.5643201405193947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 788583.0810784464, 788583.0810784464, 194286.3640795134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5760600.0000, 
sim time next is 5761200.0000, 
raw observation next is [32.56666666666666, 60.33333333333334, 1.0, 2.0, 0.5521515385808276, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 771572.4550705901, 771572.4550705901, 192170.8571111246], 
processed observation next is [0.0, 0.6956521739130435, 0.7424960505529224, 0.6033333333333334, 1.0, 1.0, 0.46042354045882833, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.21432568196405283, 0.21432568196405283, 0.2868221747927233], 
reward next is 0.7132, 
noisyNet noise sample is [array([-0.76872647], dtype=float32), -0.8902746]. 
=============================================
[2019-03-26 12:52:06,224] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5384990e-17 9.3583127e-14 1.9761399e-16 2.6601922e-06 9.9999738e-01], sum to 1.0000
[2019-03-26 12:52:06,235] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2389
[2019-03-26 12:52:06,239] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.6, 87.5, 1.0, 2.0, 0.3348922480951097, 1.0, 2.0, 0.3348922480951097, 1.0, 2.0, 0.5815970843823927, 6.9112, 6.9112, 170.5573041426782, 1404337.005989474, 1404337.005989474, 319776.8214200641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5283000.0000, 
sim time next is 5283600.0000, 
raw observation next is [28.6, 87.66666666666667, 1.0, 2.0, 0.3453070015601372, 1.0, 2.0, 0.3453070015601372, 1.0, 2.0, 0.599684066939544, 6.9112, 6.9112, 170.5573041426782, 1448039.728188294, 1448039.728188294, 324679.7925501419], 
processed observation next is [1.0, 0.13043478260869565, 0.5545023696682465, 0.8766666666666667, 1.0, 1.0, 0.2112132548917316, 1.0, 1.0, 0.2112132548917316, 1.0, 1.0, 0.5118098377311512, 0.0, 0.0, 0.8375144448122397, 0.4022332578300817, 0.4022332578300817, 0.4845967052987193], 
reward next is 0.5154, 
noisyNet noise sample is [array([0.1842054], dtype=float32), 0.13679086]. 
=============================================
[2019-03-26 12:52:08,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.7361923e-23 1.0000000e+00 3.5467353e-26 7.8518272e-28 5.0668589e-18], sum to 1.0000
[2019-03-26 12:52:08,351] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1688
[2019-03-26 12:52:08,358] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.96666666666667, 79.16666666666667, 1.0, 2.0, 0.5203001505872328, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 727048.329947903, 727048.3299479038, 186837.6735789017], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5728200.0000, 
sim time next is 5728800.0000, 
raw observation next is [28.13333333333333, 78.33333333333334, 1.0, 2.0, 0.5211864883841889, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728287.2904269149, 728287.2904269149, 186982.0259376628], 
processed observation next is [0.0, 0.30434782608695654, 0.532385466034755, 0.7833333333333334, 1.0, 1.0, 0.42311625106528783, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20230202511858747, 0.20230202511858747, 0.2790776506532281], 
reward next is 0.7209, 
noisyNet noise sample is [array([-1.45712], dtype=float32), 1.3387297]. 
=============================================
[2019-03-26 12:52:09,025] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.7690313e-26 0.0000000e+00 7.4189869e-23 2.5259127e-04 9.9974746e-01], sum to 1.0000
[2019-03-26 12:52:09,028] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-26 12:52:09,039] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.91666666666666, 53.83333333333333, 1.0, 2.0, 0.8268464870673417, 1.0, 2.0, 0.7340132830479336, 1.0, 2.0, 1.03, 7.005107736015884, 6.9112, 170.5573041426782, 3080239.371101705, 3012969.439871057, 564387.3193849965], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5331000.0000, 
sim time next is 5331600.0000, 
raw observation next is [35.9, 54.0, 1.0, 2.0, 0.8288515770943371, 1.0, 2.0, 0.7350158280614312, 1.0, 2.0, 1.03, 7.005107894183323, 6.9112, 170.5573041426782, 3084451.681637937, 3017181.637105519, 565116.0755495914], 
processed observation next is [1.0, 0.7391304347826086, 0.9004739336492891, 0.54, 1.0, 1.0, 0.7937970808365508, 1.0, 1.0, 0.6807419615197966, 1.0, 1.0, 1.0365853658536586, 0.009390789418332268, 0.0, 0.8375144448122397, 0.8567921337883159, 0.8381060103070886, 0.8434568291784947], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9006381], dtype=float32), -0.14082992]. 
=============================================
[2019-03-26 12:52:10,722] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0058156e-14 6.6175030e-09 3.0345565e-15 7.3955114e-08 9.9999988e-01], sum to 1.0000
[2019-03-26 12:52:10,731] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3456
[2019-03-26 12:52:10,735] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.68333333333333, 95.16666666666667, 1.0, 2.0, 0.2316149730274731, 1.0, 2.0, 0.2316149730274731, 1.0, 2.0, 0.394822090479194, 6.9112, 6.9112, 170.5573041426782, 971057.9979664729, 971057.9979664729, 278776.4711447764], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5890200.0000, 
sim time next is 5890800.0000, 
raw observation next is [25.66666666666667, 95.33333333333334, 1.0, 2.0, 0.2177162103020549, 1.0, 2.0, 0.2177162103020549, 1.0, 2.0, 0.3709589347153933, 6.911199999999999, 6.9112, 170.5573041426782, 912761.9026038015, 912761.9026038022, 274519.9708125311], 
processed observation next is [1.0, 0.17391304347826086, 0.4154818325434442, 0.9533333333333335, 1.0, 1.0, 0.057489410002475774, 1.0, 1.0, 0.057489410002475774, 1.0, 1.0, 0.23287674965291866, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2535449729455004, 0.2535449729455006, 0.4097312997201956], 
reward next is 0.5903, 
noisyNet noise sample is [array([0.6983192], dtype=float32), 0.10459612]. 
=============================================
[2019-03-26 12:52:16,988] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.3627205e-23 2.5926602e-34 4.0598208e-22 1.1153802e-05 9.9998879e-01], sum to 1.0000
[2019-03-26 12:52:17,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4627
[2019-03-26 12:52:17,003] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.2, 53.0, 1.0, 2.0, 0.6586492345452287, 1.0, 2.0, 0.6499146567868769, 1.0, 2.0, 1.03, 7.005094471913149, 6.9112, 170.5573041426782, 2726939.68944835, 2659679.25983404, 508586.5850176261], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5489400.0000, 
sim time next is 5490000.0000, 
raw observation next is [36.3, 52.0, 1.0, 2.0, 0.6046853341030052, 1.0, 2.0, 0.6046853341030052, 1.0, 2.0, 1.03, 6.933838848226518, 6.9112, 170.5573041426782, 2536971.887995319, 2520754.760121196, 489684.6244358573], 
processed observation next is [1.0, 0.5652173913043478, 0.9194312796208529, 0.52, 1.0, 1.0, 0.5237172700036207, 1.0, 1.0, 0.5237172700036207, 1.0, 1.0, 1.0365853658536586, 0.002263884822651807, 0.0, 0.8375144448122397, 0.704714413332033, 0.7002096555892211, 0.7308725737848616], 
reward next is 0.1559, 
noisyNet noise sample is [array([-0.4830919], dtype=float32), -0.34020212]. 
=============================================
[2019-03-26 12:52:17,020] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[31.533157]
 [31.342915]
 [30.879211]
 [30.32753 ]
 [29.916235]], R is [[32.49216461]
 [32.16724396]
 [31.84557152]
 [31.52711678]
 [31.2118454 ]].
[2019-03-26 12:52:18,449] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7078718e-17 2.9740250e-15 8.4993913e-17 1.0616311e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:18,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4176
[2019-03-26 12:52:18,465] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.86666666666667, 66.5, 1.0, 2.0, 0.1864119635585564, 1.0, 2.0, 0.1864119635585564, 1.0, 2.0, 0.3237359333228366, 6.9112, 6.9112, 170.5573041426782, 781472.9461606705, 781472.9461606705, 266211.3460635582], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5511000.0000, 
sim time next is 5511600.0000, 
raw observation next is [31.6, 68.0, 1.0, 2.0, 0.18797580493534, 1.0, 2.0, 0.18797580493534, 1.0, 2.0, 0.3264518086240635, 6.9112, 6.9112, 170.5573041426782, 788031.2628469134, 788031.2628469134, 266616.2831299768], 
processed observation next is [1.0, 0.8260869565217391, 0.6966824644549764, 0.68, 1.0, 1.0, 0.021657596307638537, 1.0, 1.0, 0.021657596307638537, 1.0, 1.0, 0.17859976661471155, 0.0, 0.0, 0.8375144448122397, 0.2188975730130315, 0.2188975730130315, 0.3979347509402638], 
reward next is 0.6021, 
noisyNet noise sample is [array([-0.61299336], dtype=float32), -0.7572168]. 
=============================================
[2019-03-26 12:52:20,799] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.7415330e-24 1.0000000e+00 2.0632116e-27 2.3503903e-27 1.3763172e-17], sum to 1.0000
[2019-03-26 12:52:20,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1244
[2019-03-26 12:52:20,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [33.2, 53.0, 1.0, 2.0, 0.5179315487928451, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723737.4052203717, 723737.4052203717, 186453.8137669691], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5754000.0000, 
sim time next is 5754600.0000, 
raw observation next is [33.4, 53.0, 1.0, 2.0, 0.5210283406326912, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 728066.2247017447, 728066.2247017447, 186957.1641838482], 
processed observation next is [0.0, 0.6086956521739131, 0.7819905213270142, 0.53, 1.0, 1.0, 0.422925711605652, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20224061797270687, 0.20224061797270687, 0.27904054355798236], 
reward next is 0.7210, 
noisyNet noise sample is [array([0.89856684], dtype=float32), 0.32199487]. 
=============================================
[2019-03-26 12:52:21,227] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.0345921e-16 4.2902307e-08 6.7343017e-17 7.8195166e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:21,239] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4018
[2019-03-26 12:52:21,244] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.2, 86.0, 1.0, 2.0, 0.1754504134568004, 1.0, 2.0, 0.1754504134568004, 1.0, 2.0, 0.2996485417545737, 6.9112, 6.9112, 170.5573041426782, 735504.3730885164, 735504.3730885164, 263261.8736641163], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6120600.0000, 
sim time next is 6121200.0000, 
raw observation next is [27.2, 86.0, 1.0, 2.0, 0.1753674921100017, 1.0, 2.0, 0.1753674921100017, 1.0, 2.0, 0.2995053415762297, 6.9112, 6.9112, 170.5573041426782, 735156.6399984151, 735156.6399984151, 263242.0042389627], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 1.0, 1.0, 0.006466857963857441, 1.0, 1.0, 0.006466857963857441, 1.0, 1.0, 0.14573822143442647, 0.0, 0.0, 0.8375144448122397, 0.20421017777733755, 0.20421017777733755, 0.3928985137894966], 
reward next is 0.6071, 
noisyNet noise sample is [array([-0.2596604], dtype=float32), 0.7379985]. 
=============================================
[2019-03-26 12:52:25,368] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.7183915e-17 1.8426482e-12 4.9686862e-18 2.9208937e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:25,379] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2635
[2019-03-26 12:52:25,385] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 91.0, 1.0, 2.0, 0.1752430659930067, 1.0, 2.0, 0.1752430659930067, 1.0, 2.0, 0.2984889939564111, 6.911200000000001, 6.9112, 170.5573041426782, 734634.8556535572, 734634.8556535565, 263177.113089161], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5616000.0000, 
sim time next is 5616600.0000, 
raw observation next is [26.25, 91.16666666666667, 1.0, 2.0, 0.1748384996813053, 1.0, 2.0, 0.1748384996813053, 1.0, 2.0, 0.2976797433470191, 6.9112, 6.9112, 170.5573041426782, 732938.2974493527, 732938.2974493527, 263075.6545575362], 
processed observation next is [0.0, 0.0, 0.4431279620853081, 0.9116666666666667, 1.0, 1.0, 0.005829517688319622, 1.0, 1.0, 0.005829517688319622, 1.0, 1.0, 0.14351188213051105, 0.0, 0.0, 0.8375144448122397, 0.2035939715137091, 0.2035939715137091, 0.39265023068288984], 
reward next is 0.6073, 
noisyNet noise sample is [array([-0.69878733], dtype=float32), -1.1977614]. 
=============================================
[2019-03-26 12:52:30,897] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [7.7308898e-21 1.0000000e+00 8.4125586e-24 2.8585968e-23 3.0520321e-13], sum to 1.0000
[2019-03-26 12:52:30,907] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2171
[2019-03-26 12:52:30,911] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 89.0, 1.0, 2.0, 0.5111576241807001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 714268.6039890058, 714268.6039890052, 185362.4687883704], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5713200.0000, 
sim time next is 5713800.0000, 
raw observation next is [26.15, 89.16666666666667, 1.0, 2.0, 0.5113257757610636, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 714503.6504446712, 714503.6504446717, 185389.3033097809], 
processed observation next is [0.0, 0.13043478260869565, 0.43838862559241704, 0.8916666666666667, 1.0, 1.0, 0.41123587441092, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19847323623463087, 0.19847323623463103, 0.2767004527011655], 
reward next is 0.7233, 
noisyNet noise sample is [array([0.32330528], dtype=float32), -0.74132526]. 
=============================================
[2019-03-26 12:52:33,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.7050308e-24 1.0000000e+00 2.3651306e-28 1.9120979e-30 1.8463206e-20], sum to 1.0000
[2019-03-26 12:52:33,345] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9606
[2019-03-26 12:52:33,353] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.5, 83.0, 1.0, 2.0, 0.5236461484442319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 731725.5149117386, 731725.5149117386, 187383.8234797242], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6330600.0000, 
sim time next is 6331200.0000, 
raw observation next is [27.6, 82.33333333333334, 1.0, 2.0, 0.5241016559454967, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 732362.2451954585, 732362.245195458, 187458.3822954582], 
processed observation next is [0.0, 0.2608695652173913, 0.5071090047393366, 0.8233333333333335, 1.0, 1.0, 0.4266285011391527, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20343395699873848, 0.2034339569987383, 0.2797886302917287], 
reward next is 0.7202, 
noisyNet noise sample is [array([1.3796426], dtype=float32), 0.78319585]. 
=============================================
[2019-03-26 12:52:34,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.5209415e-17 1.0443034e-15 2.2727755e-17 1.7271914e-07 9.9999988e-01], sum to 1.0000
[2019-03-26 12:52:34,270] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0984
[2019-03-26 12:52:34,273] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.55, 91.0, 1.0, 2.0, 0.176619533482117, 1.0, 2.0, 0.176619533482117, 1.0, 2.0, 0.3019781685862328, 6.9112, 6.9112, 170.5573041426782, 740407.1240670092, 740407.1240670092, 263556.6341669608], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5967000.0000, 
sim time next is 5967600.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.1760021232045, 1.0, 2.0, 0.1760021232045, 1.0, 2.0, 0.3006941154978196, 6.911200000000001, 6.9112, 170.5573041426782, 737817.9869023944, 737817.9869023937, 263398.3577044976], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.91, 1.0, 1.0, 0.0072314737403614444, 1.0, 1.0, 0.0072314737403614444, 1.0, 1.0, 0.14718794572904828, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.20494944080622068, 0.2049494408062205, 0.39313187717089193], 
reward next is 0.6069, 
noisyNet noise sample is [array([0.7574231], dtype=float32), 0.6076373]. 
=============================================
[2019-03-26 12:52:35,686] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [8.0083127e-21 3.2473386e-27 3.1238892e-19 3.0692136e-06 9.9999690e-01], sum to 1.0000
[2019-03-26 12:52:35,696] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8502
[2019-03-26 12:52:35,702] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.55, 72.0, 1.0, 2.0, 0.5431539199639919, 1.0, 2.0, 0.5431539199639919, 1.0, 2.0, 0.9432787352313101, 6.9112, 6.9112, 170.5573041426782, 2278579.991642016, 2278579.991642016, 446270.6154664505], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5823000.0000, 
sim time next is 5823600.0000, 
raw observation next is [30.7, 71.33333333333333, 1.0, 2.0, 0.5725245906491258, 1.0, 2.0, 0.5725245906491258, 1.0, 2.0, 0.9942858771821682, 6.911199999999999, 6.9112, 170.5573041426782, 2401911.029891308, 2401911.029891308, 468920.3908519108], 
processed observation next is [1.0, 0.391304347826087, 0.6540284360189573, 0.7133333333333333, 1.0, 1.0, 0.48496938632424785, 1.0, 1.0, 0.48496938632424785, 1.0, 1.0, 0.9930315575392293, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6671975083031411, 0.6671975083031411, 0.6998811803759862], 
reward next is 0.3001, 
noisyNet noise sample is [array([0.5471405], dtype=float32), -0.5012791]. 
=============================================
[2019-03-26 12:52:49,745] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0247218e-16 2.4451524e-12 2.6999253e-17 2.0131230e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:49,754] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5301
[2019-03-26 12:52:49,759] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333334, 86.33333333333334, 1.0, 2.0, 0.1798671171004468, 1.0, 2.0, 0.1798671171004468, 1.0, 2.0, 0.3089883832697999, 6.911199999999999, 6.9112, 170.5573041426782, 754026.1117618877, 754026.1117618883, 264410.4503032511], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6037800.0000, 
sim time next is 6038400.0000, 
raw observation next is [27.46666666666667, 86.66666666666667, 1.0, 2.0, 0.1800850151009715, 1.0, 2.0, 0.1800850151009715, 1.0, 2.0, 0.3092828341479678, 6.911199999999999, 6.9112, 170.5573041426782, 754939.889709188, 754939.8897091886, 264460.6255876732], 
processed observation next is [1.0, 0.9130434782608695, 0.500789889415482, 0.8666666666666667, 1.0, 1.0, 0.012150620603580102, 1.0, 1.0, 0.012150620603580102, 1.0, 1.0, 0.15766199286337537, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2097055249192189, 0.20970552491921907, 0.3947173516233929], 
reward next is 0.6053, 
noisyNet noise sample is [array([0.7654057], dtype=float32), -1.4841696]. 
=============================================
[2019-03-26 12:52:50,408] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.9471317e-17 4.3054343e-13 2.4573255e-17 1.8343053e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:50,415] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0755
[2019-03-26 12:52:50,419] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.15, 93.0, 1.0, 2.0, 0.2295965465374422, 1.0, 2.0, 0.2295965465374422, 1.0, 2.0, 0.3922866521238256, 6.9112, 6.9112, 170.5573041426782, 962591.8402706616, 962591.8402706616, 278206.7350068833], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6060600.0000, 
sim time next is 6061200.0000, 
raw observation next is [26.13333333333333, 93.0, 1.0, 2.0, 0.2211429362569586, 1.0, 2.0, 0.2211429362569586, 1.0, 2.0, 0.3776927796487302, 6.9112, 6.9112, 170.5573041426782, 927134.4518713921, 927134.4518713921, 275600.8337690248], 
processed observation next is [1.0, 0.13043478260869565, 0.43759873617693507, 0.93, 1.0, 1.0, 0.061617995490311564, 1.0, 1.0, 0.061617995490311564, 1.0, 1.0, 0.24108875566918317, 0.0, 0.0, 0.8375144448122397, 0.25753734774205334, 0.25753734774205334, 0.4113445280134699], 
reward next is 0.5887, 
noisyNet noise sample is [array([0.53088874], dtype=float32), 0.7981863]. 
=============================================
[2019-03-26 12:52:50,603] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1006151e-21 1.0000000e+00 4.9137027e-26 1.1055305e-25 1.0213199e-14], sum to 1.0000
[2019-03-26 12:52:50,614] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7715
[2019-03-26 12:52:50,620] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.78333333333333, 64.5, 1.0, 2.0, 0.5249184820566064, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 733504.0449582271, 733504.0449582271, 187592.5416832907], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6267000.0000, 
sim time next is 6267600.0000, 
raw observation next is [30.8, 64.0, 1.0, 2.0, 0.5226111962812262, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 730278.8104418882, 730278.8104418882, 187214.7367163221], 
processed observation next is [0.0, 0.5652173913043478, 0.6587677725118484, 0.64, 1.0, 1.0, 0.42483276660388697, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2028552251227467, 0.2028552251227467, 0.27942498017361506], 
reward next is 0.7206, 
noisyNet noise sample is [array([-0.28181654], dtype=float32), -0.08071112]. 
=============================================
[2019-03-26 12:52:51,462] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9987793e-16 1.3713819e-11 1.6051305e-16 8.0220239e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:52:51,471] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7292
[2019-03-26 12:52:51,478] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.56666666666667, 91.66666666666667, 1.0, 2.0, 0.2822816759063571, 1.0, 2.0, 0.2822816759063571, 1.0, 2.0, 0.4844668531640692, 6.9112, 6.9112, 170.5573041426782, 1183598.066068587, 1183598.066068587, 296782.7793787877], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6153000.0000, 
sim time next is 6153600.0000, 
raw observation next is [26.63333333333333, 91.33333333333334, 1.0, 2.0, 0.2460302133246267, 1.0, 2.0, 0.2460302133246267, 1.0, 2.0, 0.4222086310229913, 6.9112, 6.9112, 170.5573041426782, 1031523.722532009, 1031523.722532009, 283673.0037960323], 
processed observation next is [1.0, 0.21739130434782608, 0.46129541864139006, 0.9133333333333334, 1.0, 1.0, 0.09160266665617675, 1.0, 1.0, 0.09160266665617675, 1.0, 1.0, 0.2953763792963308, 0.0, 0.0, 0.8375144448122397, 0.2865343673700025, 0.2865343673700025, 0.42339254297915263], 
reward next is 0.5766, 
noisyNet noise sample is [array([-0.8916316], dtype=float32), 0.0044413325]. 
=============================================
[2019-03-26 12:52:52,804] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-26 12:52:52,805] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:52:52,806] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:52:52,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:52:52,807] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:52:52,807] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:52:52,808] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:52:52,808] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:52:52,809] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:52:52,808] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:52:52,811] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:52:52,837] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run67
[2019-03-26 12:52:52,862] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run67
[2019-03-26 12:52:52,864] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run67
[2019-03-26 12:52:52,882] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run67
[2019-03-26 12:52:52,883] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run67
[2019-03-26 12:52:57,726] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:52:57,727] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.73333333333333, 76.0, 1.0, 2.0, 0.3183657612174788, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 499433.5896106908, 499433.5896106908, 166890.3113152916]
[2019-03-26 12:52:57,730] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:52:57,734] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.9233363e-23 1.0000000e+00 5.4915705e-27 3.4290990e-27 4.8461892e-17], sampled 0.6855146330072088
[2019-03-26 12:52:58,587] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:52:58,589] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.25583379, 81.77195949666668, 1.0, 2.0, 0.2736027390594802, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 444829.3098323515, 444829.3098323515, 163224.0608409675]
[2019-03-26 12:52:58,590] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:52:58,592] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.6300498e-21 1.0000000e+00 1.1618750e-24 5.1809320e-23 1.7421028e-13], sampled 0.8992092730833957
[2019-03-26 12:53:42,730] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:53:42,731] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.05, 82.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2839897365662406, 6.9112, 6.9112, 169.0403247858759, 704253.4220116851, 704253.4220116851, 260312.3578719513]
[2019-03-26 12:53:42,732] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:53:42,734] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.9520074e-13 8.7324753e-03 6.2385289e-16 1.4925760e-09 9.9126750e-01], sampled 0.28112271823712287
[2019-03-26 12:54:07,369] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:54:07,370] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.49585140333334, 60.7692547, 1.0, 2.0, 0.5411052041541218, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 756130.8953727059, 756130.8953727059, 190285.8459382234]
[2019-03-26 12:54:07,371] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:54:07,374] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.07052765e-20 1.00000000e+00 1.02056355e-23 2.09145896e-22
 2.86460569e-12], sampled 0.9409505440408559
[2019-03-26 12:54:20,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:54:20,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.65, 77.5, 1.0, 2.0, 0.5986011261877667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 836506.3227321841, 836506.3227321841, 200480.7955935299]
[2019-03-26 12:54:20,290] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:54:20,293] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.2660988e-19 1.0000000e+00 3.6922499e-23 6.8420532e-23 7.3630121e-12], sampled 0.03421349294441345
[2019-03-26 12:54:27,653] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:54:27,655] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.28333333333333, 59.0, 1.0, 2.0, 0.4178085445984059, 1.0, 2.0, 0.4178085445984059, 1.0, 2.0, 0.7212288603141966, 6.9112, 6.9112, 169.0403247858759, 1752335.276489011, 1752335.276489011, 362028.1985086453]
[2019-03-26 12:54:27,655] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:54:27,658] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [4.9660354e-17 6.1579338e-15 5.5158231e-18 1.3636613e-07 9.9999988e-01], sampled 0.09754803996075201
[2019-03-26 12:54:34,807] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.409737], dtype=float32), 0.14064291]
[2019-03-26 12:54:34,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.493954055, 80.08180849499999, 1.0, 2.0, 0.4312725794512283, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 631317.2208347127, 631317.2208347127, 177189.5745336845]
[2019-03-26 12:54:34,811] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:54:34,813] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.7892303e-18 1.0000000e+00 1.2661560e-21 2.4301308e-19 5.6847760e-10], sampled 0.1697521672874548
[2019-03-26 12:54:47,326] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 8494.2207 3073510052.7152 180.0000
[2019-03-26 12:54:47,791] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 8364.5480 2971662427.6577 230.0000
[2019-03-26 12:54:47,833] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 8342.0882 3125744850.4017 136.0000
[2019-03-26 12:54:47,968] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8683.8567 2899555169.2357 162.0000
[2019-03-26 12:54:48,013] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 8065.3912 3219670402.9454 693.0000
[2019-03-26 12:54:49,028] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1650000, evaluation results [1650000.0, 8065.391237357785, 3219670402.9453526, 693.0, 8494.220696251576, 3073510052.7151504, 180.0, 8683.856652510534, 2899555169.2357492, 162.0, 8342.088201993896, 3125744850.4016685, 136.0, 8364.548011662677, 2971662427.6577163, 230.0]
[2019-03-26 12:54:49,961] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.4014222e-20 1.0000000e+00 4.2996327e-24 1.8605298e-22 5.6491628e-13], sum to 1.0000
[2019-03-26 12:54:49,969] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9937
[2019-03-26 12:54:49,974] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.7, 62.0, 1.0, 2.0, 0.5055397170101268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 706415.7837007756, 706415.783700775, 184468.7126058145], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6274800.0000, 
sim time next is 6275400.0000, 
raw observation next is [30.68333333333333, 62.16666666666667, 1.0, 2.0, 0.5065657792210737, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 707850.029151847, 707850.0291518463, 184631.288402571], 
processed observation next is [0.0, 0.6521739130434783, 0.6532385466034754, 0.6216666666666667, 1.0, 1.0, 0.4055009388205707, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19662500809773528, 0.1966250080977351, 0.2755690871680164], 
reward next is 0.7244, 
noisyNet noise sample is [array([-0.36717817], dtype=float32), -0.78691906]. 
=============================================
[2019-03-26 12:54:50,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.5935501e-19 1.0000000e+00 2.3686953e-22 4.0397692e-21 2.1935738e-11], sum to 1.0000
[2019-03-26 12:54:50,440] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9843
[2019-03-26 12:54:50,443] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.4, 63.0, 1.0, 2.0, 0.5024094626308534, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 702040.278220611, 702040.278220611, 183974.5543643206], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6282000.0000, 
sim time next is 6282600.0000, 
raw observation next is [30.25, 64.0, 1.0, 2.0, 0.5027214741685746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 702476.4107185948, 702476.4107185954, 184023.7529082939], 
processed observation next is [0.0, 0.7391304347826086, 0.6327014218009479, 0.64, 1.0, 1.0, 0.4008692459862344, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19513233631072077, 0.19513233631072094, 0.27466231777357303], 
reward next is 0.7253, 
noisyNet noise sample is [array([-0.05986676], dtype=float32), 0.8178062]. 
=============================================
[2019-03-26 12:54:52,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.6514146e-21 1.0000000e+00 2.8328446e-25 4.2083899e-23 3.5337130e-13], sum to 1.0000
[2019-03-26 12:54:52,709] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3682
[2019-03-26 12:54:52,717] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.95, 67.5, 1.0, 2.0, 0.5192269032085003, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 725548.1012805, 725548.1012805, 186663.2580894719], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6366600.0000, 
sim time next is 6367200.0000, 
raw observation next is [29.6, 69.0, 1.0, 2.0, 0.5174312777073655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 723038.1079451895, 723038.1079451895, 186372.1032476231], 
processed observation next is [0.0, 0.6956521739130435, 0.6018957345971565, 0.69, 1.0, 1.0, 0.41859190085224757, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.20084391887366373, 0.20084391887366373, 0.2781673182800345], 
reward next is 0.7218, 
noisyNet noise sample is [array([-1.1620384], dtype=float32), -0.48361993]. 
=============================================
[2019-03-26 12:55:02,535] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.2266864e-18 2.1241203e-19 3.3548808e-18 9.0444524e-07 9.9999905e-01], sum to 1.0000
[2019-03-26 12:55:02,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9760
[2019-03-26 12:55:02,551] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.7, 90.0, 1.0, 2.0, 0.1770736201360504, 1.0, 2.0, 0.1770736201360504, 1.0, 2.0, 0.3027298604362114, 6.9112, 6.9112, 170.5573041426782, 742311.3604183701, 742311.3604183701, 263665.0000241086], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6483600.0000, 
sim time next is 6484200.0000, 
raw observation next is [26.65, 90.16666666666667, 1.0, 2.0, 0.1768327899545158, 1.0, 2.0, 0.1768327899545158, 1.0, 2.0, 0.302232653712104, 6.9112, 6.9112, 170.5573041426782, 741301.4259193097, 741301.4259193097, 263603.1741858661], 
processed observation next is [1.0, 0.043478260869565216, 0.462085308056872, 0.9016666666666667, 1.0, 1.0, 0.008232277053633467, 1.0, 1.0, 0.008232277053633467, 1.0, 1.0, 0.14906421184402927, 0.0, 0.0, 0.8375144448122397, 0.2059170627553638, 0.2059170627553638, 0.3934375734117404], 
reward next is 0.6066, 
noisyNet noise sample is [array([1.1370558], dtype=float32), -0.8132922]. 
=============================================
[2019-03-26 12:55:09,030] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5419054e-20 5.9458523e-26 8.9986332e-19 9.6520424e-08 9.9999988e-01], sum to 1.0000
[2019-03-26 12:55:09,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2059
[2019-03-26 12:55:09,045] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.61666666666667, 76.33333333333334, 1.0, 2.0, 0.4465645643101289, 1.0, 2.0, 0.4465645643101289, 1.0, 2.0, 0.7667651901242785, 6.911199999999999, 6.9112, 170.5573041426782, 1873032.874106433, 1873032.874106434, 378762.3659079265], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6426600.0000, 
sim time next is 6427200.0000, 
raw observation next is [28.73333333333333, 75.66666666666667, 1.0, 2.0, 0.4438035747971345, 1.0, 2.0, 0.4438035747971345, 1.0, 2.0, 0.7619297496584104, 6.9112, 6.9112, 170.5573041426782, 1861442.352300816, 1861442.352300816, 377065.1399669857], 
processed observation next is [1.0, 0.391304347826087, 0.560821484992101, 0.7566666666666667, 1.0, 1.0, 0.32988382505678854, 1.0, 1.0, 0.32988382505678854, 1.0, 1.0, 0.7096704264126955, 0.0, 0.0, 0.8375144448122397, 0.51706732008356, 0.51706732008356, 0.562783790995501], 
reward next is 0.4372, 
noisyNet noise sample is [array([1.5132009], dtype=float32), -0.2801506]. 
=============================================
[2019-03-26 12:55:10,154] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.4569956e-23 8.5722203e-32 2.7370094e-21 1.2681313e-06 9.9999869e-01], sum to 1.0000
[2019-03-26 12:55:10,162] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3410
[2019-03-26 12:55:10,167] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.51666666666667, 57.5, 1.0, 2.0, 0.4874771393881191, 1.0, 2.0, 0.4874771393881191, 1.0, 2.0, 0.8306674278317507, 6.9112, 6.9112, 170.5573041426782, 2044796.898946655, 2044796.898946655, 403767.44467527], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6533400.0000, 
sim time next is 6534000.0000, 
raw observation next is [31.4, 58.0, 1.0, 2.0, 0.5162897697164407, 1.0, 2.0, 0.5162897697164407, 1.0, 2.0, 0.8800971850210941, 6.9112, 6.9112, 170.5573041426782, 2165778.029596575, 2165778.029596575, 423465.3844454998], 
processed observation next is [1.0, 0.6521739130434783, 0.6872037914691943, 0.58, 1.0, 1.0, 0.41721659001980804, 1.0, 1.0, 0.41721659001980804, 1.0, 1.0, 0.8537770549037733, 0.0, 0.0, 0.8375144448122397, 0.6016050082212708, 0.6016050082212708, 0.6320378872320893], 
reward next is 0.3680, 
noisyNet noise sample is [array([0.20655337], dtype=float32), -0.9192842]. 
=============================================
[2019-03-26 12:55:10,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[32.896225]
 [33.26688 ]
 [34.020218]
 [33.17853 ]
 [31.486015]], R is [[32.21020126]
 [32.28546143]
 [32.36953735]
 [32.48921967]
 [32.59059906]].
[2019-03-26 12:55:15,737] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.08710306e-20 2.43008494e-26 1.52575739e-19 6.28334984e-09
 1.00000000e+00], sum to 1.0000
[2019-03-26 12:55:15,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5563
[2019-03-26 12:55:15,750] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.6, 66.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2577351030290082, 6.9112, 6.9112, 170.5573041426782, 640733.2272126571, 640733.2272126571, 251199.9924416204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6543000.0000, 
sim time next is 6543600.0000, 
raw observation next is [29.5, 66.33333333333333, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2619296620965751, 6.911200000000001, 6.9112, 170.5573041426782, 651508.7649585941, 651508.7649585934, 252772.2608240676], 
processed observation next is [1.0, 0.7391304347826086, 0.5971563981042655, 0.6633333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.09991422206899402, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.18097465693294282, 0.18097465693294262, 0.3772720310806979], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9374578], dtype=float32), -0.6968546]. 
=============================================
[2019-03-26 12:55:16,483] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3559508e-18 1.8821060e-18 1.0657361e-18 8.7266461e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:16,495] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-26 12:55:16,504] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 67.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2382956452992531, 6.911200000000001, 6.9112, 170.5573041426782, 607231.4199117952, 607231.4199117945, 246179.1749162905], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6724200.0000, 
sim time next is 6724800.0000, 
raw observation next is [27.2, 67.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2364818351901529, 6.911199999999999, 6.9112, 170.5573041426782, 603497.5630489677, 603497.5630489683, 245623.4683601775], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.67, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.06888028681725963, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1676382119580466, 0.16763821195804676, 0.36660219158235446], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.2269788], dtype=float32), 1.5282549]. 
=============================================
[2019-03-26 12:55:17,153] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.6372947e-22 3.6045716e-30 3.2336862e-20 7.7279174e-07 9.9999928e-01], sum to 1.0000
[2019-03-26 12:55:17,162] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8549
[2019-03-26 12:55:17,169] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.73333333333333, 75.66666666666666, 1.0, 2.0, 0.4627190027712102, 1.0, 2.0, 0.4627190027712102, 1.0, 2.0, 0.7943373374759555, 6.9112, 6.9112, 170.5573041426782, 1940851.063585405, 1940851.063585405, 388784.6967414182], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6601200.0000, 
sim time next is 6601800.0000, 
raw observation next is [28.91666666666667, 74.83333333333334, 1.0, 2.0, 0.4737975792538621, 1.0, 2.0, 0.4737975792538621, 1.0, 2.0, 0.8141819773189111, 6.911199999999999, 6.9112, 170.5573041426782, 1987362.68267522, 1987362.682675221, 396023.7117531218], 
processed observation next is [1.0, 0.391304347826087, 0.5695102685624015, 0.7483333333333334, 1.0, 1.0, 0.36602117982393023, 1.0, 1.0, 0.36602117982393023, 1.0, 1.0, 0.7733926552669645, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5520451896320056, 0.5520451896320059, 0.5910801667957042], 
reward next is 0.4089, 
noisyNet noise sample is [array([-0.72905385], dtype=float32), -1.4116136]. 
=============================================
[2019-03-26 12:55:20,158] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.9594447e-25 1.6437155e-36 2.1460931e-20 1.2054223e-06 9.9999881e-01], sum to 1.0000
[2019-03-26 12:55:20,167] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4360
[2019-03-26 12:55:20,171] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.33333333333334, 61.00000000000001, 1.0, 2.0, 0.5678197342587015, 1.0, 2.0, 0.5678197342587015, 1.0, 2.0, 0.9758674585015596, 6.9112, 6.9112, 170.5573041426782, 2382153.943762447, 2382153.943762447, 463072.6621936457], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6618000.0000, 
sim time next is 6618600.0000, 
raw observation next is [31.25, 61.5, 1.0, 2.0, 0.5505350159732824, 1.0, 2.0, 0.5505350159732824, 1.0, 2.0, 0.9462281652839412, 6.9112, 6.9112, 170.5573041426782, 2309572.971465984, 2309572.971465984, 449859.4454037843], 
processed observation next is [1.0, 0.6086956521739131, 0.6800947867298578, 0.615, 1.0, 1.0, 0.45847592285937633, 1.0, 1.0, 0.45847592285937633, 1.0, 1.0, 0.9344245918096842, 0.0, 0.0, 0.8375144448122397, 0.64154804762944, 0.64154804762944, 0.6714320080653496], 
reward next is 0.3286, 
noisyNet noise sample is [array([1.83074], dtype=float32), 1.3606563]. 
=============================================
[2019-03-26 12:55:28,583] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.7393936e-15 9.9950516e-01 1.4140952e-15 2.8525901e-13 4.9477181e-04], sum to 1.0000
[2019-03-26 12:55:28,591] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1515
[2019-03-26 12:55:28,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.76666666666667, 55.33333333333334, 1.0, 2.0, 0.3849319558507194, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 580726.9653351081, 580726.9653351087, 172968.2746961309], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6983400.0000, 
sim time next is 6984000.0000, 
raw observation next is [28.7, 55.0, 1.0, 2.0, 0.3801386057698529, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 575676.5679285721, 575676.5679285721, 172582.4786308239], 
processed observation next is [0.0, 0.8695652173913043, 0.5592417061611374, 0.55, 1.0, 1.0, 0.2531790430962083, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15991015775793668, 0.15991015775793668, 0.2575857890012297], 
reward next is 0.7424, 
noisyNet noise sample is [array([-0.38847345], dtype=float32), 0.3207568]. 
=============================================
[2019-03-26 12:55:28,615] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.85141 ]
 [56.850327]
 [56.872223]
 [56.926434]
 [56.98017 ]], R is [[57.09093475]
 [57.26186371]
 [57.43051147]
 [57.59704208]
 [57.76180649]].
[2019-03-26 12:55:29,069] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.4625354e-14 9.7118473e-01 1.1064449e-14 1.2457732e-11 2.8815316e-02], sum to 1.0000
[2019-03-26 12:55:29,079] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 1.0000
[2019-03-26 12:55:29,085] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.3, 69.0, 1.0, 2.0, 0.4224405810370953, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 616696.7005535706, 616696.7005535706, 175725.2670841848], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6991200.0000, 
sim time next is 6991800.0000, 
raw observation next is [27.18333333333333, 70.16666666666667, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 1.0, 0.2443002117181692, 6.911199999999998, 6.9112, 170.5573041426782, 620413.3060188063, 620413.3060188076, 248110.7464084829], 
processed observation next is [0.0, 0.9565217391304348, 0.48736176935229053, 0.7016666666666667, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.07841489233923074, -1.7763568394002506e-16, 0.0, 0.8375144448122397, 0.17233702944966842, 0.17233702944966878, 0.3703145468783327], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0549866], dtype=float32), 1.3098493]. 
=============================================
[2019-03-26 12:55:30,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.18248396e-23 1.49660320e-30 3.09858264e-19 2.83714712e-07
 9.99999762e-01], sum to 1.0000
[2019-03-26 12:55:30,789] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3118
[2019-03-26 12:55:30,797] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.96666666666667, 72.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2285319144948705, 6.9112, 6.9112, 170.5573041426782, 586041.4221393988, 586041.4221393988, 243038.6052152146], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7328400.0000, 
sim time next is 7329000.0000, 
raw observation next is [25.88333333333333, 72.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2284387566551924, 6.911199999999999, 6.9112, 170.5573041426782, 585820.1847254238, 585820.1847254244, 243006.4093382768], 
processed observation next is [1.0, 0.8260869565217391, 0.42575039494470757, 0.725, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.059071654457551706, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.16272782909039551, 0.16272782909039565, 0.36269613334071166], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4854382], dtype=float32), -0.9708067]. 
=============================================
[2019-03-26 12:55:30,814] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[16.21049 ]
 [16.21828 ]
 [16.295195]
 [16.327517]
 [16.458687]], R is [[15.95430088]
 [15.79475784]
 [15.6368103 ]
 [15.48044205]
 [15.32563782]].
[2019-03-26 12:55:32,464] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.6409364e-21 2.1922961e-24 1.2933299e-17 3.1795569e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:32,474] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3141
[2019-03-26 12:55:32,480] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.26666666666667, 79.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1987531236247018, 6.9112, 6.9112, 170.5573041426782, 518170.7792414309, 518170.7792414309, 232900.7964467729], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6832200.0000, 
sim time next is 6832800.0000, 
raw observation next is [23.2, 80.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1987933758208063, 6.911200000000001, 6.9112, 170.5573041426782, 518256.3207512486, 518256.320751248, 232914.5662375613], 
processed observation next is [0.0, 0.08695652173913043, 0.29857819905213273, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.02291875100098331, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.14396008909756905, 0.14396008909756888, 0.34763368095158403], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.88276595], dtype=float32), 1.3374095]. 
=============================================
[2019-03-26 12:55:39,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.7375751e-22 8.5441828e-33 3.2454458e-17 2.1879362e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:39,202] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6930
[2019-03-26 12:55:39,209] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 63.33333333333333, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2515960210371639, 6.911200000000001, 6.9112, 170.5573041426782, 635536.3703685227, 635536.370368522, 250316.7068409958], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6946800.0000, 
sim time next is 6947400.0000, 
raw observation next is [28.95, 62.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2528643638054228, 6.911200000000001, 6.9112, 170.5573041426782, 638555.2908200861, 638555.2908200854, 250755.066391313], 
processed observation next is [0.0, 0.391304347826087, 0.5710900473933649, 0.6266666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.08885898025051564, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.17737646967224616, 0.17737646967224596, 0.3742612931213627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36397937], dtype=float32), 0.5585777]. 
=============================================
[2019-03-26 12:55:40,485] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.3624625e-26 0.0000000e+00 4.3323720e-20 6.3049974e-08 9.9999988e-01], sum to 1.0000
[2019-03-26 12:55:40,495] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-26 12:55:40,501] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 90.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2781779655003055, 6.9112, 6.9112, 170.5573041426782, 690559.2616048083, 690559.2616048083, 258553.2533997792], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7187400.0000, 
sim time next is 7188000.0000, 
raw observation next is [25.8, 90.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2772822839090849, 6.911199999999999, 6.9112, 170.5573041426782, 688141.769428708, 688141.7694287087, 258197.9615044003], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9066666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11863693159644498, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.19115049150797445, 0.19115049150797464, 0.3853700917976124], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07792474], dtype=float32), -0.11271803]. 
=============================================
[2019-03-26 12:55:40,516] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[-17.328524]
 [-17.552925]
 [-17.765312]
 [-18.235416]
 [-18.36805 ]], R is [[-17.1376133 ]
 [-16.96623802]
 [-16.79657555]
 [-16.02194405]
 [-15.26061058]].
[2019-03-26 12:55:41,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.6148923e-29 0.0000000e+00 5.8577736e-21 9.9930570e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:41,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6166
[2019-03-26 12:55:41,180] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 88.33333333333333, 1.0, 2.0, 0.2043859224165228, 1.0, 2.0, 0.2043859224165228, 1.0, 2.0, 0.3441251170560554, 6.911200000000001, 6.9112, 170.5573041426782, 856853.1593861786, 856853.159386178, 270447.7354864314], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7180800.0000, 
sim time next is 7181400.0000, 
raw observation next is [25.8, 88.66666666666667, 1.0, 2.0, 0.1942396672581924, 1.0, 2.0, 0.1942396672581924, 1.0, 2.0, 0.3271168136864028, 6.9112, 6.9112, 170.5573041426782, 814300.5648994246, 814300.5648994246, 267735.6815101033], 
processed observation next is [1.0, 0.08695652173913043, 0.42180094786729866, 0.8866666666666667, 1.0, 1.0, 0.029204418383364312, 1.0, 1.0, 0.029204418383364312, 1.0, 1.0, 0.17941074839805216, 0.0, 0.0, 0.8375144448122397, 0.22619460136095126, 0.22619460136095126, 0.39960549479119895], 
reward next is 0.6004, 
noisyNet noise sample is [array([-1.0900054], dtype=float32), 0.34190574]. 
=============================================
[2019-03-26 12:55:42,044] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.2394097e-32 0.0000000e+00 5.5019372e-24 8.0952800e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:42,053] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4506
[2019-03-26 12:55:42,060] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.56666666666667, 87.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2683948512273012, 6.911199999999999, 6.9112, 170.5573041426782, 672568.0988057053, 672568.0988057059, 255784.0966238083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7078200.0000, 
sim time next is 7078800.0000, 
raw observation next is [25.53333333333333, 87.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2688633370113831, 6.911199999999999, 6.9112, 170.5573041426782, 673830.8859480226, 673830.8859480232, 255968.3590515604], 
processed observation next is [1.0, 0.9565217391304348, 0.4091627172195892, 0.8733333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10836992318461353, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.18717524609667294, 0.1871752460966731, 0.38204232694262746], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4300156], dtype=float32), 1.1441567]. 
=============================================
[2019-03-26 12:55:42,973] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.5266103e-25 6.8992448e-37 1.9352309e-19 6.5163381e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:42,982] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2641
[2019-03-26 12:55:42,989] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.25, 86.33333333333334, 1.0, 2.0, 0.2167586233021508, 1.0, 2.0, 0.2167586233021508, 1.0, 2.0, 0.3611192324701623, 6.911200000000001, 6.9112, 170.5573041426782, 908745.5766658286, 908745.5766658279, 273676.5023984266], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7013400.0000, 
sim time next is 7014000.0000, 
raw observation next is [25.2, 86.66666666666667, 1.0, 2.0, 0.209084237878043, 1.0, 2.0, 0.209084237878043, 1.0, 2.0, 0.3482596638884493, 6.911199999999999, 6.9112, 170.5573041426782, 876558.0960846823, 876558.0960846829, 271498.9965771532], 
processed observation next is [1.0, 0.17391304347826086, 0.3933649289099526, 0.8666666666666667, 1.0, 1.0, 0.04708944322655782, 1.0, 1.0, 0.04708944322655782, 1.0, 1.0, 0.20519471205908452, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.24348836002352287, 0.243488360023523, 0.40522238295097496], 
reward next is 0.5948, 
noisyNet noise sample is [array([0.564293], dtype=float32), 0.7017181]. 
=============================================
[2019-03-26 12:55:43,002] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-5.0656433]
 [-5.2544174]
 [-5.352941 ]
 [-5.34315  ]
 [-5.380105 ]], R is [[-4.46045542]
 [-3.82432365]
 [-3.19700336]
 [-2.57757521]
 [-1.9662962 ]].
[2019-03-26 12:55:43,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.7056574e-23 1.4683369e-34 8.2937579e-19 2.5531067e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:55:43,343] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1755
[2019-03-26 12:55:43,353] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.75, 82.16666666666666, 1.0, 2.0, 0.1927562473350477, 1.0, 2.0, 0.1927562473350477, 1.0, 2.0, 0.3211765107863842, 6.911200000000001, 6.9112, 170.5573041426782, 809648.7583845722, 809648.7583845716, 267338.6357631765], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7019400.0000, 
sim time next is 7020000.0000, 
raw observation next is [25.9, 81.0, 1.0, 2.0, 0.1974681671784087, 1.0, 2.0, 0.1974681671784087, 1.0, 2.0, 0.3291952990855893, 6.911200000000001, 6.9112, 170.5573041426782, 830047.6016634062, 830047.6016634057, 268645.3378591796], 
processed observation next is [1.0, 0.2608695652173913, 0.42654028436018954, 0.81, 1.0, 1.0, 0.03309417732338397, 1.0, 1.0, 0.03309417732338397, 1.0, 1.0, 0.18194548668974306, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.23056877823983507, 0.2305687782398349, 0.4009631908345964], 
reward next is 0.5990, 
noisyNet noise sample is [array([-0.08734354], dtype=float32), 0.424357]. 
=============================================
[2019-03-26 12:55:43,365] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-0.4174861 ]
 [-0.30668584]
 [-0.28033248]
 [-0.07433358]
 [ 0.1048747 ]], R is [[-0.00688839]
 [ 0.59416765]
 [ 1.18866777]
 [ 1.77475762]
 [ 2.35596561]].
[2019-03-26 12:55:43,736] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-26 12:55:43,737] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:55:43,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:55:43,739] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:55:43,740] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:55:43,742] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:55:43,739] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:55:43,742] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:55:43,746] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:55:43,744] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:55:43,748] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:55:43,783] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run68
[2019-03-26 12:55:43,805] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run68
[2019-03-26 12:55:43,830] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run68
[2019-03-26 12:55:43,858] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run68
[2019-03-26 12:55:43,858] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run68
[2019-03-26 12:56:07,288] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:07,288] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.25, 94.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2472619451243835, 6.911199999999999, 6.9112, 178.6582176852504, 630444.3330260585, 630444.3330260592, 251523.9899268008]
[2019-03-26 12:56:07,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:07,292] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3977124e-23 3.8286690e-31 6.1958103e-19 9.0704546e-08 9.9999988e-01], sampled 0.8424471233589942
[2019-03-26 12:56:19,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:19,948] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.3797519, 90.91828562, 1.0, 2.0, 0.2105501860493413, 1.0, 2.0, 0.2105501860493413, 1.0, 2.0, 0.3542252100637319, 6.9112, 6.9112, 171.5212843490159, 882704.3780941431, 882704.3780941431, 272344.5813616138]
[2019-03-26 12:56:19,949] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:56:19,951] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.1508709e-21 2.1642147e-28 4.6431062e-18 4.8106720e-08 1.0000000e+00], sampled 0.573741565898069
[2019-03-26 12:56:22,839] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:22,840] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.66666666666667, 96.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.248085354927772, 6.911200000000001, 6.9112, 170.5573041426782, 627902.9791251008, 627902.9791251002, 249208.6523073085]
[2019-03-26 12:56:22,842] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:22,844] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.3143981e-22 2.1238775e-28 6.3077799e-18 1.4856823e-07 9.9999988e-01], sampled 0.1925041310408333
[2019-03-26 12:56:24,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:24,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.90550750333334, 97.43923259333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2223067874250152, 6.911199999999999, 6.9112, 184.5923449428631, 585479.4080978066, 585479.4080978073, 245592.9602228931]
[2019-03-26 12:56:24,234] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:56:24,239] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6310137e-20 1.1887023e-24 4.9198016e-17 6.0937403e-08 9.9999988e-01], sampled 0.45959292947411834
[2019-03-26 12:56:25,851] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:25,852] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.77530511666667, 96.90670068333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.228252437100106, 6.911200000000001, 6.9112, 171.5212843490159, 583586.9219850012, 583586.9219850006, 242943.1581717338]
[2019-03-26 12:56:25,855] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:56:25,862] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8534781e-18 3.5874183e-20 5.4340652e-16 3.2900536e-09 1.0000000e+00], sampled 0.03861457108328625
[2019-03-26 12:56:26,615] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:26,615] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.3, 83.0, 1.0, 2.0, 0.2564215170124435, 1.0, 2.0, 0.2564215170124435, 1.0, 2.0, 0.4364937162824564, 6.911199999999999, 6.9112, 178.6582176852504, 1075088.442315698, 1075088.442315699, 288969.0890781133]
[2019-03-26 12:56:26,616] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:26,622] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.0733330e-20 1.1468241e-24 3.1982028e-17 1.4110086e-08 1.0000000e+00], sampled 0.9569577865950021
[2019-03-26 12:56:26,664] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:26,667] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.63333333333333, 71.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2849945135667124, 6.9112, 6.9112, 169.0403247858759, 707735.8174384154, 707735.8174384154, 260813.8729111573]
[2019-03-26 12:56:26,667] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:56:26,670] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.0665313e-24 3.9406093e-34 2.2513124e-19 4.6531216e-07 9.9999952e-01], sampled 0.011982988956213414
[2019-03-26 12:56:40,284] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:40,286] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 84.0, 1.0, 2.0, 0.1941143835584889, 1.0, 2.0, 0.1941143835584889, 1.0, 2.0, 0.3371124896335013, 6.9112, 6.9112, 170.5573041426782, 813775.1454889319, 813775.1454889319, 268238.6493874384]
[2019-03-26 12:56:40,287] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:40,290] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.3890814e-24 5.2677107e-34 9.7138514e-20 3.2178531e-07 9.9999964e-01], sampled 0.2904864978681957
[2019-03-26 12:56:42,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:42,402] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 60.0, 1.0, 2.0, 0.7866350280198164, 1.0, 2.0, 0.7139075535241707, 1.0, 2.0, 1.03, 7.005104564241957, 6.9112, 170.5573041426782, 2995765.788036322, 2928498.128876357, 550088.7375059015]
[2019-03-26 12:56:42,403] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:42,409] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.8136740e-27 0.0000000e+00 1.0718405e-22 9.1837984e-07 9.9999905e-01], sampled 0.3489486816930064
[2019-03-26 12:56:48,478] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:48,480] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.32746019666667, 74.57650269999999, 1.0, 2.0, 0.1904033064946871, 1.0, 2.0, 0.1904033064946871, 1.0, 2.0, 0.3306675760456164, 6.9112, 6.9112, 171.5212843490159, 798209.9407073869, 798209.9407073869, 267448.4434268]
[2019-03-26 12:56:48,482] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:56:48,485] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.12055325e-23 2.70188258e-32 3.01260136e-19 1.22756958e-07
 9.99999881e-01], sampled 0.8095588886518357
[2019-03-26 12:56:57,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:56:57,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 63.0, 1.0, 2.0, 0.1736349664398014, 1.0, 2.0, 0.1736349664398014, 1.0, 2.0, 0.2960778402872636, 6.9112, 6.9112, 170.5573041426782, 727891.2687744198, 727891.2687744198, 262810.3915935268]
[2019-03-26 12:56:57,448] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:56:57,450] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.5541628e-22 7.0178759e-28 4.9458427e-18 5.5534962e-08 1.0000000e+00], sampled 0.2542545786087268
[2019-03-26 12:57:02,992] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:57:02,993] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [35.86854422, 55.62922555, 1.0, 2.0, 0.542584998084156, 1.0, 2.0, 0.542584998084156, 1.0, 2.0, 0.9422907060713757, 6.9112, 6.9112, 171.5212843490159, 2276179.489586143, 2276179.489586143, 446049.8414660009]
[2019-03-26 12:57:02,993] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:57:02,995] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6837731e-24 5.7038991e-37 1.3443454e-20 1.4346953e-07 9.9999988e-01], sampled 0.2287969051367923
[2019-03-26 12:57:09,786] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:57:09,787] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.1, 74.0, 1.0, 2.0, 0.5209908258258419, 1.0, 2.0, 0.5209908258258419, 1.0, 2.0, 0.9047887701605755, 6.9112, 6.9112, 170.5573041426782, 2185518.554364011, 2185518.554364011, 429965.0385159259]
[2019-03-26 12:57:09,789] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:57:09,794] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.7098092e-24 8.9878525e-36 8.4362228e-21 6.3729217e-08 9.9999988e-01], sampled 0.5452549818619221
[2019-03-26 12:57:16,069] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([-0.47059688], dtype=float32), 0.116057776]
[2019-03-26 12:57:16,071] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.99662144, 88.61609445, 1.0, 2.0, 0.1993556987401931, 1.0, 2.0, 0.1993556987401931, 1.0, 2.0, 0.3462149207747041, 6.9112, 6.9112, 171.5212843490159, 835754.7565411758, 835754.7565411758, 269862.9955725385]
[2019-03-26 12:57:16,073] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-26 12:57:16,075] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.8550177e-24 3.4237283e-33 2.1338022e-19 3.2744612e-07 9.9999964e-01], sampled 0.7586074752040642
[2019-03-26 12:57:39,118] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 4007.5373 3853934756.9617 568.0000
[2019-03-26 12:57:39,160] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 4718.0615 3682788140.9884 80.0000
[2019-03-26 12:57:39,339] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 4834.4366 3699931543.1700 16.0000
[2019-03-26 12:57:39,473] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3994.2762 3614317202.8716 60.0000
[2019-03-26 12:57:39,496] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3939.5821 3596268101.1367 102.0000
[2019-03-26 12:57:40,510] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1675000, evaluation results [1675000.0, 4007.5372952425682, 3853934756.961721, 568.0, 4718.06150552221, 3682788140.988365, 80.0, 3994.2762246549787, 3614317202.871592, 60.0, 4834.436571955372, 3699931543.169979, 16.0, 3939.582083226016, 3596268101.136736, 102.0]
[2019-03-26 12:57:42,707] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.5870971e-27 1.8946479e-38 1.9722221e-21 9.2156284e-07 9.9999905e-01], sum to 1.0000
[2019-03-26 12:57:42,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6608
[2019-03-26 12:57:42,724] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.43333333333333, 87.83333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2658417767512035, 6.9112, 6.9112, 170.5573041426782, 666548.0504305189, 666548.0504305189, 254892.4860634922], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7080600.0000, 
sim time next is 7081200.0000, 
raw observation next is [25.4, 88.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2651832785530422, 6.911199999999999, 6.9112, 170.5573041426782, 664994.7424414568, 664994.7424414573, 254662.7164594364], 
processed observation next is [1.0, 1.0, 0.4028436018957346, 0.88, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10388204701590512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.18472076178929356, 0.1847207617892937, 0.3800936066558752], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2614919], dtype=float32), 0.96301866]. 
=============================================
[2019-03-26 12:57:43,456] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6031744e-21 3.6598216e-27 2.2724812e-17 3.4138836e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 12:57:43,466] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6598
[2019-03-26 12:57:43,473] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.53333333333333, 90.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1988145950133622, 6.9112, 6.9112, 170.5573041426782, 519774.6662019385, 519774.6662019385, 232968.2879789407], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7273200.0000, 
sim time next is 7273800.0000, 
raw observation next is [21.5, 90.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2028311844137274, 6.9112, 6.9112, 170.5573041426782, 530388.2296366612, 530388.2296366612, 234422.5310208858], 
processed observation next is [1.0, 0.17391304347826086, 0.21800947867298584, 0.905, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0278429078216188, 0.0, 0.0, 0.8375144448122397, 0.14733006378796146, 0.14733006378796146, 0.3498843746580385], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6220157], dtype=float32), -0.1435391]. 
=============================================
[2019-03-26 12:57:50,297] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.2338340e-19 3.8686219e-21 8.2815311e-17 1.5277366e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:57:50,307] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7969
[2019-03-26 12:57:50,313] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.8, 90.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2772822839090849, 6.911199999999999, 6.9112, 170.5573041426782, 688141.769428708, 688141.7694287087, 258197.9615044003], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7188000.0000, 
sim time next is 7188600.0000, 
raw observation next is [25.8, 90.83333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2780956909517376, 6.9112, 6.9112, 170.5573041426782, 689941.1808662964, 689941.1808662964, 258468.5547520663], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.9083333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11962889140455803, 0.0, 0.0, 0.8375144448122397, 0.19165032801841567, 0.19165032801841567, 0.38577396231651684], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5487346], dtype=float32), -0.32740927]. 
=============================================
[2019-03-26 12:57:52,981] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.7065365e-21 1.1781534e-22 5.6547080e-19 1.8920523e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:57:52,994] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5193
[2019-03-26 12:57:52,999] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.7, 84.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2218067639775445, 6.9112, 6.9112, 170.5573041426782, 571247.5650670355, 571247.5650670355, 240825.7256247532], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7236600.0000, 
sim time next is 7237200.0000, 
raw observation next is [23.6, 85.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2208511738651282, 6.9112, 6.9112, 170.5573041426782, 568837.2311582502, 568837.2311582502, 240481.908490127], 
processed observation next is [1.0, 0.782608695652174, 0.3175355450236968, 0.8533333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.04981850471357099, 0.0, 0.0, 0.8375144448122397, 0.15801034198840286, 0.15801034198840286, 0.35892822162705523], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5130048], dtype=float32), 0.28600928]. 
=============================================
[2019-03-26 12:57:57,214] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.5930081e-20 1.9133460e-22 2.5022098e-17 3.6500674e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:57:57,223] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1176
[2019-03-26 12:57:57,228] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.56666666666667, 83.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2276685953131112, 6.911199999999999, 6.9112, 170.5573041426782, 582218.5908960329, 582218.5908960334, 242547.7493868472], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7476000.0000, 
sim time next is 7476600.0000, 
raw observation next is [24.68333333333333, 82.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2285098181721898, 6.9112, 6.9112, 170.5573041426782, 584054.7195842109, 584054.7195842109, 242818.427078052], 
processed observation next is [0.0, 0.5217391304347826, 0.3688783570300157, 0.825, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0591583148441339, 0.0, 0.0, 0.8375144448122397, 0.16223742210672526, 0.16223742210672526, 0.36241556280306264], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.787584], dtype=float32), -1.1934512]. 
=============================================
[2019-03-26 12:58:02,175] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:02,175] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:02,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run9
[2019-03-26 12:58:03,079] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.1758344e-27 0.0000000e+00 4.3858643e-21 4.2408544e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:03,087] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4819
[2019-03-26 12:58:03,091] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.63333333333333, 83.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.9112, 6.9112, 170.5573041426782, 470559.1788824469, 470559.1788824469, 225560.6975989799], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7417200.0000, 
sim time next is 7417800.0000, 
raw observation next is [21.6, 84.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1800345361447315, 6.911199999999999, 6.9112, 170.5573041426782, 474275.5019644159, 474275.5019644165, 226245.5493480534], 
processed observation next is [1.0, 0.8695652173913043, 0.22274881516587688, 0.84, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.211724967256858e-05, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.13174319499011553, 0.1317431949901157, 0.3376799244000797], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.09163826], dtype=float32), -0.17770042]. 
=============================================
[2019-03-26 12:58:03,693] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5035658e-28 0.0000000e+00 9.3564770e-22 1.1647072e-07 9.9999988e-01], sum to 1.0000
[2019-03-26 12:58:03,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6863
[2019-03-26 12:58:03,710] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.1, 94.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1915186005280518, 6.911200000000001, 6.9112, 170.5573041426782, 500774.3391988036, 500774.339198803, 230344.0295730923], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7430400.0000, 
sim time next is 7431000.0000, 
raw observation next is [21.13333333333334, 93.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1916096125497428, 6.9112, 6.9112, 170.5573041426782, 501041.6642198745, 501041.6642198745, 230377.3868184505], 
processed observation next is [0.0, 0.0, 0.20063191153238583, 0.9366666666666668, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.014158064085052192, 0.0, 0.0, 0.8375144448122397, 0.13917824006107624, 0.13917824006107624, 0.34384684599768733], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.1537206], dtype=float32), -1.0316199]. 
=============================================
[2019-03-26 12:58:03,727] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-1.1753714]
 [-2.5640852]
 [-2.4917605]
 [-2.4173472]
 [-2.3298023]], R is [[0.64015996]
 [0.63375837]
 [0.62742078]
 [0.62114656]
 [0.6149351 ]].
[2019-03-26 12:58:04,405] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:04,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:04,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run9
[2019-03-26 12:58:09,938] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.0854195e-26 6.9658042e-38 6.6436329e-20 1.3454902e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:09,945] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3770
[2019-03-26 12:58:09,952] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.8, 91.0, 1.0, 2.0, 0.1896402606017148, 1.0, 2.0, 0.1896402606017148, 1.0, 2.0, 0.316442254985, 6.9112, 6.9112, 170.5573041426782, 795011.5719944382, 795011.5719944382, 266381.1294734378], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7632000.0000, 
sim time next is 7632600.0000, 
raw observation next is [25.06666666666667, 89.33333333333334, 1.0, 2.0, 0.1863072984174679, 1.0, 2.0, 0.1863072984174679, 1.0, 2.0, 0.3110123829814342, 6.9112, 6.9112, 170.5573041426782, 781034.0110408299, 781034.0110408299, 265554.6463701255], 
processed observation next is [1.0, 0.34782608695652173, 0.38704581358609813, 0.8933333333333334, 1.0, 1.0, 0.01964734749092517, 1.0, 1.0, 0.01964734749092517, 1.0, 1.0, 0.15977119875784657, 0.0, 0.0, 0.8375144448122397, 0.2169538919557861, 0.2169538919557861, 0.39635021846287394], 
reward next is 0.6036, 
noisyNet noise sample is [array([-1.5873107], dtype=float32), -0.4866143]. 
=============================================
[2019-03-26 12:58:10,724] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:10,724] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:10,797] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run9
[2019-03-26 12:58:18,218] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2611848e-23 8.2817844e-32 2.3289262e-19 2.5929808e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:18,228] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1526
[2019-03-26 12:58:18,238] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 85.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2773784314431112, 6.9112, 6.9112, 170.5573041426782, 690050.8763347245, 690050.8763347245, 258452.5060638204], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7783200.0000, 
sim time next is 7783800.0000, 
raw observation next is [26.35, 85.33333333333334, 1.0, 2.0, 0.3181831006261184, 1.0, 2.0, 0.3181831006261184, 1.0, 2.0, 0.5373219799817281, 6.911200000000001, 6.9112, 170.5573041426782, 1334225.268262177, 1334225.268262177, 310573.278965127], 
processed observation next is [1.0, 0.08695652173913043, 0.4478672985781992, 0.8533333333333334, 1.0, 1.0, 0.17853385617604622, 1.0, 1.0, 0.17853385617604622, 1.0, 1.0, 0.4357585121728392, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.37061813007282696, 0.37061813007282696, 0.46354220741063734], 
reward next is 0.5365, 
noisyNet noise sample is [array([-0.1033653], dtype=float32), 0.8721745]. 
=============================================
[2019-03-26 12:58:21,160] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:21,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:21,234] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run9
[2019-03-26 12:58:21,312] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.9037536e-21 1.7919358e-25 2.2905742e-18 1.5757070e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:21,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2929
[2019-03-26 12:58:21,323] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.23333333333333, 86.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.9112, 6.9112, 170.5573041426782, 456700.7625192074, 456700.7625192074, 223144.3946072191], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 332400.0000, 
sim time next is 333000.0000, 
raw observation next is [21.2, 86.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 455335.3113388706, 455335.31133887, 222881.0671558953], 
processed observation next is [0.0, 0.8695652173913043, 0.20379146919431282, 0.86, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.12648203092746405, 0.12648203092746388, 0.3326583091879034], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56815153], dtype=float32), 1.2483623]. 
=============================================
[2019-03-26 12:58:21,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[21.258657]
 [21.354462]
 [21.473234]
 [21.502144]
 [21.557745]], R is [[20.97619057]
 [20.76642799]
 [20.5587635 ]
 [20.35317612]
 [20.14964485]].
[2019-03-26 12:58:21,753] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2683689e-23 1.0498011e-27 3.1314153e-19 3.8279455e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:21,759] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2617
[2019-03-26 12:58:21,766] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 86.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2838225918659146, 6.9112, 6.9112, 170.5573041426782, 703691.8839797183, 703691.8839797183, 260520.8446744064], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7780200.0000, 
sim time next is 7780800.0000, 
raw observation next is [26.4, 86.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2823535919795595, 6.911200000000001, 6.9112, 170.5573041426782, 700527.2124793773, 700527.2124793767, 260041.2527112018], 
processed observation next is [1.0, 0.043478260869565216, 0.45023696682464454, 0.8633333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.12482145363360915, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.19459089235538257, 0.1945908923553824, 0.3881212727032863], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5485431], dtype=float32), -0.7188084]. 
=============================================
[2019-03-26 12:58:21,947] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:21,948] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:21,993] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run9
[2019-03-26 12:58:23,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:23,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:23,176] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.2420289e-18 8.4114607e-18 1.1781031e-16 1.2821064e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:23,181] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5386
[2019-03-26 12:58:23,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run9
[2019-03-26 12:58:23,190] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.86666666666667, 87.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1924267556069404, 6.9112, 6.9112, 170.5573041426782, 503503.717303645, 503503.717303645, 230677.8198419468], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 220800.0000, 
sim time next is 221400.0000, 
raw observation next is [21.95, 87.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1933596034513754, 6.9112, 6.9112, 170.5573041426782, 505730.4650137768, 505730.4650137768, 231008.6157258646], 
processed observation next is [0.0, 0.5652173913043478, 0.2393364928909953, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.01629219933094562, 0.0, 0.0, 0.8375144448122397, 0.1404806847260491, 0.1404806847260491, 0.34478897869532027], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3525987], dtype=float32), 1.0823923]. 
=============================================
[2019-03-26 12:58:27,181] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:27,181] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:27,258] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run9
[2019-03-26 12:58:27,502] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:27,503] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:27,566] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run9
[2019-03-26 12:58:28,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.0244063e-22 1.9276058e-26 2.6655373e-19 2.2031907e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:28,717] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2025
[2019-03-26 12:58:28,723] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.36666666666667, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2065215141858383, 6.911199999999999, 6.9112, 170.5573041426782, 536352.3365342475, 536352.3365342481, 235611.825713792], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 92400.0000, 
sim time next is 93000.0000, 
raw observation next is [22.38333333333333, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2071740241161367, 6.911200000000001, 6.9112, 170.5573041426782, 537948.6619288328, 537948.6619288321, 235842.6411594155], 
processed observation next is [1.0, 0.043478260869565216, 0.25987361769352274, 0.89, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.033139053800166705, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.14943018386912021, 0.14943018386912002, 0.3520039420289784], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.46055046], dtype=float32), -0.06483739]. 
=============================================
[2019-03-26 12:58:28,738] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[26.447893]
 [25.90745 ]
 [25.368504]
 [24.81175 ]
 [24.34865 ]], R is [[26.69491386]
 [26.42796516]
 [26.16368484]
 [25.90204811]
 [25.64302826]].
[2019-03-26 12:58:29,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:29,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:29,546] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run9
[2019-03-26 12:58:30,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,322] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run9
[2019-03-26 12:58:30,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run9
[2019-03-26 12:58:30,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,865] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,911] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,929] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run9
[2019-03-26 12:58:30,949] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:30,952] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:30,972] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run9
[2019-03-26 12:58:31,008] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run9
[2019-03-26 12:58:31,036] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run9
[2019-03-26 12:58:31,087] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-26 12:58:31,088] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,114] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run9
[2019-03-26 12:58:31,525] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.4602853e-22 1.0135701e-27 3.6523349e-18 1.2672406e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 12:58:31,529] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5645
[2019-03-26 12:58:31,531] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.5, 90.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2258977196565126, 6.9112, 6.9112, 170.5573041426782, 584841.9749845053, 584841.9749845053, 242563.6026445667], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 100800.0000, 
sim time next is 101400.0000, 
raw observation next is [22.51666666666667, 90.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.225194772067464, 6.911199999999999, 6.9112, 170.5573041426782, 582849.8853595826, 582849.8853595832, 242293.8071438864], 
processed observation next is [1.0, 0.17391304347826086, 0.2661927330173777, 0.9016666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05511557569202927, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.16190274593321738, 0.16190274593321755, 0.36163254797594985], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41552895], dtype=float32), -0.60514784]. 
=============================================
[2019-03-26 12:58:31,892] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-26 12:58:31,893] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 12:58:31,894] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 12:58:31,894] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,895] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,895] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 12:58:31,895] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 12:58:31,897] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,897] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,897] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 12:58:31,899] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 12:58:31,914] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run69
[2019-03-26 12:58:31,932] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run69
[2019-03-26 12:58:31,954] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run69
[2019-03-26 12:58:31,972] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run69
[2019-03-26 12:58:32,002] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run69
[2019-03-26 12:58:33,353] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:58:33,355] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.93333333333334, 69.0, 1.0, 2.0, 0.3585660290469831, 1.0, 2.0, 0.3585660290469831, 1.0, 2.0, 0.6062835742755809, 6.9112, 6.9112, 170.5573041426782, 1538542.37080601, 1538542.37080601, 332138.5877445361]
[2019-03-26 12:58:33,357] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:58:33,361] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.9606753e-25 7.4888066e-36 4.3769559e-21 1.8681529e-08 1.0000000e+00], sampled 0.7144066574531945
[2019-03-26 12:58:45,705] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:58:45,706] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.9, 91.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1880768921785135, 6.911199999999999, 6.9112, 178.6582176852504, 494495.7052519107, 494495.7052519114, 231136.1431426425]
[2019-03-26 12:58:45,707] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 12:58:45,709] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.9160267e-28 0.0000000e+00 1.7710288e-21 5.8543947e-08 1.0000000e+00], sampled 0.9092288252712457
[2019-03-26 12:58:56,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:58:56,072] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.3, 85.33333333333334, 1.0, 2.0, 0.2894968582477949, 1.0, 2.0, 0.2894968582477949, 1.0, 2.0, 0.488726149317615, 6.9112, 6.9112, 170.5573041426782, 1213868.222058117, 1213868.222058117, 298814.4361950074]
[2019-03-26 12:58:56,074] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-26 12:58:56,078] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.6527089e-24 1.9434735e-33 2.2986247e-20 9.7220836e-09 1.0000000e+00], sampled 0.48128497776026047
[2019-03-26 12:59:04,024] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:59:04,026] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.25, 94.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2154381949651122, 6.9112, 6.9112, 169.0403247858759, 556012.6529475191, 556012.6529475191, 238319.6003103584]
[2019-03-26 12:59:04,027] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:59:04,032] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.0569180e-22 2.9209364e-28 6.6948268e-18 7.8541157e-10 1.0000000e+00], sampled 0.21834720995421641
[2019-03-26 12:59:17,836] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:59:17,837] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.8, 71.0, 1.0, 2.0, 0.1821923787538392, 1.0, 2.0, 0.1821923787538392, 1.0, 2.0, 0.312027758688963, 6.9112, 6.9112, 169.0403247858759, 763779.8192209922, 763779.8192209922, 264653.7442397163]
[2019-03-26 12:59:17,839] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:59:17,841] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6140964e-22 2.9285215e-29 2.2848579e-18 1.9555970e-09 1.0000000e+00], sampled 0.9024955678692304
[2019-03-26 12:59:18,807] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:59:18,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.86055850333334, 67.07851366833333, 1.0, 2.0, 0.1843489892839498, 1.0, 2.0, 0.1843489892839498, 1.0, 2.0, 0.3172850274031738, 6.9112, 6.9112, 184.5923449428631, 772800.2974727392, 772800.2974727392, 269611.5607482513]
[2019-03-26 12:59:18,809] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 12:59:18,812] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.8790820e-24 2.5783401e-33 2.1984656e-19 3.3394241e-09 1.0000000e+00], sampled 0.5586794135901954
[2019-03-26 12:59:41,626] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 12:59:41,627] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.96666666666667, 76.0, 1.0, 2.0, 0.1924197399750799, 1.0, 2.0, 0.1924197399750799, 1.0, 2.0, 0.3341694541563167, 6.911200000000001, 6.9112, 169.0403247858759, 806670.8342779109, 806670.8342779102, 267495.4927442509]
[2019-03-26 12:59:41,629] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 12:59:41,632] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.7122644e-27 0.0000000e+00 4.5058976e-21 4.1261892e-08 1.0000000e+00], sampled 0.8788880971517908
[2019-03-26 13:00:03,768] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 13:00:03,769] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.95, 74.33333333333334, 1.0, 2.0, 0.1783804089844039, 1.0, 2.0, 0.1783804089844039, 1.0, 2.0, 0.3042850661286379, 6.911200000000001, 6.9112, 178.6582176852504, 747779.6476656953, 747779.6476656947, 265956.4487227823]
[2019-03-26 13:00:03,771] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 13:00:03,774] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.2059002e-28 0.0000000e+00 4.3943864e-22 3.0645346e-08 1.0000000e+00], sampled 0.7682595532336445
[2019-03-26 13:00:08,891] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 13:00:08,894] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.41666666666667, 69.0, 1.0, 2.0, 0.1723314603106336, 1.0, 2.0, 0.1723314603106336, 1.0, 2.0, 0.2920211540549131, 6.9112, 6.9112, 178.6582176852504, 722413.9984912289, 722413.9984912289, 264429.1369139513]
[2019-03-26 13:00:08,895] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-26 13:00:08,898] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.6452548e-28 0.0000000e+00 6.4595945e-22 3.1635022e-08 1.0000000e+00], sampled 0.9535320637868909
[2019-03-26 13:00:11,109] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([-0.43065408], dtype=float32), 0.1148082]
[2019-03-26 13:00:11,111] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.26666666666667, 72.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2850420755912725, 6.9112, 6.9112, 169.0403247858759, 710177.168995678, 710177.168995678, 261135.5107419417]
[2019-03-26 13:00:11,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-26 13:00:11,115] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.3983689e-25 7.1285532e-36 5.5965063e-20 6.4557573e-09 1.0000000e+00], sampled 0.8730058527515492
[2019-03-26 13:00:24,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 4000.8186 3854510851.5233 568.0000
[2019-03-26 13:00:25,243] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 4833.1512 3699935696.2613 16.0000
[2019-03-26 13:00:25,260] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 4718.7033 3682781319.4257 80.0000
[2019-03-26 13:00:25,369] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3938.9401 3596273050.0298 102.0000
[2019-03-26 13:00:25,431] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3993.6343 3614326218.5471 60.0000
[2019-03-26 13:00:26,448] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1700000, evaluation results [1700000.0, 4000.8186075183817, 3854510851.5232544, 568.0, 4718.703254949755, 3682781319.425743, 80.0, 3993.63433906035, 3614326218.5470796, 60.0, 4833.151155502788, 3699935696.261304, 16.0, 3938.9400640401022, 3596273050.0297737, 102.0]
[2019-03-26 13:00:26,894] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.2199093e-22 5.5855768e-31 5.2625908e-19 1.1680738e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:26,904] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2784
[2019-03-26 13:00:26,910] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.73333333333333, 85.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2194147895940757, 6.9112, 6.9112, 170.5573041426782, 575935.82396903, 575935.82396903, 240487.7613377646], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 22800.0000, 
sim time next is 23400.0000, 
raw observation next is [21.8, 85.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2242586804339774, 6.9112, 6.9112, 170.5573041426782, 588506.8890651645, 588506.8890651645, 242264.9018263558], 
processed observation next is [1.0, 0.2608695652173913, 0.23222748815165886, 0.85, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.053974000529240736, 0.0, 0.0, 0.8375144448122397, 0.16347413585143458, 0.16347413585143458, 0.3615894057109788], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.22155245], dtype=float32), -0.47003505]. 
=============================================
[2019-03-26 13:00:28,188] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.1727714e-25 6.3637914e-37 8.1865936e-21 4.4860879e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:28,199] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-26 13:00:28,203] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.51666666666667, 83.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2154944921547007, 6.9112, 6.9112, 170.5573041426782, 563312.0374239121, 563312.0374239121, 239021.9461735465], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 29400.0000, 
sim time next is 30000.0000, 
raw observation next is [22.73333333333333, 82.0, 1.0, 2.0, 0.1834154786862416, 1.0, 2.0, 0.1834154786862416, 1.0, 2.0, 0.3275752247805611, 6.9112, 6.9112, 170.5573041426782, 854707.0618148168, 854707.0618148168, 275712.9594919659], 
processed observation next is [1.0, 0.34782608695652173, 0.27646129541864134, 0.82, 1.0, 1.0, 0.016163227332821207, 1.0, 1.0, 0.016163227332821207, 1.0, 1.0, 0.17996978631775745, 0.0, 0.0, 0.8375144448122397, 0.23741862828189356, 0.23741862828189356, 0.41151187983875503], 
reward next is 0.5885, 
noisyNet noise sample is [array([1.4863551], dtype=float32), -0.31703433]. 
=============================================
[2019-03-26 13:00:28,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-3.8344529]
 [-3.611471 ]
 [-3.609615 ]
 [-3.488249 ]
 [-3.3422415]], R is [[-4.06289005]
 [-4.02226114]
 [-3.9820385 ]
 [-3.94221807]
 [-3.90279603]].
[2019-03-26 13:00:35,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.1157147e-24 3.6795083e-32 3.7611169e-20 6.7059092e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:35,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5704
[2019-03-26 13:00:35,963] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.11666666666667, 88.83333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911199999999999, 6.9112, 170.5573041426782, 418109.9522871746, 418109.9522871752, 215837.4729875942], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [20.1, 89.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 418268.247109443, 418268.2471094424, 215867.7562512543], 
processed observation next is [1.0, 0.17391304347826086, 0.15165876777251197, 0.89, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1161856241970675, 0.11618562419706734, 0.32219068097202136], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4908307], dtype=float32), 0.27118787]. 
=============================================
[2019-03-26 13:00:35,978] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[ 0.291606  ]
 [ 0.08635145]
 [-0.11478084]
 [-0.34089607]
 [-0.38692182]], R is [[0.58080518]
 [0.57499713]
 [0.56924719]
 [0.5635547 ]
 [0.55791914]].
[2019-03-26 13:00:41,144] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.5478681e-27 0.0000000e+00 5.5108453e-21 1.1672463e-06 9.9999881e-01], sum to 1.0000
[2019-03-26 13:00:41,155] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9130
[2019-03-26 13:00:41,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.0, 89.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911199999999999, 6.9112, 170.5573041426782, 472131.0467236874, 472131.046723688, 225977.7203327496], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 246600.0000, 
sim time next is 247200.0000, 
raw observation next is [20.96666666666667, 89.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.9112, 6.9112, 170.5573041426782, 470479.4085161078, 470479.4085161078, 225680.9682866885], 
processed observation next is [0.0, 0.8695652173913043, 0.1927330173775673, 0.8966666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8375144448122397, 0.13068872458780773, 0.13068872458780773, 0.33683726609953507], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31028274], dtype=float32), -0.11764494]. 
=============================================
[2019-03-26 13:00:47,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8265664e-26 0.0000000e+00 4.7440230e-21 2.8065164e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:47,523] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5004
[2019-03-26 13:00:47,526] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [20.35, 87.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.9112, 6.9112, 170.5573041426782, 424966.049718849, 424966.049718849, 217027.3551605251], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 351000.0000, 
sim time next is 351600.0000, 
raw observation next is [20.33333333333334, 87.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 424821.7206422769, 424821.7206422763, 216987.6784422885], 
processed observation next is [1.0, 0.043478260869565216, 0.16271721958925783, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.11800603351174359, 0.11800603351174341, 0.32386220663028137], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.84111327], dtype=float32), 0.10126853]. 
=============================================
[2019-03-26 13:00:57,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.1239902e-29 0.0000000e+00 1.4033466e-22 1.0603314e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:57,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0603
[2019-03-26 13:00:57,152] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [18.71666666666667, 87.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 376171.360409017, 376171.3604090164, 207189.4747750424], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 521400.0000, 
sim time next is 522000.0000, 
raw observation next is [18.7, 87.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911200000000001, 6.9112, 170.5573041426782, 375291.1252480219, 375291.1252480213, 207024.8778220114], 
processed observation next is [1.0, 0.043478260869565216, 0.08530805687203795, 0.87, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.1042475347911172, 0.10424753479111702, 0.30899235495822597], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6291196], dtype=float32), -0.9259001]. 
=============================================
[2019-03-26 13:00:57,173] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[-2.745474 ]
 [-3.4205043]
 [-4.1484942]
 [-5.000295 ]
 [-6.024429 ]], R is [[-2.10541701]
 [-2.08436275]
 [-2.06351924]
 [-2.04288411]
 [-2.02245522]].
[2019-03-26 13:00:58,426] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9214099e-26 3.0977514e-37 4.5172543e-22 8.2540902e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:58,436] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3042
[2019-03-26 13:00:58,441] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 94.0, 1.0, 2.0, 0.2242073722529284, 1.0, 2.0, 0.2242073722529284, 1.0, 2.0, 0.3932444528494866, 6.911200000000001, 6.9112, 170.5573041426782, 1015488.397508107, 1015488.397508107, 285138.4706250373], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 989400.0000, 
sim time next is 990000.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.2232087899985492, 1.0, 2.0, 0.2232087899985492, 1.0, 2.0, 0.3914752275473354, 6.9112, 6.9112, 170.5573041426782, 1010892.91828077, 1010892.91828077, 284805.7182574827], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.94, 1.0, 1.0, 0.06410697590186651, 1.0, 1.0, 0.06410697590186651, 1.0, 1.0, 0.2578966189601651, 0.0, 0.0, 0.8375144448122397, 0.28080358841132497, 0.28080358841132497, 0.42508316157833237], 
reward next is 0.5749, 
noisyNet noise sample is [array([-0.12693416], dtype=float32), 0.41601038]. 
=============================================
[2019-03-26 13:00:58,454] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[1.0920743 ]
 [0.82964987]
 [0.71355337]
 [0.5961456 ]
 [0.00677483]], R is [[1.94160688]
 [2.49661112]
 [3.0472672 ]
 [3.59750175]
 [4.14759731]].
[2019-03-26 13:00:59,163] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5043674e-25 4.7250206e-37 1.4148511e-20 4.4028745e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 13:00:59,174] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3119
[2019-03-26 13:00:59,179] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.1975484016964521, 1.0, 2.0, 0.1975484016964521, 1.0, 2.0, 0.347955462319132, 6.9112, 6.9112, 170.5573041426782, 900557.9644609673, 900557.9644609673, 277631.2568261523], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1002000.0000, 
sim time next is 1002600.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.1973137620806672, 1.0, 2.0, 0.1973137620806672, 1.0, 2.0, 0.3475925216230789, 6.911199999999999, 6.9112, 170.5573041426782, 899690.2437255074, 899690.243725508, 277586.1685133402], 
processed observation next is [1.0, 0.6086956521739131, 0.22274881516587688, 0.96, 1.0, 1.0, 0.03290814708514119, 1.0, 1.0, 0.03290814708514119, 1.0, 1.0, 0.20438112393058402, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.24991395659041873, 0.24991395659041887, 0.4143077141990152], 
reward next is 0.5857, 
noisyNet noise sample is [array([0.29303625], dtype=float32), 0.027611645]. 
=============================================
[2019-03-26 13:01:01,424] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.5481132e-24 6.9942690e-37 3.1430108e-19 4.1180996e-07 9.9999964e-01], sum to 1.0000
[2019-03-26 13:01:01,434] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0304
[2019-03-26 13:01:01,443] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.25, 56.66666666666666, 1.0, 2.0, 0.1930432801449063, 1.0, 2.0, 0.1930432801449063, 1.0, 2.0, 0.3532285132554783, 6.911199999999999, 6.9112, 170.5573041426782, 938763.8261781753, 938763.8261781759, 281195.2365925998], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 648600.0000, 
sim time next is 649200.0000, 
raw observation next is [24.3, 56.33333333333334, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2416034307560549, 6.9112, 6.9112, 170.5573041426782, 642829.8674995278, 642829.8674995278, 248300.9957858901], 
processed observation next is [1.0, 0.5217391304347826, 0.3507109004739337, 0.5633333333333335, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.07512613506835963, 0.0, 0.0, 0.8375144448122397, 0.17856385208320216, 0.17856385208320216, 0.3705985011729703], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5220258], dtype=float32), 0.5945705]. 
=============================================
[2019-03-26 13:01:11,529] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.3212505e-24 1.0744513e-33 1.0079482e-20 5.9435376e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 13:01:11,540] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5067
[2019-03-26 13:01:11,543] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.73333333333333, 94.33333333333334, 1.0, 2.0, 0.2808243304011893, 1.0, 2.0, 0.2808243304011893, 1.0, 2.0, 0.4825623516107139, 6.9112, 6.9112, 170.5573041426782, 1233487.376129505, 1233487.376129505, 301625.8581454], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1336800.0000, 
sim time next is 1337400.0000, 
raw observation next is [22.65, 94.0, 1.0, 2.0, 0.2812867870492617, 1.0, 2.0, 0.2812867870492617, 1.0, 2.0, 0.4847938367842378, 6.9112, 6.9112, 170.5573041426782, 1240958.053163292, 1240958.053163292, 302438.8857791757], 
processed observation next is [1.0, 0.4782608695652174, 0.2725118483412322, 0.94, 1.0, 1.0, 0.13408046632441167, 1.0, 1.0, 0.13408046632441167, 1.0, 1.0, 0.37169980095638755, 0.0, 0.0, 0.8375144448122397, 0.3447105703231366, 0.3447105703231366, 0.45140132205847117], 
reward next is 0.5486, 
noisyNet noise sample is [array([0.9531276], dtype=float32), -1.4225789]. 
=============================================
[2019-03-26 13:01:11,866] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [7.5506327e-26 3.8203875e-36 7.2330539e-21 1.5782349e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:01:11,876] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3320
[2019-03-26 13:01:11,882] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.96666666666667, 93.66666666666667, 1.0, 2.0, 0.1965899459043605, 1.0, 2.0, 0.1965899459043605, 1.0, 2.0, 0.3458646014259992, 6.9112, 6.9112, 170.5573041426782, 894571.6690995932, 894571.6690995932, 277171.8719719439], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 985200.0000, 
sim time next is 985800.0000, 
raw observation next is [21.98333333333333, 93.83333333333334, 1.0, 2.0, 0.1990914496953622, 1.0, 2.0, 0.1990914496953622, 1.0, 2.0, 0.3499566959722739, 6.911200000000001, 6.9112, 170.5573041426782, 904724.533294873, 904724.5332948723, 277755.2174877941], 
processed observation next is [1.0, 0.391304347826087, 0.24091627172195884, 0.9383333333333335, 1.0, 1.0, 0.03504993939200262, 1.0, 1.0, 0.03504993939200262, 1.0, 1.0, 0.20726426338082185, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.25131237035968695, 0.25131237035968673, 0.41456002610118525], 
reward next is 0.5854, 
noisyNet noise sample is [array([0.67210007], dtype=float32), -1.2284727]. 
=============================================
[2019-03-26 13:01:12,285] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.2597926e-23 1.3413772e-31 2.5695425e-18 2.8329042e-10 1.0000000e+00], sum to 1.0000
[2019-03-26 13:01:12,299] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3256
[2019-03-26 13:01:12,308] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.05, 84.66666666666666, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911199999999999, 6.9112, 170.5573041426782, 448179.1791352501, 448179.1791352507, 221350.2406203356], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 802200.0000, 
sim time next is 802800.0000, 
raw observation next is [21.2, 84.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911199999999999, 6.9112, 170.5573041426782, 450022.2019453084, 450022.2019453091, 221723.3197285375], 
processed observation next is [0.0, 0.30434782608695654, 0.20379146919431282, 0.84, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.12500616720703012, 0.1250061672070303, 0.33093032795304106], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61578226], dtype=float32), -0.37774536]. 
=============================================
[2019-03-26 13:01:14,787] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5478733e-26 0.0000000e+00 1.1234474e-22 4.9591842e-09 1.0000000e+00], sum to 1.0000
[2019-03-26 13:01:14,793] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0131
[2019-03-26 13:01:14,796] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.7, 85.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2628929032026399, 6.911200000000001, 6.9112, 170.5573041426782, 659511.4947434425, 659511.4947434419, 253853.9962269366], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1279200.0000, 
sim time next is 1279800.0000, 
raw observation next is [25.55, 86.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2623922016841241, 6.9112, 6.9112, 170.5573041426782, 658531.8298726168, 658531.8298726168, 253705.6890126153], 
processed observation next is [1.0, 0.8260869565217391, 0.40995260663507116, 0.865, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10047829473673668, 0.0, 0.0, 0.8375144448122397, 0.18292550829794912, 0.18292550829794912, 0.3786652074815154], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4535615], dtype=float32), 1.2973466]. 
=============================================
[2019-03-26 13:01:16,487] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.6800748e-29 0.0000000e+00 4.7584115e-22 4.5592330e-08 1.0000000e+00], sum to 1.0000
[2019-03-26 13:01:16,496] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8858
[2019-03-26 13:01:16,501] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.66666666666667, 88.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1861035727579767, 6.9112, 6.9112, 170.5573041426782, 487514.1026105871, 487514.1026105871, 228420.4547376398], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 859200.0000, 
sim time next is 859800.0000, 
raw observation next is [21.63333333333334, 88.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1865006051698336, 6.9112, 6.9112, 170.5573041426782, 488410.0328818212, 488410.0328818212, 228560.4413206715], 
processed observation next is [0.0, 0.9565217391304348, 0.2243285939968408, 0.885, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.007927567280284892, 0.0, 0.0, 0.8375144448122397, 0.13566945357828367, 0.13566945357828367, 0.3411349870457783], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7656447], dtype=float32), -0.48408684]. 
=============================================
[2019-03-26 13:01:20,755] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-26 13:01:20,757] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-26 13:01:20,758] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-26 13:01:20,758] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 13:01:20,759] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 13:01:20,759] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-26 13:01:20,761] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-26 13:01:20,760] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-26 13:01:20,764] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 13:01:20,764] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 13:01:20,765] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-26 13:01:20,793] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run70
[2019-03-26 13:01:20,817] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run70
[2019-03-26 13:01:20,839] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run70
[2019-03-26 13:01:20,862] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run70
[2019-03-26 13:01:20,862] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/3/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run70
[2019-03-26 13:01:25,137] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40458244], dtype=float32), 0.113494836]
[2019-03-26 13:01:25,139] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.94632990666667, 87.07984521666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2355410259470374, 6.911199999999999, 6.9112, 184.5923449428631, 601815.2158549728, 601815.2158549735, 249418.3664500374]
[2019-03-26 13:01:25,139] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 13:01:25,142] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.13477726e-26 0.00000000e+00 2.34240570e-20 2.18925944e-08
 1.00000000e+00], sampled 0.12995182956134133
[2019-03-26 13:01:29,828] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([-0.40458244], dtype=float32), 0.113494836]
[2019-03-26 13:01:29,829] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.68660017, 58.81805755, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.18, 6.911199999999999, 6.9112, 184.5923449428631, 418576.3120069596, 418576.3120069603, 218525.5012768106]
[2019-03-26 13:01:29,832] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-26 13:01:29,836] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.6382501e-24 9.7140775e-35 4.3199314e-19 1.2698914e-08 1.0000000e+00], sampled 0.9434881156213275
