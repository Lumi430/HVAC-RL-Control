Using TensorFlow backend.
[2019-03-27 04:39:50,423] A3C_AGENT_MAIN INFO:Namespace(action_repeat_n=1, action_space='part3_v1', activation='relu', agent_num=5, check_args_only=False, clip_norm=5.0, debug_log_prob=0.0005, decay_steps=1000000, dropout_prob=0.0, end_e=0.0, env='Part3-NA-Shg-Train-v1', eval_act_func='part3_shg_det_v1', eval_env_res_max_keep=50, eval_epi_num=1, eval_freq=25000, forecast_dim=0, gamma=0.99, h_decay_bounds=[], h_regu_frac=[0.0], init_e=0.0, isNoisyNet=True, isNoisyNetEval_rmNoise=True, is_greedy_policy=False, is_learning_rate_decay_staircase=False, is_warm_start=False, job_mode='Train', learning_rate=1e-05, learning_rate_decay_rate=1.0, learning_rate_decay_steps=100000, max_interactions=2500000, metric_func='part3_v1', model_dir='None', model_param=[64, 2], model_type='nn', num_threads=16, output='./Part3-NA-Shg-Train-v1-res1', p_loss_frac=1.0, raw_state_prcs_func='cslDx_1', reward_func='part3_v3', rmsprop_decay=0.99, rmsprop_epsil=1e-10, rmsprop_momet=0.0, rwd_e_para=1.0, rwd_p_para=1.0, save_freq=500000, save_max_to_keep=5, save_scope='all', sharedNet_type='Dense', state_dim=17, test_env=['Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'], test_mode='Multiple', train_act_func='part3_shg_sto_v1', train_freq=5, v_loss_frac=0.5, violation_penalty_scl=50.0, weight_initer='glorot_uniform', window_len=29)
[2019-03-27 04:39:50,424] A3C_AGENT_MAIN INFO:Start compiling...
2019-03-27 04:39:50.464482: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[2019-03-27 04:40:09,230] A3C_AGENT_MAIN INFO:Start the learning...
[2019-03-27 04:40:09,230] A3C_AGENT_MAIN INFO:Prepare the evaluation environments ['Part3-NA-Shg-Train-v1', 'Part3-NA-Shg-Test-v1', 'Part3-NA-Shg-Test-v2', 'Part3-NA-Shg-Test-v3', 'Part3-NA-Shg-Test-v4'] ...
[2019-03-27 04:40:09,239] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation worker starts!
[2019-03-27 04:40:09,245] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation worker starts!
[2019-03-27 04:40:09,250] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation worker starts!
[2019-03-27 04:40:09,256] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation worker starts!
[2019-03-27 04:40:09,259] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation worker starts!
[2019-03-27 04:40:09,259] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:09,260] A3C_AGENT_WORKER-Thread-2 INFO:Local worker starts!
[2019-03-27 04:40:09,319] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:09,320] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run1
[2019-03-27 04:40:10,261] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:10,263] A3C_AGENT_WORKER-Thread-3 INFO:Local worker starts!
[2019-03-27 04:40:10,354] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,355] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run1
[2019-03-27 04:40:10,556] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 04:40:10,556] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:40:10,557] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:40:10,557] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,557] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:40:10,557] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,558] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:40:10,559] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:40:10,558] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,559] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,559] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:10,562] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run1
[2019-03-27 04:40:10,573] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run1
[2019-03-27 04:40:10,574] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run1
[2019-03-27 04:40:10,581] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run1
[2019-03-27 04:40:10,581] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run1
[2019-03-27 04:40:11,264] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:11,265] A3C_AGENT_WORKER-Thread-9 INFO:Local worker starts!
[2019-03-27 04:40:11,349] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:11,349] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run1
[2019-03-27 04:40:12,266] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:12,268] A3C_AGENT_WORKER-Thread-10 INFO:Local worker starts!
[2019-03-27 04:40:12,375] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:12,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run1
[2019-03-27 04:40:13,270] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:13,275] A3C_AGENT_WORKER-Thread-11 INFO:Local worker starts!
[2019-03-27 04:40:13,340] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:13,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run1
[2019-03-27 04:40:14,273] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:14,279] A3C_AGENT_WORKER-Thread-12 INFO:Local worker starts!
[2019-03-27 04:40:14,342] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:14,342] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run1
[2019-03-27 04:40:15,281] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:15,285] A3C_AGENT_WORKER-Thread-13 INFO:Local worker starts!
[2019-03-27 04:40:15,347] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:15,348] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run1
[2019-03-27 04:40:16,285] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:16,290] A3C_AGENT_WORKER-Thread-14 INFO:Local worker starts!
[2019-03-27 04:40:16,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:16,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run1
[2019-03-27 04:40:17,291] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:17,297] A3C_AGENT_WORKER-Thread-15 INFO:Local worker starts!
[2019-03-27 04:40:17,369] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:17,370] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run1
[2019-03-27 04:40:18,297] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:18,303] A3C_AGENT_WORKER-Thread-16 INFO:Local worker starts!
[2019-03-27 04:40:18,390] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:18,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run1
[2019-03-27 04:40:19,305] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:19,307] A3C_AGENT_WORKER-Thread-17 INFO:Local worker starts!
[2019-03-27 04:40:19,397] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:19,398] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run1
[2019-03-27 04:40:20,308] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:20,313] A3C_AGENT_WORKER-Thread-18 INFO:Local worker starts!
[2019-03-27 04:40:20,383] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:20,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run1
[2019-03-27 04:40:21,312] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:21,318] A3C_AGENT_WORKER-Thread-19 INFO:Local worker starts!
[2019-03-27 04:40:21,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:21,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run1
[2019-03-27 04:40:22,316] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:22,320] A3C_AGENT_WORKER-Thread-20 INFO:Local worker starts!
[2019-03-27 04:40:22,382] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:22,383] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run1
[2019-03-27 04:40:23,320] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:23,324] A3C_AGENT_WORKER-Thread-21 INFO:Local worker starts!
[2019-03-27 04:40:23,384] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:23,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run1
[2019-03-27 04:40:24,324] A3C_AGENT_MAIN INFO:Prepare the local workers ...
[2019-03-27 04:40:24,329] A3C_AGENT_WORKER-Thread-22 INFO:Local worker starts!
[2019-03-27 04:40:24,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:40:24,393] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run1
[2019-03-27 04:40:25,723] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:40:25,725] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.13333333333333, 84.0, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 1.0, 0.18, 6.9112, 6.9112, 170.5573041426782, 423562.9637343624, 423562.9637343624, 216218.5268185844]
[2019-03-27 04:40:25,726] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:40:25,729] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.14255852 0.23314866 0.22486381 0.17134048 0.22808848], sampled 0.6388628313440452
[2019-03-27 04:40:28,902] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:40:28,903] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.86666666666667, 80.66666666666667, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 172.86236624, 482902.7601344684, 482902.7601344684, 230297.9608591175]
[2019-03-27 04:40:28,905] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:40:28,908] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.13013928 0.24876738 0.16440602 0.21992931 0.23675802], sampled 0.24904936519485854
[2019-03-27 04:40:34,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:40:34,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.7, 47.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 1.0, 0.1852652514829994, 6.911199999999999, 6.9112, 178.6582176852504, 487977.325228423, 487977.3252284236, 230117.6690173855]
[2019-03-27 04:40:34,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:40:34,988] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.14209571 0.2355776  0.2421947  0.18058866 0.19954333], sampled 0.8492262446187042
[2019-03-27 04:41:01,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:41:01,554] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.65, 57.33333333333333, 1.0, 2.0, 0.2573329193416942, 1.0, 1.0, 0.2573329193416942, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 719166.9220810005, 719166.9220810005, 242647.3486790345]
[2019-03-27 04:41:01,555] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:41:01,559] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.13311416 0.20904446 0.23419137 0.16384396 0.25980607], sampled 0.06707443144324776
[2019-03-27 04:41:05,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:41:05,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.184615365, 78.48649896166668, 1.0, 2.0, 0.191638044036397, 1.0, 1.0, 0.191638044036397, 1.0, 2.0, 0.3314087218772924, 6.9112, 6.9112, 184.5923449428631, 803366.9572596218, 803366.9572596218, 271568.558687939]
[2019-03-27 04:41:05,538] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:41:05,541] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.14534606 0.24822874 0.2814659  0.12229069 0.20266867], sampled 0.3630227686232015
[2019-03-27 04:41:33,664] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:41:33,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.46015493666667, 94.40463745666668, 1.0, 2.0, 0.266042899958763, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4501862063145312, 6.911199999999999, 6.9112, 168.912956510431, 743522.9274525058, 743522.9274525064, 210636.9712043904]
[2019-03-27 04:41:33,667] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:41:33,669] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.1620444  0.252882   0.25069284 0.15959859 0.17478216], sampled 0.19097600380548418
[2019-03-27 04:42:05,227] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.], dtype=float32), 0.0]
[2019-03-27 04:42:05,228] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.53333333333333, 68.66666666666667, 1.0, 2.0, 0.9031096634324284, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990461167068625, 6.9112, 168.9124229846319, 2159389.180341289, 2103158.758073054, 435499.9274140364]
[2019-03-27 04:42:05,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:42:05,232] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [0.12074539 0.2628352  0.23382798 0.17150564 0.21108584], sampled 0.585322546209464
[2019-03-27 04:42:06,907] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 3574.4500 3186143738.9766 740.0000
[2019-03-27 04:42:06,944] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 3400.8560 3481739642.4081 1280.0000
[2019-03-27 04:42:06,966] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 3650.5199 3269502508.0869 881.0000
[2019-03-27 04:42:06,967] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 3603.9366 3326501627.1852 1109.0000
[2019-03-27 04:42:07,038] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 3670.8441 3143154232.8236 616.0000
[2019-03-27 04:42:08,053] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 0, evaluation results [0.0, 3400.85600898044, 3481739642.4081383, 1280.0, 3650.5199018632893, 3269502508.0869436, 881.0, 3670.8441292786333, 3143154232.8236113, 616.0, 3603.9365715460294, 3326501627.185175, 1109.0, 3574.45000777448, 3186143738.9766374, 740.0]
[2019-03-27 04:42:15,811] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [0.13743941 0.29365024 0.23680583 0.17285888 0.15924558], sum to 1.0000
[2019-03-27 04:42:15,821] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5780
[2019-03-27 04:42:15,930] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.48333333333333, 89.83333333333333, 1.0, 2.0, 0.1927274980546203, 1.0, 1.0, 0.1927274980546203, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 589901.6285450147, 589901.6285450147, 240962.1456347088], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 96600.0000, 
sim time next is 97200.0000, 
raw observation next is [22.5, 90.0, 1.0, 2.0, 0.1952446848013088, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3460331026311501, 6.9112, 6.9112, 168.912956510431, 599067.0222930566, 599067.0222930566, 199547.1834277035], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 1.0, 1.0, 0.030415282893143117, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.2024793934526221, 0.0, 0.0, 0.8294399451523027, 0.1664075061925157, 0.1664075061925157, 0.29783161705627387], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.0658448], dtype=float32), -0.7120498]. 
=============================================
[2019-03-27 04:42:19,107] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.1583483  0.20221594 0.3488672  0.14466575 0.14590283], sum to 1.0000
[2019-03-27 04:42:19,114] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5388
[2019-03-27 04:42:19,222] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.5, 96.0, 1.0, 2.0, 0.1917681163519449, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3351874843457002, 6.9112, 6.9112, 168.912956510431, 575872.5079116046, 575872.5079116046, 197508.4612462861], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 151200.0000, 
sim time next is 151800.0000, 
raw observation next is [22.48333333333333, 96.0, 1.0, 2.0, 0.193527153372847, 0.0, 2.0, 0.0, 1.0, 2.0, 0.338233625960284, 6.911200000000001, 6.9112, 168.912956510431, 581081.8251097164, 581081.8251097158, 197872.1300234575], 
processed observation next is [1.0, 0.782608695652174, 0.26461295418641384, 0.96, 1.0, 1.0, 0.02834596791909277, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.1929678365369317, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16141161808603233, 0.16141161808603216, 0.29533153734844403], 
reward next is 0.7047, 
noisyNet noise sample is [array([-1.1990279], dtype=float32), 1.357501]. 
=============================================
[2019-03-27 04:42:23,487] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [0.15814026 0.199841   0.363389   0.11788757 0.1607422 ], sum to 1.0000
[2019-03-27 04:42:23,498] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8654
[2019-03-27 04:42:23,610] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.11666666666667, 86.33333333333334, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 1.0, 0.2895640345338797, 6.911200000000001, 6.9112, 168.912956510431, 506100.4631545794, 506100.4631545788, 191795.1202596214], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 222600.0000, 
sim time next is 223200.0000, 
raw observation next is [22.2, 86.0, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 2.0, 0.1938224658565093, 6.9112, 6.9112, 170.5573041426782, 506582.8317187956, 506582.8317187956, 231166.5468040095], 
processed observation next is [0.0, 0.6086956521739131, 0.2511848341232228, 0.86, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.016856665678669894, 0.0, 0.0, 0.8375144448122397, 0.140717453255221, 0.140717453255221, 0.3450246967224022], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.16178], dtype=float32), 0.45978928]. 
=============================================
[2019-03-27 04:42:27,814] A3C_AGENT_WORKER-Thread-11 INFO:Local step 500, global step 7909: loss 3.3546
[2019-03-27 04:42:27,877] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 500, global step 7909: learning rate 0.0000
[2019-03-27 04:42:27,887] A3C_AGENT_WORKER-Thread-3 INFO:Local step 500, global step 7921: loss 0.6182
[2019-03-27 04:42:27,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 500, global step 7922: learning rate 0.0000
[2019-03-27 04:42:27,896] A3C_AGENT_WORKER-Thread-14 INFO:Local step 500, global step 7928: loss 5.5621
[2019-03-27 04:42:27,898] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 500, global step 7928: learning rate 0.0000
[2019-03-27 04:42:27,929] A3C_AGENT_WORKER-Thread-21 INFO:Local step 500, global step 7946: loss 8.6615
[2019-03-27 04:42:27,932] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 500, global step 7946: learning rate 0.0000
[2019-03-27 04:42:27,936] A3C_AGENT_WORKER-Thread-2 INFO:Local step 500, global step 7948: loss 0.3384
[2019-03-27 04:42:27,938] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 500, global step 7948: learning rate 0.0000
[2019-03-27 04:42:27,978] A3C_AGENT_WORKER-Thread-10 INFO:Local step 500, global step 7967: loss -2.0010
[2019-03-27 04:42:27,984] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 500, global step 7967: learning rate 0.0000
[2019-03-27 04:42:27,995] A3C_AGENT_WORKER-Thread-22 INFO:Local step 500, global step 7973: loss 7.0659
[2019-03-27 04:42:27,998] A3C_AGENT_WORKER-Thread-12 INFO:Local step 500, global step 7974: loss 10.0372
[2019-03-27 04:42:28,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 500, global step 7973: learning rate 0.0000
[2019-03-27 04:42:28,003] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 500, global step 7975: learning rate 0.0000
[2019-03-27 04:42:28,021] A3C_AGENT_WORKER-Thread-13 INFO:Local step 500, global step 7983: loss 4.5893
[2019-03-27 04:42:28,024] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 500, global step 7984: learning rate 0.0000
[2019-03-27 04:42:28,085] A3C_AGENT_WORKER-Thread-20 INFO:Local step 500, global step 8011: loss -1.7438
[2019-03-27 04:42:28,087] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 500, global step 8011: learning rate 0.0000
[2019-03-27 04:42:28,087] A3C_AGENT_WORKER-Thread-18 INFO:Local step 500, global step 8012: loss 4.5625
[2019-03-27 04:42:28,094] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 500, global step 8013: learning rate 0.0000
[2019-03-27 04:42:28,132] A3C_AGENT_WORKER-Thread-16 INFO:Local step 500, global step 8032: loss -0.4253
[2019-03-27 04:42:28,134] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 500, global step 8032: learning rate 0.0000
[2019-03-27 04:42:28,138] A3C_AGENT_WORKER-Thread-9 INFO:Local step 500, global step 8033: loss 5.4188
[2019-03-27 04:42:28,142] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 500, global step 8035: learning rate 0.0000
[2019-03-27 04:42:28,168] A3C_AGENT_WORKER-Thread-15 INFO:Local step 500, global step 8051: loss 11.1697
[2019-03-27 04:42:28,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 500, global step 8051: learning rate 0.0000
[2019-03-27 04:42:28,177] A3C_AGENT_WORKER-Thread-19 INFO:Local step 500, global step 8052: loss -0.3763
[2019-03-27 04:42:28,180] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 500, global step 8052: learning rate 0.0000
[2019-03-27 04:42:28,192] A3C_AGENT_WORKER-Thread-17 INFO:Local step 500, global step 8058: loss -0.3942
[2019-03-27 04:42:28,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 500, global step 8058: learning rate 0.0000
[2019-03-27 04:42:29,750] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [0.23068237 0.17169209 0.28506598 0.16838814 0.14417139], sum to 1.0000
[2019-03-27 04:42:29,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7216
[2019-03-27 04:42:29,761] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.63333333333333, 84.33333333333333, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 465604.3798613076, 465604.379861307, 226926.5676157153], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 328200.0000, 
sim time next is 328800.0000, 
raw observation next is [21.56666666666667, 84.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 464018.2496285513, 464018.2496285513, 226601.1788873235], 
processed observation next is [0.0, 0.8260869565217391, 0.22116903633491333, 0.8466666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.12889395823015315, 0.12889395823015315, 0.33821071475719927], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.48816812], dtype=float32), 0.07482523]. 
=============================================
[2019-03-27 04:42:32,362] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [0.22344162 0.20806952 0.3474944  0.09578793 0.12520653], sum to 1.0000
[2019-03-27 04:42:32,369] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6980
[2019-03-27 04:42:32,476] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.25, 79.0, 1.0, 2.0, 0.3317865074071103, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 541376.6389450685, 541376.6389450685, 170069.5276094996], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [21.33333333333333, 78.66666666666667, 1.0, 2.0, 0.1796978003598696, 0.0, 2.0, 0.0, 1.0, 1.0, 0.3295171684787195, 6.911199999999999, 6.9112, 168.912956510431, 585056.653369583, 585056.6533695835, 198605.1490192412], 
processed observation next is [1.0, 0.34782608695652173, 0.21011058451816728, 0.7866666666666667, 1.0, 1.0, 0.011684096819119982, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.1823380103399018, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16251573704710637, 0.16251573704710653, 0.29642559555110626], 
reward next is 0.7036, 
noisyNet noise sample is [array([0.86809194], dtype=float32), -0.28045103]. 
=============================================
[2019-03-27 04:42:39,429] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.2986215  0.1799814  0.32955274 0.12527816 0.06656627], sum to 1.0000
[2019-03-27 04:42:39,442] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1071
[2019-03-27 04:42:39,451] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 904785.706677917 W.
[2019-03-27 04:42:39,571] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.9, 53.0, 1.0, 2.0, 0.5512413918422174, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 904785.706677917, 904785.7066779176, 205537.3456885474], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 489600.0000, 
sim time next is 490200.0000, 
raw observation next is [24.85, 53.16666666666667, 1.0, 2.0, 0.5712106865926966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 937928.0739160028, 937928.0739160033, 209565.589536407], 
processed observation next is [1.0, 0.6956521739130435, 0.37677725118483424, 0.5316666666666667, 1.0, 1.0, 0.48338636938879104, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26053557608777855, 0.2605355760877787, 0.31278446199463733], 
reward next is 0.6872, 
noisyNet noise sample is [array([0.13094513], dtype=float32), -2.0609055]. 
=============================================
[2019-03-27 04:42:44,660] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [0.3373113  0.1484167  0.38208175 0.09349731 0.03869294], sum to 1.0000
[2019-03-27 04:42:44,669] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5519
[2019-03-27 04:42:44,675] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.63333333333333, 61.83333333333334, 1.0, 2.0, 0.3273952235673674, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6005898946521053, 6.9112, 6.9112, 168.912956510431, 1067054.886089168, 1067054.886089168, 243639.8982610381], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 575400.0000, 
sim time next is 576000.0000, 
raw observation next is [23.6, 62.0, 1.0, 2.0, 0.3290044446195113, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6035445407024566, 6.9112, 6.9112, 168.912956510431, 1072312.234691548, 1072312.234691548, 244279.3262148439], 
processed observation next is [1.0, 0.6956521739130435, 0.3175355450236968, 0.62, 1.0, 1.0, 0.19157162002350756, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5165177325639714, 0.0, 0.0, 0.8294399451523027, 0.2978645096365411, 0.2978645096365411, 0.3645960092758864], 
reward next is 0.6354, 
noisyNet noise sample is [array([0.00436289], dtype=float32), -0.28378814]. 
=============================================
[2019-03-27 04:42:44,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[5.653172 ]
 [5.488637 ]
 [5.5603886]
 [5.3415985]
 [5.3426623]], R is [[6.28407907]
 [6.8575964 ]
 [6.78902054]
 [6.72113037]
 [6.65391922]].
[2019-03-27 04:42:45,631] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1000, global step 15904: loss 4.5815
[2019-03-27 04:42:45,632] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1000, global step 15904: learning rate 0.0000
[2019-03-27 04:42:45,635] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1000, global step 15904: loss 1.7608
[2019-03-27 04:42:45,640] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1000, global step 15905: learning rate 0.0000
[2019-03-27 04:42:45,687] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1000, global step 15926: loss 21.7963
[2019-03-27 04:42:45,692] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1000, global step 15928: learning rate 0.0000
[2019-03-27 04:42:45,713] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1000, global step 15941: loss 14.9079
[2019-03-27 04:42:45,715] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1000, global step 15941: learning rate 0.0000
[2019-03-27 04:42:45,715] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1000, global step 15941: loss -0.4536
[2019-03-27 04:42:45,720] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1000, global step 15941: learning rate 0.0000
[2019-03-27 04:42:45,770] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1000, global step 15964: loss -0.4870
[2019-03-27 04:42:45,772] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1000, global step 15965: learning rate 0.0000
[2019-03-27 04:42:45,782] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1000, global step 15969: loss 7.0802
[2019-03-27 04:42:45,784] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1000, global step 15969: learning rate 0.0000
[2019-03-27 04:42:45,791] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1000, global step 15974: loss 9.6189
[2019-03-27 04:42:45,792] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1000, global step 15974: learning rate 0.0000
[2019-03-27 04:42:45,832] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1000, global step 15990: loss 1.7253
[2019-03-27 04:42:45,835] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1000, global step 15991: learning rate 0.0000
[2019-03-27 04:42:45,838] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1000, global step 15992: loss 11.1470
[2019-03-27 04:42:45,840] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1000, global step 15993: learning rate 0.0000
[2019-03-27 04:42:45,873] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1000, global step 16005: loss 4.5715
[2019-03-27 04:42:45,875] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1000, global step 16005: learning rate 0.0000
[2019-03-27 04:42:45,912] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1000, global step 16025: loss -0.8712
[2019-03-27 04:42:45,914] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1000, global step 16026: learning rate 0.0000
[2019-03-27 04:42:45,928] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1000, global step 16034: loss 3.6434
[2019-03-27 04:42:45,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1000, global step 16035: learning rate 0.0000
[2019-03-27 04:42:45,933] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1000, global step 16035: loss 3.2304
[2019-03-27 04:42:45,935] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1000, global step 16035: learning rate 0.0000
[2019-03-27 04:42:45,948] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1000, global step 16041: loss -0.0623
[2019-03-27 04:42:45,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1000, global step 16042: learning rate 0.0000
[2019-03-27 04:42:46,164] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1000, global step 16142: loss 11.0055
[2019-03-27 04:42:46,166] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1000, global step 16142: learning rate 0.0000
[2019-03-27 04:42:50,274] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [0.5050851  0.21964888 0.21546048 0.04519773 0.01460772], sum to 1.0000
[2019-03-27 04:42:50,283] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1288
[2019-03-27 04:42:50,389] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.31666666666667, 66.66666666666667, 1.0, 1.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2287030383849102, 6.911199999999999, 6.9112, 168.912956510431, 408306.4379170497, 408306.4379170503, 177914.8714066057], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 672600.0000, 
sim time next is 673200.0000, 
raw observation next is [22.1, 68.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.458018048238418, 6.911200000000001, 6.9112, 168.912956510431, 409016.1123429117, 409016.1123429111, 146820.3093047403], 
processed observation next is [1.0, 0.8260869565217391, 0.24644549763033188, 0.68, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.33904640029075367, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11361558676191992, 0.11361558676191974, 0.2191347900070751], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74057335], dtype=float32), -1.4098921]. 
=============================================
[2019-03-27 04:42:59,188] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [0.5595366  0.29304832 0.06389767 0.07541878 0.00809868], sum to 1.0000
[2019-03-27 04:42:59,196] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8239
[2019-03-27 04:42:59,309] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.76666666666667, 63.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5275073618297955, 6.911199999999999, 6.9112, 168.912956510431, 464338.8374976719, 464338.8374976725, 155633.7459838009], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 825000.0000, 
sim time next is 825600.0000, 
raw observation next is [24.73333333333333, 63.00000000000001, 1.0, 1.0, 0.2883236200248691, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 462102.2383976206, 462102.2383976199, 164404.9899748857], 
processed observation next is [0.0, 0.5652173913043478, 0.3712480252764612, 0.6300000000000001, 1.0, 0.5, 0.14255857834321578, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12836173288822794, 0.12836173288822775, 0.24538058205206822], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8868316], dtype=float32), 1.2838237]. 
=============================================
[2019-03-27 04:43:03,283] A3C_AGENT_WORKER-Thread-2 INFO:Local step 1500, global step 23868: loss 4.6822
[2019-03-27 04:43:03,289] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 1500, global step 23869: learning rate 0.0000
[2019-03-27 04:43:03,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 1500, global step 23912: loss 14.9320
[2019-03-27 04:43:03,387] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 1500, global step 23912: learning rate 0.0000
[2019-03-27 04:43:03,425] A3C_AGENT_WORKER-Thread-22 INFO:Local step 1500, global step 23931: loss 10.0382
[2019-03-27 04:43:03,428] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 1500, global step 23932: learning rate 0.0000
[2019-03-27 04:43:03,437] A3C_AGENT_WORKER-Thread-14 INFO:Local step 1500, global step 23935: loss 14.4125
[2019-03-27 04:43:03,438] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 1500, global step 23936: learning rate 0.0000
[2019-03-27 04:43:03,485] A3C_AGENT_WORKER-Thread-21 INFO:Local step 1500, global step 23958: loss 7.0785
[2019-03-27 04:43:03,488] A3C_AGENT_WORKER-Thread-11 INFO:Local step 1500, global step 23958: loss 5.4042
[2019-03-27 04:43:03,490] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 1500, global step 23958: learning rate 0.0000
[2019-03-27 04:43:03,493] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 1500, global step 23959: learning rate 0.0000
[2019-03-27 04:43:03,504] A3C_AGENT_WORKER-Thread-19 INFO:Local step 1500, global step 23966: loss 4.7438
[2019-03-27 04:43:03,509] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 1500, global step 23968: learning rate 0.0000
[2019-03-27 04:43:03,538] A3C_AGENT_WORKER-Thread-20 INFO:Local step 1500, global step 23977: loss 1.8142
[2019-03-27 04:43:03,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 1500, global step 23980: learning rate 0.0000
[2019-03-27 04:43:03,548] A3C_AGENT_WORKER-Thread-13 INFO:Local step 1500, global step 23983: loss 10.5026
[2019-03-27 04:43:03,549] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 1500, global step 23983: learning rate 0.0000
[2019-03-27 04:43:03,588] A3C_AGENT_WORKER-Thread-15 INFO:Local step 1500, global step 23999: loss 8.5836
[2019-03-27 04:43:03,591] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 1500, global step 24000: learning rate 0.0000
[2019-03-27 04:43:03,599] A3C_AGENT_WORKER-Thread-12 INFO:Local step 1500, global step 24000: loss 8.2591
[2019-03-27 04:43:03,601] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 1500, global step 24001: learning rate 0.0000
[2019-03-27 04:43:03,658] A3C_AGENT_WORKER-Thread-10 INFO:Local step 1500, global step 24033: loss 16.2943
[2019-03-27 04:43:03,661] A3C_AGENT_WORKER-Thread-16 INFO:Local step 1500, global step 24036: loss 4.4756
[2019-03-27 04:43:03,662] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 1500, global step 24035: learning rate 0.0000
[2019-03-27 04:43:03,665] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 1500, global step 24037: learning rate 0.0000
[2019-03-27 04:43:03,685] A3C_AGENT_WORKER-Thread-9 INFO:Local step 1500, global step 24046: loss 7.4691
[2019-03-27 04:43:03,687] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 1500, global step 24046: learning rate 0.0000
[2019-03-27 04:43:03,715] A3C_AGENT_WORKER-Thread-18 INFO:Local step 1500, global step 24057: loss 8.2926
[2019-03-27 04:43:03,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 1500, global step 24057: learning rate 0.0000
[2019-03-27 04:43:03,890] A3C_AGENT_WORKER-Thread-17 INFO:Local step 1500, global step 24136: loss 10.0690
[2019-03-27 04:43:03,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 1500, global step 24136: learning rate 0.0000
[2019-03-27 04:43:05,779] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-27 04:43:05,782] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:43:05,783] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:43:05,784] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:43:05,785] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:43:05,786] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:43:05,788] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:43:05,788] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:43:05,789] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:43:05,786] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:43:05,791] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:43:05,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run2
[2019-03-27 04:43:05,807] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run2
[2019-03-27 04:43:05,825] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run2
[2019-03-27 04:43:05,854] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run2
[2019-03-27 04:43:05,899] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run2
[2019-03-27 04:43:16,283] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:43:16,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.78333333333333, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6344797743616407, 6.911199999999999, 6.9112, 168.912956510431, 556139.2534148333, 556139.253414834, 171397.0930564283]
[2019-03-27 04:43:16,286] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:43:16,288] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.8510632  0.08500083 0.0256421  0.0367115  0.00158243], sampled 0.7669470915093141
[2019-03-27 04:43:29,540] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:43:29,541] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.16666666666667, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.728707797172664, 6.9112, 6.9112, 168.912956510431, 622347.1009788928, 622347.1009788928, 187985.1997620439]
[2019-03-27 04:43:29,541] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:43:29,543] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8132739e-01 6.7970589e-02 1.5680537e-02 3.4206845e-02 8.1463333e-04], sampled 0.6965011785498589
[2019-03-27 04:43:41,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:43:41,252] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.4, 87.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8082973383029463, 6.911200000000001, 6.9112, 168.912956510431, 679281.1079902063, 679281.1079902056, 203590.5799843827]
[2019-03-27 04:43:41,254] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:43:41,257] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.8596773e-01 6.5098159e-02 1.3293953e-02 3.4799360e-02 8.4084849e-04], sampled 0.8954783019962288
[2019-03-27 04:43:48,599] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:43:48,600] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.3, 57.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9707144540916763, 6.9112, 6.9112, 168.912956510431, 788381.2779165535, 788381.2779165535, 239942.2793983694]
[2019-03-27 04:43:48,601] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:43:48,602] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.8809356  0.06450137 0.01446606 0.03903243 0.00106456], sampled 0.020145785382111647
[2019-03-27 04:44:02,454] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:02,455] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.03333333333333, 49.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8856095291041252, 6.9112, 6.9112, 168.912956510431, 730145.8715645962, 730145.8715645962, 220079.7327116712]
[2019-03-27 04:44:02,456] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:44:02,462] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.8235229e-01 6.9374934e-02 1.4467616e-02 3.3015084e-02 7.9004018e-04], sampled 0.5013848152566607
[2019-03-27 04:44:04,100] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:04,103] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.28126652, 61.335922895, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.884508754655389, 6.9112, 6.9112, 168.912956510431, 732106.3297995852, 732106.3297995852, 219932.4120363753]
[2019-03-27 04:44:04,104] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:44:04,106] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7527931e-01 7.1552850e-02 2.6678082e-02 2.6104920e-02 3.8479097e-04], sampled 0.6405531370455073
[2019-03-27 04:44:05,752] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:05,754] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.10884405, 65.10108138666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8750821056585525, 6.9112, 6.9112, 168.912956510431, 725154.7291623061, 725154.7291623061, 217821.0431037782]
[2019-03-27 04:44:05,755] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:44:05,760] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [0.8755397  0.07107609 0.01438147 0.03791862 0.00108407], sampled 0.16055640498925905
[2019-03-27 04:44:37,817] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:37,818] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.37192814, 78.39107896, 1.0, 1.0, 0.2538526044723859, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4261381808590371, 6.911200000000001, 6.9112, 168.912956510431, 709442.7437153443, 709442.7437153436, 207071.0763558038]
[2019-03-27 04:44:37,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:44:37,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.8119918e-01 6.5629520e-02 2.5731675e-02 2.6773963e-02 6.6568278e-04], sampled 0.8984984127113484
[2019-03-27 04:44:41,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:41,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.5, 95.0, 1.0, 2.0, 0.5709308179899262, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9655890085656645, 6.911200000000001, 6.9112, 168.9129565094497, 1596248.390221388, 1596248.390221388, 343757.139503243]
[2019-03-27 04:44:41,489] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:44:41,492] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [0.850371   0.08613706 0.01659957 0.04551693 0.00137546], sampled 0.6270788656802793
[2019-03-27 04:44:41,493] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1596248.390221388 W.
[2019-03-27 04:44:42,643] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:42,646] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.7, 93.0, 1.0, 2.0, 0.6758201984538172, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944462.9568284159, 944462.9568284159, 215716.2294866717]
[2019-03-27 04:44:42,648] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:44:42,652] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.849062   0.08505777 0.02987131 0.03473434 0.00127466], sampled 0.9386688795705705
[2019-03-27 04:44:49,119] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02204102], dtype=float32), 0.029217608]
[2019-03-27 04:44:49,120] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.635630255, 83.06850723, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5785729748655541, 6.911200000000001, 6.9112, 168.912956510431, 506068.740388884, 506068.7403888833, 162833.2012888253]
[2019-03-27 04:44:49,121] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:44:49,123] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [0.8808926  0.06908075 0.01831075 0.03050428 0.00121164], sampled 0.30423864729012073
[2019-03-27 04:44:55,007] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7161.5690 2946390874.6241 1308.0000
[2019-03-27 04:44:55,014] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 6560.5552 3112839783.3364 1893.0000
[2019-03-27 04:44:55,020] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6298.6513 3190747693.1302 2334.0000
[2019-03-27 04:44:55,230] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 6478.4411 3326698163.1262 2054.0000
[2019-03-27 04:44:55,236] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7001.4366 2999129249.3975 1502.0000
[2019-03-27 04:44:56,250] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 25000, evaluation results [25000.0, 6478.441126555401, 3326698163.1262393, 2054.0, 6560.555209650073, 3112839783.336445, 1893.0, 7161.569014558526, 2946390874.624123, 1308.0, 6298.651330720794, 3190747693.13023, 2334.0, 7001.436605180524, 2999129249.3974786, 1502.0]
[2019-03-27 04:45:03,288] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.4143486e-01 2.7444040e-02 5.2860272e-03 2.5742300e-02 9.2778544e-05], sum to 1.0000
[2019-03-27 04:45:03,304] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5109
[2019-03-27 04:45:03,425] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5249109113702334, 6.9112, 6.9112, 168.912956510431, 462741.0287458164, 462741.0287458164, 155266.995938927], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1054800.0000, 
sim time next is 1055400.0000, 
raw observation next is [20.05, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5319984859748197, 6.9112, 6.9112, 168.912956510431, 469305.3859568174, 469305.3859568174, 156193.6776021776], 
processed observation next is [1.0, 0.21739130434782608, 0.14928909952606645, 0.9583333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4292664463107557, 0.0, 0.0, 0.8294399451523027, 0.13036260721022705, 0.13036260721022705, 0.23312489194354866], 
reward next is 0.7669, 
noisyNet noise sample is [array([1.3900113], dtype=float32), 2.3043828]. 
=============================================
[2019-03-27 04:45:11,572] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2000, global step 31864: loss 2.0770
[2019-03-27 04:45:11,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2000, global step 31866: learning rate 0.0000
[2019-03-27 04:45:11,596] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2000, global step 31873: loss -4.3005
[2019-03-27 04:45:11,598] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2000, global step 31873: learning rate 0.0000
[2019-03-27 04:45:11,654] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2000, global step 31902: loss 3.8653
[2019-03-27 04:45:11,660] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2000, global step 31904: learning rate 0.0000
[2019-03-27 04:45:11,762] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2000, global step 31948: loss 4.1451
[2019-03-27 04:45:11,766] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2000, global step 31948: learning rate 0.0000
[2019-03-27 04:45:11,814] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2000, global step 31973: loss 4.0484
[2019-03-27 04:45:11,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2000, global step 31973: learning rate 0.0000
[2019-03-27 04:45:11,820] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2000, global step 31974: loss 3.3093
[2019-03-27 04:45:11,824] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2000, global step 31975: learning rate 0.0000
[2019-03-27 04:45:11,845] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2000, global step 31987: loss 4.2689
[2019-03-27 04:45:11,848] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2000, global step 31987: learning rate 0.0000
[2019-03-27 04:45:11,854] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2000, global step 31991: loss 4.5225
[2019-03-27 04:45:11,856] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2000, global step 31991: learning rate 0.0000
[2019-03-27 04:45:11,869] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2000, global step 31996: loss 5.9704
[2019-03-27 04:45:11,872] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2000, global step 31998: loss -1.6534
[2019-03-27 04:45:11,872] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2000, global step 31998: learning rate 0.0000
[2019-03-27 04:45:11,879] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2000, global step 31998: learning rate 0.0000
[2019-03-27 04:45:11,879] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2000, global step 32000: loss 3.5767
[2019-03-27 04:45:11,883] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2000, global step 32000: learning rate 0.0000
[2019-03-27 04:45:11,884] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2000, global step 32000: loss 1.6417
[2019-03-27 04:45:11,886] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2000, global step 32000: learning rate 0.0000
[2019-03-27 04:45:11,912] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2000, global step 32010: loss 2.3573
[2019-03-27 04:45:11,915] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2000, global step 32011: learning rate 0.0000
[2019-03-27 04:45:11,932] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2000, global step 32021: loss -1.3146
[2019-03-27 04:45:11,935] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2000, global step 32021: learning rate 0.0000
[2019-03-27 04:45:12,155] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2000, global step 32122: loss 2.7458
[2019-03-27 04:45:12,157] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2000, global step 32122: learning rate 0.0000
[2019-03-27 04:45:12,202] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2000, global step 32144: loss 3.7919
[2019-03-27 04:45:12,205] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2000, global step 32145: learning rate 0.0000
[2019-03-27 04:45:12,841] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.0488923e-01 7.1598843e-02 2.0402875e-03 2.1367278e-02 1.0439295e-04], sum to 1.0000
[2019-03-27 04:45:12,853] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3819
[2019-03-27 04:45:12,856] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.15, 89.83333333333333, 1.0, 2.0, 0.3396741110653997, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 528439.9649380359, 528439.9649380354, 169027.5581453393], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1216200.0000, 
sim time next is 1216800.0000, 
raw observation next is [22.1, 90.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6055001887173235, 6.9112, 6.9112, 168.912956510431, 527088.4082916664, 527088.4082916664, 166922.7919705075], 
processed observation next is [1.0, 0.08695652173913043, 0.24644549763033188, 0.9, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.5189026691674676, 0.0, 0.0, 0.8294399451523027, 0.1464134467476851, 0.1464134467476851, 0.24913849547836942], 
reward next is 0.7509, 
noisyNet noise sample is [array([0.6632201], dtype=float32), -2.9727006]. 
=============================================
[2019-03-27 04:45:15,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.8019770e-01 2.0606609e-02 3.1412381e-03 9.6000664e-02 5.3836091e-05], sum to 1.0000
[2019-03-27 04:45:15,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0450
[2019-03-27 04:45:15,016] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1300434.47547282 W.
[2019-03-27 04:45:15,132] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.36666666666667, 72.83333333333333, 1.0, 2.0, 0.4651917023877595, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7821627010137385, 6.911199999999999, 6.9112, 168.912956510431, 1300434.47547282, 1300434.475472821, 285572.0942429673], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1255800.0000, 
sim time next is 1256400.0000, 
raw observation next is [28.4, 73.0, 1.0, 2.0, 1.032627943447711, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1443442.955936991, 1443442.955936991, 309022.3450893322], 
processed observation next is [1.0, 0.5652173913043478, 0.5450236966824644, 0.73, 1.0, 1.0, 1.039310775238206, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.4009563766491641, 0.4009563766491641, 0.4612273807303466], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8364102], dtype=float32), -0.6511655]. 
=============================================
[2019-03-27 04:45:16,356] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4897252e-01 3.6291359e-03 7.7842525e-03 3.9612714e-02 1.3769477e-06], sum to 1.0000
[2019-03-27 04:45:16,366] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8608
[2019-03-27 04:45:16,370] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7904125642967453, 6.911200000000001, 6.9112, 168.912956510431, 663133.1128216296, 663133.112821629, 199884.8684459215], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1277400.0000, 
sim time next is 1278000.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7872203619257524, 6.9112, 6.9112, 168.912956510431, 660905.2686308747, 660905.2686308747, 199246.4031150967], 
processed observation next is [1.0, 0.8260869565217391, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7405126364948199, 0.0, 0.0, 0.8294399451523027, 0.18358479684190965, 0.18358479684190965, 0.29738269121656224], 
reward next is 0.7026, 
noisyNet noise sample is [array([1.1647092], dtype=float32), -0.17059638]. 
=============================================
[2019-03-27 04:45:16,389] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[41.65611 ]
 [41.53146 ]
 [41.08068 ]
 [40.942455]
 [40.938717]], R is [[41.61572647]
 [41.90123367]
 [42.18270493]
 [42.4601326 ]
 [42.7340126 ]].
[2019-03-27 04:45:21,571] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9823391e-01 1.1497695e-03 5.5017725e-05 5.5685139e-04 4.4301232e-06], sum to 1.0000
[2019-03-27 04:45:21,582] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1589
[2019-03-27 04:45:21,700] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5755125517745993, 6.911199999999999, 6.9112, 168.912956510431, 504488.8921073263, 504488.8921073269, 162357.991527563], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1363200.0000, 
sim time next is 1363800.0000, 
raw observation next is [21.06666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.578302675604793, 6.9112, 6.9112, 168.912956510431, 506670.1759969085, 506670.1759969085, 162771.8271839794], 
processed observation next is [1.0, 0.782608695652174, 0.19747235387045833, 0.9383333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4857349702497475, 0.0, 0.0, 0.8294399451523027, 0.1407417155546968, 0.1407417155546968, 0.24294302564773043], 
reward next is 0.7571, 
noisyNet noise sample is [array([-0.67113495], dtype=float32), -0.428834]. 
=============================================
[2019-03-27 04:45:27,322] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.57099438e-01 2.86671356e-03 1.14589275e-05 4.00219969e-02
 4.88518310e-07], sum to 1.0000
[2019-03-27 04:45:27,331] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7202
[2019-03-27 04:45:27,446] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.93333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6376600944954386, 6.9112, 6.9112, 168.912956510431, 551737.6144472585, 551737.6144472585, 172051.0179637108], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1466400.0000, 
sim time next is 1467000.0000, 
raw observation next is [21.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6351078090603317, 6.911199999999999, 6.9112, 168.912956510431, 549730.4218779436, 549730.4218779443, 171635.2249682225], 
processed observation next is [0.0, 1.0, 0.23696682464454974, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.555009523244307, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15270289496609543, 0.15270289496609563, 0.2561719775645112], 
reward next is 0.7438, 
noisyNet noise sample is [array([-0.04871492], dtype=float32), 0.701252]. 
=============================================
[2019-03-27 04:45:27,471] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[49.76085 ]
 [49.738613]
 [49.708958]
 [49.69222 ]
 [49.66882 ]], R is [[50.02830505]
 [50.27122879]
 [50.51072693]
 [50.74731445]
 [50.98177719]].
[2019-03-27 04:45:29,417] A3C_AGENT_WORKER-Thread-2 INFO:Local step 2500, global step 39846: loss 1.5016
[2019-03-27 04:45:29,418] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 2500, global step 39846: learning rate 0.0000
[2019-03-27 04:45:29,495] A3C_AGENT_WORKER-Thread-22 INFO:Local step 2500, global step 39879: loss 1.4530
[2019-03-27 04:45:29,497] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 2500, global step 39880: learning rate 0.0000
[2019-03-27 04:45:29,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 2500, global step 39897: loss 1.3538
[2019-03-27 04:45:29,527] A3C_AGENT_WORKER-Thread-13 INFO:Local step 2500, global step 39897: loss 1.2719
[2019-03-27 04:45:29,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 2500, global step 39897: learning rate 0.0000
[2019-03-27 04:45:29,530] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 2500, global step 39898: learning rate 0.0000
[2019-03-27 04:45:29,590] A3C_AGENT_WORKER-Thread-19 INFO:Local step 2500, global step 39921: loss 1.2396
[2019-03-27 04:45:29,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 2500, global step 39924: learning rate 0.0000
[2019-03-27 04:45:29,727] A3C_AGENT_WORKER-Thread-16 INFO:Local step 2500, global step 39981: loss 3.0101
[2019-03-27 04:45:29,731] A3C_AGENT_WORKER-Thread-20 INFO:Local step 2500, global step 39981: loss 1.3048
[2019-03-27 04:45:29,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 2500, global step 39981: learning rate 0.0000
[2019-03-27 04:45:29,733] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 2500, global step 39982: learning rate 0.0000
[2019-03-27 04:45:29,744] A3C_AGENT_WORKER-Thread-21 INFO:Local step 2500, global step 39987: loss 1.3697
[2019-03-27 04:45:29,745] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 2500, global step 39987: learning rate 0.0000
[2019-03-27 04:45:29,769] A3C_AGENT_WORKER-Thread-15 INFO:Local step 2500, global step 39997: loss 1.2838
[2019-03-27 04:45:29,772] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 2500, global step 39997: learning rate 0.0000
[2019-03-27 04:45:29,798] A3C_AGENT_WORKER-Thread-18 INFO:Local step 2500, global step 40009: loss 1.1452
[2019-03-27 04:45:29,804] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 2500, global step 40010: learning rate 0.0000
[2019-03-27 04:45:29,810] A3C_AGENT_WORKER-Thread-3 INFO:Local step 2500, global step 40016: loss 1.3585
[2019-03-27 04:45:29,812] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 2500, global step 40016: learning rate 0.0000
[2019-03-27 04:45:29,818] A3C_AGENT_WORKER-Thread-12 INFO:Local step 2500, global step 40018: loss 1.2373
[2019-03-27 04:45:29,820] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 2500, global step 40018: learning rate 0.0000
[2019-03-27 04:45:29,878] A3C_AGENT_WORKER-Thread-9 INFO:Local step 2500, global step 40045: loss 1.3237
[2019-03-27 04:45:29,882] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 2500, global step 40048: learning rate 0.0000
[2019-03-27 04:45:29,952] A3C_AGENT_WORKER-Thread-14 INFO:Local step 2500, global step 40079: loss 1.1469
[2019-03-27 04:45:29,953] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 2500, global step 40079: learning rate 0.0000
[2019-03-27 04:45:30,016] A3C_AGENT_WORKER-Thread-17 INFO:Local step 2500, global step 40108: loss 1.1589
[2019-03-27 04:45:30,018] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 2500, global step 40109: learning rate 0.0000
[2019-03-27 04:45:30,051] A3C_AGENT_WORKER-Thread-10 INFO:Local step 2500, global step 40124: loss 2.6160
[2019-03-27 04:45:30,055] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 2500, global step 40125: learning rate 0.0000
[2019-03-27 04:45:33,003] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9700791e-01 1.8631861e-03 1.5967740e-05 1.1128330e-03 7.9131269e-08], sum to 1.0000
[2019-03-27 04:45:33,016] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8224
[2019-03-27 04:45:33,023] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6083684576006204, 6.911199999999999, 6.9112, 168.912956510431, 529303.1592968385, 529303.159296839, 167369.5337922014], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1552800.0000, 
sim time next is 1553400.0000, 
raw observation next is [22.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6066623937632847, 6.9112, 6.9112, 168.912956510431, 527998.1464570065, 527998.1464570065, 167103.3468733781], 
processed observation next is [0.0, 1.0, 0.2417061611374408, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5203199923942495, 0.0, 0.0, 0.8294399451523027, 0.1466661517936129, 0.1466661517936129, 0.249407980408027], 
reward next is 0.7506, 
noisyNet noise sample is [array([-2.1040773], dtype=float32), -1.4631866]. 
=============================================
[2019-03-27 04:45:34,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9960214e-01 1.3197541e-04 1.4014431e-07 2.6583625e-04 9.0556906e-10], sum to 1.0000
[2019-03-27 04:45:34,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8008
[2019-03-27 04:45:34,603] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.41666666666667, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6918610410799556, 6.911199999999999, 6.9112, 168.912956510431, 598482.06138325, 598482.0613832506, 181252.3715899081], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1584600.0000, 
sim time next is 1585200.0000, 
raw observation next is [23.43333333333333, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.849825846468766, 6.9112, 6.9112, 168.912956510431, 734962.9368181371, 734962.9368181371, 212598.2619320229], 
processed observation next is [1.0, 0.34782608695652173, 0.30963665086887826, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.816860788376544, 0.0, 0.0, 0.8294399451523027, 0.20415637133837142, 0.20415637133837142, 0.31731083870451177], 
reward next is 0.6827, 
noisyNet noise sample is [array([0.03576821], dtype=float32), -0.10451934]. 
=============================================
[2019-03-27 04:45:35,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999356e-01 2.5842917e-06 6.9971591e-08 3.7743998e-06 2.4466459e-10], sum to 1.0000
[2019-03-27 04:45:35,533] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8745
[2019-03-27 04:45:35,538] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1227517.42478658 W.
[2019-03-27 04:45:35,654] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.66666666666667, 85.0, 1.0, 2.0, 0.4106767928836681, 1.0, 1.0, 0.4106767928836681, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1227517.42478658, 1227517.42478658, 284154.4372702619], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1593600.0000, 
sim time next is 1594200.0000, 
raw observation next is [23.68333333333333, 85.0, 1.0, 2.0, 0.4162844555454872, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7283031849308224, 6.9112, 6.9112, 168.912956510431, 1252288.956085154, 1252288.956085154, 273765.1341915478], 
processed observation next is [1.0, 0.43478260869565216, 0.32148499210110576, 0.85, 1.0, 1.0, 0.2967282596933581, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.6686624206473444, 0.0, 0.0, 0.8294399451523027, 0.3478580433569872, 0.3478580433569872, 0.40860467789783256], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3360174], dtype=float32), -1.1013681]. 
=============================================
[2019-03-27 04:45:39,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999642e-01 1.2896338e-06 1.7404968e-08 2.3214848e-06 8.9423434e-12], sum to 1.0000
[2019-03-27 04:45:39,968] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1601
[2019-03-27 04:45:39,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1204789.557612187 W.
[2019-03-27 04:45:39,989] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.2, 91.0, 1.0, 2.0, 0.4309993391824666, 1.0, 2.0, 0.4309993391824666, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1204789.557612187, 1204789.557612187, 280207.5480932454], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1677600.0000, 
sim time next is 1678200.0000, 
raw observation next is [25.31666666666667, 90.50000000000001, 1.0, 2.0, 0.9551068654481556, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1335013.182892533, 1335013.182892533, 285542.3213619876], 
processed observation next is [1.0, 0.43478260869565216, 0.39889415481832563, 0.9050000000000001, 1.0, 1.0, 0.9459118860821152, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.37083699524792585, 0.37083699524792585, 0.42618256919699643], 
reward next is 0.5738, 
noisyNet noise sample is [array([-0.5068299], dtype=float32), 0.8584218]. 
=============================================
[2019-03-27 04:45:46,751] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3000, global step 47822: loss 1.2935
[2019-03-27 04:45:46,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3000, global step 47822: learning rate 0.0000
[2019-03-27 04:45:46,785] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3000, global step 47838: loss 1.4581
[2019-03-27 04:45:46,787] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3000, global step 47839: learning rate 0.0000
[2019-03-27 04:45:46,825] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3000, global step 47856: loss 0.3389
[2019-03-27 04:45:46,827] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3000, global step 47856: learning rate 0.0000
[2019-03-27 04:45:46,874] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3000, global step 47876: loss 0.1805
[2019-03-27 04:45:46,876] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3000, global step 47876: learning rate 0.0000
[2019-03-27 04:45:46,891] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3000, global step 47885: loss 0.4885
[2019-03-27 04:45:46,896] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3000, global step 47885: learning rate 0.0000
[2019-03-27 04:45:46,989] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3000, global step 47934: loss 2.3312
[2019-03-27 04:45:46,992] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3000, global step 47934: learning rate 0.0000
[2019-03-27 04:45:47,008] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3000, global step 47942: loss 2.4399
[2019-03-27 04:45:47,011] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3000, global step 47942: learning rate 0.0000
[2019-03-27 04:45:47,099] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3000, global step 47984: loss 1.2257
[2019-03-27 04:45:47,102] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3000, global step 47984: learning rate 0.0000
[2019-03-27 04:45:47,109] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3000, global step 47990: loss 0.2161
[2019-03-27 04:45:47,112] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3000, global step 47990: loss 2.0689
[2019-03-27 04:45:47,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3000, global step 47990: learning rate 0.0000
[2019-03-27 04:45:47,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3000, global step 47993: learning rate 0.0000
[2019-03-27 04:45:47,326] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3000, global step 48091: loss 1.2465
[2019-03-27 04:45:47,326] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3000, global step 48091: loss 1.1369
[2019-03-27 04:45:47,327] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3000, global step 48091: learning rate 0.0000
[2019-03-27 04:45:47,329] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3000, global step 48091: learning rate 0.0000
[2019-03-27 04:45:47,351] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3000, global step 48101: loss 0.7373
[2019-03-27 04:45:47,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3000, global step 48101: learning rate 0.0000
[2019-03-27 04:45:47,369] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3000, global step 48108: loss 0.4028
[2019-03-27 04:45:47,370] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3000, global step 48109: loss 2.1706
[2019-03-27 04:45:47,373] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3000, global step 48110: learning rate 0.0000
[2019-03-27 04:45:47,375] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3000, global step 48111: learning rate 0.0000
[2019-03-27 04:45:47,459] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3000, global step 48151: loss 0.1693
[2019-03-27 04:45:47,463] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3000, global step 48152: learning rate 0.0000
[2019-03-27 04:45:47,488] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.6923954e-09 1.0547803e-09 3.6641318e-08 5.3019629e-12], sum to 1.0000
[2019-03-27 04:45:47,498] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4646
[2019-03-27 04:45:47,511] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.35, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5761800083567948, 6.9112, 6.9112, 168.912956510431, 504505.9850825375, 504505.9850825375, 162470.5238303182], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1801800.0000, 
sim time next is 1802400.0000, 
raw observation next is [21.36666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849531703286174, 6.9112, 6.9112, 168.912956510431, 511905.0107555073, 511905.0107555073, 163765.0412765337], 
processed observation next is [1.0, 0.8695652173913043, 0.21169036334913136, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49384532966904554, 0.0, 0.0, 0.8294399451523027, 0.14219583632097424, 0.14219583632097424, 0.2444254347410951], 
reward next is 0.7556, 
noisyNet noise sample is [array([0.39374775], dtype=float32), -1.304222]. 
=============================================
[2019-03-27 04:45:50,461] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 7.3857215e-10 8.1942159e-10 7.2048678e-10 8.9825082e-13], sum to 1.0000
[2019-03-27 04:45:50,473] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7838
[2019-03-27 04:45:50,481] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1574758.629386427 W.
[2019-03-27 04:45:50,486] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.5, 87.33333333333334, 1.0, 2.0, 0.5632542895848694, 1.0, 2.0, 0.5632542895848694, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1574758.629386427, 1574758.629386427, 321064.1417915331], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1855200.0000, 
sim time next is 1855800.0000, 
raw observation next is [25.6, 87.0, 1.0, 2.0, 0.3895353320199038, 1.0, 2.0, 0.3895353320199038, 1.0, 1.0, 0.6548654123610781, 6.9112, 6.9112, 170.5573041426782, 1633651.920133615, 1633651.920133615, 344159.9790862746], 
processed observation next is [1.0, 0.4782608695652174, 0.4123222748815167, 0.87, 1.0, 1.0, 0.2645004000239805, 1.0, 1.0, 0.2645004000239805, 1.0, 0.5, 0.5791041614159489, 0.0, 0.0, 0.8375144448122397, 0.45379220003711523, 0.45379220003711523, 0.5136716105765292], 
reward next is 0.4863, 
noisyNet noise sample is [array([0.5914229], dtype=float32), -0.33780017]. 
=============================================
[2019-03-27 04:45:51,358] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 04:45:51,360] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:45:51,361] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:45:51,363] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:45:51,362] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:45:51,365] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:45:51,365] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:45:51,365] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:45:51,367] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:45:51,369] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:45:51,372] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:45:51,381] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run3
[2019-03-27 04:45:51,381] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run3
[2019-03-27 04:45:51,382] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run3
[2019-03-27 04:45:51,382] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run3
[2019-03-27 04:45:51,457] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run3
[2019-03-27 04:45:59,120] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.05100349]
[2019-03-27 04:45:59,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.88333333333333, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4436298896297881, 6.911200000000001, 6.9112, 168.912956510431, 397823.2113646199, 397823.2113646193, 145109.9376455276]
[2019-03-27 04:45:59,122] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:45:59,125] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 4.98931696e-09 1.79386195e-09 6.51313226e-09
 1.12051965e-11], sampled 0.16894775653305394
[2019-03-27 04:46:15,681] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.05100349]
[2019-03-27 04:46:15,819] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.82089752666667, 88.21997814666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.985199415335565, 6.911200000000001, 6.9112, 168.912956510431, 826208.8441056203, 826208.8441056196, 244625.040929894]
[2019-03-27 04:46:15,821] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:46:15,824] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.1160096e-09 3.0226996e-10 1.5836604e-09 1.3903468e-12], sampled 0.388354205119554
[2019-03-27 04:46:25,478] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.05100349]
[2019-03-27 04:46:25,481] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.11666666666667, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7108533592550395, 6.911199999999999, 6.9112, 168.912956510431, 607931.3282278003, 607931.3282278009, 184690.9794820949]
[2019-03-27 04:46:25,481] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:46:25,484] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.9396883e-09 8.5360896e-10 3.7761825e-09 5.0583869e-12], sampled 0.523821689033935
[2019-03-27 04:47:23,256] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.05100349]
[2019-03-27 04:47:23,256] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.71106853166667, 79.54510393499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8867301852265526, 6.9112, 6.9112, 168.912956510431, 733415.7073510683, 733415.7073510683, 220421.2934659862]
[2019-03-27 04:47:23,257] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:47:23,259] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.8973918e-10 6.7377652e-11 4.8860882e-10 2.2615072e-13], sampled 0.718525317977256
[2019-03-27 04:47:37,380] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.05100349]
[2019-03-27 04:47:37,381] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.7, 82.0, 1.0, 1.0, 0.626812879636282, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9128084053914, 875946.6791457287, 875946.6791457281, 205845.5835979952]
[2019-03-27 04:47:37,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:47:37,387] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.2938900e-09 2.0400255e-09 3.0098830e-09 5.5521503e-12], sampled 0.8830422291967556
[2019-03-27 04:47:37,389] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 875946.6791457287 W.
[2019-03-27 04:47:44,161] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7345.4910 3105571677.2473 2010.0000
[2019-03-27 04:47:45,264] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7925.2325 2989349426.6345 1566.0000
[2019-03-27 04:47:45,398] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8062.5406 2937714873.5162 1381.0000
[2019-03-27 04:47:45,419] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7287.4458 3319468000.8506 2143.0000
[2019-03-27 04:47:45,490] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7029.8849 3185088318.8672 2464.0000
[2019-03-27 04:47:46,504] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 50000, evaluation results [50000.0, 7287.445790887307, 3319468000.8506474, 2143.0, 7345.49097198557, 3105571677.247261, 2010.0, 8062.540634327665, 2937714873.516233, 1381.0, 7029.884949051707, 3185088318.867212, 2464.0, 7925.23248849257, 2989349426.634477, 1566.0]
[2019-03-27 04:47:49,503] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.1864999e-10 8.0136462e-12 9.3314956e-10 3.4009891e-14], sum to 1.0000
[2019-03-27 04:47:49,511] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9983
[2019-03-27 04:47:49,516] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8250740111225006, 6.9112, 6.9112, 168.912956510431, 698938.4954897553, 698938.4954897553, 207217.9772091468], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1929600.0000, 
sim time next is 1930200.0000, 
raw observation next is [25.55, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9260809534116705, 6.9112, 6.9112, 168.912956510431, 784310.8514507177, 784310.8514507177, 230112.432334672], 
processed observation next is [1.0, 0.34782608695652173, 0.40995260663507116, 0.8283333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9098548212337445, 0.0, 0.0, 0.8294399451523027, 0.21786412540297712, 0.21786412540297712, 0.34345139154428656], 
reward next is 0.6565, 
noisyNet noise sample is [array([1.8248726], dtype=float32), 1.7199664]. 
=============================================
[2019-03-27 04:47:56,742] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.6485808e-11 3.5723191e-10 5.0114917e-09 5.5987014e-14], sum to 1.0000
[2019-03-27 04:47:56,752] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7663
[2019-03-27 04:47:56,758] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.36666666666667, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8373365435123884, 6.9112, 6.9112, 168.912956510431, 696369.2291284859, 696369.2291284859, 209567.8058918614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2049600.0000, 
sim time next is 2050200.0000, 
raw observation next is [26.3, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8347775331567436, 6.911199999999999, 6.9112, 168.912956510431, 694654.6938360529, 694654.6938360535, 209028.6717598755], 
processed observation next is [0.0, 0.7391304347826086, 0.4454976303317536, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7985091867765165, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19295963717668135, 0.19295963717668152, 0.3119830921789186], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.8547866], dtype=float32), 1.142682]. 
=============================================
[2019-03-27 04:47:59,460] A3C_AGENT_WORKER-Thread-22 INFO:Local step 3500, global step 55861: loss 0.2666
[2019-03-27 04:47:59,463] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 3500, global step 55862: learning rate 0.0000
[2019-03-27 04:47:59,487] A3C_AGENT_WORKER-Thread-19 INFO:Local step 3500, global step 55873: loss 0.1654
[2019-03-27 04:47:59,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 3500, global step 55873: learning rate 0.0000
[2019-03-27 04:47:59,566] A3C_AGENT_WORKER-Thread-2 INFO:Local step 3500, global step 55907: loss 0.2760
[2019-03-27 04:47:59,567] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 3500, global step 55907: learning rate 0.0000
[2019-03-27 04:47:59,594] A3C_AGENT_WORKER-Thread-16 INFO:Local step 3500, global step 55922: loss 0.3103
[2019-03-27 04:47:59,601] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 3500, global step 55922: learning rate 0.0000
[2019-03-27 04:47:59,621] A3C_AGENT_WORKER-Thread-13 INFO:Local step 3500, global step 55928: loss 0.1474
[2019-03-27 04:47:59,625] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 3500, global step 55930: learning rate 0.0000
[2019-03-27 04:47:59,639] A3C_AGENT_WORKER-Thread-15 INFO:Local step 3500, global step 55938: loss 0.1817
[2019-03-27 04:47:59,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 3500, global step 55938: learning rate 0.0000
[2019-03-27 04:47:59,658] A3C_AGENT_WORKER-Thread-18 INFO:Local step 3500, global step 55946: loss 0.2078
[2019-03-27 04:47:59,660] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 3500, global step 55946: learning rate 0.0000
[2019-03-27 04:47:59,671] A3C_AGENT_WORKER-Thread-20 INFO:Local step 3500, global step 55949: loss 0.1701
[2019-03-27 04:47:59,675] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 3500, global step 55950: learning rate 0.0000
[2019-03-27 04:47:59,691] A3C_AGENT_WORKER-Thread-11 INFO:Local step 3500, global step 55963: loss 0.2686
[2019-03-27 04:47:59,693] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 3500, global step 55963: learning rate 0.0000
[2019-03-27 04:47:59,720] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.3541839e-09 2.1253682e-10 8.1783985e-10 4.3259802e-13], sum to 1.0000
[2019-03-27 04:47:59,730] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2014
[2019-03-27 04:47:59,853] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8003001531497285, 6.9112, 6.9112, 168.912956510431, 670354.8935108938, 670354.8935108938, 201885.5557535833], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2096400.0000, 
sim time next is 2097000.0000, 
raw observation next is [25.05, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8050028884582615, 6.911199999999999, 6.9112, 168.912956510431, 673513.5810254433, 673513.5810254439, 202839.0772853021], 
processed observation next is [0.0, 0.2608695652173913, 0.3862559241706162, 0.935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7621986444612944, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18708710584040092, 0.18708710584040106, 0.30274489147060013], 
reward next is 0.6973, 
noisyNet noise sample is [array([-0.5604664], dtype=float32), 1.2823281]. 
=============================================
[2019-03-27 04:47:59,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.11282 ]
 [65.042175]
 [64.96295 ]
 [64.89784 ]
 [64.82696 ]], R is [[65.23067474]
 [65.2770462 ]
 [65.32396698]
 [65.37073517]
 [65.41703796]].
[2019-03-27 04:47:59,878] A3C_AGENT_WORKER-Thread-21 INFO:Local step 3500, global step 55999: loss 0.2323
[2019-03-27 04:47:59,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 3500, global step 55999: learning rate 0.0000
[2019-03-27 04:47:59,992] A3C_AGENT_WORKER-Thread-17 INFO:Local step 3500, global step 56050: loss 0.2075
[2019-03-27 04:47:59,993] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 3500, global step 56051: learning rate 0.0000
[2019-03-27 04:48:00,035] A3C_AGENT_WORKER-Thread-3 INFO:Local step 3500, global step 56070: loss 0.1234
[2019-03-27 04:48:00,037] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 3500, global step 56072: learning rate 0.0000
[2019-03-27 04:48:00,044] A3C_AGENT_WORKER-Thread-9 INFO:Local step 3500, global step 56076: loss 0.1208
[2019-03-27 04:48:00,048] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 3500, global step 56076: learning rate 0.0000
[2019-03-27 04:48:00,051] A3C_AGENT_WORKER-Thread-12 INFO:Local step 3500, global step 56077: loss 0.1696
[2019-03-27 04:48:00,053] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 3500, global step 56077: learning rate 0.0000
[2019-03-27 04:48:00,151] A3C_AGENT_WORKER-Thread-14 INFO:Local step 3500, global step 56119: loss 0.1240
[2019-03-27 04:48:00,151] A3C_AGENT_WORKER-Thread-10 INFO:Local step 3500, global step 56120: loss 0.1489
[2019-03-27 04:48:00,153] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 3500, global step 56120: learning rate 0.0000
[2019-03-27 04:48:00,155] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 3500, global step 56121: learning rate 0.0000
[2019-03-27 04:48:01,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.7136445e-11 1.7078512e-12 4.2217172e-09 2.6571584e-14], sum to 1.0000
[2019-03-27 04:48:01,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6219
[2019-03-27 04:48:01,989] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.36666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9675335685551529, 6.9112, 6.9112, 168.912956510431, 783357.7214741973, 783357.7214741973, 239020.2049214881], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2139600.0000, 
sim time next is 2140200.0000, 
raw observation next is [29.2, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9659544423798512, 6.9112, 6.9112, 168.912956510431, 782465.6888332514, 782465.6888332514, 238647.5009255339], 
processed observation next is [0.0, 0.782608695652174, 0.5829383886255924, 0.795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9584810272925014, 0.0, 0.0, 0.8294399451523027, 0.2173515802314587, 0.2173515802314587, 0.3561902998888566], 
reward next is 0.6438, 
noisyNet noise sample is [array([-0.02830491], dtype=float32), 0.71688396]. 
=============================================
[2019-03-27 04:48:06,209] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8607878e-12 3.8212211e-12 1.4267706e-11 3.4668306e-14], sum to 1.0000
[2019-03-27 04:48:06,215] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5372
[2019-03-27 04:48:06,226] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1673039.55017946 W.
[2019-03-27 04:48:06,336] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.26666666666667, 68.0, 1.0, 2.0, 0.5983796562765966, 1.0, 2.0, 0.5983796562765966, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1673039.55017946, 1673039.550179459, 333659.2368856484], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2205600.0000, 
sim time next is 2206200.0000, 
raw observation next is [31.38333333333333, 67.5, 1.0, 2.0, 0.5967521351900027, 1.0, 2.0, 0.5967521351900027, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1668485.540330295, 1668485.540330295, 333060.554636351], 
processed observation next is [1.0, 0.5217391304347826, 0.6864139020537123, 0.675, 1.0, 1.0, 0.5141591990240996, 1.0, 1.0, 0.5141591990240996, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4634682056473042, 0.4634682056473042, 0.49710530542738957], 
reward next is 0.5029, 
noisyNet noise sample is [array([0.95237964], dtype=float32), -0.9803081]. 
=============================================
[2019-03-27 04:48:08,022] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.7207996e-12 1.6540910e-12 1.9534822e-10 2.1323530e-13], sum to 1.0000
[2019-03-27 04:48:08,032] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0515
[2019-03-27 04:48:08,039] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.48333333333333, 81.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9397187131381117, 6.9112, 6.9112, 168.912956510431, 765053.40405665, 765053.40405665, 232404.2128838691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2235000.0000, 
sim time next is 2235600.0000, 
raw observation next is [28.4, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9359355137862344, 6.9112, 6.9112, 168.912956510431, 762642.4945186689, 762642.4945186689, 231522.1584403801], 
processed observation next is [1.0, 0.9130434782608695, 0.5450236966824644, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9218725777880907, 0.0, 0.0, 0.8294399451523027, 0.2118451373662969, 0.2118451373662969, 0.34555546035877627], 
reward next is 0.6544, 
noisyNet noise sample is [array([-0.02989055], dtype=float32), -1.9262995]. 
=============================================
[2019-03-27 04:48:17,336] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4000, global step 63870: loss 3.1160
[2019-03-27 04:48:17,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4000, global step 63871: learning rate 0.0000
[2019-03-27 04:48:17,342] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4000, global step 63872: loss 6.4944
[2019-03-27 04:48:17,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4000, global step 63873: learning rate 0.0000
[2019-03-27 04:48:17,416] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4000, global step 63907: loss 3.9993
[2019-03-27 04:48:17,418] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4000, global step 63908: learning rate 0.0000
[2019-03-27 04:48:17,422] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4000, global step 63909: loss 4.5565
[2019-03-27 04:48:17,424] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4000, global step 63911: learning rate 0.0000
[2019-03-27 04:48:17,435] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4000, global step 63915: loss 4.8002
[2019-03-27 04:48:17,439] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4000, global step 63918: learning rate 0.0000
[2019-03-27 04:48:17,465] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4000, global step 63929: loss 6.1363
[2019-03-27 04:48:17,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4000, global step 63930: learning rate 0.0000
[2019-03-27 04:48:17,479] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4000, global step 63933: loss 3.1469
[2019-03-27 04:48:17,481] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4000, global step 63933: learning rate 0.0000
[2019-03-27 04:48:17,498] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4000, global step 63942: loss 1.3818
[2019-03-27 04:48:17,502] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4000, global step 63942: learning rate 0.0000
[2019-03-27 04:48:17,522] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4000, global step 63951: loss 1.1108
[2019-03-27 04:48:17,525] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4000, global step 63952: learning rate 0.0000
[2019-03-27 04:48:17,704] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4000, global step 64032: loss 4.0783
[2019-03-27 04:48:17,706] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4000, global step 64033: learning rate 0.0000
[2019-03-27 04:48:17,805] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4000, global step 64080: loss 3.7161
[2019-03-27 04:48:17,805] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4000, global step 64080: loss 5.3117
[2019-03-27 04:48:17,807] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4000, global step 64080: learning rate 0.0000
[2019-03-27 04:48:17,807] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4000, global step 64080: learning rate 0.0000
[2019-03-27 04:48:17,839] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4000, global step 64094: loss 5.9041
[2019-03-27 04:48:17,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4000, global step 64094: learning rate 0.0000
[2019-03-27 04:48:17,849] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4000, global step 64098: loss 3.6843
[2019-03-27 04:48:17,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4000, global step 64098: learning rate 0.0000
[2019-03-27 04:48:17,882] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4000, global step 64110: loss 4.1568
[2019-03-27 04:48:17,883] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4000, global step 64110: learning rate 0.0000
[2019-03-27 04:48:17,912] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4000, global step 64122: loss 3.7224
[2019-03-27 04:48:17,914] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4000, global step 64122: learning rate 0.0000
[2019-03-27 04:48:25,597] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8293464e-10 9.6914377e-10 3.1509479e-11 3.1015509e-12], sum to 1.0000
[2019-03-27 04:48:25,604] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0722
[2019-03-27 04:48:25,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1000581.670355886 W.
[2019-03-27 04:48:25,616] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.43333333333333, 93.66666666666667, 1.0, 2.0, 0.3579788069322292, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6116774314913497, 6.9112, 6.9112, 168.912956510431, 1000581.670355886, 1000581.670355886, 241162.9743539455], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2532000.0000, 
sim time next is 2532600.0000, 
raw observation next is [26.45, 93.5, 1.0, 2.0, 0.33647455126313, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5749573082377942, 6.911199999999999, 6.9112, 168.912956510431, 940448.8057733062, 940448.8057733068, 233302.880102348], 
processed observation next is [1.0, 0.30434782608695654, 0.45260663507109006, 0.935, 1.0, 1.0, 0.20057174850979514, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.48165525394852954, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2612357793814739, 0.2612357793814741, 0.34821325388410146], 
reward next is 0.6518, 
noisyNet noise sample is [array([-0.47602835], dtype=float32), 0.5369275]. 
=============================================
[2019-03-27 04:48:26,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8072788e-10 5.7975064e-10 4.4393128e-11 9.5234853e-12], sum to 1.0000
[2019-03-27 04:48:26,411] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4327
[2019-03-27 04:48:26,418] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1840179.444110367 W.
[2019-03-27 04:48:26,423] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.63333333333333, 78.66666666666667, 1.0, 2.0, 0.6581076585419697, 1.0, 1.0, 0.6581076585419697, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1840179.444110367, 1840179.444110367, 356705.5206285639], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2546400.0000, 
sim time next is 2547000.0000, 
raw observation next is [28.75, 78.0, 1.0, 2.0, 0.6547332709691696, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.989180965047264, 6.9112, 168.9124922219572, 1811786.509522736, 1756464.281084307, 375772.0197515209], 
processed observation next is [1.0, 0.4782608695652174, 0.561611374407583, 0.78, 1.0, 1.0, 0.5840159891194814, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00779809650472636, 0.0, 0.8294376652833441, 0.5032740304229822, 0.48790674474564083, 0.5608537608231655], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07793878], dtype=float32), -1.1047323]. 
=============================================
[2019-03-27 04:48:26,444] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[44.15864]
 [44.06009]
 [43.98463]
 [43.29887]
 [42.93551]], R is [[44.21285248]
 [43.77072525]
 [43.33301926]
 [42.89968872]
 [42.47069168]].
[2019-03-27 04:48:30,333] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 7.6032805e-11 7.4550357e-12 2.0419066e-12 1.7026601e-12], sum to 1.0000
[2019-03-27 04:48:30,340] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1002
[2019-03-27 04:48:30,345] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7353763714021609, 6.9112, 6.9112, 168.912956510431, 625845.1367824596, 625845.1367824596, 189225.6106154411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2611800.0000, 
sim time next is 2612400.0000, 
raw observation next is [23.76666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.73220718714058, 6.9112, 6.9112, 168.912956510431, 623238.8685320641, 623238.8685320641, 188629.1622829176], 
processed observation next is [0.0, 0.21739130434782608, 0.32543443917851517, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6734233989519268, 0.0, 0.0, 0.8294399451523027, 0.17312190792557336, 0.17312190792557336, 0.2815360631088322], 
reward next is 0.7185, 
noisyNet noise sample is [array([-0.18327376], dtype=float32), 0.30694008]. 
=============================================
[2019-03-27 04:48:30,779] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.5312927e-11 2.6270636e-10 3.7828779e-10 3.8575230e-11], sum to 1.0000
[2019-03-27 04:48:30,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2865
[2019-03-27 04:48:30,796] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7933190317751883, 6.911200000000001, 6.9112, 168.912956510431, 666383.3298784441, 666383.3298784435, 200494.4444706361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2629200.0000, 
sim time next is 2629800.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7937322508435586, 6.9112, 6.9112, 168.912956510431, 666730.5403852839, 666730.5403852839, 200578.8709068999], 
processed observation next is [0.0, 0.43478260869565216, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.748453964443364, 0.0, 0.0, 0.8294399451523027, 0.18520292788480108, 0.18520292788480108, 0.299371449114776], 
reward next is 0.7006, 
noisyNet noise sample is [array([-0.21465796], dtype=float32), -0.9493978]. 
=============================================
[2019-03-27 04:48:34,546] A3C_AGENT_WORKER-Thread-16 INFO:Local step 4500, global step 71798: loss 0.7240
[2019-03-27 04:48:34,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 4500, global step 71798: learning rate 0.0000
[2019-03-27 04:48:34,665] A3C_AGENT_WORKER-Thread-22 INFO:Local step 4500, global step 71855: loss 0.9159
[2019-03-27 04:48:34,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 4500, global step 71856: learning rate 0.0000
[2019-03-27 04:48:34,695] A3C_AGENT_WORKER-Thread-13 INFO:Local step 4500, global step 71870: loss 0.7718
[2019-03-27 04:48:34,699] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 4500, global step 71870: learning rate 0.0000
[2019-03-27 04:48:34,774] A3C_AGENT_WORKER-Thread-19 INFO:Local step 4500, global step 71904: loss 0.8753
[2019-03-27 04:48:34,777] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 4500, global step 71904: learning rate 0.0000
[2019-03-27 04:48:34,799] A3C_AGENT_WORKER-Thread-11 INFO:Local step 4500, global step 71915: loss 0.7354
[2019-03-27 04:48:34,801] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 4500, global step 71915: learning rate 0.0000
[2019-03-27 04:48:34,815] A3C_AGENT_WORKER-Thread-15 INFO:Local step 4500, global step 71922: loss 0.7637
[2019-03-27 04:48:34,816] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 4500, global step 71922: learning rate 0.0000
[2019-03-27 04:48:34,864] A3C_AGENT_WORKER-Thread-2 INFO:Local step 4500, global step 71947: loss 0.8021
[2019-03-27 04:48:34,876] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 4500, global step 71949: learning rate 0.0000
[2019-03-27 04:48:34,887] A3C_AGENT_WORKER-Thread-18 INFO:Local step 4500, global step 71956: loss 0.7248
[2019-03-27 04:48:34,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 4500, global step 71957: learning rate 0.0000
[2019-03-27 04:48:34,923] A3C_AGENT_WORKER-Thread-20 INFO:Local step 4500, global step 71975: loss 0.7740
[2019-03-27 04:48:34,924] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 4500, global step 71975: learning rate 0.0000
[2019-03-27 04:48:35,088] A3C_AGENT_WORKER-Thread-21 INFO:Local step 4500, global step 72052: loss 0.8400
[2019-03-27 04:48:35,092] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 4500, global step 72054: learning rate 0.0000
[2019-03-27 04:48:35,109] A3C_AGENT_WORKER-Thread-10 INFO:Local step 4500, global step 72063: loss 0.8075
[2019-03-27 04:48:35,112] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 4500, global step 72063: learning rate 0.0000
[2019-03-27 04:48:35,121] A3C_AGENT_WORKER-Thread-12 INFO:Local step 4500, global step 72066: loss 0.7240
[2019-03-27 04:48:35,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 4500, global step 72068: learning rate 0.0000
[2019-03-27 04:48:35,178] A3C_AGENT_WORKER-Thread-3 INFO:Local step 4500, global step 72090: loss 1.0455
[2019-03-27 04:48:35,180] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 4500, global step 72091: learning rate 0.0000
[2019-03-27 04:48:35,221] A3C_AGENT_WORKER-Thread-9 INFO:Local step 4500, global step 72113: loss 0.7912
[2019-03-27 04:48:35,223] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 4500, global step 72113: learning rate 0.0000
[2019-03-27 04:48:35,265] A3C_AGENT_WORKER-Thread-14 INFO:Local step 4500, global step 72134: loss 0.8360
[2019-03-27 04:48:35,268] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 4500, global step 72136: learning rate 0.0000
[2019-03-27 04:48:35,289] A3C_AGENT_WORKER-Thread-17 INFO:Local step 4500, global step 72144: loss 0.7379
[2019-03-27 04:48:35,292] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 4500, global step 72145: learning rate 0.0000
[2019-03-27 04:48:36,347] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.9360594e-12 1.2690686e-11 2.0244761e-11 1.0794497e-13], sum to 1.0000
[2019-03-27 04:48:36,357] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9100
[2019-03-27 04:48:36,363] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6821931028656527, 6.911200000000001, 6.9112, 168.912956510431, 585894.7331325805, 585894.7331325798, 179579.202841195], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2718000.0000, 
sim time next is 2718600.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6775424025252176, 6.9112, 6.9112, 168.912956510431, 582555.5111790922, 582555.5111790922, 178768.9312334549], 
processed observation next is [0.0, 0.4782608695652174, 0.2417061611374408, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6067590274697775, 0.0, 0.0, 0.8294399451523027, 0.16182097532752562, 0.16182097532752562, 0.26681930034844015], 
reward next is 0.7332, 
noisyNet noise sample is [array([0.18349056], dtype=float32), -0.3242859]. 
=============================================
[2019-03-27 04:48:41,370] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 04:48:41,373] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:48:41,374] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:48:41,374] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:48:41,376] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:48:41,376] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:48:41,377] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:48:41,376] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:48:41,377] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:48:41,379] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:48:41,378] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:48:41,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run4
[2019-03-27 04:48:41,399] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run4
[2019-03-27 04:48:41,399] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run4
[2019-03-27 04:48:41,417] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run4
[2019-03-27 04:48:41,486] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run4
[2019-03-27 04:48:47,184] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:48:47,184] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.5, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4194730735394755, 6.911199999999999, 6.9112, 168.912956510431, 377382.9180066035, 377382.9180066041, 142463.9297672701]
[2019-03-27 04:48:47,185] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:48:47,189] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.4996512e-11 9.3902447e-12 4.2747538e-11 1.2974439e-13], sampled 0.4877899808760472
[2019-03-27 04:49:00,329] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:49:00,331] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.25, 93.5, 1.0, 2.0, 0.5627762719525615, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129563213262, 801875.4086387785, 801875.4086387785, 195995.3435628484]
[2019-03-27 04:49:00,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:49:00,337] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.1094981e-12 8.1621792e-13 3.8032901e-12 8.2687238e-15], sampled 0.5052810390940646
[2019-03-27 04:49:00,900] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:49:00,900] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.4, 44.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5085889762388877, 6.911200000000001, 6.9112, 168.912956510431, 454625.6293517794, 454625.6293517788, 152837.6467269974]
[2019-03-27 04:49:00,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:49:00,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 2.24643255e-11 9.60409443e-12 3.62490662e-11
 1.12106145e-13], sampled 0.1519347487989955
[2019-03-27 04:49:09,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:49:09,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.4, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7487518354695599, 6.9112, 6.9112, 168.912956510431, 638205.5416204906, 638205.5416204906, 191782.5942786848]
[2019-03-27 04:49:09,913] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:49:09,917] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.0509651e-13 6.5552652e-14 4.1949636e-13 4.4201898e-16], sampled 0.40872841048132347
[2019-03-27 04:49:20,127] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:49:20,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.989980867507726, 6.9112, 6.9112, 168.912956510431, 801237.2965626288, 801237.2965626288, 244665.5056318183]
[2019-03-27 04:49:20,128] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:49:20,133] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.7028477e-13 5.1980003e-14 4.1948275e-13 3.6013837e-16], sampled 0.20477889233692304
[2019-03-27 04:50:22,756] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.051720154]
[2019-03-27 04:50:22,757] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.1, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9803085041281538, 6.9112, 6.9112, 168.912956510431, 794457.9696854701, 794457.9696854701, 242266.0020198735]
[2019-03-27 04:50:22,757] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:50:22,760] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.6846316e-12 1.1230331e-12 3.1022372e-12 8.9085521e-15], sampled 0.015178970587464646
[2019-03-27 04:50:34,860] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8061.7863 2937799834.5475 1381.0000
[2019-03-27 04:50:35,126] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7287.4564 3319512167.9846 2143.0000
[2019-03-27 04:50:35,282] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7032.0616 3185036340.5509 2464.0000
[2019-03-27 04:50:35,376] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7925.2504 2989312291.4649 1566.0000
[2019-03-27 04:50:35,417] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7348.3118 3105665787.6228 2010.0000
[2019-03-27 04:50:36,433] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 75000, evaluation results [75000.0, 7287.456435200253, 3319512167.9846015, 2143.0, 7348.311834666183, 3105665787.6228237, 2010.0, 8061.78626402958, 2937799834.5474706, 1381.0, 7032.061550876785, 3185036340.5509343, 2464.0, 7925.250426000709, 2989312291.464916, 1566.0]
[2019-03-27 04:50:37,482] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1058473e-13 8.6256176e-13 2.5492997e-13 3.8164465e-14], sum to 1.0000
[2019-03-27 04:50:37,488] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5761
[2019-03-27 04:50:37,606] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7078828005351413, 6.9112, 6.9112, 168.912956510431, 604419.0189070036, 604419.0189070036, 184147.3838051883], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2830800.0000, 
sim time next is 2831400.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7111675574912901, 6.9112, 6.9112, 168.912956510431, 607224.7099600784, 607224.7099600784, 184744.8415618598], 
processed observation next is [1.0, 0.782608695652174, 0.3364928909952607, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6477653140137685, 0.0, 0.0, 0.8294399451523027, 0.1686735305444662, 0.1686735305444662, 0.2757385694953131], 
reward next is 0.7243, 
noisyNet noise sample is [array([0.6263787], dtype=float32), -1.3776377]. 
=============================================
[2019-03-27 04:50:43,498] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.0123980e-15 1.6927345e-13 6.8601693e-14 4.3338648e-18], sum to 1.0000
[2019-03-27 04:50:43,505] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5433
[2019-03-27 04:50:43,510] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5707058812324782, 6.911199999999999, 6.9112, 168.912956510431, 500056.7546586314, 500056.754658632, 161668.6603854449], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2931000.0000, 
sim time next is 2931600.0000, 
raw observation next is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5722246918594889, 6.9112, 6.9112, 168.912956510431, 501368.4287978829, 501368.4287978829, 161888.2445026614], 
processed observation next is [1.0, 0.9565217391304348, 0.19431279620853087, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47832279495059615, 0.0, 0.0, 0.8294399451523027, 0.13926900799941191, 0.13926900799941191, 0.2416242455263603], 
reward next is 0.7584, 
noisyNet noise sample is [array([0.08651619], dtype=float32), 2.1667035]. 
=============================================
[2019-03-27 04:50:43,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.1671262e-15 1.5133911e-14 1.7610788e-13 8.1316751e-17], sum to 1.0000
[2019-03-27 04:50:43,789] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2329
[2019-03-27 04:50:43,792] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.548280013458453, 6.9112, 6.9112, 168.912956510431, 481818.9860315085, 481818.9860315085, 158465.0975638478], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2942400.0000, 
sim time next is 2943000.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5485666096749928, 6.911199999999999, 6.9112, 168.912956510431, 482070.9057581156, 482070.9057581162, 158504.6218804053], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.44947147521340586, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13390858493280988, 0.13390858493281005, 0.2365740625080676], 
reward next is 0.7634, 
noisyNet noise sample is [array([-1.5154631], dtype=float32), -0.82510513]. 
=============================================
[2019-03-27 04:50:43,813] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.257515]
 [71.54    ]
 [71.806725]
 [72.04782 ]
 [72.459045]], R is [[71.08546448]
 [71.13809204]
 [71.19025421]
 [71.24194336]
 [71.29311371]].
[2019-03-27 04:50:46,641] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.6420808e-12 5.2042554e-12 2.4662813e-12 2.0652460e-13], sum to 1.0000
[2019-03-27 04:50:46,655] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0067
[2019-03-27 04:50:46,659] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9403008553062029, 6.9112, 6.9112, 168.912956510431, 821864.7164444767, 821864.7164444767, 233406.0520431901], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2978400.0000, 
sim time next is 2979000.0000, 
raw observation next is [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9311984382390068, 6.9112, 6.9112, 168.912956510431, 813921.2367576531, 813921.2367576531, 231196.5739115081], 
processed observation next is [1.0, 0.4782608695652174, 0.2417061611374408, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9160956563890327, 0.0, 0.0, 0.8294399451523027, 0.22608923243268142, 0.22608923243268142, 0.34506951330075836], 
reward next is 0.6549, 
noisyNet noise sample is [array([0.69118196], dtype=float32), -0.27362084]. 
=============================================
[2019-03-27 04:50:46,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[65.47352 ]
 [65.767845]
 [65.29929 ]
 [64.49486 ]
 [64.32407 ]], R is [[66.045578  ]
 [66.03675842]
 [66.0218277 ]
 [66.00483704]
 [66.01302338]].
[2019-03-27 04:50:47,151] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5000, global step 79819: loss -142.0456
[2019-03-27 04:50:47,153] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5000, global step 79819: learning rate 0.0000
[2019-03-27 04:50:47,340] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5000, global step 79849: loss -76.7025
[2019-03-27 04:50:47,342] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5000, global step 79849: learning rate 0.0000
[2019-03-27 04:50:47,466] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5000, global step 79872: loss -63.8689
[2019-03-27 04:50:47,469] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5000, global step 79872: learning rate 0.0000
[2019-03-27 04:50:47,634] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5000, global step 79919: loss -73.6432
[2019-03-27 04:50:47,636] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5000, global step 79919: learning rate 0.0000
[2019-03-27 04:50:47,767] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5000, global step 79947: loss -52.4834
[2019-03-27 04:50:47,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5000, global step 79948: learning rate 0.0000
[2019-03-27 04:50:47,862] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5000, global step 79959: loss -56.1948
[2019-03-27 04:50:47,864] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5000, global step 79959: loss -35.4504
[2019-03-27 04:50:47,865] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5000, global step 79959: learning rate 0.0000
[2019-03-27 04:50:47,869] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5000, global step 79959: learning rate 0.0000
[2019-03-27 04:50:48,042] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5000, global step 79970: loss -143.5617
[2019-03-27 04:50:48,042] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5000, global step 79971: loss -181.6413
[2019-03-27 04:50:48,045] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5000, global step 79971: learning rate 0.0000
[2019-03-27 04:50:48,125] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5000, global step 79973: learning rate 0.0000
[2019-03-27 04:50:48,215] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5000, global step 79984: loss -48.0955
[2019-03-27 04:50:48,218] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5000, global step 79984: learning rate 0.0000
[2019-03-27 04:50:48,476] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5000, global step 80074: loss -24.6576
[2019-03-27 04:50:48,478] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5000, global step 80074: loss -66.9375
[2019-03-27 04:50:48,480] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5000, global step 80074: loss -45.0069
[2019-03-27 04:50:48,482] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5000, global step 80074: learning rate 0.0000
[2019-03-27 04:50:48,483] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5000, global step 80074: learning rate 0.0000
[2019-03-27 04:50:48,484] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5000, global step 80074: learning rate 0.0000
[2019-03-27 04:50:48,743] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5000, global step 80084: loss -136.6652
[2019-03-27 04:50:48,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5000, global step 80086: learning rate 0.0000
[2019-03-27 04:50:48,851] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5000, global step 80105: loss -6.3186
[2019-03-27 04:50:48,852] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5000, global step 80105: learning rate 0.0000
[2019-03-27 04:50:49,009] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5000, global step 80147: loss -60.4427
[2019-03-27 04:50:49,010] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5000, global step 80148: learning rate 0.0000
[2019-03-27 04:50:52,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.7801898e-13 5.2605923e-12 1.4993545e-12 5.7448173e-16], sum to 1.0000
[2019-03-27 04:50:52,668] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5792
[2019-03-27 04:50:52,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1218939.441522436 W.
[2019-03-27 04:50:52,678] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.0, 100.0, 1.0, 2.0, 0.4223403119014094, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7185982354469651, 6.911200000000001, 6.9112, 168.912956510431, 1218939.441522436, 1218939.441522436, 269926.7741953742], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3077400.0000, 
sim time next is 3078000.0000, 
raw observation next is [23.0, 100.0, 1.0, 2.0, 0.8400192072204762, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216916.286152794, 1216916.286152795, 260053.4776575227], 
processed observation next is [1.0, 0.6521739130434783, 0.28909952606635075, 1.0, 1.0, 1.0, 0.80725205689214, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3380323017091095, 0.3380323017091097, 0.3881395188918249], 
reward next is 0.6119, 
noisyNet noise sample is [array([1.6918304], dtype=float32), 0.26365626]. 
=============================================
[2019-03-27 04:50:52,693] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[65.801735]
 [64.54383 ]
 [64.98909 ]
 [65.37971 ]
 [64.680786]], R is [[65.41886139]
 [65.36179352]
 [64.70817566]
 [64.06109619]
 [64.02053833]].
[2019-03-27 04:50:53,417] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.9872359e-12 5.5293416e-13 1.7838247e-12 6.4155859e-15], sum to 1.0000
[2019-03-27 04:50:53,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9045
[2019-03-27 04:50:53,436] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7452055579603138, 6.9112, 6.9112, 168.912956510431, 633226.4892287307, 633226.4892287307, 191086.4740433558], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3090000.0000, 
sim time next is 3090600.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739477017848472, 6.9112, 6.9112, 168.912956510431, 628357.4160136356, 628357.4160136356, 189993.9384546527], 
processed observation next is [1.0, 0.782608695652174, 0.28909952606635075, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6822890461566732, 0.0, 0.0, 0.8294399451523027, 0.17454372667045434, 0.17454372667045434, 0.2835730424696309], 
reward next is 0.7164, 
noisyNet noise sample is [array([0.06073555], dtype=float32), 1.1896963]. 
=============================================
[2019-03-27 04:50:55,788] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.7629733e-13 3.9031671e-14 9.8357398e-14 2.4770179e-14], sum to 1.0000
[2019-03-27 04:50:55,799] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8743
[2019-03-27 04:50:55,803] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6777147431236187, 6.911200000000001, 6.9112, 168.912956510431, 583957.1103113499, 583957.1103113493, 178793.0966361054], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3122400.0000, 
sim time next is 3123000.0000, 
raw observation next is [22.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6738673374259916, 6.911199999999999, 6.9112, 168.912956510431, 581410.119889785, 581410.1198897855, 178123.4092776884], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.97, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6022772407634044, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16150281108049583, 0.161502811080496, 0.2658558347428185], 
reward next is 0.7341, 
noisyNet noise sample is [array([0.18956353], dtype=float32), 1.4789181]. 
=============================================
[2019-03-27 04:50:55,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[65.83958 ]
 [66.137535]
 [66.32421 ]
 [66.476875]
 [66.7463  ]], R is [[65.70500183]
 [65.78109741]
 [65.83609772]
 [65.91410065]
 [65.98999023]].
[2019-03-27 04:50:57,797] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 5.1726445e-13 4.2323371e-12 9.7588116e-13 4.2130169e-15], sum to 1.0000
[2019-03-27 04:50:57,805] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8177
[2019-03-27 04:50:57,810] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1348180.714537956 W.
[2019-03-27 04:50:57,815] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.9645213188666396, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104048, 1348180.714537956, 1348180.714537957, 288298.2484399906], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3162600.0000, 
sim time next is 3163200.0000, 
raw observation next is [26.0, 84.0, 1.0, 2.0, 0.34118777852198, 1.0, 1.0, 0.34118777852198, 1.0, 1.0, 0.5727143989443212, 6.9112, 6.9112, 170.5573041426782, 1430754.299483174, 1430754.299483174, 320363.9101813526], 
processed observation next is [1.0, 0.6086956521739131, 0.4312796208530806, 0.84, 1.0, 1.0, 0.2062503355686506, 1.0, 0.5, 0.2062503355686506, 1.0, 0.5, 0.4789199987125868, 0.0, 0.0, 0.8375144448122397, 0.3974317498564372, 0.3974317498564372, 0.47815508982291427], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20119473], dtype=float32), -0.47668606]. 
=============================================
[2019-03-27 04:50:58,780] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.9186414e-16 1.3725757e-14 3.2724213e-14 1.2478900e-16], sum to 1.0000
[2019-03-27 04:50:58,789] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7359
[2019-03-27 04:50:58,796] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8386030681337274, 6.9112, 6.9112, 168.912956510431, 696310.3400400049, 696310.3400400049, 209807.5362846004], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3177600.0000, 
sim time next is 3178200.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8378780657594136, 6.9112, 6.9112, 168.912956510431, 696175.2481932254, 696175.2481932254, 209665.3043754171], 
processed observation next is [1.0, 0.782608695652174, 0.4391785150078992, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8022903240968459, 0.0, 0.0, 0.8294399451523027, 0.19338201338700706, 0.19338201338700706, 0.3129332901125628], 
reward next is 0.6871, 
noisyNet noise sample is [array([-0.1555465], dtype=float32), 0.45740286]. 
=============================================
[2019-03-27 04:51:00,230] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.7962567e-16 6.0424207e-16 6.5584541e-14 8.6053921e-16], sum to 1.0000
[2019-03-27 04:51:00,239] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2558
[2019-03-27 04:51:00,248] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8131550163259691, 6.911200000000001, 6.9112, 168.912956510431, 679552.2329093028, 679552.2329093022, 204518.398899888], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3198000.0000, 
sim time next is 3198600.0000, 
raw observation next is [25.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8130634126285693, 6.911199999999999, 6.9112, 168.912956510431, 679475.6981089027, 679475.6981089032, 204499.214624661], 
processed observation next is [0.0, 0.0, 0.38388625592417064, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.77202855198606, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18874324947469517, 0.18874324947469534, 0.3052227083950164], 
reward next is 0.6948, 
noisyNet noise sample is [array([0.01169463], dtype=float32), 0.9974196]. 
=============================================
[2019-03-27 04:51:05,746] A3C_AGENT_WORKER-Thread-13 INFO:Local step 5500, global step 87849: loss 0.0904
[2019-03-27 04:51:05,747] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 5500, global step 87849: learning rate 0.0000
[2019-03-27 04:51:05,841] A3C_AGENT_WORKER-Thread-11 INFO:Local step 5500, global step 87891: loss 0.0715
[2019-03-27 04:51:05,844] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 5500, global step 87892: learning rate 0.0000
[2019-03-27 04:51:05,859] A3C_AGENT_WORKER-Thread-2 INFO:Local step 5500, global step 87900: loss 0.0656
[2019-03-27 04:51:05,860] A3C_AGENT_WORKER-Thread-16 INFO:Local step 5500, global step 87900: loss 0.0430
[2019-03-27 04:51:05,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 5500, global step 87900: learning rate 0.0000
[2019-03-27 04:51:05,864] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 5500, global step 87901: learning rate 0.0000
[2019-03-27 04:51:05,881] A3C_AGENT_WORKER-Thread-19 INFO:Local step 5500, global step 87908: loss 0.0706
[2019-03-27 04:51:05,882] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 5500, global step 87908: learning rate 0.0000
[2019-03-27 04:51:05,904] A3C_AGENT_WORKER-Thread-22 INFO:Local step 5500, global step 87918: loss 0.0761
[2019-03-27 04:51:05,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 5500, global step 87918: learning rate 0.0000
[2019-03-27 04:51:05,933] A3C_AGENT_WORKER-Thread-21 INFO:Local step 5500, global step 87928: loss 0.1058
[2019-03-27 04:51:05,936] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 5500, global step 87929: learning rate 0.0000
[2019-03-27 04:51:05,984] A3C_AGENT_WORKER-Thread-15 INFO:Local step 5500, global step 87951: loss 0.0555
[2019-03-27 04:51:05,987] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 5500, global step 87953: learning rate 0.0000
[2019-03-27 04:51:06,000] A3C_AGENT_WORKER-Thread-20 INFO:Local step 5500, global step 87960: loss 0.0401
[2019-03-27 04:51:06,002] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 5500, global step 87960: learning rate 0.0000
[2019-03-27 04:51:06,018] A3C_AGENT_WORKER-Thread-18 INFO:Local step 5500, global step 87967: loss 0.0482
[2019-03-27 04:51:06,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 5500, global step 87967: learning rate 0.0000
[2019-03-27 04:51:06,192] A3C_AGENT_WORKER-Thread-12 INFO:Local step 5500, global step 88046: loss 0.0254
[2019-03-27 04:51:06,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 5500, global step 88047: learning rate 0.0000
[2019-03-27 04:51:06,249] A3C_AGENT_WORKER-Thread-10 INFO:Local step 5500, global step 88073: loss 0.0763
[2019-03-27 04:51:06,251] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 5500, global step 88073: learning rate 0.0000
[2019-03-27 04:51:06,265] A3C_AGENT_WORKER-Thread-17 INFO:Local step 5500, global step 88078: loss 0.1007
[2019-03-27 04:51:06,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 5500, global step 88078: learning rate 0.0000
[2019-03-27 04:51:06,303] A3C_AGENT_WORKER-Thread-3 INFO:Local step 5500, global step 88094: loss 0.0437
[2019-03-27 04:51:06,306] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 5500, global step 88094: learning rate 0.0000
[2019-03-27 04:51:06,307] A3C_AGENT_WORKER-Thread-9 INFO:Local step 5500, global step 88094: loss 0.0304
[2019-03-27 04:51:06,311] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 5500, global step 88096: learning rate 0.0000
[2019-03-27 04:51:06,601] A3C_AGENT_WORKER-Thread-14 INFO:Local step 5500, global step 88228: loss 0.0397
[2019-03-27 04:51:06,604] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 5500, global step 88229: learning rate 0.0000
[2019-03-27 04:51:21,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 1.14348106e-11 1.36694761e-11 8.39078373e-12
 1.20038812e-13], sum to 1.0000
[2019-03-27 04:51:21,099] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6239
[2019-03-27 04:51:21,104] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 941932.9008730919 W.
[2019-03-27 04:51:21,110] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.25, 82.5, 1.0, 2.0, 0.6740105933406464, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 941932.9008730919, 941932.9008730913, 215331.5916168738], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3558600.0000, 
sim time next is 3559200.0000, 
raw observation next is [26.16666666666666, 83.0, 1.0, 2.0, 0.3290611380326633, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5483046041872184, 6.911199999999999, 6.9112, 168.912956510431, 919719.2901947432, 919719.2901947438, 229033.2129528413], 
processed observation next is [1.0, 0.17391304347826086, 0.4391785150078987, 0.83, 1.0, 1.0, 0.19163992534055818, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.44915195632587607, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25547758060965087, 0.25547758060965103, 0.34184061634752433], 
reward next is 0.6582, 
noisyNet noise sample is [array([2.1116378], dtype=float32), -0.7315406]. 
=============================================
[2019-03-27 04:51:23,202] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6000, global step 95831: loss -143.2281
[2019-03-27 04:51:23,203] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.4147234e-13 1.5274182e-10 2.3986398e-13 2.3001680e-13], sum to 1.0000
[2019-03-27 04:51:23,204] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6000, global step 95831: learning rate 0.0000
[2019-03-27 04:51:23,215] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9689
[2019-03-27 04:51:23,222] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2749298.036612168 W.
[2019-03-27 04:51:23,228] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.6692949014668407, 1.0, 1.0, 0.6552374902476829, 1.0, 2.0, 1.03, 7.005095311212451, 6.9112, 170.5573041426782, 2749298.036612168, 2682037.005773628, 511805.7182725799], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3591600.0000, 
sim time next is 3592200.0000, 
raw observation next is [32.83333333333333, 63.66666666666666, 1.0, 2.0, 0.675075119773038, 1.0, 2.0, 0.6581275994007816, 1.0, 2.0, 1.03, 7.005095766934681, 6.9112, 170.5573041426782, 2761437.991107285, 2694176.633816374, 513571.7342021343], 
processed observation next is [1.0, 0.5652173913043478, 0.7551342812006318, 0.6366666666666666, 1.0, 1.0, 0.6085242406904072, 1.0, 1.0, 0.5881055414467248, 1.0, 1.0, 1.0365853658536586, 0.009389576693468094, 0.0, 0.8375144448122397, 0.7670661086409125, 0.7483823982823261, 0.766524976421096], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39511383], dtype=float32), 0.10168519]. 
=============================================
[2019-03-27 04:51:23,318] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6000, global step 95886: loss -109.7119
[2019-03-27 04:51:23,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6000, global step 95886: learning rate 0.0000
[2019-03-27 04:51:23,356] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6000, global step 95903: loss -105.7958
[2019-03-27 04:51:23,358] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6000, global step 95905: learning rate 0.0000
[2019-03-27 04:51:23,390] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6000, global step 95915: loss -188.8220
[2019-03-27 04:51:23,391] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6000, global step 95916: learning rate 0.0000
[2019-03-27 04:51:23,398] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6000, global step 95918: loss -92.7116
[2019-03-27 04:51:23,400] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6000, global step 95918: learning rate 0.0000
[2019-03-27 04:51:23,459] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6000, global step 95949: loss -38.8377
[2019-03-27 04:51:23,460] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6000, global step 95949: learning rate 0.0000
[2019-03-27 04:51:23,464] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6000, global step 95951: loss -63.7177
[2019-03-27 04:51:23,465] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6000, global step 95951: learning rate 0.0000
[2019-03-27 04:51:23,488] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6000, global step 95964: loss 18.9182
[2019-03-27 04:51:23,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6000, global step 95964: learning rate 0.0000
[2019-03-27 04:51:23,504] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6000, global step 95969: loss -107.9868
[2019-03-27 04:51:23,508] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6000, global step 95971: learning rate 0.0000
[2019-03-27 04:51:23,696] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6000, global step 96055: loss -63.8986
[2019-03-27 04:51:23,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6000, global step 96057: learning rate 0.0000
[2019-03-27 04:51:23,712] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6000, global step 96061: loss -48.4359
[2019-03-27 04:51:23,718] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6000, global step 96063: learning rate 0.0000
[2019-03-27 04:51:23,727] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6000, global step 96069: loss -24.2212
[2019-03-27 04:51:23,733] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6000, global step 96071: loss -97.8041
[2019-03-27 04:51:23,733] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6000, global step 96071: learning rate 0.0000
[2019-03-27 04:51:23,737] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6000, global step 96074: learning rate 0.0000
[2019-03-27 04:51:23,741] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6000, global step 96075: loss -131.6223
[2019-03-27 04:51:23,741] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6000, global step 96075: loss -209.8735
[2019-03-27 04:51:23,742] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6000, global step 96075: learning rate 0.0000
[2019-03-27 04:51:23,743] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6000, global step 96075: learning rate 0.0000
[2019-03-27 04:51:23,933] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6000, global step 96163: loss -129.3159
[2019-03-27 04:51:23,935] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6000, global step 96163: learning rate 0.0000
[2019-03-27 04:51:31,942] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.5913870e-10 7.5081745e-09 3.4186404e-10 1.9553088e-10], sum to 1.0000
[2019-03-27 04:51:31,949] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0276
[2019-03-27 04:51:31,956] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2424931.168414875 W.
[2019-03-27 04:51:31,962] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 65.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.0942607768706, 6.9112, 168.9120799058391, 2424931.168414875, 2295062.226819229, 476240.2271492859], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3753600.0000, 
sim time next is 3754200.0000, 
raw observation next is [31.0, 65.5, 1.0, 2.0, 0.8470559751601663, 1.0, 1.0, 0.8470559751601663, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2369070.154739219, 2369070.154739219, 443426.1919824824], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.655, 1.0, 1.0, 0.8157300905544173, 1.0, 0.5, 0.8157300905544173, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6580750429831165, 0.6580750429831165, 0.6618301372872871], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18335368], dtype=float32), 0.8731437]. 
=============================================
[2019-03-27 04:51:32,103] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-27 04:51:32,104] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:51:32,105] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:51:32,105] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:51:32,106] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:51:32,106] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:51:32,108] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:51:32,109] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:51:32,110] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:51:32,111] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:51:32,111] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:51:32,128] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run5
[2019-03-27 04:51:32,128] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run5
[2019-03-27 04:51:32,128] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run5
[2019-03-27 04:51:32,187] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run5
[2019-03-27 04:51:32,204] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run5
[2019-03-27 04:51:33,944] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:51:33,945] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.63333333333334, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6606862370843574, 6.9112, 6.9112, 168.912956510431, 571415.3344075446, 571415.3344075446, 175864.8517446204]
[2019-03-27 04:51:33,946] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:51:33,949] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 8.5951905e-12 3.3374786e-11 7.6443851e-12 7.6923261e-13], sampled 0.9928816550763643
[2019-03-27 04:51:46,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:51:46,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.9, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5826998806367634, 6.9112, 6.9112, 168.912956510431, 506904.7506743953, 506904.7506743953, 163496.7536256256]
[2019-03-27 04:51:46,091] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:51:46,094] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.1377616e-11 4.6146146e-11 1.0221126e-11 1.0361190e-12], sampled 0.6321682142227212
[2019-03-27 04:51:54,433] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:51:54,434] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.98964002, 75.4303479, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6720187212822508, 6.911200000000001, 6.9112, 168.912956510431, 579484.5634010091, 579484.5634010085, 177807.8186716861]
[2019-03-27 04:51:54,435] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:51:54,436] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.5396813e-12 5.9657296e-12 1.8926666e-12 1.2002370e-13], sampled 0.9908276805729505
[2019-03-27 04:51:56,331] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:51:56,331] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.43333333333333, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8269560899457106, 6.911200000000001, 6.9112, 168.912956510431, 682359.0582480235, 682359.0582480228, 207168.0925267876]
[2019-03-27 04:51:56,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:51:56,335] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.9117399e-13 6.9062711e-12 2.2657513e-13 2.7016499e-14], sampled 0.15122053061884755
[2019-03-27 04:52:19,801] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:52:19,802] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.89291059333333, 92.62537315, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7710059703226758, 6.9112, 6.9112, 168.912956510431, 654553.4873631664, 654553.4873631664, 196110.9255544942]
[2019-03-27 04:52:19,804] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:52:19,806] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 7.1157040e-13 2.1842541e-12 8.3027574e-13 4.3735330e-14], sampled 0.28762110387688933
[2019-03-27 04:52:20,840] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:52:20,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.26653715, 66.28095059, 1.0, 2.0, 0.9731509691292989, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1360250.724185784, 1360250.724185785, 290853.4106645994]
[2019-03-27 04:52:20,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:52:20,847] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 6.0374050e-10 1.7775619e-08 3.6274678e-10 9.3260281e-11], sampled 0.614335746919395
[2019-03-27 04:52:20,849] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1360250.724185784 W.
[2019-03-27 04:52:47,359] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:52:47,361] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.01666666666667, 70.5, 1.0, 2.0, 0.6125406826183647, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129563925002, 855993.8000491246, 855993.8000491252, 203102.7688892752]
[2019-03-27 04:52:47,365] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:52:47,368] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.6929322e-12 4.4624721e-11 3.6533077e-12 4.2308016e-13], sampled 0.5843180266548846
[2019-03-27 04:53:07,038] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.046165258]
[2019-03-27 04:53:07,040] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.03333333333333, 87.83333333333334, 1.0, 2.0, 0.6556517815257596, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 916265.3095257316, 916265.3095257322, 211563.7879738567]
[2019-03-27 04:53:07,041] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:53:07,044] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.6209430e-10 1.8370958e-09 9.6115213e-11 2.8188887e-11], sampled 0.9570252084174635
[2019-03-27 04:53:07,045] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 916265.3095257316 W.
[2019-03-27 04:53:25,806] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8061.7811 2937733325.9902 1381.0000
[2019-03-27 04:53:25,813] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7288.2437 3319510381.6748 2143.0000
[2019-03-27 04:53:25,955] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7347.5862 3105716106.2555 2010.0000
[2019-03-27 04:53:26,205] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7926.0230 2989290904.2350 1566.0000
[2019-03-27 04:53:26,222] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7032.0211 3185063424.5605 2464.0000
[2019-03-27 04:53:27,237] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 100000, evaluation results [100000.0, 7288.24371577949, 3319510381.6747575, 2143.0, 7347.586159403535, 3105716106.255517, 2010.0, 8061.781078517382, 2937733325.990165, 1381.0, 7032.02112698184, 3185063424.5605474, 2464.0, 7926.023035227224, 2989290904.234997, 1566.0]
[2019-03-27 04:53:27,820] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.5681295e-12 3.4735541e-11 4.2799951e-13 3.9253297e-12], sum to 1.0000
[2019-03-27 04:53:27,829] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5701
[2019-03-27 04:53:27,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2520042.089478495 W.
[2019-03-27 04:53:27,845] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.33333333333334, 64.0, 1.0, 2.0, 0.9009812917964697, 1.0, 2.0, 0.9009812917964697, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2520042.089478495, 2520042.089478495, 472028.3492185086], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3757200.0000, 
sim time next is 3757800.0000, 
raw observation next is [32.66666666666666, 63.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.080341512486786, 6.9112, 168.9064651764162, 3113840.480366286, 2284443.127672648, 473308.444559061], 
processed observation next is [1.0, 0.4782608695652174, 0.7472353870458132, 0.635, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.11691415124867861, 0.0, 0.8294080697305444, 0.864955688990635, 0.6345675354646244, 0.7064305142672552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6456929], dtype=float32), 1.1311655]. 
=============================================
[2019-03-27 04:53:32,241] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.0205519e-12 6.9563634e-12 2.7206706e-13 8.3329129e-14], sum to 1.0000
[2019-03-27 04:53:32,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5779
[2019-03-27 04:53:32,252] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9591729923423322, 6.9112, 6.9112, 168.912956510431, 779491.3422204471, 779491.3422204471, 237096.0961490395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3829200.0000, 
sim time next is 3829800.0000, 
raw observation next is [29.66666666666666, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9658905053340293, 6.9112, 6.9112, 168.912956510431, 783898.3120010134, 783898.3120010134, 238709.1601364341], 
processed observation next is [0.0, 0.30434782608695654, 0.6050552922590835, 0.765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9584030552854015, 0.0, 0.0, 0.8294399451523027, 0.2177495311113926, 0.2177495311113926, 0.35628232856184194], 
reward next is 0.6437, 
noisyNet noise sample is [array([-0.45662034], dtype=float32), -0.63600385]. 
=============================================
[2019-03-27 04:53:33,539] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.1815422e-12 1.3596786e-09 5.0422617e-12 3.6287926e-12], sum to 1.0000
[2019-03-27 04:53:33,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9595
[2019-03-27 04:53:33,554] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 872844.315275333 W.
[2019-03-27 04:53:33,562] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 55.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.97325837918335, 6.9112, 168.9124596011212, 872844.315275333, 828818.0947151147, 254812.5513768981], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3857400.0000, 
sim time next is 3858000.0000, 
raw observation next is [35.0, 55.33333333333333, 1.0, 1.0, 0.1996654728118711, 1.0, 1.0, 0.1996654728118711, 1.0, 2.0, 0.3467528958933578, 6.911199999999999, 6.9112, 170.5573041426782, 837055.755748194, 837055.7557481946, 269751.3512406668], 
processed observation next is [0.0, 0.6521739130434783, 0.8578199052132701, 0.5533333333333332, 1.0, 0.5, 0.03574153350827843, 1.0, 0.5, 0.03574153350827843, 1.0, 1.0, 0.20335719011385095, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.23251548770783165, 0.23251548770783184, 0.4026139570756221], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.75303316], dtype=float32), 0.8678815]. 
=============================================
[2019-03-27 04:53:33,575] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[40.383244]
 [39.16839 ]
 [39.557983]
 [39.618896]
 [39.20226 ]], R is [[40.13950729]
 [40.04750443]
 [40.24431229]
 [39.84186935]
 [39.47372055]].
[2019-03-27 04:53:35,520] A3C_AGENT_WORKER-Thread-11 INFO:Local step 6500, global step 103747: loss 0.0322
[2019-03-27 04:53:35,524] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 6500, global step 103747: learning rate 0.0000
[2019-03-27 04:53:35,705] A3C_AGENT_WORKER-Thread-2 INFO:Local step 6500, global step 103832: loss 0.0354
[2019-03-27 04:53:35,711] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 6500, global step 103833: learning rate 0.0000
[2019-03-27 04:53:35,742] A3C_AGENT_WORKER-Thread-13 INFO:Local step 6500, global step 103849: loss 0.0142
[2019-03-27 04:53:35,745] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 6500, global step 103849: learning rate 0.0000
[2019-03-27 04:53:35,821] A3C_AGENT_WORKER-Thread-15 INFO:Local step 6500, global step 103884: loss 0.0368
[2019-03-27 04:53:35,822] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 6500, global step 103884: learning rate 0.0000
[2019-03-27 04:53:35,903] A3C_AGENT_WORKER-Thread-19 INFO:Local step 6500, global step 103922: loss 0.1180
[2019-03-27 04:53:35,907] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 6500, global step 103923: learning rate 0.0000
[2019-03-27 04:53:35,910] A3C_AGENT_WORKER-Thread-21 INFO:Local step 6500, global step 103924: loss 0.0452
[2019-03-27 04:53:35,913] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 6500, global step 103924: learning rate 0.0000
[2019-03-27 04:53:35,953] A3C_AGENT_WORKER-Thread-22 INFO:Local step 6500, global step 103941: loss 0.0298
[2019-03-27 04:53:35,956] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 6500, global step 103941: learning rate 0.0000
[2019-03-27 04:53:35,999] A3C_AGENT_WORKER-Thread-16 INFO:Local step 6500, global step 103960: loss 0.0559
[2019-03-27 04:53:36,005] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 6500, global step 103961: learning rate 0.0000
[2019-03-27 04:53:36,086] A3C_AGENT_WORKER-Thread-18 INFO:Local step 6500, global step 104002: loss 0.0280
[2019-03-27 04:53:36,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 6500, global step 104003: learning rate 0.0000
[2019-03-27 04:53:36,117] A3C_AGENT_WORKER-Thread-3 INFO:Local step 6500, global step 104014: loss 0.0317
[2019-03-27 04:53:36,117] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 6500, global step 104014: learning rate 0.0000
[2019-03-27 04:53:36,221] A3C_AGENT_WORKER-Thread-20 INFO:Local step 6500, global step 104061: loss 0.0456
[2019-03-27 04:53:36,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 6500, global step 104061: learning rate 0.0000
[2019-03-27 04:53:36,327] A3C_AGENT_WORKER-Thread-9 INFO:Local step 6500, global step 104086: loss 0.0278
[2019-03-27 04:53:36,330] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 6500, global step 104086: learning rate 0.0000
[2019-03-27 04:53:36,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 6500, global step 104102: loss 0.0150
[2019-03-27 04:53:36,364] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 6500, global step 104102: learning rate 0.0000
[2019-03-27 04:53:36,406] A3C_AGENT_WORKER-Thread-12 INFO:Local step 6500, global step 104118: loss 0.0390
[2019-03-27 04:53:36,410] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 6500, global step 104119: learning rate 0.0000
[2019-03-27 04:53:36,508] A3C_AGENT_WORKER-Thread-10 INFO:Local step 6500, global step 104169: loss 0.0471
[2019-03-27 04:53:36,510] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 6500, global step 104169: learning rate 0.0000
[2019-03-27 04:53:36,571] A3C_AGENT_WORKER-Thread-14 INFO:Local step 6500, global step 104193: loss 0.0269
[2019-03-27 04:53:36,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 6500, global step 104193: learning rate 0.0000
[2019-03-27 04:53:41,666] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.8248249e-11 3.5824038e-10 9.7443095e-12 1.3345668e-11], sum to 1.0000
[2019-03-27 04:53:41,673] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0419
[2019-03-27 04:53:41,679] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1309016.856636998 W.
[2019-03-27 04:53:41,684] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.3121751223824827, 1.0, 1.0, 0.3121751223824827, 1.0, 2.0, 0.5421449496878331, 6.9112, 6.9112, 170.5573041426782, 1309016.856636998, 1309016.856636998, 309602.8180901938], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3994200.0000, 
sim time next is 3994800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.9103491819171282, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1272415.052269487, 1272415.052269487, 272803.7478813859], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.84, 1.0, 1.0, 0.8919869661652147, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.353448625630413, 0.353448625630413, 0.4071697729572924], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.39074403], dtype=float32), 0.4310079]. 
=============================================
[2019-03-27 04:53:41,856] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9818650e-11 8.0766294e-10 1.1169881e-11 2.2928858e-11], sum to 1.0000
[2019-03-27 04:53:41,861] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6392
[2019-03-27 04:53:41,871] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2101560.19714127 W.
[2019-03-27 04:53:41,875] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 84.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 7.823731083337498, 6.9112, 168.9079598932575, 2101560.19714127, 1454198.389913241, 311355.7756934109], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4000800.0000, 
sim time next is 4001400.0000, 
raw observation next is [29.5, 84.0, 1.0, 2.0, 0.4201252592813837, 1.0, 1.0, 0.4201252592813837, 1.0, 1.0, 0.7296186378254289, 6.911199999999999, 6.9112, 170.5573041426782, 1762046.893681037, 1762046.893681037, 364309.8807530009], 
processed observation next is [1.0, 0.30434782608695654, 0.5971563981042655, 0.84, 1.0, 1.0, 0.3013557340739563, 1.0, 0.5, 0.3013557340739563, 1.0, 0.5, 0.6702666314944253, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4894574704669547, 0.4894574704669547, 0.5437460906761208], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2935792], dtype=float32), -1.273242]. 
=============================================
[2019-03-27 04:53:48,595] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 2.3483191e-09 8.2855188e-08 4.5891269e-10 3.0062725e-10], sum to 1.0000
[2019-03-27 04:53:48,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3752
[2019-03-27 04:53:48,609] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 3622968.435319179 W.
[2019-03-27 04:53:48,612] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 67.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.906268881972259, 6.9112, 170.5573041426782, 3622968.435319179, 2910160.118348258, 547920.3347251762], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4111200.0000, 
sim time next is 4111800.0000, 
raw observation next is [34.33333333333334, 66.5, 1.0, 2.0, 0.8281211786031061, 1.0, 2.0, 0.7346506288158156, 1.0, 1.0, 1.03, 7.005107836567204, 6.9112, 170.5573041426782, 3082917.252501472, 3015647.249241824, 564851.6346738545], 
processed observation next is [1.0, 0.6086956521739131, 0.8262243285939973, 0.665, 1.0, 1.0, 0.7929170826543447, 1.0, 1.0, 0.6803019624286935, 1.0, 0.5, 1.0365853658536586, 0.009390783656720369, 0.0, 0.8375144448122397, 0.8563659034726311, 0.8376797914560622, 0.8430621413042604], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7833859], dtype=float32), 1.0370278]. 
=============================================
[2019-03-27 04:53:53,431] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7000, global step 111765: loss -76.0174
[2019-03-27 04:53:53,433] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7000, global step 111765: learning rate 0.0000
[2019-03-27 04:53:53,620] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7000, global step 111847: loss -64.3205
[2019-03-27 04:53:53,622] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7000, global step 111848: learning rate 0.0000
[2019-03-27 04:53:53,713] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7000, global step 111891: loss -82.0459
[2019-03-27 04:53:53,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7000, global step 111893: learning rate 0.0000
[2019-03-27 04:53:53,731] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7000, global step 111898: loss 8.2436
[2019-03-27 04:53:53,732] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7000, global step 111898: learning rate 0.0000
[2019-03-27 04:53:53,741] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7000, global step 111902: loss -62.8129
[2019-03-27 04:53:53,743] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7000, global step 111903: learning rate 0.0000
[2019-03-27 04:53:53,807] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7000, global step 111930: loss -52.8563
[2019-03-27 04:53:53,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7000, global step 111930: learning rate 0.0000
[2019-03-27 04:53:53,875] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7000, global step 111961: loss -90.0152
[2019-03-27 04:53:53,875] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7000, global step 111961: learning rate 0.0000
[2019-03-27 04:53:53,917] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7000, global step 111981: loss -42.5942
[2019-03-27 04:53:53,920] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7000, global step 111983: learning rate 0.0000
[2019-03-27 04:53:53,971] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7000, global step 112002: loss -37.4292
[2019-03-27 04:53:53,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7000, global step 112002: learning rate 0.0000
[2019-03-27 04:53:54,065] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7000, global step 112044: loss -89.9126
[2019-03-27 04:53:54,068] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7000, global step 112045: learning rate 0.0000
[2019-03-27 04:53:54,104] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7000, global step 112063: loss -65.6848
[2019-03-27 04:53:54,107] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7000, global step 112064: learning rate 0.0000
[2019-03-27 04:53:54,143] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7000, global step 112078: loss 7.9358
[2019-03-27 04:53:54,145] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7000, global step 112079: learning rate 0.0000
[2019-03-27 04:53:54,145] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7000, global step 112079: loss -22.2900
[2019-03-27 04:53:54,148] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7000, global step 112079: learning rate 0.0000
[2019-03-27 04:53:54,179] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7000, global step 112092: loss -87.0963
[2019-03-27 04:53:54,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7000, global step 112092: learning rate 0.0000
[2019-03-27 04:53:54,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7000, global step 112098: loss -108.3182
[2019-03-27 04:53:54,194] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7000, global step 112098: learning rate 0.0000
[2019-03-27 04:53:54,446] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7000, global step 112219: loss -103.4285
[2019-03-27 04:53:54,447] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7000, global step 112219: learning rate 0.0000
[2019-03-27 04:53:59,631] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999964e-01 5.8501062e-08 3.1607647e-07 5.8095584e-10 8.5320870e-09], sum to 1.0000
[2019-03-27 04:53:59,642] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0875
[2019-03-27 04:53:59,650] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [36.66666666666667, 48.66666666666666, 1.0, 2.0, 0.1878734247236088, 1.0, 2.0, 0.1878734247236088, 1.0, 1.0, 0.3262740080539398, 6.9112, 6.9112, 170.5573041426782, 787601.9074280167, 787601.9074280167, 266590.4139623584], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4296000.0000, 
sim time next is 4296600.0000, 
raw observation next is [36.5, 49.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9568991802136863, 6.911199999999999, 6.9112, 168.9129565104269, 769958.2117411532, 769958.2117411538, 236123.6965417229], 
processed observation next is [1.0, 0.7391304347826086, 0.9289099526066351, 0.49, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9474380246508367, -8.881784197001253e-17, 0.0, 0.8294399451522826, 0.21387728103920922, 0.21387728103920942, 0.35242342767421325], 
reward next is 0.6476, 
noisyNet noise sample is [array([0.27601743], dtype=float32), -0.78428936]. 
=============================================
[2019-03-27 04:54:08,568] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999976e-01 5.7518346e-08 2.4751938e-07 1.0730654e-09 5.9676948e-09], sum to 1.0000
[2019-03-27 04:54:08,578] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1660
[2019-03-27 04:54:08,584] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 898839.1884134609 W.
[2019-03-27 04:54:08,588] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 69.66666666666667, 1.0, 2.0, 0.643187449968532, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 898839.1884134609, 898839.1884134609, 209067.7599269714], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4450800.0000, 
sim time next is 4451400.0000, 
raw observation next is [33.0, 69.0, 1.0, 2.0, 0.3172294489878614, 1.0, 1.0, 0.3172294489878614, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 886632.5847640437, 886632.5847640437, 253309.0957763535], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.69, 1.0, 1.0, 0.17738487829862815, 1.0, 0.5, 0.17738487829862815, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24628682910112323, 0.24628682910112323, 0.37807327727813955], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.1290588], dtype=float32), -0.34155932]. 
=============================================
[2019-03-27 04:54:10,849] A3C_AGENT_WORKER-Thread-11 INFO:Local step 7500, global step 119674: loss 0.7241
[2019-03-27 04:54:10,852] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 7500, global step 119674: learning rate 0.0000
[2019-03-27 04:54:11,300] A3C_AGENT_WORKER-Thread-2 INFO:Local step 7500, global step 119886: loss 0.5756
[2019-03-27 04:54:11,303] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 7500, global step 119888: learning rate 0.0000
[2019-03-27 04:54:11,325] A3C_AGENT_WORKER-Thread-13 INFO:Local step 7500, global step 119899: loss 0.6510
[2019-03-27 04:54:11,329] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 7500, global step 119899: learning rate 0.0000
[2019-03-27 04:54:11,340] A3C_AGENT_WORKER-Thread-22 INFO:Local step 7500, global step 119905: loss 0.5638
[2019-03-27 04:54:11,343] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 7500, global step 119905: learning rate 0.0000
[2019-03-27 04:54:11,363] A3C_AGENT_WORKER-Thread-19 INFO:Local step 7500, global step 119914: loss 0.5308
[2019-03-27 04:54:11,365] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 7500, global step 119915: learning rate 0.0000
[2019-03-27 04:54:11,399] A3C_AGENT_WORKER-Thread-18 INFO:Local step 7500, global step 119930: loss 0.4591
[2019-03-27 04:54:11,402] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 7500, global step 119931: learning rate 0.0000
[2019-03-27 04:54:11,448] A3C_AGENT_WORKER-Thread-16 INFO:Local step 7500, global step 119953: loss 0.5357
[2019-03-27 04:54:11,450] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 7500, global step 119953: learning rate 0.0000
[2019-03-27 04:54:11,486] A3C_AGENT_WORKER-Thread-15 INFO:Local step 7500, global step 119971: loss 0.5204
[2019-03-27 04:54:11,488] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 7500, global step 119972: learning rate 0.0000
[2019-03-27 04:54:11,509] A3C_AGENT_WORKER-Thread-21 INFO:Local step 7500, global step 119982: loss 0.5193
[2019-03-27 04:54:11,512] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 7500, global step 119983: learning rate 0.0000
[2019-03-27 04:54:11,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 7500, global step 120029: loss 0.5341
[2019-03-27 04:54:11,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 7500, global step 120030: learning rate 0.0000
[2019-03-27 04:54:11,626] A3C_AGENT_WORKER-Thread-9 INFO:Local step 7500, global step 120035: loss 0.4495
[2019-03-27 04:54:11,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 7500, global step 120037: learning rate 0.0000
[2019-03-27 04:54:11,641] A3C_AGENT_WORKER-Thread-20 INFO:Local step 7500, global step 120043: loss 0.4651
[2019-03-27 04:54:11,643] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 7500, global step 120043: learning rate 0.0000
[2019-03-27 04:54:11,737] A3C_AGENT_WORKER-Thread-10 INFO:Local step 7500, global step 120085: loss 0.4673
[2019-03-27 04:54:11,739] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 7500, global step 120086: learning rate 0.0000
[2019-03-27 04:54:11,754] A3C_AGENT_WORKER-Thread-17 INFO:Local step 7500, global step 120093: loss 0.6279
[2019-03-27 04:54:11,755] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 7500, global step 120093: learning rate 0.0000
[2019-03-27 04:54:11,916] A3C_AGENT_WORKER-Thread-12 INFO:Local step 7500, global step 120166: loss 0.4727
[2019-03-27 04:54:11,922] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 7500, global step 120166: learning rate 0.0000
[2019-03-27 04:54:12,036] A3C_AGENT_WORKER-Thread-14 INFO:Local step 7500, global step 120224: loss 0.4169
[2019-03-27 04:54:12,045] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 7500, global step 120226: learning rate 0.0000
[2019-03-27 04:54:16,733] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.6986797e-11 3.5165262e-10 3.2989653e-12 2.6637897e-11], sum to 1.0000
[2019-03-27 04:54:16,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6854
[2019-03-27 04:54:16,749] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1320359.534091607 W.
[2019-03-27 04:54:16,754] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 94.0, 1.0, 2.0, 0.4723176990844505, 1.0, 2.0, 0.4723176990844505, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1320359.534091607, 1320359.534091607, 291884.0990057022], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4596600.0000, 
sim time next is 4597200.0000, 
raw observation next is [27.0, 94.0, 1.0, 2.0, 0.3073065691500015, 1.0, 2.0, 0.3073065691500015, 1.0, 1.0, 0.5336898827781704, 6.911199999999999, 6.9112, 170.5573041426782, 1288589.70516278, 1288589.705162781, 307514.7231968396], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.94, 1.0, 1.0, 0.16542960138554394, 1.0, 1.0, 0.16542960138554394, 1.0, 0.5, 0.4313291253392322, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.35794158476743887, 0.3579415847674392, 0.45897719880125315], 
reward next is 0.5410, 
noisyNet noise sample is [array([0.590039], dtype=float32), 1.1064345]. 
=============================================
[2019-03-27 04:54:20,296] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.9052292e-14 9.9593196e-13 2.7520887e-14 3.5381220e-14], sum to 1.0000
[2019-03-27 04:54:20,308] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9664
[2019-03-27 04:54:20,315] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7999232957130867, 6.9112, 6.9112, 168.912956510431, 672172.116678605, 672172.116678605, 201854.2930630072], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4659600.0000, 
sim time next is 4660200.0000, 
raw observation next is [24.75, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8045296407145317, 6.9112, 6.9112, 168.912956510431, 675281.3501446685, 675281.3501446685, 202790.3333543635], 
processed observation next is [1.0, 0.9565217391304348, 0.3720379146919432, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.761621513066502, 0.0, 0.0, 0.8294399451523027, 0.18757815281796347, 0.18757815281796347, 0.3026721393348709], 
reward next is 0.6973, 
noisyNet noise sample is [array([0.00396809], dtype=float32), 0.2419439]. 
=============================================
[2019-03-27 04:54:22,139] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 04:54:22,141] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:54:22,141] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:54:22,141] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:54:22,143] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:54:22,144] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:54:22,145] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:54:22,146] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:54:22,147] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:54:22,148] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:54:22,152] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:54:22,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run6
[2019-03-27 04:54:22,168] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run6
[2019-03-27 04:54:22,187] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run6
[2019-03-27 04:54:22,207] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run6
[2019-03-27 04:54:22,246] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run6
[2019-03-27 04:54:33,565] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04055422]
[2019-03-27 04:54:33,567] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.05, 57.0, 1.0, 2.0, 0.9468000676153029, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564961672, 1323395.010106076, 1323395.010106076, 283132.1534012458]
[2019-03-27 04:54:33,570] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 04:54:33,572] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999964e-01 4.8534594e-09 3.4841338e-07 5.9345917e-10 2.5706466e-09], sampled 0.3662292191122719
[2019-03-27 04:54:33,575] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1323395.010106076 W.
[2019-03-27 04:55:22,964] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04055422]
[2019-03-27 04:55:22,966] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.08553283, 75.72471112, 1.0, 2.0, 0.6877998341026984, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 961212.1489055516, 961212.1489055516, 218231.7258280937]
[2019-03-27 04:55:22,968] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:55:22,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999917e-01 1.8769839e-08 8.5806425e-07 1.4219513e-09 8.1588736e-09], sampled 0.6450198701003367
[2019-03-27 04:55:22,972] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 961212.1489055516 W.
[2019-03-27 04:55:37,033] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04055422]
[2019-03-27 04:55:37,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 67.0, 1.0, 2.0, 0.8792414555361675, 1.0, 2.0, 0.8792414555361675, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2459175.993822147, 2459175.993822148, 460296.326492594]
[2019-03-27 04:55:37,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:55:37,040] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999976e-01 3.6879257e-09 2.1872900e-07 2.2823970e-10 2.3103599e-09], sampled 0.02487271525666679
[2019-03-27 04:55:37,041] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2459175.993822147 W.
[2019-03-27 04:55:53,331] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04055422]
[2019-03-27 04:55:53,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.7, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9204426557858214, 6.911200000000001, 6.9112, 168.912956510431, 753032.8127313006, 753032.8127312999, 227955.5888056441]
[2019-03-27 04:55:53,332] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:55:53,335] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.9159195e-12 1.8658994e-11 2.0999507e-13 4.2804280e-13], sampled 0.8714410675408534
[2019-03-27 04:56:09,149] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04055422]
[2019-03-27 04:56:09,150] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.9, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7147701967303715, 6.911199999999999, 6.9112, 168.912956510431, 612093.8765320304, 612093.8765320311, 185408.3668979697]
[2019-03-27 04:56:09,151] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:56:09,154] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.8585107e-12 4.5270260e-11 5.2266546e-13 1.1599844e-12], sampled 0.4110036798682887
[2019-03-27 04:56:16,356] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7348.4079 3105587199.2298 2010.0000
[2019-03-27 04:56:16,448] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.6269 2989312438.8763 1566.0000
[2019-03-27 04:56:16,574] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7287.4827 3319549959.1226 2143.0000
[2019-03-27 04:56:16,599] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7032.0426 3185049068.0852 2464.0000
[2019-03-27 04:56:16,603] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8058.1595 2937851403.7866 1381.0000
[2019-03-27 04:56:17,618] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 125000, evaluation results [125000.0, 7287.482696691261, 3319549959.122563, 2143.0, 7348.407911634859, 3105587199.229759, 2010.0, 8058.159539431461, 2937851403.786588, 1381.0, 7032.042554557039, 3185049068.0851645, 2464.0, 7924.626933369283, 2989312438.876319, 1566.0]
[2019-03-27 04:56:20,275] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.1524681e-10 1.7581366e-08 3.9044740e-12 3.3329445e-10], sum to 1.0000
[2019-03-27 04:56:20,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8375
[2019-03-27 04:56:20,290] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.16666666666666, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8828057830583091, 6.9112, 6.9112, 168.912956510431, 721085.2009765374, 721085.2009765374, 219164.4507761105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4729800.0000, 
sim time next is 4730400.0000, 
raw observation next is [30.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8834154734108306, 6.911199999999999, 6.9112, 168.912956510431, 723325.102033454, 723325.1020334547, 219378.3900746574], 
processed observation next is [1.0, 0.782608695652174, 0.6208530805687204, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8578237480619886, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20092363945373723, 0.20092363945373742, 0.3274304329472498], 
reward next is 0.6726, 
noisyNet noise sample is [array([0.14522608], dtype=float32), -2.8429744]. 
=============================================
[2019-03-27 04:56:23,523] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.3746143e-09 2.4567836e-08 4.5040818e-11 1.1439054e-09], sum to 1.0000
[2019-03-27 04:56:23,532] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7361
[2019-03-27 04:56:23,540] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2245000.051340689 W.
[2019-03-27 04:56:23,546] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.0, 72.5, 1.0, 2.0, 0.5351565228722808, 1.0, 1.0, 0.5351565228722808, 1.0, 2.0, 0.9290431977439442, 6.9112, 6.9112, 170.5573041426782, 2245000.051340689, 2245000.051340689, 440241.2443479767], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4782600.0000, 
sim time next is 4783200.0000, 
raw observation next is [30.0, 71.66666666666667, 1.0, 2.0, 0.7916944652189071, 1.0, 2.0, 0.7916944652189071, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2214096.355420747, 2214096.355420747, 415846.3379493895], 
processed observation next is [1.0, 0.34782608695652173, 0.6208530805687204, 0.7166666666666667, 1.0, 1.0, 0.7490294761673579, 1.0, 1.0, 0.7490294761673579, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.615026765394652, 0.615026765394652, 0.6206661760438649], 
reward next is 0.3793, 
noisyNet noise sample is [array([0.76040983], dtype=float32), -0.66481256]. 
=============================================
[2019-03-27 04:56:23,681] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8000, global step 127734: loss 52.2114
[2019-03-27 04:56:23,682] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8000, global step 127734: learning rate 0.0000
[2019-03-27 04:56:23,933] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8000, global step 127846: loss -86.2985
[2019-03-27 04:56:23,935] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8000, global step 127846: learning rate 0.0000
[2019-03-27 04:56:24,077] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8000, global step 127911: loss -0.0530
[2019-03-27 04:56:24,081] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8000, global step 127911: learning rate 0.0000
[2019-03-27 04:56:24,096] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8000, global step 127918: loss 60.0498
[2019-03-27 04:56:24,104] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8000, global step 127921: learning rate 0.0000
[2019-03-27 04:56:24,154] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8000, global step 127941: loss -23.4712
[2019-03-27 04:56:24,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8000, global step 127941: learning rate 0.0000
[2019-03-27 04:56:24,180] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8000, global step 127953: loss -76.9608
[2019-03-27 04:56:24,183] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8000, global step 127954: learning rate 0.0000
[2019-03-27 04:56:24,192] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8000, global step 127958: loss 12.1116
[2019-03-27 04:56:24,197] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8000, global step 127960: learning rate 0.0000
[2019-03-27 04:56:24,303] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8000, global step 128007: loss 94.5730
[2019-03-27 04:56:24,305] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8000, global step 128007: loss -119.1323
[2019-03-27 04:56:24,307] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8000, global step 128007: learning rate 0.0000
[2019-03-27 04:56:24,309] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8000, global step 128010: learning rate 0.0000
[2019-03-27 04:56:24,335] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8000, global step 128022: loss -26.5092
[2019-03-27 04:56:24,337] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8000, global step 128022: learning rate 0.0000
[2019-03-27 04:56:24,377] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8000, global step 128041: loss -90.4520
[2019-03-27 04:56:24,378] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8000, global step 128041: learning rate 0.0000
[2019-03-27 04:56:24,398] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8000, global step 128047: loss -35.3406
[2019-03-27 04:56:24,400] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8000, global step 128047: learning rate 0.0000
[2019-03-27 04:56:24,426] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8000, global step 128060: loss 39.7833
[2019-03-27 04:56:24,427] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8000, global step 128060: learning rate 0.0000
[2019-03-27 04:56:24,517] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8000, global step 128101: loss 120.0617
[2019-03-27 04:56:24,519] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8000, global step 128101: learning rate 0.0000
[2019-03-27 04:56:24,539] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8000, global step 128108: loss -10.1173
[2019-03-27 04:56:24,542] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8000, global step 128109: learning rate 0.0000
[2019-03-27 04:56:24,572] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999964e-01 1.0544501e-09 3.2443936e-07 2.9669815e-11 4.7652713e-09], sum to 1.0000
[2019-03-27 04:56:24,580] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0477
[2019-03-27 04:56:24,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2705735.123497271 W.
[2019-03-27 04:56:24,594] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.5, 65.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.498344849332041, 6.9112, 168.9096069729366, 2705735.123497271, 2289202.619402464, 475061.3231127316], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4802400.0000, 
sim time next is 4803000.0000, 
raw observation next is [31.41666666666666, 65.16666666666667, 1.0, 2.0, 0.56205065694726, 1.0, 1.0, 0.56205065694726, 1.0, 2.0, 0.9760961181248322, 6.911199999999999, 6.9112, 170.5573041426782, 2357928.304967762, 2357928.304967762, 460706.6499501436], 
processed observation next is [1.0, 0.6086956521739131, 0.6879936808846759, 0.6516666666666667, 1.0, 1.0, 0.4723501890930843, 1.0, 0.5, 0.4723501890930843, 1.0, 1.0, 0.9708489245424783, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6549800847132672, 0.6549800847132672, 0.6876218655972293], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5097122], dtype=float32), 1.0463974]. 
=============================================
[2019-03-27 04:56:24,604] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[23.859512]
 [23.238358]
 [23.06636 ]
 [23.333885]
 [23.008821]], R is [[23.35129166]
 [23.11777878]
 [23.16291046]
 [22.93128204]
 [22.70196915]].
[2019-03-27 04:56:24,656] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8000, global step 128159: loss -104.2494
[2019-03-27 04:56:24,659] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8000, global step 128160: learning rate 0.0000
[2019-03-27 04:56:26,195] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.9734436e-13 2.3061799e-11 2.5691851e-14 6.3284969e-14], sum to 1.0000
[2019-03-27 04:56:26,205] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6603
[2019-03-27 04:56:26,211] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8137913683637338, 6.9112, 6.9112, 168.912956510431, 681127.1832627802, 681127.1832627802, 204677.4171322124], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4838400.0000, 
sim time next is 4839000.0000, 
raw observation next is [27.0, 79.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8119488087481421, 6.9112, 6.9112, 168.912956510431, 679744.7718240013, 679744.7718240013, 204295.3792592102], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.7900000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7706692789611489, 0.0, 0.0, 0.8294399451523027, 0.1888179921733337, 0.1888179921733337, 0.3049184765062839], 
reward next is 0.6951, 
noisyNet noise sample is [array([-0.8679441], dtype=float32), 1.7055619]. 
=============================================
[2019-03-27 04:56:26,227] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[43.926598]
 [44.19165 ]
 [44.156254]
 [44.113426]
 [44.08052 ]], R is [[43.84220505]
 [44.0982933 ]
 [44.35129166]
 [44.6013031 ]
 [44.84824753]].
[2019-03-27 04:56:29,367] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999928e-01 7.7758147e-09 7.2492389e-07 2.4135016e-10 2.9793476e-08], sum to 1.0000
[2019-03-27 04:56:29,379] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5066
[2019-03-27 04:56:29,388] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1967046.197912623 W.
[2019-03-27 04:56:29,394] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.7656827546155419, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.992523229423831, 6.9112, 168.9124728957477, 1967046.197912623, 1909352.865212063, 400045.6746278131], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4885200.0000, 
sim time next is 4885800.0000, 
raw observation next is [31.16666666666667, 65.5, 1.0, 2.0, 0.487938283844185, 1.0, 1.0, 0.487938283844185, 1.0, 2.0, 0.8443958631200741, 6.911199999999999, 6.9112, 170.5573041426782, 2046733.087251164, 2046733.087251165, 406380.3673911393], 
processed observation next is [1.0, 0.5652173913043478, 0.6761453396524489, 0.655, 1.0, 1.0, 0.383058173306247, 1.0, 0.5, 0.383058173306247, 1.0, 1.0, 0.810238857463505, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5685369686808789, 0.5685369686808791, 0.6065378617778199], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.11300577], dtype=float32), -1.8214858]. 
=============================================
[2019-03-27 04:56:36,334] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.8607672e-12 4.0433282e-11 2.2089215e-13 5.8026665e-12], sum to 1.0000
[2019-03-27 04:56:36,340] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3245
[2019-03-27 04:56:36,345] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 83.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8475898799194919, 6.911199999999999, 6.9112, 168.912956510431, 704549.8305291543, 704549.8305291549, 211784.1280812527], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5003400.0000, 
sim time next is 5004000.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.854670448719062, 6.911199999999999, 6.9112, 168.912956510431, 709203.2161805714, 709203.2161805719, 213299.7034587367], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8227688399012951, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19700089338349205, 0.1970008933834922, 0.31835776635632346], 
reward next is 0.6816, 
noisyNet noise sample is [array([1.1778232], dtype=float32), 1.6875207]. 
=============================================
[2019-03-27 04:56:36,358] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[46.144527]
 [46.104366]
 [45.999763]
 [45.8031  ]
 [45.7365  ]], R is [[46.41472244]
 [46.63447952]
 [46.8542366 ]
 [47.07400131]
 [47.29366684]].
[2019-03-27 04:56:37,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.9792109e-13 9.2055918e-10 1.1447325e-13 5.7410170e-12], sum to 1.0000
[2019-03-27 04:56:37,283] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-27 04:56:37,291] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7926477907446777, 6.911199999999999, 6.9112, 168.912956510431, 665815.2861503358, 665815.2861503364, 200357.3155517029], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5017200.0000, 
sim time next is 5017800.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7919700897199681, 6.911200000000001, 6.9112, 168.912956510431, 665248.7122957862, 665248.7122957857, 200219.1338052814], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7463049874633756, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18479130897105173, 0.18479130897105156, 0.29883452806758415], 
reward next is 0.7012, 
noisyNet noise sample is [array([-0.7801906], dtype=float32), -1.4785542]. 
=============================================
[2019-03-27 04:56:40,262] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.00000000e+00 1.10843350e-14 1.00519866e-13 1.06141677e-15
 9.32597844e-14], sum to 1.0000
[2019-03-27 04:56:40,271] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6734
[2019-03-27 04:56:40,275] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.83333333333333, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8867670792820942, 6.9112, 6.9112, 168.912956510431, 729521.166982444, 729521.166982444, 220283.5269376567], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5064600.0000, 
sim time next is 5065200.0000, 
raw observation next is [32.0, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8887178176374593, 6.911200000000001, 6.9112, 168.912956510431, 730868.8459204015, 730868.8459204008, 220719.7672989916], 
processed observation next is [0.0, 0.6521739130434783, 0.7156398104265403, 0.59, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8642900215090967, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2030191238667782, 0.203019123866778, 0.3294324885059576], 
reward next is 0.6706, 
noisyNet noise sample is [array([0.25254133], dtype=float32), -0.35353452]. 
=============================================
[2019-03-27 04:56:40,472] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.1027904e-14 6.4442906e-13 3.2516204e-15 9.1886850e-13], sum to 1.0000
[2019-03-27 04:56:40,482] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7819
[2019-03-27 04:56:40,488] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.16666666666667, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8838297563978447, 6.911199999999999, 6.9112, 168.912956510431, 727791.4055608013, 727791.405560802, 219639.9261578572], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5068200.0000, 
sim time next is 5068800.0000, 
raw observation next is [31.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8831961383205899, 6.911199999999999, 6.9112, 168.912956510431, 727580.7199703257, 727580.7199703263, 219507.538367441], 
processed observation next is [0.0, 0.6956521739130435, 0.6682464454976303, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8575562662446217, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2021057555473127, 0.20210575554731286, 0.32762319159319553], 
reward next is 0.6724, 
noisyNet noise sample is [array([-1.4586769], dtype=float32), -0.78300536]. 
=============================================
[2019-03-27 04:56:41,405] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.6338494e-15 1.6355369e-13 1.4554959e-16 1.3856218e-15], sum to 1.0000
[2019-03-27 04:56:41,416] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4327
[2019-03-27 04:56:41,426] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8690559431913071, 6.911199999999999, 6.9112, 168.912956510431, 720101.3468800919, 720101.3468800925, 216463.3277003682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5091600.0000, 
sim time next is 5092200.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8692820657962093, 6.9112, 6.9112, 168.912956510431, 720308.896555987, 720308.896555987, 216514.6994919917], 
processed observation next is [0.0, 0.9565217391304348, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8405878851173284, 0.0, 0.0, 0.8294399451523027, 0.20008580459888525, 0.20008580459888525, 0.32315626789849505], 
reward next is 0.6768, 
noisyNet noise sample is [array([-0.29593593], dtype=float32), 0.12467727]. 
=============================================
[2019-03-27 04:56:41,527] A3C_AGENT_WORKER-Thread-11 INFO:Local step 8500, global step 135735: loss 1.3085
[2019-03-27 04:56:41,529] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 8500, global step 135735: learning rate 0.0000
[2019-03-27 04:56:41,796] A3C_AGENT_WORKER-Thread-13 INFO:Local step 8500, global step 135855: loss 1.6642
[2019-03-27 04:56:41,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 8500, global step 135856: learning rate 0.0000
[2019-03-27 04:56:41,862] A3C_AGENT_WORKER-Thread-19 INFO:Local step 8500, global step 135887: loss 1.6139
[2019-03-27 04:56:41,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 8500, global step 135887: learning rate 0.0000
[2019-03-27 04:56:41,898] A3C_AGENT_WORKER-Thread-22 INFO:Local step 8500, global step 135898: loss 1.4456
[2019-03-27 04:56:41,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 8500, global step 135900: learning rate 0.0000
[2019-03-27 04:56:41,930] A3C_AGENT_WORKER-Thread-2 INFO:Local step 8500, global step 135916: loss 1.5195
[2019-03-27 04:56:41,932] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 8500, global step 135916: learning rate 0.0000
[2019-03-27 04:56:41,973] A3C_AGENT_WORKER-Thread-21 INFO:Local step 8500, global step 135937: loss 1.1199
[2019-03-27 04:56:41,974] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 8500, global step 135937: learning rate 0.0000
[2019-03-27 04:56:42,011] A3C_AGENT_WORKER-Thread-16 INFO:Local step 8500, global step 135953: loss 1.0606
[2019-03-27 04:56:42,013] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 8500, global step 135954: learning rate 0.0000
[2019-03-27 04:56:42,020] A3C_AGENT_WORKER-Thread-20 INFO:Local step 8500, global step 135956: loss 1.4657
[2019-03-27 04:56:42,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 8500, global step 135956: learning rate 0.0000
[2019-03-27 04:56:42,123] A3C_AGENT_WORKER-Thread-3 INFO:Local step 8500, global step 136000: loss 1.3185
[2019-03-27 04:56:42,125] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 8500, global step 136001: learning rate 0.0000
[2019-03-27 04:56:42,157] A3C_AGENT_WORKER-Thread-18 INFO:Local step 8500, global step 136016: loss 1.2592
[2019-03-27 04:56:42,158] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 8500, global step 136016: learning rate 0.0000
[2019-03-27 04:56:42,245] A3C_AGENT_WORKER-Thread-9 INFO:Local step 8500, global step 136053: loss 1.1778
[2019-03-27 04:56:42,248] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 8500, global step 136053: learning rate 0.0000
[2019-03-27 04:56:42,262] A3C_AGENT_WORKER-Thread-10 INFO:Local step 8500, global step 136064: loss 1.2077
[2019-03-27 04:56:42,264] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 8500, global step 136064: learning rate 0.0000
[2019-03-27 04:56:42,315] A3C_AGENT_WORKER-Thread-15 INFO:Local step 8500, global step 136085: loss 1.1851
[2019-03-27 04:56:42,317] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 8500, global step 136085: learning rate 0.0000
[2019-03-27 04:56:42,371] A3C_AGENT_WORKER-Thread-12 INFO:Local step 8500, global step 136108: loss 1.2606
[2019-03-27 04:56:42,375] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 8500, global step 136108: learning rate 0.0000
[2019-03-27 04:56:42,417] A3C_AGENT_WORKER-Thread-17 INFO:Local step 8500, global step 136130: loss 1.1427
[2019-03-27 04:56:42,419] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 8500, global step 136130: learning rate 0.0000
[2019-03-27 04:56:42,563] A3C_AGENT_WORKER-Thread-14 INFO:Local step 8500, global step 136196: loss 1.4348
[2019-03-27 04:56:42,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 8500, global step 136197: learning rate 0.0000
[2019-03-27 04:56:52,997] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.0125504e-11 1.4052959e-08 1.7582748e-11 1.2646137e-10], sum to 1.0000
[2019-03-27 04:56:53,005] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-27 04:56:53,014] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1362651.249489895 W.
[2019-03-27 04:56:53,022] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.6, 88.0, 1.0, 2.0, 0.4874366401380055, 1.0, 1.0, 0.4874366401380055, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1362651.249489895, 1362651.249489895, 296407.1685179247], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5284800.0000, 
sim time next is 5285400.0000, 
raw observation next is [28.6, 88.00000000000001, 1.0, 2.0, 0.9206540350193985, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104293, 1286827.100684522, 1286827.100684521, 275686.2238810686], 
processed observation next is [1.0, 0.17391304347826086, 0.5545023696682465, 0.8800000000000001, 1.0, 1.0, 0.9044024518306005, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451522944, 0.3574519724123672, 0.3574519724123669, 0.4114719759418934], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9735675], dtype=float32), 0.76736796]. 
=============================================
[2019-03-27 04:56:55,865] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999964e-01 3.6763070e-10 3.3280855e-07 2.0657703e-12 1.2618623e-09], sum to 1.0000
[2019-03-27 04:56:55,873] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9224
[2019-03-27 04:56:55,879] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.65, 59.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.952171830656114, 6.9112, 168.9125460367214, 857879.0139624907, 828812.25778847, 254813.2126866746], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5334600.0000, 
sim time next is 5335200.0000, 
raw observation next is [34.4, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.037759047343395, 6.9112, 168.9120478141572, 918620.8108088546, 828835.9498128912, 254813.2350534362], 
processed observation next is [1.0, 0.782608695652174, 0.8293838862559241, 0.61, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01265590473433953, 0.0, 0.8294354830375954, 0.2551724474469041, 0.23023220828135865, 0.3803182612737854], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6795861], dtype=float32), -1.2332312]. 
=============================================
[2019-03-27 04:56:58,272] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.99989033e-01 1.52985233e-08 1.06921825e-05 1.52480500e-10
 2.16502755e-07], sum to 1.0000
[2019-03-27 04:56:58,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7873
[2019-03-27 04:56:58,287] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1436235.146222824 W.
[2019-03-27 04:56:58,291] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.3, 94.0, 1.0, 2.0, 0.5137375089845048, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8921921575157067, 6.911199999999999, 6.9112, 168.9129565104176, 1436235.146222824, 1436235.146222825, 315722.0989634955], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5374800.0000, 
sim time next is 5375400.0000, 
raw observation next is [28.5, 92.66666666666667, 1.0, 2.0, 0.4561178589137278, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7921258804522248, 6.911200000000001, 6.9112, 168.912956510431, 1275053.48833952, 1275053.48833952, 285502.4631025765], 
processed observation next is [1.0, 0.21739130434782608, 0.5497630331753555, 0.9266666666666667, 1.0, 1.0, 0.34472031194425035, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7464949761612496, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.35418152453875557, 0.35418152453875557, 0.42612307925757686], 
reward next is 0.5739, 
noisyNet noise sample is [array([0.9021368], dtype=float32), 0.01220832]. 
=============================================
[2019-03-27 04:56:59,453] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9000, global step 143833: loss 57.7655
[2019-03-27 04:56:59,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9000, global step 143833: learning rate 0.0000
[2019-03-27 04:56:59,516] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9000, global step 143866: loss -33.6806
[2019-03-27 04:56:59,521] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9000, global step 143867: learning rate 0.0000
[2019-03-27 04:56:59,552] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9000, global step 143882: loss -8.9215
[2019-03-27 04:56:59,554] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9000, global step 143882: learning rate 0.0000
[2019-03-27 04:56:59,593] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9000, global step 143898: loss -19.5119
[2019-03-27 04:56:59,595] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9000, global step 143898: learning rate 0.0000
[2019-03-27 04:56:59,606] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9000, global step 143904: loss 14.3337
[2019-03-27 04:56:59,607] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9000, global step 143904: learning rate 0.0000
[2019-03-27 04:56:59,675] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9000, global step 143941: loss 38.1060
[2019-03-27 04:56:59,681] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9000, global step 143942: learning rate 0.0000
[2019-03-27 04:56:59,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9000, global step 143958: loss -20.6311
[2019-03-27 04:56:59,714] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9000, global step 143958: learning rate 0.0000
[2019-03-27 04:56:59,829] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9000, global step 144007: loss 19.5859
[2019-03-27 04:56:59,831] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9000, global step 144008: learning rate 0.0000
[2019-03-27 04:56:59,848] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9000, global step 144016: loss 27.8625
[2019-03-27 04:56:59,850] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9000, global step 144018: learning rate 0.0000
[2019-03-27 04:56:59,884] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9000, global step 144033: loss 42.6690
[2019-03-27 04:56:59,886] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9000, global step 144034: learning rate 0.0000
[2019-03-27 04:56:59,891] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9000, global step 144036: loss 5.2196
[2019-03-27 04:56:59,894] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9000, global step 144037: learning rate 0.0000
[2019-03-27 04:56:59,913] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9000, global step 144046: loss -6.6383
[2019-03-27 04:56:59,915] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9000, global step 144046: learning rate 0.0000
[2019-03-27 04:56:59,924] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9000, global step 144049: loss -2.5481
[2019-03-27 04:56:59,927] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9000, global step 144050: learning rate 0.0000
[2019-03-27 04:56:59,964] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9000, global step 144065: loss 42.6110
[2019-03-27 04:56:59,969] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9000, global step 144067: learning rate 0.0000
[2019-03-27 04:57:00,000] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9000, global step 144083: loss -0.2906
[2019-03-27 04:57:00,003] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9000, global step 144085: learning rate 0.0000
[2019-03-27 04:57:00,255] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9000, global step 144202: loss 30.8823
[2019-03-27 04:57:00,257] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9000, global step 144202: learning rate 0.0000
[2019-03-27 04:57:00,287] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9992228e-01 1.9727280e-07 7.6419310e-05 5.2001753e-10 1.0286323e-06], sum to 1.0000
[2019-03-27 04:57:00,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9585
[2019-03-27 04:57:00,305] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 3226634.161512463 W.
[2019-03-27 04:57:00,309] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [37.81666666666666, 54.0, 1.0, 2.0, 0.8965274907072218, 1.0, 2.0, 0.7688537848678734, 1.0, 2.0, 1.03, 7.005113233285303, 6.9112, 170.5573041426782, 3226634.161512463, 3159360.292364116, 590593.9171778838], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5410200.0000, 
sim time next is 5410800.0000, 
raw observation next is [38.0, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.100506977735604, 6.9112, 170.5573041426782, 3762271.224260708, 2910322.258193932, 546629.6173228882], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.11893069777356038, 0.0, 0.8375144448122397, 1.0450753400724189, 0.8084228494983144, 0.8158651004819227], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73543316], dtype=float32), 0.5445679]. 
=============================================
[2019-03-27 04:57:04,004] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9997902e-01 4.2242728e-08 2.0857584e-05 1.8277282e-10 6.4486720e-08], sum to 1.0000
[2019-03-27 04:57:04,013] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0107
[2019-03-27 04:57:04,021] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1501191.733399304 W.
[2019-03-27 04:57:04,024] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 76.0, 1.0, 2.0, 0.3579730322515337, 1.0, 2.0, 0.3579730322515337, 1.0, 2.0, 0.6216807735301426, 6.9112, 6.9112, 170.5573041426782, 1501191.733399304, 1501191.733399304, 330845.3073007327], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5472000.0000, 
sim time next is 5472600.0000, 
raw observation next is [31.21666666666667, 75.33333333333334, 1.0, 2.0, 0.3610792936413305, 1.0, 2.0, 0.3610792936413305, 1.0, 2.0, 0.6270753223078808, 6.9112, 6.9112, 170.5573041426782, 1514227.318379038, 1514227.318379038, 332391.1904416332], 
processed observation next is [1.0, 0.34782608695652173, 0.6785150078988943, 0.7533333333333334, 1.0, 1.0, 0.23021601643533796, 1.0, 1.0, 0.23021601643533796, 1.0, 1.0, 0.5452138076925375, 0.0, 0.0, 0.8375144448122397, 0.4206186995497328, 0.4206186995497328, 0.4961062543904973], 
reward next is 0.5039, 
noisyNet noise sample is [array([-0.25001764], dtype=float32), 0.042045183]. 
=============================================
[2019-03-27 04:57:10,238] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9985301e-01 1.9567665e-07 1.4590958e-04 3.5789405e-10 7.9621839e-07], sum to 1.0000
[2019-03-27 04:57:10,244] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3145
[2019-03-27 04:57:10,251] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2298394.091761811 W.
[2019-03-27 04:57:10,254] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 49.33333333333334, 1.0, 2.0, 0.5478727443642728, 1.0, 2.0, 0.5478727443642728, 1.0, 2.0, 0.9422292760623224, 6.9112, 6.9112, 170.5573041426782, 2298394.091761811, 2298394.091761811, 447974.9080327479], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5578800.0000, 
sim time next is 5579400.0000, 
raw observation next is [34.1, 48.66666666666666, 1.0, 2.0, 0.5461681627475398, 1.0, 2.0, 0.5461681627475398, 1.0, 2.0, 0.9383228345112237, 6.9112, 6.9112, 170.5573041426782, 2291236.605282337, 2291236.605282337, 446501.2728391011], 
processed observation next is [1.0, 0.5652173913043478, 0.8151658767772513, 0.4866666666666666, 1.0, 1.0, 0.4532146539126985, 1.0, 1.0, 0.4532146539126985, 1.0, 1.0, 0.9247839445258824, 0.0, 0.0, 0.8375144448122397, 0.636454612578427, 0.636454612578427, 0.6664198102076135], 
reward next is 0.3336, 
noisyNet noise sample is [array([0.17543621], dtype=float32), 0.6175357]. 
=============================================
[2019-03-27 04:57:12,693] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 04:57:12,694] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 04:57:12,694] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 04:57:12,696] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:57:12,696] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:57:12,696] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 04:57:12,698] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 04:57:12,699] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 04:57:12,701] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:57:12,703] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:57:12,699] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 04:57:12,718] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run7
[2019-03-27 04:57:12,718] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run7
[2019-03-27 04:57:12,718] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run7
[2019-03-27 04:57:12,736] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run7
[2019-03-27 04:57:12,793] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run7
[2019-03-27 04:57:34,575] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:57:34,578] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.92854687, 58.29713357333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7730457532546209, 6.911200000000001, 6.9112, 168.912956510431, 652317.5938059192, 652317.5938059186, 196463.0738942382]
[2019-03-27 04:57:34,579] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:57:34,585] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 6.9757980e-13 4.3470538e-10 8.2592980e-15 5.5169771e-12], sampled 0.21171118581494874
[2019-03-27 04:57:45,872] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:57:45,873] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.54562172666667, 70.58925841666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8158846342632202, 6.9112, 6.9112, 168.912956510431, 686179.5282805773, 686179.5282805773, 205189.0266753746]
[2019-03-27 04:57:45,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:57:45,878] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 9.5534811e-13 2.0254090e-09 1.1295109e-14 8.4719627e-12], sampled 0.2829208036194617
[2019-03-27 04:57:51,229] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:57:51,230] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.674120462807829, 6.9112, 6.9112, 168.912956510431, 579853.4706101741, 579853.4706101741, 178176.8827542371]
[2019-03-27 04:57:51,232] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:57:51,234] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 6.8092016e-13 4.2944509e-10 7.3997188e-15 5.4498949e-12], sampled 0.23474857897790802
[2019-03-27 04:58:06,037] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:58:06,039] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.33333333333333, 64.33333333333334, 1.0, 2.0, 0.8358893510107261, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990430638588699, 6.9112, 168.9124205130705, 2065303.137033347, 2009094.37347353, 417480.6435713698]
[2019-03-27 04:58:06,040] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:58:06,044] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999976e-01 1.5911376e-10 1.9145448e-07 9.5665164e-13 2.4509266e-09], sampled 0.7420388819311688
[2019-03-27 04:58:06,047] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2065303.137033347 W.
[2019-03-27 04:58:34,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:58:34,973] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.06666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8685576208519183, 6.911200000000001, 6.9112, 168.912956510431, 719288.0111071462, 719288.0111071455, 216338.233822428]
[2019-03-27 04:58:34,975] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 04:58:34,980] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 8.4836657e-13 5.3163374e-10 9.0722404e-15 7.3321384e-12], sampled 0.35284126925716175
[2019-03-27 04:58:44,479] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:58:44,481] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9558545941835734, 6.9112, 6.9112, 168.912956510431, 776023.591791735, 776023.591791735, 236238.0786796576]
[2019-03-27 04:58:44,482] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 04:58:44,487] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.2263434e-14 6.0709819e-11 5.3857536e-16 7.1741945e-13], sampled 0.5456835307776452
[2019-03-27 04:58:45,829] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:58:45,830] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.28441551333334, 58.35208536333334, 1.0, 2.0, 0.6033029142863233, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 875584.1654025586, 875584.1654025586, 205523.2291826139]
[2019-03-27 04:58:45,832] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 04:58:45,835] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9998248e-01 1.5427352e-08 1.7440076e-05 2.0879395e-10 6.9574760e-08], sampled 0.9133842575916343
[2019-03-27 04:58:45,836] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 875584.1654025586 W.
[2019-03-27 04:59:00,244] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.040850308]
[2019-03-27 04:59:00,246] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.07290236666667, 91.09812837666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6073946187036869, 6.9112, 6.9112, 168.912956510431, 529138.852963786, 529138.852963786, 167206.9175078125]
[2019-03-27 04:59:00,248] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 04:59:00,250] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 4.3183052e-13 2.7618857e-10 5.0728621e-15 3.7289598e-12], sampled 0.5181715395200135
[2019-03-27 04:59:06,493] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.3232 2937818257.1665 1381.0000
[2019-03-27 04:59:06,655] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7031.3407 3185096716.9286 2464.0000
[2019-03-27 04:59:06,717] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.8961 2989343462.0319 1566.0000
[2019-03-27 04:59:06,798] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7288.2342 3319482626.6880 2143.0000
[2019-03-27 04:59:06,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7346.1928 3105684032.4538 2010.0000
[2019-03-27 04:59:07,962] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 150000, evaluation results [150000.0, 7288.2341555039875, 3319482626.6880374, 2143.0, 7346.192795054945, 3105684032.4538403, 2010.0, 8060.323193029773, 2937818257.1665115, 1381.0, 7031.340658675213, 3185096716.9285784, 2464.0, 7923.8961117283225, 2989343462.031945, 1566.0]
[2019-03-27 04:59:12,007] A3C_AGENT_WORKER-Thread-11 INFO:Local step 9500, global step 151838: loss 0.0649
[2019-03-27 04:59:12,009] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 9500, global step 151838: learning rate 0.0000
[2019-03-27 04:59:12,063] A3C_AGENT_WORKER-Thread-22 INFO:Local step 9500, global step 151866: loss 0.0167
[2019-03-27 04:59:12,069] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 9500, global step 151868: learning rate 0.0000
[2019-03-27 04:59:12,165] A3C_AGENT_WORKER-Thread-20 INFO:Local step 9500, global step 151909: loss 0.0307
[2019-03-27 04:59:12,170] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 9500, global step 151909: learning rate 0.0000
[2019-03-27 04:59:12,182] A3C_AGENT_WORKER-Thread-13 INFO:Local step 9500, global step 151919: loss 0.0387
[2019-03-27 04:59:12,183] A3C_AGENT_WORKER-Thread-19 INFO:Local step 9500, global step 151919: loss 0.0412
[2019-03-27 04:59:12,184] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 9500, global step 151919: learning rate 0.0000
[2019-03-27 04:59:12,187] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 9500, global step 151919: learning rate 0.0000
[2019-03-27 04:59:12,251] A3C_AGENT_WORKER-Thread-2 INFO:Local step 9500, global step 151950: loss 0.0188
[2019-03-27 04:59:12,258] A3C_AGENT_WORKER-Thread-21 INFO:Local step 9500, global step 151952: loss 0.0269
[2019-03-27 04:59:12,259] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 9500, global step 151952: learning rate 0.0000
[2019-03-27 04:59:12,263] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 9500, global step 151954: learning rate 0.0000
[2019-03-27 04:59:12,280] A3C_AGENT_WORKER-Thread-9 INFO:Local step 9500, global step 151964: loss 0.0082
[2019-03-27 04:59:12,283] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 9500, global step 151965: learning rate 0.0000
[2019-03-27 04:59:12,285] A3C_AGENT_WORKER-Thread-16 INFO:Local step 9500, global step 151965: loss 0.0048
[2019-03-27 04:59:12,288] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 9500, global step 151966: learning rate 0.0000
[2019-03-27 04:59:12,322] A3C_AGENT_WORKER-Thread-10 INFO:Local step 9500, global step 151980: loss 0.0573
[2019-03-27 04:59:12,325] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 9500, global step 151980: learning rate 0.0000
[2019-03-27 04:59:12,410] A3C_AGENT_WORKER-Thread-18 INFO:Local step 9500, global step 152020: loss 0.0411
[2019-03-27 04:59:12,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 9500, global step 152020: learning rate 0.0000
[2019-03-27 04:59:12,453] A3C_AGENT_WORKER-Thread-17 INFO:Local step 9500, global step 152039: loss 0.0586
[2019-03-27 04:59:12,456] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 9500, global step 152039: learning rate 0.0000
[2019-03-27 04:59:12,477] A3C_AGENT_WORKER-Thread-15 INFO:Local step 9500, global step 152049: loss 0.0346
[2019-03-27 04:59:12,480] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 9500, global step 152051: learning rate 0.0000
[2019-03-27 04:59:12,544] A3C_AGENT_WORKER-Thread-3 INFO:Local step 9500, global step 152079: loss 0.0108
[2019-03-27 04:59:12,553] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 9500, global step 152081: learning rate 0.0000
[2019-03-27 04:59:12,649] A3C_AGENT_WORKER-Thread-12 INFO:Local step 9500, global step 152128: loss 0.0206
[2019-03-27 04:59:12,651] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 9500, global step 152128: learning rate 0.0000
[2019-03-27 04:59:12,833] A3C_AGENT_WORKER-Thread-14 INFO:Local step 9500, global step 152213: loss 0.0546
[2019-03-27 04:59:12,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 9500, global step 152213: learning rate 0.0000
[2019-03-27 04:59:16,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.2744671e-17 6.5888599e-14 6.5794494e-19 6.0062032e-16], sum to 1.0000
[2019-03-27 04:59:16,611] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3322
[2019-03-27 04:59:16,618] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.4, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9370724620659437, 6.911199999999999, 6.9112, 168.912956510431, 765468.7990664074, 765468.799066408, 231885.5946708721], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5773800.0000, 
sim time next is 5774400.0000, 
raw observation next is [28.2, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9341613863308733, 6.9112, 6.9112, 168.912956510431, 763576.5459721037, 763576.5459721037, 231205.4316115743], 
processed observation next is [0.0, 0.8695652173913043, 0.5355450236966824, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9197090077205772, 0.0, 0.0, 0.8294399451523027, 0.21210459610336213, 0.21210459610336213, 0.34508273374861836], 
reward next is 0.6549, 
noisyNet noise sample is [array([1.5569743], dtype=float32), -1.9562674]. 
=============================================
[2019-03-27 04:59:17,966] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.9659002e-16 1.2289388e-13 3.3691197e-18 9.8181865e-16], sum to 1.0000
[2019-03-27 04:59:17,975] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3587
[2019-03-27 04:59:17,980] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.85, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912333174402092, 6.911199999999999, 6.9112, 168.912956510431, 749495.9534510219, 749495.9534510225, 226172.0105084427], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5794200.0000, 
sim time next is 5794800.0000, 
raw observation next is [26.83333333333334, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9107215965492508, 6.9112, 6.9112, 168.912956510431, 748357.9406547945, 748357.9406547945, 225800.6717432599], 
processed observation next is [1.0, 0.043478260869565216, 0.4707740916271725, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8911238982307936, 0.0, 0.0, 0.8294399451523027, 0.2078772057374429, 0.2078772057374429, 0.3370159279750148], 
reward next is 0.6630, 
noisyNet noise sample is [array([-0.18491589], dtype=float32), -0.1557079]. 
=============================================
[2019-03-27 04:59:26,039] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9982458e-01 1.8205942e-08 1.7517536e-04 5.3447115e-11 2.6393528e-07], sum to 1.0000
[2019-03-27 04:59:26,046] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3823
[2019-03-27 04:59:26,053] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2306490.212671752 W.
[2019-03-27 04:59:26,056] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.3, 78.5, 1.0, 2.0, 0.824701280161622, 1.0, 2.0, 0.824701280161622, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2306490.212671752, 2306490.212671752, 432083.2174575955], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5934600.0000, 
sim time next is 5935200.0000, 
raw observation next is [30.33333333333334, 78.66666666666667, 1.0, 2.0, 0.5364320133782344, 1.0, 2.0, 0.5364320133782344, 1.0, 1.0, 0.9316050064603262, 6.9112, 6.9112, 170.5573041426782, 2250355.595265, 2250355.595265, 441254.8063064648], 
processed observation next is [1.0, 0.6956521739130435, 0.6366508688783573, 0.7866666666666667, 1.0, 1.0, 0.4414843534677523, 1.0, 1.0, 0.4414843534677523, 1.0, 0.5, 0.9165914712930806, 0.0, 0.0, 0.8375144448122397, 0.6250987764625, 0.6250987764625, 0.6585892631439773], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.55198795], dtype=float32), 1.4026507]. 
=============================================
[2019-03-27 04:59:28,072] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.1498015e-14 8.8395923e-12 1.3713542e-17 1.5982583e-14], sum to 1.0000
[2019-03-27 04:59:28,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1721
[2019-03-27 04:59:28,086] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.73333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9150438571775242, 6.9112, 6.9112, 168.912956510431, 749701.6522759163, 749701.6522759163, 226725.7492972493], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5964600.0000, 
sim time next is 5965200.0000, 
raw observation next is [26.7, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912318445338571, 6.9112, 6.9112, 168.912956510431, 747850.0484555494, 747850.0484555494, 226100.0848033288], 
processed observation next is [1.0, 0.043478260869565216, 0.46445497630331756, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8930712748031352, 0.0, 0.0, 0.8294399451523027, 0.20773612457098595, 0.20773612457098595, 0.3374628131392967], 
reward next is 0.6625, 
noisyNet noise sample is [array([0.5029745], dtype=float32), -0.34101984]. 
=============================================
[2019-03-27 04:59:29,748] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10000, global step 159828: loss 99.3956
[2019-03-27 04:59:29,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10000, global step 159828: learning rate 0.0000
[2019-03-27 04:59:29,861] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10000, global step 159879: loss -25.6853
[2019-03-27 04:59:29,863] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10000, global step 159879: learning rate 0.0000
[2019-03-27 04:59:29,888] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10000, global step 159890: loss 16.2605
[2019-03-27 04:59:29,891] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10000, global step 159891: learning rate 0.0000
[2019-03-27 04:59:29,975] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10000, global step 159923: loss 5.0936
[2019-03-27 04:59:29,978] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10000, global step 159923: learning rate 0.0000
[2019-03-27 04:59:29,991] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10000, global step 159929: loss -60.1488
[2019-03-27 04:59:29,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10000, global step 159930: learning rate 0.0000
[2019-03-27 04:59:30,030] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10000, global step 159952: loss 74.2429
[2019-03-27 04:59:30,032] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10000, global step 159953: loss 11.7017
[2019-03-27 04:59:30,034] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10000, global step 159954: learning rate 0.0000
[2019-03-27 04:59:30,038] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10000, global step 159955: learning rate 0.0000
[2019-03-27 04:59:30,053] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10000, global step 159961: loss 88.6970
[2019-03-27 04:59:30,054] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10000, global step 159961: learning rate 0.0000
[2019-03-27 04:59:30,097] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10000, global step 159978: loss -140.6251
[2019-03-27 04:59:30,099] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10000, global step 159978: learning rate 0.0000
[2019-03-27 04:59:30,129] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10000, global step 159992: loss -104.0789
[2019-03-27 04:59:30,131] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10000, global step 159992: learning rate 0.0000
[2019-03-27 04:59:30,142] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10000, global step 159997: loss -119.0552
[2019-03-27 04:59:30,143] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10000, global step 159997: learning rate 0.0000
[2019-03-27 04:59:30,224] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10000, global step 160038: loss -13.0651
[2019-03-27 04:59:30,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10000, global step 160038: learning rate 0.0000
[2019-03-27 04:59:30,274] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10000, global step 160058: loss -57.7047
[2019-03-27 04:59:30,276] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10000, global step 160058: learning rate 0.0000
[2019-03-27 04:59:30,298] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10000, global step 160067: loss -66.5539
[2019-03-27 04:59:30,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10000, global step 160068: learning rate 0.0000
[2019-03-27 04:59:30,444] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10000, global step 160133: loss -54.6159
[2019-03-27 04:59:30,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10000, global step 160133: learning rate 0.0000
[2019-03-27 04:59:30,570] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10000, global step 160189: loss -68.0103
[2019-03-27 04:59:30,572] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10000, global step 160189: learning rate 0.0000
[2019-03-27 04:59:34,769] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9989676e-01 1.3722347e-07 1.0280225e-04 4.0336623e-10 3.3885746e-07], sum to 1.0000
[2019-03-27 04:59:34,777] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4169
[2019-03-27 04:59:34,783] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2156294.823155802 W.
[2019-03-27 04:59:34,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.13333333333333, 77.66666666666667, 1.0, 2.0, 0.5140313852889796, 1.0, 2.0, 0.5140313852889796, 1.0, 2.0, 0.8927025234702007, 6.9112, 6.9112, 170.5573041426782, 2156294.823155802, 2156294.823155802, 424984.1662376212], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6079200.0000, 
sim time next is 6079800.0000, 
raw observation next is [29.26666666666667, 76.83333333333333, 1.0, 2.0, 0.4993482249987256, 1.0, 2.0, 0.4993482249987256, 1.0, 2.0, 0.8672027298413382, 6.9112, 6.9112, 170.5573041426782, 2094640.653483031, 2094640.653483031, 414694.9947105047], 
processed observation next is [1.0, 0.34782608695652173, 0.5860979462875199, 0.7683333333333333, 1.0, 1.0, 0.3968050903599104, 1.0, 1.0, 0.3968050903599104, 1.0, 1.0, 0.8380521095626075, 0.0, 0.0, 0.8375144448122397, 0.5818446259675086, 0.5818446259675086, 0.6189477532992608], 
reward next is 0.3811, 
noisyNet noise sample is [array([0.6633841], dtype=float32), 0.27710062]. 
=============================================
[2019-03-27 04:59:36,702] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999976e-01 1.4434406e-10 2.5846418e-07 7.3210438e-15 1.3133004e-10], sum to 1.0000
[2019-03-27 04:59:36,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4074
[2019-03-27 04:59:36,714] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8934434732622828, 6.911200000000001, 6.9112, 168.912956510431, 733869.9326706474, 733869.9326706467, 221769.6912886266], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6116400.0000, 
sim time next is 6117000.0000, 
raw observation next is [28.03333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8936789679767304, 6.9112, 6.9112, 168.912956510431, 734253.6139373227, 734253.6139373227, 221831.6422284505], 
processed observation next is [1.0, 0.8260869565217391, 0.5276461295418641, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8703402048496711, 0.0, 0.0, 0.8294399451523027, 0.20395933720481188, 0.20395933720481188, 0.33109200332604555], 
reward next is 0.6689, 
noisyNet noise sample is [array([1.0644383], dtype=float32), -0.11287876]. 
=============================================
[2019-03-27 04:59:36,739] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[42.222115]
 [40.476078]
 [39.02572 ]
 [36.871887]
 [34.66831 ]], R is [[43.93052292]
 [44.16021729]
 [44.38738632]
 [44.6120224 ]
 [44.83462906]].
[2019-03-27 04:59:42,197] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998713e-01 1.2268693e-09 1.2885395e-05 6.4730334e-13 2.8549623e-09], sum to 1.0000
[2019-03-27 04:59:42,204] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9007
[2019-03-27 04:59:42,208] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.901984486299245, 6.9112, 6.9112, 168.912956510431, 739609.1179921668, 739609.1179921668, 223693.3363318896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6200400.0000, 
sim time next is 6201000.0000, 
raw observation next is [28.25, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9024656810279819, 6.9112, 6.9112, 168.912956510431, 740049.2092168102, 740049.2092168102, 223807.146452011], 
processed observation next is [1.0, 0.782608695652174, 0.537914691943128, 0.805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8810557085707096, 0.0, 0.0, 0.8294399451523027, 0.20556922478244727, 0.20556922478244727, 0.3340405170925537], 
reward next is 0.6660, 
noisyNet noise sample is [array([-0.09062562], dtype=float32), -0.39424768]. 
=============================================
[2019-03-27 04:59:42,231] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[32.972607]
 [30.786697]
 [28.597603]
 [26.598589]
 [24.256912]], R is [[35.03029251]
 [35.34611893]
 [35.6587944 ]
 [35.970047  ]
 [36.28440857]].
[2019-03-27 04:59:43,223] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8586698e-14 7.9709406e-10 1.6157021e-17 5.6409581e-13], sum to 1.0000
[2019-03-27 04:59:43,229] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.6547993e-14 1.2961010e-09 1.9494740e-17 6.7681009e-14], sum to 1.0000
[2019-03-27 04:59:43,232] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6134
[2019-03-27 04:59:43,240] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.1, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8959027592590185, 6.911199999999999, 6.9112, 168.912956510431, 736851.004732017, 736851.0047320178, 222375.4489043158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6212400.0000, 
sim time next is 6213000.0000, 
raw observation next is [27.05, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8944617427956779, 6.911199999999999, 6.9112, 168.912956510431, 735945.995442398, 735945.9954423986, 222053.9197013462], 
processed observation next is [1.0, 0.9130434782608695, 0.4810426540284361, 0.8683333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.871294808287412, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2044294431784439, 0.20442944317844405, 0.3314237607482779], 
reward next is 0.6686, 
noisyNet noise sample is [array([0.9390589], dtype=float32), -0.10162084]. 
=============================================
[2019-03-27 04:59:43,241] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0024
[2019-03-27 04:59:43,246] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.7, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8853793044227138, 6.911200000000001, 6.9112, 168.912956510431, 729186.9839966964, 729186.9839966957, 219997.9126140033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6220800.0000, 
sim time next is 6221400.0000, 
raw observation next is [26.66666666666666, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8850593359303488, 6.911200000000001, 6.9112, 168.912956510431, 728926.1772644205, 728926.1772644198, 219924.985666754], 
processed observation next is [0.0, 0.0, 0.4628751974723536, 0.8916666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8598284584516448, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20247949368456125, 0.20247949368456106, 0.3282462472638119], 
reward next is 0.6718, 
noisyNet noise sample is [array([-0.09345666], dtype=float32), 1.0804019]. 
=============================================
[2019-03-27 04:59:43,258] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[54.515602]
 [54.231426]
 [54.005882]
 [53.36016 ]
 [52.929993]], R is [[54.89621735]
 [55.01535034]
 [55.13289642]
 [55.24872589]
 [55.36268616]].
[2019-03-27 04:59:46,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3831074e-16 2.5452310e-11 8.9874849e-19 7.7202454e-15], sum to 1.0000
[2019-03-27 04:59:46,309] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5116
[2019-03-27 04:59:46,315] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.76666666666667, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8565025298793214, 6.9112, 6.9112, 168.912956510431, 709576.1251180142, 709576.1251180142, 213666.387816258], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6273600.0000, 
sim time next is 6274200.0000, 
raw observation next is [30.73333333333333, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8541898968228473, 6.9112, 6.9112, 168.912956510431, 707970.7914016359, 707970.7914016359, 213166.7676123832], 
processed observation next is [0.0, 0.6086956521739131, 0.6556082148499209, 0.62, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8221828010034722, 0.0, 0.0, 0.8294399451523027, 0.19665855316712108, 0.19665855316712108, 0.31815935464534806], 
reward next is 0.6818, 
noisyNet noise sample is [array([0.6503137], dtype=float32), 0.13238193]. 
=============================================
[2019-03-27 04:59:47,452] A3C_AGENT_WORKER-Thread-22 INFO:Local step 10500, global step 167812: loss 0.0133
[2019-03-27 04:59:47,455] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 10500, global step 167812: learning rate 0.0000
[2019-03-27 04:59:47,468] A3C_AGENT_WORKER-Thread-11 INFO:Local step 10500, global step 167819: loss 0.0240
[2019-03-27 04:59:47,470] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 10500, global step 167819: learning rate 0.0000
[2019-03-27 04:59:47,544] A3C_AGENT_WORKER-Thread-2 INFO:Local step 10500, global step 167852: loss 0.0070
[2019-03-27 04:59:47,545] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 10500, global step 167852: learning rate 0.0000
[2019-03-27 04:59:47,593] A3C_AGENT_WORKER-Thread-19 INFO:Local step 10500, global step 167879: loss 0.0000
[2019-03-27 04:59:47,595] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 10500, global step 167879: learning rate 0.0000
[2019-03-27 04:59:47,602] A3C_AGENT_WORKER-Thread-20 INFO:Local step 10500, global step 167883: loss 0.0054
[2019-03-27 04:59:47,604] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 10500, global step 167883: learning rate 0.0000
[2019-03-27 04:59:47,711] A3C_AGENT_WORKER-Thread-21 INFO:Local step 10500, global step 167930: loss 0.0002
[2019-03-27 04:59:47,715] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 10500, global step 167930: learning rate 0.0000
[2019-03-27 04:59:47,770] A3C_AGENT_WORKER-Thread-13 INFO:Local step 10500, global step 167958: loss 0.0223
[2019-03-27 04:59:47,774] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 10500, global step 167960: learning rate 0.0000
[2019-03-27 04:59:47,847] A3C_AGENT_WORKER-Thread-9 INFO:Local step 10500, global step 167994: loss 0.0002
[2019-03-27 04:59:47,850] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 10500, global step 167995: learning rate 0.0000
[2019-03-27 04:59:47,877] A3C_AGENT_WORKER-Thread-10 INFO:Local step 10500, global step 168007: loss 0.0082
[2019-03-27 04:59:47,881] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 10500, global step 168009: learning rate 0.0000
[2019-03-27 04:59:47,950] A3C_AGENT_WORKER-Thread-3 INFO:Local step 10500, global step 168040: loss 0.0010
[2019-03-27 04:59:47,951] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 10500, global step 168040: learning rate 0.0000
[2019-03-27 04:59:47,961] A3C_AGENT_WORKER-Thread-18 INFO:Local step 10500, global step 168046: loss 0.0045
[2019-03-27 04:59:47,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 10500, global step 168047: learning rate 0.0000
[2019-03-27 04:59:48,018] A3C_AGENT_WORKER-Thread-17 INFO:Local step 10500, global step 168071: loss 0.0009
[2019-03-27 04:59:48,021] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 10500, global step 168071: learning rate 0.0000
[2019-03-27 04:59:48,084] A3C_AGENT_WORKER-Thread-12 INFO:Local step 10500, global step 168104: loss 0.0105
[2019-03-27 04:59:48,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 10500, global step 168104: learning rate 0.0000
[2019-03-27 04:59:48,091] A3C_AGENT_WORKER-Thread-15 INFO:Local step 10500, global step 168106: loss 0.0158
[2019-03-27 04:59:48,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 10500, global step 168106: learning rate 0.0000
[2019-03-27 04:59:48,170] A3C_AGENT_WORKER-Thread-16 INFO:Local step 10500, global step 168142: loss 0.0097
[2019-03-27 04:59:48,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 10500, global step 168142: learning rate 0.0000
[2019-03-27 04:59:48,213] A3C_AGENT_WORKER-Thread-14 INFO:Local step 10500, global step 168162: loss 0.0053
[2019-03-27 04:59:48,214] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 10500, global step 168162: learning rate 0.0000
[2019-03-27 04:59:51,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.9374329e-18 1.0800057e-13 2.9649779e-20 3.9518302e-17], sum to 1.0000
[2019-03-27 04:59:51,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9802
[2019-03-27 04:59:51,913] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.3, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8831654077440599, 6.9112, 6.9112, 168.912956510431, 728424.1880645432, 728424.1880645432, 219533.2766038986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [29.95, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8788970122800305, 6.9112, 6.9112, 168.912956510431, 725548.1012805, 725548.1012805, 218587.379815971], 
processed observation next is [0.0, 0.6956521739130435, 0.6184834123222749, 0.675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8523134296097932, 0.0, 0.0, 0.8294399451523027, 0.2015411392445833, 0.2015411392445833, 0.3262498206208523], 
reward next is 0.6738, 
noisyNet noise sample is [array([-1.1784365], dtype=float32), 0.48206922]. 
=============================================
[2019-03-27 04:59:52,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.7883106e-17 3.4740543e-13 4.9753576e-20 1.4876387e-15], sum to 1.0000
[2019-03-27 04:59:52,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1982
[2019-03-27 04:59:52,979] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.11666666666667, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632617588336631, 6.9112, 6.9112, 168.912956510431, 715957.8233583921, 715957.8233583921, 215190.6132176783], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6393000.0000, 
sim time next is 6393600.0000, 
raw observation next is [27.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.863752029375264, 6.9112, 6.9112, 168.912956510431, 716280.4644052556, 716280.4644052556, 215297.0678404122], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8338439382625169, 0.0, 0.0, 0.8294399451523027, 0.19896679566812656, 0.19896679566812656, 0.3213389072244958], 
reward next is 0.6787, 
noisyNet noise sample is [array([0.5179426], dtype=float32), -1.5095277]. 
=============================================
[2019-03-27 04:59:57,341] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999940e-01 1.2172418e-12 5.7818579e-07 1.4516476e-15 1.7540741e-10], sum to 1.0000
[2019-03-27 04:59:57,349] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9326
[2019-03-27 04:59:57,357] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.7, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8575817463525659, 6.911199999999999, 6.9112, 168.912956510431, 710990.5673872196, 710990.5673872202, 213921.959920195], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6462000.0000, 
sim time next is 6462600.0000, 
raw observation next is [28.58333333333334, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8552706387342602, 6.9112, 6.9112, 168.912956510431, 709282.1008905068, 709282.1008905068, 213418.4230555151], 
processed observation next is [1.0, 0.8260869565217391, 0.5537124802527649, 0.735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8235007789442197, 0.0, 0.0, 0.8294399451523027, 0.19702280580291853, 0.19702280580291853, 0.3185349597843509], 
reward next is 0.6815, 
noisyNet noise sample is [array([-0.25056532], dtype=float32), -0.28304234]. 
=============================================
[2019-03-27 04:59:58,224] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 9.3116119e-15 6.2414602e-09 4.3386616e-18 8.0483024e-14], sum to 1.0000
[2019-03-27 04:59:58,231] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9094
[2019-03-27 04:59:58,236] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9047314292749389, 6.911199999999999, 6.9112, 168.912956510431, 742967.1439800152, 742967.1439800158, 224378.9937529025], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6477000.0000, 
sim time next is 6477600.0000, 
raw observation next is [27.1, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9059957931789877, 6.9112, 6.9112, 168.912956510431, 744159.4963270957, 744159.4963270957, 224680.4969071164], 
processed observation next is [1.0, 1.0, 0.4834123222748816, 0.8733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8853607233890094, 0.0, 0.0, 0.8294399451523027, 0.20671097120197102, 0.20671097120197102, 0.33534402523450213], 
reward next is 0.6647, 
noisyNet noise sample is [array([-0.7345941], dtype=float32), 0.17890699]. 
=============================================
[2019-03-27 04:59:59,809] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9897552e-01 9.8240442e-08 1.0238106e-03 1.4275298e-10 5.4676201e-07], sum to 1.0000
[2019-03-27 04:59:59,816] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5270
[2019-03-27 04:59:59,825] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 965111.2443262269 W.
[2019-03-27 04:59:59,828] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.93333333333334, 88.33333333333334, 1.0, 2.0, 0.6905885828498616, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 965111.2443262269, 965111.2443262263, 218826.6393590588], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6506400.0000, 
sim time next is 6507000.0000, 
raw observation next is [27.0, 88.0, 1.0, 2.0, 0.2370975508697032, 1.0, 1.0, 0.2370975508697032, 1.0, 1.0, 0.4058619360208585, 6.9112, 6.9112, 170.5573041426782, 994054.6489526869, 994054.6489526869, 280647.060316117], 
processed observation next is [1.0, 0.30434782608695654, 0.4786729857819906, 0.88, 1.0, 1.0, 0.08084042273458214, 1.0, 0.5, 0.08084042273458214, 1.0, 0.5, 0.27544138539129087, 0.0, 0.0, 0.8375144448122397, 0.27612629137574635, 0.27612629137574635, 0.41887620942704035], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.80539525], dtype=float32), -0.302836]. 
=============================================
[2019-03-27 04:59:59,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[22.853748]
 [23.047918]
 [22.289408]
 [22.544088]
 [22.963133]], R is [[22.72914124]
 [22.50185013]
 [22.86669731]
 [23.27693748]
 [23.70784187]].
[2019-03-27 05:00:00,598] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9072146e-01 3.2767440e-07 9.2711328e-03 1.1742719e-10 7.0562978e-06], sum to 1.0000
[2019-03-27 05:00:00,605] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4231
[2019-03-27 05:00:00,609] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1961573.092552394 W.
[2019-03-27 05:00:00,612] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.1, 57.0, 1.0, 2.0, 0.467654830643781, 1.0, 2.0, 0.467654830643781, 1.0, 1.0, 0.7913377288505222, 6.9112, 6.9112, 170.5573041426782, 1961573.092552394, 1961573.092552394, 389946.6471819687], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6519600.0000, 
sim time next is 6520200.0000, 
raw observation next is [31.15, 56.83333333333333, 1.0, 2.0, 0.4734261159721677, 1.0, 2.0, 0.4734261159721677, 1.0, 2.0, 0.801569869384444, 6.911199999999999, 6.9112, 170.5573041426782, 1985803.121195185, 1985803.121195186, 393692.0404371203], 
processed observation next is [1.0, 0.4782608695652174, 0.6753554502369667, 0.5683333333333332, 1.0, 1.0, 0.36557363370140694, 1.0, 1.0, 0.36557363370140694, 1.0, 1.0, 0.7580120358346878, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5516119781097736, 0.5516119781097739, 0.5876000603539109], 
reward next is 0.4124, 
noisyNet noise sample is [array([-0.2675672], dtype=float32), 3.3729744]. 
=============================================
[2019-03-27 05:00:00,819] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9390537e-01 2.4491581e-07 6.0937088e-03 1.3334248e-10 6.7061541e-07], sum to 1.0000
[2019-03-27 05:00:00,827] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5319
[2019-03-27 05:00:00,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2128172.351886962 W.
[2019-03-27 05:00:00,838] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.95, 55.5, 1.0, 2.0, 0.8808072836115121, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.971044730610434, 6.9112, 168.9125504506378, 2128172.351886962, 2085716.542357516, 429962.3136576141], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6528600.0000, 
sim time next is 6529200.0000, 
raw observation next is [32.0, 55.33333333333333, 1.0, 2.0, 0.7362710205028504, 1.0, 1.0, 0.7362710205028504, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2058947.332026562, 2058947.332026562, 390030.1557768427], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.5533333333333332, 1.0, 1.0, 0.6822542415696993, 1.0, 0.5, 0.6822542415696993, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5719298144518228, 0.5719298144518228, 0.5821345608609592], 
reward next is 0.4179, 
noisyNet noise sample is [array([0.8564], dtype=float32), 1.453024]. 
=============================================
[2019-03-27 05:00:02,410] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 4.7594283e-14 1.8636371e-07 8.2844679e-17 1.2845905e-12], sum to 1.0000
[2019-03-27 05:00:02,419] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6827
[2019-03-27 05:00:02,424] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8228668859647873, 6.9112, 6.9112, 168.912956510431, 686945.8392241794, 686945.8392241794, 206546.552020759], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6554400.0000, 
sim time next is 6555000.0000, 
raw observation next is [27.75, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8261276160033082, 6.911200000000001, 6.9112, 168.912956510431, 689131.4580409565, 689131.458040956, 207225.015565495], 
processed observation next is [1.0, 0.8695652173913043, 0.514218009478673, 0.7633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7879605073211076, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1914254050113768, 0.19142540501137664, 0.3092910680082015], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.29960003], dtype=float32), 0.9629428]. 
=============================================
[2019-03-27 05:00:02,448] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[57.87486 ]
 [57.369816]
 [56.956364]
 [56.475296]
 [55.68768 ]], R is [[58.35022354]
 [58.4584465 ]
 [58.5668335 ]
 [58.67544556]
 [58.78436279]].
[2019-03-27 05:00:02,854] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 05:00:02,856] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:00:02,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:00:02,858] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:00:02,859] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:00:02,861] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:00:02,862] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:00:02,861] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:00:02,863] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:00:02,864] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:00:02,866] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:00:02,873] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run8
[2019-03-27 05:00:02,892] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run8
[2019-03-27 05:00:02,892] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run8
[2019-03-27 05:00:02,893] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run8
[2019-03-27 05:00:02,946] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run8
[2019-03-27 05:00:27,975] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:00:27,976] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7626333722946302, 6.911199999999999, 6.9112, 168.912956510431, 651852.9403734016, 651852.9403734022, 194489.5866381874]
[2019-03-27 05:00:27,978] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:00:27,980] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.7867769e-14 2.2053477e-09 1.3323761e-16 1.5971995e-12], sampled 0.009168612172716362
[2019-03-27 05:01:17,030] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:17,032] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.2, 80.0, 1.0, 1.0, 0.6099744304868036, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9128755365606, 852406.1570353237, 852406.1570353231, 202618.4332629711]
[2019-03-27 05:01:17,035] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:01:17,040] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999321e-01 2.3728855e-10 6.8244703e-06 8.2208231e-13 2.2406939e-09], sampled 0.0037598701974438375
[2019-03-27 05:01:30,753] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:30,755] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.6, 67.0, 1.0, 2.0, 0.9623782379345587, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987050067495408, 6.9112, 168.9124436905381, 2242344.653863259, 2188534.168793343, 452642.1901460944]
[2019-03-27 05:01:30,755] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:01:30,757] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9957842e-01 2.3203095e-09 4.2160763e-04 1.5102781e-12 2.4369440e-08], sampled 0.9958731172370346
[2019-03-27 05:01:30,758] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2242344.653863259 W.
[2019-03-27 05:01:43,042] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:43,045] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.85, 88.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.103991651438101, 6.9112, 168.9117809347617, 985571.9157693223, 848799.8347555161, 255841.0935141797]
[2019-03-27 05:01:43,046] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:01:43,047] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.99999881e-01 2.22302667e-12 1.77095515e-07 1.03727265e-14
 8.51660201e-11], sampled 0.9977680446803797
[2019-03-27 05:01:43,049] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 985571.9157693223 W.
[2019-03-27 05:01:47,339] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:47,341] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.5, 65.0, 1.0, 1.0, 0.6338515315347955, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128104370959, 885787.0238223172, 885787.0238223178, 207221.5137391863]
[2019-03-27 05:01:47,342] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:01:47,347] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9934465e-01 4.1554280e-09 6.5521838e-04 4.6888045e-12 1.0461265e-07], sampled 0.7341713458419182
[2019-03-27 05:01:47,349] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 885787.0238223172 W.
[2019-03-27 05:01:54,135] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:54,138] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.11666666666667, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5798987103378946, 6.9112, 6.9112, 168.912956510431, 509676.927431845, 509676.927431845, 162957.1240750182]
[2019-03-27 05:01:54,138] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:01:54,141] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.6232145e-13 6.5576331e-09 1.1570990e-15 6.7766331e-12], sampled 0.8474601561000688
[2019-03-27 05:01:55,666] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:55,668] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.24336926, 76.37784519666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.80467162502085, 6.9112, 6.9112, 168.912956510431, 676191.8856639356, 676191.8856639356, 202836.3723914754]
[2019-03-27 05:01:55,670] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:01:55,672] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 5.3869818e-14 1.1100109e-08 1.8814474e-16 1.5336405e-12], sampled 0.8723780324068479
[2019-03-27 05:01:56,453] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7028.1589 3185352004.1951 2462.0000
[2019-03-27 05:01:56,467] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.044205304]
[2019-03-27 05:01:56,469] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.31666666666667, 71.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6004516130069802, 6.911199999999999, 6.9112, 168.912956510431, 524557.6379558775, 524557.637955878, 166112.2530620891]
[2019-03-27 05:01:56,471] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:01:56,473] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.000000e+00 1.374384e-13 5.920261e-09 9.329883e-16 5.765367e-12], sampled 0.895747712299288
[2019-03-27 05:01:57,042] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.8628 2989327954.8668 1565.0000
[2019-03-27 05:01:57,136] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8059.6592 2937869902.9965 1378.0000
[2019-03-27 05:01:57,185] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7344.1995 3105743428.5800 2009.0000
[2019-03-27 05:01:57,206] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7281.8142 3319289261.3415 2147.0000
[2019-03-27 05:01:58,222] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 175000, evaluation results [175000.0, 7281.814227639344, 3319289261.341473, 2147.0, 7344.199489822554, 3105743428.579973, 2009.0, 8059.659243458467, 2937869902.996532, 1378.0, 7028.158915687621, 3185352004.1950755, 2462.0, 7924.8628001522275, 2989327954.8668227, 1565.0]
[2019-03-27 05:02:00,093] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11000, global step 175851: loss -169.4181
[2019-03-27 05:02:00,096] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11000, global step 175852: learning rate 0.0000
[2019-03-27 05:02:00,118] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11000, global step 175862: loss -157.4217
[2019-03-27 05:02:00,120] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11000, global step 175863: learning rate 0.0000
[2019-03-27 05:02:00,171] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11000, global step 175882: loss -75.2782
[2019-03-27 05:02:00,174] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11000, global step 175882: learning rate 0.0000
[2019-03-27 05:02:00,259] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11000, global step 175924: loss -128.8915
[2019-03-27 05:02:00,262] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11000, global step 175925: learning rate 0.0000
[2019-03-27 05:02:00,264] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11000, global step 175926: loss -164.4282
[2019-03-27 05:02:00,266] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11000, global step 175926: learning rate 0.0000
[2019-03-27 05:02:00,292] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11000, global step 175938: loss -159.9592
[2019-03-27 05:02:00,295] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11000, global step 175939: learning rate 0.0000
[2019-03-27 05:02:00,301] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11000, global step 175941: loss -201.3800
[2019-03-27 05:02:00,302] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11000, global step 175941: learning rate 0.0000
[2019-03-27 05:02:00,323] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11000, global step 175950: loss -38.6703
[2019-03-27 05:02:00,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11000, global step 175950: learning rate 0.0000
[2019-03-27 05:02:00,386] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11000, global step 175976: loss -244.6857
[2019-03-27 05:02:00,389] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11000, global step 175977: learning rate 0.0000
[2019-03-27 05:02:00,434] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11000, global step 175998: loss -94.8865
[2019-03-27 05:02:00,436] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11000, global step 175998: learning rate 0.0000
[2019-03-27 05:02:00,510] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11000, global step 176030: loss -311.1256
[2019-03-27 05:02:00,515] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11000, global step 176031: learning rate 0.0000
[2019-03-27 05:02:00,568] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11000, global step 176056: loss -137.1331
[2019-03-27 05:02:00,571] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11000, global step 176056: learning rate 0.0000
[2019-03-27 05:02:00,588] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11000, global step 176061: loss -145.2578
[2019-03-27 05:02:00,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11000, global step 176062: learning rate 0.0000
[2019-03-27 05:02:00,693] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11000, global step 176113: loss -9.7563
[2019-03-27 05:02:00,696] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11000, global step 176113: loss -53.2080
[2019-03-27 05:02:00,699] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11000, global step 176113: learning rate 0.0000
[2019-03-27 05:02:00,699] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11000, global step 176113: learning rate 0.0000
[2019-03-27 05:02:00,878] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11000, global step 176195: loss -193.1423
[2019-03-27 05:02:00,882] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11000, global step 176195: learning rate 0.0000
[2019-03-27 05:02:01,181] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7854733e-01 6.1640521e-06 2.1318076e-02 1.7500533e-09 1.2843468e-04], sum to 1.0000
[2019-03-27 05:02:01,193] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4245
[2019-03-27 05:02:01,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1774861.464141964 W.
[2019-03-27 05:02:01,205] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.6347671680824429, 1.0, 1.0, 0.6347671680824429, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1774861.464141964, 1774861.464141964, 347449.1765772364], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6610800.0000, 
sim time next is 6611400.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.390976051658733, 1.0, 2.0, 0.390976051658733, 1.0, 1.0, 0.6752490277814166, 6.9112, 6.9112, 170.5573041426782, 1639698.701452954, 1639698.701452954, 347440.4826534446], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.2662362068177506, 1.0, 1.0, 0.2662362068177506, 1.0, 0.5, 0.6039622290017275, 0.0, 0.0, 0.8375144448122397, 0.4554718615147094, 0.4554718615147094, 0.51856788455738], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.35304663], dtype=float32), 0.26079366]. 
=============================================
[2019-03-27 05:02:14,288] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.5182806e-15 7.6897266e-10 2.0591412e-17 1.4905379e-12], sum to 1.0000
[2019-03-27 05:02:14,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7230
[2019-03-27 05:02:14,302] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5985636711210064, 6.911199999999999, 6.9112, 168.912956510431, 522265.7318182595, 522265.7318182601, 165839.827266933], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6836400.0000, 
sim time next is 6837000.0000, 
raw observation next is [23.1, 81.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5994963572104329, 6.911199999999999, 6.9112, 168.912956510431, 523009.3995175673, 523009.3995175679, 165982.914856492], 
processed observation next is [0.0, 0.13043478260869565, 0.2938388625592418, 0.8116666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5115809234273572, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1452803887548798, 0.14528038875487997, 0.24773569381565969], 
reward next is 0.7523, 
noisyNet noise sample is [array([0.5645932], dtype=float32), 0.6110149]. 
=============================================
[2019-03-27 05:02:14,324] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[62.14297 ]
 [62.06719 ]
 [62.134304]
 [62.085125]
 [62.578873]], R is [[62.13700104]
 [62.26811218]
 [62.39818954]
 [62.52729797]
 [62.65542221]].
[2019-03-27 05:02:17,652] A3C_AGENT_WORKER-Thread-11 INFO:Local step 11500, global step 183762: loss 0.1894
[2019-03-27 05:02:17,654] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 11500, global step 183763: learning rate 0.0000
[2019-03-27 05:02:17,755] A3C_AGENT_WORKER-Thread-20 INFO:Local step 11500, global step 183810: loss 0.2898
[2019-03-27 05:02:17,758] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 11500, global step 183811: learning rate 0.0000
[2019-03-27 05:02:17,890] A3C_AGENT_WORKER-Thread-19 INFO:Local step 11500, global step 183870: loss 0.2205
[2019-03-27 05:02:17,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 11500, global step 183873: learning rate 0.0000
[2019-03-27 05:02:17,930] A3C_AGENT_WORKER-Thread-2 INFO:Local step 11500, global step 183888: loss 0.2167
[2019-03-27 05:02:17,937] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 11500, global step 183888: learning rate 0.0000
[2019-03-27 05:02:17,956] A3C_AGENT_WORKER-Thread-22 INFO:Local step 11500, global step 183899: loss 0.1815
[2019-03-27 05:02:17,957] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 11500, global step 183899: learning rate 0.0000
[2019-03-27 05:02:17,990] A3C_AGENT_WORKER-Thread-13 INFO:Local step 11500, global step 183914: loss 0.1694
[2019-03-27 05:02:17,993] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 11500, global step 183914: learning rate 0.0000
[2019-03-27 05:02:18,006] A3C_AGENT_WORKER-Thread-21 INFO:Local step 11500, global step 183921: loss 0.1525
[2019-03-27 05:02:18,007] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 11500, global step 183921: learning rate 0.0000
[2019-03-27 05:02:18,112] A3C_AGENT_WORKER-Thread-3 INFO:Local step 11500, global step 183969: loss 0.1581
[2019-03-27 05:02:18,115] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 11500, global step 183969: learning rate 0.0000
[2019-03-27 05:02:18,130] A3C_AGENT_WORKER-Thread-10 INFO:Local step 11500, global step 183974: loss 0.1174
[2019-03-27 05:02:18,133] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 11500, global step 183975: learning rate 0.0000
[2019-03-27 05:02:18,209] A3C_AGENT_WORKER-Thread-9 INFO:Local step 11500, global step 184008: loss 0.1226
[2019-03-27 05:02:18,211] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 11500, global step 184009: learning rate 0.0000
[2019-03-27 05:02:18,246] A3C_AGENT_WORKER-Thread-18 INFO:Local step 11500, global step 184027: loss 0.2870
[2019-03-27 05:02:18,248] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 11500, global step 184028: learning rate 0.0000
[2019-03-27 05:02:18,334] A3C_AGENT_WORKER-Thread-12 INFO:Local step 11500, global step 184066: loss 0.1651
[2019-03-27 05:02:18,336] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 11500, global step 184066: learning rate 0.0000
[2019-03-27 05:02:18,437] A3C_AGENT_WORKER-Thread-14 INFO:Local step 11500, global step 184113: loss 0.1230
[2019-03-27 05:02:18,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 11500, global step 184115: learning rate 0.0000
[2019-03-27 05:02:18,505] A3C_AGENT_WORKER-Thread-17 INFO:Local step 11500, global step 184142: loss 0.1685
[2019-03-27 05:02:18,507] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 11500, global step 184142: learning rate 0.0000
[2019-03-27 05:02:18,586] A3C_AGENT_WORKER-Thread-16 INFO:Local step 11500, global step 184180: loss 0.1218
[2019-03-27 05:02:18,588] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 11500, global step 184181: learning rate 0.0000
[2019-03-27 05:02:18,733] A3C_AGENT_WORKER-Thread-15 INFO:Local step 11500, global step 184245: loss 0.1477
[2019-03-27 05:02:18,735] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 11500, global step 184247: learning rate 0.0000
[2019-03-27 05:02:22,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.0391989e-19 9.6487106e-12 5.4064866e-22 7.3971596e-20], sum to 1.0000
[2019-03-27 05:02:22,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7134
[2019-03-27 05:02:22,787] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.35, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7281511819202381, 6.9112, 6.9112, 168.912956510431, 619755.1127983677, 619755.1127983677, 187868.5668175328], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6978600.0000, 
sim time next is 6979200.0000, 
raw observation next is [29.26666666666667, 57.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7224466746469522, 6.911200000000001, 6.9112, 168.912956510431, 615679.3197189064, 615679.3197189058, 186812.2211448768], 
processed observation next is [0.0, 0.782608695652174, 0.5860979462875199, 0.5733333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6615203349353076, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17102203325525178, 0.17102203325525162, 0.2788242106639952], 
reward next is 0.7212, 
noisyNet noise sample is [array([-1.2232112], dtype=float32), 0.51738966]. 
=============================================
[2019-03-27 05:02:25,637] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999988e-01 1.1148824e-12 7.0090778e-08 5.1868825e-16 2.7033032e-11], sum to 1.0000
[2019-03-27 05:02:25,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9835
[2019-03-27 05:02:25,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 893522.2863036647 W.
[2019-03-27 05:02:25,656] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.35, 78.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.949164437544519, 6.9112, 168.9125374690973, 893522.2863036647, 866589.0744908915, 256434.6491702299], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7021800.0000, 
sim time next is 7022400.0000, 
raw observation next is [26.5, 77.0, 1.0, 1.0, 0.3012331046377095, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5071660267186361, 6.9112, 6.9112, 168.9129255981869, 856134.9762867879, 856134.9762867879, 221773.4272950154], 
processed observation next is [1.0, 0.2608695652173913, 0.4549763033175356, 0.77, 1.0, 0.5, 0.15811217426230062, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3989829594129708, 0.0, 0.0, 0.8294397933590324, 0.23781527119077442, 0.23781527119077442, 0.3310051153656946], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0365876], dtype=float32), 1.0889856]. 
=============================================
[2019-03-27 05:02:25,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9988556e-01 2.1584962e-10 1.1443972e-04 9.8407740e-13 1.8195248e-08], sum to 1.0000
[2019-03-27 05:02:25,928] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4743
[2019-03-27 05:02:25,938] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1717814.357271315 W.
[2019-03-27 05:02:25,944] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 63.0, 1.0, 2.0, 0.4095873316631196, 1.0, 2.0, 0.4095873316631196, 1.0, 1.0, 0.6826474831392407, 6.9112, 6.9112, 170.5573041426782, 1717814.357271315, 1717814.357271315, 353981.074422221], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7030800.0000, 
sim time next is 7031400.0000, 
raw observation next is [28.85, 62.33333333333333, 1.0, 2.0, 0.437694094853186, 1.0, 2.0, 0.437694094853186, 1.0, 2.0, 0.7302906509692171, 6.9112, 6.9112, 170.5573041426782, 1835795.44937447, 1835795.44937447, 369938.3372064035], 
processed observation next is [1.0, 0.391304347826087, 0.5663507109004741, 0.6233333333333333, 1.0, 1.0, 0.322523005847212, 1.0, 1.0, 0.322523005847212, 1.0, 1.0, 0.6710861597185575, 0.0, 0.0, 0.8375144448122397, 0.5099431803817972, 0.5099431803817972, 0.552146771949856], 
reward next is 0.4479, 
noisyNet noise sample is [array([1.2632834], dtype=float32), -1.5102578]. 
=============================================
[2019-03-27 05:02:27,768] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999976e-01 1.4990559e-13 1.8547117e-07 3.1526930e-17 3.1315811e-12], sum to 1.0000
[2019-03-27 05:02:27,779] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8524
[2019-03-27 05:02:27,784] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.01666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8048740329602373, 6.9112, 6.9112, 168.912956510431, 673158.771627048, 673158.771627048, 202806.2910357179], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7066200.0000, 
sim time next is 7066800.0000, 
raw observation next is [26.9, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8053803789084943, 6.911199999999999, 6.9112, 168.912956510431, 673699.2212934479, 673699.2212934486, 202914.1110606835], 
processed observation next is [1.0, 0.8260869565217391, 0.4739336492890995, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7626589986688955, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18713867258151332, 0.1871386725815135, 0.30285688218012463], 
reward next is 0.6971, 
noisyNet noise sample is [array([0.5411172], dtype=float32), 0.32927874]. 
=============================================
[2019-03-27 05:02:32,075] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.7071236e-01 7.2800844e-08 2.9287323e-02 3.9360792e-11 2.3872664e-07], sum to 1.0000
[2019-03-27 05:02:32,084] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9103
[2019-03-27 05:02:32,095] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1589744.165600203 W.
[2019-03-27 05:02:32,099] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.5, 81.0, 1.0, 2.0, 0.3790735284148778, 1.0, 2.0, 0.3790735284148778, 1.0, 2.0, 0.6379254148677412, 6.9112, 6.9112, 170.5573041426782, 1589744.165600203, 1589744.165600203, 338859.8972925107], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7135200.0000, 
sim time next is 7135800.0000, 
raw observation next is [26.48333333333333, 81.33333333333333, 1.0, 2.0, 0.4348174769578166, 1.0, 2.0, 0.4348174769578166, 1.0, 2.0, 0.7325304382763388, 6.9112, 6.9112, 170.5573041426782, 1823719.94672598, 1823719.94672598, 369432.689009665], 
processed observation next is [1.0, 0.6086956521739131, 0.4541864139020536, 0.8133333333333332, 1.0, 1.0, 0.31905720115399583, 1.0, 1.0, 0.31905720115399583, 1.0, 1.0, 0.6738176076540716, 0.0, 0.0, 0.8375144448122397, 0.50658887409055, 0.50658887409055, 0.5513920731487537], 
reward next is 0.4486, 
noisyNet noise sample is [array([-0.9714842], dtype=float32), -0.11566611]. 
=============================================
[2019-03-27 05:02:34,486] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 7.2967463e-19 1.1201970e-11 3.6694786e-21 1.6922026e-16], sum to 1.0000
[2019-03-27 05:02:34,494] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6167
[2019-03-27 05:02:34,498] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 85.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7863855220278685, 6.9112, 6.9112, 168.912956510431, 661242.8875761909, 661242.8875761909, 199098.4467671564], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7170000.0000, 
sim time next is 7170600.0000, 
raw observation next is [25.7, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7837332627529413, 6.9112, 6.9112, 168.912956510431, 658808.0729775097, 658808.0729775097, 198558.5343057706], 
processed observation next is [1.0, 1.0, 0.4170616113744076, 0.8583333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7362600765279771, 0.0, 0.0, 0.8294399451523027, 0.1830022424937527, 0.1830022424937527, 0.2963560213518964], 
reward next is 0.7036, 
noisyNet noise sample is [array([-0.03963778], dtype=float32), 0.748295]. 
=============================================
[2019-03-27 05:02:35,382] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12000, global step 191749: loss -514.5177
[2019-03-27 05:02:35,383] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12000, global step 191749: learning rate 0.0000
[2019-03-27 05:02:35,435] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12000, global step 191774: loss -662.6411
[2019-03-27 05:02:35,439] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12000, global step 191775: learning rate 0.0000
[2019-03-27 05:02:35,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2401749e-14 5.4840736e-09 1.5487342e-17 1.0265427e-13], sum to 1.0000
[2019-03-27 05:02:35,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8583
[2019-03-27 05:02:35,619] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8397359434178461, 6.911199999999999, 6.9112, 168.912956510431, 698931.3315806598, 698931.3315806604, 210103.0638997974], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7186800.0000, 
sim time next is 7187400.0000, 
raw observation next is [25.8, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8295775237150127, 6.911200000000001, 6.9112, 168.912956510431, 690253.689586218, 690253.6895862174, 207911.6191347987], 
processed observation next is [1.0, 0.17391304347826086, 0.42180094786729866, 0.905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7921677118475765, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19173713599617165, 0.1917371359961715, 0.31031584945492346], 
reward next is 0.6897, 
noisyNet noise sample is [array([1.0750221], dtype=float32), 1.3025007]. 
=============================================
[2019-03-27 05:02:35,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12000, global step 191888: loss -690.2805
[2019-03-27 05:02:35,685] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12000, global step 191890: learning rate 0.0000
[2019-03-27 05:02:35,714] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12000, global step 191904: loss -503.7598
[2019-03-27 05:02:35,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12000, global step 191905: learning rate 0.0000
[2019-03-27 05:02:35,726] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12000, global step 191907: loss -741.8982
[2019-03-27 05:02:35,730] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12000, global step 191907: learning rate 0.0000
[2019-03-27 05:02:35,793] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12000, global step 191939: loss -610.0527
[2019-03-27 05:02:35,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12000, global step 191939: learning rate 0.0000
[2019-03-27 05:02:35,836] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12000, global step 191958: loss -584.9358
[2019-03-27 05:02:35,840] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12000, global step 191959: learning rate 0.0000
[2019-03-27 05:02:35,847] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12000, global step 191963: loss -539.9467
[2019-03-27 05:02:35,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12000, global step 191964: learning rate 0.0000
[2019-03-27 05:02:35,883] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12000, global step 191979: loss -457.9792
[2019-03-27 05:02:35,888] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12000, global step 191980: learning rate 0.0000
[2019-03-27 05:02:35,889] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12000, global step 191984: loss -526.9163
[2019-03-27 05:02:35,892] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12000, global step 191984: learning rate 0.0000
[2019-03-27 05:02:35,944] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12000, global step 192006: loss -640.1806
[2019-03-27 05:02:35,946] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12000, global step 192006: learning rate 0.0000
[2019-03-27 05:02:36,095] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12000, global step 192078: loss -625.5446
[2019-03-27 05:02:36,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12000, global step 192079: learning rate 0.0000
[2019-03-27 05:02:36,140] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12000, global step 192100: loss -554.0165
[2019-03-27 05:02:36,142] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12000, global step 192100: learning rate 0.0000
[2019-03-27 05:02:36,204] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12000, global step 192131: loss -465.8282
[2019-03-27 05:02:36,206] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12000, global step 192131: learning rate 0.0000
[2019-03-27 05:02:36,289] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12000, global step 192166: loss -520.6964
[2019-03-27 05:02:36,291] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12000, global step 192167: learning rate 0.0000
[2019-03-27 05:02:36,357] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12000, global step 192200: loss -664.5179
[2019-03-27 05:02:36,358] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12000, global step 192200: learning rate 0.0000
[2019-03-27 05:02:40,735] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1180132e-15 5.8678262e-10 5.6628893e-19 4.0043110e-14], sum to 1.0000
[2019-03-27 05:02:40,747] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2246
[2019-03-27 05:02:40,756] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 875193.2792397122 W.
[2019-03-27 05:02:40,762] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.76666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001324207689303, 6.9112, 6.9112, 168.912956510431, 875193.2792397122, 875193.2792397122, 248794.2651820127], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7287600.0000, 
sim time next is 7288200.0000, 
raw observation next is [23.0, 81.5, 1.0, 1.0, 0.3057284013612169, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5475253060431219, 6.911200000000001, 6.9112, 168.912956510431, 954108.9138077963, 954108.9138077957, 232523.7488319892], 
processed observation next is [1.0, 0.34782608695652173, 0.28909952606635075, 0.815, 1.0, 0.5, 0.16352819441110467, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.44820159273551446, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.265030253835499, 0.26503025383549883, 0.3470503713910287], 
reward next is 0.6529, 
noisyNet noise sample is [array([-0.31564495], dtype=float32), 0.28299013]. 
=============================================
[2019-03-27 05:02:44,302] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.4616902e-18 1.5406397e-11 7.6030532e-21 3.9329132e-16], sum to 1.0000
[2019-03-27 05:02:44,311] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9317
[2019-03-27 05:02:44,319] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.88333333333333, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6432157977510928, 6.9112, 6.9112, 168.912956510431, 556529.5601895028, 556529.5601895028, 172957.6185259476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7347000.0000, 
sim time next is 7347600.0000, 
raw observation next is [24.9, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6402511097217103, 6.9112, 6.9112, 168.912956510431, 554162.282786868, 554162.282786868, 172470.7390100162], 
processed observation next is [1.0, 0.043478260869565216, 0.3791469194312796, 0.74, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5612818411240369, 0.0, 0.0, 0.8294399451523027, 0.15393396744079668, 0.15393396744079668, 0.2574190134477854], 
reward next is 0.7426, 
noisyNet noise sample is [array([0.28273475], dtype=float32), 0.0088796085]. 
=============================================
[2019-03-27 05:02:48,226] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.7004347e-19 7.9347889e-11 1.3369206e-19 4.3227263e-15], sum to 1.0000
[2019-03-27 05:02:48,234] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2650
[2019-03-27 05:02:48,238] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5374529731524039, 6.911200000000001, 6.9112, 168.912956510431, 473960.5278119164, 473960.5278119157, 156930.9525109726], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7417800.0000, 
sim time next is 7418400.0000, 
raw observation next is [21.56666666666667, 84.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5407794943081835, 6.9112, 6.9112, 168.912956510431, 476665.469937933, 476665.469937933, 157389.4447243672], 
processed observation next is [1.0, 0.8695652173913043, 0.22116903633491333, 0.8466666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43997499305876037, 0.0, 0.0, 0.8294399451523027, 0.13240707498275917, 0.13240707498275917, 0.23490961899159285], 
reward next is 0.7651, 
noisyNet noise sample is [array([-0.57799923], dtype=float32), 1.8478494]. 
=============================================
[2019-03-27 05:02:52,396] A3C_AGENT_WORKER-Thread-11 INFO:Local step 12500, global step 199739: loss 0.0868
[2019-03-27 05:02:52,400] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 12500, global step 199741: learning rate 0.0000
[2019-03-27 05:02:52,422] A3C_AGENT_WORKER-Thread-20 INFO:Local step 12500, global step 199755: loss 0.0390
[2019-03-27 05:02:52,424] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 12500, global step 199755: learning rate 0.0000
[2019-03-27 05:02:52,609] A3C_AGENT_WORKER-Thread-13 INFO:Local step 12500, global step 199842: loss 0.0472
[2019-03-27 05:02:52,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 12500, global step 199842: learning rate 0.0000
[2019-03-27 05:02:52,641] A3C_AGENT_WORKER-Thread-22 INFO:Local step 12500, global step 199857: loss 0.1069
[2019-03-27 05:02:52,643] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 12500, global step 199857: learning rate 0.0000
[2019-03-27 05:02:52,733] A3C_AGENT_WORKER-Thread-19 INFO:Local step 12500, global step 199896: loss 0.1224
[2019-03-27 05:02:52,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 12500, global step 199897: learning rate 0.0000
[2019-03-27 05:02:52,772] A3C_AGENT_WORKER-Thread-2 INFO:Local step 12500, global step 199916: loss 0.0640
[2019-03-27 05:02:52,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 12500, global step 199916: learning rate 0.0000
[2019-03-27 05:02:52,846] A3C_AGENT_WORKER-Thread-3 INFO:Local step 12500, global step 199952: loss 0.0721
[2019-03-27 05:02:52,850] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 12500, global step 199954: learning rate 0.0000
[2019-03-27 05:02:52,860] A3C_AGENT_WORKER-Thread-21 INFO:Local step 12500, global step 199957: loss 0.0883
[2019-03-27 05:02:52,863] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 12500, global step 199957: learning rate 0.0000
[2019-03-27 05:02:52,881] A3C_AGENT_WORKER-Thread-9 INFO:Local step 12500, global step 199966: loss 0.0357
[2019-03-27 05:02:52,885] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 12500, global step 199967: learning rate 0.0000
[2019-03-27 05:02:52,955] A3C_AGENT_WORKER-Thread-18 INFO:Local step 12500, global step 199998: loss 0.0542
[2019-03-27 05:02:52,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 12500, global step 199998: learning rate 0.0000
[2019-03-27 05:02:52,963] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 05:02:52,966] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:02:52,967] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:02:52,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:02:52,968] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:02:52,969] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:02:52,968] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:02:52,970] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:02:52,972] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:02:52,973] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:02:52,979] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:02:52,985] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run9
[2019-03-27 05:02:52,986] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run9
[2019-03-27 05:02:52,987] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run9
[2019-03-27 05:02:53,035] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run9
[2019-03-27 05:02:53,057] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run9
[2019-03-27 05:03:05,378] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:05,380] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.53333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.76708349045169, 6.911199999999999, 6.9112, 168.912956510431, 649877.0614350522, 649877.0614350528, 195319.1877015807]
[2019-03-27 05:03:05,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:03:05,386] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.4654811e-20 8.9291401e-14 1.1910366e-22 2.0963755e-18], sampled 0.05290509672637844
[2019-03-27 05:03:11,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:11,102] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.85, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7540769345656992, 6.911200000000001, 6.9112, 168.912956510431, 648402.5254040464, 648402.5254040457, 192820.2255686241]
[2019-03-27 05:03:11,102] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:03:11,105] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 7.4177628e-19 1.1657446e-12 4.7092600e-21 5.4795031e-17], sampled 0.2707441580569916
[2019-03-27 05:03:24,752] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:24,754] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 66.0, 1.0, 2.0, 0.8573658522118743, 1.0, 1.0, 0.8573658522118743, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2397932.776876671, 2397932.776876672, 448768.2893399672]
[2019-03-27 05:03:24,755] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:03:24,761] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999297e-01 7.8008991e-13 7.0766723e-06 4.0547888e-16 1.3259207e-11], sampled 0.4615525020295922
[2019-03-27 05:03:24,762] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2397932.776876671 W.
[2019-03-27 05:03:25,249] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:25,251] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6977709117581963, 6.9112, 6.9112, 168.912956510431, 598036.1353138825, 598036.1353138825, 182331.6486302803]
[2019-03-27 05:03:25,253] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:03:25,256] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 9.3059473e-19 1.4005140e-12 5.9170867e-21 7.2389758e-17], sampled 0.9621288043160289
[2019-03-27 05:03:44,575] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:44,577] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.68333333333333, 75.0, 1.0, 2.0, 0.9101859353353944, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995657272804086, 6.9112, 168.912385494987, 2169294.08954828, 2109377.395976976, 437287.8109508528]
[2019-03-27 05:03:44,579] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:03:44,582] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999988e-01 5.4581797e-14 1.1984470e-07 6.1008997e-17 2.2608181e-12], sampled 0.9569339517832816
[2019-03-27 05:03:44,583] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2169294.08954828 W.
[2019-03-27 05:03:55,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:03:55,296] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.45, 54.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.23655654506033, 6.9112, 168.9112297499131, 2514707.338545245, 2283890.567185287, 475405.4658371337]
[2019-03-27 05:03:55,297] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:03:55,300] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9868888e-01 4.0001677e-10 1.3110813e-03 1.8797183e-13 8.4074436e-09], sampled 0.24596675209232532
[2019-03-27 05:03:55,301] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2514707.338545245 W.
[2019-03-27 05:04:01,763] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:04:01,765] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.66666666666666, 67.33333333333334, 1.0, 2.0, 0.8933656842568579, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988798419035035, 6.9112, 168.9124321660501, 2145750.338392054, 2090699.520087972, 432860.0926807701]
[2019-03-27 05:04:01,766] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:04:01,769] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9997520e-01 4.6354597e-11 2.4802488e-05 8.4974589e-14 7.6918238e-10], sampled 0.1558507058031261
[2019-03-27 05:04:01,770] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2145750.338392054 W.
[2019-03-27 05:04:38,510] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02236602], dtype=float32), 0.04933449]
[2019-03-27 05:04:38,513] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [19.95094033, 94.56270994, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5626447642071692, 6.9112, 6.9112, 168.912956510431, 496875.4349799375, 496875.4349799375, 160385.0756125485]
[2019-03-27 05:04:38,515] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:04:38,519] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.0707998e-20 1.2715824e-13 1.4306976e-22 2.8887608e-18], sampled 0.4771894202692878
[2019-03-27 05:04:46,288] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8059.1457 2937866423.0562 1380.0000
[2019-03-27 05:04:46,461] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7347.6659 3105603889.0947 2010.0000
[2019-03-27 05:04:46,526] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.7973 2989292659.5875 1566.0000
[2019-03-27 05:04:46,727] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.0518 3185059998.5680 2464.0000
[2019-03-27 05:04:46,880] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7288.6205 3319250356.3541 2145.0000
[2019-03-27 05:04:47,895] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 200000, evaluation results [200000.0, 7288.620471551498, 3319250356.3540664, 2145.0, 7347.665868215155, 3105603889.094724, 2010.0, 8059.14567043969, 2937866423.0561843, 1380.0, 7030.051764937368, 3185059998.568027, 2464.0, 7923.797336188051, 2989292659.587512, 1566.0]
[2019-03-27 05:04:47,924] A3C_AGENT_WORKER-Thread-10 INFO:Local step 12500, global step 200016: loss 0.0529
[2019-03-27 05:04:47,929] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 12500, global step 200017: learning rate 0.0000
[2019-03-27 05:04:48,098] A3C_AGENT_WORKER-Thread-14 INFO:Local step 12500, global step 200098: loss 0.0347
[2019-03-27 05:04:48,100] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 12500, global step 200098: learning rate 0.0000
[2019-03-27 05:04:48,157] A3C_AGENT_WORKER-Thread-12 INFO:Local step 12500, global step 200128: loss 0.1090
[2019-03-27 05:04:48,161] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 12500, global step 200129: learning rate 0.0000
[2019-03-27 05:04:48,354] A3C_AGENT_WORKER-Thread-16 INFO:Local step 12500, global step 200216: loss 0.0120
[2019-03-27 05:04:48,359] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 12500, global step 200217: learning rate 0.0000
[2019-03-27 05:04:48,397] A3C_AGENT_WORKER-Thread-17 INFO:Local step 12500, global step 200230: loss 0.0840
[2019-03-27 05:04:48,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 12500, global step 200230: learning rate 0.0000
[2019-03-27 05:04:48,556] A3C_AGENT_WORKER-Thread-15 INFO:Local step 12500, global step 200302: loss 0.0232
[2019-03-27 05:04:48,560] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 12500, global step 200303: learning rate 0.0000
[2019-03-27 05:04:51,525] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.0114311e-18 7.6967577e-13 3.7895853e-22 1.1119178e-16], sum to 1.0000
[2019-03-27 05:04:51,534] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8352
[2019-03-27 05:04:51,537] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.753272181938881, 6.9112, 6.9112, 168.912956510431, 635271.9331184266, 635271.9331184266, 192577.2892957035], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7563000.0000, 
sim time next is 7563600.0000, 
raw observation next is [29.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7482340922048072, 6.9112, 6.9112, 168.912956510431, 631728.9054534495, 631728.9054534495, 191616.9001079043], 
processed observation next is [0.0, 0.5652173913043478, 0.5734597156398105, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6929684051278137, 0.0, 0.0, 0.8294399451523027, 0.17548025151484709, 0.17548025151484709, 0.28599537329537955], 
reward next is 0.7140, 
noisyNet noise sample is [array([0.39320418], dtype=float32), -0.3491052]. 
=============================================
[2019-03-27 05:04:51,792] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2794023e-19 2.8082135e-12 1.0281100e-21 1.5698030e-16], sum to 1.0000
[2019-03-27 05:04:51,799] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7024
[2019-03-27 05:04:51,806] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7487492606940065, 6.911200000000001, 6.9112, 168.912956510431, 632240.670983596, 632240.6709835954, 191717.3854528889], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7569600.0000, 
sim time next is 7570200.0000, 
raw observation next is [29.83333333333333, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7625632932616093, 6.911199999999999, 6.9112, 168.912956510431, 641912.5485249424, 641912.548524943, 194366.5474100194], 
processed observation next is [0.0, 0.6086956521739131, 0.6129541864139019, 0.615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7104430405629382, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17830904125692842, 0.1783090412569286, 0.2900993244925663], 
reward next is 0.7099, 
noisyNet noise sample is [array([0.62975836], dtype=float32), 0.5627451]. 
=============================================
[2019-03-27 05:04:52,388] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.3490453e-20 6.5378310e-15 3.6636722e-22 4.6219864e-19], sum to 1.0000
[2019-03-27 05:04:52,390] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0912
[2019-03-27 05:04:52,394] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7257822470316841, 6.911199999999999, 6.9112, 168.912956510431, 616395.5155018282, 616395.5155018289, 187415.1815936771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7568400.0000, 
sim time next is 7569000.0000, 
raw observation next is [29.5, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7368084952560595, 6.9112, 6.9112, 168.912956510431, 624022.2027819117, 624022.2027819117, 189465.7080097231], 
processed observation next is [0.0, 0.6086956521739131, 0.5971563981042655, 0.605, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6790347503122676, 0.0, 0.0, 0.8294399451523027, 0.17333950077275326, 0.17333950077275326, 0.28278463882048227], 
reward next is 0.7172, 
noisyNet noise sample is [array([-1.189964], dtype=float32), 1.4800353]. 
=============================================
[2019-03-27 05:04:52,410] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[82.33059 ]
 [82.27355 ]
 [82.19549 ]
 [82.133575]
 [82.07183 ]], R is [[82.28111267]
 [82.17858124]
 [82.07982635]
 [81.98323822]
 [81.88536072]].
[2019-03-27 05:04:54,824] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.6642807e-16 1.5267695e-09 3.0703579e-18 1.1857736e-14], sum to 1.0000
[2019-03-27 05:04:54,834] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1584
[2019-03-27 05:04:54,842] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.45, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7140371859485446, 6.911200000000001, 6.9112, 168.912956510431, 608823.8065641841, 608823.8065641836, 185264.9391189803], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7623000.0000, 
sim time next is 7623600.0000, 
raw observation next is [23.53333333333333, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.715544144324051, 6.911199999999999, 6.9112, 168.912956510431, 609649.1494993184, 609649.1494993191, 185538.347448279], 
processed observation next is [1.0, 0.21739130434782608, 0.3143759873617693, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6531026150293304, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1693469859720329, 0.1693469859720331, 0.2769229066392224], 
reward next is 0.7231, 
noisyNet noise sample is [array([1.0324565], dtype=float32), -0.69849664]. 
=============================================
[2019-03-27 05:04:56,450] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9814248e-01 3.8294079e-09 1.8573753e-03 7.7611129e-12 1.5199524e-07], sum to 1.0000
[2019-03-27 05:04:56,456] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9658
[2019-03-27 05:04:56,464] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1433130.884078107 W.
[2019-03-27 05:04:56,468] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.23333333333333, 61.33333333333334, 1.0, 2.0, 0.5126312055872255, 1.0, 2.0, 0.5126312055872255, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1433130.884078107, 1433130.884078107, 304214.1137726945], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7647600.0000, 
sim time next is 7648200.0000, 
raw observation next is [30.3, 61.0, 1.0, 2.0, 0.4869023116229128, 0.0, 1.0, 0.0, 1.0, 1.0, 0.816601690186938, 6.911199999999999, 6.9112, 168.912956510431, 1361164.974416174, 1361164.974416175, 295911.9570509443], 
processed observation next is [1.0, 0.5217391304347826, 0.6350710900473934, 0.61, 1.0, 1.0, 0.38181001400350945, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.776343524618217, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.37810138178227054, 0.3781013817822708, 0.44165963738946906], 
reward next is 0.5583, 
noisyNet noise sample is [array([-0.8036889], dtype=float32), 0.3647362]. 
=============================================
[2019-03-27 05:05:01,331] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8046380e-01 8.6510468e-08 1.9535908e-02 2.8336054e-11 2.6061613e-07], sum to 1.0000
[2019-03-27 05:05:01,337] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5860
[2019-03-27 05:05:01,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2294818.951782124 W.
[2019-03-27 05:05:01,348] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.43333333333333, 63.33333333333333, 1.0, 2.0, 0.8205319693587081, 1.0, 1.0, 0.8205319693587081, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2294818.951782124, 2294818.951782124, 429987.7029402732], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7732200.0000, 
sim time next is 7732800.0000, 
raw observation next is [31.5, 63.0, 1.0, 2.0, 0.8265169529298192, 1.0, 2.0, 0.8265169529298192, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2311572.907058744, 2311572.907058745, 432983.7959555787], 
processed observation next is [1.0, 0.5217391304347826, 0.6919431279620853, 0.63, 1.0, 1.0, 0.7909842806383364, 1.0, 1.0, 0.7909842806383364, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6421035852940956, 0.6421035852940958, 0.6462444715754906], 
reward next is 0.3538, 
noisyNet noise sample is [array([-1.1455626], dtype=float32), -0.41922987]. 
=============================================
[2019-03-27 05:05:04,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999940e-01 9.7129622e-12 6.4338423e-07 2.8484507e-15 1.0213427e-10], sum to 1.0000
[2019-03-27 05:05:04,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0558
[2019-03-27 05:05:04,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1019963.792670253 W.
[2019-03-27 05:05:04,531] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.65, 89.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.136893995010826, 6.9112, 168.9116363906492, 1019963.792670253, 859849.9561828016, 256249.8022053711], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7791000.0000, 
sim time next is 7791600.0000, 
raw observation next is [25.6, 89.66666666666667, 1.0, 1.0, 0.6239858527200315, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9127727407343, 871994.3970162227, 871994.3970162233, 205290.2341283029], 
processed observation next is [1.0, 0.17391304347826086, 0.4123222748815167, 0.8966666666666667, 1.0, 0.5, 0.5469709068916042, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294390427589619, 0.24222066583783963, 0.2422206658378398, 0.3064033345198551], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7173306], dtype=float32), -0.22293696]. 
=============================================
[2019-03-27 05:05:04,603] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.3154901e-19 8.5140315e-12 1.6477425e-20 5.5069778e-16], sum to 1.0000
[2019-03-27 05:05:04,615] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7374
[2019-03-27 05:05:04,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2685211.749294242 W.
[2019-03-27 05:05:04,626] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.35, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 9.484888492165947, 6.9112, 168.898319542916, 2685211.749294242, 859506.7716084092, 256218.9516531962], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7783800.0000, 
sim time next is 7784400.0000, 
raw observation next is [26.3, 85.66666666666667, 1.0, 1.0, 0.3820144616237517, 1.0, 1.0, 0.3820144616237517, 1.0, 2.0, 0.6473965836472939, 6.911200000000001, 6.9112, 170.5573041426782, 1602086.958172348, 1602086.958172347, 340994.9184683388], 
processed observation next is [1.0, 0.08695652173913043, 0.4454976303317536, 0.8566666666666667, 1.0, 0.5, 0.2554391103900623, 1.0, 0.5, 0.2554391103900623, 1.0, 1.0, 0.5699958337162121, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.44502415504787446, 0.4450241550478741, 0.5089476395049832], 
reward next is 0.4911, 
noisyNet noise sample is [array([-0.51078755], dtype=float32), 0.4096747]. 
=============================================
[2019-03-27 05:05:05,009] A3C_AGENT_WORKER-Thread-11 INFO:Local step 13000, global step 207748: loss -23.4435
[2019-03-27 05:05:05,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 13000, global step 207749: learning rate 0.0000
[2019-03-27 05:05:05,147] A3C_AGENT_WORKER-Thread-20 INFO:Local step 13000, global step 207806: loss 61.2280
[2019-03-27 05:05:05,151] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 13000, global step 207807: learning rate 0.0000
[2019-03-27 05:05:05,209] A3C_AGENT_WORKER-Thread-13 INFO:Local step 13000, global step 207839: loss 4.2755
[2019-03-27 05:05:05,211] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 13000, global step 207840: learning rate 0.0000
[2019-03-27 05:05:05,248] A3C_AGENT_WORKER-Thread-22 INFO:Local step 13000, global step 207858: loss -18.9866
[2019-03-27 05:05:05,250] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 13000, global step 207858: learning rate 0.0000
[2019-03-27 05:05:05,325] A3C_AGENT_WORKER-Thread-2 INFO:Local step 13000, global step 207889: loss -54.0190
[2019-03-27 05:05:05,328] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 13000, global step 207889: learning rate 0.0000
[2019-03-27 05:05:05,366] A3C_AGENT_WORKER-Thread-19 INFO:Local step 13000, global step 207910: loss 0.3549
[2019-03-27 05:05:05,368] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 13000, global step 207910: learning rate 0.0000
[2019-03-27 05:05:05,431] A3C_AGENT_WORKER-Thread-21 INFO:Local step 13000, global step 207941: loss 9.5431
[2019-03-27 05:05:05,434] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 13000, global step 207941: learning rate 0.0000
[2019-03-27 05:05:05,435] A3C_AGENT_WORKER-Thread-9 INFO:Local step 13000, global step 207941: loss -12.0366
[2019-03-27 05:05:05,440] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 13000, global step 207941: learning rate 0.0000
[2019-03-27 05:05:05,448] A3C_AGENT_WORKER-Thread-3 INFO:Local step 13000, global step 207945: loss -31.4219
[2019-03-27 05:05:05,449] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 13000, global step 207945: learning rate 0.0000
[2019-03-27 05:05:05,579] A3C_AGENT_WORKER-Thread-18 INFO:Local step 13000, global step 208006: loss 25.0189
[2019-03-27 05:05:05,582] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 13000, global step 208006: learning rate 0.0000
[2019-03-27 05:05:05,599] A3C_AGENT_WORKER-Thread-10 INFO:Local step 13000, global step 208014: loss -18.0081
[2019-03-27 05:05:05,601] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 13000, global step 208014: learning rate 0.0000
[2019-03-27 05:05:05,741] A3C_AGENT_WORKER-Thread-12 INFO:Local step 13000, global step 208076: loss 55.8908
[2019-03-27 05:05:05,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 13000, global step 208077: learning rate 0.0000
[2019-03-27 05:05:05,826] A3C_AGENT_WORKER-Thread-14 INFO:Local step 13000, global step 208111: loss 26.4687
[2019-03-27 05:05:05,827] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 13000, global step 208111: learning rate 0.0000
[2019-03-27 05:05:05,915] A3C_AGENT_WORKER-Thread-16 INFO:Local step 13000, global step 208156: loss -24.2151
[2019-03-27 05:05:05,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 13000, global step 208156: learning rate 0.0000
[2019-03-27 05:05:05,924] A3C_AGENT_WORKER-Thread-17 INFO:Local step 13000, global step 208156: loss -27.2039
[2019-03-27 05:05:05,929] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 13000, global step 208158: learning rate 0.0000
[2019-03-27 05:05:06,187] A3C_AGENT_WORKER-Thread-15 INFO:Local step 13000, global step 208273: loss 43.6737
[2019-03-27 05:05:06,189] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 13000, global step 208274: learning rate 0.0000
[2019-03-27 05:05:07,500] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.7701434e-02 4.0290993e-06 9.2229342e-01 1.2903614e-10 1.1414038e-06], sum to 1.0000
[2019-03-27 05:05:07,508] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6479
[2019-03-27 05:05:07,514] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 63.0, 1.0, 2.0, 0.5677369894925779, 1.0, 1.0, 0.5677369894925779, 1.0, 2.0, 0.9765832572592934, 6.911199999999999, 6.9112, 170.5573041426782, 2381806.476765631, 2381806.476765632, 463188.9335476781], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7833600.0000, 
sim time next is 7834200.0000, 
raw observation next is [30.81666666666667, 64.16666666666667, 1.0, 2.0, 0.9663979116836041, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.985084695708364, 6.9112, 168.9125166911894, 2247970.690550544, 2195554.480982881, 453897.1118318255], 
processed observation next is [1.0, 0.6956521739130435, 0.6595576619273303, 0.6416666666666667, 1.0, 1.0, 0.9595155562453062, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007388469570836431, 0.0, 0.8294377854384763, 0.6244363029307066, 0.6098762447174669, 0.6774583758683963], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41824514], dtype=float32), -0.5006516]. 
=============================================
[2019-03-27 05:05:09,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.6994179e-19 4.4887106e-12 2.9487772e-22 1.6434191e-18], sum to 1.0000
[2019-03-27 05:05:09,395] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3447
[2019-03-27 05:05:09,399] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.65, 87.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8760273163987882, 6.9112, 6.9112, 168.912956510431, 723132.2324851381, 723132.2324851381, 217936.4079606019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7855800.0000, 
sim time next is 7856400.0000, 
raw observation next is [26.6, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8735743348714095, 6.9112, 6.9112, 168.912956510431, 721841.7002209431, 721841.7002209431, 217409.6263002807], 
processed observation next is [1.0, 0.9565217391304348, 0.4597156398104266, 0.8766666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8458223595992796, 0.0, 0.0, 0.8294399451523027, 0.2005115833947064, 0.2005115833947064, 0.3244919795526578], 
reward next is 0.6755, 
noisyNet noise sample is [array([0.689732], dtype=float32), 0.8890051]. 
=============================================
[2019-03-27 05:05:10,041] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9986780e-01 1.1869905e-10 1.3215673e-04 5.6687904e-14 2.0960922e-09], sum to 1.0000
[2019-03-27 05:05:10,048] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8473
[2019-03-27 05:05:10,056] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 915284.4489036831 W.
[2019-03-27 05:05:10,060] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.35, 88.66666666666667, 1.0, 2.0, 0.6549502095997967, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104079, 915284.4489036831, 915284.4489036838, 211420.1885506029], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7881000.0000, 
sim time next is 7881600.0000, 
raw observation next is [26.4, 88.33333333333334, 1.0, 2.0, 0.294489976554177, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4974426770391279, 6.9112, 6.9112, 168.912956510431, 823056.1469005333, 823056.1469005333, 218795.5715119654], 
processed observation next is [1.0, 0.21739130434782608, 0.45023696682464454, 0.8833333333333334, 1.0, 1.0, 0.14998792355924942, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.3871252159013755, 0.0, 0.0, 0.8294399451523027, 0.22862670747237038, 0.22862670747237038, 0.3265605544954707], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3895788], dtype=float32), -0.18144092]. 
=============================================
[2019-03-27 05:05:14,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.2987748e-20 5.4871756e-11 3.8163529e-21 2.3257680e-17], sum to 1.0000
[2019-03-27 05:05:14,300] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4931
[2019-03-27 05:05:14,302] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.48333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8960415861707676, 6.9112, 6.9112, 168.912956510431, 736901.1500824142, 736901.1500824142, 222405.0186934035], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7945800.0000, 
sim time next is 7946400.0000, 
raw observation next is [26.46666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972190255179338, 6.911199999999999, 6.9112, 168.912956510431, 737592.4058309586, 737592.4058309593, 222666.172927401], 
processed observation next is [1.0, 1.0, 0.45339652448657203, 0.9166666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8746573481926021, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2048867793974885, 0.2048867793974887, 0.33233757153343435], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.5008016], dtype=float32), -0.42760384]. 
=============================================
[2019-03-27 05:05:14,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:14,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:14,886] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run2
[2019-03-27 05:05:14,966] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:14,967] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:14,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run2
[2019-03-27 05:05:15,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run2
[2019-03-27 05:05:15,066] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,067] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run2
[2019-03-27 05:05:15,099] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,099] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run2
[2019-03-27 05:05:15,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,135] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run2
[2019-03-27 05:05:15,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,162] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run2
[2019-03-27 05:05:15,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run2
[2019-03-27 05:05:15,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,224] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run2
[2019-03-27 05:05:15,222] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,245] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,247] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,250] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run2
[2019-03-27 05:05:15,246] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,270] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run2
[2019-03-27 05:05:15,293] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run2
[2019-03-27 05:05:15,332] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run2
[2019-03-27 05:05:15,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,421] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run2
[2019-03-27 05:05:15,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,476] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run2
[2019-03-27 05:05:15,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:05:15,682] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:15,683] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run2
[2019-03-27 05:05:22,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.7425878e-16 1.3713892e-08 3.6674391e-19 7.5076464e-16], sum to 1.0000
[2019-03-27 05:05:22,286] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5617
[2019-03-27 05:05:22,297] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6563125149070309, 6.9112, 6.9112, 168.912956510431, 568852.5160799492, 568852.5160799492, 175115.7998155501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 102000.0000, 
sim time next is 102600.0000, 
raw observation next is [22.55, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6546058609629495, 6.9112, 6.9112, 168.912956510431, 567152.388750782, 567152.388750782, 174833.2595804416], 
processed observation next is [1.0, 0.17391304347826086, 0.26777251184834133, 0.905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.57878763532067, 0.0, 0.0, 0.8294399451523027, 0.15754233020855055, 0.15754233020855055, 0.26094516355289793], 
reward next is 0.7391, 
noisyNet noise sample is [array([-0.77490795], dtype=float32), 0.8119314]. 
=============================================
[2019-03-27 05:05:24,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9558347e-01 2.1764197e-09 4.4165854e-03 3.0557794e-13 5.4628844e-09], sum to 1.0000
[2019-03-27 05:05:24,295] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9507
[2019-03-27 05:05:24,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1143682.718055911 W.
[2019-03-27 05:05:24,305] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.262438218993454, 1.0, 2.0, 0.262438218993454, 1.0, 2.0, 0.4485689114727143, 6.9112, 6.9112, 170.5573041426782, 1143682.718055911, 1143682.718055911, 293540.630470748], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 136800.0000, 
sim time next is 137400.0000, 
raw observation next is [22.78333333333333, 96.0, 1.0, 2.0, 0.8812022441624751, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1303356.766225639, 1303356.766225638, 275074.1006396059], 
processed observation next is [1.0, 0.6086956521739131, 0.27883096366508686, 0.96, 1.0, 1.0, 0.856870173689729, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.36204354617378864, 0.36204354617378837, 0.4105583591635909], 
reward next is 0.5894, 
noisyNet noise sample is [array([-0.06288996], dtype=float32), 1.9613861]. 
=============================================
[2019-03-27 05:05:25,542] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9992001e-01 9.3550417e-13 8.0004495e-05 1.8081423e-16 6.0102609e-12], sum to 1.0000
[2019-03-27 05:05:25,546] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2039
[2019-03-27 05:05:25,556] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6696424653516118, 6.9112, 6.9112, 168.912956510431, 576234.0410331846, 576234.0410331846, 177407.0356206723], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 153600.0000, 
sim time next is 154200.0000, 
raw observation next is [22.41666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6741887014448353, 6.9112, 6.9112, 168.912956510431, 580258.5197760034, 580258.5197760034, 178187.2212586287], 
processed observation next is [1.0, 0.782608695652174, 0.26145339652448685, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6026691481034577, 0.0, 0.0, 0.8294399451523027, 0.16118292216000096, 0.16118292216000096, 0.265951076505416], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.3094923], dtype=float32), -0.09663436]. 
=============================================
[2019-03-27 05:05:28,058] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.4367831e-17 6.1287736e-10 1.8332326e-19 1.3706914e-15], sum to 1.0000
[2019-03-27 05:05:28,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4247
[2019-03-27 05:05:28,068] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.96666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5303733595120036, 6.911200000000001, 6.9112, 168.912956510431, 468160.597263258, 468160.5972632574, 155966.1767645347], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 181200.0000, 
sim time next is 181800.0000, 
raw observation next is [19.95, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5280115907536997, 6.9112, 6.9112, 168.912956510431, 466149.7125251241, 466149.7125251241, 155650.2096808121], 
processed observation next is [0.0, 0.08695652173913043, 0.14454976303317538, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4244043789679265, 0.0, 0.0, 0.8294399451523027, 0.1294860312569789, 0.1294860312569789, 0.2323137457922569], 
reward next is 0.7677, 
noisyNet noise sample is [array([0.18389846], dtype=float32), 1.5066772]. 
=============================================
[2019-03-27 05:05:28,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.4786743e-18 1.5149307e-10 4.5570688e-19 4.7985306e-15], sum to 1.0000
[2019-03-27 05:05:28,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5560
[2019-03-27 05:05:28,381] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5217416619866461, 6.911199999999999, 6.9112, 168.912956510431, 460879.9610897925, 460879.9610897932, 154815.8468487655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 186600.0000, 
sim time next is 187200.0000, 
raw observation next is [19.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5222626472071552, 6.911199999999999, 6.9112, 168.912956510431, 461340.351837531, 461340.3518375317, 154883.8722154352], 
processed observation next is [0.0, 0.17391304347826086, 0.14218009478672985, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4173934722038478, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12815009773264752, 0.1281500977326477, 0.2311699585305003], 
reward next is 0.7688, 
noisyNet noise sample is [array([0.3687563], dtype=float32), -1.3314415]. 
=============================================
[2019-03-27 05:05:29,974] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.3726127e-21 1.4292076e-12 4.1111242e-22 1.7112133e-19], sum to 1.0000
[2019-03-27 05:05:29,982] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5110
[2019-03-27 05:05:29,989] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.63333333333334, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5539872608318478, 6.9112, 6.9112, 168.912956510431, 486341.1507683891, 486341.1507683891, 159271.6623282122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 233400.0000, 
sim time next is 234000.0000, 
raw observation next is [21.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5536599747599065, 6.911199999999999, 6.9112, 168.912956510431, 486206.4938149715, 486206.4938149721, 159221.3912455658], 
processed observation next is [0.0, 0.7391304347826086, 0.22274881516587688, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4556828960486664, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13505735939304764, 0.1350573593930478, 0.23764386753069525], 
reward next is 0.7624, 
noisyNet noise sample is [array([2.1578932], dtype=float32), -0.1440604]. 
=============================================
[2019-03-27 05:05:30,013] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[82.50073]
 [82.42561]
 [82.33958]
 [82.25833]
 [82.16632]], R is [[82.52184296]
 [82.45890808]
 [82.39640808]
 [82.33412933]
 [82.27207184]].
[2019-03-27 05:05:31,544] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.0316046e-19 9.9250339e-13 1.6751661e-20 1.5998960e-18], sum to 1.0000
[2019-03-27 05:05:31,554] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7120
[2019-03-27 05:05:31,559] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5192829102648093, 6.9112, 6.9112, 168.912956510431, 458158.2345127119, 458158.2345127119, 154517.3587339385], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 265200.0000, 
sim time next is 265800.0000, 
raw observation next is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5190167409532722, 6.9112, 6.9112, 168.912956510431, 457923.3451514558, 457923.3451514558, 154482.7936942496], 
processed observation next is [0.0, 0.043478260869565216, 0.1706161137440759, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4134350499430149, 0.0, 0.0, 0.8294399451523027, 0.1272009292087377, 0.1272009292087377, 0.2305713338720143], 
reward next is 0.7694, 
noisyNet noise sample is [array([0.5331434], dtype=float32), 0.29071602]. 
=============================================
[2019-03-27 05:05:36,526] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.6529624e-21 2.0801302e-13 5.2673599e-23 1.1389054e-19], sum to 1.0000
[2019-03-27 05:05:36,536] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9354
[2019-03-27 05:05:36,541] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.73333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4938967734248867, 6.9112, 6.9112, 168.912956510431, 437581.6072774003, 437581.6072774003, 151230.4338286727], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 341400.0000, 
sim time next is 342000.0000, 
raw observation next is [20.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4926196998160208, 6.9112, 6.9112, 168.912956510431, 436573.3455994083, 436573.3455994083, 151068.0469046634], 
processed observation next is [0.0, 1.0, 0.18009478672985785, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.38124353636100095, 0.0, 0.0, 0.8294399451523027, 0.12127037377761342, 0.12127037377761342, 0.22547469687263194], 
reward next is 0.7745, 
noisyNet noise sample is [array([1.4266613], dtype=float32), -0.15836377]. 
=============================================
[2019-03-27 05:05:36,550] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[83.454544]
 [83.40857 ]
 [83.359924]
 [83.30953 ]
 [83.25147 ]], R is [[83.44986725]
 [83.38965607]
 [83.32994843]
 [83.26982117]
 [83.20924377]].
[2019-03-27 05:05:36,998] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.5547783e-20 2.4689333e-14 3.1100743e-24 4.0958976e-20], sum to 1.0000
[2019-03-27 05:05:37,004] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0358
[2019-03-27 05:05:37,015] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.86666666666667, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4994227134660484, 6.9112, 6.9112, 168.912956510431, 441973.9626977112, 441973.9626977112, 151936.1116386036], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 339000.0000, 
sim time next is 339600.0000, 
raw observation next is [20.83333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5054326640892617, 6.911200000000001, 6.9112, 168.912956510431, 447421.9574306399, 447421.9574306393, 152683.0423472416], 
processed observation next is [0.0, 0.9565217391304348, 0.1864139020537123, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3968691025478801, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12428387706406664, 0.12428387706406648, 0.2278851378317039], 
reward next is 0.7721, 
noisyNet noise sample is [array([0.6468007], dtype=float32), 0.43470007]. 
=============================================
[2019-03-27 05:05:38,468] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.1555148e-16 1.0075444e-09 4.7908550e-20 7.3577189e-16], sum to 1.0000
[2019-03-27 05:05:38,475] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0734
[2019-03-27 05:05:38,477] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.524630888959943, 6.9112, 6.9112, 168.912956510431, 466092.7313237334, 466092.7313237334, 155070.727167171], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 371400.0000, 
sim time next is 372000.0000, 
raw observation next is [20.8, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4895986017756531, 6.9112, 6.9112, 168.912956510431, 435066.5850133558, 435066.5850133558, 150641.4908236365], 
processed observation next is [1.0, 0.30434782608695654, 0.1848341232227489, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.37755927045811355, 0.0, 0.0, 0.8294399451523027, 0.12085182917037662, 0.12085182917037662, 0.22483804600542762], 
reward next is 0.7752, 
noisyNet noise sample is [array([-0.18917896], dtype=float32), -0.27583095]. 
=============================================
[2019-03-27 05:05:38,497] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.49777 ]
 [68.37818 ]
 [68.30684 ]
 [68.23909 ]
 [68.164825]], R is [[68.68626404]
 [68.76795959]
 [68.85869598]
 [68.94844055]
 [69.03720856]].
[2019-03-27 05:05:39,108] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.5898939e-18 8.4166501e-13 1.3415375e-21 6.4545333e-18], sum to 1.0000
[2019-03-27 05:05:39,116] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9796
[2019-03-27 05:05:39,124] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.31666666666667, 72.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8513784113181303, 6.911200000000001, 6.9112, 168.912956510431, 756174.7748838082, 756174.7748838076, 212232.3819549174], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 384600.0000, 
sim time next is 385200.0000, 
raw observation next is [22.4, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8559782708597925, 6.911200000000001, 6.9112, 168.912956510431, 760201.3799058652, 760201.3799058646, 213245.68766451], 
processed observation next is [1.0, 0.4782608695652174, 0.2606635071090047, 0.72, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8243637449509664, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21116704997385144, 0.21116704997385127, 0.3182771457679254], 
reward next is 0.6817, 
noisyNet noise sample is [array([0.13404198], dtype=float32), 0.35566768]. 
=============================================
[2019-03-27 05:05:42,561] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.0803208e-17 5.0028983e-12 2.9860202e-21 4.0412440e-16], sum to 1.0000
[2019-03-27 05:05:42,573] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7658
[2019-03-27 05:05:42,578] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.36666666666667, 80.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4511483301708334, 6.9112, 6.9112, 168.912956510431, 403357.0519538737, 403357.0519538737, 146020.7447156473], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 460200.0000, 
sim time next is 460800.0000, 
raw observation next is [20.4, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4592448320597555, 6.911199999999999, 6.9112, 168.912956510431, 410561.7255160952, 410561.7255160959, 146929.5744050189], 
processed observation next is [1.0, 0.34782608695652173, 0.16587677725118483, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.34054247812165306, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11404492375447088, 0.11404492375447108, 0.21929787224629688], 
reward next is 0.7807, 
noisyNet noise sample is [array([1.0253266], dtype=float32), -0.25080353]. 
=============================================
[2019-03-27 05:05:44,709] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 05:05:44,713] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:05:44,714] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:44,714] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:05:44,716] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:05:44,717] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:05:44,718] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:44,719] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:05:44,719] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:44,719] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:44,723] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:05:44,735] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run10
[2019-03-27 05:05:44,736] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run10
[2019-03-27 05:05:44,775] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run10
[2019-03-27 05:05:44,797] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run10
[2019-03-27 05:05:44,797] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run10
[2019-03-27 05:06:34,817] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:06:34,818] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9301958764972883, 6.911199999999999, 6.9112, 168.912956510431, 762659.3907043264, 762659.3907043271, 230354.9844025527]
[2019-03-27 05:06:34,819] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:06:34,822] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 8.0140752e-23 4.7545454e-15 1.6602437e-25 3.9289144e-21], sampled 0.7666013883146007
[2019-03-27 05:06:34,992] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:06:34,994] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8748369664543195, 6.9112, 6.9112, 168.912956510431, 722537.2784442991, 722537.2784442991, 217681.846473759]
[2019-03-27 05:06:34,994] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:06:34,997] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.4807796e-24 7.7470877e-16 9.4739706e-27 2.2999907e-22], sampled 0.025528078696456347
[2019-03-27 05:06:37,203] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:06:37,207] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.671960865, 64.947682355, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.694964814242108, 6.9112, 168.9083780447324, 2010150.461530807, 1454135.798653712, 311349.7859790564]
[2019-03-27 05:06:37,208] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:06:37,211] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9616444e-01 1.3631924e-09 3.8355377e-03 1.6860853e-12 4.0093666e-09], sampled 0.7225962443291422
[2019-03-27 05:06:37,212] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2010150.461530807 W.
[2019-03-27 05:06:53,940] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:06:53,942] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.03333333333333, 53.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.532546462463156, 6.9112, 168.9094114194455, 1894852.168452722, 1454056.854351457, 311356.3546909289]
[2019-03-27 05:06:53,943] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:06:53,946] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9996531e-01 2.6399642e-12 3.4706463e-05 2.7523383e-15 1.3104420e-11], sampled 0.9507205041457667
[2019-03-27 05:06:53,948] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1894852.168452722 W.
[2019-03-27 05:06:54,712] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:06:54,714] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666666, 65.66666666666667, 1.0, 2.0, 0.9208595832411499, 1.0, 2.0, 0.9208595832411499, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2575698.921073364, 2575698.921073363, 482995.0687824549]
[2019-03-27 05:06:54,715] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:06:54,719] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.98580694e-01 2.45433205e-11 1.41928880e-03 4.34608412e-15
 1.04706535e-10], sampled 0.9102109359968836
[2019-03-27 05:06:54,720] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2575698.921073364 W.
[2019-03-27 05:07:03,045] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:07:03,046] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.36666666666667, 52.33333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.364661051114475, 6.9112, 168.9099396760445, 2605669.578377558, 2283974.447462996, 475102.14677352]
[2019-03-27 05:07:03,047] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:07:03,050] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.1589768e-17 2.1559885e-08 7.6683577e-21 4.4013282e-16], sampled 0.15412416385107208
[2019-03-27 05:07:03,051] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2605669.578377558 W.
[2019-03-27 05:07:07,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:07:07,841] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.38780527, 89.64585605333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8310845139557517, 6.9112, 6.9112, 168.912956510431, 696898.3038306751, 696898.3038306751, 208375.2232832232]
[2019-03-27 05:07:07,842] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:07:07,845] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.0920415e-22 7.6227663e-15 4.7390030e-25 8.1505410e-21], sampled 0.11020212359675807
[2019-03-27 05:07:20,892] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051049776]
[2019-03-27 05:07:20,894] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8171258528340284, 6.9112, 6.9112, 168.912956510431, 686902.7287402173, 686902.7287402173, 205444.3649000962]
[2019-03-27 05:07:20,896] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:07:20,899] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.0702965e-23 1.4021262e-15 2.1458436e-26 5.0411494e-22], sampled 0.20023678653298738
[2019-03-27 05:07:38,185] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7347.7229 3105689986.6020 2010.0000
[2019-03-27 05:07:38,952] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.5742 3319246442.1569 2147.0000
[2019-03-27 05:07:38,956] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.7002 2989400357.2590 1565.0000
[2019-03-27 05:07:38,980] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8062.7793 2937746569.8053 1379.0000
[2019-03-27 05:07:39,151] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.7654 3185130590.1885 2464.0000
[2019-03-27 05:07:40,165] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 225000, evaluation results [225000.0, 7286.574178561911, 3319246442.156917, 2147.0, 7347.722935200103, 3105689986.602043, 2010.0, 8062.779342452763, 2937746569.8052874, 1379.0, 7030.765435313934, 3185130590.1884828, 2464.0, 7924.70016788502, 2989400357.2590485, 1565.0]
[2019-03-27 05:07:44,670] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.3892610e-18 1.4436192e-11 4.1383155e-21 3.3493105e-17], sum to 1.0000
[2019-03-27 05:07:44,683] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2517
[2019-03-27 05:07:44,690] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1040605.354574352 W.
[2019-03-27 05:07:44,693] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.56666666666666, 55.0, 1.0, 2.0, 0.3194685385073701, 1.0, 1.0, 0.3194685385073701, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1040605.354574352, 1040605.354574352, 268757.9620737016], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 560400.0000, 
sim time next is 561000.0000, 
raw observation next is [24.78333333333333, 54.5, 1.0, 2.0, 0.3238048703782, 1.0, 2.0, 0.3238048703782, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1051476.241224949, 1051476.241224949, 269701.2243292387], 
processed observation next is [1.0, 0.4782608695652174, 0.37361769352290675, 0.545, 1.0, 1.0, 0.18530707274481925, 1.0, 1.0, 0.18530707274481925, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.29207673367359693, 0.29207673367359693, 0.4025391407899085], 
reward next is 0.5975, 
noisyNet noise sample is [array([0.08997338], dtype=float32), 0.6755752]. 
=============================================
[2019-03-27 05:07:44,705] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.656204]
 [81.2874  ]
 [84.85927 ]
 [88.979805]
 [88.5471  ]], R is [[72.06402588]
 [71.94225311]
 [71.89546967]
 [71.8403244 ]
 [71.12192535]].
[2019-03-27 05:07:47,028] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.6744086e-19 1.8410664e-13 9.3071703e-23 6.7840582e-19], sum to 1.0000
[2019-03-27 05:07:47,038] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8266
[2019-03-27 05:07:47,047] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.16666666666667, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4029220851061137, 6.9112, 6.9112, 168.912956510431, 364737.7274437897, 364737.7274437897, 140588.9348239123], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 613200.0000, 
sim time next is 613800.0000, 
raw observation next is [17.15, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3853095321390009, 6.9112, 6.9112, 168.912956510431, 348792.9853543976, 348792.9853543976, 138921.8018911369], 
processed observation next is [1.0, 0.08695652173913043, 0.011848341232227487, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.25037747821829376, 0.0, 0.0, 0.8294399451523027, 0.09688694037622156, 0.09688694037622156, 0.20734597297184615], 
reward next is 0.7927, 
noisyNet noise sample is [array([-1.2176298], dtype=float32), -0.5323528]. 
=============================================
[2019-03-27 05:07:47,062] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.4424553e-19 2.1919154e-13 1.2647072e-22 8.5612749e-19], sum to 1.0000
[2019-03-27 05:07:47,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3824
[2019-03-27 05:07:47,081] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.15, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3853095321390009, 6.9112, 6.9112, 168.912956510431, 348792.9853543976, 348792.9853543976, 138921.8018911369], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 613800.0000, 
sim time next is 614400.0000, 
raw observation next is [17.13333333333333, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3810992058650003, 6.911200000000001, 6.9112, 168.912956510431, 344979.0289928328, 344979.0289928322, 138535.7187381904], 
processed observation next is [1.0, 0.08695652173913043, 0.011058451816745531, 0.9166666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.24524293398170766, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.09582750805356467, 0.09582750805356449, 0.20676972945998567], 
reward next is 0.7932, 
noisyNet noise sample is [array([-1.2176298], dtype=float32), -0.5323528]. 
=============================================
[2019-03-27 05:07:54,905] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.8116208e-17 3.4970506e-09 2.9804584e-19 3.1688763e-16], sum to 1.0000
[2019-03-27 05:07:54,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5271
[2019-03-27 05:07:54,918] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4512949911412575, 6.911200000000001, 6.9112, 168.912956510431, 403930.1500833399, 403930.1500833393, 146006.7290579627], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 757200.0000, 
sim time next is 757800.0000, 
raw observation next is [22.7, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4496990949635202, 6.911200000000001, 6.9112, 168.912956510431, 402372.2842304306, 402372.28423043, 145839.1840124018], 
processed observation next is [1.0, 0.782608695652174, 0.27488151658767773, 0.635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.32890133532136606, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1117700789528974, 0.11177007895289723, 0.21767042389910715], 
reward next is 0.7823, 
noisyNet noise sample is [array([1.0293114], dtype=float32), 1.6330159]. 
=============================================
[2019-03-27 05:07:55,575] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.0841242e-17 5.0141113e-09 5.6876132e-19 7.5331824e-15], sum to 1.0000
[2019-03-27 05:07:55,586] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8999
[2019-03-27 05:07:55,594] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4512949298218881, 6.911200000000001, 6.9112, 168.912956510431, 403930.1500833399, 403930.1500833393, 146006.7184239099], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 757200.0000, 
sim time next is 757800.0000, 
raw observation next is [22.7, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4496990772738323, 6.911200000000001, 6.9112, 168.912956510431, 402372.2842304306, 402372.28423043, 145839.1809675506], 
processed observation next is [1.0, 0.782608695652174, 0.27488151658767773, 0.635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.32890131374857595, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1117700789528974, 0.11177007895289723, 0.21767041935455314], 
reward next is 0.7823, 
noisyNet noise sample is [array([0.06629609], dtype=float32), 0.26496363]. 
=============================================
[2019-03-27 05:07:57,425] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.0518011e-20 1.0168182e-14 5.2755442e-23 1.0762979e-17], sum to 1.0000
[2019-03-27 05:07:57,429] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5642
[2019-03-27 05:07:57,435] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.6, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4700931983547628, 6.9112, 6.9112, 168.912956510431, 419403.3804272165, 419403.3804272165, 148226.8874601711], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 765000.0000, 
sim time next is 765600.0000, 
raw observation next is [20.53333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4696521806838971, 6.911199999999999, 6.9112, 168.912956510431, 419011.686924542, 419011.6869245426, 148175.6030738184], 
processed observation next is [1.0, 0.8695652173913043, 0.17219589257503945, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3532343666876793, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11639213525681723, 0.11639213525681738, 0.22115761652808716], 
reward next is 0.7788, 
noisyNet noise sample is [array([0.30079657], dtype=float32), 0.16751286]. 
=============================================
[2019-03-27 05:08:01,385] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.8509696e-20 6.0023153e-14 3.6725836e-23 3.0758543e-19], sum to 1.0000
[2019-03-27 05:08:01,395] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4996
[2019-03-27 05:08:01,409] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613115436100753, 6.911200000000001, 6.9112, 168.912956510431, 492077.1015525088, 492077.1015525082, 160320.529328531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 842400.0000, 
sim time next is 843000.0000, 
raw observation next is [22.93333333333333, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5594104570357795, 6.9112, 6.9112, 168.912956510431, 490571.6716944638, 490571.6716944638, 160047.4965250248], 
processed observation next is [0.0, 0.782608695652174, 0.28593996840442326, 0.7816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46269567931192623, 0.0, 0.0, 0.8294399451523027, 0.13626990880401774, 0.13626990880401774, 0.23887686048511164], 
reward next is 0.7611, 
noisyNet noise sample is [array([-0.6544449], dtype=float32), -1.7785686]. 
=============================================
[2019-03-27 05:08:01,426] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[87.546616]
 [87.40985 ]
 [87.290306]
 [87.16787 ]
 [87.04701 ]], R is [[87.58540344]
 [87.47026825]
 [87.35644531]
 [87.2438736 ]
 [87.13232422]].
[2019-03-27 05:08:06,907] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 6.610711e-22 7.278025e-15 8.918440e-24 2.824617e-21], sum to 1.0000
[2019-03-27 05:08:06,915] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8722
[2019-03-27 05:08:06,919] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.9, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5962062600409704, 6.9112, 6.9112, 168.912956510431, 518922.6041117552, 518922.6041117552, 165508.3074927828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 934200.0000, 
sim time next is 934800.0000, 
raw observation next is [22.83333333333334, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5971186468748392, 6.911199999999999, 6.9112, 168.912956510431, 519477.9307774201, 519477.9307774206, 165650.4818115509], 
processed observation next is [0.0, 0.8260869565217391, 0.2812006319115327, 0.8533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5086812766766331, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14429942521595004, 0.14429942521595016, 0.24723952509186703], 
reward next is 0.7528, 
noisyNet noise sample is [array([-3.082027], dtype=float32), 1.0375736]. 
=============================================
[2019-03-27 05:08:14,398] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6826933e-18 8.9538349e-14 1.1981832e-20 2.3138140e-16], sum to 1.0000
[2019-03-27 05:08:14,411] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8880
[2019-03-27 05:08:14,416] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.75, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5558796874442966, 6.9112, 6.9112, 168.912956510431, 487850.8660610176, 487850.8660610176, 159540.6579925993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1063800.0000, 
sim time next is 1064400.0000, 
raw observation next is [20.8, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5553109428421346, 6.9112, 6.9112, 168.912956510431, 487114.345083642, 487114.345083642, 159468.0444833062], 
processed observation next is [1.0, 0.30434782608695654, 0.1848341232227489, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.45769627175870065, 0.0, 0.0, 0.8294399451523027, 0.13530954030101167, 0.13530954030101167, 0.2380120066915018], 
reward next is 0.7620, 
noisyNet noise sample is [array([-0.5129495], dtype=float32), -1.1346705]. 
=============================================
[2019-03-27 05:08:17,516] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.6203091e-20 2.6015594e-13 1.3060834e-22 1.0911294e-19], sum to 1.0000
[2019-03-27 05:08:17,525] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6770
[2019-03-27 05:08:17,531] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.05, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5386378788703737, 6.911199999999999, 6.9112, 168.912956510431, 474421.9454683191, 474421.9454683198, 157112.1644520098], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1122600.0000, 
sim time next is 1123200.0000, 
raw observation next is [21.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5360674564316787, 6.9112, 6.9112, 168.912956510431, 472284.1767909801, 472284.1767909801, 156761.0608797484], 
processed observation next is [1.0, 0.0, 0.19431279620853087, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43422860540448627, 0.0, 0.0, 0.8294399451523027, 0.13119004910860557, 0.13119004910860557, 0.2339717326563409], 
reward next is 0.7660, 
noisyNet noise sample is [array([0.39743212], dtype=float32), 0.45988584]. 
=============================================
[2019-03-27 05:08:17,536] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.6890979e-19 4.2830435e-12 1.9616520e-21 5.0534267e-17], sum to 1.0000
[2019-03-27 05:08:17,543] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0205
[2019-03-27 05:08:17,548] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.55, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5242926993718113, 6.9112, 6.9112, 168.912956510431, 462853.398360409, 462853.398360409, 155160.8375809224], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1129800.0000, 
sim time next is 1130400.0000, 
raw observation next is [20.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5251915285053553, 6.9112, 6.9112, 168.912956510431, 463771.3538605892, 463771.3538605892, 155273.9644279389], 
processed observation next is [1.0, 0.08695652173913043, 0.1706161137440759, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42096527866506744, 0.0, 0.0, 0.8294399451523027, 0.1288253760723859, 0.1288253760723859, 0.23175218571334164], 
reward next is 0.7682, 
noisyNet noise sample is [array([-1.3583992], dtype=float32), -1.1041312]. 
=============================================
[2019-03-27 05:08:17,718] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.1402107e-17 1.4717896e-10 3.1407555e-21 4.6917891e-16], sum to 1.0000
[2019-03-27 05:08:17,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3427
[2019-03-27 05:08:17,731] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5181631606873247, 6.9112, 6.9112, 168.912956510431, 458312.5188377349, 458312.5188377349, 154325.782612651], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1136400.0000, 
sim time next is 1137000.0000, 
raw observation next is [19.95, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5131457735794475, 6.911200000000001, 6.9112, 168.912956510431, 453996.2622211641, 453996.2622211634, 153674.2260642993], 
processed observation next is [1.0, 0.13043478260869565, 0.14454976303317538, 0.9383333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4062753336334725, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12611007283921224, 0.12611007283921205, 0.22936451651387954], 
reward next is 0.7706, 
noisyNet noise sample is [array([0.16189751], dtype=float32), 1.0428271]. 
=============================================
[2019-03-27 05:08:17,746] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.79319 ]
 [70.90089 ]
 [70.7945  ]
 [71.06558 ]
 [71.233765]], R is [[70.78804779]
 [70.84983063]
 [70.90914154]
 [70.9659729 ]
 [71.01263428]].
[2019-03-27 05:08:24,999] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 1.06411474e-19 1.58736170e-13 1.30698046e-22
 8.98718087e-18], sum to 1.0000
[2019-03-27 05:08:25,004] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-27 05:08:25,010] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.51666666666667, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7952094521225354, 6.9112, 6.9112, 168.912956510431, 681742.7895175884, 681742.7895175884, 201030.1384559908], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1239000.0000, 
sim time next is 1239600.0000, 
raw observation next is [24.73333333333333, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.848298429047545, 6.9112, 168.908013091012, 1547045.829975085, 882255.4083463415, 256635.96575431], 
processed observation next is [1.0, 0.34782608695652173, 0.3712480252764612, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.09370984290475448, 0.0, 0.8294156706998482, 0.429734952770857, 0.24507094676287264, 0.3830387548571791], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.92824817], dtype=float32), 0.059317365]. 
=============================================
[2019-03-27 05:08:28,344] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.3904139e-18 2.5774755e-10 8.6358504e-22 4.1725179e-16], sum to 1.0000
[2019-03-27 05:08:28,353] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9833
[2019-03-27 05:08:28,364] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.26666666666667, 93.33333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9281001411068153, 6.911200000000001, 6.9112, 168.9129565103874, 781323.9735649514, 781323.9735649507, 230514.4881063783], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1305600.0000, 
sim time next is 1306200.0000, 
raw observation next is [24.28333333333333, 93.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.903872335305536, 6.9112, 6.9112, 168.912956510431, 763002.2734135357, 763002.2734135357, 224801.3098971844], 
processed observation next is [1.0, 0.08695652173913043, 0.34992101105845175, 0.9316666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8827711406165073, 0.0, 0.0, 0.8294399451523027, 0.21194507594820436, 0.21194507594820436, 0.33552434313012597], 
reward next is 0.6645, 
noisyNet noise sample is [array([-0.04303062], dtype=float32), -1.4688096]. 
=============================================
[2019-03-27 05:08:29,693] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.5573619e-20 1.9574198e-11 6.7934480e-22 2.2881188e-19], sum to 1.0000
[2019-03-27 05:08:29,704] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8417
[2019-03-27 05:08:29,708] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7982863761578818, 6.9112, 6.9112, 168.912956510431, 679141.4078438018, 679141.4078438018, 201639.2978720683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1321200.0000, 
sim time next is 1321800.0000, 
raw observation next is [23.51666666666667, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9071469471117999, 6.9112, 6.9112, 168.912956510431, 772385.0555037736, 772385.0555037736, 225657.4210709438], 
processed observation next is [1.0, 0.30434782608695654, 0.31358609794628767, 0.9416666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8867645696485364, 0.0, 0.0, 0.8294399451523027, 0.21455140430660377, 0.21455140430660377, 0.33680212100140866], 
reward next is 0.6632, 
noisyNet noise sample is [array([-0.7237873], dtype=float32), 1.9694842]. 
=============================================
[2019-03-27 05:08:31,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 3.8556393e-15 1.1756649e-07 1.3742657e-17 4.3147787e-14], sum to 1.0000
[2019-03-27 05:08:31,566] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3129
[2019-03-27 05:08:31,569] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.96666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5747303494405622, 6.9112, 6.9112, 168.912956510431, 504321.7038382572, 504321.7038382572, 162229.3990710668], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1362000.0000, 
sim time next is 1362600.0000, 
raw observation next is [21.0, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5776467449595225, 6.911200000000001, 6.9112, 168.912956510431, 506622.848828721, 506622.8488287205, 162661.2086052704], 
processed observation next is [1.0, 0.782608695652174, 0.19431279620853087, 0.935, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.48493505482868593, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14072856911908915, 0.14072856911908904, 0.24277792329144834], 
reward next is 0.7572, 
noisyNet noise sample is [array([0.06850482], dtype=float32), 0.46823856]. 
=============================================
[2019-03-27 05:08:34,171] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.4036895e-19 9.1454795e-13 3.0295165e-21 3.2990937e-18], sum to 1.0000
[2019-03-27 05:08:34,179] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4472
[2019-03-27 05:08:34,183] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.43333333333334, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5873522551079331, 6.9112, 6.9112, 168.912956510431, 512773.129944919, 512773.129944919, 164150.0711777089], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1406400.0000, 
sim time next is 1407000.0000, 
raw observation next is [21.51666666666667, 93.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5889112717900556, 6.911199999999999, 6.9112, 168.912956510431, 513909.2603748616, 513909.2603748622, 164387.0204032524], 
processed observation next is [0.0, 0.2608695652173913, 0.21879936808846778, 0.9333333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49867228267079955, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14275257232635044, 0.1427525723263506, 0.2453537617958991], 
reward next is 0.7546, 
noisyNet noise sample is [array([-0.6876853], dtype=float32), -1.3259764]. 
=============================================
[2019-03-27 05:08:34,197] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[78.78931 ]
 [78.699615]
 [78.611534]
 [78.51665 ]
 [78.39998 ]], R is [[78.84370422]
 [78.81026459]
 [78.77729797]
 [78.74495697]
 [78.71356201]].
[2019-03-27 05:08:34,936] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 05:08:34,937] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:08:34,938] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:08:34,938] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:08:34,939] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:08:34,940] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:08:34,939] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:08:34,942] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:08:34,943] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:08:34,944] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:08:34,941] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:08:34,970] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run11
[2019-03-27 05:08:34,970] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run11
[2019-03-27 05:08:34,970] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run11
[2019-03-27 05:08:34,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run11
[2019-03-27 05:08:34,990] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run11
[2019-03-27 05:08:42,267] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051546793]
[2019-03-27 05:08:42,269] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.3, 89.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5914668236139701, 6.911199999999999, 6.9112, 168.912956510431, 514772.5227771446, 514772.5227771453, 164795.7082530452]
[2019-03-27 05:08:42,269] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:08:42,274] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 7.5455881e-20 3.2978814e-13 2.5108279e-22 4.6827546e-18], sampled 0.02473594004643065
[2019-03-27 05:09:32,813] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051546793]
[2019-03-27 05:09:32,814] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.31091565333333, 90.17594503666668, 1.0, 2.0, 0.6298328151709056, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564729976, 880168.6702532171, 880168.6702532171, 206435.6617662142]
[2019-03-27 05:09:32,815] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:09:32,817] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9999917e-01 7.3998574e-14 8.6500120e-07 8.2540859e-17 4.9140119e-13], sampled 0.8387927178427927
[2019-03-27 05:09:32,821] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 880168.6702532171 W.
[2019-03-27 05:09:54,588] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051546793]
[2019-03-27 05:09:54,589] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.1, 79.0, 1.0, 2.0, 0.8294449770494327, 1.0, 2.0, 0.8294449770494327, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2319740.790566234, 2319740.790566234, 434945.5638244685]
[2019-03-27 05:09:54,590] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:09:54,592] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.8357380e-16 3.0035976e-09 3.2890518e-19 1.9182064e-14], sampled 0.4611617355259967
[2019-03-27 05:09:54,594] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2319740.790566234 W.
[2019-03-27 05:10:02,412] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051546793]
[2019-03-27 05:10:02,414] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.76666666666667, 93.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.064757052061834, 6.9112, 168.9117354652255, 1562767.404852886, 1453829.534594795, 311348.8315768247]
[2019-03-27 05:10:02,415] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:10:02,417] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999988e-01 4.6364070e-14 1.4378773e-07 5.0389887e-17 7.4839240e-13], sampled 0.06783312225857352
[2019-03-27 05:10:02,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1562767.404852886 W.
[2019-03-27 05:10:31,372] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8061.8851 2937706358.0323 1378.0000
[2019-03-27 05:10:31,397] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7287.6081 3319178506.8158 2146.0000
[2019-03-27 05:10:31,439] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.7369 2989231504.2226 1567.0000
[2019-03-27 05:10:31,473] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7346.7896 3105826639.6484 2011.0000
[2019-03-27 05:10:31,532] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7028.7986 3185120678.5872 2464.0000
[2019-03-27 05:10:32,548] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 250000, evaluation results [250000.0, 7287.6080641005765, 3319178506.815808, 2146.0, 7346.789564577235, 3105826639.648395, 2011.0, 8061.885098774584, 2937706358.0322814, 1378.0, 7028.7986166665305, 3185120678.5872374, 2464.0, 7922.736852801341, 2989231504.2226057, 1567.0]
[2019-03-27 05:10:34,730] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.5243422e-21 2.5369260e-13 1.2481236e-23 3.9595349e-20], sum to 1.0000
[2019-03-27 05:10:34,744] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9437
[2019-03-27 05:10:34,749] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6678220462254614, 6.9112, 6.9112, 168.912956510431, 574572.6535373455, 574572.6535373455, 177096.3989374125], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1458000.0000, 
sim time next is 1458600.0000, 
raw observation next is [22.63333333333333, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6660934703736887, 6.9112, 6.9112, 168.912956510431, 573246.6561010603, 573246.6561010603, 176801.1988816337], 
processed observation next is [0.0, 0.9130434782608695, 0.27172195892575024, 0.9416666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5927969150898642, 0.0, 0.0, 0.8294399451523027, 0.15923518225029454, 0.15923518225029454, 0.26388238639049805], 
reward next is 0.7361, 
noisyNet noise sample is [array([-0.89499134], dtype=float32), -0.3800562]. 
=============================================
[2019-03-27 05:10:35,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.2833839e-21 2.5072777e-14 1.8871913e-23 9.6839647e-19], sum to 1.0000
[2019-03-27 05:10:35,921] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5423
[2019-03-27 05:10:35,933] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6330053591598409, 6.9112, 6.9112, 168.912956510431, 548512.7026637949, 548512.7026637949, 171288.7891246733], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1468800.0000, 
sim time next is 1469400.0000, 
raw observation next is [21.76666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6308829141953167, 6.911200000000001, 6.9112, 168.912956510431, 546872.345333176, 546872.3453331754, 170944.9122067142], 
processed observation next is [0.0, 0.0, 0.23064770932069528, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5498572124333131, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1519089848147711, 0.15190898481477094, 0.2551416600100212], 
reward next is 0.7449, 
noisyNet noise sample is [array([1.1592847], dtype=float32), 2.2595067]. 
=============================================
[2019-03-27 05:10:36,115] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.7740537e-19 5.2945728e-13 2.8616984e-21 5.3410237e-18], sum to 1.0000
[2019-03-27 05:10:36,121] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7259
[2019-03-27 05:10:36,129] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6027963371622731, 6.911199999999999, 6.9112, 168.912956510431, 524194.9318888809, 524194.9318888815, 166518.0087543248], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1491600.0000, 
sim time next is 1492200.0000, 
raw observation next is [22.1, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6083304755608897, 6.911199999999999, 6.9112, 168.912956510431, 528449.00397552, 528449.0039755206, 167377.2945048273], 
processed observation next is [0.0, 0.2608695652173913, 0.24644549763033188, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5223542384888898, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14679138999320002, 0.14679138999320016, 0.2498168574698915], 
reward next is 0.7502, 
noisyNet noise sample is [array([0.45081604], dtype=float32), 0.8383419]. 
=============================================
[2019-03-27 05:10:46,812] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4164240e-18 1.3677900e-11 1.8675206e-21 1.2692930e-16], sum to 1.0000
[2019-03-27 05:10:46,824] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9717
[2019-03-27 05:10:46,831] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.61666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.757889007679895, 6.911199999999999, 6.9112, 168.912956510431, 640969.2873152549, 640969.2873152556, 193501.3173730921], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1667400.0000, 
sim time next is 1668000.0000, 
raw observation next is [23.63333333333334, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7341690437217397, 6.911199999999999, 6.9112, 168.912956510431, 620794.4020437129, 620794.4020437135, 188954.1219282224], 
processed observation next is [1.0, 0.30434782608695654, 0.3191153238546607, 0.98, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6758159069777313, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17244288945658692, 0.1724428894565871, 0.28202107750480954], 
reward next is 0.7180, 
noisyNet noise sample is [array([-0.6454223], dtype=float32), 0.97600895]. 
=============================================
[2019-03-27 05:10:46,842] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[74.5647  ]
 [74.51281 ]
 [74.438545]
 [74.16171 ]
 [73.91874 ]], R is [[74.84238434]
 [74.80515289]
 [74.75997162]
 [74.7088089 ]
 [74.65776062]].
[2019-03-27 05:10:53,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.7914916e-01 5.7022254e-09 2.0850679e-02 2.6450676e-13 1.1138280e-07], sum to 1.0000
[2019-03-27 05:10:53,048] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9425
[2019-03-27 05:10:53,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1191475.664920432 W.
[2019-03-27 05:10:53,058] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [23.71666666666667, 82.66666666666667, 1.0, 2.0, 0.3962949363498088, 1.0, 2.0, 0.3962949363498088, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1191475.664920432, 1191475.664920432, 280997.4467705899], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1768200.0000, 
sim time next is 1768800.0000, 
raw observation next is [23.63333333333334, 83.33333333333334, 1.0, 2.0, 0.3867666997252097, 1.0, 2.0, 0.3867666997252097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1164064.894725403, 1164064.894725403, 278600.1449883887], 
processed observation next is [1.0, 0.4782608695652174, 0.3191153238546607, 0.8333333333333335, 1.0, 1.0, 0.2611646984641081, 1.0, 1.0, 0.2611646984641081, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3233513596459453, 0.3233513596459453, 0.4158211119229682], 
reward next is 0.5842, 
noisyNet noise sample is [array([-0.23773557], dtype=float32), 1.2130789]. 
=============================================
[2019-03-27 05:10:57,227] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.1368759e-01 1.7403472e-09 8.6312339e-02 1.0968990e-13 6.8720039e-09], sum to 1.0000
[2019-03-27 05:10:57,236] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8405
[2019-03-27 05:10:57,243] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1563892.436237483 W.
[2019-03-27 05:10:57,251] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.8, 84.0, 1.0, 1.0, 0.3729136935385054, 1.0, 1.0, 0.3729136935385054, 1.0, 2.0, 0.6359010798344372, 6.9112, 6.9112, 170.5573041426782, 1563892.436237483, 1563892.436237483, 336876.7138308523], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1863000.0000, 
sim time next is 1863600.0000, 
raw observation next is [26.9, 83.66666666666666, 1.0, 2.0, 0.522971581025424, 1.0, 2.0, 0.522971581025424, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1462058.538275966, 1462058.538275966, 307536.9739054891], 
processed observation next is [1.0, 0.5652173913043478, 0.4739336492890995, 0.8366666666666666, 1.0, 1.0, 0.4252669650908722, 1.0, 1.0, 0.4252669650908722, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.40612737174332386, 0.40612737174332386, 0.45901040881416283], 
reward next is 0.5410, 
noisyNet noise sample is [array([-0.21569534], dtype=float32), -0.9047336]. 
=============================================
[2019-03-27 05:11:07,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.4133491e-18 2.1432054e-11 4.1542569e-22 3.5009539e-17], sum to 1.0000
[2019-03-27 05:11:07,182] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2520
[2019-03-27 05:11:07,188] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.55, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8531914215175289, 6.911200000000001, 6.9112, 168.912956510431, 707319.625740364, 707319.6257403634, 212952.8362110296], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2021400.0000, 
sim time next is 2022000.0000, 
raw observation next is [25.53333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8529254413730999, 6.911200000000001, 6.9112, 168.912956510431, 707268.2754399147, 707268.275439914, 212899.8442918908], 
processed observation next is [0.0, 0.391304347826087, 0.4091627172195892, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8206407821623168, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19646340984442073, 0.19646340984442054, 0.31776096162968775], 
reward next is 0.6822, 
noisyNet noise sample is [array([1.1469636], dtype=float32), 0.7467971]. 
=============================================
[2019-03-27 05:11:07,201] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.90846 ]
 [80.80468 ]
 [80.6955  ]
 [80.558205]
 [80.44126 ]], R is [[80.88751221]
 [80.76079559]
 [80.63545227]
 [80.51150513]
 [80.38884735]].
[2019-03-27 05:11:18,142] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [3.3291243e-02 5.9901026e-08 9.6670860e-01 2.8012231e-13 1.3238411e-08], sum to 1.0000
[2019-03-27 05:11:18,149] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0100
[2019-03-27 05:11:18,159] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2231088.885100798 W.
[2019-03-27 05:11:18,167] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 74.5, 1.0, 2.0, 0.954336195961388, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.997898921741024, 6.9112, 168.9123706252432, 2231088.885100798, 2169581.899412697, 449879.4982137688], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2197800.0000, 
sim time next is 2198400.0000, 
raw observation next is [30.0, 74.0, 1.0, 2.0, 0.7784179951614353, 1.0, 1.0, 0.7784179951614353, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2176929.129321575, 2176929.129321575, 409502.5521616539], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.74, 1.0, 1.0, 0.733033729110163, 1.0, 0.5, 0.733033729110163, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6047025359226598, 0.6047025359226598, 0.6111978390472446], 
reward next is 0.3888, 
noisyNet noise sample is [array([0.11271138], dtype=float32), -0.35675216]. 
=============================================
[2019-03-27 05:11:18,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.5770311e-04 5.8234013e-09 9.9984229e-01 1.1077092e-14 4.4925638e-10], sum to 1.0000
[2019-03-27 05:11:18,735] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6122
[2019-03-27 05:11:18,740] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333334, 67.66666666666666, 1.0, 2.0, 0.7695499197321372, 1.0, 2.0, 0.7695499197321372, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2152103.694459016, 2152103.694459016, 405325.3069803797], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2220000.0000, 
sim time next is 2220600.0000, 
raw observation next is [31.81666666666667, 67.83333333333334, 1.0, 2.0, 0.826843439061209, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005983161477031, 6.9112, 168.912393175526, 2052642.511196456, 1985400.29851758, 414567.3545726954], 
processed observation next is [1.0, 0.6956521739130435, 0.7069510268562403, 0.6783333333333335, 1.0, 1.0, 0.7913776374231434, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009478316147703137, 0.0, 0.8294371789200233, 0.5701784753323489, 0.55150008292155, 0.6187572456308886], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6176501], dtype=float32), 0.63961303]. 
=============================================
[2019-03-27 05:11:21,130] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999917e-01 1.7282119e-16 8.5313991e-07 5.4284762e-20 2.1650169e-14], sum to 1.0000
[2019-03-27 05:11:21,141] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3001
[2019-03-27 05:11:21,146] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.3, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9330208271339202, 6.911199999999999, 6.9112, 168.912956510431, 760887.8415388272, 760887.8415388279, 230849.6535225691], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2236200.0000, 
sim time next is 2236800.0000, 
raw observation next is [28.2, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9302496191485616, 6.911199999999999, 6.9112, 168.912956510431, 759203.1609540338, 759203.1609540345, 230211.1543201735], 
processed observation next is [1.0, 0.9130434782608695, 0.5355450236966824, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9149385599372702, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21088976693167608, 0.21088976693167627, 0.34359873779130373], 
reward next is 0.6564, 
noisyNet noise sample is [array([0.468672], dtype=float32), -0.008123165]. 
=============================================
[2019-03-27 05:11:21,816] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.9700966e-01 6.0910068e-08 4.0299016e-01 4.4359312e-12 9.1606431e-08], sum to 1.0000
[2019-03-27 05:11:21,826] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0131
[2019-03-27 05:11:21,834] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1063664.240618321 W.
[2019-03-27 05:11:21,839] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.95, 87.16666666666667, 1.0, 2.0, 0.7610732102637446, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1063664.240618321, 1063664.240618321, 234576.9916560088], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2261400.0000, 
sim time next is 2262000.0000, 
raw observation next is [25.9, 87.33333333333334, 1.0, 2.0, 0.3573412564454568, 1.0, 1.0, 0.3573412564454568, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 998794.2954123806, 998794.2954123806, 261907.5027065681], 
processed observation next is [1.0, 0.17391304347826086, 0.42654028436018954, 0.8733333333333334, 1.0, 1.0, 0.22571235716320093, 1.0, 0.5, 0.22571235716320093, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2774428598367724, 0.2774428598367724, 0.39090672045756436], 
reward next is 0.6091, 
noisyNet noise sample is [array([0.77424717], dtype=float32), 0.84005964]. 
=============================================
[2019-03-27 05:11:21,851] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[21.961819]
 [22.891981]
 [24.053518]
 [26.853832]
 [28.623985]], R is [[20.10461998]
 [20.55345917]
 [21.02983475]
 [20.81953621]
 [20.61134148]].
[2019-03-27 05:11:23,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5965249e-03 2.4398314e-09 9.9240351e-01 8.0749616e-15 1.9739099e-10], sum to 1.0000
[2019-03-27 05:11:23,534] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0024
[2019-03-27 05:11:23,543] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1721252.600324335 W.
[2019-03-27 05:11:23,551] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.95, 63.5, 1.0, 2.0, 0.6156048977449742, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.94855184714433, 6.9112, 168.9126958234231, 1721252.600324335, 1694753.955304775, 367758.5025255526], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2291400.0000, 
sim time next is 2292000.0000, 
raw observation next is [31.93333333333333, 63.66666666666667, 1.0, 2.0, 0.8066917532984661, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.997762935580667, 6.9112, 168.9124120960462, 2024438.826503998, 1963028.298666409, 409811.7372915696], 
processed observation next is [1.0, 0.5217391304347826, 0.7124802527646128, 0.6366666666666667, 1.0, 1.0, 0.7670984979499591, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008656293558066696, 0.0, 0.8294372718284394, 0.5623441184733328, 0.5452856385184469, 0.6116593093904024], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1962609], dtype=float32), -0.24798799]. 
=============================================
[2019-03-27 05:11:23,567] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[29.594793]
 [29.00133 ]
 [31.177183]
 [31.514608]
 [31.450043]], R is [[29.95651817]
 [29.65695381]
 [29.79554367]
 [29.49758911]
 [29.20261383]].
[2019-03-27 05:11:23,570] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.8836709e-02 1.4931608e-09 9.8116332e-01 4.9886353e-15 3.2115903e-09], sum to 1.0000
[2019-03-27 05:11:23,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4951
[2019-03-27 05:11:23,587] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.9, 62.5, 1.0, 2.0, 0.8044438801042155, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993000892933748, 6.9112, 168.9124038323439, 2021292.818350119, 1963260.639413619, 409430.2969418867], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2285400.0000, 
sim time next is 2286000.0000, 
raw observation next is [32.1, 62.0, 1.0, 2.0, 0.8270085329088853, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994659756968876, 6.9112, 168.912393577055, 2052873.57459966, 1993664.547868376, 415050.6227524114], 
processed observation next is [1.0, 0.4782608695652174, 0.7203791469194314, 0.62, 1.0, 1.0, 0.7915765456733558, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008345975696887642, 0.0, 0.8294371808917146, 0.5702426596110167, 0.5537957077412156, 0.6194785414215096], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29624453], dtype=float32), 1.5339646]. 
=============================================
[2019-03-27 05:11:23,596] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[31.193043]
 [30.836918]
 [30.90745 ]
 [33.86933 ]
 [32.25076 ]], R is [[30.6952095 ]
 [30.38825798]
 [30.08437538]
 [30.27981758]
 [30.44495773]].
[2019-03-27 05:11:24,000] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.240524e-03 6.979622e-09 9.947595e-01 7.105651e-15 8.064442e-10], sum to 1.0000
[2019-03-27 05:11:24,007] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7825
[2019-03-27 05:11:24,011] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.81666666666667, 64.83333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.180545069515611, 6.9112, 168.9112620196119, 2479151.243388202, 2288070.497823505, 475718.5730942936], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2296200.0000, 
sim time next is 2296800.0000, 
raw observation next is [31.8, 65.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.322210991149515, 6.9112, 168.9102064211594, 2579535.502192955, 2287954.90649595, 475404.75746801], 
processed observation next is [1.0, 0.6086956521739131, 0.7061611374407584, 0.65, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04110109911495145, 0.0, 0.8294264409549827, 0.716537639498043, 0.6355430295822084, 0.7095593395044926], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7448682], dtype=float32), -0.4382367]. 
=============================================
[2019-03-27 05:11:27,705] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 05:11:27,706] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:11:27,706] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:11:27,707] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:11:27,708] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:11:27,709] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:11:27,707] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:11:27,709] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:11:27,711] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:11:27,714] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:11:27,713] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:11:27,732] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run12
[2019-03-27 05:11:27,752] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run12
[2019-03-27 05:11:27,753] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run12
[2019-03-27 05:11:27,787] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run12
[2019-03-27 05:11:27,808] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run12
[2019-03-27 05:11:32,176] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:11:32,177] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.77848153833333, 90.09536531333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325828896787597, 6.9112, 6.9112, 168.912956510431, 470252.3185106953, 470252.3185106953, 156254.9324624719]
[2019-03-27 05:11:32,178] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:11:32,181] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999988e-01 1.2905910e-15 8.0123776e-08 3.6261225e-19 8.0668623e-15], sampled 0.8840944833921995
[2019-03-27 05:11:51,211] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:11:51,213] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.30641036, 91.13171717, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9274924639399397, 6.9112, 6.9112, 168.912956510431, 793305.1069427256, 793305.1069427256, 230522.9644361068]
[2019-03-27 05:11:51,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:11:51,217] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999976e-01 4.1542074e-15 1.8064489e-07 1.5196181e-18 2.9250487e-14], sampled 0.5825461792298754
[2019-03-27 05:12:12,685] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:12:12,686] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 1.0, 2.0, 0.2388812010495233, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4032929405655393, 6.911199999999999, 6.9112, 168.9129565103815, 667588.9638855772, 667588.9638855779, 203496.6168862858]
[2019-03-27 05:12:12,688] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:12:12,690] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.7229997e-01 4.2833809e-10 1.2770005e-01 7.7591996e-15 3.3638667e-10], sampled 0.3342152661722336
[2019-03-27 05:12:13,363] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:12:13,364] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.43333333333334, 54.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.926465806257826, 6.9112, 168.9126785387882, 841048.9734100067, 830218.9028647395, 254895.8812450281]
[2019-03-27 05:12:13,365] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:12:13,367] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999988e-01 4.1621209e-16 9.3095302e-08 5.3605514e-20 2.4436145e-15], sampled 0.9730570897100075
[2019-03-27 05:12:59,976] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:12:59,978] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.0, 80.33333333333334, 1.0, 2.0, 0.6042030670389475, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.925406306020569, 6.9112, 168.9125134564566, 1689347.31477386, 1679268.898775023, 365650.661349868]
[2019-03-27 05:12:59,980] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:12:59,982] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.8767922e-01 1.8131475e-08 6.1232072e-01 1.6568325e-12 1.7926254e-08], sampled 0.37764377335282906
[2019-03-27 05:12:59,984] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1689347.31477386 W.
[2019-03-27 05:13:01,118] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:13:01,119] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.75, 91.0, 1.0, 2.0, 0.3153606927860725, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5384631823750469, 6.9112, 6.9112, 168.912956510431, 881410.9306329554, 881410.9306329554, 226022.0942550087]
[2019-03-27 05:13:01,120] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:13:01,122] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.6819381e-01 2.2188136e-08 6.3180619e-01 2.5680087e-12 1.9139849e-08], sampled 0.3385815681384019
[2019-03-27 05:13:01,124] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 881410.9306329554 W.
[2019-03-27 05:13:02,410] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:13:02,411] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.07473872666667, 73.89745635666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.806964745054276, 6.9112, 6.9112, 168.912956510431, 678993.7905763892, 678993.7905763892, 203329.4688118455]
[2019-03-27 05:13:02,412] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:13:02,414] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9999988e-01 2.5368009e-16 7.9600845e-08 2.3724955e-20 1.4306971e-15], sampled 0.22456968620462303
[2019-03-27 05:13:19,438] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046572484]
[2019-03-27 05:13:19,439] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.48333333333333, 61.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5765487183153024, 6.9112, 6.9112, 168.912956510431, 505697.8240916816, 505697.8240916816, 162500.0247874679]
[2019-03-27 05:13:19,440] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:13:19,442] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999976e-01 3.4699374e-15 2.8338698e-07 6.8565926e-19 1.5341506e-14], sampled 0.36291083942931124
[2019-03-27 05:13:21,015] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7086.6878 3122421341.9537 1785.0000
[2019-03-27 05:13:21,726] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7113.9906 3326149838.4502 2051.0000
[2019-03-27 05:13:21,728] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6833.3003 3199459386.6372 2296.0000
[2019-03-27 05:13:21,988] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7897.6530 2947965493.9672 1223.0000
[2019-03-27 05:13:22,001] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7765.0093 2999833650.5335 1399.0000
[2019-03-27 05:13:23,018] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 275000, evaluation results [275000.0, 7113.990646032077, 3326149838.4502068, 2051.0, 7086.687771559629, 3122421341.9536834, 1785.0, 7897.652983969123, 2947965493.9672146, 1223.0, 6833.300257315502, 3199459386.6371937, 2296.0, 7765.009279574002, 2999833650.5334773, 1399.0]
[2019-03-27 05:13:31,941] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999881e-01 1.7055037e-14 1.1417446e-06 1.1799579e-18 5.3136643e-14], sum to 1.0000
[2019-03-27 05:13:31,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6742
[2019-03-27 05:13:31,954] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.43333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9335322575495425, 6.9112, 6.9112, 168.912956510431, 762114.3246316728, 762114.3246316728, 231010.4641322339], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2511600.0000, 
sim time next is 2512200.0000, 
raw observation next is [26.41666666666666, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9322189577618589, 6.911199999999999, 6.9112, 168.912956510431, 761241.5150704212, 761241.5150704217, 230703.8277730159], 
processed observation next is [1.0, 0.043478260869565216, 0.4510268562401261, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9173401923925109, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21145597640845032, 0.21145597640845049, 0.3443340713030088], 
reward next is 0.6557, 
noisyNet noise sample is [array([0.6379996], dtype=float32), 0.6498402]. 
=============================================
[2019-03-27 05:13:37,963] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.7942685e-17 3.7233649e-09 1.3900819e-19 2.6340851e-16], sum to 1.0000
[2019-03-27 05:13:37,973] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9663
[2019-03-27 05:13:37,979] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7353763714021609, 6.9112, 6.9112, 168.912956510431, 625845.1367824596, 625845.1367824596, 189225.6106154411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2611800.0000, 
sim time next is 2612400.0000, 
raw observation next is [23.76666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.73220718714058, 6.9112, 6.9112, 168.912956510431, 623238.8685320641, 623238.8685320641, 188629.1622829176], 
processed observation next is [0.0, 0.21739130434782608, 0.32543443917851517, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6734233989519268, 0.0, 0.0, 0.8294399451523027, 0.17312190792557336, 0.17312190792557336, 0.2815360631088322], 
reward next is 0.7185, 
noisyNet noise sample is [array([-0.46962377], dtype=float32), -1.2884799]. 
=============================================
[2019-03-27 05:13:50,857] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0897449e-18 3.3683531e-08 5.9841383e-22 1.0473744e-17], sum to 1.0000
[2019-03-27 05:13:50,869] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6824
[2019-03-27 05:13:50,876] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7055632674951186, 6.911200000000001, 6.9112, 168.912956510431, 602438.267845867, 602438.2678458664, 183727.2489241094], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2835600.0000, 
sim time next is 2836200.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7072190966109732, 6.9112, 6.9112, 168.912956510431, 603852.4830929274, 603852.4830929274, 184027.0201129953], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6429501178182598, 0.0, 0.0, 0.8294399451523027, 0.1677368008591465, 0.1677368008591465, 0.27466719419850044], 
reward next is 0.7253, 
noisyNet noise sample is [array([-0.8797474], dtype=float32), 0.20853728]. 
=============================================
[2019-03-27 05:14:03,299] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.8082116e-20 2.7471787e-11 3.1706198e-22 7.5973789e-19], sum to 1.0000
[2019-03-27 05:14:03,307] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4430
[2019-03-27 05:14:03,312] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.83333333333334, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6324975510962105, 6.911199999999999, 6.9112, 168.912956510431, 548977.406688696, 548977.4066886967, 171194.8857681802], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3052200.0000, 
sim time next is 3052800.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6244317416969462, 6.911199999999999, 6.9112, 168.912956510431, 541706.0223128739, 541706.0223128746, 169909.2347394127], 
processed observation next is [1.0, 0.34782608695652173, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5419899288987148, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1504738950869094, 0.1504738950869096, 0.2535958727453921], 
reward next is 0.7464, 
noisyNet noise sample is [array([1.0785613], dtype=float32), -0.6513576]. 
=============================================
[2019-03-27 05:14:05,078] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9420470e-01 7.2967275e-12 5.7953321e-03 1.5138140e-15 3.5297895e-10], sum to 1.0000
[2019-03-27 05:14:05,090] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1328
[2019-03-27 05:14:05,093] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 1.0, 2.0, 0.2701882850315017, 1.0, 2.0, 0.2701882850315017, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 795432.5283982962, 795432.5283982962, 249982.7282535291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3068400.0000, 
sim time next is 3069000.0000, 
raw observation next is [23.0, 94.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8646553792237027, 6.9112, 6.9112, 168.912956510431, 739526.1912032064, 739526.1912032064, 215921.3065992094], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.8349455844191496, 0.0, 0.0, 0.8294399451523027, 0.20542394200089067, 0.20542394200089067, 0.32227060686449166], 
reward next is 0.6777, 
noisyNet noise sample is [array([-1.8339535], dtype=float32), -0.91402125]. 
=============================================
[2019-03-27 05:14:05,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[39.26086 ]
 [40.32371 ]
 [42.23408 ]
 [42.603344]
 [44.355206]], R is [[44.4499855 ]
 [44.63237762]
 [44.18605423]
 [43.74419403]
 [43.30675125]].
[2019-03-27 05:14:17,623] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 05:14:17,626] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:14:17,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:14:17,631] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:14:17,632] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:14:17,633] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:14:17,634] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:14:17,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:14:17,635] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:14:17,637] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:14:17,635] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:14:17,655] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run13
[2019-03-27 05:14:17,674] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run13
[2019-03-27 05:14:17,675] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run13
[2019-03-27 05:14:17,676] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run13
[2019-03-27 05:14:17,741] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run13
[2019-03-27 05:14:32,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.050375964]
[2019-03-27 05:14:32,463] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.43614463, 90.53612993499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6829071658373095, 6.911200000000001, 6.9112, 168.912956510431, 586611.2690547685, 586611.2690547679, 179703.9455333563]
[2019-03-27 05:14:32,464] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:14:32,468] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.5572085e-19 4.2299747e-11 7.6279462e-22 1.3994369e-17], sampled 0.6487819850590314
[2019-03-27 05:15:15,360] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.050375964]
[2019-03-27 05:15:15,360] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.6, 74.0, 1.0, 1.0, 0.5943651076225387, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129043002192, 830584.4465732421, 830584.4465732427, 199699.8329143159]
[2019-03-27 05:15:15,361] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:15:15,363] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.4978121e-18 1.1175263e-09 1.0761684e-21 6.5361780e-17], sampled 0.5128909315794979
[2019-03-27 05:15:19,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.050375964]
[2019-03-27 05:15:19,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.7, 58.0, 1.0, 2.0, 0.5632452833627545, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9781707891395537, 6.911200000000001, 6.9112, 168.9129563878642, 1574744.693511149, 1574744.693511148, 344603.4246508989]
[2019-03-27 05:15:19,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:15:19,562] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [7.5985831e-01 3.4619387e-09 2.4014162e-01 9.0175843e-13 3.1420229e-09], sampled 0.9136999417188914
[2019-03-27 05:15:44,919] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.050375964]
[2019-03-27 05:15:44,919] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 91.0, 1.0, 2.0, 0.6757427520560813, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 944354.6768828112, 944354.6768828105, 215696.0613666146]
[2019-03-27 05:15:44,920] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:15:44,925] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.7730970e-01 8.1996049e-10 2.2690244e-02 6.1861551e-13 3.0864289e-09], sampled 0.18309459943433393
[2019-03-27 05:15:44,926] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 944354.6768828112 W.
[2019-03-27 05:15:57,445] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.050375964]
[2019-03-27 05:15:57,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.5, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7352651520041561, 6.9112, 6.9112, 168.912956510431, 624812.9897712702, 624812.9897712702, 189196.6632975504]
[2019-03-27 05:15:57,448] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:15:57,450] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.2610430e-19 1.6009916e-11 3.2022719e-22 6.8206753e-18], sampled 0.3268280148769026
[2019-03-27 05:16:11,809] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6967.7319 3187605344.7014 2429.0000
[2019-03-27 05:16:11,849] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7239.4104 3108923077.8953 1970.0000
[2019-03-27 05:16:12,027] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7248.8801 3320659873.9778 2131.0000
[2019-03-27 05:16:12,057] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8010.7934 2939219322.8500 1361.0000
[2019-03-27 05:16:12,119] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7865.2961 2990930798.4745 1541.0000
[2019-03-27 05:16:13,132] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 300000, evaluation results [300000.0, 7248.880064493448, 3320659873.9777846, 2131.0, 7239.410367558138, 3108923077.8952684, 1970.0, 8010.793410242228, 2939219322.8499637, 1361.0, 6967.731932902896, 3187605344.701415, 2429.0, 7865.296143798732, 2990930798.474457, 1541.0]
[2019-03-27 05:16:25,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.1752520e-01 1.6994159e-10 7.8247482e-01 9.5948017e-16 3.0233354e-11], sum to 1.0000
[2019-03-27 05:16:25,254] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9542
[2019-03-27 05:16:25,263] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.66666666666667, 71.66666666666667, 1.0, 2.0, 0.27994484641452, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4842266371505978, 6.9112, 6.9112, 168.912956510431, 782389.6767051055, 782389.6767051055, 215553.5782535371], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3522000.0000, 
sim time next is 3522600.0000, 
raw observation next is [30.5, 72.5, 1.0, 2.0, 0.2793109146480601, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4830064079735234, 6.9112, 6.9112, 168.912956510431, 780617.3135819572, 780617.3135819572, 215353.891315716], 
processed observation next is [1.0, 0.782608695652174, 0.6445497630331753, 0.725, 1.0, 1.0, 0.13169989716633748, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.369520009723809, 0.0, 0.0, 0.8294399451523027, 0.2168381426616548, 0.2168381426616548, 0.32142371838166567], 
reward next is 0.6786, 
noisyNet noise sample is [array([0.93277323], dtype=float32), 0.3791224]. 
=============================================
[2019-03-27 05:16:33,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.2192039e-02 7.4001725e-09 9.0780789e-01 1.2538745e-13 2.9763751e-09], sum to 1.0000
[2019-03-27 05:16:33,514] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6159
[2019-03-27 05:16:33,517] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.33333333333334, 73.33333333333334, 1.0, 2.0, 0.8068994360920968, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983876586883482, 6.9112, 168.9124672618746, 2024729.488549908, 1973170.365818732, 410353.2245862418], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3661800.0000, 
sim time next is 3662400.0000, 
raw observation next is [29.66666666666667, 72.66666666666667, 1.0, 2.0, 0.8331776021594821, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987454150396049, 6.9112, 168.9124440564428, 2061507.766858989, 2007410.612225043, 416885.7743355262], 
processed observation next is [1.0, 0.391304347826087, 0.6050552922590839, 0.7266666666666667, 1.0, 1.0, 0.7990091592282917, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007625415039604899, 0.0, 0.8294374287686183, 0.5726410463497191, 0.5576140589514008, 0.6222175736351138], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4223862], dtype=float32), -0.8220265]. 
=============================================
[2019-03-27 05:16:39,965] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.0590567e-02 1.8308024e-08 9.4940948e-01 6.1696653e-14 1.8743615e-08], sum to 1.0000
[2019-03-27 05:16:39,975] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6090
[2019-03-27 05:16:39,980] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 64.5, 1.0, 2.0, 0.5725266536555337, 1.0, 1.0, 0.5725266536555337, 1.0, 2.0, 0.9892423322423767, 6.911200000000001, 6.9112, 170.5573041426782, 2401919.693135041, 2401919.693135041, 467862.8814163437], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3753000.0000, 
sim time next is 3753600.0000, 
raw observation next is [31.0, 65.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.088374519264676, 6.9112, 168.9121017859047, 2420675.540525664, 2294982.474711669, 476248.4829863265], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.65, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.017717451926467565, 0.0, 0.8294357480635839, 0.67240987236824, 0.6374951318643526, 0.7108186313228754], 
reward next is 0.0000, 
noisyNet noise sample is [array([3.2967708], dtype=float32), -0.9667859]. 
=============================================
[2019-03-27 05:16:48,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.1110903e-17 2.5542597e-09 3.7346655e-21 8.8421836e-17], sum to 1.0000
[2019-03-27 05:16:48,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5550
[2019-03-27 05:16:48,249] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666667, 85.66666666666667, 1.0, 1.0, 0.5940940542614059, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128920429063, 830205.5200932891, 830205.5200932897, 199649.7164022147], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3889200.0000, 
sim time next is 3889800.0000, 
raw observation next is [28.5, 86.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.920120252889364, 6.9112, 168.9127194810247, 835400.8928599448, 829072.5673291406, 254827.9293354], 
processed observation next is [0.0, 0.0, 0.5497630331753555, 0.865, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.0008920252889364378, 0.0, 0.8294387812294053, 0.2320558035722069, 0.23029793536920573, 0.38034019303791045], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81951165], dtype=float32), 0.29680273]. 
=============================================
[2019-03-27 05:16:49,036] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.6640912e-19 2.0276111e-10 4.2051504e-22 2.4820463e-17], sum to 1.0000
[2019-03-27 05:16:49,043] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4911
[2019-03-27 05:16:49,046] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9600106098544013, 6.911199999999999, 6.9112, 168.912956510431, 781678.0245270559, 781678.0245270566, 237378.0292224327], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3907800.0000, 
sim time next is 3908400.0000, 
raw observation next is [27.0, 90.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9505121876043368, 6.911199999999999, 6.9112, 168.912956510431, 775346.7365393053, 775346.736539306, 235105.8628949598], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.9066666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9396490092735814, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21537409348314035, 0.21537409348314054, 0.35090427297755195], 
reward next is 0.6491, 
noisyNet noise sample is [array([0.30343282], dtype=float32), 1.8155195]. 
=============================================
[2019-03-27 05:16:50,591] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999416e-01 3.8039023e-14 5.8043493e-06 1.6953911e-16 5.6669469e-13], sum to 1.0000
[2019-03-27 05:16:50,598] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8831
[2019-03-27 05:16:50,605] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1114843.9868089 W.
[2019-03-27 05:16:50,611] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.16666666666667, 59.33333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.31424674834002, 6.9112, 168.9107451790863, 1114843.9868089, 828912.4950715939, 254812.7066779155], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3931800.0000, 
sim time next is 3932400.0000, 
raw observation next is [34.33333333333334, 58.66666666666667, 1.0, 1.0, 0.2148147652362996, 1.0, 1.0, 0.2148147652362996, 1.0, 2.0, 0.373062206887029, 6.9112, 6.9112, 170.5573041426782, 900592.6639025536, 900592.6639025536, 274095.2702486845], 
processed observation next is [0.0, 0.5217391304347826, 0.8262243285939973, 0.5866666666666667, 1.0, 0.5, 0.05399369305578265, 1.0, 0.5, 0.05399369305578265, 1.0, 1.0, 0.23544171571588904, 0.0, 0.0, 0.8375144448122397, 0.25016462886182045, 0.25016462886182045, 0.40909741828161866], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3083489], dtype=float32), -0.08077326]. 
=============================================
[2019-03-27 05:16:53,792] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.1335277e-01 5.9170513e-10 8.8664728e-01 1.3902817e-14 2.0245821e-09], sum to 1.0000
[2019-03-27 05:16:53,797] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3064
[2019-03-27 05:16:53,804] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 84.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.944485455303299, 6.9112, 168.9075041784667, 2187281.694898824, 1454257.091990222, 311352.3057139782], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4004400.0000, 
sim time next is 4005000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.7828238122643452, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.99229591413994, 6.9112, 168.9116329325844, 1991034.963050247, 1933503.181267787, 404155.6632672823], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.84, 1.0, 1.0, 0.7383419424871628, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00810959141399401, 0.0, 0.8294334457791394, 0.5530652675139575, 0.5370842170188297, 0.6032174078616154], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.0055141], dtype=float32), 0.42192748]. 
=============================================
[2019-03-27 05:16:53,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[27.343277]
 [28.593235]
 [27.48391 ]
 [26.624569]
 [26.374687]], R is [[27.01844406]
 [26.7482605 ]
 [27.04928398]
 [27.31386375]
 [27.56072235]].
[2019-03-27 05:16:53,839] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2938374e-03 1.9248782e-08 9.9370617e-01 1.2518010e-13 3.4031981e-08], sum to 1.0000
[2019-03-27 05:16:53,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9450
[2019-03-27 05:16:53,855] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8922242332164992, 1.0, 2.0, 0.8922242332164992, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2495524.162507532, 2495524.162507532, 467262.5509384479], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4014000.0000, 
sim time next is 4014600.0000, 
raw observation next is [31.33333333333334, 65.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.190203000001713, 6.9112, 168.911149829427, 2489422.247664428, 2291490.034012603, 475870.7778414086], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.655, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.027900300000171276, 0.0, 0.8294310735214708, 0.6915061799067855, 0.6365250094479453, 0.7102548923006099], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.433057], dtype=float32), -0.034284525]. 
=============================================
[2019-03-27 05:16:57,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9924493e-01 2.0042981e-14 7.5505691e-04 6.5160812e-19 9.9177990e-14], sum to 1.0000
[2019-03-27 05:16:57,234] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1336
[2019-03-27 05:16:57,241] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9535024000577459, 6.9112, 6.9112, 168.912956510431, 774440.6378305204, 774440.6378305204, 235675.9487002518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4042800.0000, 
sim time next is 4043400.0000, 
raw observation next is [28.83333333333334, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9482403409793286, 6.911200000000001, 6.9112, 168.912956510431, 771456.3617024589, 771456.3617024582, 234451.1935845846], 
processed observation next is [1.0, 0.8260869565217391, 0.5655608214849924, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9368784646089372, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21429343380623858, 0.2142934338062384, 0.3499271546038576], 
reward next is 0.6501, 
noisyNet noise sample is [array([1.1050863], dtype=float32), 0.3940335]. 
=============================================
[2019-03-27 05:17:04,764] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [3.8492560e-01 2.7089092e-10 6.1507446e-01 9.9364605e-15 2.2552906e-09], sum to 1.0000
[2019-03-27 05:17:04,774] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9676
[2019-03-27 05:17:04,780] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333333, 83.16666666666667, 1.0, 2.0, 0.4788109766907295, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8315363213021488, 6.911199999999999, 6.9112, 168.912956510431, 1338530.896345231, 1338530.896345231, 296976.1586407426], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4173000.0000, 
sim time next is 4173600.0000, 
raw observation next is [30.66666666666667, 82.33333333333334, 1.0, 2.0, 0.5169661029165088, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977991574632689, 6.911200000000001, 6.9112, 168.912956510431, 1445267.339993035, 1445267.339993034, 317534.9194920098], 
processed observation next is [1.0, 0.30434782608695654, 0.6524486571879939, 0.8233333333333335, 1.0, 1.0, 0.41803144929699854, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8753648261747181, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.40146314999806526, 0.401463149998065, 0.4739327156597161], 
reward next is 0.5261, 
noisyNet noise sample is [array([0.47348002], dtype=float32), -0.9718687]. 
=============================================
[2019-03-27 05:17:05,992] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.9834563e-04 2.0211842e-06 9.9979967e-01 1.2359970e-11 1.1791082e-08], sum to 1.0000
[2019-03-27 05:17:05,999] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4645
[2019-03-27 05:17:06,007] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 3294390.925065438 W.
[2019-03-27 05:17:06,011] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.66666666666667, 51.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.448113777526657, 6.9112, 170.5573041426782, 3294390.925065438, 2909777.745967003, 550739.9135933972], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4202400.0000, 
sim time next is 4203000.0000, 
raw observation next is [36.5, 51.5, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 7.566546261030233, 6.9112, 170.5573041426782, 3379327.763633538, 2909876.579076076, 550040.7675642428], 
processed observation next is [1.0, 0.6521739130434783, 0.9289099526066351, 0.515, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.2195121951219512, 0.06553462610302327, 0.0, 0.8375144448122397, 0.9387021565648717, 0.8082990497433544, 0.8209563694988699], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1919628], dtype=float32), 0.4070819]. 
=============================================
[2019-03-27 05:17:06,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[11.683579]
 [12.761563]
 [12.925621]
 [13.844188]
 [13.380116]], R is [[10.82199669]
 [10.71377659]
 [10.60663891]
 [10.5005722 ]
 [10.39556694]].
[2019-03-27 05:17:07,678] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9869567e-01 2.0068342e-13 1.3043127e-03 1.5907544e-18 1.3283815e-12], sum to 1.0000
[2019-03-27 05:17:07,684] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4355
[2019-03-27 05:17:07,689] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.33333333333334, 67.33333333333333, 1.0, 2.0, 0.3088232156557649, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5363237961960176, 6.9112, 6.9112, 168.9129564832275, 863131.7179210756, 863131.7179210756, 224853.7962902476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4218000.0000, 
sim time next is 4218600.0000, 
raw observation next is [33.16666666666666, 69.16666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.178612125622293, 6.9112, 168.911378373871, 1018584.536124917, 828874.9430473741, 254813.7509884708], 
processed observation next is [1.0, 0.8260869565217391, 0.7709320695102682, 0.6916666666666668, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.026741212562229322, 0.0, 0.829432195779319, 0.28294014892358804, 0.2302430397353817, 0.3803190313260758], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.32601044], dtype=float32), -1.5738281]. 
=============================================
[2019-03-27 05:17:07,897] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-27 05:17:07,898] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:17:07,899] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:17:07,900] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:17:07,900] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:17:07,901] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:17:07,902] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:17:07,902] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:17:07,904] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:17:07,904] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:17:07,906] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:17:07,921] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run14
[2019-03-27 05:17:07,922] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run14
[2019-03-27 05:17:07,922] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run14
[2019-03-27 05:17:07,980] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run14
[2019-03-27 05:17:07,981] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run14
[2019-03-27 05:17:23,479] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:17:23,482] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.7, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6205615378641984, 6.911199999999999, 6.9112, 168.912956510431, 537152.0915332764, 537152.091533277, 169311.3640357101]
[2019-03-27 05:17:23,484] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:17:23,487] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999988e-01 9.2514506e-16 8.5816275e-08 3.6156799e-19 1.0384565e-14], sampled 0.28022656037329596
[2019-03-27 05:17:59,450] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:17:59,451] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.54172839666667, 76.66368606166667, 1.0, 2.0, 0.6722546665850865, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005973551126365, 6.9112, 168.912316049949, 1836303.964919299, 1769068.600830962, 378748.2808070102]
[2019-03-27 05:17:59,453] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:17:59,457] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [3.4170112e-01 3.7139967e-09 6.5829891e-01 1.3626956e-13 4.7837703e-09], sampled 0.04795460260055706
[2019-03-27 05:17:59,457] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1836303.964919299 W.
[2019-03-27 05:18:05,855] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:18:05,858] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.83333333333334, 48.5, 1.0, 2.0, 0.9979198455192383, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.004777919389333, 6.9112, 168.9123249749333, 2292090.479526096, 2225703.331018546, 462701.2398000104]
[2019-03-27 05:18:05,859] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:18:05,860] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.7017315e-01 1.2215867e-10 8.2982683e-01 4.5714421e-16 1.2737356e-10], sampled 0.3146978008771377
[2019-03-27 05:18:17,446] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:18:17,447] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.57884538333333, 78.33823529, 1.0, 2.0, 0.6218242194402772, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.929211993010425, 6.9112, 168.9128428016328, 1738656.282637823, 1725877.963473385, 369942.4885371515]
[2019-03-27 05:18:17,448] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:18:17,454] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.2954332e-01 2.1141719e-09 7.0456654e-02 2.0497743e-13 5.6599330e-09], sampled 0.31140427494663436
[2019-03-27 05:18:17,455] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1738656.282637823 W.
[2019-03-27 05:18:25,308] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:18:25,308] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.79268632, 80.31353179, 1.0, 2.0, 0.6884174669290257, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 962075.6924160682, 962075.6924160676, 218377.0224294009]
[2019-03-27 05:18:25,309] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:18:25,311] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.7602243e-01 4.7056461e-09 2.2397754e-01 2.3212316e-13 1.0164321e-08], sampled 0.5570356936616783
[2019-03-27 05:18:25,312] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 962075.6924160682 W.
[2019-03-27 05:18:39,662] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:18:39,663] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.48068781166666, 65.15686651166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001770230481019, 6.9112, 6.9112, 168.9129072567897, 807258.9107510088, 807258.9107510088, 247494.6056911396]
[2019-03-27 05:18:39,666] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:18:39,668] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.0613261e-17 7.3192390e-09 7.8859845e-21 3.6797067e-16], sampled 0.5978549578760537
[2019-03-27 05:18:57,846] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.046934366]
[2019-03-27 05:18:57,846] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.90539242666667, 89.34030835333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6539548457120158, 6.911200000000001, 6.9112, 168.912956510431, 565440.7458658732, 565440.7458658725, 174737.3854683034]
[2019-03-27 05:18:57,848] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:18:57,850] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.4801307e-16 4.0778612e-08 1.7673660e-19 4.8364980e-15], sampled 0.06596884360227895
[2019-03-27 05:19:02,429] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7105.0632 3327147537.0664 2073.0000
[2019-03-27 05:19:02,436] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7070.7355 3120703921.3085 1810.0000
[2019-03-27 05:19:02,593] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7892.4115 2947249560.5426 1248.0000
[2019-03-27 05:19:02,700] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6838.3369 3197528096.6624 2290.0000
[2019-03-27 05:19:02,703] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7717.6632 2999013881.5317 1417.0000
[2019-03-27 05:19:03,719] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 325000, evaluation results [325000.0, 7105.063179263193, 3327147537.0663996, 2073.0, 7070.735509849475, 3120703921.3085055, 1810.0, 7892.411523451804, 2947249560.542586, 1248.0, 6838.336854196265, 3197528096.662403, 2290.0, 7717.663205789654, 2999013881.5316873, 1417.0]
[2019-03-27 05:19:04,443] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.5198562e-02 1.9405289e-07 9.6480125e-01 3.1520227e-12 4.4374836e-08], sum to 1.0000
[2019-03-27 05:19:04,452] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5036
[2019-03-27 05:19:04,460] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.66666666666666, 1.0, 2.0, 0.5718853922407184, 0.0, 2.0, 0.0, 1.0, 2.0, 0.990969422047645, 6.911200000000001, 6.9112, 168.9129181289592, 1598919.266360036, 1598919.266360035, 349437.3298475863], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4243800.0000, 
sim time next is 4244400.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.5550553371361432, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9600364364469431, 6.911199999999999, 6.9112, 168.9129565008471, 1551830.160791701, 1551830.160791702, 338824.2297069239], 
processed observation next is [1.0, 0.13043478260869565, 0.6208530805687204, 0.75, 1.0, 1.0, 0.4639220929351123, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.951263946886516, -8.881784197001253e-17, 0.0, 0.8294399451052413, 0.43106393355325023, 0.43106393355325057, 0.5057078055327222], 
reward next is 0.4943, 
noisyNet noise sample is [array([-0.89070696], dtype=float32), -0.14236869]. 
=============================================
[2019-03-27 05:19:17,525] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 2.9273673e-16 2.3127451e-07 2.7682100e-20 2.5241563e-15], sum to 1.0000
[2019-03-27 05:19:17,534] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7429
[2019-03-27 05:19:17,539] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 71.0, 1.0, 1.0, 0.3089978026210164, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5366269960178677, 6.911200000000001, 6.9112, 168.9128673321961, 863619.8705668091, 863619.8705668084, 224900.6516451815], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4464600.0000, 
sim time next is 4465200.0000, 
raw observation next is [32.0, 71.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.05950440675318, 6.9112, 168.9119797485041, 934053.6113994143, 828841.9694089646, 254812.837167371], 
processed observation next is [0.0, 0.6956521739130435, 0.7156398104265403, 0.71, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.014830440675318001, 0.0, 0.8294351488040781, 0.25945933649983727, 0.23023388039137907, 0.3803176674139866], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13696416], dtype=float32), -2.180466]. 
=============================================
[2019-03-27 05:19:18,715] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.9048733e-20 1.0211189e-11 6.5418673e-24 5.3373953e-19], sum to 1.0000
[2019-03-27 05:19:18,726] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8865
[2019-03-27 05:19:18,729] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8623328284837423, 6.9112, 6.9112, 168.912956510431, 716011.1047529984, 716011.1047529984, 215010.2578607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4491600.0000, 
sim time next is 4492200.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8586713423821313, 6.911199999999999, 6.9112, 168.912956510431, 713455.1117163408, 713455.1117163413, 214212.6898034595], 
processed observation next is [0.0, 1.0, 0.4391785150078992, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8276479785147942, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19818197547676134, 0.19818197547676147, 0.3197204325424769], 
reward next is 0.6803, 
noisyNet noise sample is [array([1.0286082], dtype=float32), 0.87746847]. 
=============================================
[2019-03-27 05:19:31,816] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.2546360e-02 4.4037887e-10 9.4745368e-01 9.7714932e-15 3.2098844e-09], sum to 1.0000
[2019-03-27 05:19:31,824] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2528
[2019-03-27 05:19:31,828] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.6077997034519552, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.924309746524135, 6.9112, 168.9127158028702, 1699411.533474367, 1690111.041341076, 366620.2071788646], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4710000.0000, 
sim time next is 4710600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.5437284865197132, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9314037791464638, 6.911200000000001, 6.9112, 168.9129458198346, 1520139.743652501, 1520139.7436525, 330293.5952950686], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.4502752849635098, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9163460721298339, 8.881784197001253e-17, 0.0, 0.8294398926565801, 0.42226103990347247, 0.4222610399034722, 0.492975515365774], 
reward next is 0.5070, 
noisyNet noise sample is [array([-0.6785982], dtype=float32), 1.1261039]. 
=============================================
[2019-03-27 05:19:32,595] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.4478533e-04 8.2032020e-10 9.9975520e-01 2.7092218e-15 3.9027628e-10], sum to 1.0000
[2019-03-27 05:19:32,605] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3100
[2019-03-27 05:19:32,615] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2550717.122912471 W.
[2019-03-27 05:19:32,619] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.9119372397552058, 1.0, 1.0, 0.9119372397552058, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2550717.122912471, 2550717.12291247, 478045.8835763761], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4726800.0000, 
sim time next is 4727400.0000, 
raw observation next is [30.83333333333334, 70.0, 1.0, 2.0, 0.3883785522532301, 1.0, 2.0, 0.3883785522532301, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1085589.665038074, 1085589.665038074, 269245.4485495866], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.7, 1.0, 1.0, 0.263106689461723, 1.0, 1.0, 0.263106689461723, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3015526847327983, 0.3015526847327983, 0.4018588784322188], 
reward next is 0.5981, 
noisyNet noise sample is [array([-0.35230008], dtype=float32), -0.50203323]. 
=============================================
[2019-03-27 05:19:37,729] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.8273353e-03 4.5832246e-10 9.9317259e-01 9.5191299e-16 8.4032881e-10], sum to 1.0000
[2019-03-27 05:19:37,734] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4407
[2019-03-27 05:19:37,740] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.16666666666667, 65.5, 1.0, 2.0, 0.534532896242739, 1.0, 1.0, 0.534532896242739, 1.0, 2.0, 0.9262186438992224, 6.911199999999999, 6.9112, 170.5573041426782, 2242381.56916736, 2242381.56916736, 439442.2500490739], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4795800.0000, 
sim time next is 4796400.0000, 
raw observation next is [31.33333333333334, 65.0, 1.0, 2.0, 0.6211223567902299, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.955621620447845, 6.9112, 168.912651491463, 1736692.230143488, 1705178.060631238, 368948.7407248291], 
processed observation next is [1.0, 0.5217391304347826, 0.6840442338072673, 0.65, 1.0, 1.0, 0.5435209117954577, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0044421620447844925, 0.0, 0.8294384473695315, 0.4824145083731911, 0.4736605723975661, 0.5506697622758643], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.26198328], dtype=float32), 1.799975]. 
=============================================
[2019-03-27 05:19:37,824] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.0837024e-03 8.2640943e-09 9.9691629e-01 9.0967767e-14 2.8808989e-09], sum to 1.0000
[2019-03-27 05:19:37,834] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4480
[2019-03-27 05:19:37,839] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.83333333333334, 66.66666666666667, 1.0, 2.0, 0.2600475069459516, 1.0, 1.0, 0.2600475069459516, 1.0, 2.0, 0.4484268652128231, 6.9112, 6.9112, 170.5573041426782, 1090323.502115943, 1090323.502115943, 288702.9257676965], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4813800.0000, 
sim time next is 4814400.0000, 
raw observation next is [30.66666666666667, 67.33333333333334, 1.0, 2.0, 0.2491322901479257, 0.0, 1.0, 0.0, 1.0, 2.0, 0.426750763533337, 6.911199999999999, 6.9112, 168.9129564473708, 696246.5418769432, 696246.5418769438, 206570.6032594115], 
processed observation next is [1.0, 0.7391304347826086, 0.6524486571879939, 0.6733333333333335, 1.0, 1.0, 0.09534010861195867, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.3009155652845573, -8.881784197001253e-17, 0.0, 0.8294399448426482, 0.19340181718803978, 0.19340181718803995, 0.3083143332230022], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.1213496], dtype=float32), 0.51187736]. 
=============================================
[2019-03-27 05:19:40,479] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.1033378e-01 3.6355496e-09 4.8966631e-01 3.5918368e-13 9.2996153e-09], sum to 1.0000
[2019-03-27 05:19:40,483] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7813
[2019-03-27 05:19:40,491] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.3309886529206449, 1.0, 1.0, 0.3309886529206449, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 925105.1175834133, 925105.1175834133, 256137.5027595329], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4854600.0000, 
sim time next is 4855200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.3271666218638929, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5530176803891509, 6.9112, 6.9112, 168.912956510431, 914421.8758995278, 914421.8758995278, 229350.2302697616], 
processed observation next is [1.0, 0.17391304347826086, 0.4786729857819906, 0.84, 1.0, 1.0, 0.18935737573963, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.45489961023067177, 0.0, 0.0, 0.8294399451523027, 0.25400607663875774, 0.25400607663875774, 0.34231377652203226], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7578188], dtype=float32), -0.19486918]. 
=============================================
[2019-03-27 05:19:58,482] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-27 05:19:58,485] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:19:58,486] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:19:58,486] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:19:58,488] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:19:58,489] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:19:58,490] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:19:58,490] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:19:58,488] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:19:58,492] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:19:58,494] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:19:58,514] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run15
[2019-03-27 05:19:58,515] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run15
[2019-03-27 05:19:58,515] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run15
[2019-03-27 05:19:58,515] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run15
[2019-03-27 05:19:58,584] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run15
[2019-03-27 05:20:00,327] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:20:00,327] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.53333333333333, 66.66666666666667, 1.0, 2.0, 0.8859006549695817, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1238222.882295279, 1238222.882295278, 266086.1646517927]
[2019-03-27 05:20:00,330] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:20:00,332] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2058845e-01 2.2715296e-10 2.7941155e-01 7.0809806e-14 1.2357663e-09], sampled 0.7426082910579382
[2019-03-27 05:20:19,407] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:20:19,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.6, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7326464632503131, 6.9112, 6.9112, 168.912956510431, 620818.23157765, 620818.23157765, 188684.3714011842]
[2019-03-27 05:20:19,410] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:20:19,413] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.8009813e-21 1.1761281e-11 7.2065757e-24 2.7121549e-19], sampled 0.2646607452496701
[2019-03-27 05:20:20,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:20:20,553] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.7, 47.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5409021503866794, 6.9112, 6.9112, 168.912956510431, 477165.1742673734, 477165.1742673734, 157391.3153584491]
[2019-03-27 05:20:20,553] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:20:20,557] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.9124648e-20 3.2583197e-11 1.2771866e-22 2.7013043e-18], sampled 0.321704402896686
[2019-03-27 05:20:31,197] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:20:31,201] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.56666666666667, 71.33333333333334, 1.0, 2.0, 0.7345591429544613, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1084063.551011374, 1084063.551011373, 236128.2400109569]
[2019-03-27 05:20:31,202] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:20:31,205] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.76053035e-01 3.18445548e-10 1.23946995e-01 1.25416658e-13
 1.75019832e-09], sampled 0.028474594487766902
[2019-03-27 05:20:31,206] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1084063.551011374 W.
[2019-03-27 05:20:55,716] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:20:55,720] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.25, 47.00000000000001, 1.0, 2.0, 0.7491064086181546, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989390912171286, 6.9112, 168.9124281666939, 1943848.26726566, 1888377.116556893, 396278.4454574725]
[2019-03-27 05:20:55,722] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:20:55,727] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9958223e-01 1.6198600e-15 4.1773604e-04 6.4704142e-20 1.8743929e-14], sampled 0.0017840745741759534
[2019-03-27 05:20:55,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1943848.26726566 W.
[2019-03-27 05:21:25,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:21:25,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.76666666666667, 90.66666666666667, 1.0, 1.0, 0.6193747508131993, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9128573619007, 865547.9471451874, 865547.9471451868, 204405.1089544303]
[2019-03-27 05:21:25,559] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:21:25,563] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9997473e-01 3.9248295e-14 2.5233598e-05 2.1261786e-17 6.3812595e-13], sampled 0.5072589632617899
[2019-03-27 05:21:41,952] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:21:41,955] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.25, 76.0, 1.0, 2.0, 0.7032791320298881, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.991054727731123, 6.9112, 168.9124149979763, 1879717.47175678, 1823065.961134487, 385923.3851349159]
[2019-03-27 05:21:41,955] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:21:41,957] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9532449e-01 3.2680065e-13 4.6754940e-03 6.5106830e-17 5.1685635e-12], sampled 0.2660192237112039
[2019-03-27 05:21:41,959] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1879717.47175678 W.
[2019-03-27 05:21:49,296] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:21:49,298] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.76633471, 68.7076596, 1.0, 2.0, 0.8952645224063414, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1251318.467431238, 1251318.467431238, 268639.6788458591]
[2019-03-27 05:21:49,300] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:21:49,301] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.7635308e-01 1.0375730e-09 5.2364695e-01 2.9170747e-13 3.8895354e-09], sampled 0.693549851350413
[2019-03-27 05:21:51,180] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.051121708]
[2019-03-27 05:21:51,182] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.25, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6266648264744074, 6.911199999999999, 6.9112, 168.912956510431, 544884.8392391345, 544884.839239135, 170245.3864622372]
[2019-03-27 05:21:51,183] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:21:51,186] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 8.4592369e-20 7.0888080e-11 2.6259105e-22 5.7402550e-18], sampled 0.404711190743942
[2019-03-27 05:21:52,000] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7209.3278 3110160787.9604 1960.0000
[2019-03-27 05:21:52,184] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7991.0715 2940077566.2744 1358.0000
[2019-03-27 05:21:52,244] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7839.1890 2991625075.4884 1527.0000
[2019-03-27 05:21:52,357] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7228.2886 3321426938.2950 2123.0000
[2019-03-27 05:21:52,421] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6911.3103 3189148152.1774 2419.0000
[2019-03-27 05:21:53,438] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 350000, evaluation results [350000.0, 7228.2885964919815, 3321426938.294958, 2123.0, 7209.327809017711, 3110160787.960432, 1960.0, 7991.071473329679, 2940077566.27435, 1358.0, 6911.3102913269395, 3189148152.1774445, 2419.0, 7839.189034791122, 2991625075.488414, 1527.0]
[2019-03-27 05:22:08,979] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4678050e-01 1.5274568e-12 5.3219467e-02 1.8351866e-16 2.3570887e-11], sum to 1.0000
[2019-03-27 05:22:08,984] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-27 05:22:08,989] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.35, 83.0, 1.0, 1.0, 0.1987943514050078, 1.0, 1.0, 0.1987943514050078, 1.0, 2.0, 0.3452400460938877, 6.9112, 6.9112, 170.5573041426782, 833402.3424075125, 833402.3424075125, 269510.9386079259], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5441400.0000, 
sim time next is 5442000.0000, 
raw observation next is [29.26666666666667, 83.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.946643779035199, 6.9112, 168.9125920215274, 853955.7100172333, 828810.7275481637, 254812.183665248], 
processed observation next is [1.0, 1.0, 0.5860979462875199, 0.8366666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.003544377903519891, 0.0, 0.8294381553449222, 0.23720991944923148, 0.23022520209671216, 0.3803166920376836], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.42735317], dtype=float32), 0.97322464]. 
=============================================
[2019-03-27 05:22:08,998] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[34.41442 ]
 [36.549854]
 [35.05644 ]
 [33.16319 ]
 [36.186367]], R is [[35.75222397]
 [35.9924469 ]
 [35.91543961]
 [35.55628586]
 [35.20072174]].
[2019-03-27 05:22:09,508] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9908447e-01 1.3656139e-13 9.1555837e-04 1.0628937e-18 1.3126821e-13], sum to 1.0000
[2019-03-27 05:22:09,520] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1061
[2019-03-27 05:22:09,529] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 887105.1874250644 W.
[2019-03-27 05:22:09,532] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.26666666666667, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.993352431842972, 6.9112, 168.9122830801552, 887105.1874250644, 828823.6571676949, 254812.1848729696], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5442000.0000, 
sim time next is 5442600.0000, 
raw observation next is [29.18333333333334, 84.33333333333334, 1.0, 1.0, 0.2989481451761015, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5191740645085533, 6.9112, 6.9112, 168.9128896119406, 835520.973002128, 835520.973002128, 221619.3364003557], 
processed observation next is [1.0, 1.0, 0.5821484992101109, 0.8433333333333334, 1.0, 0.5, 0.15535921105554398, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4136269079372601, 0.0, 0.0, 0.8294396166500886, 0.23208915916725775, 0.23208915916725775, 0.3307751289557548], 
reward next is 0.6692, 
noisyNet noise sample is [array([0.9403174], dtype=float32), 0.23027544]. 
=============================================
[2019-03-27 05:22:13,818] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999940e-01 1.2050102e-16 5.3688825e-07 1.5707145e-21 9.5625763e-16], sum to 1.0000
[2019-03-27 05:22:13,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6188
[2019-03-27 05:22:13,831] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9431852040525873, 6.911199999999999, 6.9112, 168.912956510431, 768995.7409661268, 768995.7409661275, 233299.025647657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5526000.0000, 
sim time next is 5526600.0000, 
raw observation next is [27.53333333333334, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9413913528740727, 6.9112, 6.9112, 168.912956510431, 767906.2771858174, 767906.2771858174, 232880.9396680853], 
processed observation next is [1.0, 1.0, 0.5039494470774094, 0.875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9285260400903326, 0.0, 0.0, 0.8294399451523027, 0.2133072992182826, 0.2133072992182826, 0.34758349204191835], 
reward next is 0.6524, 
noisyNet noise sample is [array([-1.1350553], dtype=float32), -0.6352634]. 
=============================================
[2019-03-27 05:22:20,873] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.8571735e-20 5.6004510e-11 1.1602728e-22 2.9823494e-17], sum to 1.0000
[2019-03-27 05:22:20,884] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8570
[2019-03-27 05:22:20,890] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.927484491037817, 6.911199999999999, 6.9112, 168.912956510431, 757301.8589368007, 757301.8589368014, 229565.6755480697], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5650200.0000, 
sim time next is 5650800.0000, 
raw observation next is [30.16666666666666, 71.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9298575944844938, 6.911199999999999, 6.9112, 168.912956510431, 758688.2026011939, 758688.2026011946, 230108.2073899057], 
processed observation next is [0.0, 0.391304347826087, 0.6287519747235385, 0.7133333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.914460481078651, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2107467229447761, 0.21074672294477628, 0.34344508565657567], 
reward next is 0.6566, 
noisyNet noise sample is [array([0.7760648], dtype=float32), 0.7685393]. 
=============================================
[2019-03-27 05:22:27,064] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.5676922e-23 9.9375870e-14 1.5260970e-24 2.6072193e-19], sum to 1.0000
[2019-03-27 05:22:27,074] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2046
[2019-03-27 05:22:27,081] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8850626126749938, 6.9112, 6.9112, 168.912956510431, 729656.527181369, 729656.527181369, 219953.3970535265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5732400.0000, 
sim time next is 5733000.0000, 
raw observation next is [29.25, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8857860959135617, 6.911200000000001, 6.9112, 168.912956510431, 730447.4574323051, 730447.4574323044, 220125.8884213976], 
processed observation next is [0.0, 0.34782608695652173, 0.5853080568720379, 0.72, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8607147511140997, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20290207150897363, 0.20290207150897344, 0.32854610212148894], 
reward next is 0.6715, 
noisyNet noise sample is [array([1.5285426], dtype=float32), -0.22656478]. 
=============================================
[2019-03-27 05:22:27,094] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[68.31752]
 [68.29188]
 [68.24065]
 [68.20726]
 [68.19158]], R is [[68.3195343 ]
 [68.30805206]
 [68.29720306]
 [68.28491211]
 [68.27300262]].
[2019-03-27 05:22:28,444] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.3514598e-23 1.7500348e-14 7.7184316e-27 6.1051917e-22], sum to 1.0000
[2019-03-27 05:22:28,453] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0652
[2019-03-27 05:22:28,463] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.63333333333333, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9341271473264897, 6.911200000000001, 6.9112, 168.912956510431, 764493.2969627016, 764493.296962701, 231239.7327602437], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5780400.0000, 
sim time next is 5781000.0000, 
raw observation next is [27.56666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9322410246163694, 6.9112, 6.9112, 168.912956510431, 763144.8483131971, 763144.8483131971, 230794.3473788658], 
processed observation next is [0.0, 0.9130434782608695, 0.505529225908373, 0.8566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9173671031906943, 0.0, 0.0, 0.8294399451523027, 0.2119846800869992, 0.2119846800869992, 0.344469175192337], 
reward next is 0.6555, 
noisyNet noise sample is [array([-0.40589976], dtype=float32), -0.3692116]. 
=============================================
[2019-03-27 05:22:28,472] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.47267 ]
 [73.48548 ]
 [73.48974 ]
 [73.493416]
 [73.460106]], R is [[73.38559723]
 [73.30661011]
 [73.22854614]
 [73.15142822]
 [73.07472992]].
[2019-03-27 05:22:29,701] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.5936877e-22 2.9222515e-13 3.0908871e-26 2.0321538e-20], sum to 1.0000
[2019-03-27 05:22:29,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0867
[2019-03-27 05:22:29,713] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9197641190571993, 6.911200000000001, 6.9112, 168.912956510431, 754212.5270855913, 754212.5270855908, 227870.0618582219], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5784000.0000, 
sim time next is 5784600.0000, 
raw observation next is [27.25, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9177291673869691, 6.9112, 6.9112, 168.912956510431, 752833.9174064738, 752833.9174064738, 227400.146678038], 
processed observation next is [0.0, 0.9565217391304348, 0.490521327014218, 0.8683333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8996697163255719, 0.0, 0.0, 0.8294399451523027, 0.2091205326129094, 0.2091205326129094, 0.33940320399707163], 
reward next is 0.6606, 
noisyNet noise sample is [array([0.99679774], dtype=float32), 0.60350096]. 
=============================================
[2019-03-27 05:22:29,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999988e-01 1.5638302e-18 7.7605030e-08 5.3409917e-22 3.3017010e-17], sum to 1.0000
[2019-03-27 05:22:29,899] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2224
[2019-03-27 05:22:29,906] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.83333333333334, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9107215965492508, 6.9112, 6.9112, 168.912956510431, 748357.9406547945, 748357.9406547945, 225800.6717432599], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5794800.0000, 
sim time next is 5795400.0000, 
raw observation next is [26.81666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9090737144306846, 6.911200000000001, 6.9112, 168.912956510431, 747190.0156496192, 747190.0156496185, 225421.4610460488], 
processed observation next is [1.0, 0.043478260869565216, 0.46998420221169057, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8891142858910789, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20755278212489423, 0.20755278212489403, 0.33644994185977434], 
reward next is 0.6636, 
noisyNet noise sample is [array([-0.8251354], dtype=float32), 0.6625254]. 
=============================================
[2019-03-27 05:22:30,552] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9885714e-01 2.5948663e-13 1.1428376e-03 6.0116608e-17 8.7802550e-11], sum to 1.0000
[2019-03-27 05:22:30,563] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8641
[2019-03-27 05:22:30,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1660677.623700781 W.
[2019-03-27 05:22:30,581] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.55, 90.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.202676255728889, 6.9112, 168.9111498921544, 1660677.623700781, 1453896.54771079, 311349.9015112257], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5799000.0000, 
sim time next is 5799600.0000, 
raw observation next is [26.5, 91.0, 1.0, 2.0, 0.3524186447243913, 1.0, 1.0, 0.3524186447243913, 1.0, 1.0, 0.6042594445286413, 6.9112, 6.9112, 170.5573041426782, 1477882.856923222, 1477882.856923222, 327175.84878031], 
processed observation next is [1.0, 0.13043478260869565, 0.4549763033175356, 0.91, 1.0, 1.0, 0.21978149966794128, 1.0, 0.5, 0.21978149966794128, 1.0, 0.5, 0.5173895664983431, 0.0, 0.0, 0.8375144448122397, 0.4105230158120061, 0.4105230158120061, 0.48832216235867165], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.695855], dtype=float32), -0.6039052]. 
=============================================
[2019-03-27 05:22:34,081] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2396434e-01 1.6340020e-11 8.7603563e-01 1.7524089e-16 2.5255673e-09], sum to 1.0000
[2019-03-27 05:22:34,093] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8646
[2019-03-27 05:22:34,097] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.6, 72.16666666666667, 1.0, 2.0, 0.2748490825510553, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4755809663974154, 6.9112, 6.9112, 168.912956510431, 768142.8895896821, 768142.8895896821, 214066.2640282552], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5854200.0000, 
sim time next is 5854800.0000, 
raw observation next is [30.4, 73.33333333333334, 1.0, 2.0, 0.2781392045941337, 0.0, 2.0, 0.0, 1.0, 2.0, 0.48133519537356, 6.911200000000001, 6.9112, 168.912956510431, 777341.4235484771, 777341.4235484765, 215038.9685747033], 
processed observation next is [1.0, 0.782608695652174, 0.6398104265402843, 0.7333333333333334, 1.0, 1.0, 0.13028819830618518, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3674819455775122, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2159281732079103, 0.21592817320791016, 0.32095368443985567], 
reward next is 0.6790, 
noisyNet noise sample is [array([0.2050844], dtype=float32), 0.3004439]. 
=============================================
[2019-03-27 05:22:48,079] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-27 05:22:48,080] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:22:48,081] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:22:48,082] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:22:48,083] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:22:48,086] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:22:48,087] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:22:48,088] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:22:48,088] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:22:48,089] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:22:48,092] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:22:48,112] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run16
[2019-03-27 05:22:48,113] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run16
[2019-03-27 05:22:48,159] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run16
[2019-03-27 05:22:48,176] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run16
[2019-03-27 05:22:48,177] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run16
[2019-03-27 05:24:11,624] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.05036756]
[2019-03-27 05:24:11,625] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.34812757, 90.61599906000001, 1.0, 2.0, 0.763910643157359, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1147683.96773194, 1147683.96773194, 245880.673098479]
[2019-03-27 05:24:11,626] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:24:11,632] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.4028089e-01 2.8092899e-12 1.5971914e-01 3.0469083e-16 6.1325930e-11], sampled 0.9298263936119993
[2019-03-27 05:24:42,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7101.2115 3124353699.4030 1768.0000
[2019-03-27 05:24:42,459] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7892.2780 2950632855.8089 1221.0000
[2019-03-27 05:24:42,547] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6827.1016 3201716685.0903 2245.0000
[2019-03-27 05:24:42,618] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7733.8066 3001757536.9435 1378.0000
[2019-03-27 05:24:42,641] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7125.5097 3329700614.7135 2032.0000
[2019-03-27 05:24:43,659] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 375000, evaluation results [375000.0, 7125.509737054171, 3329700614.7134743, 2032.0, 7101.211527383108, 3124353699.4030385, 1768.0, 7892.277955976979, 2950632855.808925, 1221.0, 6827.101646950156, 3201716685.0902863, 2245.0, 7733.806644745817, 3001757536.943498, 1378.0]
[2019-03-27 05:24:47,280] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0328481e-03 3.9775444e-12 9.9796706e-01 1.1060519e-17 3.4529057e-11], sum to 1.0000
[2019-03-27 05:24:47,289] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6899
[2019-03-27 05:24:47,295] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.88333333333334, 73.5, 1.0, 2.0, 0.9710861182823634, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994787741508299, 6.9112, 168.9123916373757, 2254532.457514833, 2195232.635129952, 454960.7196044534], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6178200.0000, 
sim time next is 6178800.0000, 
raw observation next is [29.96666666666667, 73.0, 1.0, 2.0, 0.703865904379098, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994588915411168, 6.9112, 168.9123916093995, 1880538.578058304, 1821379.809287884, 385923.7971037625], 
processed observation next is [1.0, 0.5217391304347826, 0.6192733017377569, 0.73, 1.0, 1.0, 0.6432119329868651, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008338891541116755, 0.0, 0.8294371712296251, 0.5223718272384178, 0.5059388359133011, 0.5760056673190486], 
reward next is 0.0070, 
noisyNet noise sample is [array([0.564608], dtype=float32), -0.4955554]. 
=============================================
[2019-03-27 05:24:48,091] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.8473454e-04 2.3491990e-12 9.9981529e-01 3.9139105e-18 6.9456528e-12], sum to 1.0000
[2019-03-27 05:24:48,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9870
[2019-03-27 05:24:48,104] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.40000000000001, 74.0, 1.0, 2.0, 1.020013003559805, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988149859527996, 6.9112, 168.9124363101155, 2323014.182711089, 2268423.47207539, 470185.3803716982], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6193200.0000, 
sim time next is 6193800.0000, 
raw observation next is [29.3, 74.5, 1.0, 2.0, 1.010877094701349, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987917125837733, 6.9112, 168.9124378889408, 2310226.594057516, 2255800.991694563, 467339.1724441716], 
processed observation next is [1.0, 0.6956521739130435, 0.5876777251184835, 0.745, 1.0, 1.0, 1.0131049333751192, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0076717125837732604, 0.0, 0.8294373984833597, 0.6417296094604211, 0.626611386581823, 0.6975211529017487], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6005218], dtype=float32), 1.2462263]. 
=============================================
[2019-03-27 05:24:54,097] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9631025e-23 4.3401588e-11 3.0347962e-25 6.1445438e-20], sum to 1.0000
[2019-03-27 05:24:54,106] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2687
[2019-03-27 05:24:54,108] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.55, 77.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8935919171138564, 6.911199999999999, 6.9112, 168.912956510431, 735718.1373429636, 735718.1373429642, 221872.560134357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6289800.0000, 
sim time next is 6290400.0000, 
raw observation next is [28.4, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8970901368396405, 6.9112, 6.9112, 168.912956510431, 738134.5754765758, 738134.5754765758, 222662.156632082], 
processed observation next is [0.0, 0.8260869565217391, 0.5450236966824644, 0.7833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8745001668776103, 0.0, 0.0, 0.8294399451523027, 0.2050373820768266, 0.2050373820768266, 0.33233157706280897], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.15612042], dtype=float32), -0.08012348]. 
=============================================
[2019-03-27 05:24:54,146] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.4579180e-20 5.1992726e-09 1.3736701e-22 3.9371703e-19], sum to 1.0000
[2019-03-27 05:24:54,155] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6708
[2019-03-27 05:24:54,160] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.63333333333334, 83.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9090017973687147, 6.911199999999999, 6.9112, 168.912956510431, 746530.7973011857, 746530.7973011864, 225380.0437189411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6295800.0000, 
sim time next is 6296400.0000, 
raw observation next is [27.6, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9099048855851405, 6.9112, 6.9112, 168.912956510431, 747363.2004427084, 747363.2004427084, 225595.61897593], 
processed observation next is [0.0, 0.9130434782608695, 0.5071090047393366, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8901279092501712, 0.0, 0.0, 0.8294399451523027, 0.20760088901186347, 0.20760088901186347, 0.33670987906855226], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.6596575], dtype=float32), -0.7536189]. 
=============================================
[2019-03-27 05:25:06,613] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.4972609e-01 5.5176665e-11 8.5027397e-01 2.4907474e-15 1.4878986e-10], sum to 1.0000
[2019-03-27 05:25:06,621] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4720
[2019-03-27 05:25:06,626] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 92.0, 1.0, 2.0, 0.3323240612557857, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5648096673796914, 6.9112, 6.9112, 168.912956510431, 928843.083259159, 928843.083259159, 231483.1373484574], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6499800.0000, 
sim time next is 6500400.0000, 
raw observation next is [26.36666666666667, 91.66666666666667, 1.0, 2.0, 0.3217631257739009, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5469708584146671, 6.911200000000001, 6.9112, 168.912956510431, 899312.8560311132, 899312.8560311126, 227888.4979028179], 
processed observation next is [1.0, 0.21739130434782608, 0.4486571879936811, 0.9166666666666667, 1.0, 1.0, 0.18284713948662762, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4475254370910574, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.24980912667530922, 0.24980912667530905, 0.3401320864221163], 
reward next is 0.6599, 
noisyNet noise sample is [array([1.9563559], dtype=float32), 0.15194547]. 
=============================================
[2019-03-27 05:25:09,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.2877586e-02 1.8488557e-12 9.2712241e-01 1.8069175e-18 2.6664077e-12], sum to 1.0000
[2019-03-27 05:25:09,593] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1802
[2019-03-27 05:25:09,597] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.8, 65.33333333333334, 1.0, 2.0, 0.3235566371588098, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5443822162097303, 6.911199999999999, 6.9112, 168.9129090708334, 904327.7705435166, 904327.7705435172, 227835.5867286593], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6541800.0000, 
sim time next is 6542400.0000, 
raw observation next is [29.7, 65.66666666666667, 1.0, 2.0, 0.2316181030241467, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3892634534226604, 6.911199999999999, 6.9112, 168.9129564985852, 647284.9747680371, 647284.9747680377, 201606.4551001329], 
processed observation next is [1.0, 0.7391304347826086, 0.6066350710900474, 0.6566666666666667, 1.0, 1.0, 0.07423867834234542, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.25519933344226875, -8.881784197001253e-17, 0.0, 0.8294399450941344, 0.1798013818800103, 0.17980138188001046, 0.30090515686587], 
reward next is 0.6991, 
noisyNet noise sample is [array([2.4744985], dtype=float32), 1.0022241]. 
=============================================
[2019-03-27 05:25:11,170] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.4702187e-01 4.0194913e-11 8.5297811e-01 2.5825522e-15 6.0315580e-10], sum to 1.0000
[2019-03-27 05:25:11,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6802
[2019-03-27 05:25:11,182] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.73333333333334, 87.0, 1.0, 2.0, 0.3279612757937867, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5551997488886867, 6.911199999999999, 6.9112, 168.912956510431, 916643.8706559733, 916643.870655974, 229720.5897823072], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6592800.0000, 
sim time next is 6593400.0000, 
raw observation next is [26.8, 86.5, 1.0, 2.0, 0.3317185030414665, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5615187403391801, 6.9112, 6.9112, 168.912956510431, 927149.8141302812, 927149.8141302812, 231003.6980527546], 
processed observation next is [1.0, 0.30434782608695654, 0.4691943127962086, 0.865, 1.0, 1.0, 0.1948415699294777, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46526675651119526, 0.0, 0.0, 0.8294399451523027, 0.2575416150361892, 0.2575416150361892, 0.34478163888470836], 
reward next is 0.6552, 
noisyNet noise sample is [array([-0.3465514], dtype=float32), 0.0063729086]. 
=============================================
[2019-03-27 05:25:18,394] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9997723e-01 3.5686018e-17 2.2815047e-05 9.9961576e-22 4.5931505e-16], sum to 1.0000
[2019-03-27 05:25:18,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3324
[2019-03-27 05:25:18,408] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.08333333333334, 67.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7013989985631043, 6.911199999999999, 6.9112, 168.912956510431, 599843.3394211539, 599843.3394211545, 182979.8794111858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6725400.0000, 
sim time next is 6726000.0000, 
raw observation next is [26.96666666666667, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6965649916228499, 6.911200000000001, 6.9112, 168.912956510431, 596171.6056717106, 596171.60567171, 182115.4058605631], 
processed observation next is [1.0, 0.8695652173913043, 0.47709320695102697, 0.6766666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6299573068571339, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16560322379769737, 0.1656032237976972, 0.27181403859785536], 
reward next is 0.7282, 
noisyNet noise sample is [array([0.00532385], dtype=float32), -0.8872896]. 
=============================================
[2019-03-27 05:25:18,418] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.27193 ]
 [57.87379 ]
 [58.159054]
 [58.19895 ]
 [58.714657]], R is [[56.84825134]
 [57.00666428]
 [57.16223526]
 [57.314785  ]
 [57.46416855]].
[2019-03-27 05:25:19,713] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1044241e-01 2.3881611e-12 5.8955765e-01 1.4058022e-17 6.4841119e-11], sum to 1.0000
[2019-03-27 05:25:19,721] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9970
[2019-03-27 05:25:19,727] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.33333333333334, 67.0, 1.0, 2.0, 0.2315250982519098, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3886587180166995, 6.9112, 6.9112, 168.9129564983627, 647024.9824617755, 647024.9824617755, 201548.745788498], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6715200.0000, 
sim time next is 6715800.0000, 
raw observation next is [29.2, 67.0, 1.0, 2.0, 0.2278380270011232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3817456373765241, 6.9112, 6.9112, 168.912956510428, 636717.9265215548, 636717.9265215548, 200631.0164518181], 
processed observation next is [1.0, 0.7391304347826086, 0.5829383886255924, 0.67, 1.0, 1.0, 0.06968436988087133, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.24603126509332207, 0.0, 0.0, 0.8294399451522879, 0.17686609070043188, 0.17686609070043188, 0.2994492782862957], 
reward next is 0.7006, 
noisyNet noise sample is [array([2.1553848], dtype=float32), 0.47148255]. 
=============================================
[2019-03-27 05:25:29,533] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.0550319e-22 1.4763640e-10 5.3345934e-24 1.3812230e-19], sum to 1.0000
[2019-03-27 05:25:29,539] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2018
[2019-03-27 05:25:29,545] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.23333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304282488134751, 6.911200000000001, 6.9112, 168.912956510431, 622474.592731903, 622474.5927319024, 188300.3847245593], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6923400.0000, 
sim time next is 6924000.0000, 
raw observation next is [24.16666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7261920364755584, 6.9112, 6.9112, 168.912956510431, 619006.1099668499, 619006.1099668499, 187509.290852095], 
processed observation next is [0.0, 0.13043478260869565, 0.34439178515007923, 0.8866666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.666087849360437, 0.0, 0.0, 0.8294399451523027, 0.1719461416574583, 0.1719461416574583, 0.2798646132120821], 
reward next is 0.7201, 
noisyNet noise sample is [array([-0.35881644], dtype=float32), -0.30960187]. 
=============================================
[2019-03-27 05:25:29,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[75.246216]
 [74.99186 ]
 [74.56381 ]
 [74.43815 ]
 [74.14433 ]], R is [[75.30633545]
 [75.27223206]
 [75.23779297]
 [75.20417786]
 [75.17146301]].
[2019-03-27 05:25:31,579] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2396342e-24 4.1390563e-14 2.6072398e-26 2.8442850e-21], sum to 1.0000
[2019-03-27 05:25:31,585] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6889
[2019-03-27 05:25:31,594] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.717846295068133, 6.9112, 6.9112, 168.912956510431, 612405.9088191288, 612405.9088191288, 185966.1406293703], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6932400.0000, 
sim time next is 6933000.0000, 
raw observation next is [24.6, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7183564405053875, 6.9112, 6.9112, 168.912956510431, 612707.8473380536, 612707.8473380536, 186059.3979398539], 
processed observation next is [0.0, 0.21739130434782608, 0.36492890995260674, 0.8533333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6565322445187652, 0.0, 0.0, 0.8294399451523027, 0.17019662426057044, 0.17019662426057044, 0.27770059394008045], 
reward next is 0.7223, 
noisyNet noise sample is [array([0.08373533], dtype=float32), -1.1007359]. 
=============================================
[2019-03-27 05:25:31,610] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.06763 ]
 [79.06086 ]
 [79.050476]
 [79.0276  ]
 [78.971146]], R is [[79.00424957]
 [78.93664551]
 [78.86988831]
 [78.80400848]
 [78.73898315]].
[2019-03-27 05:25:38,246] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 05:25:38,248] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:25:38,249] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:25:38,250] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:25:38,250] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:25:38,251] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:25:38,252] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:25:38,253] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:25:38,254] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:25:38,255] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:25:38,255] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:25:38,273] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run17
[2019-03-27 05:25:38,273] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run17
[2019-03-27 05:25:38,312] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run17
[2019-03-27 05:25:38,333] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run17
[2019-03-27 05:25:38,353] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run17
[2019-03-27 05:25:44,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:25:44,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [20.1, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5069309101531065, 6.9112, 6.9112, 168.912956510431, 449804.8457277757, 449804.8457277757, 152822.7931256342]
[2019-03-27 05:25:44,919] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:25:44,922] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.1115471e-19 1.3062365e-09 4.7892788e-22 9.2143205e-18], sampled 0.8768317370519894
[2019-03-27 05:26:22,336] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:26:22,336] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.270930225, 99.08468633, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9224132450021741, 6.911200000000001, 6.9112, 168.912956478804, 786929.2343915754, 786929.2343915749, 229292.2917304304]
[2019-03-27 05:26:22,338] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:26:22,340] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 5.3434229e-20 1.7096660e-09 2.5670587e-22 7.0876739e-18], sampled 0.2726586151077397
[2019-03-27 05:26:39,741] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:26:39,745] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.37164564166667, 74.42529477333333, 1.0, 2.0, 0.7398348396798275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1033967.369201024, 1033967.369201024, 229691.8971757239]
[2019-03-27 05:26:39,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:26:39,752] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.4615835e-01 1.3199167e-12 5.3841677e-02 6.9571861e-16 2.8234418e-11], sampled 0.5781770217795238
[2019-03-27 05:26:39,753] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1033967.369201024 W.
[2019-03-27 05:26:39,765] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:26:39,767] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 65.0, 1.0, 2.0, 0.9224344231784036, 1.0, 1.0, 0.9224344231784036, 0.0, 1.0, 0.0, 6.9112, 6.9112, 172.86236624, 2580072.867600489, 2580072.867600489, 484358.2897231302]
[2019-03-27 05:26:39,769] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:26:39,771] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.8920223e-04 9.1542651e-10 9.9911076e-01 3.5361359e-14 2.1495390e-09], sampled 0.7880182032126402
[2019-03-27 05:26:39,772] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2580072.867600489 W.
[2019-03-27 05:26:46,757] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:26:46,759] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.56666666666667, 85.00000000000001, 1.0, 2.0, 0.7050567268396363, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.005975555855583, 6.9112, 168.9123932344069, 1882204.969955986, 1814968.152925297, 385753.3039864682]
[2019-03-27 05:26:46,760] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:26:46,763] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.9576685e-01 7.3647609e-11 6.0423315e-01 3.1501453e-14 6.7906691e-10], sampled 0.6649081023753729
[2019-03-27 05:26:49,925] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02304387], dtype=float32), 0.053904247]
[2019-03-27 05:26:49,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.856987649966004, 6.911200000000001, 6.9112, 168.912956510431, 710209.3036399233, 710209.3036399228, 213781.2033301459]
[2019-03-27 05:26:49,930] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:26:49,932] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.1284992e-22 5.5288833e-11 5.3584324e-25 4.0099855e-20], sampled 0.7156096427289065
[2019-03-27 05:27:31,972] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7152.6118 3112371563.7925 1940.0000
[2019-03-27 05:27:32,496] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7948.4449 2941821896.4801 1333.0000
[2019-03-27 05:27:32,619] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7193.4038 3322704893.8660 2111.0000
[2019-03-27 05:27:32,749] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6877.3172 3190809107.7451 2384.0000
[2019-03-27 05:27:32,767] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7797.5764 2993159142.4974 1502.0000
[2019-03-27 05:27:33,781] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 400000, evaluation results [400000.0, 7193.4038384097585, 3322704893.865994, 2111.0, 7152.611771394171, 3112371563.7924676, 1940.0, 7948.444888940103, 2941821896.480148, 1333.0, 6877.317165771788, 3190809107.745114, 2384.0, 7797.576386749714, 2993159142.4974017, 1502.0]
[2019-03-27 05:27:56,926] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.5913662e-25 1.1525401e-14 1.0430635e-26 4.3737821e-22], sum to 1.0000
[2019-03-27 05:27:56,932] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9130
[2019-03-27 05:27:56,939] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.23333333333333, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5796954092926365, 6.9112, 6.9112, 168.912956510431, 506334.9479582717, 506334.9479582717, 163014.4081599962], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7447200.0000, 
sim time next is 7447800.0000, 
raw observation next is [21.21666666666667, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5794232971577735, 6.9112, 6.9112, 168.912956510431, 506079.5579301456, 506079.5579301456, 162974.9417084234], 
processed observation next is [0.0, 0.17391304347826086, 0.20458135860979476, 0.9483333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4871015818997238, 0.0, 0.0, 0.8294399451523027, 0.140577654980596, 0.140577654980596, 0.2432461816543633], 
reward next is 0.7568, 
noisyNet noise sample is [array([-0.3595631], dtype=float32), -0.82781994]. 
=============================================
[2019-03-27 05:27:59,643] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2942225e-24 2.6683229e-13 1.0763634e-25 1.0241213e-21], sum to 1.0000
[2019-03-27 05:27:59,651] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1695
[2019-03-27 05:27:59,657] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.66666666666667, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7131771148843612, 6.9112, 6.9112, 168.912956510431, 606903.4914427524, 606903.4914427524, 185099.5067459804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7496400.0000, 
sim time next is 7497000.0000, 
raw observation next is [25.55, 79.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7107783080872127, 6.9112, 6.9112, 168.912956510431, 605155.6039935349, 605155.6039935349, 184663.8531680446], 
processed observation next is [0.0, 0.782608695652174, 0.40995260663507116, 0.795, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6472906196185519, 0.0, 0.0, 0.8294399451523027, 0.16809877888709304, 0.16809877888709304, 0.27561769129558894], 
reward next is 0.7244, 
noisyNet noise sample is [array([0.9855815], dtype=float32), 2.2043297]. 
=============================================
[2019-03-27 05:27:59,674] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[83.904465]
 [83.860176]
 [83.78744 ]
 [83.73257 ]
 [83.68773 ]], R is [[83.82627106]
 [83.71173859]
 [83.59767914]
 [83.48428345]
 [83.37184143]].
[2019-03-27 05:28:01,970] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.2814476e-23 3.1571486e-12 3.1719579e-25 1.7221815e-20], sum to 1.0000
[2019-03-27 05:28:01,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7487
[2019-03-27 05:28:01,987] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.25, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6757384153728434, 6.9112, 6.9112, 168.912956510431, 579652.4909455976, 579652.4909455976, 178459.5017411591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7529400.0000, 
sim time next is 7530000.0000, 
raw observation next is [23.23333333333333, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6726896182513595, 6.911199999999999, 6.9112, 168.912956510431, 577294.8021213635, 577294.8021213642, 177933.8111999822], 
processed observation next is [0.0, 0.13043478260869565, 0.3001579778830963, 0.9133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6008409978675116, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16035966725593429, 0.16035966725593448, 0.2655728525372869], 
reward next is 0.7344, 
noisyNet noise sample is [array([-0.10540428], dtype=float32), 0.56347495]. 
=============================================
[2019-03-27 05:28:02,003] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[73.23343]
 [72.76843]
 [72.68141]
 [72.42735]
 [71.98734]], R is [[73.43026733]
 [73.42961121]
 [73.42810059]
 [73.42575073]
 [73.42266846]].
[2019-03-27 05:28:11,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.2319504e-21 9.6542481e-09 7.7277524e-24 3.4080666e-18], sum to 1.0000
[2019-03-27 05:28:11,953] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2256
[2019-03-27 05:28:11,960] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8290618087978476, 6.9112, 6.9112, 168.912956510431, 694538.838280199, 694538.838280199, 207925.8124261997], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7710000.0000, 
sim time next is 7710600.0000, 
raw observation next is [25.33333333333333, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8345885780840202, 6.9112, 6.9112, 168.912956510431, 698213.6747139937, 698213.6747139937, 209088.5349771009], 
processed observation next is [1.0, 0.21739130434782608, 0.3996840442338071, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7982787537610001, 0.0, 0.0, 0.8294399451523027, 0.19394824297610935, 0.19394824297610935, 0.31207244026432973], 
reward next is 0.6879, 
noisyNet noise sample is [array([0.16008092], dtype=float32), 0.65619]. 
=============================================
[2019-03-27 05:28:12,442] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9997139e-01 2.7880820e-16 2.8627670e-05 2.6553747e-18 7.6802713e-14], sum to 1.0000
[2019-03-27 05:28:12,454] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7394
[2019-03-27 05:28:12,461] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 934524.0565605063 W.
[2019-03-27 05:28:12,466] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.4, 85.0, 1.0, 2.0, 0.3343571394474116, 1.0, 2.0, 0.3343571394474116, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 934524.0565605063, 934524.0565605063, 256856.6854431103], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7718400.0000, 
sim time next is 7719000.0000, 
raw observation next is [27.6, 83.83333333333334, 1.0, 2.0, 0.8690733958403579, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104117, 1214689.977229823, 1214689.977229822, 261571.7941818166], 
processed observation next is [1.0, 0.34782608695652173, 0.5071090047393366, 0.8383333333333334, 1.0, 1.0, 0.842257103422118, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451522079, 0.3374138825638397, 0.3374138825638394, 0.3904056629579352], 
reward next is 0.6096, 
noisyNet noise sample is [array([-2.7184772], dtype=float32), 0.40825504]. 
=============================================
[2019-03-27 05:28:12,480] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.50307 ]
 [53.555958]
 [57.66385 ]
 [58.009117]
 [63.506733]], R is [[46.01100159]
 [46.16752243]
 [45.70584869]
 [45.24879074]
 [45.42047501]].
[2019-03-27 05:28:15,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [2.6330107e-03 1.1861581e-13 9.9736696e-01 1.6858342e-18 1.6666627e-12], sum to 1.0000
[2019-03-27 05:28:15,132] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4603
[2019-03-27 05:28:15,144] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.01666666666667, 60.83333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.180604929448023, 6.9112, 168.911332279845, 2495767.751510635, 2304644.460176178, 476462.3094622313], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7746600.0000, 
sim time next is 7747200.0000, 
raw observation next is [30.9, 61.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.339382519682992, 6.9112, 168.9101139629866, 2610650.726350446, 2306888.421924672, 476198.2260308692], 
processed observation next is [1.0, 0.6956521739130435, 0.6635071090047393, 0.61, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04281825196829923, 0.0, 0.8294259869430268, 0.7251807573195684, 0.64080233942352, 0.7107436209415958], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.217358], dtype=float32), -1.1119853]. 
=============================================
[2019-03-27 05:28:21,447] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.3256805e-21 2.4553362e-08 2.0865081e-24 1.5875476e-19], sum to 1.0000
[2019-03-27 05:28:21,455] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1768
[2019-03-27 05:28:21,463] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.75, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9216516884163953, 6.911200000000001, 6.9112, 168.912956510431, 753035.8593542437, 753035.8593542431, 228198.4649232655], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7846200.0000, 
sim time next is 7846800.0000, 
raw observation next is [27.6, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9253668504430514, 6.911199999999999, 6.9112, 168.912956510431, 755795.6329067571, 755795.6329067578, 229070.2247972736], 
processed observation next is [1.0, 0.8260869565217391, 0.5071090047393366, 0.8666666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9089839639549407, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20994323136298806, 0.20994323136298826, 0.3418958579063785], 
reward next is 0.6581, 
noisyNet noise sample is [array([0.16325593], dtype=float32), 1.5946367]. 
=============================================
[2019-03-27 05:28:23,136] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2089661e-01 4.0965183e-11 8.7910342e-01 1.6527641e-15 1.7004423e-10], sum to 1.0000
[2019-03-27 05:28:23,144] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-27 05:28:23,152] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1903807.128080666 W.
[2019-03-27 05:28:23,158] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.68333333333333, 76.5, 1.0, 2.0, 0.7204937040556577, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.982633813915813, 6.9112, 168.9124737499187, 1903807.128080666, 1853129.666765438, 389998.864751487], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7897800.0000, 
sim time next is 7898400.0000, 
raw observation next is [28.8, 76.0, 1.0, 2.0, 0.7377533876054867, 1.0, 1.0, 0.7377533876054867, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2063096.693738159, 2063096.693738159, 390701.8093784177], 
processed observation next is [1.0, 0.43478260869565216, 0.5639810426540285, 0.76, 1.0, 1.0, 0.6840402260307068, 1.0, 0.5, 0.6840402260307068, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5730824149272664, 0.5730824149272664, 0.5831370289230114], 
reward next is 0.4169, 
noisyNet noise sample is [array([0.69547564], dtype=float32), -0.34591502]. 
=============================================
[2019-03-27 05:28:25,630] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999928e-01 3.2043886e-19 7.5299255e-07 5.7829847e-23 6.9773088e-17], sum to 1.0000
[2019-03-27 05:28:25,636] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6161
[2019-03-27 05:28:25,640] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.897541954841085, 6.911200000000002, 6.9112, 168.912956510431, 737807.7591457566, 737807.7591457553, 222738.8557945498], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7937400.0000, 
sim time next is 7938000.0000, 
raw observation next is [27.4, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8992593827158898, 6.911200000000001, 6.9112, 168.912956510431, 739221.395754234, 739221.3957542335, 223136.7744025338], 
processed observation next is [1.0, 0.9130434782608695, 0.4976303317535545, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8771455886779143, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20533927659839835, 0.20533927659839818, 0.3330399617948266], 
reward next is 0.6670, 
noisyNet noise sample is [array([1.0438308], dtype=float32), -0.32754055]. 
=============================================
[2019-03-27 05:28:25,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[61.091415]
 [61.703415]
 [62.335236]
 [62.723362]
 [63.047554]], R is [[60.8718071 ]
 [60.93064117]
 [60.98975754]
 [61.04924393]
 [61.10886383]].
[2019-03-27 05:28:25,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:25,968] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,003] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run3
[2019-03-27 05:28:26,325] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,326] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,327] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run3
[2019-03-27 05:28:26,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,547] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run3
[2019-03-27 05:28:26,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,808] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run3
[2019-03-27 05:28:26,834] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,835] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,836] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run3
[2019-03-27 05:28:26,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,861] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,862] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run3
[2019-03-27 05:28:26,888] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,888] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,890] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run3
[2019-03-27 05:28:26,921] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:26,921] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:26,923] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run3
[2019-03-27 05:28:27,023] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,023] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,024] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run3
[2019-03-27 05:28:27,068] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,068] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,070] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run3
[2019-03-27 05:28:27,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,099] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run3
[2019-03-27 05:28:27,132] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,132] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,133] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run3
[2019-03-27 05:28:27,155] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,156] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,157] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run3
[2019-03-27 05:28:27,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,187] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,188] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run3
[2019-03-27 05:28:27,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,241] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run3
[2019-03-27 05:28:27,266] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:28:27,266] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:27,267] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run3
[2019-03-27 05:28:30,213] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 05:28:30,216] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:28:30,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:30,218] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:28:30,220] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:28:30,221] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:30,221] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:28:30,222] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:28:30,221] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:30,224] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:30,224] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:28:30,241] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run18
[2019-03-27 05:28:30,241] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run18
[2019-03-27 05:28:30,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run18
[2019-03-27 05:28:30,242] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run18
[2019-03-27 05:28:30,296] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run18
[2019-03-27 05:28:32,148] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:28:32,367] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.46996505, 64.41046918, 1.0, 2.0, 0.8411232469272013, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1243538.744384873, 1243538.744384873, 263769.0717409271]
[2019-03-27 05:28:32,370] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:28:32,371] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9230403e-01 3.6072705e-13 7.6959385e-03 4.4915060e-16 9.1888910e-12], sampled 0.20661177100575245
[2019-03-27 05:28:32,372] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1243538.744384873 W.
[2019-03-27 05:28:48,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:28:48,902] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.46666666666667, 52.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.387805341538771, 6.9112, 6.9112, 168.912956510431, 351184.4358905373, 351184.4358905373, 139137.8051991764]
[2019-03-27 05:28:48,903] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:28:48,905] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.5222256e-20 3.4087305e-10 2.2222651e-22 4.4448720e-18], sampled 0.4201655778914094
[2019-03-27 05:28:50,585] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:28:50,587] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.03333333333333, 71.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4425963680212264, 6.911199999999999, 6.9112, 168.912956510431, 397195.7912281004, 397195.7912281011, 144974.7101502929]
[2019-03-27 05:28:50,587] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:28:50,590] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 9.8255793e-21 2.3982683e-10 7.2012203e-23 1.8153488e-18], sampled 0.7383447723607631
[2019-03-27 05:29:05,998] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:29:06,002] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.73686025333333, 87.7515745, 1.0, 2.0, 0.901626968034438, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1260216.586927137, 1260216.586927136, 270387.1484501908]
[2019-03-27 05:29:06,002] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:29:06,004] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [4.1966116e-01 1.5324958e-11 5.8033878e-01 7.0588977e-15 1.4136746e-10], sampled 0.517693291103696
[2019-03-27 05:29:47,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:29:47,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.3, 66.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.025486498446473, 6.9112, 168.9121516563974, 2364830.780296183, 2283752.391193132, 475830.3580203144]
[2019-03-27 05:29:47,238] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:29:47,240] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.5982920e-04 1.6990508e-10 9.9954021e-01 2.1223615e-14 2.0265746e-10], sampled 0.6159850614785337
[2019-03-27 05:29:58,750] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:29:58,751] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.43333333333334, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9526077078458629, 6.9112, 6.9112, 168.912956510431, 776677.2501702806, 776677.2501702806, 235602.2062102915]
[2019-03-27 05:29:58,753] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:29:58,756] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.8627660e-23 1.9722415e-11 5.3177650e-26 7.1488139e-21], sampled 0.8072949122296497
[2019-03-27 05:30:03,396] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:30:03,397] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.18800105333334, 51.62609497333334, 1.0, 2.0, 0.6397517916045993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565027967, 920280.9297432711, 920280.9297432711, 211796.1084481401]
[2019-03-27 05:30:03,399] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:30:03,401] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9999988e-01 1.2548101e-18 7.5388144e-08 6.4704976e-21 1.4678796e-16], sampled 0.31759790810569855
[2019-03-27 05:30:03,402] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 920280.9297432711 W.
[2019-03-27 05:30:04,253] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05527713]
[2019-03-27 05:30:04,254] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 87.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.130653182352543, 6.9112, 168.9111677188958, 1609547.545400095, 1453861.553578753, 311349.882832262]
[2019-03-27 05:30:04,255] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:30:04,259] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.8299187e-01 2.8316405e-14 1.7008144e-02 1.1347567e-17 1.1272268e-12], sampled 0.15648252994602085
[2019-03-27 05:30:04,260] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1609547.545400095 W.
[2019-03-27 05:30:23,873] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7186.6341 3110244158.1098 1952.0000
[2019-03-27 05:30:23,998] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7981.0676 2940627782.4171 1347.0000
[2019-03-27 05:30:24,046] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7225.6988 3321751573.2417 2123.0000
[2019-03-27 05:30:24,416] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7829.6930 2991964920.3099 1532.0000
[2019-03-27 05:30:24,446] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6931.9556 3188999224.7063 2408.0000
[2019-03-27 05:30:25,460] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 425000, evaluation results [425000.0, 7225.69881251248, 3321751573.2416544, 2123.0, 7186.634129547642, 3110244158.109792, 1952.0, 7981.067605957496, 2940627782.417053, 1347.0, 6931.95560282077, 3188999224.7062893, 2408.0, 7829.693049487149, 2991964920.309855, 1532.0]
[2019-03-27 05:30:25,487] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [5.3969300e-01 5.7231182e-12 4.6030703e-01 1.7494027e-15 5.9629519e-12], sum to 1.0000
[2019-03-27 05:30:25,488] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7673
[2019-03-27 05:30:25,495] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.4106927798579857, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7115476330125382, 6.911200000000001, 6.9112, 168.912956510431, 1217378.171507893, 1217378.171507892, 268921.3046344537], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 135600.0000, 
sim time next is 136200.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.4138344925310021, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7165871431599478, 6.9112, 6.9112, 168.912956510431, 1225662.879915967, 1225662.879915967, 270217.8643393754], 
processed observation next is [1.0, 0.5652173913043478, 0.2796208530805688, 0.96, 1.0, 1.0, 0.29377649702530373, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6543745648292046, 0.0, 0.0, 0.8294399451523027, 0.3404619110877686, 0.3404619110877686, 0.40331024528264986], 
reward next is 0.5967, 
noisyNet noise sample is [array([0.6167438], dtype=float32), 0.08525114]. 
=============================================
[2019-03-27 05:30:28,638] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.2993933e-20 2.0571171e-08 7.3039478e-22 3.3303906e-17], sum to 1.0000
[2019-03-27 05:30:28,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5888
[2019-03-27 05:30:28,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6157216006697936, 6.9112, 6.9112, 168.912956510431, 535782.427160749, 535782.427160749, 168510.6752276351], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 87600.0000, 
sim time next is 88200.0000, 
raw observation next is [22.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6157127148951701, 6.9112, 6.9112, 168.912956510431, 535770.6797168505, 535770.6797168505, 168509.3564472383], 
processed observation next is [1.0, 0.0, 0.25592417061611383, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5313569693843537, 0.0, 0.0, 0.8294399451523027, 0.14882518881023626, 0.14882518881023626, 0.25150650216005715], 
reward next is 0.7485, 
noisyNet noise sample is [array([1.5135549], dtype=float32), 0.82168776]. 
=============================================
[2019-03-27 05:30:31,002] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2891479e-01 9.7481851e-14 5.7108521e-01 1.7053991e-17 3.4937786e-12], sum to 1.0000
[2019-03-27 05:30:31,008] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6036
[2019-03-27 05:30:31,012] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.8, 95.33333333333334, 1.0, 2.0, 0.322784038183943, 1.0, 1.0, 0.322784038183943, 1.0, 2.0, 0.5524752613005545, 6.9112, 6.9112, 170.5573041426782, 1409682.311953277, 1409682.311953277, 318453.8473080927], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 127200.0000, 
sim time next is 127800.0000, 
raw observation next is [22.8, 95.5, 1.0, 2.0, 0.48250030683727, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8335734177476167, 6.911199999999999, 6.9112, 168.912956510431, 1424284.489682872, 1424284.489682872, 303491.3406695982], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.955, 1.0, 1.0, 0.37650639377984346, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.797040753350752, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.39563458046746447, 0.39563458046746447, 0.45297215025313164], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.8267803], dtype=float32), 1.8241521]. 
=============================================
[2019-03-27 05:30:33,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.7179493e-23 3.0675399e-12 2.9710178e-24 3.8284552e-21], sum to 1.0000
[2019-03-27 05:30:33,833] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3286
[2019-03-27 05:30:33,838] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5511402397380988, 6.911199999999999, 6.9112, 168.912956510431, 484301.3616666102, 484301.3616666108, 158861.5847912312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 214800.0000, 
sim time next is 215400.0000, 
raw observation next is [21.21666666666667, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5532731379642186, 6.9112, 6.9112, 168.912956510431, 485981.2259200464, 485981.2259200464, 159164.0309180335], 
processed observation next is [0.0, 0.4782608695652174, 0.20458135860979476, 0.9033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4552111438588032, 0.0, 0.0, 0.8294399451523027, 0.13499478497779066, 0.13499478497779066, 0.23755825510154255], 
reward next is 0.7624, 
noisyNet noise sample is [array([1.5555948], dtype=float32), 0.41548026]. 
=============================================
[2019-03-27 05:30:36,424] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.0094813e-24 3.6947908e-13 3.3182793e-25 8.1209329e-21], sum to 1.0000
[2019-03-27 05:30:36,432] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5476
[2019-03-27 05:30:36,439] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.71666666666667, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432635906885748, 6.9112, 6.9112, 168.912956510431, 477946.181177679, 477946.181177679, 157759.4069347371], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 209400.0000, 
sim time next is 210000.0000, 
raw observation next is [20.73333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5531604788885984, 6.911200000000001, 6.9112, 168.912956510431, 486642.5017893348, 486642.5017893342, 159123.7256878617], 
processed observation next is [0.0, 0.43478260869565216, 0.18167456556082143, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4550737547421932, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13517847271925967, 0.13517847271925948, 0.23749809804158464], 
reward next is 0.7625, 
noisyNet noise sample is [array([0.26426405], dtype=float32), -1.3226795]. 
=============================================
[2019-03-27 05:30:36,457] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[80.61438 ]
 [80.558945]
 [80.52099 ]
 [80.49618 ]
 [80.46628 ]], R is [[80.60028076]
 [80.55882263]
 [80.51877594]
 [80.47890472]
 [80.43971252]].
[2019-03-27 05:30:38,563] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.8841441e-25 3.1399297e-13 3.6213960e-26 7.5363423e-23], sum to 1.0000
[2019-03-27 05:30:38,573] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5033
[2019-03-27 05:30:38,577] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5494337926622472, 6.9112, 6.9112, 168.912956510431, 482007.6237752045, 482007.6237752045, 158649.4250712965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 295800.0000, 
sim time next is 296400.0000, 
raw observation next is [22.93333333333334, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.551304182231186, 6.9112, 6.9112, 168.912956510431, 483565.4332241096, 483565.4332241096, 158910.8728989495], 
processed observation next is [0.0, 0.43478260869565216, 0.28593996840442376, 0.7833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4528099783307147, 0.0, 0.0, 0.8294399451523027, 0.13432373145114154, 0.13432373145114154, 0.23718040731186493], 
reward next is 0.7628, 
noisyNet noise sample is [array([-0.96131945], dtype=float32), 0.16378187]. 
=============================================
[2019-03-27 05:30:46,622] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 8.7205891e-24 1.2003481e-11 7.7488259e-25 6.7787961e-22], sum to 1.0000
[2019-03-27 05:30:46,628] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2327
[2019-03-27 05:30:46,632] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9194298584691725, 6.9112, 6.9112, 168.912956510431, 815320.8419876557, 815320.8419876557, 227833.0304585562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 387600.0000, 
sim time next is 388200.0000, 
raw observation next is [22.56666666666667, 72.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9297970135771522, 6.9112, 6.9112, 168.912956510431, 824134.3303615414, 824134.3303615414, 230331.8170237257], 
processed observation next is [1.0, 0.4782608695652174, 0.26856240126382325, 0.7283333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9143866019233562, 0.0, 0.0, 0.8294399451523027, 0.22892620287820592, 0.22892620287820592, 0.3437788313786951], 
reward next is 0.6562, 
noisyNet noise sample is [array([-0.7434754], dtype=float32), 1.6575391]. 
=============================================
[2019-03-27 05:30:55,435] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.7186309e-25 6.0118650e-16 2.1887916e-27 3.8003557e-22], sum to 1.0000
[2019-03-27 05:30:55,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4910
[2019-03-27 05:30:55,447] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.16666666666667, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.40570205097248, 6.911199999999999, 6.9112, 168.912956510431, 365366.1159042977, 365366.1159042984, 141052.0180320476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 530400.0000, 
sim time next is 531000.0000, 
raw observation next is [18.1, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4079909894372011, 6.911199999999999, 6.9112, 168.912956510431, 367540.3790585317, 367540.3790585322, 141267.1950717328], 
processed observation next is [1.0, 0.13043478260869565, 0.05687203791469207, 0.895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2780377919965867, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10209454973848103, 0.10209454973848116, 0.2108465598085564], 
reward next is 0.7892, 
noisyNet noise sample is [array([0.7697395], dtype=float32), 1.4311355]. 
=============================================
[2019-03-27 05:30:55,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[79.503136]
 [79.36997 ]
 [79.08128 ]
 [78.60058 ]
 [78.42327 ]], R is [[79.96695709]
 [79.95676422]
 [79.94189453]
 [79.93191528]
 [79.92210388]].
[2019-03-27 05:30:56,245] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9871437e-24 9.9848498e-12 1.6501483e-24 8.3738620e-21], sum to 1.0000
[2019-03-27 05:30:56,255] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6695
[2019-03-27 05:30:56,260] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4056311384330072, 6.9112, 6.9112, 168.912956510431, 364991.9936182111, 364991.9936182111, 141072.7768631206], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 540000.0000, 
sim time next is 540600.0000, 
raw observation next is [19.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4066916117670736, 6.911200000000001, 6.9112, 168.912956510431, 365717.7777312685, 365717.7777312679, 141196.82744069], 
processed observation next is [1.0, 0.2608695652173913, 0.09952606635071096, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.27645318508179706, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10158827159201902, 0.10158827159201886, 0.21074153349356714], 
reward next is 0.7893, 
noisyNet noise sample is [array([0.32026973], dtype=float32), 0.99319303]. 
=============================================
[2019-03-27 05:30:59,190] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.3261708e-24 9.9354561e-12 1.3118986e-25 5.2162761e-21], sum to 1.0000
[2019-03-27 05:30:59,200] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0756
[2019-03-27 05:30:59,206] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.26666666666667, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.423009381718165, 6.9112, 6.9112, 168.912956510431, 380504.1474334769, 380504.1474334769, 142831.3274253634], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 598200.0000, 
sim time next is 598800.0000, 
raw observation next is [19.13333333333333, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4218599550317672, 6.911199999999999, 6.9112, 168.912956510431, 379638.9429128517, 379638.9429128523, 142698.5097064168], 
processed observation next is [1.0, 0.9565217391304348, 0.10584518167456543, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.29495116467288685, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10545526192023658, 0.10545526192023674, 0.21298285030808478], 
reward next is 0.7870, 
noisyNet noise sample is [array([-0.5934414], dtype=float32), -0.04320609]. 
=============================================
[2019-03-27 05:31:05,662] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.8561955e-24 1.6752904e-13 3.1397428e-25 4.6139992e-22], sum to 1.0000
[2019-03-27 05:31:05,672] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3091
[2019-03-27 05:31:05,679] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.36666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4057506450991352, 6.9112, 6.9112, 168.912956510431, 365581.386566581, 365581.386566581, 141041.1567107215], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 711600.0000, 
sim time next is 712200.0000, 
raw observation next is [18.58333333333334, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4095085705468701, 6.9112, 6.9112, 168.912956510431, 368721.5013603071, 368721.5013603071, 141434.4279078365], 
processed observation next is [1.0, 0.21739130434782608, 0.07977883096366543, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2798885006669148, 0.0, 0.0, 0.8294399451523027, 0.10242263926675198, 0.10242263926675198, 0.2110961610564724], 
reward next is 0.7889, 
noisyNet noise sample is [array([0.17159392], dtype=float32), -0.7646128]. 
=============================================
[2019-03-27 05:31:17,771] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.2338678e-21 3.5723005e-09 1.9999814e-23 4.0215226e-19], sum to 1.0000
[2019-03-27 05:31:17,782] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8667
[2019-03-27 05:31:17,787] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6663393306102081, 6.9112, 6.9112, 168.912956510431, 572905.3294677648, 572905.3294677648, 176845.1595094771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1041000.0000, 
sim time next is 1041600.0000, 
raw observation next is [22.46666666666667, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6662443098835713, 6.9112, 6.9112, 168.912956510431, 572713.346781979, 572713.346781979, 176829.3259178709], 
processed observation next is [1.0, 0.043478260869565216, 0.2638230647709322, 0.9666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5929808657116723, 0.0, 0.0, 0.8294399451523027, 0.15908704077277194, 0.15908704077277194, 0.2639243670415984], 
reward next is 0.7361, 
noisyNet noise sample is [array([1.0203514], dtype=float32), -1.1478527]. 
=============================================
[2019-03-27 05:31:19,221] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 4.032975e-23 6.465818e-11 5.070725e-26 7.660318e-21], sum to 1.0000
[2019-03-27 05:31:19,229] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2962
[2019-03-27 05:31:19,234] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6121231958338996, 6.911200000000001, 6.9112, 168.912956510431, 531856.6910016238, 531856.6910016232, 167963.0188149585], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 961200.0000, 
sim time next is 961800.0000, 
raw observation next is [21.81666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6032203026680161, 6.911199999999999, 6.9112, 168.912956510431, 524192.5131478327, 524192.5131478332, 166588.8204799306], 
processed observation next is [1.0, 0.13043478260869565, 0.2330173775671408, 0.9383333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5161223203268488, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14560903142995352, 0.14560903142995366, 0.2486400305670606], 
reward next is 0.7514, 
noisyNet noise sample is [array([-1.8491381], dtype=float32), 0.35469997]. 
=============================================
[2019-03-27 05:31:19,969] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 05:31:19,971] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:31:19,972] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:31:19,972] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:31:19,974] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:31:19,974] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:31:19,975] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:31:19,976] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:31:19,977] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:31:19,978] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:31:19,976] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:31:19,997] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run19
[2019-03-27 05:31:20,018] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run19
[2019-03-27 05:31:20,020] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run19
[2019-03-27 05:31:20,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run19
[2019-03-27 05:31:20,090] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run19
[2019-03-27 05:31:28,603] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:28,604] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [17.95468401, 94.81173112, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4330790020548579, 6.9112, 6.9112, 168.912956510431, 388750.2340665614, 388750.2340665614, 143948.2212967723]
[2019-03-27 05:31:28,606] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:31:28,608] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.9651712e-22 3.4988533e-12 6.2265493e-24 7.3685456e-20], sampled 0.7495869731412846
[2019-03-27 05:31:30,559] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:30,561] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.1, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4479734215338007, 6.9112, 6.9112, 168.912956510431, 401307.3486973058, 401307.3486973058, 145614.9817868468]
[2019-03-27 05:31:30,562] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:31:30,563] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.9068083e-22 2.4724951e-11 4.4674668e-24 1.0923455e-19], sampled 0.20842983312002605
[2019-03-27 05:31:32,062] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:32,064] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [18.63812879666667, 87.59340223666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4388029608948463, 6.9112, 6.9112, 168.912956510431, 394308.6424398085, 394308.6424398085, 144524.0017710887]
[2019-03-27 05:31:32,065] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:31:32,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.9685540e-23 5.4454135e-13 7.0190383e-25 1.0516407e-20], sampled 0.6025139839712207
[2019-03-27 05:31:42,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:42,819] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.72605992, 93.45276401, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6260197649083786, 6.9112, 6.9112, 168.912956510431, 544376.4986485406, 544376.4986485406, 170141.7077271152]
[2019-03-27 05:31:42,820] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:31:42,821] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.0833686e-24 2.9803382e-12 8.3616791e-26 2.9232207e-21], sampled 0.29560436861586203
[2019-03-27 05:31:48,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:48,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6895997990146175, 6.911200000000001, 6.9112, 168.912956510431, 586313.7685134024, 586313.7685134019, 180859.44999454]
[2019-03-27 05:31:48,158] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:31:48,167] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999702e-01 1.1473843e-18 2.9869827e-06 1.0080177e-21 4.0004761e-17], sampled 0.6294107401093053
[2019-03-27 05:31:54,282] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:31:54,283] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.68333333333333, 84.83333333333334, 1.0, 2.0, 0.7626785205240949, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1065908.923617191, 1065908.923617191, 234956.3210672544]
[2019-03-27 05:31:54,284] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:31:54,286] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.5513523e-01 3.8726021e-13 4.4864714e-02 4.9158833e-16 6.4730578e-12], sampled 0.9519509216711887
[2019-03-27 05:31:54,286] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1065908.923617191 W.
[2019-03-27 05:32:00,673] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05829443]
[2019-03-27 05:32:00,674] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.53333333333333, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8596979738793841, 6.9112, 6.9112, 168.912956510431, 713351.1662556361, 713351.1662556361, 214410.1053466816]
[2019-03-27 05:32:00,675] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:32:00,678] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 7.6259272e-25 1.8207187e-12 4.6026136e-27 4.1327761e-22], sampled 0.06778067800374787
[2019-03-27 05:33:13,428] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7289.5662 3107376658.4890 1985.0000
[2019-03-27 05:33:13,568] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7005.5778 3186257194.4166 2450.0000
[2019-03-27 05:33:13,770] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7899.6920 2990070014.4546 1554.0000
[2019-03-27 05:33:13,991] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8040.7443 2938609497.1993 1372.0000
[2019-03-27 05:33:14,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7272.5746 3320026587.2056 2143.0000
[2019-03-27 05:33:15,040] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 450000, evaluation results [450000.0, 7272.5745847179505, 3320026587.2056255, 2143.0, 7289.566235464398, 3107376658.4890323, 1985.0, 8040.744273862554, 2938609497.1993375, 1372.0, 7005.577786068991, 3186257194.4165983, 2450.0, 7899.692034814613, 2990070014.4546037, 1554.0]
[2019-03-27 05:33:26,795] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999785e-01 5.6536177e-19 2.1150861e-06 8.5729758e-22 3.9609095e-16], sum to 1.0000
[2019-03-27 05:33:26,803] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5429
[2019-03-27 05:33:26,808] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.85, 61.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5923764684468329, 6.911200000000001, 6.9112, 168.912956510431, 513966.7101941255, 513966.7101941248, 164957.1763733359], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1187400.0000, 
sim time next is 1188000.0000, 
raw observation next is [26.7, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.598079246337168, 6.9112, 6.9112, 168.912956510431, 518897.0400071052, 518897.0400071052, 165817.9095616101], 
processed observation next is [1.0, 0.782608695652174, 0.46445497630331756, 0.62, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5098527394355707, 0.0, 0.0, 0.8294399451523027, 0.14413806666864035, 0.14413806666864035, 0.2474894172561345], 
reward next is 0.7525, 
noisyNet noise sample is [array([-0.38804102], dtype=float32), 1.4754088]. 
=============================================
[2019-03-27 05:33:26,821] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[70.11385 ]
 [67.708   ]
 [64.394295]
 [60.301807]
 [55.901546]], R is [[72.18917084]
 [72.22106934]
 [72.25436401]
 [72.28879547]
 [71.56591034]].
[2019-03-27 05:33:29,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0368898e-20 9.6147712e-10 8.5965354e-23 4.5759367e-18], sum to 1.0000
[2019-03-27 05:33:29,140] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6532
[2019-03-27 05:33:29,144] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6161592864884222, 6.911199999999999, 6.9112, 168.912956510431, 535479.6854406107, 535479.6854406114, 168590.7158082771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1212600.0000, 
sim time next is 1213200.0000, 
raw observation next is [22.4, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6159219526818492, 6.911200000000001, 6.9112, 168.912956510431, 535339.9796372114, 535339.9796372108, 168552.5006688212], 
processed observation next is [1.0, 0.043478260869565216, 0.2606635071090047, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5316121374168893, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14870554989922538, 0.14870554989922524, 0.25157089652062864], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.03254177], dtype=float32), -0.22486646]. 
=============================================
[2019-03-27 05:33:32,042] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.6357002e-23 4.1987827e-09 1.3449621e-26 1.3938666e-21], sum to 1.0000
[2019-03-27 05:33:32,052] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6185
[2019-03-27 05:33:32,059] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.45, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7984145284325453, 6.9112, 6.9112, 168.912956510431, 668955.3979834877, 668955.3979834877, 201501.5232456453], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1276200.0000, 
sim time next is 1276800.0000, 
raw observation next is [26.3, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7943488299692352, 6.9112, 6.9112, 168.912956510431, 665988.6470284841, 665988.6470284841, 200677.9281702838], 
processed observation next is [1.0, 0.782608695652174, 0.4454976303317536, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7492058902063844, 0.0, 0.0, 0.8294399451523027, 0.18499684639680114, 0.18499684639680114, 0.29951929577654296], 
reward next is 0.7005, 
noisyNet noise sample is [array([1.2403303], dtype=float32), 0.1305781]. 
=============================================
[2019-03-27 05:33:43,693] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.1102127e-23 5.7911041e-11 3.9651024e-25 1.0732383e-19], sum to 1.0000
[2019-03-27 05:33:43,703] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4666
[2019-03-27 05:33:43,709] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.56666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7138552881100884, 6.911199999999999, 6.9112, 168.912956510431, 608421.2986899934, 608421.2986899941, 185230.0703456559], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1448400.0000, 
sim time next is 1449000.0000, 
raw observation next is [25.3, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7108597746646467, 6.9112, 6.9112, 168.912956510431, 606327.0677499193, 606327.0677499193, 184685.6115626329], 
processed observation next is [0.0, 0.782608695652174, 0.39810426540284366, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6473899691032275, 0.0, 0.0, 0.8294399451523027, 0.16842418548608867, 0.16842418548608867, 0.2756501665113924], 
reward next is 0.7243, 
noisyNet noise sample is [array([-0.7524001], dtype=float32), -3.0086346]. 
=============================================
[2019-03-27 05:33:43,724] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.66932]
 [76.65561]
 [76.61942]
 [76.60153]
 [76.6013 ]], R is [[76.63838196]
 [76.59553528]
 [76.55342102]
 [76.51070404]
 [76.46755219]].
[2019-03-27 05:33:45,697] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.5716437e-22 1.0320443e-08 3.2453119e-23 1.9764145e-18], sum to 1.0000
[2019-03-27 05:33:45,707] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9290
[2019-03-27 05:33:45,713] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.1, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6125517574461745, 6.911200000000001, 6.9112, 168.912956510431, 531896.1454583206, 531896.14545832, 168034.7175471446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1530000.0000, 
sim time next is 1530600.0000, 
raw observation next is [26.9, 60.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6124015664041025, 6.9112, 6.9112, 168.912956510431, 531968.7533513719, 531968.7533513719, 168008.329200063], 
processed observation next is [0.0, 0.7391304347826086, 0.4739336492890995, 0.6016666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5273189834196371, 0.0, 0.0, 0.8294399451523027, 0.14776909815315883, 0.14776909815315883, 0.2507587002986015], 
reward next is 0.7492, 
noisyNet noise sample is [array([0.8741769], dtype=float32), 0.57001686]. 
=============================================
[2019-03-27 05:33:46,285] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1279950e-22 1.6217501e-10 1.8317950e-24 7.6638620e-19], sum to 1.0000
[2019-03-27 05:33:46,301] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8723
[2019-03-27 05:33:46,307] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 96.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767239985345034, 6.9112, 6.9112, 168.912956510431, 504130.242019396, 504130.242019396, 162571.1722910131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [21.28333333333333, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5834120949782879, 6.9112, 6.9112, 168.912956510431, 509261.1217800895, 509261.1217800895, 163568.1984000275], 
processed observation next is [0.0, 0.21739130434782608, 0.20774091627172192, 0.9566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49196596948571697, 0.0, 0.0, 0.8294399451523027, 0.14146142271669154, 0.14146142271669154, 0.24413163940302612], 
reward next is 0.7559, 
noisyNet noise sample is [array([-1.1977954], dtype=float32), -0.52387667]. 
=============================================
[2019-03-27 05:33:48,586] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.9532580e-22 1.4591861e-10 6.8222905e-25 2.0958938e-20], sum to 1.0000
[2019-03-27 05:33:48,594] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3435
[2019-03-27 05:33:48,601] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666666, 71.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6231479969884592, 6.9112, 6.9112, 168.912956510431, 540471.1066668897, 540471.1066668897, 169707.2580428412], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1536000.0000, 
sim time next is 1536600.0000, 
raw observation next is [24.98333333333333, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6248898302427921, 6.911200000000001, 6.9112, 168.912956510431, 541815.6587861801, 541815.6587861795, 169985.8643012404], 
processed observation next is [0.0, 0.782608695652174, 0.3830963665086887, 0.7266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5425485734668196, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1505043496628278, 0.15050434966282764, 0.25371024522573193], 
reward next is 0.7463, 
noisyNet noise sample is [array([0.36963806], dtype=float32), 0.65822387]. 
=============================================
[2019-03-27 05:33:53,499] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [4.6034905e-01 5.2847331e-14 5.3965092e-01 2.5186128e-18 6.6070440e-14], sum to 1.0000
[2019-03-27 05:33:53,507] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4129
[2019-03-27 05:33:53,513] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 96.0, 1.0, 2.0, 0.2007604984081194, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3461547996865137, 6.911199999999999, 6.9112, 168.912956510431, 590660.1738120958, 590660.1738120964, 198107.1812492756], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1618800.0000, 
sim time next is 1619400.0000, 
raw observation next is [23.08333333333334, 96.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6990567753295746, 6.9112, 6.9112, 168.912956510431, 596656.750383481, 596656.750383481, 182555.4489691344], 
processed observation next is [1.0, 0.7391304347826086, 0.2930489731437602, 0.96, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6329960674750909, 0.0, 0.0, 0.8294399451523027, 0.1657379862176336, 0.1657379862176336, 0.272470819356917], 
reward next is 0.7275, 
noisyNet noise sample is [array([-1.3879821], dtype=float32), -1.189034]. 
=============================================
[2019-03-27 05:33:54,926] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999976e-01 1.1595039e-20 2.9154234e-07 1.0619712e-23 3.0490210e-18], sum to 1.0000
[2019-03-27 05:33:54,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9505
[2019-03-27 05:33:54,939] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.11666666666667, 98.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227695064910701, 6.9112, 6.9112, 168.912956510431, 615138.4424327402, 615138.4424327402, 186866.4878507637], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1642200.0000, 
sim time next is 1642800.0000, 
raw observation next is [23.13333333333333, 98.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7243473157645711, 6.9112, 6.9112, 168.912956510431, 616241.6862204515, 616241.6862204515, 187157.5439164707], 
processed observation next is [1.0, 0.0, 0.29541864139020524, 0.9833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6638381899567939, 0.0, 0.0, 0.8294399451523027, 0.17117824617234764, 0.17117824617234764, 0.27933961778577715], 
reward next is 0.7207, 
noisyNet noise sample is [array([-0.79217154], dtype=float32), -0.56469345]. 
=============================================
[2019-03-27 05:34:04,601] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 1.1973104e-20 9.2198157e-08 1.3858855e-23 1.5046726e-18], sum to 1.0000
[2019-03-27 05:34:04,611] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2153
[2019-03-27 05:34:04,621] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.2, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6866174292721066, 6.9112, 6.9112, 168.912956510431, 589394.8802071229, 589394.8802071229, 180354.6107160611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1839600.0000, 
sim time next is 1840200.0000, 
raw observation next is [23.31666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8420541744934633, 6.911200000000001, 6.9112, 168.912956510431, 722343.5373102932, 722343.5373102926, 210933.636299046], 
processed observation next is [1.0, 0.30434782608695654, 0.30410742496050575, 0.9166666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8073831396261748, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20065098258619254, 0.20065098258619238, 0.314826322834397], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.7683749], dtype=float32), -0.30135438]. 
=============================================
[2019-03-27 05:34:08,282] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9691641e-01 4.4399304e-18 3.0836232e-03 5.2680513e-23 3.7569286e-16], sum to 1.0000
[2019-03-27 05:34:08,290] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2072
[2019-03-27 05:34:08,296] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666666, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8319723827138097, 6.9112, 6.9112, 168.912956510431, 687960.0018907437, 687960.0018907437, 208288.7021108513], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1878000.0000, 
sim time next is 1878600.0000, 
raw observation next is [26.48333333333333, 87.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8350512775702167, 6.9112, 6.9112, 168.912956510431, 691619.6584573638, 691619.6584573638, 208986.3246195336], 
processed observation next is [1.0, 0.7391304347826086, 0.4541864139020536, 0.8716666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7988430214270934, 0.0, 0.0, 0.8294399451523027, 0.19211657179371217, 0.19211657179371217, 0.3119198874918412], 
reward next is 0.6881, 
noisyNet noise sample is [array([0.6755422], dtype=float32), -0.14389403]. 
=============================================
[2019-03-27 05:34:09,171] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.8899274e-21 3.8266190e-08 6.3831834e-25 1.3536355e-18], sum to 1.0000
[2019-03-27 05:34:09,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4251
[2019-03-27 05:34:09,185] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.65, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7640737573668032, 6.9112, 6.9112, 168.912956510431, 645650.7652913006, 645650.7652913006, 194703.5863013199], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1894200.0000, 
sim time next is 1894800.0000, 
raw observation next is [24.6, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7639935194344392, 6.911200000000001, 6.9112, 168.912956510431, 645650.2503282651, 645650.2503282645, 194688.818911223], 
processed observation next is [1.0, 0.9565217391304348, 0.36492890995260674, 0.9066666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7121872188224868, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1793472917578514, 0.17934729175785127, 0.29058032673316864], 
reward next is 0.7094, 
noisyNet noise sample is [array([-1.0789634], dtype=float32), 0.27217177]. 
=============================================
[2019-03-27 05:34:09,768] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 05:34:09,771] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:34:09,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:34:09,772] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:34:09,773] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:34:09,776] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:34:09,777] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:34:09,778] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:34:09,776] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:34:09,778] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:34:09,779] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:34:09,786] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run20
[2019-03-27 05:34:09,806] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run20
[2019-03-27 05:34:09,825] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run20
[2019-03-27 05:34:09,844] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run20
[2019-03-27 05:34:09,871] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run20
[2019-03-27 05:34:31,719] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:34:31,719] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.45, 55.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6421099761948695, 6.9112, 6.9112, 168.912956510431, 554235.9988482147, 554235.9988482147, 172788.706681928]
[2019-03-27 05:34:31,721] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:34:31,724] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.4918593e-21 3.3342116e-09 1.7259540e-23 1.1731374e-18], sampled 0.8985241974052118
[2019-03-27 05:34:37,364] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:34:37,365] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.56588244, 97.16564531, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8042182600166462, 6.9112, 6.9112, 168.912956510431, 675758.4876593753, 675758.4876593753, 202741.5861737446]
[2019-03-27 05:34:37,367] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:34:37,369] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.9267466e-21 4.3022417e-09 7.1489660e-24 6.1875674e-19], sampled 0.74257081998725
[2019-03-27 05:34:44,769] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:34:44,771] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.97729449333333, 93.83087187333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8263865468231624, 6.911199999999999, 6.9112, 168.912956510431, 692048.9767340294, 692048.97673403, 207348.8966035529]
[2019-03-27 05:34:44,772] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:34:44,778] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.4233277e-21 3.0641765e-09 4.2190932e-24 3.4038552e-19], sampled 0.9996834590796161
[2019-03-27 05:34:54,005] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:34:54,006] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.1, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9791742461590256, 6.9112, 6.9112, 168.912956510431, 792205.550931609, 792205.550931609, 241908.0876523854]
[2019-03-27 05:34:54,007] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:34:54,014] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999952e-01 1.3723091e-20 4.1956187e-07 9.9225883e-24 1.2336556e-18], sampled 0.7237512088011763
[2019-03-27 05:35:10,329] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:35:10,330] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.99655709333334, 66.67411804666666, 1.0, 2.0, 0.6759298461894966, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 944616.2583719897, 944616.2583719897, 215746.5452520657]
[2019-03-27 05:35:10,331] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:35:10,335] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3885756e-01 2.5629856e-16 6.1142460e-02 5.2815718e-20 1.2292638e-14], sampled 0.18263374315051828
[2019-03-27 05:35:10,336] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 944616.2583719897 W.
[2019-03-27 05:35:22,170] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:35:22,171] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.84589028333333, 84.90444477666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8015277193241909, 6.911199999999999, 6.9112, 168.912956510431, 674704.685236273, 674704.6852362737, 202208.5412700025]
[2019-03-27 05:35:22,172] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:35:22,176] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.4340690e-22 2.8029562e-10 6.5391944e-25 5.5701386e-20], sampled 0.3729921283139712
[2019-03-27 05:35:27,079] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:35:27,081] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.7, 76.0, 1.0, 2.0, 0.6041191354007679, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.92537866115781, 6.9112, 168.9127608052028, 1689112.453814024, 1679053.635251138, 365629.3637552408]
[2019-03-27 05:35:27,083] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:35:27,085] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9198216e-01 2.9571737e-17 8.0178706e-03 3.9837846e-21 6.2057482e-16], sampled 0.026837182522905012
[2019-03-27 05:35:27,090] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1689112.453814024 W.
[2019-03-27 05:35:49,880] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05802497]
[2019-03-27 05:35:49,882] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.9, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9572518060748201, 6.9112, 6.9112, 168.912956510431, 779613.9032347805, 779613.9032347805, 236704.9365778381]
[2019-03-27 05:35:49,886] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:35:49,890] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.5702414e-22 7.6344847e-10 4.2141369e-25 5.1696274e-20], sampled 0.5338648989046147
[2019-03-27 05:36:03,917] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7831.7383 2946881157.4104 1283.0000
[2019-03-27 05:36:04,258] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7106.6099 3119390004.4167 1824.0000
[2019-03-27 05:36:04,417] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7770.8672 2997725473.3492 1445.0000
[2019-03-27 05:36:04,424] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7121.5688 3325759008.4321 2079.0000
[2019-03-27 05:36:04,450] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6825.5153 3196328002.3738 2308.0000
[2019-03-27 05:36:05,465] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 475000, evaluation results [475000.0, 7121.568778528733, 3325759008.432072, 2079.0, 7106.609886366671, 3119390004.416747, 1824.0, 7831.738282314059, 2946881157.4104314, 1283.0, 6825.515270535027, 3196328002.373815, 2308.0, 7770.867230630513, 2997725473.349182, 1445.0]
[2019-03-27 05:36:16,594] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 7.7943143e-22 2.4191169e-10 8.1554420e-24 2.9295183e-20], sum to 1.0000
[2019-03-27 05:36:16,606] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6699
[2019-03-27 05:36:16,610] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.763919515928722, 6.911199999999999, 6.9112, 168.912956510431, 644345.0983357441, 644345.0983357447, 194654.8579162625], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2091600.0000, 
sim time next is 2092200.0000, 
raw observation next is [23.93333333333334, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7659721628948796, 6.9112, 6.9112, 168.912956510431, 645876.5576527448, 645876.5576527448, 195055.3185342216], 
processed observation next is [0.0, 0.21739130434782608, 0.3333333333333337, 0.975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7146001986522921, 0.0, 0.0, 0.8294399451523027, 0.17941015490354023, 0.17941015490354023, 0.29112734109585314], 
reward next is 0.7089, 
noisyNet noise sample is [array([0.55991083], dtype=float32), 0.5371834]. 
=============================================
[2019-03-27 05:36:20,538] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 7.3826690e-20 6.8299265e-08 5.6734725e-23 1.0949205e-17], sum to 1.0000
[2019-03-27 05:36:20,547] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9530
[2019-03-27 05:36:20,556] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.43333333333334, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9345955396380488, 6.9112, 6.9112, 168.912956510431, 763062.308261928, 763062.308261928, 231270.196116784], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2146800.0000, 
sim time next is 2147400.0000, 
raw observation next is [27.35, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9319216133017346, 6.9112, 6.9112, 168.912956510431, 761301.3853222206, 761301.3853222206, 230646.2589403971], 
processed observation next is [0.0, 0.8695652173913043, 0.4952606635071091, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9169775771972372, 0.0, 0.0, 0.8294399451523027, 0.21147260703395018, 0.21147260703395018, 0.34424814767223444], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.03135728], dtype=float32), -0.09951697]. 
=============================================
[2019-03-27 05:36:21,421] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9871683e-01 7.0570676e-17 1.2831423e-03 9.6717503e-21 4.1413846e-14], sum to 1.0000
[2019-03-27 05:36:21,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6935
[2019-03-27 05:36:21,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.36666666666667, 93.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9663088225065753, 6.9112, 6.9112, 168.912956510431, 804895.7936268034, 804895.7936268034, 239680.9339303595], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2180400.0000, 
sim time next is 2181000.0000, 
raw observation next is [25.58333333333333, 92.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9881126582468286, 6.911199999999999, 6.9112, 168.912956510431, 821822.250041263, 821822.2500412636, 245169.1863285771], 
processed observation next is [1.0, 0.21739130434782608, 0.41153238546603454, 0.9283333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9855032417644249, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22828395834479526, 0.22828395834479545, 0.36592415869936884], 
reward next is 0.6341, 
noisyNet noise sample is [array([-0.33600515], dtype=float32), -0.26818824]. 
=============================================
[2019-03-27 05:36:21,457] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[59.394882]
 [58.115105]
 [56.877605]
 [54.423943]
 [52.00742 ]], R is [[60.17515182]
 [60.21567154]
 [60.264328  ]
 [60.3188858 ]
 [60.38490677]].
[2019-03-27 05:36:31,129] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8009378e-01 6.4024276e-17 1.9906260e-02 1.5159928e-20 1.5514283e-13], sum to 1.0000
[2019-03-27 05:36:31,134] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8509
[2019-03-27 05:36:31,139] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666667, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9154578769600649, 6.9112, 6.9112, 168.912956510431, 750590.1287718669, 750590.1287718669, 226847.0066363222], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2335200.0000, 
sim time next is 2335800.0000, 
raw observation next is [28.13333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9125529466141875, 6.9112, 6.9112, 168.912956510431, 748577.4894066376, 748577.4894066376, 226177.96164861], 
processed observation next is [1.0, 0.0, 0.532385466034755, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8933572519685213, 0.0, 0.0, 0.8294399451523027, 0.20793819150184378, 0.20793819150184378, 0.3375790472367314], 
reward next is 0.6624, 
noisyNet noise sample is [array([-0.31855533], dtype=float32), 0.878564]. 
=============================================
[2019-03-27 05:36:31,291] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7678818e-01 3.1595256e-13 7.2321182e-01 2.1865697e-17 6.2234544e-11], sum to 1.0000
[2019-03-27 05:36:31,301] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5555
[2019-03-27 05:36:31,306] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.3, 82.0, 1.0, 2.0, 0.3352426337038585, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5662066306109291, 6.911200000000001, 6.9112, 168.912956510431, 937004.0683421745, 937004.0683421738, 232069.9875811948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2347200.0000, 
sim time next is 2347800.0000, 
raw observation next is [27.26666666666667, 82.00000000000001, 1.0, 2.0, 0.3476276980610861, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5868324364445608, 6.911200000000001, 6.9112, 168.912956510431, 971636.1919683645, 971636.191968364, 236418.717911826], 
processed observation next is [1.0, 0.17391304347826086, 0.4913112164297, 0.8200000000000002, 1.0, 1.0, 0.2140092747723929, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4961371176153181, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2698989422134346, 0.2698989422134344, 0.35286375807735226], 
reward next is 0.6471, 
noisyNet noise sample is [array([0.42135915], dtype=float32), -1.1201637]. 
=============================================
[2019-03-27 05:36:34,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.0991958e-07 2.1744217e-12 9.9999917e-01 3.1905946e-18 3.0759729e-13], sum to 1.0000
[2019-03-27 05:36:34,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0298
[2019-03-27 05:36:34,365] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2714880.012498984 W.
[2019-03-27 05:36:34,371] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.03333333333333, 61.33333333333333, 1.0, 2.0, 0.6529070805503143, 1.0, 2.0, 0.6470435797894196, 1.0, 1.0, 1.03, 7.005094019216934, 6.9112, 170.5573041426782, 2714880.012498984, 2647619.907169388, 506865.9352156678], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2389200.0000, 
sim time next is 2389800.0000, 
raw observation next is [33.06666666666667, 61.16666666666666, 1.0, 2.0, 0.957132718851072, 1.0, 2.0, 0.957132718851072, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2677265.739929062, 2677265.739929062, 503620.4376846658], 
processed observation next is [1.0, 0.6521739130434783, 0.7661927330173778, 0.6116666666666666, 1.0, 1.0, 0.9483526733145445, 1.0, 1.0, 0.9483526733145445, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7436849277580727, 0.7436849277580727, 0.7516722950517399], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.19814852], dtype=float32), 0.17326474]. 
=============================================
[2019-03-27 05:36:35,173] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [6.2707454e-01 1.7289672e-14 3.7292552e-01 7.2476421e-20 6.0499701e-14], sum to 1.0000
[2019-03-27 05:36:35,185] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0438
[2019-03-27 05:36:35,190] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.7, 69.0, 1.0, 1.0, 0.2886661864996434, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5013177025832394, 6.9112, 6.9112, 168.912956510431, 806773.329155256, 806773.329155256, 218385.0822558163], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2401200.0000, 
sim time next is 2401800.0000, 
raw observation next is [31.56666666666667, 69.83333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.017831898815744, 6.9112, 6.9112, 168.912855906226, 819005.9439903721, 819005.9439903721, 251602.1460398235], 
processed observation next is [1.0, 0.8260869565217391, 0.6951026856240128, 0.6983333333333333, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0217462180679804, 0.0, 0.0, 0.8294394511395994, 0.2275016511084367, 0.2275016511084367, 0.3755255911042142], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1641966], dtype=float32), 4.0331883]. 
=============================================
[2019-03-27 05:36:37,247] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.8536528e-01 3.7221580e-12 6.1463469e-01 2.8114903e-17 2.4144863e-11], sum to 1.0000
[2019-03-27 05:36:37,256] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4987
[2019-03-27 05:36:37,264] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.7, 85.5, 1.0, 2.0, 0.2492027919552801, 1.0, 2.0, 0.2492027919552801, 1.0, 1.0, 0.4288367671514204, 6.9112, 6.9112, 170.5573041426782, 1044831.781282468, 1044831.781282468, 284838.8769416506], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2446200.0000, 
sim time next is 2446800.0000, 
raw observation next is [27.7, 85.66666666666666, 1.0, 2.0, 0.3685640780568372, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6318512297426345, 6.911199999999999, 6.9112, 168.912956510431, 1030182.767817739, 1030182.767817739, 245488.8755849282], 
processed observation next is [1.0, 0.30434782608695654, 0.5118483412322274, 0.8566666666666666, 1.0, 1.0, 0.23923382898414122, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.5510380850519933, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.286161879949372, 0.286161879949372, 0.3664013068431764], 
reward next is 0.6336, 
noisyNet noise sample is [array([0.35332868], dtype=float32), 1.7623082]. 
=============================================
[2019-03-27 05:36:38,891] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [5.8157265e-04 5.6039662e-15 9.9941850e-01 2.0247296e-20 7.0839046e-14], sum to 1.0000
[2019-03-27 05:36:38,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1269
[2019-03-27 05:36:38,907] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 89.0, 1.0, 2.0, 0.764524631094201, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.97420034173336, 6.9112, 168.9125312610209, 1965425.43340342, 1920730.935194958, 400357.2553441089], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2467800.0000, 
sim time next is 2468400.0000, 
raw observation next is [26.33333333333333, 89.0, 1.0, 2.0, 0.8062726094872068, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.974885982296447, 6.9112, 168.9125263960423, 2023852.212269042, 1978671.299573074, 410465.5730005435], 
processed observation next is [1.0, 0.5652173913043478, 0.44707740916271704, 0.89, 1.0, 1.0, 0.7665935054062732, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006368598229644728, 0.0, 0.829437833093747, 0.5621811700747339, 0.5496309165480762, 0.6126351835829008], 
reward next is 0.0689, 
noisyNet noise sample is [array([-0.2527629], dtype=float32), -0.6066046]. 
=============================================
[2019-03-27 05:36:50,080] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.8423861e-23 2.9800044e-11 8.7069891e-25 1.8961710e-20], sum to 1.0000
[2019-03-27 05:36:50,089] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8124
[2019-03-27 05:36:50,094] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7436403778910662, 6.9112, 6.9112, 168.912956510431, 630808.7300177492, 630808.7300177492, 190775.8668304844], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2710800.0000, 
sim time next is 2711400.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.738612331635632, 6.9112, 6.9112, 168.912956510431, 627312.4138143113, 627312.4138143113, 189826.7958957655], 
processed observation next is [0.0, 0.391304347826087, 0.28909952606635075, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6812345507751608, 0.0, 0.0, 0.8294399451523027, 0.17425344828175313, 0.17425344828175313, 0.2833235759638291], 
reward next is 0.7167, 
noisyNet noise sample is [array([-0.19314417], dtype=float32), 1.1690247]. 
=============================================
[2019-03-27 05:36:54,845] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.3549604e-22 1.1627812e-10 4.1704323e-24 2.8924848e-20], sum to 1.0000
[2019-03-27 05:36:54,851] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0727
[2019-03-27 05:36:54,858] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6856938487638012, 6.9112, 6.9112, 168.912956510431, 587940.3788081201, 587940.3788081201, 180192.9520251957], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2740800.0000, 
sim time next is 2741400.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.685138963578686, 6.911199999999999, 6.9112, 168.912956510431, 587464.4672788494, 587464.46727885, 180095.6371858319], 
processed observation next is [0.0, 0.7391304347826086, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6160231263154707, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16318457424412486, 0.163184574244125, 0.26879945848631626], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.31318492], dtype=float32), 0.771989]. 
=============================================
[2019-03-27 05:37:00,226] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 05:37:00,230] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:37:00,231] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:37:00,231] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:37:00,232] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:37:00,233] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:37:00,234] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:37:00,235] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:37:00,235] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:37:00,236] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:37:00,236] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:37:00,243] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run21
[2019-03-27 05:37:00,244] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run21
[2019-03-27 05:37:00,281] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run21
[2019-03-27 05:37:00,282] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run21
[2019-03-27 05:37:00,299] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run21
[2019-03-27 05:37:22,004] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:37:22,005] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.7, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5085575237990139, 6.9112, 6.9112, 168.912956510431, 451218.0673523485, 451218.0673523485, 153030.0218114337]
[2019-03-27 05:37:22,006] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:37:22,010] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.3502032e-22 7.2252139e-12 1.4948051e-24 4.7031764e-20], sampled 0.7320742817270207
[2019-03-27 05:37:45,853] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:37:45,855] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.7574378, 91.095974465, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9470073772159371, 6.9112, 6.9112, 168.9129564970538, 770968.219401033, 770968.219401033, 234174.8890300681]
[2019-03-27 05:37:45,857] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:37:45,860] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 4.4195885e-21 8.5464180e-10 2.2213910e-23 9.4524224e-19], sampled 0.3672526507040976
[2019-03-27 05:37:55,350] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:37:55,351] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9453573407998795, 6.911199999999999, 6.9112, 168.912956510431, 768858.2356942953, 768858.2356942958, 233735.3438293602]
[2019-03-27 05:37:55,352] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:37:55,354] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.7289654e-23 2.1123658e-11 6.8238225e-26 5.3299839e-21], sampled 0.6771802895513371
[2019-03-27 05:38:22,747] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:38:22,748] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.42157446, 81.99031549333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8803537135493649, 6.911199999999999, 6.9112, 168.912956510431, 728721.4883634148, 728721.4883634154, 218987.8896699967]
[2019-03-27 05:38:22,749] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:38:22,754] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.9316563e-24 2.0158287e-12 7.9540591e-27 9.4955225e-22], sampled 0.9709632759473514
[2019-03-27 05:38:33,136] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:38:33,137] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.22856916666667, 83.89227437, 1.0, 2.0, 0.8729324537735398, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.993037847136689, 6.9112, 168.9124704934733, 2117150.107410286, 2059091.689063439, 427150.3799152666]
[2019-03-27 05:38:33,138] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:38:33,140] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9999857e-01 6.5697873e-18 1.3932506e-06 8.2537172e-21 1.1769835e-15], sampled 0.5999565589031404
[2019-03-27 05:38:33,142] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2117150.107410286 W.
[2019-03-27 05:38:37,484] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05844165]
[2019-03-27 05:38:37,485] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.64455652, 70.03909190666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6031732266729519, 6.9112, 6.9112, 168.912956510431, 526647.0248060965, 526647.0248060965, 166533.084570741]
[2019-03-27 05:38:37,488] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:38:37,490] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.2315002e-22 3.1734206e-11 5.4993328e-25 3.2943114e-20], sampled 0.9996592853284035
[2019-03-27 05:38:54,846] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7869.0151 2990568950.6844 1530.0000
[2019-03-27 05:38:55,069] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7224.2479 3109502388.3099 1947.0000
[2019-03-27 05:38:55,197] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8010.8349 2939737784.1891 1349.0000
[2019-03-27 05:38:55,274] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7257.8095 3319936367.5834 2135.0000
[2019-03-27 05:38:55,305] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6973.6518 3187369620.5863 2440.0000
[2019-03-27 05:38:56,318] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 500000, evaluation results [500000.0, 7257.809459922183, 3319936367.583365, 2135.0, 7224.2479055483045, 3109502388.3099256, 1947.0, 8010.834930743644, 2939737784.189133, 1349.0, 6973.6518047237905, 3187369620.5863442, 2440.0, 7869.015143473058, 2990568950.684358, 1530.0]
[2019-03-27 05:38:57,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.5335908e-21 1.7209969e-08 3.3418451e-24 2.6397354e-18], sum to 1.0000
[2019-03-27 05:38:57,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1538
[2019-03-27 05:38:57,396] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6217136848221602, 6.9112, 6.9112, 168.912956510431, 539133.7468120259, 539133.7468120259, 169481.5027300552], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2854200.0000, 
sim time next is 2854800.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6208070528526176, 6.9112, 6.9112, 168.912956510431, 538347.7601012872, 538347.7601012872, 169338.3092547679], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5375695766495336, 0.0, 0.0, 0.8294399451523027, 0.14954104447257976, 0.14954104447257976, 0.25274374515637], 
reward next is 0.7473, 
noisyNet noise sample is [array([0.02660695], dtype=float32), -0.3297254]. 
=============================================
[2019-03-27 05:38:59,118] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.1160492e-23 8.1284241e-12 1.4156465e-25 6.5603202e-21], sum to 1.0000
[2019-03-27 05:38:59,126] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6282
[2019-03-27 05:38:59,131] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6126987715572473, 6.911199999999999, 6.9112, 168.912956510431, 531314.878465243, 531314.8784652436, 168067.615193012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2877600.0000, 
sim time next is 2878200.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6132655979474249, 6.9112, 6.9112, 168.912956510431, 531806.5372556624, 531806.5372556624, 168155.8677166398], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5283726804236888, 0.0, 0.0, 0.8294399451523027, 0.1477240381265729, 0.1477240381265729, 0.2509789070397609], 
reward next is 0.7490, 
noisyNet noise sample is [array([2.6671867], dtype=float32), -0.6307587]. 
=============================================
[2019-03-27 05:38:59,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.3119943e-23 7.6065446e-11 8.0613775e-25 6.3450362e-20], sum to 1.0000
[2019-03-27 05:38:59,420] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5620
[2019-03-27 05:38:59,426] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5479481593072838, 6.9112, 6.9112, 168.912956510431, 481525.9147603776, 481525.9147603776, 158419.4026090509], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2940000.0000, 
sim time next is 2940600.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5477787015136392, 6.911200000000001, 6.9112, 168.912956510431, 481377.9521034923, 481377.9521034916, 158396.0271086831], 
processed observation next is [1.0, 0.0, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.44851061160199895, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13371609780652563, 0.13371609780652544, 0.2364119807592285], 
reward next is 0.7636, 
noisyNet noise sample is [array([1.1355729], dtype=float32), 0.2805747]. 
=============================================
[2019-03-27 05:39:05,399] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.7658664e-21 8.0948315e-09 2.7317114e-23 1.2652799e-17], sum to 1.0000
[2019-03-27 05:39:05,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1710
[2019-03-27 05:39:05,417] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1001148.579441502 W.
[2019-03-27 05:39:05,423] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.0, 94.00000000000001, 1.0, 2.0, 0.2142367318664935, 1.0, 1.0, 0.2142367318664935, 1.0, 1.0, 0.3832667347482924, 6.911199999999999, 6.9112, 170.5573041426782, 1001148.579441502, 1001148.579441503, 285141.7040597756], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2992200.0000, 
sim time next is 2992800.0000, 
raw observation next is [21.0, 94.0, 1.0, 2.0, 0.2864082629079174, 0.0, 1.0, 0.0, 1.0, 2.0, 0.514825162315323, 6.911199999999999, 6.9112, 168.912956510431, 899290.952220272, 899290.9522202727, 226341.39066782], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.94, 1.0, 1.0, 0.1402509191661655, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.4083233686772232, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2498030422834089, 0.2498030422834091, 0.337822971146], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09127442], dtype=float32), 1.0400561]. 
=============================================
[2019-03-27 05:39:08,145] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.3999370e-24 2.9071593e-12 5.0502648e-25 3.8558483e-21], sum to 1.0000
[2019-03-27 05:39:08,154] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5976
[2019-03-27 05:39:08,159] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5566488615073304, 6.911199999999999, 6.9112, 168.912956510431, 486999.0640897314, 486999.064089732, 159690.0244543588], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3039600.0000, 
sim time next is 3040200.0000, 
raw observation next is [21.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5672514418454013, 6.911199999999999, 6.9112, 168.912956510431, 495703.1224979213, 495703.1224979219, 161206.3202460381], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.97, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47225785590902597, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13769531180497813, 0.13769531180497832, 0.24060644812841508], 
reward next is 0.7594, 
noisyNet noise sample is [array([-0.5095353], dtype=float32), 0.2950264]. 
=============================================
[2019-03-27 05:39:23,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.4036026e-21 4.1107673e-09 3.4501390e-23 4.4367238e-18], sum to 1.0000
[2019-03-27 05:39:23,832] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1317
[2019-03-27 05:39:23,836] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.939955061600089, 6.9112, 6.9112, 168.912956510431, 767159.5323086154, 767159.5323086154, 232552.4988368445], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3355200.0000, 
sim time next is 3355800.0000, 
raw observation next is [28.0, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9339211347468696, 6.9112, 6.9112, 168.912956510431, 763123.1049005303, 763123.1049005303, 231135.7939296213], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9194160179839871, 0.0, 0.0, 0.8294399451523027, 0.21197864025014732, 0.21197864025014732, 0.34497879690988253], 
reward next is 0.6550, 
noisyNet noise sample is [array([0.39064354], dtype=float32), 0.54278874]. 
=============================================
[2019-03-27 05:39:28,952] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2332428e-01 1.4226235e-13 7.7667570e-01 1.1316039e-17 1.3308998e-11], sum to 1.0000
[2019-03-27 05:39:28,962] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7402
[2019-03-27 05:39:28,966] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.7706807539857006, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1077098.406093335, 1077098.406093336, 236840.5662310966], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3384000.0000, 
sim time next is 3384600.0000, 
raw observation next is [26.0, 94.00000000000001, 1.0, 2.0, 0.4187955248799307, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7115019962951677, 6.9112, 6.9112, 168.912956510431, 1170663.348445308, 1170663.348445308, 265466.5086699492], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.9400000000000002, 1.0, 1.0, 0.2997536444336515, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.6481731662136191, 0.0, 0.0, 0.8294399451523027, 0.32518426345703, 0.32518426345703, 0.3962186696566406], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08646042], dtype=float32), 1.1488096]. 
=============================================
[2019-03-27 05:39:35,953] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.9242064e-03 1.9078043e-14 9.9307585e-01 3.6423234e-19 1.7358012e-13], sum to 1.0000
[2019-03-27 05:39:35,962] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0927
[2019-03-27 05:39:35,968] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.5, 77.0, 1.0, 2.0, 0.2776083654970492, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4784942219080873, 6.9112, 6.9112, 168.912956510431, 775857.2964768948, 775857.2964768948, 214708.0430507581], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3526200.0000, 
sim time next is 3526800.0000, 
raw observation next is [29.33333333333334, 77.66666666666667, 1.0, 2.0, 0.2773881484936052, 0.0, 2.0, 0.0, 1.0, 2.0, 0.47771006955006, 6.9112, 6.9112, 168.912956510431, 775241.6114318797, 775241.6114318797, 214606.5680892887], 
processed observation next is [1.0, 0.8260869565217391, 0.5892575039494474, 0.7766666666666667, 1.0, 1.0, 0.12938331143807857, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36306106042690245, 0.0, 0.0, 0.8294399451523027, 0.21534489206441101, 0.21534489206441101, 0.3203083105810279], 
reward next is 0.6797, 
noisyNet noise sample is [array([0.42481863], dtype=float32), 0.8272335]. 
=============================================
[2019-03-27 05:39:36,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.8992434e-07 1.2568641e-12 9.9999964e-01 2.6103530e-19 3.9846704e-13], sum to 1.0000
[2019-03-27 05:39:36,122] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4931
[2019-03-27 05:39:36,131] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2594846.000894133 W.
[2019-03-27 05:39:36,138] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.83333333333334, 60.33333333333334, 1.0, 2.0, 0.6184652761943712, 1.0, 1.0, 0.6184652761943712, 1.0, 2.0, 1.03, 6.960742500865411, 6.9112, 170.5573041426782, 2594846.000894133, 2559356.692264152, 494770.6426985279], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3514200.0000, 
sim time next is 3514800.0000, 
raw observation next is [32.66666666666667, 61.66666666666667, 1.0, 2.0, 0.5985458350757701, 1.0, 2.0, 0.5985458350757701, 1.0, 2.0, 1.03, 6.921852627670984, 6.9112, 170.5573041426782, 2511187.58770452, 2503556.677182605, 487451.3016452855], 
processed observation next is [1.0, 0.6956521739130435, 0.7472353870458138, 0.6166666666666667, 1.0, 1.0, 0.5163202832238194, 1.0, 1.0, 0.5163202832238194, 1.0, 1.0, 1.0365853658536586, 0.001065262767098396, 0.0, 0.8375144448122397, 0.6975521076957001, 0.6954324103285014, 0.7275392561869933], 
reward next is 0.2192, 
noisyNet noise sample is [array([1.7384994], dtype=float32), 0.7997753]. 
=============================================
[2019-03-27 05:39:38,882] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.8038565e-01 1.6116935e-15 3.1961435e-01 3.0423111e-19 6.8269538e-13], sum to 1.0000
[2019-03-27 05:39:38,889] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0195
[2019-03-27 05:39:38,896] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333333, 72.66666666666667, 1.0, 1.0, 0.2638341736225072, 0.0, 2.0, 0.0, 1.0, 2.0, 0.448917726349199, 6.911200000000001, 6.9112, 168.912956510431, 737347.9509567774, 737347.9509567769, 210258.205157703], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3613800.0000, 
sim time next is 3614400.0000, 
raw observation next is [29.0, 74.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8922182419437189, 6.9112, 6.9112, 168.912956510431, 733777.457917772, 733777.457917772, 221524.2970871713], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8685588316386814, 0.0, 0.0, 0.8294399451523027, 0.20382707164382555, 0.20382707164382555, 0.330633279234584], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.34340256], dtype=float32), -0.8633498]. 
=============================================
[2019-03-27 05:39:40,653] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.1577682e-01 2.6498053e-13 5.8422327e-01 1.4067694e-17 3.7478635e-11], sum to 1.0000
[2019-03-27 05:39:40,666] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8365
[2019-03-27 05:39:40,675] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 84.0, 1.0, 2.0, 0.3092588552878018, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5153004966542922, 6.911200000000001, 6.9112, 168.912956510431, 864349.7849800411, 864349.7849800404, 222601.8417192706], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3646800.0000, 
sim time next is 3647400.0000, 
raw observation next is [26.16666666666667, 83.16666666666667, 1.0, 2.0, 0.3205720184638269, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5343261988926015, 6.9112, 6.9112, 168.912956510431, 895982.3626824671, 895982.3626824671, 226246.6688966824], 
processed observation next is [1.0, 0.21739130434782608, 0.4391785150078992, 0.8316666666666667, 1.0, 1.0, 0.18141207043834565, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43210512060073347, 0.0, 0.0, 0.8294399451523027, 0.24888398963401864, 0.24888398963401864, 0.33768159536818265], 
reward next is 0.6623, 
noisyNet noise sample is [array([0.42117146], dtype=float32), 0.81220543]. 
=============================================
[2019-03-27 05:39:50,286] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 7.7179546e-21 3.0216345e-09 1.7184448e-23 8.0872795e-18], sum to 1.0000
[2019-03-27 05:39:50,291] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6786
[2019-03-27 05:39:50,295] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.949122282327795, 6.9112, 168.9125441497218, 855714.7202726547, 828811.4136832567, 254811.9316490931], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3885600.0000, 
sim time next is 3886200.0000, 
raw observation next is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.971184943574597, 6.9112, 168.9123860802717, 871372.7607067198, 828817.520924802, 254811.9300315225], 
processed observation next is [0.0, 1.0, 0.5734597156398105, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005998494357459716, 0.0, 0.8294371440790764, 0.24204798908519995, 0.23022708914577836, 0.3803163134798843], 
reward next is 0.3198, 
noisyNet noise sample is [array([0.5035526], dtype=float32), 0.5886119]. 
=============================================
[2019-03-27 05:39:50,918] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 05:39:50,919] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:39:50,920] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:39:50,923] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:39:50,923] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:39:50,924] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:39:50,925] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:39:50,926] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:39:50,927] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:39:50,928] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:39:50,929] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:39:50,942] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run22
[2019-03-27 05:39:50,963] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run22
[2019-03-27 05:39:50,964] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run22
[2019-03-27 05:39:50,983] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run22
[2019-03-27 05:39:51,017] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run22
[2019-03-27 05:40:05,255] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:40:05,256] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.91690830333333, 92.20037658833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6486907728099198, 6.9112, 6.9112, 168.912956510431, 559667.3850158742, 559667.3850158742, 173873.5130179147]
[2019-03-27 05:40:05,257] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:40:05,258] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.4919816e-20 9.1639502e-10 1.2119544e-22 1.7116590e-17], sampled 0.4580423834261891
[2019-03-27 05:40:35,185] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:40:35,198] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.4, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.00250710919783, 6.911200000000001, 6.9112, 168.9129442741893, 808321.2787554757, 808321.278755475, 247711.4270938068]
[2019-03-27 05:40:35,198] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:40:35,201] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.8319703e-20 4.4204840e-09 3.8700352e-23 1.6791034e-17], sampled 0.39554388443415756
[2019-03-27 05:40:41,844] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:40:41,846] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.76634029, 75.31638056333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.025921334046918, 6.9112, 168.9121056690381, 910219.5256850809, 828832.672869172, 254812.324407459]
[2019-03-27 05:40:41,847] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:40:41,849] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:40:41,849] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.93333333333334, 66.0, 1.0, 2.0, 0.6430715621224291, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104308, 898677.1693825303, 898677.169382531, 209040.2462897569]
[2019-03-27 05:40:41,851] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 1.84754651e-20 1.46422545e-08 6.46698428e-24
 3.13352001e-18], sampled 0.3061425072768267
[2019-03-27 05:40:41,852] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:40:41,853] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 910219.5256850809 W.
[2019-03-27 05:40:41,854] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.0968378e-01 4.9761740e-12 2.9031616e-01 1.2130616e-15 8.4474878e-11], sampled 0.17751390110219878
[2019-03-27 05:40:41,855] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 898677.1693825303 W.
[2019-03-27 05:40:49,017] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:40:49,019] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.73333333333333, 58.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.934923450676579, 6.9112, 168.9126147553713, 845637.681718941, 828807.4833627766, 254811.9234454003]
[2019-03-27 05:40:49,020] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:40:49,023] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999988e-01 1.8716865e-20 1.0258469e-07 3.4171423e-24 2.5844551e-18], sampled 0.40840954921227357
[2019-03-27 05:41:00,950] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.055255584]
[2019-03-27 05:41:00,951] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.13193045833334, 60.235076225, 1.0, 2.0, 0.7103670198544562, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 992764.9219332655, 992764.9219332655, 223099.4571196351]
[2019-03-27 05:41:00,954] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:41:00,958] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [8.8168365e-01 1.5821360e-11 1.1831633e-01 3.4802163e-15 2.7137745e-10], sampled 0.24412736598565354
[2019-03-27 05:41:00,959] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 992764.9219332655 W.
[2019-03-27 05:41:44,880] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7125.4098 3327743433.7026 2073.0000
[2019-03-27 05:41:45,243] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7862.4421 2948261107.6894 1240.0000
[2019-03-27 05:41:45,422] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7097.3012 3122059425.8630 1781.0000
[2019-03-27 05:41:45,482] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6853.0139 3198373108.7628 2266.0000
[2019-03-27 05:41:45,628] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7750.6317 2999321018.7686 1393.0000
[2019-03-27 05:41:46,645] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 525000, evaluation results [525000.0, 7125.40982780453, 3327743433.7025633, 2073.0, 7097.301244102952, 3122059425.862996, 1781.0, 7862.4421443608335, 2948261107.6894054, 1240.0, 6853.013852935085, 3198373108.7628016, 2266.0, 7750.631681262243, 2999321018.7685766, 1393.0]
[2019-03-27 05:41:49,810] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.5470414e-23 1.3752310e-13 4.4581673e-26 5.0481014e-20], sum to 1.0000
[2019-03-27 05:41:49,819] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7475
[2019-03-27 05:41:49,823] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9131049201483095, 6.9112, 6.9112, 168.912956510431, 748611.8246158515, 748611.8246158515, 226290.1925338438], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3823200.0000, 
sim time next is 3823800.0000, 
raw observation next is [27.16666666666666, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9154082686914474, 6.911199999999999, 6.9112, 168.912956510431, 750269.6699026373, 750269.669902638, 226823.3943616457], 
processed observation next is [0.0, 0.2608695652173913, 0.4865718799368086, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8968393520627407, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20840824163962146, 0.20840824163962166, 0.3385423796442473], 
reward next is 0.6615, 
noisyNet noise sample is [array([0.07411454], dtype=float32), 0.54459774]. 
=============================================
[2019-03-27 05:41:53,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2230971e-21 8.4902745e-12 3.0237965e-24 6.4350555e-20], sum to 1.0000
[2019-03-27 05:41:53,758] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0827
[2019-03-27 05:41:53,762] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.83333333333334, 89.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.00817325018702, 6.9112, 6.9112, 168.912887657546, 814060.7878974364, 814060.7878974364, 249245.8070285447], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3903000.0000, 
sim time next is 3903600.0000, 
raw observation next is [27.66666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9986679658117321, 6.9112, 6.9112, 168.912956510431, 806796.8781804093, 806796.8781804093, 246810.8964861354], 
processed observation next is [0.0, 0.17391304347826086, 0.5102685624012641, 0.9066666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9983755680630879, 0.0, 0.0, 0.8294399451523027, 0.22411024393900258, 0.22411024393900258, 0.36837447236736626], 
reward next is 0.6316, 
noisyNet noise sample is [array([-0.09774058], dtype=float32), -0.21644723]. 
=============================================
[2019-03-27 05:41:57,270] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7246593e-01 5.0517191e-13 2.7534036e-02 5.6904404e-16 2.1356266e-11], sum to 1.0000
[2019-03-27 05:41:57,279] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4831
[2019-03-27 05:41:57,284] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 73.0, 1.0, 2.0, 0.3104632301577434, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5391719590248706, 6.9112, 6.9112, 168.912956510431, 867717.2759399276, 867717.2759399276, 225393.2391694931], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3958200.0000, 
sim time next is 3958800.0000, 
raw observation next is [32.0, 72.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.150784330834391, 6.9112, 168.9115099653818, 998835.1535742306, 828867.239016044, 254813.1302708408], 
processed observation next is [0.0, 0.8260869565217391, 0.7156398104265403, 0.7233333333333333, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.02395843308343908, 0.0, 0.82943284195388, 0.27745420932617515, 0.23024089972667888, 0.38031810488185197], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3401722], dtype=float32), -1.279502]. 
=============================================
[2019-03-27 05:41:57,388] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9820817e-01 1.7920209e-13 1.7918387e-03 2.1665231e-16 2.3390175e-11], sum to 1.0000
[2019-03-27 05:41:57,396] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2537
[2019-03-27 05:41:57,403] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 920815.477886354 W.
[2019-03-27 05:41:57,407] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 75.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.040851368886825, 6.9112, 168.9120912108081, 920815.477886354, 828836.8057288803, 254812.5348748243], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3963600.0000, 
sim time next is 3964200.0000, 
raw observation next is [31.16666666666667, 74.33333333333333, 1.0, 1.0, 0.2087705083565242, 1.0, 1.0, 0.2087705083565242, 1.0, 2.0, 0.3625653315531537, 6.9112, 6.9112, 170.5573041426782, 875242.2897251006, 875242.2897251006, 272323.9636375954], 
processed observation next is [0.0, 0.9130434782608695, 0.6761453396524489, 0.7433333333333333, 1.0, 0.5, 0.04671145585123396, 1.0, 0.5, 0.04671145585123396, 1.0, 1.0, 0.22264064823555327, 0.0, 0.0, 0.8375144448122397, 0.24312285825697239, 0.24312285825697239, 0.4064536770710379], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5799962], dtype=float32), 1.4419487]. 
=============================================
[2019-03-27 05:42:00,048] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.9433015e-01 9.3423641e-13 7.0566982e-01 2.9978571e-17 1.4629478e-11], sum to 1.0000
[2019-03-27 05:42:00,057] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2413
[2019-03-27 05:42:00,065] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1938084.277867933 W.
[2019-03-27 05:42:00,070] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666667, 84.0, 1.0, 2.0, 0.7449876282000731, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.98678714872951, 6.9112, 168.9124405068164, 1938084.277867933, 1884460.316863949, 395414.0852040718], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4005600.0000, 
sim time next is 4006200.0000, 
raw observation next is [27.33333333333333, 84.0, 1.0, 2.0, 0.7271120328876731, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981056965619711, 6.9112, 168.9124788450685, 1913068.803327157, 1863510.007771993, 391528.5769355745], 
processed observation next is [1.0, 0.34782608695652173, 0.494470774091627, 0.84, 1.0, 1.0, 0.6712193167321363, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0069856965619710994, 0.0, 0.8294375995966967, 0.5314080009242103, 0.5176416688255536, 0.5843710103516038], 
reward next is 0.0663, 
noisyNet noise sample is [array([-0.13857417], dtype=float32), -0.890087]. 
=============================================
[2019-03-27 05:42:06,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.2928891e-06 1.5880788e-13 9.9999571e-01 4.3206215e-19 2.2110659e-13], sum to 1.0000
[2019-03-27 05:42:06,194] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6127
[2019-03-27 05:42:06,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3857979.162814511 W.
[2019-03-27 05:42:06,206] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 69.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 8.233958187428602, 6.9112, 170.5573041426782, 3857979.162814511, 2910433.666796504, 545699.9694648578], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4109400.0000, 
sim time next is 4110000.0000, 
raw observation next is [34.0, 68.33333333333333, 1.0, 2.0, 0.9748131068616789, 1.0, 2.0, 0.8079965929451021, 1.0, 1.0, 1.03, 7.005119410926034, 6.9112, 170.5573041426782, 3391127.099766399, 3323848.805322705, 622197.5443704361], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6833333333333332, 1.0, 1.0, 0.9696543456164806, 1.0, 1.0, 0.7686705939097616, 1.0, 0.5, 1.0365853658536586, 0.009391941092603417, 0.0, 0.8375144448122397, 0.9419797499351108, 0.9232913348118624, 0.9286530512991584], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.252075], dtype=float32), -0.6080792]. 
=============================================
[2019-03-27 05:42:06,219] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[34.40242 ]
 [36.836304]
 [38.970787]
 [38.308296]
 [37.438374]], R is [[33.13069916]
 [32.7993927 ]
 [32.4713974 ]
 [32.14668274]
 [31.82521629]].
[2019-03-27 05:42:09,311] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.0596383e-01 1.5819858e-11 3.9403617e-01 9.8953756e-16 3.2945358e-09], sum to 1.0000
[2019-03-27 05:42:09,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9765
[2019-03-27 05:42:09,325] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.4211087845494483, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7303128019249965, 6.9112, 6.9112, 168.912956510431, 1177133.210844216, 1177133.210844216, 268754.4196848199], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4161600.0000, 
sim time next is 4162200.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.4030901517949654, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6989158960608121, 6.9112, 6.9112, 168.912956510431, 1126738.66811313, 1126738.66811313, 260739.7645735943], 
processed observation next is [1.0, 0.17391304347826086, 0.5260663507109005, 0.89, 1.0, 1.0, 0.28083150818670527, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6328242634887951, 0.0, 0.0, 0.8294399451523027, 0.3129829633647583, 0.3129829633647583, 0.38916382772178254], 
reward next is 0.6108, 
noisyNet noise sample is [array([-0.13668603], dtype=float32), -0.96865875]. 
=============================================
[2019-03-27 05:42:16,926] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.8544352e-07 1.2084096e-13 9.9999976e-01 1.0347208e-19 3.0727669e-13], sum to 1.0000
[2019-03-27 05:42:16,935] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2550
[2019-03-27 05:42:16,944] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 3203854.373748922 W.
[2019-03-27 05:42:16,950] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [38.0, 49.00000000000001, 1.0, 2.0, 0.8856853021867638, 1.0, 2.0, 0.7634326906076445, 1.0, 2.0, 1.03, 7.005112377839421, 6.9112, 170.5573041426782, 3203854.373748922, 3136581.117391258, 586396.3613970123], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4288800.0000, 
sim time next is 4289400.0000, 
raw observation next is [38.0, 48.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.882048170987895, 6.9112, 170.5573041426782, 3605597.937885846, 2910139.901428556, 548074.8454736125], 
processed observation next is [1.0, 0.6521739130434783, 1.0, 0.48, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.09708481709878951, 0.0, 0.8375144448122397, 1.0015549827460684, 0.8083721948412655, 0.8180221574233023], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9981752], dtype=float32), -0.762222]. 
=============================================
[2019-03-27 05:42:39,477] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.4396527e-01 1.9917093e-12 2.5603470e-01 1.8314043e-16 7.6607526e-11], sum to 1.0000
[2019-03-27 05:42:39,486] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0559
[2019-03-27 05:42:39,491] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1237051.772720461 W.
[2019-03-27 05:42:39,500] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.16666666666666, 88.16666666666667, 1.0, 2.0, 0.4425316295657508, 0.0, 2.0, 0.0, 1.0, 1.0, 0.755670956450017, 6.9112, 6.9112, 168.912956510431, 1237051.772720461, 1237051.772720461, 276830.8786933501], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4687800.0000, 
sim time next is 4688400.0000, 
raw observation next is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.3088319135760382, 1.0, 1.0, 0.3088319135760382, 1.0, 2.0, 0.5311384414332143, 6.911199999999999, 6.9112, 170.5573041426782, 1294989.601867502, 1294989.601867503, 307637.2558520436], 
processed observation next is [1.0, 0.2608695652173913, 0.4944707740916275, 0.8733333333333334, 1.0, 1.0, 0.16726736575426285, 1.0, 0.5, 0.16726736575426285, 1.0, 1.0, 0.42821761150391985, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.35971933385208393, 0.35971933385208416, 0.45916008336125913], 
reward next is 0.5408, 
noisyNet noise sample is [array([-0.5706092], dtype=float32), 0.8959631]. 
=============================================
[2019-03-27 05:42:40,754] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.0437795e-02 3.9060091e-13 9.5956218e-01 2.1318142e-16 5.5282966e-11], sum to 1.0000
[2019-03-27 05:42:40,762] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5908
[2019-03-27 05:42:40,770] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.9255309817288213, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000958003303429, 6.9112, 168.9123504467917, 2190773.413353822, 2127096.225054371, 441422.881771173], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4698000.0000, 
sim time next is 4698600.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.072556249471686, 6.9112, 168.9120323747863, 2401612.681361429, 2287141.63081596, 475893.631812321], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.75, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01613562494716856, 0.0, 0.8294354072232161, 0.667114633711508, 0.6353171196711, 0.7102890027049568], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05076599], dtype=float32), 0.35528275]. 
=============================================
[2019-03-27 05:42:41,319] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 05:42:41,321] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:42:41,322] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:42:41,322] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:42:41,324] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:42:41,324] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:42:41,323] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:42:41,324] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:42:41,326] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:42:41,331] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:42:41,332] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:42:41,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run23
[2019-03-27 05:42:41,363] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run23
[2019-03-27 05:42:41,365] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run23
[2019-03-27 05:42:41,365] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run23
[2019-03-27 05:42:41,422] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run23
[2019-03-27 05:43:17,298] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056038413]
[2019-03-27 05:43:17,301] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.13333333333334, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7690359192880776, 6.911199999999999, 6.9112, 168.912956510431, 650841.1562148086, 650841.1562148092, 195696.1238513047]
[2019-03-27 05:43:17,302] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:43:17,305] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.8555153e-21 4.2812243e-11 1.0813070e-23 3.6180553e-18], sampled 0.1500479608425841
[2019-03-27 05:43:52,259] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056038413]
[2019-03-27 05:43:52,261] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.51666666666667, 51.83333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.952282626938729, 6.9112, 168.912459099681, 1482920.231564418, 1453774.887885937, 311354.3102793368]
[2019-03-27 05:43:52,263] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:43:52,267] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.2955348e-01 3.7208275e-12 5.7044655e-01 5.2046257e-16 2.5478228e-10], sampled 0.5033109208344972
[2019-03-27 05:43:56,822] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056038413]
[2019-03-27 05:43:56,823] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.53333333333333, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.934029810478278, 6.9112, 6.9112, 168.912956510431, 762576.7663983356, 762576.7663983356, 231132.8698329635]
[2019-03-27 05:43:56,824] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:43:56,827] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.9655624e-22 2.3495714e-11 6.9889536e-25 5.8610430e-19], sampled 0.03833808453790888
[2019-03-27 05:44:35,315] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7098.9764 3116945378.6304 1855.0000
[2019-03-27 05:44:35,527] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7925.8029 2944323136.1234 1286.0000
[2019-03-27 05:44:35,691] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7149.9396 3324610125.1338 2096.0000
[2019-03-27 05:44:35,950] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7784.6814 2996014414.1923 1447.0000
[2019-03-27 05:44:35,974] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6868.7239 3193873004.2246 2344.0000
[2019-03-27 05:44:36,991] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 550000, evaluation results [550000.0, 7149.93964510246, 3324610125.1338363, 2096.0, 7098.976378585816, 3116945378.630433, 1855.0, 7925.802923283093, 2944323136.123399, 1286.0, 6868.723915228442, 3193873004.22457, 2344.0, 7784.681362028899, 2996014414.1923146, 1447.0]
[2019-03-27 05:44:41,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.5756118e-04 1.3479947e-12 9.9934238e-01 1.6796323e-17 2.7991300e-11], sum to 1.0000
[2019-03-27 05:44:41,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2825
[2019-03-27 05:44:41,198] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.071075192420651, 6.9112, 168.9118481574016, 2408267.472626845, 2294847.252876417, 476280.6901511739], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4791000.0000, 
sim time next is 4791600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.8740434542508152, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990314365335855, 6.9112, 168.9123556314001, 2118705.147574557, 2062578.893559274, 427544.3742861524], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 0.8482451256033918, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007911436533585458, 0.0, 0.8294369945611773, 0.5885292076595992, 0.5729385815442428, 0.6381259317703768], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.90711784], dtype=float32), 0.77252775]. 
=============================================
[2019-03-27 05:44:49,567] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 7.1492290e-19 1.5379166e-07 1.2981557e-22 2.4786693e-16], sum to 1.0000
[2019-03-27 05:44:49,576] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2129
[2019-03-27 05:44:49,581] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8578379003279818, 6.911200000000001, 6.9112, 168.912956510431, 710830.8339312272, 710830.8339312265, 213966.3888353623], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4927200.0000, 
sim time next is 4927800.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.858577513124144, 6.9112, 6.9112, 168.912956510431, 711443.9050444438, 711443.9050444438, 214130.0318190817], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8275335525904195, 0.0, 0.0, 0.8294399451523027, 0.19762330695678995, 0.19762330695678995, 0.31959706241653985], 
reward next is 0.6804, 
noisyNet noise sample is [array([-1.4659514], dtype=float32), 0.3862516]. 
=============================================
[2019-03-27 05:44:56,789] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4520634e-23 4.8616227e-13 2.2172405e-25 1.2639278e-19], sum to 1.0000
[2019-03-27 05:44:56,797] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2711
[2019-03-27 05:44:56,806] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.83333333333334, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8707271189811538, 6.9112, 6.9112, 168.912956510431, 718741.8941740311, 718741.8941740311, 216742.6666820238], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5050200.0000, 
sim time next is 5050800.0000, 
raw observation next is [31.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8742289041711907, 6.911199999999999, 6.9112, 168.912956510431, 720972.8905128329, 720972.8905128335, 217505.9853288348], 
processed observation next is [0.0, 0.4782608695652174, 0.6682464454976303, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8466206148429154, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2002702473646758, 0.20027024736467597, 0.3246357989982609], 
reward next is 0.6754, 
noisyNet noise sample is [array([-0.7907792], dtype=float32), -0.09815089]. 
=============================================
[2019-03-27 05:45:05,367] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.0468257e-20 1.4890647e-10 5.6184847e-24 8.5794569e-18], sum to 1.0000
[2019-03-27 05:45:05,381] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-27 05:45:05,391] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 4034721.542596118 W.
[2019-03-27 05:45:05,399] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.83333333333333, 84.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 11.39432262244125, 6.9112, 168.8754317593461, 4034721.542596118, 854946.6149177119, 256044.859961819], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5191800.0000, 
sim time next is 5192400.0000, 
raw observation next is [26.66666666666667, 85.66666666666667, 1.0, 1.0, 0.5513880939144441, 1.0, 1.0, 0.5513880939144441, 1.0, 2.0, 0.9431232596260257, 6.9112, 6.9112, 170.5573041426782, 2313155.067286151, 2313155.067286151, 449567.0000448279], 
processed observation next is [1.0, 0.08695652173913043, 0.4628751974723541, 0.8566666666666667, 1.0, 0.5, 0.4595037276077639, 1.0, 0.5, 0.4595037276077639, 1.0, 1.0, 0.9306381214951533, 0.0, 0.0, 0.8375144448122397, 0.6425430742461531, 0.6425430742461531, 0.670995522454967], 
reward next is 0.3290, 
noisyNet noise sample is [array([0.55144614], dtype=float32), -0.83521646]. 
=============================================
[2019-03-27 05:45:06,746] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.2441133e-03 9.5644586e-13 9.9575585e-01 6.8791596e-17 8.5820427e-11], sum to 1.0000
[2019-03-27 05:45:06,755] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0810
[2019-03-27 05:45:06,762] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.8963262829692465, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990068504754995, 6.9112, 168.9124240332085, 2149894.328967885, 2093942.473632113, 433632.5428174414], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5220000.0000, 
sim time next is 5220600.0000, 
raw observation next is [31.0, 66.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.299147788760827, 6.9112, 168.9110538281269, 2569103.002570312, 2293882.589284804, 475751.7104386301], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6666666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.038794778876082694, 0.0, 0.8294306021111378, 0.7136397229361978, 0.6371896081346679, 0.7100771797591494], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8059253], dtype=float32), -0.1687655]. 
=============================================
[2019-03-27 05:45:14,994] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.1563794e-01 5.7809660e-13 8.8436204e-01 1.3058796e-17 3.5191138e-11], sum to 1.0000
[2019-03-27 05:45:15,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8992
[2019-03-27 05:45:15,005] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.9, 79.33333333333334, 1.0, 2.0, 0.3126173421260232, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5429129391380589, 6.911199999999999, 6.9112, 168.912956510431, 873740.3048395718, 873740.3048395724, 226112.6619782631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5346600.0000, 
sim time next is 5347200.0000, 
raw observation next is [30.8, 79.66666666666667, 1.0, 2.0, 0.3108531302664042, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5398490865716781, 6.9112, 6.9112, 168.912956510431, 868807.4579748324, 868807.4579748324, 225522.5076911577], 
processed observation next is [1.0, 0.9130434782608695, 0.6587677725118484, 0.7966666666666667, 1.0, 1.0, 0.16970256658602917, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43884034947765616, 0.0, 0.0, 0.8294399451523027, 0.24133540499300898, 0.24133540499300898, 0.3366007577479965], 
reward next is 0.6634, 
noisyNet noise sample is [array([-0.53244036], dtype=float32), -0.63413143]. 
=============================================
[2019-03-27 05:45:17,323] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9956971e-01 6.8475948e-15 4.3033223e-04 6.3718732e-18 7.4171719e-12], sum to 1.0000
[2019-03-27 05:45:17,332] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8073
[2019-03-27 05:45:17,337] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.25, 91.0, 1.0, 1.0, 0.2015328819836991, 1.0, 1.0, 0.2015328819836991, 1.0, 2.0, 0.3499959680631731, 6.9112, 6.9112, 170.5573041426782, 844887.5620361121, 844887.5620361121, 270269.3956158753], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5448600.0000, 
sim time next is 5449200.0000, 
raw observation next is [28.16666666666666, 91.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.974062722769999, 6.9112, 168.9124441380212, 873415.1612114807, 828818.3173888254, 254812.2940225859], 
processed observation next is [1.0, 0.043478260869565216, 0.5339652448657185, 0.9166666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006286272276999938, 0.0, 0.8294374291692054, 0.24261532255874466, 0.2302273103857848, 0.3803168567501282], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7540835], dtype=float32), 0.09331826]. 
=============================================
[2019-03-27 05:45:25,426] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3995690e-19 4.2372870e-09 8.0877213e-23 1.2066984e-17], sum to 1.0000
[2019-03-27 05:45:25,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2214
[2019-03-27 05:45:25,443] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.26666666666667, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.942048112076183, 6.9112, 6.9112, 168.912956510431, 768356.4774477064, 768356.4774477064, 233036.3860986416], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5529000.0000, 
sim time next is 5529600.0000, 
raw observation next is [27.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9416420609712071, 6.9112, 6.9112, 168.912956510431, 767970.9725694183, 767970.9725694183, 232935.2145856464], 
processed observation next is [1.0, 0.0, 0.4881516587677725, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9288317816722037, 0.0, 0.0, 0.8294399451523027, 0.21332527015817174, 0.21332527015817174, 0.3476644993815618], 
reward next is 0.6523, 
noisyNet noise sample is [array([-1.1974143], dtype=float32), 1.124653]. 
=============================================
[2019-03-27 05:45:28,704] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999976e-01 1.3818400e-18 2.5011008e-07 1.5689604e-21 9.4146844e-16], sum to 1.0000
[2019-03-27 05:45:28,713] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9226
[2019-03-27 05:45:28,717] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9514096529912637, 6.9112, 6.9112, 168.912956510431, 772438.1135362382, 772438.1135362382, 235147.3125382916], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5599200.0000, 
sim time next is 5599800.0000, 
raw observation next is [28.9, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9578785514537654, 6.9112, 6.9112, 168.912956510431, 776707.877682623, 776707.877682623, 236687.8440887645], 
processed observation next is [1.0, 0.8260869565217391, 0.5687203791469194, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.948632379821665, 0.0, 0.0, 0.8294399451523027, 0.21575218824517306, 0.21575218824517306, 0.35326543893845447], 
reward next is 0.6467, 
noisyNet noise sample is [array([-0.87403464], dtype=float32), -0.57878715]. 
=============================================
[2019-03-27 05:45:31,707] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-27 05:45:31,709] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:45:31,709] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:45:31,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:45:31,711] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:45:31,712] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:45:31,714] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:45:31,711] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:45:31,717] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:45:31,719] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:45:31,717] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:45:31,736] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run24
[2019-03-27 05:45:31,755] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run24
[2019-03-27 05:45:31,758] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run24
[2019-03-27 05:45:31,776] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run24
[2019-03-27 05:45:31,819] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run24
[2019-03-27 05:46:08,029] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05645584]
[2019-03-27 05:46:08,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.31666666666667, 87.66666666666666, 1.0, 2.0, 0.7602204657618706, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 158.3874379661933, 1062507.185874841, 1062507.185874841, 232966.5959546156]
[2019-03-27 05:46:08,034] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:46:08,038] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.7874873e-01 9.8282944e-11 3.2125130e-01 1.7911203e-13 2.2171027e-09], sampled 0.16301084043167324
[2019-03-27 05:46:08,040] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1062507.185874841 W.
[2019-03-27 05:46:13,614] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05645584]
[2019-03-27 05:46:13,616] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.5, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8464261310767767, 6.911199999999999, 6.9112, 168.912956510431, 700821.5020236148, 700821.5020236155, 211441.9567983242]
[2019-03-27 05:46:13,618] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:46:13,620] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.2676651e-19 7.2657858e-09 7.0687046e-22 2.5075896e-17], sampled 0.8751386003957545
[2019-03-27 05:46:26,681] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05645584]
[2019-03-27 05:46:26,683] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.9, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9286584732817077, 6.911200000000002, 6.9112, 168.912956510431, 760266.5651072767, 760266.5651072754, 229936.9300060401]
[2019-03-27 05:46:26,685] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:46:26,688] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.4713834e-24 6.9408726e-15 1.0069157e-25 3.4727086e-21], sampled 0.9377285655073347
[2019-03-27 05:46:56,507] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05645584]
[2019-03-27 05:46:56,510] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.8, 91.0, 1.0, 2.0, 0.680065376765337, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 950398.2746481972, 950398.2746481972, 216601.6165847068]
[2019-03-27 05:46:56,511] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:46:56,514] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.5567349e-01 1.0036902e-11 1.4432648e-01 2.5101347e-14 4.2600976e-10], sampled 0.15327835597473827
[2019-03-27 05:46:56,515] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 950398.2746481972 W.
[2019-03-27 05:47:00,976] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.05645584]
[2019-03-27 05:47:00,979] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.32288184, 87.440638865, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.94513761443188, 6.9112, 168.9125549234925, 854103.2436867545, 830026.7892076258, 254884.2220138274]
[2019-03-27 05:47:00,980] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:47:00,982] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.1607144e-24 6.4531891e-15 7.3736407e-26 2.5178406e-21], sampled 0.8525910358631963
[2019-03-27 05:47:25,702] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7934.5467 2942757437.9988 1313.0000
[2019-03-27 05:47:26,022] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7808.2545 2994132435.3243 1475.0000
[2019-03-27 05:47:26,079] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7200.5390 3322791737.8405 2115.0000
[2019-03-27 05:47:26,228] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6868.2757 3191190199.3149 2374.0000
[2019-03-27 05:47:26,299] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7141.7406 3113892239.7637 1889.0000
[2019-03-27 05:47:27,316] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 575000, evaluation results [575000.0, 7200.538995084659, 3322791737.8404737, 2115.0, 7141.7406202309785, 3113892239.7636986, 1889.0, 7934.546730045523, 2942757437.9988227, 1313.0, 6868.275704561718, 3191190199.3148932, 2374.0, 7808.254457637234, 2994132435.3243375, 1475.0]
[2019-03-27 05:47:28,768] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.9899452e-24 2.1108453e-13 6.0703679e-26 7.0968659e-20], sum to 1.0000
[2019-03-27 05:47:28,776] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8846
[2019-03-27 05:47:28,782] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.68333333333333, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8930677095046238, 6.9112, 6.9112, 168.912956510431, 734684.6366596281, 734684.6366596281, 221728.1924031565], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5677800.0000, 
sim time next is 5678400.0000, 
raw observation next is [31.46666666666667, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8946301531429209, 6.9112, 6.9112, 168.912956510431, 735576.8609126025, 735576.8609126025, 222072.692315247], 
processed observation next is [0.0, 0.7391304347826086, 0.6903633491311217, 0.6166666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8715001867596596, 0.0, 0.0, 0.8294399451523027, 0.20432690580905624, 0.20432690580905624, 0.3314517795749955], 
reward next is 0.6685, 
noisyNet noise sample is [array([1.4890105], dtype=float32), -0.6099184]. 
=============================================
[2019-03-27 05:47:30,138] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.7942180e-25 1.6031793e-15 9.1110985e-27 7.6312896e-23], sum to 1.0000
[2019-03-27 05:47:30,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1683
[2019-03-27 05:47:30,152] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9160893218494537, 6.9112, 6.9112, 168.912956510431, 751239.8670519596, 751239.8670519596, 227001.7720687261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5689800.0000, 
sim time next is 5690400.0000, 
raw observation next is [27.63333333333333, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9152218342262958, 6.9112, 6.9112, 168.912956510431, 750707.6636300974, 750707.6636300974, 226804.5129911186], 
processed observation next is [0.0, 0.8695652173913043, 0.5086887835703, 0.8433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8966119929588972, 0.0, 0.0, 0.8294399451523027, 0.20852990656391596, 0.20852990656391596, 0.33851419849420683], 
reward next is 0.6615, 
noisyNet noise sample is [array([-0.89740515], dtype=float32), -0.3462947]. 
=============================================
[2019-03-27 05:47:37,904] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0117779e-19 1.0723337e-08 4.0325440e-23 3.6560725e-17], sum to 1.0000
[2019-03-27 05:47:37,912] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9585
[2019-03-27 05:47:37,917] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.1, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9610372074881991, 6.9112, 6.9112, 168.912956510431, 779919.0607056242, 779919.0607056242, 237502.013610472], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5950800.0000, 
sim time next is 5951400.0000, 
raw observation next is [28.01666666666667, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9649711258248784, 6.9112, 6.9112, 168.912956510431, 783101.9786781631, 783101.9786781631, 238477.7414429033], 
processed observation next is [1.0, 0.9130434782608695, 0.5268562401263824, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9572818607620467, 0.0, 0.0, 0.8294399451523027, 0.21752832741060088, 0.21752832741060088, 0.35593692752672135], 
reward next is 0.6441, 
noisyNet noise sample is [array([-0.6214808], dtype=float32), -0.5964897]. 
=============================================
[2019-03-27 05:47:42,167] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.08330685e-04 1.64526032e-11 9.99891639e-01 4.50717401e-16
 9.02536865e-11], sum to 1.0000
[2019-03-27 05:47:42,175] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2548
[2019-03-27 05:47:42,184] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2586102.51201043 W.
[2019-03-27 05:47:42,193] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.95, 74.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.337103272677591, 6.9112, 168.9105377043459, 2586102.51201043, 2283956.398658778, 475167.5524973461], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5910600.0000, 
sim time next is 5911200.0000, 
raw observation next is [31.1, 74.0, 1.0, 2.0, 0.9120332041318794, 1.0, 1.0, 0.9120332041318794, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2550985.812297027, 2550985.812297026, 478104.3632732913], 
processed observation next is [1.0, 0.43478260869565216, 0.6729857819905214, 0.74, 1.0, 1.0, 0.8940159085926258, 1.0, 0.5, 0.8940159085926258, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7086071700825075, 0.7086071700825073, 0.7135886019004348], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.50805295], dtype=float32), -2.175116]. 
=============================================
[2019-03-27 05:47:44,899] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999988e-01 1.1489325e-20 9.1972808e-08 2.8606908e-23 4.6221314e-17], sum to 1.0000
[2019-03-27 05:47:44,909] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5036
[2019-03-27 05:47:44,914] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9639962402670746, 6.911200000000001, 6.9112, 168.912956510431, 782804.5956170058, 782804.5956170053, 238260.7716695033], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5956800.0000, 
sim time next is 5957400.0000, 
raw observation next is [27.26666666666667, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.963384454722268, 6.911199999999999, 6.9112, 168.912956510431, 782260.4470934046, 782260.4470934053, 238106.3921316013], 
processed observation next is [1.0, 0.9565217391304348, 0.4913112164297, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9553468960027657, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21729456863705685, 0.21729456863705704, 0.3553826748232855], 
reward next is 0.6446, 
noisyNet noise sample is [array([0.7165386], dtype=float32), -0.31415176]. 
=============================================
[2019-03-27 05:47:47,977] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9993575e-01 3.6380462e-16 6.4220374e-05 3.1512136e-19 1.2162355e-13], sum to 1.0000
[2019-03-27 05:47:47,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1963
[2019-03-27 05:47:47,994] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1297589.668697167 W.
[2019-03-27 05:47:47,999] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.2, 93.0, 1.0, 2.0, 0.3094516080775355, 1.0, 2.0, 0.3094516080775355, 1.0, 1.0, 0.530450832098424, 6.9112, 6.9112, 170.5573041426782, 1297589.668697167, 1297589.668697167, 307718.3835220051], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6057000.0000, 
sim time next is 6057600.0000, 
raw observation next is [26.2, 93.0, 1.0, 2.0, 0.8063145340275192, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129565102871, 1126926.371633509, 1126926.371633509, 245466.0974553667], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.93, 1.0, 1.0, 0.7666440169006256, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.829439945151596, 0.3130351032315303, 0.3130351032315303, 0.3663673096348757], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.18163577], dtype=float32), 0.5677063]. 
=============================================
[2019-03-27 05:47:48,943] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.5037204e-06 2.4384208e-12 9.9999547e-01 5.8818524e-17 2.8058931e-12], sum to 1.0000
[2019-03-27 05:47:48,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8772
[2019-03-27 05:47:48,953] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.16666666666667, 66.83333333333333, 1.0, 2.0, 0.5758059816080919, 1.0, 1.0, 0.5758059816080919, 1.0, 2.0, 0.99998456810532, 6.9112, 6.9112, 170.5573041426782, 2415690.747778137, 2415690.747778137, 471524.2805918098], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6022200.0000, 
sim time next is 6022800.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.9272474923705527, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.994959787527812, 6.9112, 168.9124582685947, 2193175.857481873, 2133753.956697286, 442137.4877716186], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.66, 1.0, 1.0, 0.9123463763500635, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008375978752781154, 0.0, 0.8294374985567903, 0.6092155159671869, 0.5927094324159128, 0.6599066981665949], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04353618], dtype=float32), 1.0254012]. 
=============================================
[2019-03-27 05:47:50,397] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 8.0680919e-23 2.2407369e-11 6.0520590e-25 2.3761107e-19], sum to 1.0000
[2019-03-27 05:47:50,407] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3887
[2019-03-27 05:47:50,413] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.73333333333333, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9162392655830293, 6.9112, 6.9112, 168.912956510431, 751163.5360147613, 751163.5360147613, 227028.7129267659], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6047400.0000, 
sim time next is 6048000.0000, 
raw observation next is [26.7, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9158033789363318, 6.9112, 6.9112, 168.912956510431, 750921.9115468435, 750921.9115468435, 226930.6779359564], 
processed observation next is [1.0, 0.0, 0.46445497630331756, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8973211938247949, 0.0, 0.0, 0.8294399451523027, 0.2085894198741232, 0.2085894198741232, 0.3387025043820245], 
reward next is 0.6613, 
noisyNet noise sample is [array([0.23037657], dtype=float32), -0.13930865]. 
=============================================
[2019-03-27 05:47:50,432] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[60.431458]
 [60.438698]
 [60.43225 ]
 [60.43014 ]
 [60.34549 ]], R is [[59.70028305]
 [59.764431  ]
 [59.82765198]
 [59.88984299]
 [59.95108414]].
[2019-03-27 05:48:03,456] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.7587176e-24 1.4170356e-13 3.3481580e-26 2.7952911e-20], sum to 1.0000
[2019-03-27 05:48:03,466] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9167
[2019-03-27 05:48:03,471] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.11666666666667, 82.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8632617588336631, 6.9112, 6.9112, 168.912956510431, 715957.8233583921, 715957.8233583921, 215190.6132176783], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6393000.0000, 
sim time next is 6393600.0000, 
raw observation next is [27.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.863752029375264, 6.9112, 6.9112, 168.912956510431, 716280.4644052556, 716280.4644052556, 215297.0678404122], 
processed observation next is [1.0, 0.0, 0.4834123222748816, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8338439382625169, 0.0, 0.0, 0.8294399451523027, 0.19896679566812656, 0.19896679566812656, 0.3213389072244958], 
reward next is 0.6787, 
noisyNet noise sample is [array([-0.82926637], dtype=float32), -0.2949059]. 
=============================================
[2019-03-27 05:48:03,851] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.2698291e-24 1.6777397e-13 8.4276831e-25 6.7870828e-20], sum to 1.0000
[2019-03-27 05:48:03,859] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6368
[2019-03-27 05:48:03,865] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.68333333333333, 62.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8535360062328288, 6.911200000000001, 6.9112, 168.912956510431, 707850.029151847, 707850.0291518463, 213036.5864590602], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6275400.0000, 
sim time next is 6276000.0000, 
raw observation next is [30.66666666666667, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8532846048061774, 6.9112, 6.9112, 168.912956510431, 707564.8236539173, 707564.8236539173, 212978.8063716499], 
processed observation next is [0.0, 0.6521739130434783, 0.6524486571879939, 0.6233333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8210787863489967, 0.0, 0.0, 0.8294399451523027, 0.19654578434831035, 0.19654578434831035, 0.31787881548007446], 
reward next is 0.6821, 
noisyNet noise sample is [array([2.210089], dtype=float32), 0.5714731]. 
=============================================
[2019-03-27 05:48:03,883] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.2568  ]
 [65.27166 ]
 [65.30117 ]
 [65.348915]
 [65.37999 ]], R is [[65.25247192]
 [65.28198242]
 [65.31172943]
 [65.3404541 ]
 [65.36814117]].
[2019-03-27 05:48:05,054] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.1493587e-24 1.3819447e-12 2.4394949e-25 8.3193529e-21], sum to 1.0000
[2019-03-27 05:48:05,063] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9627
[2019-03-27 05:48:05,068] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.63333333333334, 83.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9090017973687147, 6.911199999999999, 6.9112, 168.912956510431, 746530.7973011857, 746530.7973011864, 225380.0437189411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6295800.0000, 
sim time next is 6296400.0000, 
raw observation next is [27.6, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9099048855851405, 6.9112, 6.9112, 168.912956510431, 747363.2004427084, 747363.2004427084, 225595.61897593], 
processed observation next is [0.0, 0.9130434782608695, 0.5071090047393366, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8901279092501712, 0.0, 0.0, 0.8294399451523027, 0.20760088901186347, 0.20760088901186347, 0.33670987906855226], 
reward next is 0.6633, 
noisyNet noise sample is [array([-0.71610653], dtype=float32), 1.9739794]. 
=============================================
[2019-03-27 05:48:08,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 9.4475984e-25 1.0396739e-13 1.1084103e-25 2.9927813e-22], sum to 1.0000
[2019-03-27 05:48:08,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4052
[2019-03-27 05:48:08,885] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.41666666666666, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8791309314283596, 6.9112, 6.9112, 168.912956510431, 727127.3935614872, 727127.3935614872, 218690.0367116684], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6385800.0000, 
sim time next is 6386400.0000, 
raw observation next is [27.4, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8772926447694454, 6.911199999999999, 6.9112, 168.912956510431, 725778.4742334214, 725778.4742334221, 218279.5711535509], 
processed observation next is [0.0, 0.9565217391304348, 0.4976303317535545, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8503568838651773, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20160513173150593, 0.20160513173150613, 0.3257904047067924], 
reward next is 0.6742, 
noisyNet noise sample is [array([1.6803412], dtype=float32), 0.42196018]. 
=============================================
[2019-03-27 05:48:10,643] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.8479205e-25 3.2169776e-14 3.9082909e-26 5.6264261e-22], sum to 1.0000
[2019-03-27 05:48:10,650] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-27 05:48:10,655] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8629821373355843, 6.911199999999999, 6.9112, 168.912956510431, 715888.5804238338, 715888.5804238344, 215133.6402177826], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6391800.0000, 
sim time next is 6392400.0000, 
raw observation next is [27.13333333333333, 82.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8629993253136706, 6.911199999999999, 6.9112, 168.912956510431, 715823.3238133824, 715823.323813383, 215134.8918372038], 
processed observation next is [0.0, 1.0, 0.484992101105845, 0.8266666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.832926006480086, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19883981217038402, 0.19883981217038416, 0.32109685348836386], 
reward next is 0.6789, 
noisyNet noise sample is [array([0.81991893], dtype=float32), 2.034358]. 
=============================================
[2019-03-27 05:48:13,665] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.5874537e-05 7.7230533e-14 9.9997413e-01 8.3052258e-19 2.7276265e-12], sum to 1.0000
[2019-03-27 05:48:13,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7692
[2019-03-27 05:48:13,681] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.9833426486130895, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980306985555442, 6.9112, 168.9124894128738, 2271687.256582973, 2222660.518125818, 459135.7402316141], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6447000.0000, 
sim time next is 6447600.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 1.005144466775284, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.980317742914117, 6.9112, 168.9124894433692, 2302202.665790745, 2253168.295705357, 465805.8456592515], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.68, 1.0, 1.0, 1.006198152741306, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006911774291411721, 0.0, 0.829437651639205, 0.6395007404974292, 0.6258800821403769, 0.6952326054615694], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.05396984], dtype=float32), 0.1340526]. 
=============================================
[2019-03-27 05:48:21,865] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-27 05:48:21,867] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:48:21,868] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:48:21,869] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:48:21,869] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:48:21,871] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:48:21,872] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:48:21,873] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:48:21,873] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:48:21,870] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:48:21,875] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:48:21,889] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run25
[2019-03-27 05:48:21,910] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run25
[2019-03-27 05:48:21,927] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run25
[2019-03-27 05:48:21,930] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run25
[2019-03-27 05:48:21,930] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run25
[2019-03-27 05:48:41,738] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:48:41,740] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.6, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6414120446719006, 6.9112, 6.9112, 168.912956510431, 570657.3007689115, 570657.3007689115, 172153.5537435152]
[2019-03-27 05:48:41,743] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:48:41,745] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.2995060e-22 3.0444870e-12 2.5436915e-23 4.9208670e-19], sampled 0.08163819576524156
[2019-03-27 05:48:41,926] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:48:41,928] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.124963215, 88.64262394, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5461523917668389, 6.9112, 6.9112, 168.912956510431, 482026.2131473377, 482026.2131473377, 158098.9667393255]
[2019-03-27 05:48:41,929] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:48:41,934] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.3179931e-22 2.5743186e-12 1.8685590e-23 2.6456920e-19], sampled 0.010673456492553579
[2019-03-27 05:49:14,502] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:49:14,505] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.87762218333333, 73.91054448666668, 1.0, 2.0, 0.7652950783427077, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995070212179404, 6.9112, 168.9123910187838, 1966503.655614806, 1907003.439702008, 399864.0330512251]
[2019-03-27 05:49:14,506] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:49:14,510] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.4385290e-01 9.4460308e-14 5.6147102e-02 7.1205778e-17 1.2876432e-11], sampled 0.46900458088847985
[2019-03-27 05:49:14,510] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1966503.655614806 W.
[2019-03-27 05:49:32,256] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:49:32,257] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8198597391293352, 6.911199999999999, 6.9112, 168.912956510431, 684271.5635466398, 684271.5635466403, 205905.7708257251]
[2019-03-27 05:49:32,259] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:49:32,263] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.4893718e-22 2.7790686e-11 6.9412912e-24 2.4703118e-19], sampled 0.4056421130072442
[2019-03-27 05:50:00,951] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:50:00,953] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.7, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4970168048314682, 6.9112, 6.9112, 168.912956510431, 440749.8059422688, 440749.8059422688, 151596.3594797358]
[2019-03-27 05:50:00,954] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:50:00,956] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 5.3458435e-22 1.5578899e-12 5.7943834e-23 5.4233089e-19], sampled 0.9418141792725364
[2019-03-27 05:50:11,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.056175556]
[2019-03-27 05:50:11,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8046394934771394, 6.911200000000001, 6.9112, 168.912956510431, 673652.8544986771, 673652.8544986764, 202774.2840644723]
[2019-03-27 05:50:11,401] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:50:11,402] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 1.18420415e-23 4.81987172e-13 5.14274645e-25
 1.69136011e-20], sampled 0.7851605073577531
[2019-03-27 05:50:16,052] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6855.6519 3198830586.0996 2277.0000
[2019-03-27 05:50:16,256] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7769.9557 2999123134.2338 1393.0000
[2019-03-27 05:50:16,337] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7153.9670 3327859954.0778 2059.0000
[2019-03-27 05:50:16,373] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7108.4346 3122079144.1644 1788.0000
[2019-03-27 05:50:16,550] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7910.9911 2947640490.9528 1249.0000
[2019-03-27 05:50:17,566] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 600000, evaluation results [600000.0, 7153.966955581325, 3327859954.077766, 2059.0, 7108.434599676367, 3122079144.1643715, 1788.0, 7910.991148729125, 2947640490.952752, 1249.0, 6855.651858005391, 3198830586.0996265, 2277.0, 7769.955701989901, 2999123134.2337914, 1393.0]
[2019-03-27 05:50:23,613] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9899369e-01 1.4569460e-16 1.0062673e-03 5.5934981e-20 5.6244119e-14], sum to 1.0000
[2019-03-27 05:50:23,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1671
[2019-03-27 05:50:23,628] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.06666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7736255144510019, 6.9112, 6.9112, 168.912956510431, 646354.0396976963, 646354.0396976963, 196445.8936130158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6716400.0000, 
sim time next is 6717000.0000, 
raw observation next is [28.93333333333333, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7771053419808159, 6.911200000000001, 6.9112, 168.912956510431, 650402.6171552644, 650402.6171552637, 197166.6301670468], 
processed observation next is [1.0, 0.7391304347826086, 0.5703001579778829, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7281772463180681, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1806673936542401, 0.1806673936542399, 0.29427855248812956], 
reward next is 0.7057, 
noisyNet noise sample is [array([-0.39970604], dtype=float32), 1.2395543]. 
=============================================
[2019-03-27 05:50:23,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.884422]
 [47.24613 ]
 [42.97843 ]
 [40.932426]
 [38.765236]], R is [[54.15816498]
 [54.32338333]
 [54.4899559 ]
 [54.64423752]
 [54.76014709]].
[2019-03-27 05:50:30,914] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.3496495e-25 4.0752072e-13 1.2386266e-25 1.3775074e-20], sum to 1.0000
[2019-03-27 05:50:30,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3683
[2019-03-27 05:50:30,929] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.63333333333333, 70.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5938720319674606, 6.9112, 6.9112, 168.912956510431, 518461.7341679638, 518461.7341679638, 165124.9035268374], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6820800.0000, 
sim time next is 6821400.0000, 
raw observation next is [24.51666666666667, 71.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5939431043597502, 6.9112, 6.9112, 168.912956510431, 518444.9361335237, 518444.9361335237, 165137.3317178406], 
processed observation next is [1.0, 0.9565217391304348, 0.36097946287519767, 0.7116666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5048086638533539, 0.0, 0.0, 0.8294399451523027, 0.14401248225931215, 0.14401248225931215, 0.24647362942961284], 
reward next is 0.7535, 
noisyNet noise sample is [array([1.8737168], dtype=float32), 0.4976144]. 
=============================================
[2019-03-27 05:50:32,056] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.5592080e-27 3.0615642e-17 6.7405638e-27 1.6202708e-23], sum to 1.0000
[2019-03-27 05:50:32,066] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0940
[2019-03-27 05:50:32,069] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6011199237112238, 6.911199999999999, 6.9112, 168.912956510431, 524204.8813087184, 524204.881308719, 166234.5734407607], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6838200.0000, 
sim time next is 6838800.0000, 
raw observation next is [23.1, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6022563715027557, 6.9112, 6.9112, 168.912956510431, 525077.1570925282, 525077.1570925282, 166410.354704869], 
processed observation next is [0.0, 0.13043478260869565, 0.2938388625592418, 0.8166666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5149467945155557, 0.0, 0.0, 0.8294399451523027, 0.14585476585903562, 0.14585476585903562, 0.24837366373861047], 
reward next is 0.7516, 
noisyNet noise sample is [array([0.12273018], dtype=float32), -0.62016195]. 
=============================================
[2019-03-27 05:50:34,157] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.6538270e-25 1.1594224e-16 1.9178225e-25 2.6890436e-22], sum to 1.0000
[2019-03-27 05:50:34,162] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1135
[2019-03-27 05:50:34,170] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.9, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4693677071879472, 6.9112, 6.9112, 168.912956510431, 419707.3587315264, 419707.3587315264, 148081.1735941965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6876000.0000, 
sim time next is 6876600.0000, 
raw observation next is [29.86666666666667, 31.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4661693020018569, 6.911199999999999, 6.9112, 168.912956510431, 416885.9759888996, 416885.9759889003, 147709.884189609], 
processed observation next is [0.0, 0.6086956521739131, 0.6145339652448659, 0.3116666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.34898695366080107, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11580165999691655, 0.11580165999691674, 0.22046251371583434], 
reward next is 0.7795, 
noisyNet noise sample is [array([0.32979384], dtype=float32), -1.1907862]. 
=============================================
[2019-03-27 05:50:50,070] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.0943627e-01 2.3877799e-12 7.9056370e-01 4.6944170e-16 4.6751016e-11], sum to 1.0000
[2019-03-27 05:50:50,081] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9458
[2019-03-27 05:50:50,086] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.15, 85.0, 1.0, 2.0, 0.6616465889533, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.963737785570329, 6.9112, 168.9126433746077, 1821460.15353868, 1784188.109340203, 377908.0359731161], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7144200.0000, 
sim time next is 7144800.0000, 
raw observation next is [26.13333333333333, 85.33333333333333, 1.0, 2.0, 0.6175919317470766, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.916364063456335, 6.9112, 168.9128537190815, 1726812.934962668, 1723149.372842846, 369238.3623259772], 
processed observation next is [1.0, 0.6956521739130435, 0.43759873617693507, 0.8533333333333333, 1.0, 1.0, 0.5392673876470803, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0005164063456335021, 0.0, 0.8294394403997186, 0.47967025971185223, 0.4786526035674572, 0.551102033322354], 
reward next is 0.4231, 
noisyNet noise sample is [array([-0.20562641], dtype=float32), 0.55572265]. 
=============================================
[2019-03-27 05:51:08,538] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.7265097e-28 1.7077263e-17 2.5968856e-27 5.6716335e-23], sum to 1.0000
[2019-03-27 05:51:08,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1118
[2019-03-27 05:51:08,550] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.06666666666667, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6550404974819665, 6.9112, 6.9112, 168.912956510431, 563972.4160132934, 563972.4160132934, 174936.0526836864], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7533600.0000, 
sim time next is 7534200.0000, 
raw observation next is [23.03333333333333, 90.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6516657794605784, 6.9112, 6.9112, 168.912956510431, 561413.998717409, 561413.998717409, 174371.7354238807], 
processed observation next is [0.0, 0.17391304347826086, 0.29067930489731436, 0.9016666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.575202170073876, 0.0, 0.0, 0.8294399451523027, 0.15594833297705804, 0.15594833297705804, 0.2602563215281801], 
reward next is 0.7397, 
noisyNet noise sample is [array([-0.5149769], dtype=float32), 0.98972106]. 
=============================================
[2019-03-27 05:51:11,173] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.1590481e-27 1.4354964e-16 2.6463689e-26 1.3324680e-23], sum to 1.0000
[2019-03-27 05:51:11,184] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6569
[2019-03-27 05:51:11,191] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.15, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6987805255021121, 6.911199999999999, 6.9112, 168.912956510431, 597081.3529848715, 597081.3529848721, 182508.7467854132], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7506600.0000, 
sim time next is 7507200.0000, 
raw observation next is [24.1, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6975088044661185, 6.911199999999999, 6.9112, 168.912956510431, 595894.2537914377, 595894.2537914383, 182280.9898537283], 
processed observation next is [0.0, 0.9130434782608695, 0.3412322274881518, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6311082981294127, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1655261816087327, 0.16552618160873286, 0.27206117888616166], 
reward next is 0.7279, 
noisyNet noise sample is [array([-0.63697964], dtype=float32), -0.07301727]. 
=============================================
[2019-03-27 05:51:11,762] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-27 05:51:11,763] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:51:11,763] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:51:11,764] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:51:11,766] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:51:11,767] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:51:11,768] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:51:11,769] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:51:11,770] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:51:11,771] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:51:11,772] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:51:11,792] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run26
[2019-03-27 05:51:11,812] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run26
[2019-03-27 05:51:11,829] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run26
[2019-03-27 05:51:11,830] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run26
[2019-03-27 05:51:11,858] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run26
[2019-03-27 05:51:21,395] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:51:21,396] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [11.49395351, 94.77777289, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2751821435949437, 6.911199999999999, 6.9112, 168.912956510431, 249594.5675936636, 249594.5675936643, 75835.1406645953]
[2019-03-27 05:51:21,397] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:51:21,399] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.1840704e-24 8.5603454e-15 3.2520769e-24 4.8183812e-21], sampled 0.33818048849319615
[2019-03-27 05:51:29,298] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:51:29,299] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.1, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4660176218285882, 6.911200000000001, 6.9112, 168.912956510431, 416450.4133599662, 416450.4133599656, 147712.4512211637]
[2019-03-27 05:51:29,303] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:51:29,305] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.8605177e-25 9.4489083e-15 2.9965808e-25 1.0762013e-21], sampled 0.8360693567313227
[2019-03-27 05:52:02,520] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:52:02,521] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.73333333333333, 57.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.553926953372778, 6.9112, 168.909403890313, 1910030.276749871, 1454067.245204453, 311353.1993785139]
[2019-03-27 05:52:02,522] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:52:02,526] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.3113438e-01 2.2812438e-13 1.6886559e-01 4.6189940e-16 1.5150128e-11], sampled 0.9449698119753278
[2019-03-27 05:52:32,496] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:52:32,496] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.61954622666666, 88.71513861333332, 1.0, 2.0, 0.7490869581072198, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564560602, 1046904.1809953, 1046904.1809953, 231801.7391261308]
[2019-03-27 05:52:32,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:52:32,502] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999988e-01 2.5553394e-18 1.0331496e-07 1.3917001e-19 4.9153396e-16], sampled 0.7929729408719449
[2019-03-27 05:52:32,503] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1046904.1809953 W.
[2019-03-27 05:52:36,668] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:52:36,668] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.53333333333334, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9584285298955011, 6.9112, 6.9112, 168.912956510431, 778407.1397231638, 778407.1397231638, 236887.806380691]
[2019-03-27 05:52:36,669] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:52:36,670] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 2.93760977e-27 1.81285337e-15 9.47638807e-28
 1.24023544e-23], sampled 0.6634978676223205
[2019-03-27 05:52:46,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:52:46,545] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.43333333333334, 85.0, 1.0, 2.0, 0.4972048661313572, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129564953248, 694765.2734237368, 694765.2734237375, 183161.5521853305]
[2019-03-27 05:52:46,547] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:52:46,549] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9595624e-01 2.9064583e-16 4.0437444e-03 5.5656341e-19 3.0462764e-14], sampled 0.543121269817598
[2019-03-27 05:53:02,797] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02373195], dtype=float32), 0.058736384]
[2019-03-27 05:53:02,798] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.3, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.823989735646577, 6.911199999999999, 6.9112, 168.912956510431, 682794.3316196293, 682794.3316196299, 206635.7260043544]
[2019-03-27 05:53:02,798] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:53:02,800] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.3148132e-22 9.3555226e-09 3.2200306e-24 1.1554954e-19], sampled 0.5697100118802275
[2019-03-27 05:53:05,635] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7221.5940 3321918352.5700 2114.0000
[2019-03-27 05:53:05,966] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6930.8030 3189429520.6284 2388.0000
[2019-03-27 05:53:06,151] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7971.6768 2941337499.5359 1332.0000
[2019-03-27 05:53:06,390] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7181.0746 3112127658.7880 1915.0000
[2019-03-27 05:53:06,466] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7823.2173 2992585510.6134 1506.0000
[2019-03-27 05:53:07,478] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 625000, evaluation results [625000.0, 7221.594030176147, 3321918352.569958, 2114.0, 7181.0745519727725, 3112127658.7880316, 1915.0, 7971.676769597417, 2941337499.5359282, 1332.0, 6930.803023119617, 3189429520.628376, 2388.0, 7823.217294834242, 2992585510.6134224, 1506.0]
[2019-03-27 05:53:08,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.5965347e-25 4.1954876e-15 6.1050395e-26 3.5776294e-22], sum to 1.0000
[2019-03-27 05:53:08,943] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7459
[2019-03-27 05:53:08,952] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7640248407778151, 6.911200000000001, 6.9112, 168.912956510431, 642895.3599905617, 642895.3599905611, 194648.4862333383], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7561800.0000, 
sim time next is 7562400.0000, 
raw observation next is [29.0, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7584783382636974, 6.9112, 6.9112, 168.912956510431, 638945.6299543233, 638945.6299543233, 193576.3108126265], 
processed observation next is [0.0, 0.5217391304347826, 0.5734597156398105, 0.64, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7054613881264601, 0.0, 0.0, 0.8294399451523027, 0.17748489720953425, 0.17748489720953425, 0.28891986688451715], 
reward next is 0.7111, 
noisyNet noise sample is [array([-1.2136072], dtype=float32), 0.76839197]. 
=============================================
[2019-03-27 05:53:09,463] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.6258862e-25 1.7172267e-11 5.2383372e-26 1.5989723e-21], sum to 1.0000
[2019-03-27 05:53:09,473] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5643
[2019-03-27 05:53:09,478] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.66666666666667, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8136718493816358, 6.911199999999999, 6.9112, 168.912956510431, 681068.175803685, 681068.1758036857, 204653.341150828], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7683000.0000, 
sim time next is 7683600.0000, 
raw observation next is [25.63333333333334, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8099627052557451, 6.9112, 6.9112, 168.912956510431, 678268.8769390162, 678268.8769390162, 203884.8534992929], 
processed observation next is [1.0, 0.9565217391304348, 0.4139020537124806, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7682472015313964, 0.0, 0.0, 0.8294399451523027, 0.18840802137194892, 0.18840802137194892, 0.3043057514914819], 
reward next is 0.6957, 
noisyNet noise sample is [array([-0.69428223], dtype=float32), 1.2955571]. 
=============================================
[2019-03-27 05:53:18,579] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.2349332e-24 1.2905930e-12 7.8841298e-26 1.9861245e-20], sum to 1.0000
[2019-03-27 05:53:18,590] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0229
[2019-03-27 05:53:18,596] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.75, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7933178692398191, 6.9112, 6.9112, 168.912956510431, 665951.6936347899, 665951.6936347899, 200485.2385264415], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7695000.0000, 
sim time next is 7695600.0000, 
raw observation next is [24.7, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7956941441427612, 6.9112, 6.9112, 168.912956510431, 667810.0132973973, 667810.0132973973, 200968.415686114], 
processed observation next is [1.0, 0.043478260869565216, 0.3696682464454976, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7508465172472698, 0.0, 0.0, 0.8294399451523027, 0.18550278147149926, 0.18550278147149926, 0.29995285923300596], 
reward next is 0.7000, 
noisyNet noise sample is [array([-1.4841985], dtype=float32), 0.46320024]. 
=============================================
[2019-03-27 05:53:19,341] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9999976e-01 3.4678661e-19 1.8639749e-07 3.4985030e-21 1.0199092e-16], sum to 1.0000
[2019-03-27 05:53:19,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7488
[2019-03-27 05:53:19,356] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1042526.070307162 W.
[2019-03-27 05:53:19,365] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.23333333333333, 85.5, 1.0, 1.0, 0.7459558430896785, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9125873192747, 1042526.070307162, 1042526.070307162, 231076.8018925073], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7717800.0000, 
sim time next is 7718400.0000, 
raw observation next is [27.4, 85.0, 1.0, 2.0, 0.3343134142378454, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5688112948811332, 6.911200000000001, 6.9112, 168.912956418242, 934405.7548875161, 934405.7548875154, 232250.685478773], 
processed observation next is [1.0, 0.34782608695652173, 0.4976303317535545, 0.85, 1.0, 1.0, 0.19796796896125948, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.47416011570869904, 8.881784197001253e-17, 0.0, 0.8294399446996125, 0.25955715413542113, 0.25955715413542096, 0.3466428141474224], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71035874], dtype=float32), 0.042625774]. 
=============================================
[2019-03-27 05:53:22,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.9223168e-24 9.0769970e-12 6.4053805e-25 6.5287641e-21], sum to 1.0000
[2019-03-27 05:53:22,328] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2309
[2019-03-27 05:53:22,333] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8468280311745828, 6.9112, 6.9112, 168.912956510431, 703384.5230968969, 703384.5230968969, 211601.2950489073], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7780200.0000, 
sim time next is 7780800.0000, 
raw observation next is [26.4, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8424533514155615, 6.911199999999999, 6.9112, 168.912956510431, 700220.1590717006, 700220.1590717013, 210663.2798859811], 
processed observation next is [1.0, 0.043478260869565216, 0.45023696682464454, 0.8633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8078699407506847, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19450559974213907, 0.19450559974213927, 0.3144228057999718], 
reward next is 0.6856, 
noisyNet noise sample is [array([-0.43872717], dtype=float32), 0.7138134]. 
=============================================
[2019-03-27 05:53:23,518] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999976e-01 2.9021470e-18 1.8365823e-07 3.1889871e-20 7.0801674e-16], sum to 1.0000
[2019-03-27 05:53:23,528] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-27 05:53:23,532] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 89.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9766584523583944, 6.911200000000001, 6.9112, 168.9129565027155, 814305.4039848585, 814305.403984858, 242314.002902003], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7795800.0000, 
sim time next is 7796400.0000, 
raw observation next is [25.93333333333333, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9683227908757607, 6.9112, 6.9112, 168.912956510429, 806829.9877070438, 806829.9877070438, 240194.2787263514], 
processed observation next is [1.0, 0.21739130434782608, 0.42812006319115314, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9613692571655617, 0.0, 0.0, 0.8294399451522929, 0.22411944102973438, 0.22411944102973438, 0.3584989234721663], 
reward next is 0.6415, 
noisyNet noise sample is [array([0.20930927], dtype=float32), -0.6060423]. 
=============================================
[2019-03-27 05:53:26,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:26,344] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:26,377] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run4
[2019-03-27 05:53:26,941] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.86540496e-01 1.43275538e-14 1.34594655e-02 2.58162573e-17
 2.24337194e-12], sum to 1.0000
[2019-03-27 05:53:26,950] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0052
[2019-03-27 05:53:26,957] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 941327.8425950287 W.
[2019-03-27 05:53:26,960] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.73333333333334, 86.0, 1.0, 1.0, 0.3367889141835014, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5694226091940453, 6.911199999999999, 6.9112, 168.9126367810289, 941327.8425950287, 941327.8425950293, 232682.3471085587], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7885200.0000, 
sim time next is 7885800.0000, 
raw observation next is [26.8, 85.5, 1.0, 2.0, 0.6365727544229748, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129564305931, 889591.4371251684, 889591.437125169, 207748.6287533467], 
processed observation next is [1.0, 0.2608695652173913, 0.4691943127962086, 0.855, 1.0, 1.0, 0.5621358487023792, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399447602621, 0.247108732534769, 0.24710873253476917, 0.3100725802288757], 
reward next is 0.6899, 
noisyNet noise sample is [array([-1.0201693], dtype=float32), -1.0175737]. 
=============================================
[2019-03-27 05:53:29,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:29,590] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:29,631] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run4
[2019-03-27 05:53:30,324] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.4684110e-02 3.0420124e-14 9.8531586e-01 1.9142695e-19 6.9529892e-14], sum to 1.0000
[2019-03-27 05:53:30,327] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5287
[2019-03-27 05:53:30,334] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.36666666666666, 67.5, 1.0, 2.0, 0.9696512517851724, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.985110710611957, 6.9112, 168.9124560294091, 2252524.167522649, 2200089.520966002, 454868.9543711131], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7915800.0000, 
sim time next is 7916400.0000, 
raw observation next is [30.4, 67.0, 1.0, 2.0, 0.9245091104193859, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984097858721933, 6.9112, 168.9124626329699, 2189343.027667234, 2137626.928950187, 441737.3305863244], 
processed observation next is [1.0, 0.6521739130434783, 0.6398104265402843, 0.67, 1.0, 1.0, 0.9090471209872119, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007289785872193288, 0.0, 0.8294375199878705, 0.6081508410186761, 0.5937852580417186, 0.659309448636305], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9016446], dtype=float32), 1.0841994]. 
=============================================
[2019-03-27 05:53:30,687] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.1907758e-23 5.4050733e-11 5.7973846e-25 6.5854472e-20], sum to 1.0000
[2019-03-27 05:53:30,694] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1705
[2019-03-27 05:53:30,699] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.7, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8996469150880452, 6.911199999999999, 6.9112, 168.912956510431, 740132.1758280952, 740132.1758280959, 223250.3158140101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7943400.0000, 
sim time next is 7944000.0000, 
raw observation next is [26.63333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8974517386302397, 6.9112, 6.9112, 168.912956510431, 738287.1356138227, 738287.1356138227, 222740.0646413726], 
processed observation next is [1.0, 0.9565217391304348, 0.46129541864139006, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8749411446710239, 0.0, 0.0, 0.8294399451523027, 0.20507975989272853, 0.20507975989272853, 0.33244785767369045], 
reward next is 0.6676, 
noisyNet noise sample is [array([-0.04911883], dtype=float32), 1.304088]. 
=============================================
[2019-03-27 05:53:30,716] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[61.012817]
 [60.985077]
 [60.875847]
 [60.930027]
 [60.91592 ]], R is [[61.10420609]
 [61.15995407]
 [61.21517944]
 [61.27114868]
 [61.32712173]].
[2019-03-27 05:53:31,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:31,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:31,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run4
[2019-03-27 05:53:31,999] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,000] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,008] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run4
[2019-03-27 05:53:32,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run4
[2019-03-27 05:53:32,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,060] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run4
[2019-03-27 05:53:32,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,123] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,128] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run4
[2019-03-27 05:53:32,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,212] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,217] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run4
[2019-03-27 05:53:32,301] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,307] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run4
[2019-03-27 05:53:32,326] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,327] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,327] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,328] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run4
[2019-03-27 05:53:32,341] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run4
[2019-03-27 05:53:32,416] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,416] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,418] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run4
[2019-03-27 05:53:32,451] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,452] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,453] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run4
[2019-03-27 05:53:32,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,483] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run4
[2019-03-27 05:53:32,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,505] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,506] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run4
[2019-03-27 05:53:32,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 05:53:32,593] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:53:32,595] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run4
[2019-03-27 05:53:33,874] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.9705847e-16 2.7802287e-08 8.2785943e-17 3.0935835e-14], sum to 1.0000
[2019-03-27 05:53:33,879] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6891
[2019-03-27 05:53:33,881] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5829752598515139, 6.9112, 6.9112, 168.912956510431, 515866.1548263548, 515866.1548263548, 163273.5625391365], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 12000.0000, 
sim time next is 12600.0000, 
raw observation next is [21.1, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849435658473026, 6.911200000000001, 6.9112, 168.912956510431, 517453.0357388292, 517453.0357388285, 163570.2498476895], 
processed observation next is [1.0, 0.13043478260869565, 0.1990521327014219, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4938336168869543, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14373695437189699, 0.1437369543718968, 0.2441347012652082], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.93752414], dtype=float32), -0.7948463]. 
=============================================
[2019-03-27 05:53:38,680] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.4421489e-27 4.8049441e-14 1.9379575e-26 1.5683071e-23], sum to 1.0000
[2019-03-27 05:53:38,688] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7026
[2019-03-27 05:53:38,696] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6913353302400441, 6.9112, 6.9112, 168.912956510431, 599538.9229341301, 599538.9229341301, 181140.7003035004], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 98400.0000, 
sim time next is 99000.0000, 
raw observation next is [22.5, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6914967052332915, 6.9112, 6.9112, 168.912956510431, 599667.7422333704, 599667.7422333704, 181169.4019481931], 
processed observation next is [1.0, 0.13043478260869565, 0.2654028436018958, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6237764697966969, 0.0, 0.0, 0.8294399451523027, 0.1665743728426029, 0.1665743728426029, 0.2704020924599897], 
reward next is 0.7296, 
noisyNet noise sample is [array([0.75999653], dtype=float32), -0.49718598]. 
=============================================
[2019-03-27 05:53:38,709] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[71.20887]
 [71.0568 ]
 [70.81448]
 [70.38942]
 [70.10427]], R is [[71.60407257]
 [71.61766815]
 [71.61669922]
 [71.63018036]
 [71.64684296]].
[2019-03-27 05:53:41,131] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9994040e-01 1.5834517e-16 5.9542323e-05 1.0025016e-18 1.0053644e-14], sum to 1.0000
[2019-03-27 05:53:41,138] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3101
[2019-03-27 05:53:41,148] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1044454.445147141 W.
[2019-03-27 05:53:41,151] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.9, 93.33333333333334, 1.0, 2.0, 0.352673245226284, 1.0, 1.0, 0.352673245226284, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1044454.445147141, 1044454.445147141, 268086.3238280166], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 121200.0000, 
sim time next is 121800.0000, 
raw observation next is [22.9, 93.66666666666667, 1.0, 2.0, 0.6796897086039884, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1014566.050376067, 1014566.050376068, 224853.3845052924], 
processed observation next is [1.0, 0.391304347826087, 0.2843601895734597, 0.9366666666666668, 1.0, 1.0, 0.6140839862698655, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28182390288224085, 0.28182390288224113, 0.33560206642580953], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41587692], dtype=float32), -0.10658909]. 
=============================================
[2019-03-27 05:53:41,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.5520723e-21 2.5927434e-08 7.5193426e-23 5.3717523e-19], sum to 1.0000
[2019-03-27 05:53:41,758] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0876
[2019-03-27 05:53:41,762] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6696405569794744, 6.9112, 6.9112, 168.912956510431, 575872.5079116046, 575872.5079116046, 177408.0986112542], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 151200.0000, 
sim time next is 151800.0000, 
raw observation next is [22.48333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6756373590076984, 6.911199999999999, 6.9112, 168.912956510431, 581081.8251097152, 581081.8251097158, 178438.8527447254], 
processed observation next is [1.0, 0.782608695652174, 0.26461295418641384, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6044358036679248, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.161411618086032, 0.16141161808603216, 0.2663266458876498], 
reward next is 0.7337, 
noisyNet noise sample is [array([1.4566814], dtype=float32), -1.4708184]. 
=============================================
[2019-03-27 05:53:47,636] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2330019e-26 1.3234405e-16 1.7696610e-25 8.0038364e-24], sum to 1.0000
[2019-03-27 05:53:47,646] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4535
[2019-03-27 05:53:47,652] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5695812224093846, 6.9112, 6.9112, 168.912956510431, 498106.7996662023, 498106.7996662023, 161531.7759618097], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [23.56666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5700220617672406, 6.9112, 6.9112, 168.912956510431, 498449.7570176365, 498449.7570176365, 161596.2226706574], 
processed observation next is [0.0, 0.5217391304347826, 0.31595576619273325, 0.7616666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47563666069175675, 0.0, 0.0, 0.8294399451523027, 0.13845826583823237, 0.13845826583823237, 0.2411883920457573], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.02471974], dtype=float32), 0.43045083]. 
=============================================
[2019-03-27 05:53:51,484] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.4148718e-28 1.4586243e-17 2.6168939e-27 7.0734988e-24], sum to 1.0000
[2019-03-27 05:53:51,494] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2647
[2019-03-27 05:53:51,501] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 76.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5695812224093846, 6.9112, 6.9112, 168.912956510431, 498106.7996662023, 498106.7996662023, 161531.7759618097], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 304800.0000, 
sim time next is 305400.0000, 
raw observation next is [23.56666666666667, 76.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5700220617672406, 6.9112, 6.9112, 168.912956510431, 498449.7570176365, 498449.7570176365, 161596.2226706574], 
processed observation next is [0.0, 0.5217391304347826, 0.31595576619273325, 0.7616666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47563666069175675, 0.0, 0.0, 0.8294399451523027, 0.13845826583823237, 0.13845826583823237, 0.2411883920457573], 
reward next is 0.7588, 
noisyNet noise sample is [array([-0.8888911], dtype=float32), -0.61297536]. 
=============================================
[2019-03-27 05:53:53,854] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.3971772e-25 4.0901154e-15 1.0416643e-25 4.1059993e-22], sum to 1.0000
[2019-03-27 05:53:53,857] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3713
[2019-03-27 05:53:53,862] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.03333333333333, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4714067393260039, 6.9112, 6.9112, 168.912956510431, 418631.7409646709, 418631.7409646709, 148488.165324055], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 362400.0000, 
sim time next is 363000.0000, 
raw observation next is [20.01666666666667, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4722024487260476, 6.9112, 6.9112, 168.912956510431, 419326.6400830902, 419326.6400830902, 148581.7131029783], 
processed observation next is [1.0, 0.17391304347826086, 0.14770932069510287, 0.8983333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3563444496659117, 0.0, 0.0, 0.8294399451523027, 0.11647962224530284, 0.11647962224530284, 0.2217637508999676], 
reward next is 0.7782, 
noisyNet noise sample is [array([0.54355884], dtype=float32), 1.6803951]. 
=============================================
[2019-03-27 05:53:53,885] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[72.28639]
 [72.52565]
 [72.62833]
 [72.83192]
 [72.91124]], R is [[72.33831024]
 [72.39330292]
 [72.44792175]
 [72.50252533]
 [72.5565033 ]].
[2019-03-27 05:53:54,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.6558068e-25 2.7505930e-14 1.5527208e-25 4.4200752e-22], sum to 1.0000
[2019-03-27 05:53:54,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5445
[2019-03-27 05:53:54,836] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.01666666666667, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4722024487260476, 6.9112, 6.9112, 168.912956510431, 419326.6400830902, 419326.6400830902, 148581.7131029783], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 363000.0000, 
sim time next is 363600.0000, 
raw observation next is [20.0, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4732181151967695, 6.911200000000001, 6.9112, 168.912956510431, 420216.9715948617, 420216.9715948611, 148701.1986171561], 
processed observation next is [1.0, 0.21739130434782608, 0.1469194312796209, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3575830673131335, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11672693655412825, 0.1167269365541281, 0.2219420874882927], 
reward next is 0.7781, 
noisyNet noise sample is [array([0.45004353], dtype=float32), -0.49876174]. 
=============================================
[2019-03-27 05:53:55,561] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.0292166e-26 6.9965383e-15 8.8136539e-26 7.7303516e-23], sum to 1.0000
[2019-03-27 05:53:55,574] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7367
[2019-03-27 05:53:55,578] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.25, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.608763056378888, 6.9112, 6.9112, 168.912956510431, 541376.6389771566, 541376.6389771566, 167012.2974316375], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 376200.0000, 
sim time next is 376800.0000, 
raw observation next is [21.33333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6580614902495663, 6.911200000000001, 6.9112, 168.912956510431, 585056.6533695924, 585056.6533695918, 174917.2406800401], 
processed observation next is [1.0, 0.34782608695652173, 0.21011058451816728, 0.7866666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5830018173775198, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.162515737047109, 0.16251573704710884, 0.26107050847767177], 
reward next is 0.7389, 
noisyNet noise sample is [array([0.83042777], dtype=float32), -0.44717303]. 
=============================================
[2019-03-27 05:53:58,374] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.1913826e-26 1.1194898e-15 2.8443632e-27 1.2127539e-23], sum to 1.0000
[2019-03-27 05:53:58,382] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5898
[2019-03-27 05:53:58,387] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.95, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4586495625271128, 6.911200000000001, 6.9112, 168.912956510431, 409676.4962874188, 409676.4962874181, 146885.5000212802], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 425400.0000, 
sim time next is 426000.0000, 
raw observation next is [19.9, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4598453029713757, 6.9112, 6.9112, 168.912956510431, 410761.8222188284, 410761.8222188284, 147019.6391561372], 
processed observation next is [1.0, 0.9565217391304348, 0.14218009478672985, 0.8466666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.34127475972118987, 0.0, 0.0, 0.8294399451523027, 0.11410050617189678, 0.11410050617189678, 0.21943229724796595], 
reward next is 0.7806, 
noisyNet noise sample is [array([1.6652145], dtype=float32), 0.24739805]. 
=============================================
[2019-03-27 05:53:58,408] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[79.577225]
 [79.32438 ]
 [79.28428 ]
 [79.21697 ]
 [78.78843 ]], R is [[79.55393219]
 [79.53916168]
 [79.52475739]
 [79.51049805]
 [79.49578857]].
[2019-03-27 05:53:58,415] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.6247593e-27 3.6041756e-15 7.9644429e-27 4.3193789e-23], sum to 1.0000
[2019-03-27 05:53:58,423] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1937
[2019-03-27 05:53:58,427] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.75, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4550531231332387, 6.911199999999999, 6.9112, 168.912956510431, 406555.8672708419, 406555.8672708425, 146475.0545220589], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 427800.0000, 
sim time next is 428400.0000, 
raw observation next is [19.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4536787683459516, 6.911200000000001, 6.9112, 168.912956510431, 405354.9084954147, 405354.9084954141, 146319.6596534148], 
processed observation next is [1.0, 1.0, 0.1327014218009479, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3337545955438434, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11259858569317076, 0.11259858569317059, 0.2183875517215146], 
reward next is 0.7816, 
noisyNet noise sample is [array([-0.473303], dtype=float32), -0.84069425]. 
=============================================
[2019-03-27 05:54:01,696] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 05:54:01,700] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:54:01,700] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:54:01,701] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:54:01,701] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:54:01,703] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:54:01,702] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:54:01,705] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:54:01,703] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:54:01,706] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:54:01,709] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:54:01,725] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run27
[2019-03-27 05:54:01,745] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run27
[2019-03-27 05:54:01,765] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run27
[2019-03-27 05:54:01,766] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run27
[2019-03-27 05:54:01,768] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run27
[2019-03-27 05:54:05,111] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:05,113] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.9, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237682320640957, 6.9112, 6.9112, 168.912956510431, 462614.4258105197, 462614.4258105197, 155083.1364515549]
[2019-03-27 05:54:05,114] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:54:05,117] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 7.6212587e-29 1.3116031e-18 2.5241883e-28 1.7651640e-25], sampled 0.3674969021219464
[2019-03-27 05:54:19,569] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:19,570] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.86666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.654850849998744, 6.9112, 6.9112, 168.912956510431, 569940.3009527042, 569940.3009527042, 174834.3941969737]
[2019-03-27 05:54:19,570] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:54:19,572] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 7.2167087e-29 2.5789500e-18 2.2390472e-28 1.8262889e-25], sampled 0.37576471284312574
[2019-03-27 05:54:27,629] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:27,631] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.8, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7948960558208451, 6.9112, 6.9112, 168.912956510431, 671587.9333844536, 671587.9333844536, 200886.7948288283]
[2019-03-27 05:54:27,631] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 05:54:27,634] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.3243952e-21 2.1352142e-09 5.3125846e-22 7.2755115e-19], sampled 0.8981889738756508
[2019-03-27 05:54:29,207] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:29,209] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.51666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.793894880091703, 6.911199999999999, 6.9112, 168.912956510431, 677225.1522928609, 677225.1522928616, 200750.8833657535]
[2019-03-27 05:54:29,210] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:54:29,213] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 6.5445712e-29 3.6668114e-18 1.7809545e-28 2.0799112e-25], sampled 0.502625433338624
[2019-03-27 05:54:30,467] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:30,468] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.29972443333333, 86.42965689333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7311395874427407, 6.911199999999999, 6.9112, 168.912956510431, 624079.063472143, 624079.0634721436, 188439.3284554824]
[2019-03-27 05:54:30,469] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:54:30,474] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 9.3149513e-30 6.3660833e-19 2.6661033e-29 3.1632922e-26], sampled 0.8645883487952887
[2019-03-27 05:54:46,864] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:46,866] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.469341755, 87.27978703333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8609033963672513, 6.9112, 6.9112, 168.912956510431, 740803.2033357377, 740803.2033357377, 215079.8789821138]
[2019-03-27 05:54:46,869] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:54:46,872] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.1040646e-29 2.8753261e-18 1.9328169e-28 1.8418349e-25], sampled 0.9936102744280141
[2019-03-27 05:54:52,970] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:52,971] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.7986823087826467, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.989980470932982, 6.9112, 168.9124242542631, 2013229.260445397, 1957339.859062831, 408111.5311471771]
[2019-03-27 05:54:52,974] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:54:52,979] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9248695e-01 1.2233258e-14 7.5130123e-03 6.8537525e-17 4.1415474e-13], sampled 0.09273084356477967
[2019-03-27 05:54:52,981] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2013229.260445397 W.
[2019-03-27 05:54:55,845] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:54:55,847] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.28113271833333, 92.82806508499999, 1.0, 2.0, 0.6512581227120288, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104237, 910122.5944528783, 910122.5944528776, 210684.0152813756]
[2019-03-27 05:54:55,848] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:54:55,851] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 7.6341099e-24 5.4571527e-13 4.3441134e-24 9.7154802e-21], sampled 0.8946252174751392
[2019-03-27 05:54:55,853] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 910122.5944528783 W.
[2019-03-27 05:55:03,687] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:55:03,690] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [33.356079875, 59.12571042666666, 1.0, 2.0, 0.7437745249364249, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1039476.030686161, 1039476.030686161, 230580.5966008149]
[2019-03-27 05:55:03,690] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:55:03,692] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9959821e-01 8.9399874e-17 4.0179520e-04 6.1581953e-19 3.3968014e-15], sampled 0.792146599708497
[2019-03-27 05:55:03,695] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1039476.030686161 W.
[2019-03-27 05:55:06,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:55:06,581] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.92295205, 86.939876365, 1.0, 1.0, 0.6008416051865212, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9128450170311, 839638.484847677, 839638.484847677, 200899.7961566896]
[2019-03-27 05:55:06,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:55:06,584] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 5.9380617e-24 2.7352602e-13 2.0612715e-24 5.9304419e-21], sampled 0.6146277936536948
[2019-03-27 05:55:39,492] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.061027907]
[2019-03-27 05:55:39,493] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.96508754, 59.4357867, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.213170942565863, 6.9112, 168.9114097187279, 1102228.297935887, 888001.6800037373, 256618.3394912957]
[2019-03-27 05:55:39,494] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:55:39,499] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.7845513e-21 3.0458375e-10 6.8860196e-22 7.0608732e-19], sampled 0.36764204793511635
[2019-03-27 05:55:39,500] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1102228.297935887 W.
[2019-03-27 05:55:55,830] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8058.4886 2937947951.9541 1375.0000
[2019-03-27 05:55:56,097] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.2730 3320117114.1792 2145.0000
[2019-03-27 05:55:56,180] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7911.3356 2989777954.2588 1560.0000
[2019-03-27 05:55:56,318] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7321.3984 3106354273.1719 1996.0000
[2019-03-27 05:55:56,476] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7025.0181 3185677216.9367 2450.0000
[2019-03-27 05:55:57,493] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 650000, evaluation results [650000.0, 7286.272982619711, 3320117114.179155, 2145.0, 7321.398434997507, 3106354273.1718507, 1996.0, 8058.488562226268, 2937947951.954074, 1375.0, 7025.018142428823, 3185677216.936705, 2450.0, 7911.335641698354, 2989777954.2588134, 1560.0]
[2019-03-27 05:55:58,416] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.6785737e-29 1.7992713e-18 1.0003902e-28 1.3347297e-26], sum to 1.0000
[2019-03-27 05:55:58,427] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4319
[2019-03-27 05:55:58,437] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4802137523046955, 6.9112, 6.9112, 168.912956510431, 427311.7269864683, 427311.7269864683, 149481.0918350113], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 792600.0000, 
sim time next is 793200.0000, 
raw observation next is [19.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4802604117079814, 6.9112, 6.9112, 168.912956510431, 427342.1188710238, 427342.1188710238, 149487.2548987025], 
processed observation next is [0.0, 0.17391304347826086, 0.11848341232227487, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3661712337902212, 0.0, 0.0, 0.8294399451523027, 0.11870614413083995, 0.11870614413083995, 0.22311530581895894], 
reward next is 0.7769, 
noisyNet noise sample is [array([0.5569393], dtype=float32), -0.93003714]. 
=============================================
[2019-03-27 05:55:59,635] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.6047235e-27 1.2824289e-16 7.9196042e-27 4.5082830e-23], sum to 1.0000
[2019-03-27 05:55:59,644] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9885
[2019-03-27 05:55:59,651] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.8, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4056311384330072, 6.9112, 6.9112, 168.912956510431, 364991.9936182111, 364991.9936182111, 141072.7768631206], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 540000.0000, 
sim time next is 540600.0000, 
raw observation next is [19.0, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4066916117670736, 6.911200000000001, 6.9112, 168.912956510431, 365717.7777312685, 365717.7777312679, 141196.82744069], 
processed observation next is [1.0, 0.2608695652173913, 0.09952606635071096, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.27645318508179706, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10158827159201902, 0.10158827159201886, 0.21074153349356714], 
reward next is 0.7893, 
noisyNet noise sample is [array([0.5230801], dtype=float32), 0.29562306]. 
=============================================
[2019-03-27 05:56:01,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.0252978e-22 3.2365712e-08 5.2163926e-22 9.0125869e-18], sum to 1.0000
[2019-03-27 05:56:01,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-27 05:56:01,184] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1049942.525081191 W.
[2019-03-27 05:56:01,193] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.78333333333333, 54.5, 1.0, 2.0, 0.6431694234720878, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1049942.525081191, 1049942.525081191, 225085.7767322022], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 561000.0000, 
sim time next is 561600.0000, 
raw observation next is [25.0, 54.0, 1.0, 2.0, 0.2091194745550593, 1.0, 1.0, 0.2091194745550593, 1.0, 1.0, 0.3835745400834542, 6.911199999999999, 6.9112, 170.5573041426782, 1022072.838017549, 1022072.83801755, 286292.9778625049], 
processed observation next is [1.0, 0.5217391304347826, 0.38388625592417064, 0.54, 1.0, 1.0, 0.0471318970542883, 1.0, 0.5, 0.0471318970542883, 1.0, 0.5, 0.24826163424811487, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2839091216715414, 0.28390912167154164, 0.42730295203358937], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.5654329], dtype=float32), -0.7619802]. 
=============================================
[2019-03-27 05:56:05,292] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.5142134e-26 9.3052459e-17 2.7352840e-26 3.1757628e-23], sum to 1.0000
[2019-03-27 05:56:05,305] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7106
[2019-03-27 05:56:05,312] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.05, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3735135658973495, 6.9112, 6.9112, 168.912956510431, 338178.3682727466, 338178.3682727466, 137843.8152831165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 617400.0000, 
sim time next is 618000.0000, 
raw observation next is [17.03333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3727176079988087, 6.9112, 6.9112, 168.912956510431, 337490.9929626672, 337490.9929626672, 137769.0500488444], 
processed observation next is [1.0, 0.13043478260869565, 0.006319115323854638, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2350214731692789, 0.0, 0.0, 0.8294399451523027, 0.09374749804518533, 0.09374749804518533, 0.20562544783409611], 
reward next is 0.7944, 
noisyNet noise sample is [array([-0.00931038], dtype=float32), 0.43926647]. 
=============================================
[2019-03-27 05:56:05,335] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[79.2052  ]
 [78.95002 ]
 [79.00043 ]
 [78.790634]
 [78.41847 ]], R is [[79.07337952]
 [79.07691193]
 [79.0800705 ]
 [79.08215332]
 [79.08466339]].
[2019-03-27 05:56:07,901] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9993408e-01 4.8455213e-16 6.5889704e-05 4.8158290e-18 1.7895326e-14], sum to 1.0000
[2019-03-27 05:56:07,910] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9789
[2019-03-27 05:56:07,917] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 955780.1424262744 W.
[2019-03-27 05:56:07,920] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.7, 53.66666666666667, 1.0, 2.0, 0.2937247523218952, 1.0, 2.0, 0.2937247523218952, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 955780.1424262744, 955780.1424262744, 262983.0269961093], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 661200.0000, 
sim time next is 661800.0000, 
raw observation next is [24.7, 53.83333333333333, 1.0, 2.0, 0.1957511870827237, 1.0, 2.0, 0.1957511870827237, 1.0, 1.0, 0.3585186530344088, 6.9112, 6.9112, 170.5573041426782, 953740.3668126969, 953740.3668126969, 282054.9959225422], 
processed observation next is [1.0, 0.6521739130434783, 0.3696682464454976, 0.5383333333333333, 1.0, 1.0, 0.031025526605691203, 1.0, 1.0, 0.031025526605691203, 1.0, 0.5, 0.21770567443220581, 0.0, 0.0, 0.8375144448122397, 0.2649278796701936, 0.2649278796701936, 0.4209776058545406], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.76053315], dtype=float32), 0.9181351]. 
=============================================
[2019-03-27 05:56:09,467] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.00000000e+00 1.27689656e-26 9.37544770e-15 1.10357897e-26
 1.30898064e-23], sum to 1.0000
[2019-03-27 05:56:09,478] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3273
[2019-03-27 05:56:09,484] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.53333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4283731273354082, 6.9112, 6.9112, 168.912956510431, 384851.1732432463, 384851.1732432463, 143427.3692689671], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 690000.0000, 
sim time next is 690600.0000, 
raw observation next is [18.46666666666667, 89.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4259590309164071, 6.9112, 6.9112, 168.912956510431, 382757.0898627586, 382757.0898627586, 143169.862008853], 
processed observation next is [1.0, 1.0, 0.0742496050552924, 0.8966666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.29995003770293543, 0.0, 0.0, 0.8294399451523027, 0.10632141385076628, 0.10632141385076628, 0.2136863612072433], 
reward next is 0.7863, 
noisyNet noise sample is [array([2.149302], dtype=float32), 0.20004152]. 
=============================================
[2019-03-27 05:56:13,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.9220747e-24 6.1718832e-14 6.9285661e-24 5.8311758e-21], sum to 1.0000
[2019-03-27 05:56:13,069] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3970
[2019-03-27 05:56:13,074] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.66666666666667, 71.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4607568304599716, 6.9112, 6.9112, 168.912956510431, 411660.5502184638, 411660.5502184638, 147117.5487658049], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 760800.0000, 
sim time next is 761400.0000, 
raw observation next is [21.45, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.46198290300658, 6.9112, 6.9112, 168.912956510431, 412607.3434961428, 412607.3434961428, 147266.531575613], 
processed observation next is [1.0, 0.8260869565217391, 0.2156398104265403, 0.735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3438815890324146, 0.0, 0.0, 0.8294399451523027, 0.11461315097115078, 0.11461315097115078, 0.2198007933964373], 
reward next is 0.7802, 
noisyNet noise sample is [array([0.7816681], dtype=float32), 0.56465465]. 
=============================================
[2019-03-27 05:56:15,524] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.0496264e-28 4.2357322e-18 2.2871049e-28 1.6122056e-24], sum to 1.0000
[2019-03-27 05:56:15,532] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3058
[2019-03-27 05:56:15,539] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4791462745280475, 6.9112, 6.9112, 168.912956510431, 426467.4504086699, 426467.4504086699, 149348.3944264584], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 791400.0000, 
sim time next is 792000.0000, 
raw observation next is [19.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.479921118112053, 6.9112, 6.9112, 168.912956510431, 427089.8824543229, 427089.8824543229, 149444.1640813268], 
processed observation next is [0.0, 0.17391304347826086, 0.11848341232227487, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36575746111225976, 0.0, 0.0, 0.8294399451523027, 0.11863607845953414, 0.11863607845953414, 0.2230509911661594], 
reward next is 0.7769, 
noisyNet noise sample is [array([0.6913183], dtype=float32), -2.3285127]. 
=============================================
[2019-03-27 05:56:15,557] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[82.14719 ]
 [82.40983 ]
 [82.87132 ]
 [82.98758 ]
 [83.123764]], R is [[81.8418045 ]
 [81.80047607]
 [81.75966644]
 [81.71929169]
 [81.67933655]].
[2019-03-27 05:56:20,495] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.1953296e-28 1.3826115e-16 1.6416500e-28 1.0859036e-23], sum to 1.0000
[2019-03-27 05:56:20,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8517
[2019-03-27 05:56:20,511] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6020542046802777, 6.911200000000001, 6.9112, 168.912956510431, 523230.9448159701, 523230.9448159695, 166409.757683804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 940800.0000, 
sim time next is 941400.0000, 
raw observation next is [22.25, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6034239589943124, 6.9112, 6.9112, 168.912956510431, 524352.718064378, 524352.718064378, 166620.2724283953], 
processed observation next is [0.0, 0.9130434782608695, 0.2535545023696683, 0.905, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.516370681700381, 0.0, 0.0, 0.8294399451523027, 0.14565353279566057, 0.14565353279566057, 0.24868697377372434], 
reward next is 0.7513, 
noisyNet noise sample is [array([0.21950896], dtype=float32), -0.007781645]. 
=============================================
[2019-03-27 05:56:28,403] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.3426523e-23 3.4321629e-11 4.2954669e-25 1.4840018e-20], sum to 1.0000
[2019-03-27 05:56:28,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7518
[2019-03-27 05:56:28,417] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 915033.7321907307 W.
[2019-03-27 05:56:28,426] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.020106308159115, 6.937972032367085, 6.9112, 168.9126590873023, 915033.7321907307, 896040.7644502888, 253564.2316583997], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1075200.0000, 
sim time next is 1075800.0000, 
raw observation next is [22.5, 79.83333333333334, 1.0, 1.0, 0.1924585672354003, 1.0, 1.0, 0.1924585672354003, 1.0, 2.0, 0.3449842640458952, 6.9112, 6.9112, 170.5573041426782, 902249.8282176089, 902249.8282176089, 278771.3287311811], 
processed observation next is [1.0, 0.43478260869565216, 0.2654028436018958, 0.7983333333333335, 1.0, 0.5, 0.02705851474144614, 1.0, 0.5, 0.02705851474144614, 1.0, 1.0, 0.2012003220071893, 0.0, 0.0, 0.8375144448122397, 0.2506249522826691, 0.2506249522826691, 0.41607661004653895], 
reward next is 0.5839, 
noisyNet noise sample is [array([1.2335017], dtype=float32), -0.92976946]. 
=============================================
[2019-03-27 05:56:34,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.4500432e-25 2.6299224e-13 3.0901462e-25 1.6960823e-21], sum to 1.0000
[2019-03-27 05:56:34,789] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7629
[2019-03-27 05:56:34,797] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5061695462338793, 6.9112, 6.9112, 168.912956510431, 447636.3536289852, 447636.3536289852, 152795.0158911505], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1143600.0000, 
sim time next is 1144200.0000, 
raw observation next is [20.35, 91.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.508233665819961, 6.9112, 6.9112, 168.912956510431, 449255.712040299, 449255.712040299, 153064.8731254213], 
processed observation next is [1.0, 0.21739130434782608, 0.16350710900473947, 0.9183333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4002849583170256, 0.0, 0.0, 0.8294399451523027, 0.12479325334452751, 0.12479325334452751, 0.22845503451555416], 
reward next is 0.7715, 
noisyNet noise sample is [array([0.1077797], dtype=float32), 0.90198934]. 
=============================================
[2019-03-27 05:56:40,928] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [4.3972105e-01 2.4237350e-15 5.6027901e-01 1.0819147e-18 2.4930968e-14], sum to 1.0000
[2019-03-27 05:56:40,936] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6019
[2019-03-27 05:56:40,940] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.88333333333333, 71.66666666666667, 1.0, 2.0, 0.6429067400766791, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.956648926128315, 6.9112, 168.9126598895216, 1795238.122264618, 1762995.146458502, 374258.8974039388], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1248600.0000, 
sim time next is 1249200.0000, 
raw observation next is [28.1, 71.0, 1.0, 2.0, 0.675287027224402, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.958224799608549, 6.9112, 168.9126396958802, 1840547.160918136, 1807186.212179328, 380849.3824468421], 
processed observation next is [1.0, 0.4782608695652174, 0.5308056872037916, 0.71, 1.0, 1.0, 0.6087795508727735, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.004702479960854866, 0.0, 0.8294383894478199, 0.5112631002550377, 0.5019961700498133, 0.5684319140997643], 
reward next is 0.1964, 
noisyNet noise sample is [array([1.4668299], dtype=float32), 0.59874666]. 
=============================================
[2019-03-27 05:56:49,056] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.7645216e-26 1.9728002e-13 4.0457120e-26 2.4072441e-23], sum to 1.0000
[2019-03-27 05:56:49,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2761
[2019-03-27 05:56:49,066] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.03333333333333, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7063844135374571, 6.911199999999999, 6.9112, 168.912956510431, 602988.650792751, 602988.6507927517, 183875.0965570867], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1449600.0000, 
sim time next is 1450200.0000, 
raw observation next is [24.76666666666667, 82.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7019793010643939, 6.911199999999999, 6.9112, 168.912956510431, 599728.062371842, 599728.0623718426, 183082.2853109782], 
processed observation next is [0.0, 0.782608695652174, 0.3728278041074251, 0.8266666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6365601232492607, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16659112843662277, 0.16659112843662294, 0.2732571422551913], 
reward next is 0.7267, 
noisyNet noise sample is [array([-0.37877214], dtype=float32), -0.74571556]. 
=============================================
[2019-03-27 05:56:51,235] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 05:56:51,237] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:56:51,238] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:56:51,238] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:56:51,239] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:56:51,240] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:56:51,240] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:56:51,241] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:56:51,241] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:56:51,242] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:56:51,243] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:56:51,256] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run28
[2019-03-27 05:56:51,271] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run28
[2019-03-27 05:56:51,271] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run28
[2019-03-27 05:56:51,308] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run28
[2019-03-27 05:56:51,322] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run28
[2019-03-27 05:57:02,626] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:02,627] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.04574044, 62.38191362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6026701022026998, 6.9112, 6.9112, 168.912956510431, 534701.7060584454, 534701.7060584454, 166150.4000463003]
[2019-03-27 05:57:02,627] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:57:02,629] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.5345408e-25 1.6077435e-13 2.2345025e-25 4.5143084e-22], sampled 0.7898717472981592
[2019-03-27 05:57:16,539] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:16,541] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 93.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9586874699260602, 6.9112, 6.9112, 168.912956510431, 840384.0150709643, 840384.0150709643, 237852.7191464932]
[2019-03-27 05:57:16,542] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:57:16,545] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9916828e-01 9.3877487e-16 8.3175959e-04 1.4460419e-17 3.8911088e-14], sampled 0.3944665066694807
[2019-03-27 05:57:17,188] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:17,189] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.540647005, 92.78388477833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6712599384094777, 6.9112, 6.9112, 168.912956510431, 579757.5240869723, 579757.5240869723, 177670.6448433932]
[2019-03-27 05:57:17,190] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:57:17,195] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 5.9613873e-26 1.1285231e-13 2.7047477e-26 7.4004506e-23], sampled 0.7253919615746842
[2019-03-27 05:57:19,147] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:19,148] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.86403685, 93.28703803000002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6488617200648361, 6.9112, 6.9112, 168.912956510431, 564970.4821977094, 564970.4821977094, 173834.978706734]
[2019-03-27 05:57:19,149] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:57:19,151] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.2301562e-24 2.2393983e-12 5.8307416e-25 1.0457634e-21], sampled 0.13478811088632314
[2019-03-27 05:57:35,635] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:35,636] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.33333333333334, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9812766456741786, 6.9112, 6.9112, 168.912956510431, 792310.8842177809, 792310.8842177809, 242351.3715020525]
[2019-03-27 05:57:35,637] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:57:35,639] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.0551000e-25 5.6486760e-10 1.0981533e-26 1.1725087e-22], sampled 0.7584157641083547
[2019-03-27 05:57:59,344] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:57:59,344] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.78303791, 85.843640645, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9423755795275873, 6.911199999999999, 6.9112, 168.912956510431, 769841.7534111912, 769841.7534111919, 233172.9371031299]
[2019-03-27 05:57:59,345] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 05:57:59,347] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 5.2256661e-25 3.5719474e-12 1.5860296e-25 5.7870745e-22], sampled 0.6835053955391757
[2019-03-27 05:58:14,540] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:58:14,541] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.98333333333333, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.010611615017558, 6.9112, 168.9121723659492, 899354.1286249359, 828828.4348506388, 254812.2802785968]
[2019-03-27 05:58:14,542] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 05:58:14,545] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.0346393e-20 2.0036392e-08 5.8420188e-21 8.0832387e-18], sampled 0.8855945581544047
[2019-03-27 05:58:14,547] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 899354.1286249359 W.
[2019-03-27 05:58:25,773] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:58:25,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.73333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9237656341702556, 6.911199999999999, 6.9112, 168.912956510431, 765595.215277056, 765595.2152770566, 229136.2395474575]
[2019-03-27 05:58:25,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:58:25,780] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.3865594e-20 3.6947437e-08 1.1295285e-21 2.2495032e-18], sampled 0.9438077154055908
[2019-03-27 05:58:36,000] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:58:36,003] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.3, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6459770767449121, 6.911199999999999, 6.9112, 168.912956510431, 565085.5175363016, 565085.5175363023, 173299.9542062384]
[2019-03-27 05:58:36,005] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 05:58:36,009] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.8458855e-25 8.4037805e-14 2.2649079e-25 3.5618875e-22], sampled 0.8851681195564498
[2019-03-27 05:58:39,873] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060947835]
[2019-03-27 05:58:39,875] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.357330295, 84.790043415, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5486710470613555, 6.9112, 6.9112, 168.912956510431, 483409.6653703816, 483409.6653703816, 158476.5866923055]
[2019-03-27 05:58:39,877] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:58:39,881] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.1707147e-25 3.8637835e-14 9.5871511e-26 1.5665917e-22], sampled 0.8338885329280952
[2019-03-27 05:58:45,454] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7926.1934 2943328981.0148 1296.0000
[2019-03-27 05:58:45,654] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7185.5060 3323641060.7330 2094.0000
[2019-03-27 05:58:46,004] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7124.3801 3114342859.1354 1863.0000
[2019-03-27 05:58:46,088] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6847.6755 3192039868.8767 2365.0000
[2019-03-27 05:58:46,114] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7795.4537 2994460531.7818 1462.0000
[2019-03-27 05:58:47,131] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 675000, evaluation results [675000.0, 7185.505966622891, 3323641060.7329717, 2094.0, 7124.38013675408, 3114342859.135442, 1863.0, 7926.19343717683, 2943328981.014792, 1296.0, 6847.675539360165, 3192039868.8767076, 2365.0, 7795.453677876362, 2994460531.781763, 1462.0]
[2019-03-27 05:58:48,821] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 9.9003510e-26 2.3165289e-13 1.0092730e-25 4.0647456e-23], sum to 1.0000
[2019-03-27 05:58:48,832] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6313
[2019-03-27 05:58:48,837] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.75, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6855595491387647, 6.911199999999999, 6.9112, 168.912956510431, 587622.5538527947, 587622.5538527954, 180169.3406760591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1452600.0000, 
sim time next is 1453200.0000, 
raw observation next is [23.5, 89.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6814490741356267, 6.911199999999999, 6.9112, 168.912956510431, 584580.0612230237, 584580.0612230243, 179450.4414657121], 
processed observation next is [0.0, 0.8260869565217391, 0.31279620853080575, 0.8933333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6115232611410082, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1623833503397288, 0.16238335033972898, 0.2678364797995703], 
reward next is 0.7322, 
noisyNet noise sample is [array([-0.02353249], dtype=float32), 1.8779285]. 
=============================================
[2019-03-27 05:58:50,086] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9985969e-01 5.7822938e-21 1.4030715e-04 9.0548500e-24 9.4172257e-20], sum to 1.0000
[2019-03-27 05:58:50,094] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4643
[2019-03-27 05:58:50,100] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8542738211231454, 6.9112, 6.9112, 168.912956510431, 705050.9564022105, 705050.9564022105, 213082.4949713788], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1706400.0000, 
sim time next is 1707000.0000, 
raw observation next is [28.06666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8571919144591366, 6.9112, 6.9112, 168.912956510431, 707648.3718230554, 707648.3718230554, 213732.3832980184], 
processed observation next is [1.0, 0.782608695652174, 0.529225908372828, 0.7866666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8258437981208981, 0.0, 0.0, 0.8294399451523027, 0.19656899217307094, 0.19656899217307094, 0.3190035571612215], 
reward next is 0.6810, 
noisyNet noise sample is [array([0.528724], dtype=float32), -0.95023483]. 
=============================================
[2019-03-27 05:58:50,118] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[75.35773]
 [72.82767]
 [69.64141]
 [65.02796]
 [60.50525]], R is [[77.05939484]
 [76.97077179]
 [76.88677216]
 [76.80857086]
 [76.0404892 ]].
[2019-03-27 05:58:50,495] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.4542134e-24 7.6014524e-15 2.7103678e-25 1.7923154e-21], sum to 1.0000
[2019-03-27 05:58:50,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5226
[2019-03-27 05:58:50,509] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5562006766927909, 6.911199999999999, 6.9112, 168.912956510431, 488180.2791504993, 488180.2791505, 159584.1030068747], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1486800.0000, 
sim time next is 1487400.0000, 
raw observation next is [20.41666666666666, 98.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5592893945394393, 6.9112, 6.9112, 168.912956510431, 490732.9703280488, 490732.9703280488, 160022.7918137255], 
processed observation next is [0.0, 0.21739130434782608, 0.16666666666666644, 0.9833333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4625480421212674, 0.0, 0.0, 0.8294399451523027, 0.13631471398001355, 0.13631471398001355, 0.23883998778167984], 
reward next is 0.7612, 
noisyNet noise sample is [array([-1.5145935], dtype=float32), 1.0447038]. 
=============================================
[2019-03-27 05:58:50,690] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.5801822e-25 2.9678215e-14 1.4257050e-25 1.4254842e-22], sum to 1.0000
[2019-03-27 05:58:50,698] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1805
[2019-03-27 05:58:50,702] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.26666666666667, 98.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5588856960889778, 6.911200000000001, 6.9112, 168.912956510431, 490307.2586242497, 490307.2586242491, 159967.9151955647], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1486200.0000, 
sim time next is 1486800.0000, 
raw observation next is [20.2, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5562006766927909, 6.911199999999999, 6.9112, 168.912956510431, 488180.2791504993, 488180.2791505, 159584.1030068747], 
processed observation next is [0.0, 0.21739130434782608, 0.15639810426540288, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4587813130399889, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13560563309736093, 0.13560563309736112, 0.2381852283684697], 
reward next is 0.7618, 
noisyNet noise sample is [array([1.7407799], dtype=float32), 1.0009953]. 
=============================================
[2019-03-27 05:58:50,942] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.2801796e-01 7.5845702e-15 3.7198207e-01 9.9547084e-17 4.3643214e-13], sum to 1.0000
[2019-03-27 05:58:50,952] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9285
[2019-03-27 05:58:50,957] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.16666666666667, 85.33333333333333, 1.0, 2.0, 0.3338274778086954, 1.0, 2.0, 0.3338274778086954, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1039635.901737203, 1039635.901737203, 269167.9408266009], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1779000.0000, 
sim time next is 1779600.0000, 
raw observation next is [21.93333333333333, 86.66666666666667, 1.0, 2.0, 0.3173884246294247, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5704868914364717, 6.911200000000001, 6.9112, 168.912956510431, 996535.4762404143, 996535.4762404137, 237289.0688765064], 
processed observation next is [1.0, 0.6086956521739131, 0.23854660347551332, 0.8666666666666667, 1.0, 1.0, 0.17757641521617432, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.4762035261420386, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27681541006678173, 0.27681541006678156, 0.35416278936792], 
reward next is 0.6458, 
noisyNet noise sample is [array([1.673888], dtype=float32), -0.31928155]. 
=============================================
[2019-03-27 05:58:58,023] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.9697297e-01 1.3619085e-14 3.0302694e-01 8.0501515e-18 9.7928686e-13], sum to 1.0000
[2019-03-27 05:58:58,033] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5630
[2019-03-27 05:58:58,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1082529.12914269 W.
[2019-03-27 05:58:58,045] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.96666666666667, 86.33333333333334, 1.0, 2.0, 0.3674937335922747, 1.0, 1.0, 0.3674937335922747, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1082529.12914269, 1082529.12914269, 271005.3097813985], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1606800.0000, 
sim time next is 1607400.0000, 
raw observation next is [23.9, 87.0, 1.0, 2.0, 0.2588840317557587, 1.0, 2.0, 0.2588840317557587, 1.0, 1.0, 0.4438786553932179, 6.9112, 6.9112, 170.5573041426782, 1133369.888299576, 1133369.888299576, 292870.0040023039], 
processed observation next is [1.0, 0.6086956521739131, 0.33175355450236965, 0.87, 1.0, 1.0, 0.10708919488645624, 1.0, 1.0, 0.10708919488645624, 1.0, 0.5, 0.3218032382844121, 0.0, 0.0, 0.8375144448122397, 0.31482496897210444, 0.31482496897210444, 0.4371194089586625], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2603226], dtype=float32), -0.5989074]. 
=============================================
[2019-03-27 05:59:01,689] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.4784148e-02 1.1811917e-15 9.0521586e-01 1.1721447e-19 1.1561960e-14], sum to 1.0000
[2019-03-27 05:59:01,696] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6879
[2019-03-27 05:59:01,703] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.5, 86.0, 1.0, 2.0, 0.5302478630301529, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8932908282828794, 6.9112, 6.9112, 168.912956510431, 1482424.704309491, 1482424.704309491, 319565.8917502616], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1684800.0000, 
sim time next is 1685400.0000, 
raw observation next is [26.61666666666667, 85.66666666666667, 1.0, 2.0, 0.5713370176468143, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9634703100732587, 6.911200000000001, 6.9112, 168.912956510431, 1597384.926300022, 1597384.926300021, 343382.9459305273], 
processed observation next is [1.0, 0.5217391304347826, 0.4605055292259086, 0.8566666666666667, 1.0, 1.0, 0.48353857547808954, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9554515976503155, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.44371803508333946, 0.4437180350833391, 0.5125118595978019], 
reward next is 0.4875, 
noisyNet noise sample is [array([0.6002327], dtype=float32), -0.29921144]. 
=============================================
[2019-03-27 05:59:06,581] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1236557e-22 9.9037987e-09 2.3269425e-22 2.5992662e-18], sum to 1.0000
[2019-03-27 05:59:06,591] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8674
[2019-03-27 05:59:06,596] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.56666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9202573558406344, 6.9112, 6.9112, 168.912956510431, 775670.7534867938, 775670.7534867938, 228654.2120995201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1750200.0000, 
sim time next is 1750800.0000, 
raw observation next is [24.63333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8680983365080156, 6.9112, 6.9112, 168.912956510431, 731460.8390015784, 731460.8390015784, 216569.7469421593], 
processed observation next is [1.0, 0.2608695652173913, 0.3665086887835701, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8391443128146531, 0.0, 0.0, 0.8294399451523027, 0.20318356638932733, 0.20318356638932733, 0.3232384282718796], 
reward next is 0.6768, 
noisyNet noise sample is [array([-2.2976222], dtype=float32), 0.61551]. 
=============================================
[2019-03-27 05:59:11,569] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.3821958e-22 1.0856240e-08 3.8026743e-23 1.9448369e-19], sum to 1.0000
[2019-03-27 05:59:11,577] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1846
[2019-03-27 05:59:11,584] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6358321337818252, 6.911200000000001, 6.9112, 168.912956510431, 549235.8589680403, 549235.8589680396, 171763.4624370464], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1833600.0000, 
sim time next is 1834200.0000, 
raw observation next is [22.15, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6378449279604888, 6.9112, 6.9112, 168.912956510431, 550631.5804476335, 550631.5804476335, 172092.7435931037], 
processed observation next is [1.0, 0.21739130434782608, 0.24881516587677724, 0.965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5583474731225472, 0.0, 0.0, 0.8294399451523027, 0.15295321679100932, 0.15295321679100932, 0.25685484118373686], 
reward next is 0.7431, 
noisyNet noise sample is [array([1.2784569], dtype=float32), -0.79545283]. 
=============================================
[2019-03-27 05:59:13,833] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [5.8482941e-03 9.9549125e-16 9.9415165e-01 1.8165212e-19 1.3098378e-14], sum to 1.0000
[2019-03-27 05:59:13,844] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6206
[2019-03-27 05:59:13,851] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.7710068e-23 2.7319225e-10 6.7000407e-25 4.8160107e-21], sum to 1.0000
[2019-03-27 05:59:13,853] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 85.16666666666667, 1.0, 2.0, 0.7070344960462542, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976748298295695, 6.9112, 168.9125647211054, 1884972.589466211, 1838470.478517645, 387202.569796473], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1869000.0000, 
sim time next is 1869600.0000, 
raw observation next is [27.0, 85.33333333333334, 1.0, 2.0, 0.56621608468608, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9596053880309271, 6.911199999999999, 6.9112, 168.9129031376577, 1583056.778436182, 1583056.778436182, 341378.2547673879], 
processed observation next is [1.0, 0.6521739130434783, 0.4786729857819906, 0.8533333333333334, 1.0, 1.0, 0.4773687767302168, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9507382780864964, -8.881784197001253e-17, 0.0, 0.8294396830675517, 0.4397379940100506, 0.4397379940100506, 0.5095197832349073], 
reward next is 0.4905, 
noisyNet noise sample is [array([-2.3358018], dtype=float32), -0.2769648]. 
=============================================
[2019-03-27 05:59:13,864] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0249
[2019-03-27 05:59:13,871] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.36666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9072644020817067, 6.911200000000001, 6.9112, 168.912956510431, 743244.2379628149, 743244.2379628143, 224894.9982222373], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2108400.0000, 
sim time next is 2109000.0000, 
raw observation next is [28.58333333333333, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9138108708204494, 6.9112, 6.9112, 168.912956510431, 747650.7553564974, 747650.7553564974, 226389.8142162517], 
processed observation next is [0.0, 0.391304347826087, 0.5537124802527644, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8948913058785968, 0.0, 0.0, 0.8294399451523027, 0.20768076537680483, 0.20768076537680483, 0.33789524509888313], 
reward next is 0.6621, 
noisyNet noise sample is [array([-2.1280613], dtype=float32), -0.9313821]. 
=============================================
[2019-03-27 05:59:13,895] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[73.55037]
 [73.52771]
 [73.50084]
 [73.46696]
 [73.41611]], R is [[73.48630524]
 [73.41577911]
 [73.34854889]
 [73.28431702]
 [73.22251892]].
[2019-03-27 05:59:17,749] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [5.0843764e-02 4.9822427e-15 9.4915628e-01 1.0257884e-17 7.9777486e-14], sum to 1.0000
[2019-03-27 05:59:17,758] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2229
[2019-03-27 05:59:17,767] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.1, 80.0, 1.0, 2.0, 0.4749898029969745, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7981959664162845, 6.911200000000001, 6.9112, 168.912956510431, 1346624.101512016, 1346624.101512016, 291600.5527526984], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1936800.0000, 
sim time next is 1937400.0000, 
raw observation next is [26.15, 79.83333333333334, 1.0, 2.0, 0.4553711221413008, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7650323486325347, 6.9112, 6.9112, 168.912956510431, 1290498.259889063, 1290498.259889063, 282013.3325385669], 
processed observation next is [1.0, 0.43478260869565216, 0.43838862559241704, 0.7983333333333335, 1.0, 1.0, 0.34382062908590455, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7134540836982128, 0.0, 0.0, 0.8294399451523027, 0.35847173885807304, 0.35847173885807304, 0.4209154216993536], 
reward next is 0.5791, 
noisyNet noise sample is [array([-0.23485482], dtype=float32), -0.38926846]. 
=============================================
[2019-03-27 05:59:21,241] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.0874875e-24 1.6198225e-12 6.2078576e-25 5.7658326e-22], sum to 1.0000
[2019-03-27 05:59:21,254] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7707
[2019-03-27 05:59:21,258] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8516253164748689, 6.911200000000001, 6.9112, 168.912956510431, 705692.6776508042, 705692.6776508036, 212598.0261295171], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2017200.0000, 
sim time next is 2017800.0000, 
raw observation next is [25.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8523311569362108, 6.9112, 6.9112, 168.912956510431, 706239.9046428276, 706239.9046428276, 212751.7625875982], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8199160450441594, 0.0, 0.0, 0.8294399451523027, 0.19617775128967432, 0.19617775128967432, 0.31753994416059433], 
reward next is 0.6825, 
noisyNet noise sample is [array([0.96558523], dtype=float32), -0.75061256]. 
=============================================
[2019-03-27 05:59:23,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.6085839e-24 9.5368826e-12 9.2626391e-25 4.0268146e-21], sum to 1.0000
[2019-03-27 05:59:23,996] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3313
[2019-03-27 05:59:24,001] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.85, 87.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8146149823989239, 6.911199999999998, 6.9112, 168.912956510431, 680448.1610901399, 680448.1610901412, 204816.1845568896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2055000.0000, 
sim time next is 2055600.0000, 
raw observation next is [25.8, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8127049160329651, 6.911200000000001, 6.9112, 168.912956510431, 679100.5861074259, 679100.5861074253, 204422.2242601203], 
processed observation next is [0.0, 0.8260869565217391, 0.42180094786729866, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7715913610158112, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1886390516965072, 0.18863905169650702, 0.3051077974031646], 
reward next is 0.6949, 
noisyNet noise sample is [array([-1.3643236], dtype=float32), -0.2924898]. 
=============================================
[2019-03-27 05:59:26,719] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.5365892e-23 5.3801821e-11 5.0456845e-24 5.8378752e-21], sum to 1.0000
[2019-03-27 05:59:26,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7376
[2019-03-27 05:59:26,738] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9833840039591013, 6.9112, 6.9112, 168.912956510431, 793047.7893572358, 793047.7893572358, 242830.399876456], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2122800.0000, 
sim time next is 2123400.0000, 
raw observation next is [30.0, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9872952323046522, 6.911200000000001, 6.9112, 168.9129408107538, 795848.8170738516, 795848.8170738509, 243802.4485661858], 
processed observation next is [0.0, 0.5652173913043478, 0.6208530805687204, 0.7683333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.984506380859332, 8.881784197001253e-17, 0.0, 0.8294398680597004, 0.22106911585384767, 0.22106911585384748, 0.3638842515913221], 
reward next is 0.6361, 
noisyNet noise sample is [array([0.99735636], dtype=float32), 0.78140974]. 
=============================================
[2019-03-27 05:59:29,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.7960421e-01 4.0391833e-14 5.2039576e-01 1.5387263e-17 4.5286369e-13], sum to 1.0000
[2019-03-27 05:59:29,344] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5641
[2019-03-27 05:59:29,350] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.1, 81.5, 1.0, 2.0, 0.4176545804960503, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7129095801212942, 6.911199999999999, 6.9112, 168.912956510431, 1167472.30176609, 1167472.301766091, 265479.2291259489], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2431800.0000, 
sim time next is 2432400.0000, 
raw observation next is [28.03333333333333, 81.66666666666667, 1.0, 2.0, 0.4072219380373289, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6946622379917573, 6.9112, 6.9112, 168.912956510431, 1138294.243563123, 1138294.243563123, 260872.3067126095], 
processed observation next is [1.0, 0.13043478260869565, 0.5276461295418641, 0.8166666666666668, 1.0, 1.0, 0.2858095639003963, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.627636875599704, 0.0, 0.0, 0.8294399451523027, 0.31619284543420084, 0.31619284543420084, 0.38936165180986493], 
reward next is 0.6106, 
noisyNet noise sample is [array([-0.6719802], dtype=float32), 1.077619]. 
=============================================
[2019-03-27 05:59:29,723] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 4.788822e-22 3.159944e-08 9.551392e-23 8.146286e-20], sum to 1.0000
[2019-03-27 05:59:29,732] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6483
[2019-03-27 05:59:29,735] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.78333333333333, 86.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9413055897370397, 6.911200000000001, 6.9112, 168.912956510431, 766793.9386372156, 766793.9386372151, 232810.454448019], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2145000.0000, 
sim time next is 2145600.0000, 
raw observation next is [27.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9366161724946863, 6.911199999999999, 6.9112, 168.912956510431, 763674.6535109015, 763674.6535109022, 231709.0587601774], 
processed observation next is [0.0, 0.8695652173913043, 0.5071090047393366, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9227026493837637, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21213184819747263, 0.21213184819747283, 0.3458344160599663], 
reward next is 0.6542, 
noisyNet noise sample is [array([-0.5541405], dtype=float32), -1.247761]. 
=============================================
[2019-03-27 05:59:30,116] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999988e-01 1.1728268e-21 8.7705352e-08 2.5604360e-23 2.5228533e-18], sum to 1.0000
[2019-03-27 05:59:30,125] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5058
[2019-03-27 05:59:30,132] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.66666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8631029784317658, 6.9112, 6.9112, 168.912956510431, 714827.5192284478, 714827.5192284478, 215122.2384075502], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2162400.0000, 
sim time next is 2163000.0000, 
raw observation next is [25.63333333333333, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8621030109576042, 6.911200000000001, 6.9112, 168.912956510431, 714116.6362485503, 714116.6362485496, 214903.7696989839], 
processed observation next is [1.0, 0.0, 0.4139020537124801, 0.9383333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8318329401922003, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19836573229126397, 0.19836573229126378, 0.3207518950731103], 
reward next is 0.6792, 
noisyNet noise sample is [array([-0.09351527], dtype=float32), -1.1695194]. 
=============================================
[2019-03-27 05:59:30,144] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[61.862495]
 [62.667637]
 [63.62068 ]
 [64.13928 ]
 [65.74615 ]], R is [[61.28603363]
 [61.35209274]
 [61.41712189]
 [61.4810791 ]
 [61.54383087]].
[2019-03-27 05:59:30,746] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.8286459e-01 1.1206329e-14 8.1713539e-01 8.6773074e-18 1.6466166e-13], sum to 1.0000
[2019-03-27 05:59:30,755] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7613
[2019-03-27 05:59:30,758] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.86666666666667, 95.66666666666667, 1.0, 2.0, 0.3072745728451966, 1.0, 1.0, 0.3072745728451966, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 858798.3102466664, 858798.3102466664, 251287.1020291007], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2173200.0000, 
sim time next is 2173800.0000, 
raw observation next is [24.83333333333334, 95.83333333333333, 1.0, 2.0, 0.3017904634035335, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5061761982796934, 6.9112, 6.9112, 168.912956510431, 843468.0348835229, 843468.0348835229, 220653.0048293824], 
processed observation next is [1.0, 0.13043478260869565, 0.3759873617693526, 0.9583333333333333, 1.0, 1.0, 0.15878369084763072, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.3977758515606017, 0.0, 0.0, 0.8294399451523027, 0.23429667635653414, 0.23429667635653414, 0.32933284302892896], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6836841], dtype=float32), 0.017668555]. 
=============================================
[2019-03-27 05:59:31,349] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.1428761e-06 1.0195933e-17 9.9999189e-01 2.9178018e-23 2.6617488e-17], sum to 1.0000
[2019-03-27 05:59:31,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7465
[2019-03-27 05:59:31,363] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.38333333333333, 67.5, 1.0, 2.0, 0.6029346724031917, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.925757900289753, 6.9112, 168.9128037315076, 1685798.07375637, 1675470.207587949, 365303.5965492588], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2206200.0000, 
sim time next is 2206800.0000, 
raw observation next is [31.5, 67.0, 1.0, 2.0, 0.6308860370009867, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.981203474233662, 6.9112, 168.912517553076, 1764014.707201805, 1714351.962306672, 370583.2325630132], 
processed observation next is [1.0, 0.5652173913043478, 0.6919431279620853, 0.67, 1.0, 1.0, 0.5552843819288996, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007000347423366193, 0.0, 0.829437789670734, 0.4900040853338347, 0.47620887841852, 0.5531093023328555], 
reward next is 0.0969, 
noisyNet noise sample is [array([1.2289901], dtype=float32), -1.3991288]. 
=============================================
[2019-03-27 05:59:41,785] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 05:59:41,786] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 05:59:41,787] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:59:41,787] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 05:59:41,788] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:59:41,788] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 05:59:41,789] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 05:59:41,789] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:59:41,790] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:59:41,790] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 05:59:41,791] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 05:59:41,816] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run29
[2019-03-27 05:59:41,816] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run29
[2019-03-27 05:59:41,854] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run29
[2019-03-27 05:59:41,878] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run29
[2019-03-27 05:59:41,879] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run29
[2019-03-27 05:59:44,459] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 05:59:44,459] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.45255942, 96.05487488333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6282965461200588, 6.911199999999999, 6.9112, 168.912956510431, 545378.223919793, 545378.2239197936, 170520.1482497778]
[2019-03-27 05:59:44,460] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 05:59:44,463] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 4.1697545e-21 4.1184089e-10 5.1199890e-22 1.6034459e-18], sampled 0.03491646304258422
[2019-03-27 06:00:17,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:00:17,939] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.36666666666667, 95.33333333333334, 1.0, 1.0, 0.5252851672629512, 1.0, 1.0, 0.5252851672629512, 1.0, 2.0, 0.9116497388023669, 6.911200000000001, 6.9112, 170.5573041426782, 2203551.533825652, 2203551.533825652, 432957.7547903704]
[2019-03-27 06:00:17,940] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:00:17,941] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9998808e-01 5.2165004e-18 1.1966092e-05 4.1286029e-20 1.2978330e-15], sampled 0.013038878676356336
[2019-03-27 06:00:17,942] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2203551.533825652 W.
[2019-03-27 06:00:21,301] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:00:21,304] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.79852040333333, 97.84511486333332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5290878679877093, 6.9112, 6.9112, 168.912956510431, 467167.3933228792, 467167.3933228792, 155790.059658697]
[2019-03-27 06:00:21,304] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:00:21,307] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 1.02620625e-20 2.91867575e-09 5.58362060e-22
 2.59385808e-18], sampled 0.8200570470422351
[2019-03-27 06:00:37,327] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:00:37,328] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.38333333333333, 56.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992438007930164, 6.9112, 168.9123356123565, 886456.2309211917, 828823.4039492793, 254812.1357047703]
[2019-03-27 06:00:37,330] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:00:37,337] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.8394483e-01 2.7391179e-14 1.6055198e-02 2.4309046e-16 2.2235024e-12], sampled 0.5843035102123212
[2019-03-27 06:00:37,339] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 886456.2309211917 W.
[2019-03-27 06:01:16,186] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:16,189] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.23333333333333, 92.33333333333334, 1.0, 2.0, 0.6725292212962422, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 939861.7605912888, 939861.7605912882, 215026.8088946777]
[2019-03-27 06:01:16,190] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:16,194] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.060318e-01 2.999883e-13 6.939682e-01 6.068388e-16 6.744426e-12], sampled 0.8981403488817701
[2019-03-27 06:01:17,317] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:17,318] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.98333333333333, 91.16666666666667, 1.0, 2.0, 0.7469134029996835, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1043864.984662786, 1043864.984662787, 231295.5749254419]
[2019-03-27 06:01:17,321] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:17,324] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.4269198e-01 2.4644391e-14 5.7308041e-02 6.8791159e-17 1.7908467e-12], sampled 0.38069750815359193
[2019-03-27 06:01:17,326] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1043864.984662786 W.
[2019-03-27 06:01:18,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:18,251] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.83333333333334, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8651335019938589, 6.911199999999999, 6.9112, 168.912956510431, 715755.7319229668, 715755.7319229674, 215549.0134907831]
[2019-03-27 06:01:18,253] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:18,256] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.4754652e-21 1.5409476e-08 7.1179753e-23 1.2184375e-18], sampled 0.9598501079350605
[2019-03-27 06:01:18,304] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:18,306] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.66666666666667, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8655824455412431, 6.911200000000001, 6.9112, 168.912956510431, 716594.6577153507, 716594.65771535, 215665.1670146903]
[2019-03-27 06:01:18,309] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:18,314] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 9.7154382e-22 4.0799053e-09 2.3810602e-23 3.9633907e-19], sampled 0.16917062337669653
[2019-03-27 06:01:26,998] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:27,001] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6546171565480188, 6.911200000000001, 6.9112, 168.912956510431, 564717.0880237719, 564717.0880237712, 174858.8075948026]
[2019-03-27 06:01:27,001] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:27,005] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999952e-01 3.5273689e-20 4.2048919e-07 4.3627825e-22 4.0957745e-18], sampled 0.05832499341129582
[2019-03-27 06:01:34,269] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:34,270] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.01859510333333, 85.76262163, 1.0, 2.0, 0.7355237252888782, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1027939.389995177, 1027939.389995177, 228696.4689092457]
[2019-03-27 06:01:34,271] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:01:34,275] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.3466494e-01 7.4037532e-13 6.6533506e-01 1.4054174e-15 1.4027155e-11], sampled 0.6908882297432376
[2019-03-27 06:01:36,234] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05837471]
[2019-03-27 06:01:36,235] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.08333333333334, 91.33333333333334, 1.0, 2.0, 0.7600381161484411, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104309, 1062216.885436506, 1062216.885436506, 234336.6562353221]
[2019-03-27 06:01:36,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:01:36,240] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.4607025e-01 4.2587011e-14 5.3929728e-02 1.2073213e-16 3.1280495e-12], sampled 0.8398605385073764
[2019-03-27 06:01:36,245] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1062216.885436506 W.
[2019-03-27 06:01:36,837] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7310.1639 3132764082.8272 1582.0000
[2019-03-27 06:01:36,889] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7873.6605 3007715529.3212 1282.0000
[2019-03-27 06:01:36,911] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6987.3476 3207580462.8031 2099.0000
[2019-03-27 06:01:37,031] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7193.8007 3334805318.5259 1980.0000
[2019-03-27 06:01:37,112] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7989.7383 2956681590.7659 1115.0000
[2019-03-27 06:01:38,129] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 700000, evaluation results [700000.0, 7193.800698920545, 3334805318.525885, 1980.0, 7310.16387288621, 3132764082.8272448, 1582.0, 7989.738272067215, 2956681590.7659326, 1115.0, 6987.347576623612, 3207580462.8031178, 2099.0, 7873.660463433869, 3007715529.321224, 1282.0]
[2019-03-27 06:01:43,486] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [3.8770816e-04 2.0037570e-15 9.9961227e-01 1.6751491e-20 1.2956891e-14], sum to 1.0000
[2019-03-27 06:01:43,499] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2952
[2019-03-27 06:01:43,503] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 84.66666666666667, 1.0, 2.0, 0.6799950461366497, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.983998801089508, 6.9112, 168.9124639822114, 1847135.153161651, 1795489.328720336, 381173.7233498907], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2475600.0000, 
sim time next is 2476200.0000, 
raw observation next is [27.6, 84.33333333333333, 1.0, 2.0, 0.6402878110989749, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.982997671867829, 6.9112, 168.9124707197097, 1790325.098002988, 1739389.504985092, 373021.6635157339], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.8433333333333333, 1.0, 1.0, 0.5666118206011745, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0071797671867829035, 0.0, 0.8294375596974651, 0.4973125272230522, 0.48316375138474776, 0.5567487515160208], 
reward next is 0.0843, 
noisyNet noise sample is [array([-0.6131864], dtype=float32), 0.88201857]. 
=============================================
[2019-03-27 06:01:45,752] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3487405e-03 1.3003372e-15 9.9865133e-01 9.3289455e-20 1.2702689e-14], sum to 1.0000
[2019-03-27 06:01:45,761] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1213
[2019-03-27 06:01:45,766] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.98333333333333, 76.66666666666667, 1.0, 2.0, 0.7861550548657216, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.98814794359789, 6.9112, 168.9124363173867, 1995697.061141645, 1941107.709726169, 405109.0757849764], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2548200.0000, 
sim time next is 2548800.0000, 
raw observation next is [29.1, 76.0, 1.0, 2.0, 0.83626938358531, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.988313745695198, 6.9112, 168.9124352866891, 2065835.032402885, 2011128.055969177, 417651.9510475583], 
processed observation next is [1.0, 0.5217391304347826, 0.5781990521327015, 0.76, 1.0, 1.0, 0.8027341970907349, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00771137456951978, 0.0, 0.8294373857051126, 0.5738430645563569, 0.5586466822136603, 0.6233611209665049], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.71013355], dtype=float32), 0.00044362806]. 
=============================================
[2019-03-27 06:01:46,344] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.9420911e-07 7.2783196e-16 9.9999905e-01 7.0943921e-21 7.7504243e-15], sum to 1.0000
[2019-03-27 06:01:46,355] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7353
[2019-03-27 06:01:46,360] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.25, 69.0, 1.0, 2.0, 0.8267753489531137, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987106369628051, 6.9112, 168.9124429693866, 2052547.212511156, 1998696.785121748, 415256.9984502147], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2557800.0000, 
sim time next is 2558400.0000, 
raw observation next is [30.16666666666667, 69.33333333333333, 1.0, 2.0, 0.8775115505266861, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.986806689229961, 6.9112, 168.9124450676559, 2123559.366066554, 2069921.540953081, 428600.6976168203], 
processed observation next is [1.0, 0.6086956521739131, 0.6287519747235389, 0.6933333333333332, 1.0, 1.0, 0.852423554851429, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007560668922996072, 0.0, 0.8294374337341375, 0.5898776016851539, 0.5749782058203003, 0.6397025337564481], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8525898], dtype=float32), 0.318026]. 
=============================================
[2019-03-27 06:01:46,996] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.4189826e-01 1.8584389e-13 1.5810174e-01 1.8890420e-16 4.1377036e-12], sum to 1.0000
[2019-03-27 06:01:47,005] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4951
[2019-03-27 06:01:47,013] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 890175.990020367 W.
[2019-03-27 06:01:47,021] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.16666666666667, 83.0, 1.0, 2.0, 0.2876061836396364, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5124726745600111, 6.9112, 6.9112, 168.912956510431, 890175.990020367, 890175.990020367, 225597.80083861], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2805000.0000, 
sim time next is 2805600.0000, 
raw observation next is [23.33333333333334, 83.0, 1.0, 2.0, 0.1994620104221975, 1.0, 1.0, 0.1994620104221975, 1.0, 2.0, 0.3516587980177174, 6.9112, 6.9112, 170.5573041426782, 910624.5274787759, 910624.5274787759, 278337.1264402485], 
processed observation next is [1.0, 0.4782608695652174, 0.3048973143759877, 0.83, 1.0, 1.0, 0.035496398099033113, 1.0, 0.5, 0.035496398099033113, 1.0, 1.0, 0.20933999758258215, 0.0, 0.0, 0.8375144448122397, 0.2529512576329933, 0.2529512576329933, 0.41542854692574405], 
reward next is 0.5846, 
noisyNet noise sample is [array([-0.26132601], dtype=float32), 0.4291875]. 
=============================================
[2019-03-27 06:01:55,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.3828481e-25 4.1067911e-14 8.4845479e-26 9.5637514e-23], sum to 1.0000
[2019-03-27 06:01:55,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9102
[2019-03-27 06:01:55,979] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7624141268373608, 6.9112, 6.9112, 168.912956510431, 643519.545552736, 643519.545552736, 194366.7053239154], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2693400.0000, 
sim time next is 2694000.0000, 
raw observation next is [24.0, 96.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7667673135457259, 6.911200000000001, 6.9112, 168.912956510431, 646834.9573899846, 646834.957389984, 195216.7984239709], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.9666666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7155698945679583, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1796763770527735, 0.17967637705277334, 0.291368355856673], 
reward next is 0.7086, 
noisyNet noise sample is [array([-1.0441866], dtype=float32), 0.6635598]. 
=============================================
[2019-03-27 06:01:55,998] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[71.934425]
 [72.13194 ]
 [72.05045 ]
 [72.12399 ]
 [72.16068 ]], R is [[71.68305206]
 [71.67612457]
 [71.67012024]
 [71.66439056]
 [71.65911865]].
[2019-03-27 06:02:10,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.5241947e-25 7.4850175e-11 4.2487442e-25 1.9858432e-21], sum to 1.0000
[2019-03-27 06:02:10,735] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8200
[2019-03-27 06:02:10,739] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.83333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5668707642551157, 6.911199999999999, 6.9112, 168.912956510431, 496768.6923173688, 496768.6923173695, 161116.2605628874], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2934600.0000, 
sim time next is 2935200.0000, 
raw observation next is [20.66666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5645149265010938, 6.9112, 6.9112, 168.912956510431, 494900.8156601652, 494900.8156601652, 160774.6731898925], 
processed observation next is [1.0, 1.0, 0.17851500789889443, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4689206420745046, 0.0, 0.0, 0.8294399451523027, 0.13747244879449033, 0.13747244879449033, 0.23996219879088432], 
reward next is 0.7600, 
noisyNet noise sample is [array([-0.5986603], dtype=float32), -1.7736007]. 
=============================================
[2019-03-27 06:02:11,135] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 8.3631546e-24 9.2964625e-10 1.2924474e-24 1.3270719e-21], sum to 1.0000
[2019-03-27 06:02:11,146] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8732
[2019-03-27 06:02:11,156] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.08333333333334, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5588470151256414, 6.911200000000001, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524185, 159940.7010612792], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [20.16666666666667, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5592135916951001, 6.911200000000001, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387388, 159994.3966678323], 
processed observation next is [1.0, 0.8695652173913043, 0.15481832543443946, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46245559962817084, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13645785803853874, 0.13645785803853855, 0.23879760696691388], 
reward next is 0.7612, 
noisyNet noise sample is [array([0.5528141], dtype=float32), -0.20034653]. 
=============================================
[2019-03-27 06:02:11,308] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.0170101e-01 4.4880522e-16 1.9829899e-01 1.3795179e-18 1.1562900e-14], sum to 1.0000
[2019-03-27 06:02:11,320] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0201
[2019-03-27 06:02:11,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.5887978086039838, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 831913.991455402, 831913.991455402, 199851.4817443932], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3156000.0000, 
sim time next is 3156600.0000, 
raw observation next is [26.0, 83.16666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.982844831529276, 6.9112, 6.9112, 168.912956510431, 827588.6658456714, 827588.6658456714, 244101.9434216104], 
processed observation next is [1.0, 0.5217391304347826, 0.4312796208530806, 0.8316666666666666, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9790790628405804, 0.0, 0.0, 0.8294399451523027, 0.2298857405126865, 0.2298857405126865, 0.3643312588382245], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2759937], dtype=float32), -2.9912655]. 
=============================================
[2019-03-27 06:02:31,028] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.8126092e-23 7.0811322e-11 3.9133074e-24 1.3955165e-20], sum to 1.0000
[2019-03-27 06:02:31,040] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8882
[2019-03-27 06:02:31,048] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9204714020942781, 6.9112, 6.9112, 168.912956510431, 753412.0448389226, 753412.0448389226, 227977.992747345], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3270000.0000, 
sim time next is 3270600.0000, 
raw observation next is [28.0, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.911762390665438, 6.9112, 6.9112, 168.912956510431, 747664.4202319708, 747664.4202319708, 225980.733750166], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.892393159348095, 0.0, 0.0, 0.8294399451523027, 0.20768456117554746, 0.20768456117554746, 0.3372846772390537], 
reward next is 0.6627, 
noisyNet noise sample is [array([-0.96001476], dtype=float32), -1.1293056]. 
=============================================
[2019-03-27 06:02:31,753] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.5178187e-23 6.5173474e-12 1.7981826e-23 1.0786226e-20], sum to 1.0000
[2019-03-27 06:02:31,762] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3044
[2019-03-27 06:02:31,770] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7974921862068882, 6.911200000000001, 6.9112, 168.912956510431, 669889.8455261776, 669889.845526177, 201349.1970573968], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3291600.0000, 
sim time next is 3292200.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7958925375884771, 6.9112, 6.9112, 168.912956510431, 668545.7355885248, 668545.7355885248, 201020.9984415036], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7510884604737526, 0.0, 0.0, 0.8294399451523027, 0.18570714877459024, 0.18570714877459024, 0.30003134095746803], 
reward next is 0.7000, 
noisyNet noise sample is [array([-1.1817557], dtype=float32), 0.19108742]. 
=============================================
[2019-03-27 06:02:32,385] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0373234e-23 3.3483369e-11 1.5808176e-24 1.6088290e-21], sum to 1.0000
[2019-03-27 06:02:32,394] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3568
[2019-03-27 06:02:32,404] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7954981849985898, 6.9112, 6.9112, 168.912956510431, 668212.2365948637, 668212.2365948637, 200940.1512230568], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3289200.0000, 
sim time next is 3289800.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.797222637764873, 6.911199999999999, 6.9112, 168.912956510431, 669662.7503428259, 669662.7503428266, 201293.8330249709], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7527105338596013, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18601743065078497, 0.18601743065078516, 0.3004385567536879], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.43654194], dtype=float32), 0.5890502]. 
=============================================
[2019-03-27 06:02:32,827] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:02:32,828] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:02:32,828] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:02:32,829] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:02:32,830] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:02:32,830] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:02:32,832] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:02:32,832] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:02:32,834] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:02:32,833] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:02:32,839] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:02:32,856] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run30
[2019-03-27 06:02:32,877] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run30
[2019-03-27 06:02:32,894] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run30
[2019-03-27 06:02:32,913] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run30
[2019-03-27 06:02:32,939] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run30
[2019-03-27 06:02:42,470] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060653344]
[2019-03-27 06:02:42,471] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.76666666666667, 46.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6500689057155312, 6.9112, 6.9112, 168.912956510431, 569506.9267025836, 569506.9267025836, 173951.9385264039]
[2019-03-27 06:02:42,472] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:02:42,476] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.4385391e-23 3.2697608e-12 3.1392534e-24 1.0247940e-20], sampled 0.8948826821055241
[2019-03-27 06:02:50,571] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060653344]
[2019-03-27 06:02:50,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.06666666666667, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8084762456486931, 6.911200000000001, 6.9112, 168.912956510431, 704014.5907130953, 704014.5907130947, 203662.7919953634]
[2019-03-27 06:02:50,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:02:50,577] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.0729332e-23 2.1606358e-12 2.3899223e-24 7.1215679e-21], sampled 0.20115328001349175
[2019-03-27 06:03:53,209] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060653344]
[2019-03-27 06:03:53,212] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.06720666, 96.090609, 1.0, 2.0, 0.5474266018040799, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9193318606916948, 6.911200000000001, 6.9112, 168.912956510431, 1530486.276959387, 1530486.276959386, 328604.9269617734]
[2019-03-27 06:03:53,214] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:03:53,218] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.2131975e-01 4.1885932e-15 5.7868028e-01 7.6902783e-18 1.3298031e-13], sampled 0.04270273231199495
[2019-03-27 06:03:53,219] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1530486.276959387 W.
[2019-03-27 06:04:19,687] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060653344]
[2019-03-27 06:04:19,687] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [20.25449506833333, 91.70883311166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5306916679771059, 6.911200000000001, 6.9112, 168.912956510431, 468508.6649313239, 468508.6649313233, 156005.6942798723]
[2019-03-27 06:04:19,688] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:04:19,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.2161761e-24 6.8660377e-13 2.4594267e-24 5.0691712e-21], sampled 0.41302672912826965
[2019-03-27 06:04:26,294] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.060653344]
[2019-03-27 06:04:26,295] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.35496337, 70.91030278666668, 1.0, 2.0, 0.6472598108369478, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.994909642288336, 6.9112, 168.9124078796145, 1801329.170155823, 1741942.861740834, 374058.790736313]
[2019-03-27 06:04:26,297] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:04:26,301] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.8558210e-01 5.6881190e-14 8.1441790e-01 4.6000682e-17 6.7040351e-13], sampled 0.10521581314448913
[2019-03-27 06:04:26,302] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1801329.170155823 W.
[2019-03-27 06:04:27,645] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7097.8740 3120057703.0033 1793.0000
[2019-03-27 06:04:27,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6827.1220 3196569457.7188 2282.0000
[2019-03-27 06:04:27,838] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7161.6871 3327518317.9536 2069.0000
[2019-03-27 06:04:27,866] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7757.4710 2998180217.5972 1405.0000
[2019-03-27 06:04:27,962] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7871.3977 2947172932.8361 1257.0000
[2019-03-27 06:04:28,980] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 725000, evaluation results [725000.0, 7161.687112849995, 3327518317.9535856, 2069.0, 7097.873966233994, 3120057703.0033307, 1793.0, 7871.397686377798, 2947172932.836067, 1257.0, 6827.121990580195, 3196569457.718793, 2282.0, 7757.471009488973, 2998180217.5972333, 1405.0]
[2019-03-27 06:04:30,156] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999976e-01 1.1713166e-19 2.4927971e-07 3.4803333e-21 2.6071318e-17], sum to 1.0000
[2019-03-27 06:04:30,161] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7070
[2019-03-27 06:04:30,168] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 891558.3097376901 W.
[2019-03-27 06:04:30,176] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 75.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.999626999957228, 6.9112, 168.9123064764472, 891558.3097376901, 828825.393963904, 254812.5234650098], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3339000.0000, 
sim time next is 3339600.0000, 
raw observation next is [31.0, 75.0, 1.0, 1.0, 0.3030427610536164, 1.0, 1.0, 0.3030427610536164, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 846966.1959010961, 846966.1959010961, 250478.6395659211], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.75, 1.0, 0.5, 0.16029248319712816, 1.0, 0.5, 0.16029248319712816, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23526838775030448, 0.23526838775030448, 0.3738487157700315], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7000017], dtype=float32), 0.504865]. 
=============================================
[2019-03-27 06:04:33,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.9100973e-25 4.4744785e-12 4.7290165e-25 3.7724934e-22], sum to 1.0000
[2019-03-27 06:04:33,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0292
[2019-03-27 06:04:33,159] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9161286421193702, 6.9112, 6.9112, 168.912956510431, 751091.7178992864, 751091.7178992864, 227003.3906249487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3367800.0000, 
sim time next is 3368400.0000, 
raw observation next is [27.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9183349181302937, 6.911199999999999, 6.9112, 168.912956510431, 752901.1765240583, 752901.176524059, 227525.3298658305], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9004084367442604, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2091392157011273, 0.2091392157011275, 0.33959004457586645], 
reward next is 0.6604, 
noisyNet noise sample is [array([0.44695187], dtype=float32), 0.13962756]. 
=============================================
[2019-03-27 06:04:34,041] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999678e-01 8.1066335e-22 3.1913855e-06 2.7777285e-23 1.2331482e-19], sum to 1.0000
[2019-03-27 06:04:34,049] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3045
[2019-03-27 06:04:34,052] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8746287046120181, 6.9112, 6.9112, 168.912956510431, 722286.8123248421, 722286.8123248421, 217632.0394009687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3442200.0000, 
sim time next is 3442800.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8740221827217547, 6.911199999999999, 6.9112, 168.912956510431, 721841.5477557711, 721841.5477557718, 217497.3266773644], 
processed observation next is [1.0, 0.8695652173913043, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.846368515514335, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20051154104326974, 0.20051154104326993, 0.32462287563785736], 
reward next is 0.6754, 
noisyNet noise sample is [array([0.42652], dtype=float32), 0.018340759]. 
=============================================
[2019-03-27 06:04:34,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6560453e-23 2.5840186e-09 6.1701273e-26 2.2040570e-20], sum to 1.0000
[2019-03-27 06:04:34,820] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0872
[2019-03-27 06:04:34,826] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8646245200866095, 6.9112, 6.9112, 168.912956510431, 715790.4260027313, 715790.4260027313, 215451.0261233068], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3626400.0000, 
sim time next is 3627000.0000, 
raw observation next is [28.0, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8559264539161655, 6.9112, 6.9112, 168.912956510431, 709844.1747993702, 709844.1747993702, 213563.5925473469], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8243005535562994, 0.0, 0.0, 0.8294399451523027, 0.1971789374442695, 0.1971789374442695, 0.3187516306676819], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.07327052], dtype=float32), 0.7160922]. 
=============================================
[2019-03-27 06:04:34,841] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.4263 ]
 [66.39688]
 [66.34638]
 [66.2186 ]
 [66.40527]], R is [[66.45594025]
 [66.46981049]
 [66.48091888]
 [66.49004364]
 [66.49900055]].
[2019-03-27 06:04:36,610] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.8389451e-03 3.3700820e-16 9.9116099e-01 1.8032177e-20 2.5281607e-16], sum to 1.0000
[2019-03-27 06:04:36,621] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0425
[2019-03-27 06:04:36,625] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.2595923835969546, 0.0, 2.0, 0.0, 1.0, 2.0, 0.449181396437402, 6.9112, 6.9112, 168.912956510431, 725489.2018954367, 725489.2018954367, 209736.0142385022], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3432600.0000, 
sim time next is 3433200.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.2648016245089845, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4581870319599477, 6.911200000000001, 6.9112, 168.912956510431, 740052.6666240429, 740052.6666240423, 211185.1964242073], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.11421882470961985, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3392524779999362, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20557018517334524, 0.20557018517334508, 0.3152017857077721], 
reward next is 0.6848, 
noisyNet noise sample is [array([-1.0333825], dtype=float32), -0.48700345]. 
=============================================
[2019-03-27 06:04:37,647] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [5.5578560e-01 7.6642074e-15 4.4421440e-01 7.6120841e-18 3.7281176e-12], sum to 1.0000
[2019-03-27 06:04:37,658] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5523
[2019-03-27 06:04:37,669] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1064208.759012632 W.
[2019-03-27 06:04:37,673] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 82.33333333333334, 1.0, 2.0, 0.7614626290215535, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565103226, 1064208.759012632, 1064208.759012632, 234668.1466658181], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3465600.0000, 
sim time next is 3466200.0000, 
raw observation next is [26.83333333333333, 80.66666666666667, 1.0, 2.0, 0.7387328466759125, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104309, 1032426.513555706, 1032426.513555706, 229424.5692677757], 
processed observation next is [1.0, 0.08695652173913043, 0.470774091627172, 0.8066666666666668, 1.0, 1.0, 0.6852202971998946, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523021, 0.2867851426543628, 0.2867851426543628, 0.3424247302504115], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.5182213], dtype=float32), 1.9990191]. 
=============================================
[2019-03-27 06:04:40,256] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1292382e-06 2.2616144e-15 9.9999690e-01 3.0092026e-20 2.9101693e-15], sum to 1.0000
[2019-03-27 06:04:40,266] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2074
[2019-03-27 06:04:40,273] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.030118294521288, 6.9112, 168.9120326312334, 2379645.691511903, 2295281.421964455, 476384.1592447074], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3495600.0000, 
sim time next is 3496200.0000, 
raw observation next is [31.16666666666667, 66.16666666666667, 1.0, 2.0, 1.008508860779849, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.992940529063159, 6.9112, 168.9123738518584, 2306911.784640002, 2248922.440063349, 466428.2147108928], 
processed observation next is [1.0, 0.4782608695652174, 0.6761453396524489, 0.6616666666666667, 1.0, 1.0, 1.010251639493794, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008174052906315944, 0.0, 0.829437084031969, 0.6408088290666673, 0.6247006777953747, 0.6961615144938699], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.3063483], dtype=float32), 0.3006428]. 
=============================================
[2019-03-27 06:04:43,887] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.1797690e-02 2.0385989e-15 9.5820230e-01 4.8239320e-18 4.6665173e-14], sum to 1.0000
[2019-03-27 06:04:43,895] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9736
[2019-03-27 06:04:43,902] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.3858013230038913, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6487189744625304, 6.9112, 6.9112, 168.9129565067873, 1078387.490607772, 1078387.490607772, 250582.2366092119], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3565200.0000, 
sim time next is 3565800.0000, 
raw observation next is [27.5, 79.0, 1.0, 2.0, 0.3952119828110334, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6647990558602351, 6.911199999999999, 6.9112, 168.9129565104301, 1104705.743144839, 1104705.743144839, 254423.5702232432], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.79, 1.0, 1.0, 0.2713397383265463, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5912183608051648, -8.881784197001253e-17, 0.0, 0.8294399451522982, 0.30686270642912195, 0.30686270642912195, 0.37973667197498984], 
reward next is 0.6203, 
noisyNet noise sample is [array([0.09596403], dtype=float32), -0.23008439]. 
=============================================
[2019-03-27 06:05:03,574] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.7350891e-23 3.7310477e-14 2.8566206e-25 3.1737797e-21], sum to 1.0000
[2019-03-27 06:05:03,578] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2009
[2019-03-27 06:05:03,583] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9822927902406334, 6.9112, 6.9112, 168.912956510431, 796047.6663254774, 796047.6663254774, 242766.9226629439], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3906000.0000, 
sim time next is 3906600.0000, 
raw observation next is [27.0, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.977182711756631, 6.9112, 6.9112, 168.912956510431, 792912.7017176654, 792912.7017176654, 241529.2931796394], 
processed observation next is [0.0, 0.21739130434782608, 0.4786729857819906, 0.9316666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9721740387275988, 0.0, 0.0, 0.8294399451523027, 0.22025352825490707, 0.22025352825490707, 0.36049148235767076], 
reward next is 0.6395, 
noisyNet noise sample is [array([-0.68589586], dtype=float32), -0.6375295]. 
=============================================
[2019-03-27 06:05:06,918] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999797e-01 1.0015049e-17 2.0730379e-06 1.0989219e-19 2.8983167e-16], sum to 1.0000
[2019-03-27 06:05:06,926] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5249
[2019-03-27 06:05:06,934] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 915808.7030306947 W.
[2019-03-27 06:05:06,941] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 75.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.033796636133139, 6.9112, 168.9121352177002, 915808.7030306947, 828834.8527957199, 254812.5342140243], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3963600.0000, 
sim time next is 3964200.0000, 
raw observation next is [31.16666666666667, 74.33333333333333, 1.0, 1.0, 0.2085109755716708, 1.0, 1.0, 0.2085109755716708, 1.0, 2.0, 0.3621146089346668, 6.911199999999999, 6.9112, 170.5573041426782, 874153.7899741759, 874153.7899741764, 272249.034097581], 
processed observation next is [0.0, 0.9130434782608695, 0.6761453396524489, 0.7433333333333333, 1.0, 0.5, 0.04639876574900096, 1.0, 0.5, 0.04639876574900096, 1.0, 1.0, 0.2220909865056912, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.24282049721504884, 0.242820497215049, 0.40634184193668804], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9725586], dtype=float32), 0.8415278]. 
=============================================
[2019-03-27 06:05:07,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999428e-01 7.5445456e-18 5.7370999e-06 1.6502500e-19 1.2242328e-15], sum to 1.0000
[2019-03-27 06:05:07,947] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1733
[2019-03-27 06:05:07,956] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 935875.7199006549 W.
[2019-03-27 06:05:07,960] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.66666666666666, 72.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.062071812330205, 6.9112, 168.911983625297, 935875.7199006549, 828842.6801065331, 254812.7469223147], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3966000.0000, 
sim time next is 3966600.0000, 
raw observation next is [31.83333333333333, 71.66666666666667, 1.0, 1.0, 0.6239360002037884, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128336641969, 871924.70146306, 871924.7014630606, 205289.1193269391], 
processed observation next is [0.0, 0.9130434782608695, 0.7077409162717218, 0.7166666666666667, 1.0, 0.5, 0.5469108436190221, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294393419210541, 0.2422013059619611, 0.24220130596196127, 0.30640167063722257], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.33075902], dtype=float32), -0.8268577]. 
=============================================
[2019-03-27 06:05:11,413] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0395397e-06 3.9382747e-13 9.9999893e-01 1.9534983e-18 1.1332224e-12], sum to 1.0000
[2019-03-27 06:05:11,423] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0394
[2019-03-27 06:05:11,428] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2537146.655751618 W.
[2019-03-27 06:05:11,431] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.0, 60.0, 1.0, 2.0, 0.9070904214244975, 1.0, 2.0, 0.9070904214244975, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2537146.655751618, 2537146.655751617, 475380.8258126625], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4021200.0000, 
sim time next is 4021800.0000, 
raw observation next is [34.0, 60.0, 1.0, 2.0, 0.5929376954158774, 1.0, 2.0, 0.5929376954158774, 1.0, 1.0, 1.029736689445112, 6.9112, 6.9112, 170.5573041426782, 2487635.323643079, 2487635.323643079, 485362.3338900722], 
processed observation next is [1.0, 0.5652173913043478, 0.8104265402843602, 0.6, 1.0, 1.0, 0.5095634884528643, 1.0, 1.0, 0.5095634884528643, 1.0, 0.5, 1.0362642554208683, 0.0, 0.0, 0.8375144448122397, 0.6910098121230775, 0.6910098121230775, 0.7244213938657794], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.57281935], dtype=float32), 0.99876326]. 
=============================================
[2019-03-27 06:05:11,831] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999905e-01 1.4863977e-19 8.9490953e-07 1.1218575e-22 7.0407013e-17], sum to 1.0000
[2019-03-27 06:05:11,842] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0574
[2019-03-27 06:05:11,846] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.66666666666666, 52.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.916703155724857, 6.9112, 168.9126846358262, 832706.5617631082, 828802.4399717989, 254812.3740714479], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4302600.0000, 
sim time next is 4303200.0000, 
raw observation next is [35.33333333333334, 54.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.952187600802706, 6.9112, 168.9125351833181, 857890.2043375982, 828812.2621743976, 254812.5924889156], 
processed observation next is [1.0, 0.8260869565217391, 0.8736176935229073, 0.5433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00409876008027057, 0.0, 0.829437876243294, 0.2383028345382217, 0.2302256283817771, 0.38031730222226207], 
reward next is 0.4147, 
noisyNet noise sample is [array([0.7595962], dtype=float32), 0.34505457]. 
=============================================
[2019-03-27 06:05:11,887] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.2911706e-06 4.9569501e-13 9.9999774e-01 3.9384832e-19 1.2163296e-13], sum to 1.0000
[2019-03-27 06:05:11,897] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1506
[2019-03-27 06:05:11,906] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2606919.78742597 W.
[2019-03-27 06:05:11,911] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 66.33333333333334, 1.0, 2.0, 0.9320099826876354, 1.0, 2.0, 0.9320099826876354, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2606919.78742597, 2606919.78742597, 489261.5907752861], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4033200.0000, 
sim time next is 4033800.0000, 
raw observation next is [32.0, 69.5, 1.0, 2.0, 0.6194995924870483, 1.0, 2.0, 0.6194995924870483, 1.0, 1.0, 1.03, 6.962761927234619, 6.9112, 170.5573041426782, 2599190.11409488, 2562254.208211622, 495157.8384754565], 
processed observation next is [1.0, 0.6956521739130435, 0.7156398104265403, 0.695, 1.0, 1.0, 0.5415657740807811, 1.0, 1.0, 0.5415657740807811, 1.0, 0.5, 1.0365853658536586, 0.005156192723461928, 0.0, 0.8375144448122397, 0.7219972539152444, 0.7117372800587839, 0.7390415499633679], 
reward next is 0.0031, 
noisyNet noise sample is [array([2.1884716], dtype=float32), -0.094049014]. 
=============================================
[2019-03-27 06:05:16,895] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.0995106e-06 1.6861974e-13 9.9999690e-01 8.6702647e-19 2.0099204e-13], sum to 1.0000
[2019-03-27 06:05:16,904] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2285
[2019-03-27 06:05:16,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3167785.248324494 W.
[2019-03-27 06:05:16,917] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.83333333333334, 67.0, 1.0, 2.0, 0.8685175622545696, 1.0, 2.0, 0.7548488206415472, 1.0, 2.0, 1.03, 7.00511102337295, 6.9112, 170.5573041426782, 3167785.248324494, 3100512.962226259, 579842.4557928541], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4119000.0000, 
sim time next is 4119600.0000, 
raw observation next is [34.66666666666667, 67.0, 1.0, 2.0, 0.8779496336962961, 1.0, 2.0, 0.7595648563624107, 1.0, 2.0, 1.03, 7.005111767516233, 6.9112, 170.5573041426782, 3187601.738755339, 3120328.919597, 583430.0072463097], 
processed observation next is [1.0, 0.6956521739130435, 0.8420221169036337, 0.67, 1.0, 1.0, 0.8529513658991519, 1.0, 1.0, 0.7103191040510972, 1.0, 1.0, 1.0365853658536586, 0.00939117675162331, 0.0, 0.8375144448122397, 0.8854449274320385, 0.8667580332213889, 0.8707910555915069], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.56800145], dtype=float32), -0.6777438]. 
=============================================
[2019-03-27 06:05:23,709] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-27 06:05:23,710] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:05:23,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:05:23,713] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:05:23,715] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:05:23,717] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:05:23,718] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:05:23,719] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:05:23,719] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:05:23,719] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:05:23,721] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:05:23,746] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run31
[2019-03-27 06:05:23,746] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run31
[2019-03-27 06:05:23,786] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run31
[2019-03-27 06:05:23,787] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run31
[2019-03-27 06:05:23,787] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run31
[2019-03-27 06:05:25,771] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05770886]
[2019-03-27 06:05:25,774] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.66666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7549591803284184, 6.9112, 6.9112, 168.912956510431, 641114.2574904739, 641114.2574904739, 192963.1669434712]
[2019-03-27 06:05:25,774] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:05:25,778] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 7.4532026e-23 1.6770048e-12 2.5651863e-24 5.2976146e-20], sampled 0.6380126525596695
[2019-03-27 06:05:57,657] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05770886]
[2019-03-27 06:05:57,658] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.43333333333334, 63.83333333333334, 1.0, 2.0, 0.755909775565013, 1.0, 2.0, 0.755909775565013, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2113920.375647899, 2113920.375647899, 398982.6591705662]
[2019-03-27 06:05:57,659] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:05:57,661] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0747640e-05 2.8657255e-12 9.9996924e-01 9.4688139e-17 2.8352466e-12], sampled 0.9625562363577812
[2019-03-27 06:06:35,315] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05770886]
[2019-03-27 06:06:35,316] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.10175894333333, 90.27486234, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8664757970709611, 6.911199999999999, 6.9112, 168.912956510431, 720578.225143269, 720578.2251432698, 215969.4902389328]
[2019-03-27 06:06:35,316] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:06:35,318] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.1026985e-22 3.6295194e-12 6.4465903e-24 1.2684972e-19], sampled 0.42181261711807017
[2019-03-27 06:06:52,073] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05770886]
[2019-03-27 06:06:52,075] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.86666666666667, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8940177851536486, 6.9112, 6.9112, 168.912956510431, 734672.0938592498, 734672.0938592498, 221915.3605199168]
[2019-03-27 06:06:52,077] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:06:52,081] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.8827691e-22 2.1318601e-10 5.1097203e-24 2.1484887e-19], sampled 0.37960028186640526
[2019-03-27 06:07:16,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05770886]
[2019-03-27 06:07:16,529] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.75251912333333, 74.72818943666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9491380886536699, 6.9112, 6.9112, 168.912956510431, 773010.9173290685, 773010.9173290685, 234711.1441426229]
[2019-03-27 06:07:16,532] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:07:16,534] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.7794957e-21 3.7632170e-10 5.7702083e-23 1.1536022e-18], sampled 0.4077254652488337
[2019-03-27 06:07:18,330] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7131.1151 3122157125.8521 1750.0000
[2019-03-27 06:07:18,719] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7140.4932 3328539595.3609 2063.0000
[2019-03-27 06:07:18,764] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6830.5906 3198063689.6282 2256.0000
[2019-03-27 06:07:18,849] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7912.8702 2948598368.1477 1222.0000
[2019-03-27 06:07:18,868] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7781.5241 2999547958.6857 1365.0000
[2019-03-27 06:07:19,883] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 750000, evaluation results [750000.0, 7140.493227946993, 3328539595.360873, 2063.0, 7131.115121943753, 3122157125.852091, 1750.0, 7912.870216869913, 2948598368.147741, 1222.0, 6830.590627944395, 3198063689.6282187, 2256.0, 7781.524080992638, 2999547958.685726, 1365.0]
[2019-03-27 06:07:23,419] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.1125239e-01 3.2025803e-12 7.8874767e-01 7.6253446e-17 1.8312057e-11], sum to 1.0000
[2019-03-27 06:07:23,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6097
[2019-03-27 06:07:23,441] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.3126953062726428, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5430483370776, 6.911199999999999, 6.9112, 168.912956510431, 873958.2980055744, 873958.298005575, 226139.4800907747], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4317600.0000, 
sim time next is 4318200.0000, 
raw observation next is [31.0, 79.0, 1.0, 2.0, 0.3123294855306263, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5424130274274854, 6.9112, 6.9112, 168.912956510431, 872935.4382042066, 872935.4382042066, 226016.9658715619], 
processed observation next is [1.0, 1.0, 0.6682464454976303, 0.79, 1.0, 1.0, 0.17148130786822444, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.44196710661888466, 0.0, 0.0, 0.8294399451523027, 0.2424820661678352, 0.2424820661678352, 0.3373387550321819], 
reward next is 0.6627, 
noisyNet noise sample is [array([0.06430648], dtype=float32), 0.8862129]. 
=============================================
[2019-03-27 06:07:28,574] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.2624969e-01 2.0031699e-13 2.7375031e-01 5.7406798e-17 1.0191930e-12], sum to 1.0000
[2019-03-27 06:07:28,584] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0581
[2019-03-27 06:07:28,589] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.6188664987325366, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129564635609, 864837.3986801275, 864837.3986801275, 204313.5998292752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4404600.0000, 
sim time next is 4405200.0000, 
raw observation next is [30.0, 84.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.138385086878783, 6.9112, 168.9115793836577, 990035.4120684318, 828863.8063525753, 254813.1134606652], 
processed observation next is [1.0, 1.0, 0.6208530805687204, 0.84, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.02271850868787828, 0.0, 0.8294331828293945, 0.2750098366856755, 0.2302399462090487, 0.3803180797920376], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.39210787], dtype=float32), 0.92964375]. 
=============================================
[2019-03-27 06:07:35,478] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.7449973e-24 9.2469401e-15 3.5469538e-25 1.1409742e-21], sum to 1.0000
[2019-03-27 06:07:35,483] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-27 06:07:35,490] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8484411947175418, 6.911199999999999, 6.9112, 168.912956510431, 705827.0196237068, 705827.0196237075, 211987.2058758516], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4524000.0000, 
sim time next is 4524600.0000, 
raw observation next is [27.83333333333334, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8410532905189277, 6.9112, 6.9112, 168.912956510431, 700610.3909894257, 700610.3909894257, 210405.1522689881], 
processed observation next is [0.0, 0.34782608695652173, 0.5181674565560824, 0.7566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8061625494133264, 0.0, 0.0, 0.8294399451523027, 0.1946139974970627, 0.1946139974970627, 0.31403754069998224], 
reward next is 0.6860, 
noisyNet noise sample is [array([-0.29900232], dtype=float32), -0.20319365]. 
=============================================
[2019-03-27 06:07:35,862] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.0442908e-24 2.4488204e-16 6.3407580e-26 1.4113096e-20], sum to 1.0000
[2019-03-27 06:07:35,869] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3330
[2019-03-27 06:07:35,876] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8529797366306165, 6.9112, 6.9112, 168.912956510431, 709612.3104869892, 709612.3104869892, 212983.3205674432], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4501800.0000, 
sim time next is 4502400.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8524420141597239, 6.9112, 6.9112, 168.912956510431, 709164.8182007936, 709164.8182007936, 212865.0495822367], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8200512367801509, 0.0, 0.0, 0.8294399451523027, 0.19699022727799823, 0.19699022727799823, 0.31770902922721894], 
reward next is 0.6823, 
noisyNet noise sample is [array([-0.04785446], dtype=float32), 0.67022574]. 
=============================================
[2019-03-27 06:07:37,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.9411449e-25 3.0917653e-15 1.2569665e-25 6.6066270e-22], sum to 1.0000
[2019-03-27 06:07:37,064] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5577
[2019-03-27 06:07:37,068] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9012478509621881, 6.9112, 6.9112, 168.912956510431, 740444.2144029543, 740444.2144029543, 223581.8732186009], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4530600.0000, 
sim time next is 4531200.0000, 
raw observation next is [28.66666666666666, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9129034563075115, 6.911199999999999, 6.9112, 168.912956510431, 748198.9319862392, 748198.9319862397, 226232.3338853914], 
processed observation next is [0.0, 0.43478260869565216, 0.5576619273301735, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8937847028140382, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20783303666284422, 0.20783303666284436, 0.33766019982894235], 
reward next is 0.6623, 
noisyNet noise sample is [array([-0.866938], dtype=float32), -0.43516085]. 
=============================================
[2019-03-27 06:07:40,345] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.0604524e-26 7.1676187e-16 8.8781634e-28 7.7387271e-24], sum to 1.0000
[2019-03-27 06:07:40,353] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8818
[2019-03-27 06:07:40,360] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.952814904498726, 6.9112, 6.9112, 168.912956510431, 776134.0468403588, 776134.0468403588, 235618.9072621741], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4580400.0000, 
sim time next is 4581000.0000, 
raw observation next is [28.0, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9635136046675982, 6.9112, 6.9112, 168.912956510431, 783400.7262489481, 783400.7262489481, 238191.0360838163], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9555043959360952, 0.0, 0.0, 0.8294399451523027, 0.21761131284693003, 0.21761131284693003, 0.35550900908032285], 
reward next is 0.6445, 
noisyNet noise sample is [array([-0.88191265], dtype=float32), -0.44319937]. 
=============================================
[2019-03-27 06:07:40,368] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[63.339184]
 [63.92095 ]
 [65.56255 ]
 [67.03587 ]
 [67.009125]], R is [[62.3372345 ]
 [62.36219406]
 [62.39022827]
 [62.41963577]
 [62.4486084 ]].
[2019-03-27 06:07:42,362] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.7511540e-23 1.4814704e-09 5.8697767e-24 6.2697297e-19], sum to 1.0000
[2019-03-27 06:07:42,368] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0076
[2019-03-27 06:07:42,377] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8281934418735022, 6.9112, 6.9112, 168.912956510431, 688745.9076437948, 688745.9076437948, 207605.6274054547], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4904400.0000, 
sim time next is 4905000.0000, 
raw observation next is [29.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8298605719337425, 6.911200000000001, 6.9112, 168.912956510431, 690153.8890522765, 690153.8890522758, 207962.2635432671], 
processed observation next is [1.0, 0.782608695652174, 0.5734597156398105, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7925128926021249, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19170941362563237, 0.19170941362563218, 0.3103914381242792], 
reward next is 0.6896, 
noisyNet noise sample is [array([-0.33748606], dtype=float32), -2.1000237]. 
=============================================
[2019-03-27 06:07:42,389] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[61.871883]
 [61.83558 ]
 [60.690437]
 [59.341652]
 [56.32718 ]], R is [[61.89740753]
 [61.96857452]
 [62.04129791]
 [62.11655045]
 [62.19323349]].
[2019-03-27 06:07:42,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [7.5662014e-05 2.1928702e-13 9.9992430e-01 6.7488322e-18 8.7842803e-13], sum to 1.0000
[2019-03-27 06:07:42,597] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5992
[2019-03-27 06:07:42,601] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.5778454609777421, 1.0, 2.0, 0.5778454609777421, 1.0, 1.0, 1.003526469304268, 6.911200000000001, 6.9112, 170.5573041426782, 2424255.31748745, 2424255.31748745, 473151.93390737], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4618800.0000, 
sim time next is 4619400.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 9.18367267321279, 6.9112, 168.8998210090019, 3897211.020087689, 2285166.063523037, 469774.96098441], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.71, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.227247267321279, 0.0, 0.8293754438268273, 1.0825586166910248, 0.6347683509786214, 0.7011566581856866], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2393912], dtype=float32), 1.0862287]. 
=============================================
[2019-03-27 06:07:45,160] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.4778216e-01 2.0092427e-13 6.5221786e-01 6.6092346e-17 7.9596676e-12], sum to 1.0000
[2019-03-27 06:07:45,169] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6992
[2019-03-27 06:07:45,175] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.3077260060019208, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5207478783220973, 6.911200000000001, 6.9112, 168.912956510431, 860063.8789519029, 860063.8789519022, 223019.1296407872], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4950600.0000, 
sim time next is 4951200.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 1.0, 2.0, 0.301334686278257, 0.0, 2.0, 0.0, 1.0, 2.0, 0.509853714332301, 6.911199999999999, 6.9112, 168.912956510431, 842193.687619796, 842193.6876197966, 220994.4730164419], 
processed observation next is [1.0, 0.30434782608695654, 0.5102685624012641, 0.8066666666666668, 1.0, 1.0, 0.1582345617810325, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4022606272345134, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2339426910054989, 0.23394269100549905, 0.3298424970394655], 
reward next is 0.6702, 
noisyNet noise sample is [array([0.16440922], dtype=float32), -0.73236156]. 
=============================================
[2019-03-27 06:07:45,649] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 4.5404994e-18 1.4129698e-07 1.7189981e-20 1.3561647e-15], sum to 1.0000
[2019-03-27 06:07:45,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2997
[2019-03-27 06:07:45,665] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1291546.451758714 W.
[2019-03-27 06:07:45,671] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.0, 91.5, 1.0, 2.0, 0.4620169170785574, 1.0, 2.0, 0.4620169170785574, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1291546.451758714, 1291546.451758714, 288880.7723048088], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4674600.0000, 
sim time next is 4675200.0000, 
raw observation next is [27.0, 92.33333333333334, 1.0, 2.0, 0.4341257252322865, 1.0, 2.0, 0.4341257252322865, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1213533.814696246, 1213533.814696246, 281068.5340749408], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.9233333333333335, 1.0, 1.0, 0.3182237653401042, 1.0, 1.0, 0.3182237653401042, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3370927263045128, 0.3370927263045128, 0.41950527473871757], 
reward next is 0.5805, 
noisyNet noise sample is [array([0.17444038], dtype=float32), 0.38077924]. 
=============================================
[2019-03-27 06:07:47,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6907098e-03 5.9091431e-14 9.9830925e-01 4.3760009e-18 1.4101316e-11], sum to 1.0000
[2019-03-27 06:07:47,266] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6643
[2019-03-27 06:07:47,272] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 75.0, 1.0, 2.0, 0.8722535597108771, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001155497917378, 6.9112, 168.9123481001699, 2116199.87954465, 2052382.583158124, 426657.5910413265], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4701000.0000, 
sim time next is 4701600.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.8234984605494721, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001099636312743, 6.9112, 168.9123483647022, 2047960.92996755, 1984183.263483334, 413909.8474300893], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.75, 1.0, 1.0, 0.7873475428306892, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00898996363127429, 0.0, 0.829436958878364, 0.5688780361020972, 0.5511620176342594, 0.6177758916867004], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.89129907], dtype=float32), 0.01768445]. 
=============================================
[2019-03-27 06:07:52,801] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.4371792e-03 7.7323876e-14 9.9756289e-01 2.7319201e-18 2.0314091e-12], sum to 1.0000
[2019-03-27 06:07:52,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2959
[2019-03-27 06:07:52,815] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.5, 64.5, 1.0, 2.0, 0.5741789148806119, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9862741602203031, 6.911199999999999, 6.9112, 168.9129203404637, 1605336.515173111, 1605336.515173112, 349013.4156798865], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4797000.0000, 
sim time next is 4797600.0000, 
raw observation next is [31.66666666666666, 64.0, 1.0, 2.0, 0.5670969617032037, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9749440562577756, 6.911199999999999, 6.9112, 168.9129565013993, 1585521.419963364, 1585521.419963364, 344867.485170646], 
processed observation next is [1.0, 0.5217391304347826, 0.6998420221169034, 0.64, 1.0, 1.0, 0.4784300743412092, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9694439710460678, -8.881784197001253e-17, 0.0, 0.8294399451079528, 0.44042261665649, 0.44042261665649, 0.5147275898069343], 
reward next is 0.4853, 
noisyNet noise sample is [array([-1.0573677], dtype=float32), -1.2324693]. 
=============================================
[2019-03-27 06:07:53,195] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.4765533e-01 3.6714416e-14 6.5234470e-01 4.0816305e-16 5.4571112e-11], sum to 1.0000
[2019-03-27 06:07:53,202] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7238
[2019-03-27 06:07:53,205] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.3407395861649882, 1.0, 1.0, 0.3407395861649882, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 952370.8372799108, 952370.8372799108, 258226.5244910839], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4858200.0000, 
sim time next is 4858800.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.3505057286947956, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5924081683505441, 6.9112, 6.9112, 168.912956510431, 979684.136870617, 979684.136870617, 237551.6870377767], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.84, 1.0, 1.0, 0.21747678155999473, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.5029367906713952, 0.0, 0.0, 0.8294399451523027, 0.2721344824640603, 0.2721344824640603, 0.354554756772801], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.36711523], dtype=float32), -0.047554627]. 
=============================================
[2019-03-27 06:08:06,548] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3276901e-28 2.1834050e-19 3.2983234e-27 1.4996077e-25], sum to 1.0000
[2019-03-27 06:08:06,557] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0551
[2019-03-27 06:08:06,562] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666666, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.86681715814374, 6.911199999999999, 6.9112, 168.912956510431, 717650.6268661107, 717650.6268661113, 215942.2040384181], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5037000.0000, 
sim time next is 5037600.0000, 
raw observation next is [27.33333333333334, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8774209100791919, 6.911199999999999, 6.9112, 168.912956510431, 724911.0722911513, 724911.0722911519, 218274.3517090241], 
processed observation next is [0.0, 0.30434782608695654, 0.4944707740916275, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8505133049746243, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20136418674754203, 0.20136418674754217, 0.32578261449108076], 
reward next is 0.6742, 
noisyNet noise sample is [array([1.8566822], dtype=float32), -0.80654174]. 
=============================================
[2019-03-27 06:08:09,753] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.0313168e-29 4.4427002e-19 2.1465782e-28 3.1709657e-25], sum to 1.0000
[2019-03-27 06:08:09,760] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4580
[2019-03-27 06:08:09,765] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881308949503709, 6.911200000000001, 6.9112, 168.912956510431, 728349.6647396589, 728349.6647396584, 219164.1039075704], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5088000.0000, 
sim time next is 5088600.0000, 
raw observation next is [27.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8786775523064634, 6.911199999999999, 6.9112, 168.912956510431, 726538.1833107037, 726538.1833107043, 218579.6936266805], 
processed observation next is [0.0, 0.9130434782608695, 0.5023696682464456, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.852045795495687, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20181616203075103, 0.2018161620307512, 0.32623834869653806], 
reward next is 0.6738, 
noisyNet noise sample is [array([-0.21391739], dtype=float32), -1.0424262]. 
=============================================
[2019-03-27 06:08:14,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9875057e-01 3.8908506e-16 1.2494149e-03 6.9398861e-19 1.3439415e-13], sum to 1.0000
[2019-03-27 06:08:14,335] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0508
[2019-03-27 06:08:14,344] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1330148.04886644 W.
[2019-03-27 06:08:14,348] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.4758170658070852, 1.0, 2.0, 0.4758170658070852, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1330148.04886644, 1330148.04886644, 292905.6866621695], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5196000.0000, 
sim time next is 5196600.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.9390889223921548, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1312610.051314403, 1312610.051314403, 280913.8639878352], 
processed observation next is [1.0, 0.13043478260869565, 0.4312796208530806, 0.89, 1.0, 1.0, 0.9266131595086202, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3646139031428897, 0.3646139031428897, 0.41927442386244057], 
reward next is 0.5807, 
noisyNet noise sample is [array([0.91304433], dtype=float32), 1.0296001]. 
=============================================
[2019-03-27 06:08:14,476] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-27 06:08:14,477] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:08:14,480] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:08:14,480] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:08:14,481] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:08:14,482] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:08:14,482] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:08:14,483] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:08:14,484] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:08:14,485] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:08:14,486] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:08:14,505] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run32
[2019-03-27 06:08:14,506] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run32
[2019-03-27 06:08:14,525] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run32
[2019-03-27 06:08:14,525] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run32
[2019-03-27 06:08:14,579] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run32
[2019-03-27 06:08:23,979] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:23,980] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.83333333333334, 49.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.829011757032246, 6.9112, 6.9112, 168.912956510431, 727932.060205617, 727932.060205617, 207823.5307215162]
[2019-03-27 06:08:23,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:08:23,985] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 9.62287045e-27 3.35288810e-18 1.28253006e-26
 1.47826475e-23], sampled 0.8171747321792014
[2019-03-27 06:08:28,034] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:28,037] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.72912937, 73.75936552, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4641601866748946, 6.911200000000001, 6.9112, 168.912956510431, 413964.9192257392, 413964.9192257386, 147551.7672933877]
[2019-03-27 06:08:28,038] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:08:28,041] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.2380747e-27 2.1899948e-19 6.3102066e-27 3.6526303e-24], sampled 0.32685589480977095
[2019-03-27 06:08:34,060] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:34,063] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.62534986666667, 89.62624635333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6849866540411979, 6.911199999999999, 6.9112, 168.912956510431, 587951.7441120701, 587951.7441120708, 180068.606393402]
[2019-03-27 06:08:34,065] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:08:34,067] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.9477788e-28 3.8598111e-19 3.4248485e-28 8.1568691e-25], sampled 0.7514224813086299
[2019-03-27 06:08:35,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:35,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.23333333333333, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5519606413982432, 6.9112, 6.9112, 168.912956510431, 485071.9430994448, 485071.9430994448, 158973.8243499171]
[2019-03-27 06:08:35,085] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:08:35,089] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 6.4637156e-28 1.9576096e-19 1.2700559e-27 1.3573077e-24], sampled 0.6415875131096078
[2019-03-27 06:08:41,002] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:41,006] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.23378598666667, 83.20961432333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7235582852466983, 6.911199999999999, 6.9112, 168.912956510431, 626890.6827471796, 626890.6827471802, 186989.5431384043]
[2019-03-27 06:08:41,008] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:08:41,010] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.0650490e-23 1.7422755e-13 1.0247377e-23 1.7243245e-20], sampled 0.8811426940877413
[2019-03-27 06:08:50,632] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:50,633] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.719762005, 97.67157659, 1.0, 2.0, 0.8150465243427047, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005982468000148, 6.9112, 168.9123159987234, 2036131.819239066, 1968890.12925795, 411610.7367751561]
[2019-03-27 06:08:50,635] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:08:50,638] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.99999523e-01 1.06572395e-17 4.85607472e-07 1.17645259e-19
 2.74122054e-15], sampled 0.5357744570962724
[2019-03-27 06:08:50,640] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2036131.819239066 W.
[2019-03-27 06:08:57,973] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:57,974] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.06666666666667, 53.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.464114242160566, 6.9112, 168.9098259970971, 1846272.71862427, 1454023.595198706, 311354.0819177674]
[2019-03-27 06:08:57,975] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:08:57,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.3161257e-01 4.5330020e-12 8.6838746e-01 3.7273321e-15 1.4327378e-10], sampled 0.49079357960024783
[2019-03-27 06:08:59,198] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:08:59,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.15, 51.5, 1.0, 2.0, 0.6112739777265681, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.947034701698309, 6.9112, 168.9126870811588, 1709133.447090073, 1683711.116920698, 366678.5256690099]
[2019-03-27 06:08:59,200] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:08:59,204] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.4173944e-01 4.8218737e-13 5.8260627e-02 1.1087559e-15 2.3257254e-11], sampled 0.5318330576827587
[2019-03-27 06:08:59,205] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1709133.447090073 W.
[2019-03-27 06:09:42,997] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.05943925]
[2019-03-27 06:09:42,997] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.01666666666667, 65.0, 1.0, 2.0, 0.716911155826211, 1.0, 1.0, 0.716911155826211, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2004757.722860971, 2004757.722860971, 381446.8084083569]
[2019-03-27 06:09:42,999] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:09:43,001] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.9741324e-02 1.1125370e-12 9.3025869e-01 3.1381282e-16 4.0712014e-11], sampled 0.4447306319380724
[2019-03-27 06:10:08,756] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7230.0153 3109125068.4796 1932.0000
[2019-03-27 06:10:09,256] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7871.8929 2991200540.5858 1518.0000
[2019-03-27 06:10:09,299] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6955.9750 3187847271.1917 2414.0000
[2019-03-27 06:10:09,382] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7257.1531 3320949708.2172 2127.0000
[2019-03-27 06:10:09,391] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8006.4504 2939629287.2435 1338.0000
[2019-03-27 06:10:10,406] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 775000, evaluation results [775000.0, 7257.153132821119, 3320949708.2171693, 2127.0, 7230.015305918344, 3109125068.479558, 1932.0, 8006.45038587287, 2939629287.2434626, 1338.0, 6955.9749749306075, 3187847271.19166, 2414.0, 7871.89288781516, 2991200540.5857706, 1518.0]
[2019-03-27 06:10:13,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6542459e-23 5.1498449e-13 1.2121381e-24 7.5010717e-21], sum to 1.0000
[2019-03-27 06:10:13,012] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6733
[2019-03-27 06:10:13,023] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.6, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.02376929053474, 6.9112, 6.9112, 168.9128061317408, 823785.3628281186, 823785.3628281186, 253163.3574553627], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5277000.0000, 
sim time next is 5277600.0000, 
raw observation next is [28.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.919174181357342, 6.9112, 168.9127211796295, 834460.2746852459, 828803.1238618018, 254811.9941892909], 
processed observation next is [1.0, 0.08695652173913043, 0.5545023696682465, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0007974181357342403, 0.0, 0.8294387895703325, 0.23179452074590165, 0.23022308996161162, 0.3803164092377476], 
reward next is 0.5798, 
noisyNet noise sample is [array([-0.13402423], dtype=float32), -1.067049]. 
=============================================
[2019-03-27 06:10:20,233] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [5.0740129e-01 5.6294596e-13 4.9259871e-01 1.8748460e-16 1.0804007e-11], sum to 1.0000
[2019-03-27 06:10:20,241] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8135
[2019-03-27 06:10:20,245] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.311556573823244, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5410707353975699, 6.911199999999999, 6.9112, 168.912956510431, 870774.3274751618, 870774.3274751623, 225758.6900316312], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [30.9, 79.33333333333334, 1.0, 2.0, 0.3126172490136955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5429127774327385, 6.9112, 6.9112, 168.912956510431, 873740.0444910671, 873740.0444910671, 226112.6323475224], 
processed observation next is [1.0, 0.9130434782608695, 0.6635071090047393, 0.7933333333333334, 1.0, 1.0, 0.17182801085987406, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.442576557844803, 0.0, 0.0, 0.8294399451523027, 0.2427055679141853, 0.2427055679141853, 0.3374815408171976], 
reward next is 0.6625, 
noisyNet noise sample is [array([-0.7958443], dtype=float32), -0.14626049]. 
=============================================
[2019-03-27 06:10:23,252] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.7152499e-20 1.1519342e-09 5.5758728e-22 6.9597662e-18], sum to 1.0000
[2019-03-27 06:10:23,257] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4356
[2019-03-27 06:10:23,266] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 897494.1771478399 W.
[2019-03-27 06:10:23,273] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.1, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.007990878802826, 6.9112, 168.9121867112143, 897494.1771478399, 828827.7093802413, 254812.2297146111], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5443200.0000, 
sim time next is 5443800.0000, 
raw observation next is [29.0, 85.66666666666667, 1.0, 1.0, 0.301410297513795, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5234500088729064, 6.9112, 6.9112, 168.9128776899869, 842405.095759009, 842405.095759009, 222410.9189506161], 
processed observation next is [1.0, 0.0, 0.5734597156398105, 0.8566666666666667, 1.0, 0.5, 0.1583256596551747, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41884147423525164, 0.0, 0.0, 0.8294395581078381, 0.2340014154886136, 0.2340014154886136, 0.3319565954486807], 
reward next is 0.6680, 
noisyNet noise sample is [array([-0.97151756], dtype=float32), -0.34289488]. 
=============================================
[2019-03-27 06:10:38,920] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.0589233e-30 1.9436420e-20 1.0724389e-29 6.3621732e-27], sum to 1.0000
[2019-03-27 06:10:38,928] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9943
[2019-03-27 06:10:38,933] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666667, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9422088677311667, 6.911200000000001, 6.9112, 168.912956510431, 767038.5732999484, 767038.5732999478, 233006.0789856928], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5652600.0000, 
sim time next is 5653200.0000, 
raw observation next is [30.83333333333334, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9469664156261767, 6.911200000000001, 6.9112, 168.912956510431, 770119.6229159015, 770119.6229159008, 234125.4120353664], 
processed observation next is [0.0, 0.43478260869565216, 0.6603475513428123, 0.69, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9353248971050934, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2139221174766393, 0.2139221174766391, 0.3494409134856215], 
reward next is 0.6506, 
noisyNet noise sample is [array([0.652487], dtype=float32), -1.1681076]. 
=============================================
[2019-03-27 06:10:44,827] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.7359394e-29 1.3505136e-20 4.3831556e-28 3.2018151e-25], sum to 1.0000
[2019-03-27 06:10:44,837] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3648
[2019-03-27 06:10:44,841] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.4, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9007810488526233, 6.911200000000001, 6.9112, 168.912956510431, 738434.2367303645, 738434.2367303639, 223405.6904881031], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5751000.0000, 
sim time next is 5751600.0000, 
raw observation next is [33.2, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8901446732245594, 6.911199999999999, 6.9112, 168.912956510431, 731587.7569039543, 731587.7569039549, 221028.6047282357], 
processed observation next is [0.0, 0.5652173913043478, 0.7725118483412324, 0.53, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.866030089298243, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20321882136220953, 0.2032188213622097, 0.3298934398928891], 
reward next is 0.6701, 
noisyNet noise sample is [array([-0.01115301], dtype=float32), 1.2236296]. 
=============================================
[2019-03-27 06:10:46,675] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.7826400e-21 2.6148994e-11 3.7733426e-22 1.8051089e-17], sum to 1.0000
[2019-03-27 06:10:46,681] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4262
[2019-03-27 06:10:46,689] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2645938.682246251 W.
[2019-03-27 06:10:46,694] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.7, 89.66666666666667, 1.0, 1.0, 0.6306300153868976, 1.0, 1.0, 0.6306300153868976, 1.0, 2.0, 1.03, 6.978203820191984, 6.9112, 170.5573041426782, 2645938.682246251, 2597941.120301587, 499612.7062284881], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5797200.0000, 
sim time next is 5797800.0000, 
raw observation next is [26.65, 90.0, 1.0, 2.0, 0.4083059042608193, 1.0, 2.0, 0.4083059042608193, 1.0, 2.0, 0.7026326269603996, 6.911199999999999, 6.9112, 170.5573041426782, 1712435.740694585, 1712435.740694585, 356607.0613442515], 
processed observation next is [1.0, 0.08695652173913043, 0.462085308056872, 0.9, 1.0, 1.0, 0.2871155473021919, 1.0, 1.0, 0.2871155473021919, 1.0, 1.0, 0.6373568621468287, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4756765946373847, 0.4756765946373847, 0.5322493452899276], 
reward next is 0.4678, 
noisyNet noise sample is [array([-1.3148638], dtype=float32), 0.23150124]. 
=============================================
[2019-03-27 06:10:48,468] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.1870214e-26 1.6232655e-15 7.5197288e-27 8.7372429e-23], sum to 1.0000
[2019-03-27 06:10:48,477] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1610
[2019-03-27 06:10:48,481] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.1, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.89160003020262, 6.9112, 6.9112, 168.912956510431, 734233.6853797697, 734233.6853797697, 221420.0520834692], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5881200.0000, 
sim time next is 5881800.0000, 
raw observation next is [26.05, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891117046033366, 6.911200000000001, 6.9112, 168.912956510431, 733892.4519447054, 733892.4519447049, 221311.217855224], 
processed observation next is [1.0, 0.043478260869565216, 0.43364928909952616, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8672159097967878, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20385901442908486, 0.2038590144290847, 0.33031525053018507], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.5813633], dtype=float32), -0.06094831]. 
=============================================
[2019-03-27 06:10:48,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 9.4436038e-24 1.4517088e-12 6.0665977e-25 1.8962063e-21], sum to 1.0000
[2019-03-27 06:10:48,711] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4073
[2019-03-27 06:10:48,717] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.898811836460819, 6.9112, 6.9112, 168.912956510431, 739024.9802409161, 739024.9802409161, 223039.8930952314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6052800.0000, 
sim time next is 6053400.0000, 
raw observation next is [26.3, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977064042387554, 6.9112, 6.9112, 168.912956510431, 738242.634801634, 738242.634801634, 222788.9017257076], 
processed observation next is [1.0, 0.043478260869565216, 0.4454976303317536, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8752517124862869, 0.0, 0.0, 0.8294399451523027, 0.20506739855600944, 0.20506739855600944, 0.3325207488443397], 
reward next is 0.6675, 
noisyNet noise sample is [array([0.16378689], dtype=float32), -0.88476527]. 
=============================================
[2019-03-27 06:10:52,716] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.0925434e-01 4.5701431e-13 4.9074563e-01 1.7651206e-15 7.7558959e-11], sum to 1.0000
[2019-03-27 06:10:52,718] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7018
[2019-03-27 06:10:52,723] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.6, 91.83333333333334, 1.0, 2.0, 0.3492297674247253, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5962652327704999, 6.911199999999999, 6.9112, 168.912956510431, 976116.1110345233, 976116.1110345239, 237845.6627030151], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5896200.0000, 
sim time next is 5896800.0000, 
raw observation next is [26.8, 91.0, 1.0, 2.0, 0.3400325845863265, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5809069479519542, 6.911200000000001, 6.9112, 168.912956510431, 950397.984405501, 950397.9844055005, 234554.2695053453], 
processed observation next is [1.0, 0.2608695652173913, 0.4691943127962086, 0.91, 1.0, 1.0, 0.2048585356461765, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4889109121365295, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2639994401126392, 0.26399944011263904, 0.3500809992617094], 
reward next is 0.6499, 
noisyNet noise sample is [array([-0.17748393], dtype=float32), 0.621344]. 
=============================================
[2019-03-27 06:10:56,250] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 7.6374478e-27 7.7082017e-17 6.9426839e-27 3.6727920e-24], sum to 1.0000
[2019-03-27 06:10:56,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0324
[2019-03-27 06:10:56,264] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9296606369817163, 6.9112, 6.9112, 168.912956510431, 759347.9166735118, 759347.9166735118, 230098.7781070664], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5961600.0000, 
sim time next is 5962200.0000, 
raw observation next is [26.86666666666667, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9263752924086224, 6.911199999999999, 6.9112, 168.912956510431, 757323.6234659345, 757323.6234659351, 229342.7887093494], 
processed observation next is [1.0, 0.0, 0.4723538704581361, 0.9100000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9102137712300273, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2103676731849818, 0.21036767318498198, 0.3423026697154469], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.06692046], dtype=float32), -0.495445]. 
=============================================
[2019-03-27 06:10:59,352] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.9664167e-26 1.3909798e-17 2.7877526e-27 4.2799491e-23], sum to 1.0000
[2019-03-27 06:10:59,363] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9579
[2019-03-27 06:10:59,366] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.53333333333334, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9215720910402104, 6.911199999999999, 6.9112, 168.912956510431, 753714.2263053441, 753714.2263053447, 228212.9370956793], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6037800.0000, 
sim time next is 6038400.0000, 
raw observation next is [27.46666666666667, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9224803937854517, 6.911199999999999, 6.9112, 168.912956510431, 754628.068830808, 754628.0688308086, 228436.4506710492], 
processed observation next is [1.0, 0.9130434782608695, 0.500789889415482, 0.8666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9054638948603068, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20961890800855779, 0.20961890800855795, 0.34094992637470034], 
reward next is 0.6591, 
noisyNet noise sample is [array([0.13853574], dtype=float32), 1.0057614]. 
=============================================
[2019-03-27 06:11:00,098] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 5.60090742e-27 3.02640531e-16 2.42905488e-27
 1.13629505e-23], sum to 1.0000
[2019-03-27 06:11:00,110] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5439
[2019-03-27 06:11:00,114] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9203950235364807, 6.9112, 6.9112, 168.912956510431, 754060.7566500064, 754060.7566500064, 227991.0322269943], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6044400.0000, 
sim time next is 6045000.0000, 
raw observation next is [26.86666666666667, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9194818977457968, 6.911199999999998, 6.9112, 168.912956510431, 753380.7421293092, 753380.7421293105, 227777.3419691352], 
processed observation next is [1.0, 1.0, 0.4723538704581361, 0.9016666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.901807192372923, -1.7763568394002506e-16, 0.0, 0.8294399451523027, 0.20927242836925256, 0.20927242836925292, 0.33996618204348533], 
reward next is 0.6600, 
noisyNet noise sample is [array([2.3721552], dtype=float32), -0.39823163]. 
=============================================
[2019-03-27 06:11:00,122] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.240482]
 [62.196465]
 [62.190712]
 [62.174168]
 [62.163597]], R is [[62.33971024]
 [62.37602615]
 [62.41136932]
 [62.44628906]
 [62.48177338]].
[2019-03-27 06:11:03,070] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.1836907e-01 4.3507366e-13 7.8163093e-01 1.6948691e-17 1.2347666e-11], sum to 1.0000
[2019-03-27 06:11:03,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2394
[2019-03-27 06:11:03,083] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.1, 65.0, 1.0, 2.0, 0.4022318890359536, 1.0, 2.0, 0.4022318890359536, 1.0, 1.0, 0.693727160003058, 6.911200000000001, 6.9112, 170.5573041426782, 1686941.258283254, 1686941.258283254, 353449.9110829813], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6095400.0000, 
sim time next is 6096000.0000, 
raw observation next is [31.1, 65.0, 1.0, 2.0, 0.89616770402979, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.990945622583417, 6.9112, 168.9124831403067, 2149672.36268701, 2093098.231940445, 433555.4342459061], 
processed observation next is [1.0, 0.5652173913043478, 0.6729857819905214, 0.65, 1.0, 1.0, 0.8749008482286625, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007974562258341677, 0.0, 0.8294376206882826, 0.5971312118575027, 0.5814161755390125, 0.6470976630535912], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.59585], dtype=float32), 1.279246]. 
=============================================
[2019-03-27 06:11:03,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[33.552525]
 [33.579266]
 [34.53166 ]
 [33.522373]
 [32.30862 ]], R is [[32.42303848]
 [32.09880829]
 [32.306633  ]
 [32.40536499]
 [32.54932785]].
[2019-03-27 06:11:05,027] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:11:05,029] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:11:05,030] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:11:05,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:11:05,031] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:11:05,031] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:11:05,032] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:11:05,032] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:11:05,033] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:11:05,033] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:11:05,033] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:11:05,042] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run33
[2019-03-27 06:11:05,062] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run33
[2019-03-27 06:11:05,083] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run33
[2019-03-27 06:11:05,084] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run33
[2019-03-27 06:11:05,084] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run33
[2019-03-27 06:11:06,345] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:06,346] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.58333333333334, 57.16666666666666, 1.0, 2.0, 0.824999344637985, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1157982.320957255, 1157982.320957255, 250841.5623339845]
[2019-03-27 06:11:06,348] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:11:06,350] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9997282e-01 2.0912979e-15 2.7225387e-05 4.6790590e-17 2.6550257e-13], sampled 0.8833906443566718
[2019-03-27 06:11:06,351] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1157982.320957255 W.
[2019-03-27 06:11:15,438] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:15,440] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [18.53333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4283731273354082, 6.9112, 6.9112, 168.912956510431, 384851.1732432463, 384851.1732432463, 143427.3692689671]
[2019-03-27 06:11:15,440] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:11:15,443] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.9171959e-29 4.3876382e-21 3.5554285e-28 9.2112250e-26], sampled 0.2796661814939976
[2019-03-27 06:11:16,857] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:16,858] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.36666666666667, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7519325328752091, 6.911200000000001, 6.9112, 168.912956510431, 638996.6403863857, 638996.6403863851, 192381.2727424963]
[2019-03-27 06:11:16,859] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:11:16,862] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.0088596e-28 6.8745010e-21 1.0527647e-27 2.8636035e-25], sampled 0.47314287630485585
[2019-03-27 06:11:17,989] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:17,991] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.9, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6470505862665149, 6.911199999999999, 6.9112, 168.912956510431, 560218.03552078, 560218.0355207807, 173584.0653882628]
[2019-03-27 06:11:17,992] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:11:17,995] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.1431478e-30 5.6478442e-22 1.8753373e-29 6.4830045e-27], sampled 0.5366217189417072
[2019-03-27 06:11:30,581] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:30,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.43047906, 97.73329016666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9434484695631551, 6.9112, 6.9112, 168.912956510431, 821548.0917529445, 821548.0917529445, 234259.4315553264]
[2019-03-27 06:11:30,583] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:11:30,586] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.4046009e-28 1.7438253e-20 8.6572304e-28 2.8219941e-25], sampled 0.13307281048545194
[2019-03-27 06:11:33,181] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:11:33,182] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.7, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8445364480388866, 6.9112, 6.9112, 168.912956510431, 706924.3268756013, 706924.3268756013, 211252.8235209105]
[2019-03-27 06:11:33,184] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:11:33,186] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.000000e+00 3.071092e-28 6.501726e-20 1.403857e-27 6.869873e-25], sampled 0.9725689047921933
[2019-03-27 06:12:51,877] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:12:51,879] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.63333333333334, 75.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.956506092325966, 6.9112, 6.9112, 168.9129565104262, 769641.8033840602, 769641.8033840602, 236026.9014205906]
[2019-03-27 06:12:51,880] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:12:51,884] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.9096458e-20 1.4973883e-08 9.7377010e-22 2.1892787e-17], sampled 0.8802750861859262
[2019-03-27 06:12:57,288] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.057953373]
[2019-03-27 06:12:57,289] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.95, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6175482194840137, 6.9112, 6.9112, 168.912956510431, 537946.0618078574, 537946.0618078574, 168786.0624831893]
[2019-03-27 06:12:57,291] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:12:57,293] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 7.6413784e-28 1.1330553e-19 3.2205293e-27 1.1362165e-24], sampled 0.9742268495915131
[2019-03-27 06:12:59,488] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8017.4048 2939788244.7256 1337.0000
[2019-03-27 06:12:59,802] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7244.3204 3321173833.6985 2135.0000
[2019-03-27 06:12:59,841] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6959.3895 3188281280.6022 2403.0000
[2019-03-27 06:12:59,939] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7856.1836 2991300391.6309 1508.0000
[2019-03-27 06:12:59,942] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7231.2146 3109512831.5562 1946.0000
[2019-03-27 06:13:00,958] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 800000, evaluation results [800000.0, 7244.32039735606, 3321173833.698517, 2135.0, 7231.214590028308, 3109512831.556194, 1946.0, 8017.404769712878, 2939788244.725605, 1337.0, 6959.38946271399, 3188281280.6021976, 2403.0, 7856.18355807177, 2991300391.630918, 1508.0]
[2019-03-27 06:13:01,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.00000000e+00 1.03093505e-26 4.24061910e-16 1.18985801e-26
 3.33765534e-23], sum to 1.0000
[2019-03-27 06:13:01,607] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1789
[2019-03-27 06:13:01,615] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8932401011814125, 6.9112, 6.9112, 168.912956510431, 734846.3587202758, 734846.3587202758, 221768.6542966486], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6121200.0000, 
sim time next is 6121800.0000, 
raw observation next is [27.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.892700084745922, 6.9112, 6.9112, 168.912956510431, 734411.5238320105, 734411.5238320105, 221644.6962856289], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8691464448120999, 0.0, 0.0, 0.8294399451523027, 0.20400320106444736, 0.20400320106444736, 0.33081297953078936], 
reward next is 0.6692, 
noisyNet noise sample is [array([-0.65303266], dtype=float32), -1.7044339]. 
=============================================
[2019-03-27 06:13:05,147] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [2.3244675e-01 3.5845906e-14 7.6755327e-01 1.4163193e-17 1.3591189e-12], sum to 1.0000
[2019-03-27 06:13:05,159] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9459
[2019-03-27 06:13:05,164] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.13333333333333, 72.0, 1.0, 2.0, 0.6082879559949574, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.930669111446949, 6.9112, 168.9127948191013, 1700777.783705364, 1686965.73919134, 366515.1216411538], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6180000.0000, 
sim time next is 6180600.0000, 
raw observation next is [30.21666666666667, 71.5, 1.0, 2.0, 0.6131367930454236, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.938782536716037, 6.9112, 168.912741550901, 1714346.119903547, 1694778.143941884, 367479.4715727912], 
processed observation next is [1.0, 0.5217391304347826, 0.6311216429699843, 0.715, 1.0, 1.0, 0.5338997506571368, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.002758253671603672, 0.0, 0.8294388896026015, 0.47620725552876303, 0.4707717066505233, 0.548476823242972], 
reward next is 0.3136, 
noisyNet noise sample is [array([1.8804398], dtype=float32), 0.9338363]. 
=============================================
[2019-03-27 06:13:10,311] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 9.3755859e-31 4.8806473e-22 1.5096835e-29 5.7602311e-28], sum to 1.0000
[2019-03-27 06:13:10,319] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1389
[2019-03-27 06:13:10,325] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.95, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8557401389220151, 6.9112, 6.9112, 168.912956510431, 709863.3512516905, 709863.3512516905, 213528.213938683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6283800.0000, 
sim time next is 6284400.0000, 
raw observation next is [29.8, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.860024450763473, 6.911199999999999, 6.9112, 168.912956510431, 713061.0371501195, 713061.0371501202, 214464.3678083798], 
processed observation next is [0.0, 0.7391304347826086, 0.6113744075829385, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8292981106871621, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19807251031947765, 0.19807251031947784, 0.3200960713557907], 
reward next is 0.6799, 
noisyNet noise sample is [array([0.4627746], dtype=float32), 0.7014327]. 
=============================================
[2019-03-27 06:13:11,460] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.7329401e-32 1.5342178e-22 1.5324569e-30 5.2920214e-27], sum to 1.0000
[2019-03-27 06:13:11,471] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0132
[2019-03-27 06:13:11,477] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.904604568806502, 6.9112, 6.9112, 168.912956510431, 743605.7875573626, 743605.7875573626, 224379.7088617165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6310200.0000, 
sim time next is 6310800.0000, 
raw observation next is [27.3, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9069054690265407, 6.9112, 6.9112, 168.912956510431, 745227.5040839155, 745227.5040839155, 224906.3131844979], 
processed observation next is [0.0, 0.043478260869565216, 0.4928909952606636, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.886470084178708, 0.0, 0.0, 0.8294399451523027, 0.20700764002330985, 0.20700764002330985, 0.3356810644544745], 
reward next is 0.6643, 
noisyNet noise sample is [array([-1.5264801], dtype=float32), -1.2104456]. 
=============================================
[2019-03-27 06:13:21,843] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4959704e-01 1.6112919e-12 6.5040296e-01 5.4160693e-15 2.5624738e-10], sum to 1.0000
[2019-03-27 06:13:21,852] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9108
[2019-03-27 06:13:21,860] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.6337594378839801, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.964005750984112, 6.9112, 168.9126294881159, 1772055.704378411, 1734593.559724963, 371936.7887402198], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6690600.0000, 
sim time next is 6691200.0000, 
raw observation next is [28.86666666666667, 74.0, 1.0, 2.0, 0.6534175723112797, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.97864055331673, 6.9112, 168.9125122670736, 1809945.492730125, 1762100.968914602, 375844.8405718955], 
processed observation next is [1.0, 0.43478260869565216, 0.567140600315956, 0.74, 1.0, 1.0, 0.58243081001359, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006744055331672971, 0.0, 0.8294377637140423, 0.5027626368694792, 0.4894724913651672, 0.5609624486147694], 
reward next is 0.1018, 
noisyNet noise sample is [array([-1.065052], dtype=float32), 0.9356526]. 
=============================================
[2019-03-27 06:13:23,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.00000000e+00 4.44329217e-27 1.17830025e-17 1.00569779e-27
 2.29805137e-23], sum to 1.0000
[2019-03-27 06:13:23,541] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1977
[2019-03-27 06:13:23,545] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.95, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8101081424989337, 6.911199999999999, 6.9112, 168.912956510431, 677749.9294035789, 677749.9294035796, 203899.9430484816], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6552600.0000, 
sim time next is 6553200.0000, 
raw observation next is [27.9, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8146150040192368, 6.911199999999999, 6.9112, 168.912956510431, 681090.2673966298, 681090.2673966304, 204832.4941419824], 
processed observation next is [1.0, 0.8695652173913043, 0.5213270142180094, 0.7433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7739207366088254, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18919174094350827, 0.18919174094350844, 0.3057201405104215], 
reward next is 0.6943, 
noisyNet noise sample is [array([-0.22317936], dtype=float32), -1.3609995]. 
=============================================
[2019-03-27 06:13:37,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.7089863e-01 6.4064070e-14 2.9101377e-02 4.6486232e-16 1.0876268e-11], sum to 1.0000
[2019-03-27 06:13:37,808] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0645
[2019-03-27 06:13:37,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1977476.592169537 W.
[2019-03-27 06:13:37,823] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.01666666666667, 51.5, 1.0, 2.0, 0.7602216465516588, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.948758694254629, 6.9112, 168.9127319679616, 1977476.592169537, 1950831.197215602, 402270.4557645703], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7041000.0000, 
sim time next is 7041600.0000, 
raw observation next is [31.1, 51.0, 1.0, 2.0, 0.4717923672737382, 1.0, 1.0, 0.4717923672737382, 1.0, 2.0, 0.7862068605842942, 6.9112, 6.9112, 170.5573041426782, 1978943.973460669, 1978943.973460669, 390381.311666842], 
processed observation next is [1.0, 0.5217391304347826, 0.6729857819905214, 0.51, 1.0, 1.0, 0.36360526177558816, 1.0, 0.5, 0.36360526177558816, 1.0, 1.0, 0.7392766592491393, 0.0, 0.0, 0.8375144448122397, 0.5497066592946303, 0.5497066592946303, 0.5826586741296149], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5180447], dtype=float32), -0.79072267]. 
=============================================
[2019-03-27 06:13:45,525] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6859333e-31 2.9219787e-24 7.4263001e-30 2.4257295e-28], sum to 1.0000
[2019-03-27 06:13:45,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2039
[2019-03-27 06:13:45,714] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666666, 52.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.629938208081811, 6.911200000000001, 6.9112, 168.912956510431, 546388.899086117, 546388.8990861165, 170788.9827721922], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6889200.0000, 
sim time next is 6889800.0000, 
raw observation next is [28.53333333333333, 53.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6275052193696151, 6.911199999999999, 6.9112, 168.912956510431, 544047.8425581695, 544047.8425581701, 170402.9017766208], 
processed observation next is [0.0, 0.7391304347826086, 0.5513428120063191, 0.5316666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5457380724019696, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15112440071060265, 0.1511244007106028, 0.254332689218837], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.0685816], dtype=float32), -0.8867]. 
=============================================
[2019-03-27 06:13:49,960] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.6517603e-32 1.0486271e-22 7.9500385e-31 1.6112255e-27], sum to 1.0000
[2019-03-27 06:13:49,968] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7315
[2019-03-27 06:13:49,973] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.1, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7589005693913768, 6.911199999999999, 6.9112, 168.912956510431, 642065.4255987656, 642065.4255987662, 193701.8863109713], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6948000.0000, 
sim time next is 6948600.0000, 
raw observation next is [29.25, 61.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7564558672639127, 6.911199999999999, 6.9112, 168.912956510431, 639732.0855265777, 639732.0855265782, 193222.0287692495], 
processed observation next is [0.0, 0.43478260869565216, 0.5853080568720379, 0.615, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7029949600779422, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17770335709071602, 0.1777033570907162, 0.28839108771529776], 
reward next is 0.7116, 
noisyNet noise sample is [array([-2.3778346], dtype=float32), -1.1694466]. 
=============================================
[2019-03-27 06:13:53,312] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2514297e-27 4.0686846e-16 1.2431460e-27 3.5991735e-23], sum to 1.0000
[2019-03-27 06:13:53,320] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0180
[2019-03-27 06:13:53,328] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.13333333333333, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8038376880520639, 6.9112, 6.9112, 168.912956510431, 672183.7460203867, 672183.7460203867, 202589.0158461419], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7065600.0000, 
sim time next is 7066200.0000, 
raw observation next is [27.01666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8048739607232852, 6.9112, 6.9112, 168.912956510431, 673158.771627048, 673158.771627048, 202806.2775492407], 
processed observation next is [1.0, 0.782608695652174, 0.4794628751974725, 0.7933333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7620414155162013, 0.0, 0.0, 0.8294399451523027, 0.18698854767418002, 0.18698854767418002, 0.30269593664065775], 
reward next is 0.6973, 
noisyNet noise sample is [array([-0.31029585], dtype=float32), -0.35742155]. 
=============================================
[2019-03-27 06:13:55,380] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999905e-01 7.8050255e-20 1.0129519e-06 7.0701546e-22 6.0056410e-18], sum to 1.0000
[2019-03-27 06:13:55,386] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1056
[2019-03-27 06:13:55,390] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.86666666666667, 74.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7702162668316588, 6.911199999999999, 6.9112, 168.912956510431, 643463.0049312024, 643463.004931203, 195768.8252108924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7062000.0000, 
sim time next is 7062600.0000, 
raw observation next is [27.73333333333333, 75.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7813252264026029, 6.911199999999999, 6.9112, 168.912956510431, 652996.3637531929, 652996.3637531936, 197989.6123951835], 
processed observation next is [1.0, 0.7391304347826086, 0.513428120063191, 0.7516666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7333234468324427, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18138787882033136, 0.18138787882033156, 0.2955068841719157], 
reward next is 0.7045, 
noisyNet noise sample is [array([0.89766455], dtype=float32), 0.23783177]. 
=============================================
[2019-03-27 06:13:55,536] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 06:13:55,538] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:13:55,539] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:13:55,540] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:13:55,540] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:13:55,542] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:13:55,543] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:13:55,544] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:13:55,546] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:13:55,547] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:13:55,548] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:13:55,565] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run34
[2019-03-27 06:13:55,585] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run34
[2019-03-27 06:13:55,586] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run34
[2019-03-27 06:13:55,605] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run34
[2019-03-27 06:13:55,624] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run34
[2019-03-27 06:14:24,980] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:14:24,981] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.11964011833333, 91.56287964500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8471151744936836, 6.911200000000001, 6.9112, 168.912956510431, 706358.3454172969, 706358.3454172963, 211745.0448394068]
[2019-03-27 06:14:24,982] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:14:24,986] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.0273089e-31 9.3074189e-23 3.0161265e-30 2.9610436e-28], sampled 0.7715219668794377
[2019-03-27 06:14:28,229] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:14:28,230] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.2, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6815390892071744, 6.911200000000001, 6.9112, 168.912956510431, 584265.9749167567, 584265.974916756, 179466.3483912093]
[2019-03-27 06:14:28,231] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:14:28,234] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.7886951e-29 1.1708025e-20 9.2052797e-28 9.1451227e-26], sampled 0.8318333734438689
[2019-03-27 06:14:39,504] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:14:39,506] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.1, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8954670271258015, 6.9112, 6.9112, 168.912956510431, 742865.5760800624, 742865.5760800624, 222507.4043197435]
[2019-03-27 06:14:39,507] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:14:39,511] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.2845068e-28 7.4402324e-20 1.4474040e-27 2.7086518e-25], sampled 0.8767190316918363
[2019-03-27 06:14:57,456] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:14:57,458] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 73.0, 1.0, 2.0, 0.6152117471952829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564726631, 859727.9848232062, 859727.9848232062, 203614.8669554363]
[2019-03-27 06:14:57,461] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:14:57,466] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.3454474e-21 3.2825850e-11 1.0348345e-21 1.0677953e-18], sampled 0.160966640027578
[2019-03-27 06:15:11,608] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:15:11,610] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.6, 88.0, 1.0, 2.0, 0.8658029850654017, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1210116.371567856, 1210116.371567856, 260708.0426498714]
[2019-03-27 06:15:11,611] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:15:11,614] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.7291133e-01 3.6420078e-13 1.2708867e-01 2.0871150e-15 1.0477136e-11], sampled 0.3891802870836092
[2019-03-27 06:15:11,616] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1210116.371567856 W.
[2019-03-27 06:15:17,508] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:15:17,509] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.48939347333333, 62.49729054333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8764337912826147, 6.9112, 6.9112, 168.912956510431, 726261.223347547, 726261.223347547, 218125.9311173012]
[2019-03-27 06:15:17,510] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:15:17,514] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.4604221e-31 2.5525870e-22 6.0503582e-30 8.4252271e-28], sampled 0.920320756217791
[2019-03-27 06:15:45,514] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:15:45,515] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.4, 81.0, 1.0, 2.0, 0.5566879721400219, 0.0, 2.0, 0.0, 1.0, 1.0, 0.927388775484072, 6.9112, 6.9112, 168.9125882629379, 1556398.049789441, 1556398.049789441, 332271.5293785678]
[2019-03-27 06:15:45,516] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:15:45,518] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.4628809e-18 8.3384988e-09 1.7353122e-19 2.5194323e-16], sampled 0.17181580675577302
[2019-03-27 06:15:45,519] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1556398.049789441 W.
[2019-03-27 06:15:49,728] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02452342], dtype=float32), 0.058471117]
[2019-03-27 06:15:49,729] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.58333333333334, 58.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7089545069762205, 6.9112, 6.9112, 168.912956510431, 618828.9214771679, 618828.9214771679, 184223.5674774485]
[2019-03-27 06:15:49,731] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:15:49,734] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.2738666e-29 9.0882851e-21 9.4106792e-28 7.9345164e-26], sampled 0.22393749002654173
[2019-03-27 06:15:50,083] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7259.7090 3320631269.5043 2126.0000
[2019-03-27 06:15:50,343] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7273.3584 3108287845.6446 1968.0000
[2019-03-27 06:15:50,510] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8020.4943 2939171927.1503 1361.0000
[2019-03-27 06:15:50,538] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7890.6089 2990744961.3209 1530.0000
[2019-03-27 06:15:50,591] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6979.1229 3187243580.5131 2419.0000
[2019-03-27 06:15:51,606] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 825000, evaluation results [825000.0, 7259.70897421524, 3320631269.5043116, 2126.0, 7273.358433141784, 3108287845.644639, 1968.0, 8020.494321094364, 2939171927.1502833, 1361.0, 6979.122877761422, 3187243580.513145, 2419.0, 7890.608872137947, 2990744961.3208795, 1530.0]
[2019-03-27 06:16:11,634] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.99103701e-01 1.53489248e-14 1.00896314e-01 2.67196702e-16
 5.52924286e-12], sum to 1.0000
[2019-03-27 06:16:11,641] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6725
[2019-03-27 06:16:11,649] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1008690.988796625 W.
[2019-03-27 06:16:11,657] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.16666666666667, 92.83333333333333, 1.0, 2.0, 0.320661210113743, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5770081663421005, 6.911200000000001, 6.9112, 168.912956510431, 1008690.988796625, 1008690.988796624, 238676.9239549107], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [21.13333333333333, 92.66666666666667, 1.0, 2.0, 0.4587372066358965, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 724441.5512895741, 724441.5512895734, 187013.2234039902], 
processed observation next is [1.0, 0.5217391304347826, 0.20063191153238533, 0.9266666666666667, 1.0, 1.0, 0.34787615257336935, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20123376424710393, 0.20123376424710374, 0.2791242140358063], 
reward next is 0.7209, 
noisyNet noise sample is [array([-0.41627482], dtype=float32), -0.092335716]. 
=============================================
[2019-03-27 06:16:12,749] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.2205628e-19 3.0846433e-08 3.4158595e-20 2.7545526e-17], sum to 1.0000
[2019-03-27 06:16:12,756] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2238
[2019-03-27 06:16:12,762] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.46666666666667, 88.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5930557169482138, 6.911200000000001, 6.9112, 168.912956510431, 524529.8857305017, 524529.8857305011, 164779.6309630809], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7405800.0000, 
sim time next is 7406400.0000, 
raw observation next is [20.53333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5166079480857488, 6.9112, 6.9112, 168.912956510431, 457425.8604899528, 457425.8604899528, 154103.2098694252], 
processed observation next is [1.0, 0.7391304347826086, 0.17219589257503945, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41049749766554733, 0.0, 0.0, 0.8294399451523027, 0.12706273902498688, 0.12706273902498688, 0.23000479084988834], 
reward next is 0.7700, 
noisyNet noise sample is [array([-0.22595774], dtype=float32), -0.19141747]. 
=============================================
[2019-03-27 06:16:12,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.9990333e-24 1.4235480e-13 5.3387870e-24 1.2110446e-21], sum to 1.0000
[2019-03-27 06:16:12,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4915
[2019-03-27 06:16:12,935] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.66666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5153466856437233, 6.9112, 6.9112, 168.912956510431, 456471.5194258331, 456471.5194258331, 153933.3606558361], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7407600.0000, 
sim time next is 7408200.0000, 
raw observation next is [20.73333333333333, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147698094329256, 6.911200000000001, 6.9112, 168.912956510431, 455956.5888777226, 455956.588877722, 153859.3659421838], 
processed observation next is [1.0, 0.7391304347826086, 0.18167456556082143, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4082558651621044, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12665460802158962, 0.12665460802158943, 0.22964084468982657], 
reward next is 0.7704, 
noisyNet noise sample is [array([0.35031033], dtype=float32), -0.52401924]. 
=============================================
[2019-03-27 06:16:13,692] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.6137959e-31 2.0803053e-20 5.8236356e-30 2.6757537e-28], sum to 1.0000
[2019-03-27 06:16:13,703] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6191
[2019-03-27 06:16:13,709] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.05, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5742873028527412, 6.9112, 6.9112, 168.912956510431, 502615.6106929396, 502615.6106929396, 162201.57568515], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7428600.0000, 
sim time next is 7429200.0000, 
raw observation next is [21.06666666666667, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5733018417144489, 6.911200000000001, 6.9112, 168.912956510431, 501764.1874958618, 501764.1874958611, 162058.4989274965], 
processed observation next is [1.0, 1.0, 0.19747235387045833, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47963639233469374, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13937894097107273, 0.13937894097107253, 0.24187835660820373], 
reward next is 0.7581, 
noisyNet noise sample is [array([1.3544846], dtype=float32), -1.260394]. 
=============================================
[2019-03-27 06:16:17,531] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.6753067e-01 7.2598931e-15 3.2469284e-02 6.3377910e-17 8.3565446e-12], sum to 1.0000
[2019-03-27 06:16:17,541] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3942
[2019-03-27 06:16:17,550] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2053448.628968656 W.
[2019-03-27 06:16:17,554] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.2, 80.33333333333334, 1.0, 2.0, 0.4895377265843541, 1.0, 2.0, 0.4895377265843541, 1.0, 2.0, 0.8441976204970405, 6.911199999999999, 6.9112, 170.5573041426782, 2053448.628968656, 2053448.628968656, 406932.7840446768], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7720800.0000, 
sim time next is 7721400.0000, 
raw observation next is [28.4, 79.16666666666666, 1.0, 2.0, 0.4881583222618682, 1.0, 2.0, 0.4881583222618682, 1.0, 2.0, 0.8417140383447052, 6.9112, 6.9112, 170.5573041426782, 2047656.954759425, 2047656.954759425, 405987.857483722], 
processed observation next is [1.0, 0.34782608695652173, 0.5450236966824644, 0.7916666666666665, 1.0, 1.0, 0.3833232798335762, 1.0, 1.0, 0.3833232798335762, 1.0, 1.0, 0.8069683394447622, 0.0, 0.0, 0.8375144448122397, 0.5687935985442847, 0.5687935985442847, 0.6059520260951075], 
reward next is 0.3940, 
noisyNet noise sample is [array([1.9274487], dtype=float32), 1.6834273]. 
=============================================
[2019-03-27 06:16:22,503] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.8951918e-30 1.3563263e-21 9.3868327e-29 3.4621029e-27], sum to 1.0000
[2019-03-27 06:16:22,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1151
[2019-03-27 06:16:22,521] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666667, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7157484444769577, 6.9112, 6.9112, 168.912956510431, 609221.5057515084, 609221.5057515084, 185571.6830044257], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7567800.0000, 
sim time next is 7568400.0000, 
raw observation next is [29.33333333333334, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7257822470316841, 6.911199999999999, 6.9112, 168.912956510431, 616395.5155018282, 616395.5155018289, 187415.1815936771], 
processed observation next is [0.0, 0.6086956521739131, 0.5892575039494474, 0.6, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6655881061362002, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1712209765282856, 0.1712209765282858, 0.27972415163235387], 
reward next is 0.7203, 
noisyNet noise sample is [array([1.4884675], dtype=float32), -1.480965]. 
=============================================
[2019-03-27 06:16:24,779] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.7171826e-24 1.3064857e-09 1.3773042e-25 2.9530564e-21], sum to 1.0000
[2019-03-27 06:16:24,787] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7244
[2019-03-27 06:16:24,793] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.880137378218324, 6.9112, 6.9112, 168.912956510431, 721648.6830076418, 721648.6830076418, 218676.7928214549], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7840800.0000, 
sim time next is 7841400.0000, 
raw observation next is [28.86666666666667, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8915441249260209, 6.911200000000001, 6.9112, 168.912956510431, 730748.9337854412, 730748.9337854405, 221268.4073565801], 
processed observation next is [1.0, 0.782608695652174, 0.567140600315956, 0.77, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8677367377146594, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20298581494040033, 0.20298581494040013, 0.3302513542635524], 
reward next is 0.6697, 
noisyNet noise sample is [array([-0.27032328], dtype=float32), 0.09857327]. 
=============================================
[2019-03-27 06:16:28,262] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:28,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:28,290] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run5
[2019-03-27 06:16:30,445] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.5845053e-25 4.2353772e-14 5.3299352e-24 5.4026309e-22], sum to 1.0000
[2019-03-27 06:16:30,452] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3880
[2019-03-27 06:16:30,456] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.008886813958847, 6.911200000000001, 6.9112, 168.9128680283474, 836942.3655104566, 836942.365510456, 250478.6757830701], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7714800.0000, 
sim time next is 7715400.0000, 
raw observation next is [26.56666666666667, 87.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.000853148706212, 6.911200000000001, 6.9112, 168.9129547966209, 829297.4749522518, 829297.4749522511, 248347.489837927], 
processed observation next is [1.0, 0.30434782608695654, 0.45813586097946307, 0.8750000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.001040425251478, 8.881784197001253e-17, 0.0, 0.8294399367367106, 0.23036040970895882, 0.23036040970895863, 0.37066789528048805], 
reward next is 0.6293, 
noisyNet noise sample is [array([-0.39191422], dtype=float32), -0.021148426]. 
=============================================
[2019-03-27 06:16:31,564] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:31,565] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:31,598] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run5
[2019-03-27 06:16:32,889] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [6.2507214e-03 1.3882792e-15 9.9374926e-01 9.1318870e-18 3.6326153e-14], sum to 1.0000
[2019-03-27 06:16:32,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5073
[2019-03-27 06:16:32,904] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.65, 69.0, 1.0, 2.0, 0.9482659851742281, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.996308274774373, 6.9112, 168.9124502575168, 2222592.988546584, 2162214.430183401, 448159.5272435129], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7824600.0000, 
sim time next is 7825200.0000, 
raw observation next is [30.53333333333333, 68.66666666666666, 1.0, 2.0, 0.9027311595611591, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.991875685463581, 6.9112, 168.9124070670448, 2158859.37786328, 2101625.456124844, 435343.1208284897], 
processed observation next is [1.0, 0.5652173913043478, 0.646129541864139, 0.6866666666666665, 1.0, 1.0, 0.8828086259773001, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008067568546358128, 0.0, 0.8294372471337401, 0.5996831605175778, 0.5837848489235677, 0.6497658519828204], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8229671], dtype=float32), -0.15905578]. 
=============================================
[2019-03-27 06:16:36,017] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.5111035e-03 4.2822784e-15 9.9248886e-01 1.0128812e-18 1.5832560e-13], sum to 1.0000
[2019-03-27 06:16:36,029] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4035
[2019-03-27 06:16:36,036] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.41666666666666, 68.33333333333334, 1.0, 2.0, 0.9652197366405643, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987509977994094, 6.9112, 168.9124422361905, 2246321.685058568, 2192184.925108684, 453470.5372987296], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7827000.0000, 
sim time next is 7827600.0000, 
raw observation next is [30.53333333333333, 68.66666666666667, 1.0, 2.0, 0.9030843267079021, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.9904591236808, 6.9112, 168.9124230141737, 2159353.715795281, 2103124.743162284, 435492.9506549103], 
processed observation next is [1.0, 0.6086956521739131, 0.646129541864139, 0.6866666666666668, 1.0, 1.0, 0.8832341285637374, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007925912368080023, 0.0, 0.8294373254414437, 0.5998204766098002, 0.584201317545079, 0.6499894785894184], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.73622626], dtype=float32), -0.29648766]. 
=============================================
[2019-03-27 06:16:41,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:41,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:41,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run5
[2019-03-27 06:16:42,456] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:42,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:42,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run5
[2019-03-27 06:16:42,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:42,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:42,920] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run5
[2019-03-27 06:16:43,007] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,008] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,022] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run5
[2019-03-27 06:16:43,045] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,053] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run5
[2019-03-27 06:16:43,201] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,202] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run5
[2019-03-27 06:16:43,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,337] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,343] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run5
[2019-03-27 06:16:43,379] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,380] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run5
[2019-03-27 06:16:43,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,457] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,459] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run5
[2019-03-27 06:16:43,509] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,509] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,512] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run5
[2019-03-27 06:16:43,531] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,532] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,533] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run5
[2019-03-27 06:16:43,568] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,568] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,569] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run5
[2019-03-27 06:16:43,607] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,608] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:16:43,610] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:43,612] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run5
[2019-03-27 06:16:43,635] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run5
[2019-03-27 06:16:44,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.7947162e-27 4.8966201e-18 9.6830396e-27 2.3675727e-24], sum to 1.0000
[2019-03-27 06:16:44,386] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9818
[2019-03-27 06:16:44,391] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.76666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8261919058088814, 6.911200000000001, 6.9112, 168.912956510431, 730803.3037629497, 730803.3037629491, 206982.0737349336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 393600.0000, 
sim time next is 394200.0000, 
raw observation next is [22.8, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8741410030989409, 6.9112, 6.9112, 168.912956510431, 773024.1119324766, 773024.1119324766, 217487.1546287639], 
processed observation next is [1.0, 0.5652173913043478, 0.2796208530805688, 0.73, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8465134184133426, 0.0, 0.0, 0.8294399451523027, 0.21472891998124352, 0.21472891998124352, 0.324607693475767], 
reward next is 0.6754, 
noisyNet noise sample is [array([1.5268507], dtype=float32), 1.3819269]. 
=============================================
[2019-03-27 06:16:44,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.3686495e-30 1.2092534e-21 6.5878540e-29 1.2560934e-26], sum to 1.0000
[2019-03-27 06:16:44,435] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6492
[2019-03-27 06:16:44,438] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.8, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5506254992993291, 6.9112, 6.9112, 168.912956510431, 483240.9047978253, 483240.9047978253, 158808.8195557017], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 318600.0000, 
sim time next is 319200.0000, 
raw observation next is [22.73333333333333, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5486962894910635, 6.911199999999999, 6.9112, 168.912956510431, 481738.2384693777, 481738.2384693783, 158536.3214382841], 
processed observation next is [0.0, 0.6956521739130435, 0.27646129541864134, 0.7866666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4496296213305653, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13381617735260493, 0.1338161773526051, 0.23662137528102103], 
reward next is 0.7634, 
noisyNet noise sample is [array([-0.49524033], dtype=float32), 0.4346848]. 
=============================================
[2019-03-27 06:16:44,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [0.11447182 0.04006681 0.8175331  0.01038557 0.01754264], sum to 1.0000
[2019-03-27 06:16:44,902] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6324
[2019-03-27 06:16:44,904] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [20.9, 85.66666666666667, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2690644981247712, 6.911199999999999, 6.9112, 168.912956510431, 475247.4919162323, 475247.4919162329, 187063.7858868575], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2400.0000, 
sim time next is 3000.0000, 
raw observation next is [20.55, 84.83333333333333, 1.0, 2.0, 0.17, 0.0, 2.0, 0.0, 1.0, 2.0, 0.2587586707417515, 6.911199999999999, 6.9112, 168.912956510431, 458816.9973071057, 458816.9973071063, 184673.2993460918], 
processed observation next is [1.0, 0.0, 0.17298578199052142, 0.8483333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.09604715944116039, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12744916591864047, 0.12744916591864064, 0.27563179006879374], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98337], dtype=float32), 0.07040338]. 
=============================================
[2019-03-27 06:16:44,910] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[ 2.1740031 ]
 [ 0.72858226]
 [-0.32543305]
 [-0.34006396]
 [ 0.029186  ]], R is [[3.79452825]
 [3.75658298]
 [3.71901727]
 [3.68182707]
 [3.6450088 ]].
[2019-03-27 06:16:45,060] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.24025721e-26 1.24081248e-16 1.07373815e-26
 2.78471706e-24], sum to 1.0000
[2019-03-27 06:16:45,065] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6430
[2019-03-27 06:16:45,069] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.459854616792879, 6.911200000000001, 6.9112, 168.912956510431, 410709.9933251419, 410709.9933251413, 147024.5529259463], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 418200.0000, 
sim time next is 418800.0000, 
raw observation next is [20.4, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.45865363514095, 6.9112, 6.9112, 168.912956510431, 409706.6606145651, 409706.6606145651, 146884.2407447576], 
processed observation next is [1.0, 0.8695652173913043, 0.16587677725118483, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3398215062694512, 0.0, 0.0, 0.8294399451523027, 0.11380740572626807, 0.11380740572626807, 0.2192302100668024], 
reward next is 0.7808, 
noisyNet noise sample is [array([-1.6983947], dtype=float32), -1.169972]. 
=============================================
[2019-03-27 06:16:45,684] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:16:45,685] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:16:45,687] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:16:45,688] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:45,689] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:45,690] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:16:45,691] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:45,691] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:16:45,691] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:16:45,692] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:45,692] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:16:45,713] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run35
[2019-03-27 06:16:45,733] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run35
[2019-03-27 06:16:45,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run35
[2019-03-27 06:16:45,771] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run35
[2019-03-27 06:16:45,791] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run35
[2019-03-27 06:17:00,306] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:17:00,379] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.0, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.50409334198035, 6.9112, 6.9112, 168.912956510431, 445940.5700648647, 445940.5700648647, 152527.4554756952]
[2019-03-27 06:17:00,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:17:00,386] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.6314380e-30 1.7002930e-21 1.1525935e-28 9.0331630e-27], sampled 0.22475823086915525
[2019-03-27 06:17:44,656] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:17:44,657] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.6, 75.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.982258180317657, 6.9112, 168.9123989476672, 879231.5383528746, 828820.5860031672, 254812.0885714529]
[2019-03-27 06:17:44,658] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:17:44,661] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 7.445693e-25 7.021993e-15 9.547448e-25 4.311315e-22], sampled 0.39125600508037783
[2019-03-27 06:17:44,662] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 879231.5383528746 W.
[2019-03-27 06:17:59,616] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:17:59,617] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.9, 78.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.019044203683969, 6.9112, 168.9121992222853, 905338.8158169305, 828830.7690228621, 254812.0073923275]
[2019-03-27 06:17:59,620] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:17:59,622] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.9644161e-21 8.3242632e-12 4.6097616e-21 8.0682628e-19], sampled 0.5352992982734642
[2019-03-27 06:17:59,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 905338.8158169305 W.
[2019-03-27 06:18:12,710] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:18:12,711] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.46666666666667, 91.33333333333334, 1.0, 2.0, 0.8731320497970261, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1220365.952998864, 1220365.952998864, 262656.0506189485]
[2019-03-27 06:18:12,714] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:18:12,717] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.7140551e-01 4.0122138e-14 2.8594548e-02 4.1169571e-16 1.1145502e-12], sampled 0.5600423153210966
[2019-03-27 06:18:12,718] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1220365.952998864 W.
[2019-03-27 06:18:22,807] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:18:22,808] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.0, 91.0, 1.0, 2.0, 0.5857708161353573, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9767097629430562, 6.911200000000001, 6.9112, 168.9129565104284, 1637771.109177414, 1637771.109177413, 349558.3215401316]
[2019-03-27 06:18:22,809] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:18:22,812] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.4006219e-20 6.3711048e-10 4.6523719e-21 6.5924665e-18], sampled 0.9987525880431177
[2019-03-27 06:18:22,813] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1637771.109177414 W.
[2019-03-27 06:18:30,078] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060288772]
[2019-03-27 06:18:30,080] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.53333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6467153476322478, 6.9112, 6.9112, 168.912956510431, 558996.2606867781, 558996.2606867781, 173538.4964516462]
[2019-03-27 06:18:30,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:18:30,085] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.0189983e-31 2.8056079e-22 9.6403815e-30 6.5999568e-28], sampled 0.4508247227569273
[2019-03-27 06:18:40,068] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8035.2165 2938436803.2682 1374.0000
[2019-03-27 06:18:40,289] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7263.2362 3320631283.0344 2140.0000
[2019-03-27 06:18:40,316] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7299.4328 3107040294.5101 1981.0000
[2019-03-27 06:18:40,372] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7896.2059 2990146134.0602 1548.0000
[2019-03-27 06:18:40,437] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7002.3268 3186687814.3917 2441.0000
[2019-03-27 06:18:41,454] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 850000, evaluation results [850000.0, 7263.236185084752, 3320631283.034374, 2140.0, 7299.432832786869, 3107040294.510083, 1981.0, 8035.216544571225, 2938436803.268206, 1374.0, 7002.32681144364, 3186687814.391731, 2441.0, 7896.2058595250055, 2990146134.0601616, 1548.0]
[2019-03-27 06:18:48,835] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9868625e-01 3.8199365e-16 1.3137882e-03 6.7117902e-18 3.7973625e-14], sum to 1.0000
[2019-03-27 06:18:48,845] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4576
[2019-03-27 06:18:48,858] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1217715.42652974 W.
[2019-03-27 06:18:48,863] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.4160230925892848, 1.0, 2.0, 0.4160230925892848, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1217715.42652974, 1217715.42652974, 282768.0890202417], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 135600.0000, 
sim time next is 136200.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.4188278810479273, 1.0, 2.0, 0.4188278810479273, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1225981.092539269, 1225981.092539269, 283545.0899427224], 
processed observation next is [1.0, 0.5652173913043478, 0.2796208530805688, 0.96, 1.0, 1.0, 0.2997926277685871, 1.0, 1.0, 0.2997926277685871, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.34055030348313026, 0.34055030348313026, 0.4232016267801827], 
reward next is 0.5768, 
noisyNet noise sample is [array([-0.3915433], dtype=float32), 0.0762654]. 
=============================================
[2019-03-27 06:18:49,898] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9922562e-01 3.3804254e-16 7.7436573e-04 3.0502426e-18 3.6229628e-15], sum to 1.0000
[2019-03-27 06:18:49,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-27 06:18:49,917] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1007644.909499362 W.
[2019-03-27 06:18:49,924] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.56666666666667, 62.66666666666667, 1.0, 2.0, 0.309794840974541, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5677619355493272, 6.9112, 6.9112, 168.912956510431, 1007644.909499362, 1007644.909499362, 236792.0355209377], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 577200.0000, 
sim time next is 577800.0000, 
raw observation next is [23.55, 63.0, 1.0, 2.0, 0.3081525078614941, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5649673484500415, 6.911199999999999, 6.9112, 168.912956510431, 1003097.684034218, 1003097.684034219, 236207.6034025863], 
processed observation next is [1.0, 0.6956521739130435, 0.3151658767772513, 0.63, 1.0, 1.0, 0.16644880465240255, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46947237615858717, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27863824556506056, 0.27863824556506084, 0.3525486617949049], 
reward next is 0.6475, 
noisyNet noise sample is [array([0.24776858], dtype=float32), -0.1681142]. 
=============================================
[2019-03-27 06:18:54,077] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.0276460e-31 6.8058991e-22 6.2703885e-30 5.5840297e-28], sum to 1.0000
[2019-03-27 06:18:54,087] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0075
[2019-03-27 06:18:54,091] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5689632260932713, 6.9112, 6.9112, 168.912956510431, 498201.1455460843, 498201.1455460843, 161426.8592223206], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 226200.0000, 
sim time next is 226800.0000, 
raw observation next is [22.0, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5680481939214552, 6.9112, 6.9112, 168.912956510431, 497559.3291075045, 497559.3291075045, 161291.3614765132], 
processed observation next is [0.0, 0.6521739130434783, 0.2417061611374408, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47322950478226244, 0.0, 0.0, 0.8294399451523027, 0.13821092475208457, 0.13821092475208457, 0.24073337533807943], 
reward next is 0.7593, 
noisyNet noise sample is [array([2.5924404], dtype=float32), -0.77040696]. 
=============================================
[2019-03-27 06:19:02,260] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 4.0832580e-29 1.9241607e-18 1.1697224e-27 1.5226536e-25], sum to 1.0000
[2019-03-27 06:19:02,267] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5167
[2019-03-27 06:19:02,275] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.11666666666667, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4704006575383995, 6.911200000000001, 6.9112, 168.912956510431, 417798.8141201269, 417798.8141201264, 148367.8155434056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 359400.0000, 
sim time next is 360000.0000, 
raw observation next is [20.1, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4705929870582792, 6.9112, 6.9112, 168.912956510431, 417957.3153252194, 417957.3153252194, 148390.8395902668], 
processed observation next is [1.0, 0.17391304347826086, 0.15165876777251197, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3543816915344868, 0.0, 0.0, 0.8294399451523027, 0.11609925425700539, 0.11609925425700539, 0.22147886506009973], 
reward next is 0.7785, 
noisyNet noise sample is [array([1.1782746], dtype=float32), 0.14361303]. 
=============================================
[2019-03-27 06:19:02,291] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[74.5546  ]
 [74.747795]
 [74.61366 ]
 [74.14648 ]
 [74.35759 ]], R is [[74.72856903]
 [74.75984192]
 [74.79087067]
 [74.82167816]
 [74.85193634]].
[2019-03-27 06:19:02,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.1607863e-29 3.5853988e-17 6.3097013e-27 5.1074380e-25], sum to 1.0000
[2019-03-27 06:19:02,926] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0233
[2019-03-27 06:19:02,933] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5541139272101568, 6.911199999999999, 6.9112, 168.912956510431, 492901.9234781688, 492901.9234781694, 159015.9151317158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 375600.0000, 
sim time next is 376200.0000, 
raw observation next is [21.25, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.608763056378888, 6.9112, 6.9112, 168.912956510431, 541376.6389771566, 541376.6389771566, 167012.2974316375], 
processed observation next is [1.0, 0.34782608695652173, 0.20616113744075834, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5228817760718145, 0.0, 0.0, 0.8294399451523027, 0.15038239971587683, 0.15038239971587683, 0.24927208571886195], 
reward next is 0.7507, 
noisyNet noise sample is [array([1.0543157], dtype=float32), 0.054986034]. 
=============================================
[2019-03-27 06:19:10,889] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.5379431e-32 1.8863521e-20 3.6199957e-29 2.1848626e-27], sum to 1.0000
[2019-03-27 06:19:10,899] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4465
[2019-03-27 06:19:10,903] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4398943920954025, 6.9112, 6.9112, 168.912956510431, 394586.0703036775, 394586.0703036775, 144697.3135540216], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 509400.0000, 
sim time next is 510000.0000, 
raw observation next is [19.53333333333333, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4387175992452307, 6.9112, 6.9112, 168.912956510431, 393541.1061144191, 393541.1061144191, 144570.0111877521], 
processed observation next is [1.0, 0.9130434782608695, 0.12480252764612951, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3155092673722325, 0.0, 0.0, 0.8294399451523027, 0.10931697392067198, 0.10931697392067198, 0.21577613610112253], 
reward next is 0.7842, 
noisyNet noise sample is [array([2.4156704], dtype=float32), -0.36199972]. 
=============================================
[2019-03-27 06:19:10,918] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[83.155014]
 [83.324844]
 [83.35007 ]
 [83.466095]
 [83.42355 ]], R is [[83.35836029]
 [83.308815  ]
 [83.25961304]
 [83.21083832]
 [83.16240692]].
[2019-03-27 06:19:18,156] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1404407e-23 3.4225012e-11 8.1305956e-23 4.3406438e-20], sum to 1.0000
[2019-03-27 06:19:18,165] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0079
[2019-03-27 06:19:18,172] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 903509.2197638132 W.
[2019-03-27 06:19:18,180] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [21.98333333333333, 93.83333333333334, 1.0, 2.0, 0.2950731206760031, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5222303823158085, 6.9112, 6.9112, 168.9129565084176, 903509.2197638132, 903509.2197638132, 227147.8511834493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 985800.0000, 
sim time next is 986400.0000, 
raw observation next is [22.0, 94.0, 1.0, 2.0, 0.1940770981897172, 1.0, 1.0, 0.1940770981897172, 1.0, 2.0, 0.341322807220511, 6.9112, 6.9112, 170.5573041426782, 882648.6323134067, 882648.6323134067, 276399.1011849671], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.94, 1.0, 1.0, 0.02900855203580383, 1.0, 0.5, 0.02900855203580383, 1.0, 1.0, 0.19673513075672072, 0.0, 0.0, 0.8375144448122397, 0.24518017564261296, 0.24518017564261296, 0.41253597191786134], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5140857], dtype=float32), -0.3136176]. 
=============================================
[2019-03-27 06:19:23,210] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.0067207e-24 1.1271066e-11 5.8552625e-24 9.4315533e-22], sum to 1.0000
[2019-03-27 06:19:23,219] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1613
[2019-03-27 06:19:23,230] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333333, 52.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7408862995348517, 6.911200000000001, 6.9112, 168.912956510431, 658645.1152586085, 658645.1152586079, 189656.615829261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 737400.0000, 
sim time next is 738000.0000, 
raw observation next is [25.6, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7552995647524273, 6.9112, 6.9112, 168.912956510431, 671624.6867285226, 671624.6867285226, 192398.8509627027], 
processed observation next is [1.0, 0.5652173913043478, 0.4123222748815167, 0.52, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7015848350639357, 0.0, 0.0, 0.8294399451523027, 0.18656241298014517, 0.18656241298014517, 0.2871624641234369], 
reward next is 0.7128, 
noisyNet noise sample is [array([0.7918868], dtype=float32), -0.8617195]. 
=============================================
[2019-03-27 06:19:23,240] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.73121 ]
 [69.70522 ]
 [67.676674]
 [63.80775 ]
 [58.370087]], R is [[72.69249725]
 [72.68251038]
 [72.68457031]
 [72.71328735]
 [72.72906494]].
[2019-03-27 06:19:28,341] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.8222777e-30 7.2805570e-21 3.3648127e-28 2.3373465e-26], sum to 1.0000
[2019-03-27 06:19:28,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6894
[2019-03-27 06:19:28,360] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.01666666666667, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5276731002560157, 6.9112, 6.9112, 168.912956510431, 464791.6358541474, 464791.6358541474, 155645.100150721], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 813000.0000, 
sim time next is 813600.0000, 
raw observation next is [24.2, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292231497389421, 6.9112, 6.9112, 168.912956510431, 466062.1251034748, 466062.1251034748, 155853.7274504398], 
processed observation next is [0.0, 0.43478260869565216, 0.3459715639810427, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42588188992553916, 0.0, 0.0, 0.8294399451523027, 0.12946170141763189, 0.12946170141763189, 0.23261750365737283], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.22321859], dtype=float32), -1.0718452]. 
=============================================
[2019-03-27 06:19:30,433] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 8.4584107e-32 1.1052339e-20 1.5888847e-29 2.3606880e-27], sum to 1.0000
[2019-03-27 06:19:30,442] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8579
[2019-03-27 06:19:30,450] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.08333333333334, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5316432054656318, 6.911200000000001, 6.9112, 168.912956510431, 468052.1249192206, 468052.12491922, 156180.4459538265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 871800.0000, 
sim time next is 872400.0000, 
raw observation next is [21.06666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5304155560404263, 6.9112, 6.9112, 168.912956510431, 467054.6373133096, 467054.6373133096, 156014.0898162569], 
processed observation next is [0.0, 0.08695652173913043, 0.19747235387045833, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4273360439517394, 0.0, 0.0, 0.8294399451523027, 0.12973739925369712, 0.12973739925369712, 0.2328568504720252], 
reward next is 0.7671, 
noisyNet noise sample is [array([-0.7069088], dtype=float32), -0.35487714]. 
=============================================
[2019-03-27 06:19:31,819] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 4.303511e-29 6.665878e-18 9.617145e-27 5.677881e-26], sum to 1.0000
[2019-03-27 06:19:31,828] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2642
[2019-03-27 06:19:31,833] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5066104375715913, 6.911199999999999, 6.9112, 168.912956510431, 448091.5260082611, 448091.5260082617, 152847.8840850369], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 882000.0000, 
sim time next is 882600.0000, 
raw observation next is [20.9, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5070686914435583, 6.9112, 6.9112, 168.912956510431, 448518.5441800884, 448518.5441800884, 152904.9309879438], 
processed observation next is [0.0, 0.21739130434782608, 0.1895734597156398, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.39886425785799784, 0.0, 0.0, 0.8294399451523027, 0.12458848449446899, 0.12458848449446899, 0.22821631490737881], 
reward next is 0.7718, 
noisyNet noise sample is [array([0.36627248], dtype=float32), 0.039011676]. 
=============================================
[2019-03-27 06:19:34,644] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.5636378e-32 1.2078111e-20 1.5282769e-30 3.6547954e-29], sum to 1.0000
[2019-03-27 06:19:34,654] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1575
[2019-03-27 06:19:34,657] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.43333333333334, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5821089324096745, 6.9112, 6.9112, 168.912956510431, 507438.459516309, 507438.459516309, 163390.3066526645], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 930000.0000, 
sim time next is 930600.0000, 
raw observation next is [23.35, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5844742089806754, 6.9112, 6.9112, 168.912956510431, 509438.0009322782, 509438.0009322782, 163740.5875462918], 
processed observation next is [0.0, 0.782608695652174, 0.3056872037914693, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4932612304642382, 0.0, 0.0, 0.8294399451523027, 0.14151055581452174, 0.14151055581452174, 0.2443889366362564], 
reward next is 0.7556, 
noisyNet noise sample is [array([0.1711707], dtype=float32), 0.19125901]. 
=============================================
[2019-03-27 06:19:35,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0682380e-28 3.2613405e-19 7.4784702e-29 6.2409060e-26], sum to 1.0000
[2019-03-27 06:19:35,556] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8158
[2019-03-27 06:19:35,563] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6079436548496113, 6.9112, 6.9112, 168.912956510431, 528265.8485009397, 528265.8485009397, 167315.1311465393], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 951000.0000, 
sim time next is 951600.0000, 
raw observation next is [21.8, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6065625964609173, 6.911200000000001, 6.9112, 168.912956510431, 526970.7987906242, 526970.7987906237, 167103.782370183], 
processed observation next is [1.0, 0.0, 0.23222748815165886, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5201982883669722, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14638077744184008, 0.14638077744183992, 0.24940863040325822], 
reward next is 0.7506, 
noisyNet noise sample is [array([-0.32860103], dtype=float32), -1.1121804]. 
=============================================
[2019-03-27 06:19:35,814] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-27 06:19:35,815] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:19:35,816] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:19:35,817] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:19:35,818] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:19:35,819] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:19:35,817] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:19:35,822] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:19:35,823] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:19:35,821] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:19:35,827] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:19:35,849] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run36
[2019-03-27 06:19:35,850] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run36
[2019-03-27 06:19:35,889] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run36
[2019-03-27 06:19:35,889] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run36
[2019-03-27 06:19:35,890] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run36
[2019-03-27 06:19:41,708] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:19:41,709] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [19.9, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4536360615471441, 6.911199999999999, 6.9112, 168.912956510431, 408036.809805499, 408036.8098054996, 146109.8825157093]
[2019-03-27 06:19:41,711] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:19:41,713] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.8177640e-29 2.0699207e-19 5.0780754e-28 5.7943528e-26], sampled 0.7602817907384093
[2019-03-27 06:19:59,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:19:59,035] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.58333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.54835120119339, 6.9112, 168.9097871286073, 1317675.861734228, 865667.3519325174, 256409.085231308]
[2019-03-27 06:19:59,036] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:19:59,038] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.2536263e-29 1.8015721e-18 1.3444992e-28 4.0741621e-26], sampled 0.6481369283636107
[2019-03-27 06:19:59,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1317675.861734228 W.
[2019-03-27 06:20:19,068] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:20:19,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6815330874777292, 6.911200000000001, 6.9112, 168.912956510431, 584371.8003753352, 584371.8003753345, 179465.2739098473]
[2019-03-27 06:20:19,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:20:19,073] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.3034683e-29 1.3340582e-18 3.2996808e-28 6.3881981e-26], sampled 0.701461229153125
[2019-03-27 06:20:24,345] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:20:24,346] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.60175835, 68.89418922333334, 1.0, 2.0, 0.7500883592224259, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005978411164469, 6.9112, 168.9123160208803, 1945222.454788632, 1877983.642846639, 395876.6536639043]
[2019-03-27 06:20:24,347] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:20:24,349] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9423873e-01 1.9031106e-18 5.7612048e-03 9.6995336e-21 1.9379625e-16], sampled 0.5572502655423076
[2019-03-27 06:20:24,352] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1945222.454788632 W.
[2019-03-27 06:20:28,274] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:20:28,275] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 66.0, 1.0, 2.0, 0.8786334346240435, 1.0, 1.0, 0.8786334346240435, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2457473.730197933, 2457473.730197933, 459964.5743312543]
[2019-03-27 06:20:28,279] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:20:28,283] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0501877e-02 2.4370339e-14 9.8949814e-01 7.3384704e-17 7.2646186e-13], sampled 0.44070798591248594
[2019-03-27 06:20:34,897] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:20:34,899] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [34.513480345, 51.82216907, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.930809725854199, 6.911200000000001, 6.9112, 168.912956510431, 759768.810955281, 759768.8109552803, 230350.8942523825]
[2019-03-27 06:20:34,900] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:20:34,905] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.7532560e-21 2.7944607e-08 3.4416620e-22 3.1456986e-19], sampled 0.271046578851026
[2019-03-27 06:21:07,870] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061889615]
[2019-03-27 06:21:07,871] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.48333333333333, 71.83333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.583477075828846, 6.9112, 168.9093038358489, 1931007.789271485, 1454081.607246673, 311352.5582523459]
[2019-03-27 06:21:07,873] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:21:07,876] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.6086650e-01 2.0219547e-13 3.3913347e-01 3.0649102e-15 4.4919238e-12], sampled 0.05919363351153628
[2019-03-27 06:21:07,877] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1931007.789271485 W.
[2019-03-27 06:21:28,567] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7221.2893 3321900184.2034 2123.0000
[2019-03-27 06:21:28,654] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6939.0635 3188590459.1156 2408.0000
[2019-03-27 06:21:28,743] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7235.0614 3109365223.4432 1944.0000
[2019-03-27 06:21:28,798] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7991.9541 2940220773.2957 1342.0000
[2019-03-27 06:21:28,946] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7847.9253 2991686800.3907 1510.0000
[2019-03-27 06:21:29,963] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 875000, evaluation results [875000.0, 7221.289327555769, 3321900184.2034364, 2123.0, 7235.061386845933, 3109365223.4431863, 1944.0, 7991.9541236992845, 2940220773.2957263, 1342.0, 6939.063501576531, 3188590459.1155725, 2408.0, 7847.92525348293, 2991686800.3907423, 1510.0]
[2019-03-27 06:21:32,592] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9989927e-01 1.7138116e-18 1.0074829e-04 1.7655707e-19 2.2601086e-15], sum to 1.0000
[2019-03-27 06:21:32,600] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3187
[2019-03-27 06:21:32,605] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.2676884051797696, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4752224343962174, 6.911199999999999, 6.9112, 168.912956510431, 823619.6662567869, 823619.6662567875, 218770.7013017663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1003200.0000, 
sim time next is 1003800.0000, 
raw observation next is [21.6, 96.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9275111400984941, 6.911199999999999, 6.9112, 168.912956510431, 804925.2480920475, 804925.2480920481, 230446.7344797224], 
processed observation next is [1.0, 0.6086956521739131, 0.22274881516587688, 0.96, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.911598951339627, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.22359034669223543, 0.2235903466922356, 0.3439503499697349], 
reward next is 0.6560, 
noisyNet noise sample is [array([0.33301222], dtype=float32), -0.23071377]. 
=============================================
[2019-03-27 06:21:38,486] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.3493299e-27 6.2801793e-15 2.1783306e-26 8.5274199e-24], sum to 1.0000
[2019-03-27 06:21:38,494] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8158
[2019-03-27 06:21:38,499] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 82.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7564206789461804, 6.9112, 6.9112, 168.912956510431, 663846.6084781395, 663846.6084781395, 193037.4218181251], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1152600.0000, 
sim time next is 1153200.0000, 
raw observation next is [22.6, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021667964351264, 6.939170246418723, 6.9112, 168.9128322078536, 915884.1635188264, 896041.1226502467, 254036.3966960127], 
processed observation next is [1.0, 0.34782608695652173, 0.27014218009478685, 0.8133333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0264243467698342, 0.002797024641872259, 0.0, 0.8294393347697416, 0.25441226764411845, 0.24890031184729075, 0.37915880103882493], 
reward next is 0.4810, 
noisyNet noise sample is [array([0.16373613], dtype=float32), 0.8671699]. 
=============================================
[2019-03-27 06:21:46,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.0085174e-20 3.8067672e-08 8.3482461e-22 2.6751665e-17], sum to 1.0000
[2019-03-27 06:21:46,015] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7349
[2019-03-27 06:21:46,023] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1165394.785100656 W.
[2019-03-27 06:21:46,028] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.16666666666667, 81.33333333333333, 1.0, 2.0, 0.2715567788051644, 1.0, 2.0, 0.2715567788051644, 1.0, 1.0, 0.459271726178099, 6.9112, 6.9112, 170.5573041426782, 1165394.785100656, 1165394.785100656, 294748.7431546404], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [25.38333333333333, 80.66666666666667, 1.0, 2.0, 0.4028782646067671, 1.0, 2.0, 0.4028782646067671, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1156692.86535818, 1156692.86535818, 276571.21881246], 
processed observation next is [1.0, 0.34782608695652173, 0.4020537124802526, 0.8066666666666668, 1.0, 1.0, 0.28057622241779173, 1.0, 1.0, 0.28057622241779173, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.32130357371060553, 0.32130357371060553, 0.41279286389919406], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.3534041], dtype=float32), -0.00044561698]. 
=============================================
[2019-03-27 06:21:55,287] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 6.0746302e-26 1.7822652e-14 1.0533483e-25 2.2958531e-22], sum to 1.0000
[2019-03-27 06:21:55,294] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8495
[2019-03-27 06:21:55,297] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.585019010347259, 6.911199999999999, 6.9112, 168.912956510431, 510860.6854647915, 510860.6854647922, 163801.2103076859], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1562400.0000, 
sim time next is 1563000.0000, 
raw observation next is [21.7, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8184017907373564, 6.911200000000001, 6.9112, 168.912956510431, 714791.7576813748, 714791.7576813741, 205693.2480046533], 
processed observation next is [1.0, 0.08695652173913043, 0.2274881516587678, 0.9083333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7785387691918981, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19855326602260412, 0.19855326602260392, 0.30700484776813924], 
reward next is 0.6930, 
noisyNet noise sample is [array([0.21879102], dtype=float32), -1.6991831]. 
=============================================
[2019-03-27 06:21:55,321] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[71.02306 ]
 [71.24588 ]
 [71.34391 ]
 [71.644295]
 [71.854866]], R is [[70.82078552]
 [70.86810303]
 [70.91481781]
 [70.96101379]
 [71.00678253]].
[2019-03-27 06:22:03,791] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.5329876e-02 2.3841993e-15 9.5467013e-01 2.0179301e-17 1.0084644e-13], sum to 1.0000
[2019-03-27 06:22:03,801] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7221
[2019-03-27 06:22:03,805] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.3, 79.33333333333334, 1.0, 2.0, 0.5295294641020203, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8851292701150135, 6.9112, 6.9112, 168.912956510431, 1490007.833929251, 1490007.833929251, 318418.0280665024], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1939200.0000, 
sim time next is 1939800.0000, 
raw observation next is [26.35, 79.16666666666667, 1.0, 2.0, 0.529902525781773, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8872599979399808, 6.911199999999999, 6.9112, 168.912956510431, 1494673.496054328, 1494673.496054329, 319195.9837971117], 
processed observation next is [1.0, 0.43478260869565216, 0.4478672985781992, 0.7916666666666667, 1.0, 1.0, 0.43361750094189516, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8625121926097326, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4151870822373133, 0.4151870822373136, 0.47641191611509215], 
reward next is 0.5236, 
noisyNet noise sample is [array([-3.2470052], dtype=float32), -0.9357458]. 
=============================================
[2019-03-27 06:22:11,003] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1106746e-27 8.3439706e-13 1.0901859e-25 2.7628790e-23], sum to 1.0000
[2019-03-27 06:22:11,018] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0470
[2019-03-27 06:22:11,024] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.83333333333333, 97.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7639523501261617, 6.911200000000001, 6.9112, 168.912956510431, 645374.6808852643, 645374.6808852637, 194677.1800002729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1986600.0000, 
sim time next is 1987200.0000, 
raw observation next is [23.9, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.768174261065128, 6.9112, 6.9112, 168.912956510431, 648548.5964251377, 648548.5964251377, 195502.9660421165], 
processed observation next is [0.0, 0.0, 0.33175355450236965, 0.97, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7172856842257658, 0.0, 0.0, 0.8294399451523027, 0.1801523878958716, 0.1801523878958716, 0.2917954717046515], 
reward next is 0.7082, 
noisyNet noise sample is [array([1.0774325], dtype=float32), -0.31101522]. 
=============================================
[2019-03-27 06:22:18,676] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.1242862e-01 1.9027158e-16 8.7571301e-02 1.4783676e-19 5.3730273e-15], sum to 1.0000
[2019-03-27 06:22:18,685] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2425
[2019-03-27 06:22:18,695] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 999130.5592158082 W.
[2019-03-27 06:22:18,698] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.93333333333333, 86.66666666666667, 1.0, 2.0, 0.2142289897767274, 1.0, 1.0, 0.2142289897767274, 1.0, 2.0, 0.3827880383169326, 6.9112, 6.9112, 170.5573041426782, 999130.5592158082, 999130.5592158082, 284954.88829707], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1779600.0000, 
sim time next is 1780200.0000, 
raw observation next is [21.7, 88.0, 1.0, 2.0, 0.3235177937984398, 1.0, 2.0, 0.3235177937984398, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1010031.724216968, 1010031.724216968, 266998.5840581738], 
processed observation next is [1.0, 0.6086956521739131, 0.2274881516587678, 0.88, 1.0, 1.0, 0.18496119734751784, 1.0, 1.0, 0.18496119734751784, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.28056436783804667, 0.28056436783804667, 0.3985053493405579], 
reward next is 0.6015, 
noisyNet noise sample is [array([-0.1697474], dtype=float32), 2.2600458]. 
=============================================
[2019-03-27 06:22:24,085] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.7552957e-03 1.5722276e-17 9.9724472e-01 2.3229159e-20 7.7915358e-16], sum to 1.0000
[2019-03-27 06:22:24,095] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6320
[2019-03-27 06:22:24,101] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.98333333333333, 86.33333333333334, 1.0, 2.0, 0.5698895822934613, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9696056131289443, 6.911199999999999, 6.9112, 168.9129564978196, 1593335.045373494, 1593335.045373495, 344390.1772826459], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1872600.0000, 
sim time next is 1873200.0000, 
raw observation next is [26.96666666666667, 86.66666666666667, 1.0, 2.0, 0.5884660617282043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9995454030876197, 6.9112, 6.9112, 168.9129565104278, 1645312.654063079, 1645312.654063079, 355391.8712597545], 
processed observation next is [1.0, 0.6956521739130435, 0.47709320695102697, 0.8666666666666667, 1.0, 1.0, 0.5041759779857883, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9994456135214873, 0.0, 0.0, 0.8294399451522869, 0.45703129279529975, 0.45703129279529975, 0.5304356287459022], 
reward next is 0.4696, 
noisyNet noise sample is [array([0.96823746], dtype=float32), 0.18161738]. 
=============================================
[2019-03-27 06:22:24,373] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:22:24,374] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:22:24,375] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:22:24,375] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:22:24,376] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:22:24,376] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:22:24,377] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:22:24,377] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:22:24,378] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:22:24,378] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:22:24,379] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:22:24,409] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run37
[2019-03-27 06:22:24,430] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run37
[2019-03-27 06:22:24,431] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run37
[2019-03-27 06:22:24,431] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run37
[2019-03-27 06:22:24,483] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run37
[2019-03-27 06:22:53,183] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061715018]
[2019-03-27 06:22:53,186] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.46666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6699098606870109, 6.911199999999999, 6.9112, 168.912956510431, 577232.7169003858, 577232.7169003865, 177449.017568235]
[2019-03-27 06:22:53,187] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:22:53,191] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.00000000e+00 1.15049485e-26 8.53910855e-16 7.80233109e-26
 1.91369546e-23], sampled 0.0163393689175918
[2019-03-27 06:22:55,502] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061715018]
[2019-03-27 06:22:55,504] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.01387706333334, 78.960279435, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7786991913525548, 6.911200000000001, 6.9112, 168.912956510431, 660680.386698893, 660680.3866988923, 197641.443076229]
[2019-03-27 06:22:55,505] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:22:55,507] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.2832395e-24 2.8513501e-11 1.9834249e-24 1.6101491e-21], sampled 0.023705148878184867
[2019-03-27 06:23:44,962] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061715018]
[2019-03-27 06:23:44,965] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.86666666666667, 70.33333333333333, 1.0, 2.0, 0.9116992018102797, 1.0, 1.0, 0.9116992018102797, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2550050.643879256, 2550050.643879256, 477913.9769168631]
[2019-03-27 06:23:44,968] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:23:44,972] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.8791127e-05 4.8654904e-14 9.9994123e-01 5.1307866e-17 3.1312171e-13], sampled 0.16091974388122576
[2019-03-27 06:23:44,972] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2550050.643879256 W.
[2019-03-27 06:23:51,139] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061715018]
[2019-03-27 06:23:51,140] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.1, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9661565548672816, 6.9112, 6.9112, 168.912956510431, 794974.335925965, 794974.335925965, 239282.8467692]
[2019-03-27 06:23:51,142] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:23:51,143] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.7951328e-26 1.9477970e-14 1.3739038e-25 5.3684225e-23], sampled 0.3061683200680906
[2019-03-27 06:23:53,558] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061715018]
[2019-03-27 06:23:53,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.8, 90.0, 1.0, 2.0, 0.6527531459587288, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 912212.7622834033, 912212.7622834033, 210977.6328821811]
[2019-03-27 06:23:53,560] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:23:53,562] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.9628757e-01 1.1350995e-14 3.0371243e-01 1.0738617e-16 2.4267646e-13], sampled 0.5120293151096491
[2019-03-27 06:23:53,564] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 912212.7622834033 W.
[2019-03-27 06:24:19,231] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7107.3475 3119838404.9306 1786.0000
[2019-03-27 06:24:19,595] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6816.5213 3197170348.7404 2268.0000
[2019-03-27 06:24:19,757] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7132.5975 3327806818.0696 2065.0000
[2019-03-27 06:24:19,853] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7740.9801 2998648847.5708 1406.0000
[2019-03-27 06:24:19,968] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7902.4437 2947554296.8006 1233.0000
[2019-03-27 06:24:20,985] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 900000, evaluation results [900000.0, 7132.597466382153, 3327806818.0695972, 2065.0, 7107.347509583908, 3119838404.9306226, 1786.0, 7902.443653533793, 2947554296.8006163, 1233.0, 6816.521333354438, 3197170348.740372, 2268.0, 7740.980129289067, 2998648847.570823, 1406.0]
[2019-03-27 06:24:33,198] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.3654591e-25 1.0627787e-14 6.2999159e-26 1.1398121e-22], sum to 1.0000
[2019-03-27 06:24:33,208] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7402
[2019-03-27 06:24:33,215] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7671074339721117, 6.9112, 6.9112, 168.912956510431, 646711.1113267598, 646711.1113267598, 195276.978606206], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2089800.0000, 
sim time next is 2090400.0000, 
raw observation next is [23.86666666666667, 97.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7657703139196964, 6.9112, 6.9112, 168.912956510431, 645689.8343248379, 645689.8343248379, 195015.2413966245], 
processed observation next is [0.0, 0.17391304347826086, 0.33017377567140627, 0.9766666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7143540413654833, 0.0, 0.0, 0.8294399451523027, 0.17935828731245498, 0.17935828731245498, 0.2910675244725739], 
reward next is 0.7089, 
noisyNet noise sample is [array([1.5662252], dtype=float32), -0.3653465]. 
=============================================
[2019-03-27 06:24:39,292] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9495409e-08 2.3023490e-17 1.0000000e+00 9.4581429e-22 2.3830404e-16], sum to 1.0000
[2019-03-27 06:24:39,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0029
[2019-03-27 06:24:39,310] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.06666666666667, 65.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.012533641442098, 6.9112, 168.9121376347998, 2355633.137452476, 2283743.913093203, 475829.1736177539], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2211600.0000, 
sim time next is 2212200.0000, 
raw observation next is [32.05, 65.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.144095339100886, 6.9112, 168.9114075090064, 2449052.492686835, 2283830.038661599, 475566.7116650017], 
processed observation next is [1.0, 0.6086956521739131, 0.7180094786729857, 0.655, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.02328953391008861, 0.0, 0.8294323388461721, 0.6802923590796764, 0.6343972329615554, 0.7098010621865697], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.48105487], dtype=float32), -0.7161861]. 
=============================================
[2019-03-27 06:24:44,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.0912454e-07 6.0831861e-17 9.9999905e-01 3.7165697e-21 7.6106063e-17], sum to 1.0000
[2019-03-27 06:24:44,795] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1769
[2019-03-27 06:24:44,799] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.83333333333333, 65.0, 1.0, 2.0, 0.5681720620480565, 1.0, 1.0, 0.5681720620480565, 1.0, 2.0, 0.9867269744053145, 6.9112, 6.9112, 170.5573041426782, 2383633.461731852, 2383633.461731852, 465488.9024059403], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2297400.0000, 
sim time next is 2298000.0000, 
raw observation next is [31.86666666666667, 65.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.271913228636574, 6.9112, 168.9108949796326, 2540849.442065582, 2284950.186089596, 475351.9415100082], 
processed observation next is [1.0, 0.6086956521739131, 0.7093206951026858, 0.65, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.03607132286365742, 0.0, 0.8294298220923096, 0.705791511684884, 0.6347083850248877, 0.7094805097164302], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6926581], dtype=float32), -0.048266575]. 
=============================================
[2019-03-27 06:24:44,810] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[40.896523]
 [41.043102]
 [41.706352]
 [42.5268  ]
 [43.446342]], R is [[40.39569473]
 [40.296978  ]
 [39.89400864]
 [39.4950676 ]
 [39.10011673]].
[2019-03-27 06:24:53,976] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.5016191e-22 1.9399926e-10 2.0520786e-22 7.0787806e-19], sum to 1.0000
[2019-03-27 06:24:53,986] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1319
[2019-03-27 06:24:53,994] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6028494423596441, 6.9112, 6.9112, 168.912956510431, 522788.8774418494, 522788.8774418494, 166547.761406969], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2784000.0000, 
sim time next is 2784600.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5959410528752707, 6.911200000000001, 6.9112, 168.912956510431, 516784.415103858, 516784.4151038575, 165497.6899562036], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5072451864332569, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14355122641773832, 0.1435512264177382, 0.24701147754657254], 
reward next is 0.7530, 
noisyNet noise sample is [array([0.42780772], dtype=float32), 0.2554212]. 
=============================================
[2019-03-27 06:25:04,636] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.4475440e-29 1.4158359e-17 9.4840855e-29 2.4429033e-25], sum to 1.0000
[2019-03-27 06:25:04,649] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3198
[2019-03-27 06:25:04,653] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8353444804094294, 6.9112, 6.9112, 168.912956510431, 694949.3092605183, 694949.3092605183, 209145.5186923622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2651400.0000, 
sim time next is 2652000.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8352331841783956, 6.911199999999999, 6.9112, 168.912956510431, 694847.4702376963, 694847.470237697, 209121.2902118245], 
processed observation next is [0.0, 0.6956521739130435, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7990648587541409, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19301318617713786, 0.19301318617713806, 0.31212132867436493], 
reward next is 0.6879, 
noisyNet noise sample is [array([1.4565419], dtype=float32), 2.0737784]. 
=============================================
[2019-03-27 06:25:04,667] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[74.3863 ]
 [74.36102]
 [74.32145]
 [74.25264]
 [74.18548]], R is [[74.34661102]
 [74.29099274]
 [74.2357254 ]
 [74.18083191]
 [74.12708282]].
[2019-03-27 06:25:07,706] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.4347383e-28 1.0207229e-16 7.4058293e-27 3.7477752e-24], sum to 1.0000
[2019-03-27 06:25:07,715] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6035
[2019-03-27 06:25:07,721] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7483345853117528, 6.9112, 6.9112, 168.912956510431, 633801.0473858983, 633801.0473858983, 191664.0896653905], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2688000.0000, 
sim time next is 2688600.0000, 
raw observation next is [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7470465313417556, 6.9112, 6.9112, 168.912956510431, 632708.5283133048, 632708.5283133048, 191416.6183618696], 
processed observation next is [0.0, 0.08695652173913043, 0.3364928909952607, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6915201601728727, 0.0, 0.0, 0.8294399451523027, 0.17575236897591798, 0.17575236897591798, 0.2856964453162233], 
reward next is 0.7143, 
noisyNet noise sample is [array([0.24627194], dtype=float32), 0.008137041]. 
=============================================
[2019-03-27 06:25:07,954] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0909075e-29 1.1108313e-18 6.4290635e-29 3.0718700e-25], sum to 1.0000
[2019-03-27 06:25:07,966] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2028
[2019-03-27 06:25:07,972] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7928476672923008, 6.911200000000001, 6.9112, 168.912956510431, 664878.2063941116, 664878.206394111, 200374.6025859474], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2700600.0000, 
sim time next is 2701200.0000, 
raw observation next is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7930556423945508, 6.911199999999999, 6.9112, 168.912956510431, 664990.3861802926, 664990.3861802932, 200415.6733508327], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7476288321884765, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18471955171674795, 0.18471955171674811, 0.2991278706728846], 
reward next is 0.7009, 
noisyNet noise sample is [array([-0.6707329], dtype=float32), 0.31005326]. 
=============================================
[2019-03-27 06:25:14,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999976e-01 1.6784025e-20 2.4499852e-07 3.0554668e-21 1.2393586e-18], sum to 1.0000
[2019-03-27 06:25:14,063] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9939
[2019-03-27 06:25:14,070] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 977358.4574253424 W.
[2019-03-27 06:25:14,075] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 88.00000000000001, 1.0, 1.0, 0.6223907682691002, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129496780799, 977358.4574253424, 977358.4574253424, 217713.2930936417], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2974200.0000, 
sim time next is 2974800.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.3053938556385395, 1.0, 1.0, 0.3053938556385395, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 949142.709263619, 949142.709263619, 262533.5138076335], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.88, 1.0, 1.0, 0.16312512727534878, 1.0, 0.5, 0.16312512727534878, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2636507525732275, 0.2636507525732275, 0.39184106538452756], 
reward next is 0.6082, 
noisyNet noise sample is [array([0.13671507], dtype=float32), -0.18022461]. 
=============================================
[2019-03-27 06:25:15,461] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:25:15,462] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:25:15,463] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:25:15,464] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:25:15,464] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:25:15,466] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:25:15,469] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:25:15,468] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:25:15,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:25:15,470] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:25:15,466] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:25:15,481] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run38
[2019-03-27 06:25:15,499] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run38
[2019-03-27 06:25:15,518] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run38
[2019-03-27 06:25:15,538] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run38
[2019-03-27 06:25:15,558] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run38
[2019-03-27 06:25:32,234] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.062712796]
[2019-03-27 06:25:32,235] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5520301485891664, 6.9112, 6.9112, 168.912956510431, 487025.3476600831, 487025.3476600831, 158916.8203523628]
[2019-03-27 06:25:32,236] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:25:32,240] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.6071914e-28 1.0713215e-16 2.5302055e-27 6.5660655e-25], sampled 0.8212587829168565
[2019-03-27 06:26:09,116] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.062712796]
[2019-03-27 06:26:09,119] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.275315955, 88.32099567, 1.0, 1.0, 0.6537274698981639, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9127187424467, 913574.9515979007, 913574.9515979013, 211180.4217788456]
[2019-03-27 06:26:09,119] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:26:09,120] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.8065698e-24 1.1351799e-11 1.5589416e-24 1.2735772e-21], sampled 0.6751476370497703
[2019-03-27 06:26:09,123] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 913574.9515979007 W.
[2019-03-27 06:26:29,880] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.062712796]
[2019-03-27 06:26:29,882] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.53733405, 62.69102497666667, 1.0, 2.0, 0.7694893202192394, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00406289828933, 6.9112, 168.9123315674975, 1972373.406886104, 1906493.514488206, 400508.321436046]
[2019-03-27 06:26:29,884] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:26:29,887] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [6.5233463e-01 2.2504472e-16 3.4766534e-01 9.1702969e-19 8.0605180e-15], sampled 0.7116219256097533
[2019-03-27 06:26:39,111] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.062712796]
[2019-03-27 06:26:39,111] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.65624398666667, 83.687457815, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9036272514718201, 6.911200000000001, 6.9112, 168.912956510431, 744702.2117151095, 744702.2117151088, 224226.9705560728]
[2019-03-27 06:26:39,112] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:26:39,115] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.6383409e-28 7.6698696e-16 1.2334576e-27 5.4858388e-25], sampled 0.35937995709080905
[2019-03-27 06:27:01,012] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.062712796]
[2019-03-27 06:27:01,014] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.1, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6697266221361164, 6.9112, 6.9112, 168.912956510431, 576763.0394685502, 576763.0394685502, 177419.3324116567]
[2019-03-27 06:27:01,019] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:27:01,021] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.9866694e-28 1.2117039e-16 1.1957225e-27 4.1827461e-25], sampled 0.4226977755708994
[2019-03-27 06:27:09,091] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6835.7525 3193401988.1629 2332.0000
[2019-03-27 06:27:09,211] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7802.8020 2996140812.5253 1447.0000
[2019-03-27 06:27:09,348] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7898.9614 2944587736.9162 1268.0000
[2019-03-27 06:27:09,515] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7186.0882 3325313191.6268 2084.0000
[2019-03-27 06:27:09,869] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7100.3930 3116394177.7672 1832.0000
[2019-03-27 06:27:10,885] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 925000, evaluation results [925000.0, 7186.088176673062, 3325313191.626835, 2084.0, 7100.392990903047, 3116394177.7672253, 1832.0, 7898.9613991718425, 2944587736.9161916, 1268.0, 6835.752488411593, 3193401988.162892, 2332.0, 7802.801996312539, 2996140812.5253, 1447.0]
[2019-03-27 06:27:13,833] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9657309e-01 3.5687781e-18 3.4269225e-03 6.4938719e-20 2.2021463e-16], sum to 1.0000
[2019-03-27 06:27:13,844] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6399
[2019-03-27 06:27:13,853] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 91.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9265289246340684, 6.9112, 6.9112, 168.912956510431, 795784.8260941306, 795784.8260941306, 230291.574638522], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2896200.0000, 
sim time next is 2896800.0000, 
raw observation next is [23.0, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9041324270076042, 6.9112, 6.9112, 168.912956510431, 777290.9085017957, 777290.9085017957, 224968.8389265208], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8830883256190294, 0.0, 0.0, 0.8294399451523027, 0.21591414125049882, 0.21591414125049882, 0.33577438645749375], 
reward next is 0.6642, 
noisyNet noise sample is [array([0.28967732], dtype=float32), 1.1674067]. 
=============================================
[2019-03-27 06:27:15,707] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.04067486e-26 1.40324454e-15 5.26104357e-27
 2.27899155e-25], sum to 1.0000
[2019-03-27 06:27:15,717] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1966
[2019-03-27 06:27:15,720] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666667, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9424486849987106, 6.9112, 6.9112, 168.912956510431, 766267.0699559365, 766267.0699559365, 233017.0928519548], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3322200.0000, 
sim time next is 3322800.0000, 
raw observation next is [31.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.958274025150062, 6.911199999999999, 6.9112, 168.912956510431, 776663.7190279783, 776663.719027979, 236766.5814375593], 
processed observation next is [0.0, 0.4782608695652174, 0.6682464454976303, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9491146648171487, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21573992195221617, 0.21573992195221636, 0.3533829573694915], 
reward next is 0.6466, 
noisyNet noise sample is [array([0.02836161], dtype=float32), -1.2155154]. 
=============================================
[2019-03-27 06:27:17,542] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8289103e-25 1.1756043e-13 2.7026154e-24 6.8675744e-23], sum to 1.0000
[2019-03-27 06:27:17,551] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4943
[2019-03-27 06:27:17,555] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.587344496504605, 6.911200000000001, 6.9112, 168.912956510431, 514351.9279243697, 514351.9279243691, 164110.2574369309], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2959800.0000, 
sim time next is 2960400.0000, 
raw observation next is [21.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.563856735355342, 6.9112, 6.9112, 168.912956510431, 493290.6173517926, 493290.6173517926, 160708.5195984574], 
processed observation next is [1.0, 0.2608695652173913, 0.19431279620853087, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46811796994553895, 0.0, 0.0, 0.8294399451523027, 0.13702517148660906, 0.13702517148660906, 0.23986346208724987], 
reward next is 0.7601, 
noisyNet noise sample is [array([0.06440513], dtype=float32), 0.38088197]. 
=============================================
[2019-03-27 06:27:18,291] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999976e-01 4.4386120e-21 1.8354389e-07 1.0016465e-20 3.8703839e-18], sum to 1.0000
[2019-03-27 06:27:18,298] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6791
[2019-03-27 06:27:18,308] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 923639.2006947377 W.
[2019-03-27 06:27:18,317] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 91.0, 1.0, 1.0, 0.5943794975077216, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129362239472, 923639.2006947377, 923639.2006947371, 210817.1206911691], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2971800.0000, 
sim time next is 2972400.0000, 
raw observation next is [22.0, 90.0, 1.0, 2.0, 0.1880122845732367, 1.0, 1.0, 0.1880122845732367, 1.0, 1.0, 0.3334331906662149, 6.9112, 6.9112, 170.5573041426782, 866315.5904836208, 866315.5904836208, 275970.8386630669], 
processed observation next is [1.0, 0.391304347826087, 0.2417061611374408, 0.9, 1.0, 1.0, 0.021701547678598433, 1.0, 0.5, 0.021701547678598433, 1.0, 0.5, 0.18711364715392062, 0.0, 0.0, 0.8375144448122397, 0.24064321957878354, 0.24064321957878354, 0.41189677412398046], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5496429], dtype=float32), 2.228311]. 
=============================================
[2019-03-27 06:27:19,625] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.9084825e-21 5.5766969e-09 7.4412181e-22 1.7505119e-18], sum to 1.0000
[2019-03-27 06:27:19,630] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8622
[2019-03-27 06:27:19,635] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 89.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9680910089132421, 6.9112, 6.9112, 168.9129565104295, 844190.4178041227, 844190.4178041227, 240346.3078666452], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2973000.0000, 
sim time next is 2973600.0000, 
raw observation next is [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.02615791872471, 6.919463374612808, 6.9112, 168.9127219514471, 901897.5395065062, 896035.2252934199, 255371.7887489309], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0318999008837928, 0.0008263374612807794, 0.0, 0.8294387933603102, 0.2505270943073628, 0.24889867369261665, 0.381151923505867], 
reward next is 0.5775, 
noisyNet noise sample is [array([0.75989085], dtype=float32), 0.88985765]. 
=============================================
[2019-03-27 06:27:27,796] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.4723206e-26 1.8563301e-10 2.1837636e-26 3.3743330e-23], sum to 1.0000
[2019-03-27 06:27:27,808] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0795
[2019-03-27 06:27:27,813] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333333, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9001425368045489, 6.9112, 6.9112, 168.912956510431, 737414.7106371127, 737414.7106371127, 223236.4300775285], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3437400.0000, 
sim time next is 3438000.0000, 
raw observation next is [29.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8872265594673971, 6.911200000000001, 6.9112, 168.912956510431, 729106.38192588, 729106.3819258793, 220356.9187380982], 
processed observation next is [1.0, 0.8260869565217391, 0.5734597156398105, 0.74, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8624714139846307, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20252955053496666, 0.20252955053496646, 0.32889092348969884], 
reward next is 0.6711, 
noisyNet noise sample is [array([0.04652542], dtype=float32), -0.74724716]. 
=============================================
[2019-03-27 06:27:27,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[84.29253 ]
 [84.57866 ]
 [84.42247 ]
 [83.762085]
 [81.99437 ]], R is [[83.36956787]
 [83.2026825 ]
 [83.03318787]
 [82.86129761]
 [82.68768311]].
[2019-03-27 06:27:28,962] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.5894941e-25 2.1038547e-10 1.8523194e-25 1.3998880e-21], sum to 1.0000
[2019-03-27 06:27:28,970] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5767
[2019-03-27 06:27:28,976] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6738673374259916, 6.911199999999999, 6.9112, 168.912956510431, 581410.119889785, 581410.1198897855, 178123.4092776884], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3123000.0000, 
sim time next is 3123600.0000, 
raw observation next is [22.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6616472873524188, 6.911200000000001, 6.9112, 168.912956510431, 571630.6657486432, 571630.6657486426, 176032.8145518866], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5873747406736815, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15878629604128977, 0.15878629604128963, 0.26273554410729344], 
reward next is 0.7373, 
noisyNet noise sample is [array([0.6299644], dtype=float32), 1.0285305]. 
=============================================
[2019-03-27 06:27:34,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6251337e-26 9.6124043e-14 4.3386960e-25 2.3472873e-22], sum to 1.0000
[2019-03-27 06:27:34,087] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1211
[2019-03-27 06:27:34,092] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9217199099449989, 6.9112, 6.9112, 168.912956510431, 751533.0838607838, 751533.0838607838, 228142.9047847904], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3234000.0000, 
sim time next is 3234600.0000, 
raw observation next is [29.5, 74.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9173031248259949, 6.911200000000001, 6.9112, 168.912956510431, 748668.8860541384, 748668.8860541377, 227130.9515753066], 
processed observation next is [0.0, 0.43478260869565216, 0.5971563981042655, 0.745, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.899150152226823, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2079635794594829, 0.2079635794594827, 0.33900142026165164], 
reward next is 0.6610, 
noisyNet noise sample is [array([-0.9473669], dtype=float32), -0.43672296]. 
=============================================
[2019-03-27 06:27:40,243] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9977356e-01 4.1771426e-18 2.2648815e-04 6.7333603e-19 7.5951486e-16], sum to 1.0000
[2019-03-27 06:27:40,252] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4594
[2019-03-27 06:27:40,257] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 75.0, 1.0, 1.0, 0.60527889655074, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912882909029, 845841.7904172649, 845841.7904172649, 201733.2335739479], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3340800.0000, 
sim time next is 3341400.0000, 
raw observation next is [30.83333333333334, 75.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.079095349084015, 6.9112, 168.9119071383476, 947957.3918877383, 828847.3927112921, 254812.4933337142], 
processed observation next is [0.0, 0.6956521739130435, 0.6603475513428123, 0.7566666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.01678953490840147, 0.0, 0.8294347922549685, 0.26332149774659397, 0.23023538686424783, 0.3803171542294242], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.81937057], dtype=float32), 0.3463666]. 
=============================================
[2019-03-27 06:27:45,719] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.77850735e-01 2.18885432e-19 2.21492406e-02 1.40629701e-21
 1.38077355e-17], sum to 1.0000
[2019-03-27 06:27:45,729] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7825
[2019-03-27 06:27:45,735] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 70.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9329720386026427, 6.9112, 6.9112, 168.912956510431, 753774.6415356724, 753774.6415356724, 230483.5453937056], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3434400.0000, 
sim time next is 3435000.0000, 
raw observation next is [30.66666666666667, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9374458885705722, 6.9112, 6.9112, 168.912956510431, 758737.373915605, 758737.373915605, 231629.9929113272], 
processed observation next is [1.0, 0.782608695652174, 0.6524486571879939, 0.7066666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9237144982567952, 0.0, 0.0, 0.8294399451523027, 0.2107603816432236, 0.2107603816432236, 0.3457164073303391], 
reward next is 0.6543, 
noisyNet noise sample is [array([-0.4837108], dtype=float32), -0.04651537]. 
=============================================
[2019-03-27 06:27:45,744] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[68.26435 ]
 [65.347534]
 [63.956223]
 [62.008423]
 [58.987408]], R is [[71.70825958]
 [71.64717865]
 [71.6145401 ]
 [71.58319092]
 [71.55432129]].
[2019-03-27 06:27:47,612] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.0072745e-22 6.4901533e-09 2.8627421e-24 1.0384856e-19], sum to 1.0000
[2019-03-27 06:27:47,622] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0103
[2019-03-27 06:27:47,626] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8579928584015939, 6.9112, 6.9112, 168.912956510431, 710959.2798855753, 710959.2798855753, 214000.6618672444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3456600.0000, 
sim time next is 3457200.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8575951577770233, 6.9112, 6.9112, 168.912956510431, 710629.622705914, 710629.622705914, 213912.7129741632], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8263355582646627, 0.0, 0.0, 0.8294399451523027, 0.19739711741830943, 0.19739711741830943, 0.31927270593158685], 
reward next is 0.6807, 
noisyNet noise sample is [array([-0.601354], dtype=float32), -0.7657147]. 
=============================================
[2019-03-27 06:27:49,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.1516196e-25 1.6592123e-13 8.7307655e-26 1.8672001e-21], sum to 1.0000
[2019-03-27 06:27:49,851] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6396
[2019-03-27 06:27:49,856] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9986892388997062, 6.911200000000001, 6.9112, 168.9129494357265, 806806.9425436404, 806806.9425436397, 246815.9959358749], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3895200.0000, 
sim time next is 3895800.0000, 
raw observation next is [27.41666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9958023360404413, 6.9112, 6.9112, 168.9129565104308, 804777.7802085128, 804777.7802085128, 246090.9935558867], 
processed observation next is [0.0, 0.08695652173913043, 0.4984202211690366, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9948808976102943, 0.0, 0.0, 0.8294399451523017, 0.22354938339125355, 0.22354938339125355, 0.36729999038192046], 
reward next is 0.6327, 
noisyNet noise sample is [array([-0.42637238], dtype=float32), 0.3335376]. 
=============================================
[2019-03-27 06:27:55,586] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9976021e-01 2.6440261e-21 2.3979475e-04 8.2058176e-23 8.4829931e-20], sum to 1.0000
[2019-03-27 06:27:55,592] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2180
[2019-03-27 06:27:55,599] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.5, 66.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9582627649787897, 6.9112, 6.9112, 168.912956510431, 774710.4581690775, 774710.4581690775, 236660.4933142846], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3609000.0000, 
sim time next is 3609600.0000, 
raw observation next is [31.33333333333333, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9495053010606883, 6.911199999999999, 6.9112, 168.912956510431, 769895.836702051, 769895.8367020516, 234629.9591700406], 
processed observation next is [1.0, 0.782608695652174, 0.6840442338072668, 0.6633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9384210988544978, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21385995463945862, 0.21385995463945878, 0.35019396891050836], 
reward next is 0.6498, 
noisyNet noise sample is [array([1.7605319], dtype=float32), 0.20181589]. 
=============================================
[2019-03-27 06:27:56,917] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.9126335e-22 3.0921521e-09 3.2335601e-23 1.4719092e-19], sum to 1.0000
[2019-03-27 06:27:56,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2538
[2019-03-27 06:27:56,932] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8288960098021099, 6.911199999999999, 6.9112, 168.912956510431, 691204.310479273, 691204.3104792737, 207808.7919655605], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3628800.0000, 
sim time next is 3629400.0000, 
raw observation next is [27.83333333333334, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8298810259157089, 6.9112, 6.9112, 168.912956510431, 692324.0140958324, 692324.0140958324, 208027.5845991716], 
processed observation next is [1.0, 0.0, 0.5181674565560824, 0.7566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7925378364825717, 0.0, 0.0, 0.8294399451523027, 0.19231222613773122, 0.19231222613773122, 0.3104889322375695], 
reward next is 0.6895, 
noisyNet noise sample is [array([0.77055585], dtype=float32), 0.7880774]. 
=============================================
[2019-03-27 06:27:57,105] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.0208337e-01 4.8158977e-15 1.9791669e-01 3.5060868e-17 3.5726687e-13], sum to 1.0000
[2019-03-27 06:27:57,112] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5980
[2019-03-27 06:27:57,123] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1333659.3206053 W.
[2019-03-27 06:27:57,130] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.318048218580434, 1.0, 2.0, 0.318048218580434, 1.0, 1.0, 0.5361364609197407, 6.911199999999999, 6.9112, 170.5573041426782, 1333659.3206053, 1333659.320605301, 310407.3547167508], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3637800.0000, 
sim time next is 3638400.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.8940153897328623, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565102878, 1249571.517166541, 1249571.517166542, 268293.2442022217], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 1.0, 1.0, 0.8723076984733281, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451515996, 0.34710319921292804, 0.3471031992129283, 0.4004376779137637], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.84071517], dtype=float32), 0.67062396]. 
=============================================
[2019-03-27 06:27:57,959] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.0924294e-02 3.7062316e-14 9.4907576e-01 4.0323506e-17 1.3056397e-12], sum to 1.0000
[2019-03-27 06:27:57,968] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0240
[2019-03-27 06:27:57,975] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1240320.195969404 W.
[2019-03-27 06:27:57,980] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.5, 72.0, 1.0, 2.0, 0.4437001629725886, 0.0, 2.0, 0.0, 1.0, 2.0, 0.745278314216354, 6.911199999999999, 6.9112, 168.912956510431, 1240320.195969404, 1240320.195969404, 275316.1149556337], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3655800.0000, 
sim time next is 3656400.0000, 
raw observation next is [28.66666666666666, 71.33333333333333, 1.0, 2.0, 0.7719786979650235, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1078913.32569186, 1078913.32569186, 237146.3070622756], 
processed observation next is [1.0, 0.30434782608695654, 0.5576619273301735, 0.7133333333333333, 1.0, 1.0, 0.7252755397168957, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29969814602551664, 0.29969814602551664, 0.35394971203324715], 
reward next is 0.6461, 
noisyNet noise sample is [array([-0.16136427], dtype=float32), -0.4618311]. 
=============================================
[2019-03-27 06:27:59,835] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.2565203e-09 6.0285347e-17 1.0000000e+00 1.1197683e-21 2.5446698e-17], sum to 1.0000
[2019-03-27 06:27:59,845] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7408
[2019-03-27 06:27:59,849] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.83333333333334, 60.33333333333334, 1.0, 2.0, 0.8382142665558835, 1.0, 2.0, 0.8382142665558835, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2344318.218430059, 2344318.218430058, 438905.4166750703], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3687000.0000, 
sim time next is 3687600.0000, 
raw observation next is [32.66666666666667, 61.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.336597759490481, 6.9112, 168.9106372152691, 2586503.605205355, 2284715.937378319, 475197.8979234119], 
processed observation next is [1.0, 0.6956521739130435, 0.7472353870458138, 0.6166666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.04253977594904814, 0.0, 0.8294285563512799, 0.7184732236681542, 0.6346433159384219, 0.7092505939155401], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06613775], dtype=float32), 0.6192509]. 
=============================================
[2019-03-27 06:28:00,177] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [4.0850963e-02 2.3659495e-17 9.5914900e-01 5.2869811e-20 6.5755019e-16], sum to 1.0000
[2019-03-27 06:28:00,185] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7890
[2019-03-27 06:28:00,193] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.33333333333333, 73.66666666666666, 1.0, 2.0, 0.2735014561107751, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4733767548927011, 6.911200000000001, 6.9112, 168.912956510431, 764375.2141804774, 764375.2141804767, 213684.3099630612], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3693000.0000, 
sim time next is 3693600.0000, 
raw observation next is [30.0, 75.0, 1.0, 2.0, 0.2760614334362287, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4770762427418824, 6.911199999999999, 6.9112, 168.912956510431, 771532.3748875092, 771532.3748875097, 214366.9426759046], 
processed observation next is [1.0, 0.782608695652174, 0.6208530805687204, 0.75, 1.0, 1.0, 0.1277848595617213, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36228810090473457, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21431454857986365, 0.21431454857986382, 0.31995066071030537], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.08019668], dtype=float32), 0.03369997]. 
=============================================
[2019-03-27 06:28:00,482] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.8036831e-07 4.5810549e-17 9.9999964e-01 5.8247490e-21 3.1904777e-16], sum to 1.0000
[2019-03-27 06:28:00,489] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1234
[2019-03-27 06:28:00,497] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.66666666666667, 68.33333333333334, 1.0, 2.0, 0.3959672434513477, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6876641535065732, 6.9112, 6.9112, 168.9129565025585, 1106817.965536032, 1106817.965536032, 257834.0818669661], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3690600.0000, 
sim time next is 3691200.0000, 
raw observation next is [31.33333333333334, 69.66666666666667, 1.0, 2.0, 0.2735715221779229, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4751032625381824, 6.911199999999999, 6.9112, 168.912956510429, 764571.1035949895, 764571.1035949901, 213846.5009438393], 
processed observation next is [1.0, 0.7391304347826086, 0.6840442338072673, 0.6966666666666668, 1.0, 1.0, 0.12478496647942518, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3598820274855883, -8.881784197001253e-17, 0.0, 0.8294399451522929, 0.21238086210971932, 0.21238086210971946, 0.31917388200573027], 
reward next is 0.6808, 
noisyNet noise sample is [array([1.6185343], dtype=float32), 1.2349545]. 
=============================================
[2019-03-27 06:28:01,227] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9993789e-01 2.9137447e-20 6.2102830e-05 7.5588243e-22 3.6856994e-17], sum to 1.0000
[2019-03-27 06:28:01,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8090
[2019-03-27 06:28:01,244] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9616032294260047, 6.911199999999999, 6.9112, 168.912956510431, 779320.1088175253, 779320.1088175259, 237587.2685723785], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3694800.0000, 
sim time next is 3695400.0000, 
raw observation next is [29.5, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.957872651831219, 6.9112, 6.9112, 168.912956510431, 777006.7758588339, 777006.7758588339, 236701.9627952446], 
processed observation next is [1.0, 0.782608695652174, 0.5971563981042655, 0.77, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9486251851600229, 0.0, 0.0, 0.8294399451523027, 0.21583521551634274, 0.21583521551634274, 0.35328651163469343], 
reward next is 0.6467, 
noisyNet noise sample is [array([0.04319295], dtype=float32), 0.3583116]. 
=============================================
[2019-03-27 06:28:02,332] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999833e-01 1.9777235e-18 1.7074204e-06 7.2054750e-21 1.3088433e-16], sum to 1.0000
[2019-03-27 06:28:02,338] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5969
[2019-03-27 06:28:02,348] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1302302.720021947 W.
[2019-03-27 06:28:02,354] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 74.0, 1.0, 1.0, 0.3105749030620475, 1.0, 1.0, 0.3105749030620475, 1.0, 2.0, 0.5183310938736445, 6.9112, 6.9112, 170.5573041426782, 1302302.720021947, 1302302.720021947, 306665.7425717376], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3723600.0000, 
sim time next is 3724200.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.2466222500420978, 1.0, 2.0, 0.2466222500420978, 1.0, 2.0, 0.4109953723399657, 6.9112, 6.9112, 170.5573041426782, 1034007.134471438, 1034007.134471438, 282885.9388131252], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.09231596390614193, 1.0, 1.0, 0.09231596390614193, 1.0, 1.0, 0.281701673585324, 0.0, 0.0, 0.8375144448122397, 0.2872242040198439, 0.2872242040198439, 0.4222178191240675], 
reward next is 0.5778, 
noisyNet noise sample is [array([1.4695886], dtype=float32), 1.6166865]. 
=============================================
[2019-03-27 06:28:05,373] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 06:28:05,374] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:28:05,375] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:28:05,376] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:28:05,377] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:28:05,379] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:28:05,379] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:28:05,380] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:28:05,380] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:28:05,377] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:28:05,383] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:28:05,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run39
[2019-03-27 06:28:05,425] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run39
[2019-03-27 06:28:05,426] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run39
[2019-03-27 06:28:05,428] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run39
[2019-03-27 06:28:05,445] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run39
[2019-03-27 06:28:15,961] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:28:15,962] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.63333333333333, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4402172930366842, 6.9112, 6.9112, 168.912956510431, 394101.6041391643, 394101.6041391643, 144789.1622684251]
[2019-03-27 06:28:15,963] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:28:15,965] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.5449035e-24 1.8013009e-14 6.5033007e-24 1.7368866e-21], sampled 0.44080931228043985
[2019-03-27 06:28:21,252] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:28:21,253] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.66666666666666, 67.5, 1.0, 2.0, 0.2124568092544984, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3771123262982657, 6.911199999999999, 6.9112, 168.912956510431, 653470.7032023642, 653470.7032023648, 203658.421304266]
[2019-03-27 06:28:21,260] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:28:21,262] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [7.2778434e-01 3.1306839e-14 2.7221572e-01 2.3056867e-16 1.2442828e-12], sampled 0.5635587209124195
[2019-03-27 06:28:50,550] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:28:50,550] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.23333333333333, 66.66666666666667, 1.0, 2.0, 0.7072587015697286, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.995864608887184, 6.9112, 168.9123849608247, 1885286.337089126, 1825222.552851705, 386617.910341274]
[2019-03-27 06:28:50,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:28:50,554] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.4597208e-02 1.8443209e-15 9.8540282e-01 8.4299672e-19 6.8924921e-14], sampled 0.08258194872073243
[2019-03-27 06:29:04,080] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:29:04,081] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.66666666666667, 82.33333333333334, 1.0, 2.0, 0.6711924021294612, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.997297765529535, 6.9112, 168.9124468783779, 1834817.535160579, 1773737.00132589, 378863.8953836139]
[2019-03-27 06:29:04,083] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:29:04,086] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.9363324e-01 1.4845011e-13 8.0636680e-01 4.6220862e-16 3.9204404e-12], sampled 0.527354027407868
[2019-03-27 06:29:04,977] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:29:04,978] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.9, 56.0, 1.0, 2.0, 0.9779537605839114, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005992180073992, 6.9112, 168.9123159328203, 2264144.695338872, 2196896.115330672, 456611.4479851685]
[2019-03-27 06:29:04,980] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:29:04,983] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [3.7514361e-05 1.2340642e-14 9.9996245e-01 3.3654865e-18 1.9407086e-13], sampled 0.1438477517811264
[2019-03-27 06:29:26,480] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:29:26,481] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.15420723, 89.72144402666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9516437220844954, 6.911199999999999, 6.9112, 168.912956510431, 776030.5008261021, 776030.5008261027, 235372.0607516503]
[2019-03-27 06:29:26,483] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:29:26,488] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 6.7703388e-24 2.0832283e-12 2.7271600e-24 5.6114034e-21], sampled 0.6852022946817704
[2019-03-27 06:29:27,761] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:29:27,762] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.76666666666667, 91.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8598641410989889, 6.9112, 6.9112, 168.912956510431, 714527.4904560291, 714527.4904560291, 214479.641921763]
[2019-03-27 06:29:27,763] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:29:27,765] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 5.6818491e-25 4.3367260e-14 6.7742365e-25 6.4945810e-22], sampled 0.7198494884909683
[2019-03-27 06:29:37,307] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.060916148]
[2019-03-27 06:29:37,307] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.03333333333333, 68.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702022065889395, 6.9112, 6.9112, 168.912956510431, 787653.5490731308, 787653.5490731308, 239798.1302797646]
[2019-03-27 06:29:37,310] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:29:37,312] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.8390669e-24 1.5796510e-13 3.0026582e-24 3.0295742e-21], sampled 0.6004510313187118
[2019-03-27 06:30:00,107] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7166.7374 3332634765.2617 2008.0000
[2019-03-27 06:30:00,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7791.7760 3003480817.5398 1336.0000
[2019-03-27 06:30:00,528] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7236.7620 3127391905.5734 1649.0000
[2019-03-27 06:30:00,535] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7947.8948 2952570909.4887 1170.0000
[2019-03-27 06:30:00,694] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6871.3863 3203618582.5184 2171.0000
[2019-03-27 06:30:01,707] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 950000, evaluation results [950000.0, 7166.737388476637, 3332634765.261705, 2008.0, 7236.762024103123, 3127391905.5734477, 1649.0, 7947.894778765221, 2952570909.4886675, 1170.0, 6871.386336148272, 3203618582.5184026, 2171.0, 7791.776003571458, 3003480817.5397964, 1336.0]
[2019-03-27 06:30:08,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.4684156e-08 4.2845383e-16 1.0000000e+00 2.6279373e-20 3.3561272e-17], sum to 1.0000
[2019-03-27 06:30:08,816] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5307
[2019-03-27 06:30:08,825] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3318592.912893478 W.
[2019-03-27 06:30:08,831] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.0, 55.66666666666667, 1.0, 2.0, 0.9402938473430826, 1.0, 2.0, 0.7907369631858041, 1.0, 1.0, 1.03, 7.005116686756659, 6.9112, 170.5573041426782, 3318592.912893478, 3251316.56988312, 607978.7983785031], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4196400.0000, 
sim time next is 4197000.0000, 
raw observation next is [36.0, 56.33333333333333, 1.0, 2.0, 0.8996846911822796, 1.0, 2.0, 0.7704323851054026, 1.0, 2.0, 1.03, 7.005113482393471, 6.9112, 170.5573041426782, 3233267.619656079, 3165993.572061418, 591822.9568192585], 
processed observation next is [1.0, 0.5652173913043478, 0.9052132701421801, 0.5633333333333332, 1.0, 1.0, 0.8791381821473248, 1.0, 1.0, 0.7234125121751838, 1.0, 1.0, 1.0365853658536586, 0.009391348239347064, 0.0, 0.8375144448122397, 0.8981298943489108, 0.8794426589059494, 0.8833178459988933], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5943933], dtype=float32), 0.44512215]. 
=============================================
[2019-03-27 06:30:08,842] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[43.221085]
 [44.718956]
 [46.38187 ]
 [48.563473]
 [49.764297]], R is [[42.54590225]
 [42.12044525]
 [41.69924164]
 [41.28224945]
 [41.14425278]].
[2019-03-27 06:30:12,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.7693400e-01 4.3358820e-15 8.2306600e-01 1.5397417e-18 3.9283699e-13], sum to 1.0000
[2019-03-27 06:30:12,251] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3276
[2019-03-27 06:30:12,256] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 79.0, 1.0, 2.0, 0.4247978976597854, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7304754708130142, 6.911199999999999, 6.9112, 168.912956510431, 1187451.223647226, 1187451.223647227, 269486.9398615913], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4253400.0000, 
sim time next is 4254000.0000, 
raw observation next is [29.0, 79.0, 1.0, 2.0, 0.4315263156688592, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7420528701976304, 6.911199999999999, 6.9112, 168.912956510431, 1206270.070790945, 1206270.070790946, 272559.2732293645], 
processed observation next is [1.0, 0.21739130434782608, 0.5734597156398105, 0.79, 1.0, 1.0, 0.315091946588987, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6854303295093053, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33507501966415143, 0.33507501966415165, 0.4068048854169619], 
reward next is 0.5932, 
noisyNet noise sample is [array([-0.7293215], dtype=float32), 1.6038522]. 
=============================================
[2019-03-27 06:30:12,274] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[45.297596]
 [44.733826]
 [43.66006 ]
 [43.088245]
 [43.036785]], R is [[45.68707275]
 [45.82798386]
 [45.96910858]
 [46.0931778 ]
 [46.2231636 ]].
[2019-03-27 06:30:12,838] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9994338e-01 3.2866257e-16 5.6618534e-05 1.6800205e-17 2.0035244e-13], sum to 1.0000
[2019-03-27 06:30:12,847] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1300
[2019-03-27 06:30:12,851] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.0, 56.0, 1.0, 1.0, 0.2015561363079501, 1.0, 1.0, 0.2015561363079501, 1.0, 2.0, 0.3500363531340744, 6.9112, 6.9112, 170.5573041426782, 844985.0896904174, 844985.0896904174, 270276.2364130357], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3940800.0000, 
sim time next is 3941400.0000, 
raw observation next is [35.0, 56.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.993659324018365, 6.9112, 168.9123425104426, 887323.011846914, 828823.7420034815, 254812.6746246361], 
processed observation next is [0.0, 0.6086956521739131, 0.8578199052132701, 0.56, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.00824593240183651, 0.0, 0.8294369301312693, 0.24647861440192054, 0.2302288172231893, 0.3803174248128897], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.6677439], dtype=float32), -0.17254058]. 
=============================================
[2019-03-27 06:30:13,265] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9999416e-01 7.2610788e-19 5.8812830e-06 7.9179551e-20 1.3782695e-16], sum to 1.0000
[2019-03-27 06:30:13,272] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2806
[2019-03-27 06:30:13,278] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 999165.3220393852 W.
[2019-03-27 06:30:13,284] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.16666666666666, 83.16666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.151249539705332, 6.9112, 168.9115172407031, 999165.3220393852, 828867.3677882332, 254813.1564846141], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3973800.0000, 
sim time next is 3974400.0000, 
raw observation next is [30.0, 84.0, 1.0, 1.0, 0.2155200857654527, 1.0, 1.0, 0.2155200857654527, 1.0, 2.0, 0.3742871153931045, 6.9112, 6.9112, 170.5573041426782, 903550.9060284074, 903550.9060284074, 274305.7090308566], 
processed observation next is [1.0, 0.0, 0.6208530805687204, 0.84, 1.0, 0.5, 0.054843476825846615, 1.0, 0.5, 0.054843476825846615, 1.0, 1.0, 0.2369355065769567, 0.0, 0.0, 0.8375144448122397, 0.2509863627856687, 0.2509863627856687, 0.4094115060162039], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.2086616], dtype=float32), 0.18310447]. 
=============================================
[2019-03-27 06:30:20,986] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.5784569e-23 9.8994216e-12 2.1748468e-23 9.0778949e-20], sum to 1.0000
[2019-03-27 06:30:20,997] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4167
[2019-03-27 06:30:21,002] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9586874047596382, 6.9112, 6.9112, 168.912956510431, 780615.4814059095, 780615.4814059095, 237051.4410620453], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4476000.0000, 
sim time next is 4476600.0000, 
raw observation next is [28.5, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9566249952121423, 6.9112, 6.9112, 168.912956510431, 779418.0187281467, 779418.0187281467, 236565.5947064926], 
processed observation next is [0.0, 0.8260869565217391, 0.5497630331753555, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9471036526977343, 0.0, 0.0, 0.8294399451523027, 0.21650500520226296, 0.21650500520226296, 0.35308297717386955], 
reward next is 0.6469, 
noisyNet noise sample is [array([-0.38715723], dtype=float32), -0.57723063]. 
=============================================
[2019-03-27 06:30:34,038] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.2458314e-03 2.6170158e-12 9.9875414e-01 6.7162238e-16 2.5464761e-11], sum to 1.0000
[2019-03-27 06:30:34,048] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1538
[2019-03-27 06:30:34,053] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 84.0, 1.0, 2.0, 0.7542680580598897, 1.0, 2.0, 0.7542680580598897, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2109324.751845998, 2109324.751845998, 398234.6146980427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4329600.0000, 
sim time next is 4330200.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.7869097426753578, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.005980667339821, 6.9112, 168.9123931862907, 1996753.257523519, 1929512.814261235, 404638.6421276811], 
processed observation next is [1.0, 0.08695652173913043, 0.6208530805687204, 0.84, 1.0, 1.0, 0.7432647502112745, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.009478066733982082, 0.0, 0.8294371789728829, 0.5546536826454219, 0.535975781739232, 0.6039382718323599], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5383345], dtype=float32), 1.5352741]. 
=============================================
[2019-03-27 06:30:36,810] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.1285874e-06 5.8146298e-14 9.9999690e-01 1.2789453e-18 7.6759083e-15], sum to 1.0000
[2019-03-27 06:30:36,818] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5248
[2019-03-27 06:30:36,826] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 3303437.614320516 W.
[2019-03-27 06:30:36,829] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [34.0, 71.0, 1.0, 2.0, 0.9330811373557046, 1.0, 2.0, 0.7871306081921151, 1.0, 1.0, 1.03, 7.005116117588459, 6.9112, 170.5573041426782, 3303437.614320516, 3236161.679028491, 605065.5688358844], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4356000.0000, 
sim time next is 4356600.0000, 
raw observation next is [34.33333333333334, 69.16666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.169258984195008, 6.9112, 170.5573041426782, 3094403.212902507, 2909545.065355293, 552309.9361092214], 
processed observation next is [1.0, 0.43478260869565216, 0.8262243285939973, 0.6916666666666668, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.025805898419500827, 0.0, 0.8375144448122397, 0.8595564480284741, 0.8082069625986925, 0.8243431882227186], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.53105944], dtype=float32), -0.96265167]. 
=============================================
[2019-03-27 06:30:45,725] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.8059134e-26 6.1507443e-17 9.0830931e-27 1.1125205e-23], sum to 1.0000
[2019-03-27 06:30:45,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7440
[2019-03-27 06:30:45,926] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8109927895043542, 6.911200000000001, 6.9112, 168.912956510431, 680519.9560845736, 680519.9560845731, 204131.4506418817], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4507800.0000, 
sim time next is 4508400.0000, 
raw observation next is [26.0, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8152891572257049, 6.9112, 6.9112, 168.912956510431, 683393.7833797967, 683393.7833797967, 205015.5752762454], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.8566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7747428746654937, 0.0, 0.0, 0.8294399451523027, 0.18983160649438796, 0.18983160649438796, 0.3059933959346946], 
reward next is 0.6940, 
noisyNet noise sample is [array([-1.311494], dtype=float32), -1.0259507]. 
=============================================
[2019-03-27 06:30:46,415] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.5093816e-28 5.4886608e-19 1.2745746e-27 5.5790160e-24], sum to 1.0000
[2019-03-27 06:30:46,423] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.2179
[2019-03-27 06:30:46,427] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8429514042008706, 6.9112, 6.9112, 168.912956510431, 702188.4758776496, 702188.4758776496, 210817.3237868299], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4510800.0000, 
sim time next is 4511400.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8465931623651404, 6.9112, 6.9112, 168.912956510431, 704564.6133413261, 704564.6133413261, 211591.5585089658], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8129184906891956, 0.0, 0.0, 0.8294399451523027, 0.19571239259481282, 0.19571239259481282, 0.3158082962820385], 
reward next is 0.6842, 
noisyNet noise sample is [array([1.5602099], dtype=float32), -0.94215375]. 
=============================================
[2019-03-27 06:30:46,743] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.2915139e-29 1.5912705e-19 5.9603096e-29 4.0024561e-25], sum to 1.0000
[2019-03-27 06:30:46,750] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3396
[2019-03-27 06:30:46,757] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.0, 50.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9208821853136087, 6.9112, 6.9112, 168.912956510431, 756955.7034645611, 756955.7034645611, 228211.9650252482], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4543800.0000, 
sim time next is 4544400.0000, 
raw observation next is [34.0, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.893771552728329, 6.9112, 6.9112, 168.912956510431, 733981.123906031, 733981.123906031, 221838.9126299524], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.51, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8704531130833281, 0.0, 0.0, 0.8294399451523027, 0.20388364552945307, 0.20388364552945307, 0.33110285467157075], 
reward next is 0.6689, 
noisyNet noise sample is [array([-0.36810625], dtype=float32), -1.3828121]. 
=============================================
[2019-03-27 06:30:48,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.3863098e-32 1.1710259e-20 4.5406601e-31 3.3470328e-27], sum to 1.0000
[2019-03-27 06:30:48,554] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1526
[2019-03-27 06:30:48,559] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8835999596858953, 6.9112, 6.9112, 168.912956510431, 729770.6637668267, 729770.6637668267, 219668.6554394729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4566600.0000, 
sim time next is 4567200.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8835065310150773, 6.9112, 6.9112, 168.912956510431, 729698.1380788796, 729698.1380788796, 219647.5307074271], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8579347939208258, 0.0, 0.0, 0.8294399451523027, 0.2026939272441332, 0.2026939272441332, 0.32783213538421957], 
reward next is 0.6722, 
noisyNet noise sample is [array([1.2143478], dtype=float32), 0.8552158]. 
=============================================
[2019-03-27 06:30:50,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.5436651e-01 5.1693625e-15 6.4563346e-01 2.2251709e-17 1.1916647e-12], sum to 1.0000
[2019-03-27 06:30:50,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8042
[2019-03-27 06:30:50,622] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.83333333333334, 89.83333333333333, 1.0, 2.0, 0.9787719358586844, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1368112.660358884, 1368112.660358883, 292529.9876098948], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4603800.0000, 
sim time next is 4604400.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 0.5006645008140526, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8694886656334974, 6.911200000000001, 6.9112, 168.912956510431, 1399663.372522734, 1399663.372522734, 308545.2219130759], 
processed observation next is [1.0, 0.30434782608695654, 0.5734597156398105, 0.89, 1.0, 1.0, 0.3983909648362079, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.8408398361384113, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.388795381256315, 0.388795381256315, 0.4605152565866804], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.5083983], dtype=float32), -1.5810932]. 
=============================================
[2019-03-27 06:30:51,088] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.1532803e-01 3.4601198e-15 5.8467197e-01 2.3099957e-17 9.3531194e-13], sum to 1.0000
[2019-03-27 06:30:51,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2718
[2019-03-27 06:30:51,104] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1442261.182112252 W.
[2019-03-27 06:30:51,108] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.66666666666666, 94.0, 1.0, 2.0, 1.031783085521591, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1442261.182112252, 1442261.182112253, 308763.2045752427], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4599600.0000, 
sim time next is 4600200.0000, 
raw observation next is [27.83333333333334, 94.0, 1.0, 2.0, 0.531571952562743, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9231646880704896, 6.911199999999999, 6.9112, 168.912956510431, 1486129.079610583, 1486129.079610584, 325806.5918647916], 
processed observation next is [1.0, 0.21739130434782608, 0.5181674565560824, 0.94, 1.0, 1.0, 0.4356288585093289, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.9062984000859629, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4128136332251619, 0.41281363322516224, 0.4862784953205844], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.17309508], dtype=float32), -0.32034984]. 
=============================================
[2019-03-27 06:30:56,377] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-27 06:30:56,379] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:30:56,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:30:56,382] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:30:56,382] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:30:56,383] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:30:56,384] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:30:56,385] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:30:56,386] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:30:56,387] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:30:56,387] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:30:56,404] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run40
[2019-03-27 06:30:56,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run40
[2019-03-27 06:30:56,427] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run40
[2019-03-27 06:30:56,427] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run40
[2019-03-27 06:30:56,482] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run40
[2019-03-27 06:31:08,932] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:08,935] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.25, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5462848799578471, 6.911199999999999, 6.9112, 168.912956510431, 479914.674252031, 479914.6742520316, 158195.3230036377]
[2019-03-27 06:31:08,936] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:31:08,937] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.0161707e-29 3.4263634e-21 1.0260298e-28 7.0107924e-26], sampled 0.8798629514856926
[2019-03-27 06:31:10,351] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:10,352] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.33786652833334, 71.95308645833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6487988469946427, 6.9112, 6.9112, 168.912956510431, 560271.3376284882, 560271.3376284882, 173887.1109490363]
[2019-03-27 06:31:10,353] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:31:10,356] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.3543553e-30 3.8467542e-21 6.2666372e-29 5.2150294e-26], sampled 0.27356800314941276
[2019-03-27 06:31:16,453] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:16,567] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.76666666666667, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4462726327500133, 6.9112, 6.9112, 168.912956510431, 400373.2727637105, 400373.2727637105, 145384.2278673123]
[2019-03-27 06:31:16,567] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:31:16,569] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.4889145e-29 2.3241504e-20 1.4781989e-28 1.7832890e-25], sampled 0.9112429893637897
[2019-03-27 06:31:25,761] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:25,762] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.42912958, 78.128087935, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7610235938072736, 6.9112, 6.9112, 168.912956510431, 645087.7531548706, 645087.7531548706, 194132.6638141773]
[2019-03-27 06:31:25,763] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:31:25,765] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.1106343e-30 5.1440516e-21 1.7929988e-29 2.5583528e-26], sampled 0.5259472195565065
[2019-03-27 06:31:31,620] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:31,622] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6427077778738816, 6.911199999999999, 6.9112, 168.912956510431, 554261.7831214335, 554261.783121434, 172890.1066025334]
[2019-03-27 06:31:31,626] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:31:31,629] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.4712608e-29 2.6342605e-20 1.3577036e-28 1.4657188e-25], sampled 0.1450932636101816
[2019-03-27 06:31:54,823] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:54,825] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.6, 75.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.294890509809108, 6.9112, 168.9103766444591, 2556127.861465158, 2283928.765652762, 475254.459269111]
[2019-03-27 06:31:54,827] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:31:54,831] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.80492154e-03 1.71787958e-13 9.98195112e-01 1.02882045e-16
 2.13876074e-12], sampled 0.6743784899055739
[2019-03-27 06:31:54,832] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 2556127.861465158 W.
[2019-03-27 06:31:59,318] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:31:59,319] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.8, 56.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9208070053298844, 6.9112, 6.9112, 168.912956510431, 754499.9337200961, 754499.9337200961, 228093.2598574008]
[2019-03-27 06:31:59,319] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:31:59,322] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.2655429e-29 4.0311835e-19 4.2160256e-29 2.1792046e-25], sampled 0.26428423828193914
[2019-03-27 06:32:16,123] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.061141048]
[2019-03-27 06:32:16,124] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.33528061, 73.70646924, 1.0, 2.0, 0.8545390825398265, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005984934766083, 6.9112, 168.9123159933832, 2091405.713024534, 2024162.273043527, 421778.6973457881]
[2019-03-27 06:32:16,125] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:32:16,128] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.1092086e-01 4.6936515e-14 5.8907914e-01 2.9661224e-17 5.1835463e-12], sampled 0.5649275959014248
[2019-03-27 06:32:51,355] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7230.6621 3110459482.7070 1904.0000
[2019-03-27 06:32:51,504] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7863.0282 2991753246.9928 1500.0000
[2019-03-27 06:32:51,599] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7238.0672 3321873422.8043 2113.0000
[2019-03-27 06:32:51,767] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7994.7751 2940762884.3469 1329.0000
[2019-03-27 06:32:51,828] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6938.3331 3188986929.2249 2383.0000
[2019-03-27 06:32:52,843] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 975000, evaluation results [975000.0, 7238.067231033664, 3321873422.8043437, 2113.0, 7230.662058150139, 3110459482.706994, 1904.0, 7994.775109546225, 2940762884.346944, 1329.0, 6938.333080812712, 3188986929.22495, 2383.0, 7863.028204314617, 2991753246.9928026, 1500.0]
[2019-03-27 06:32:53,124] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2344316e-03 4.7738320e-15 9.9876559e-01 6.0601676e-19 1.4432500e-13], sum to 1.0000
[2019-03-27 06:32:53,132] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9010
[2019-03-27 06:32:53,138] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2757918.745478441 W.
[2019-03-27 06:32:53,143] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.563547428789995, 6.9112, 168.9089680068813, 2757918.745478441, 2295131.955367227, 475196.7838459346], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4716000.0000, 
sim time next is 4716600.0000, 
raw observation next is [30.83333333333334, 67.5, 1.0, 2.0, 0.8111434536162053, 1.0, 1.0, 0.8111434536162053, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2268537.83292142, 2268537.83292142, 425331.1519584621], 
processed observation next is [1.0, 0.6086956521739131, 0.6603475513428123, 0.675, 1.0, 1.0, 0.7724619923086811, 1.0, 0.5, 0.7724619923086811, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6301493980337278, 0.6301493980337278, 0.6348226148633762], 
reward next is 0.3652, 
noisyNet noise sample is [array([-0.4598115], dtype=float32), -0.3679882]. 
=============================================
[2019-03-27 06:33:05,699] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.5406657e-28 2.3939821e-17 1.1213037e-27 8.2721564e-24], sum to 1.0000
[2019-03-27 06:33:05,709] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9591
[2019-03-27 06:33:05,715] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8495677518901128, 6.9112, 6.9112, 168.912956510431, 705417.6133108041, 705417.6133108041, 212192.8008506562], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4930800.0000, 
sim time next is 4931400.0000, 
raw observation next is [26.16666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8464435658898327, 6.9112, 6.9112, 168.912956510431, 703294.5079751044, 703294.5079751044, 211524.4514900551], 
processed observation next is [1.0, 0.043478260869565216, 0.4391785150078992, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8127360559632105, 0.0, 0.0, 0.8294399451523027, 0.1953595855486401, 0.1953595855486401, 0.31570813655232105], 
reward next is 0.6843, 
noisyNet noise sample is [array([-0.9455106], dtype=float32), 1.1357358]. 
=============================================
[2019-03-27 06:33:08,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1600740e-01 6.7787437e-14 5.8399260e-01 3.7617885e-17 4.3595188e-12], sum to 1.0000
[2019-03-27 06:33:08,099] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4744
[2019-03-27 06:33:08,105] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.8, 63.0, 1.0, 2.0, 0.9821556637214165, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977747519649072, 6.9112, 168.9125065799377, 2270025.887645834, 2222814.912573304, 458852.95113633], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4978800.0000, 
sim time next is 4979400.0000, 
raw observation next is [30.83333333333334, 63.0, 1.0, 2.0, 0.8768761166476549, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.978110490749307, 6.9112, 168.9125041199685, 2122669.960556595, 2075201.482670276, 428702.1143960209], 
processed observation next is [1.0, 0.6521739130434783, 0.6603475513428123, 0.63, 1.0, 1.0, 0.8516579718646444, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0066910490749307, 0.0, 0.8294377237080266, 0.5896305445990542, 0.5764448562972989, 0.6398539020836133], 
reward next is 0.0256, 
noisyNet noise sample is [array([-0.6816162], dtype=float32), -0.8436565]. 
=============================================
[2019-03-27 06:33:10,163] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.1021260e-30 9.1672558e-21 2.7047937e-30 2.5489815e-26], sum to 1.0000
[2019-03-27 06:33:10,171] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7872
[2019-03-27 06:33:10,178] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8188843242721524, 6.9112, 6.9112, 168.912956510431, 684405.3479702373, 684405.3479702373, 205724.3230551671], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5000400.0000, 
sim time next is 5001000.0000, 
raw observation next is [27.0, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8202848703641836, 6.9112, 6.9112, 168.912956510431, 685940.7219201197, 685940.7219201197, 206029.4165845611], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7808352077611995, 0.0, 0.0, 0.8294399451523027, 0.19053908942225548, 0.19053908942225548, 0.3075065919172554], 
reward next is 0.6925, 
noisyNet noise sample is [array([-0.19430186], dtype=float32), 0.1474567]. 
=============================================
[2019-03-27 06:33:10,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.06484 ]
 [63.46691 ]
 [63.007515]
 [63.173347]
 [62.994873]], R is [[64.34669495]
 [64.3961792 ]
 [64.44165802]
 [64.4832077 ]
 [64.52122498]].
[2019-03-27 06:33:11,259] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.3204215e-34 3.3896402e-27 5.1361603e-32 9.3596170e-30], sum to 1.0000
[2019-03-27 06:33:11,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6402
[2019-03-27 06:33:11,272] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8539647278073613, 6.911199999999999, 6.9112, 168.912956510431, 708880.172886724, 708880.1728867247, 213152.5304202729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5035200.0000, 
sim time next is 5035800.0000, 
raw observation next is [26.83333333333333, 84.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8568108960277343, 6.9112, 6.9112, 168.912956510431, 710784.0142643537, 710784.0142643537, 213765.6612260253], 
processed observation next is [0.0, 0.2608695652173913, 0.470774091627172, 0.8483333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.825379141497237, 0.0, 0.0, 0.8294399451523027, 0.19744000396232048, 0.19744000396232048, 0.3190532257104855], 
reward next is 0.6809, 
noisyNet noise sample is [array([0.46422684], dtype=float32), 0.77758026]. 
=============================================
[2019-03-27 06:33:16,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.9314642e-32 7.0202199e-24 3.1302855e-31 1.1858828e-28], sum to 1.0000
[2019-03-27 06:33:16,428] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1121
[2019-03-27 06:33:16,434] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8757498500277652, 6.9112, 6.9112, 168.912956510431, 723918.9855987724, 723918.9855987724, 217910.3570406907], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5124600.0000, 
sim time next is 5125200.0000, 
raw observation next is [28.33333333333334, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8802517230874716, 6.9112, 6.9112, 168.912956510431, 726903.3764013159, 726903.3764013159, 218903.3914011771], 
processed observation next is [0.0, 0.30434782608695654, 0.5418641390205374, 0.7733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8539655159603312, 0.0, 0.0, 0.8294399451523027, 0.2019176045559211, 0.2019176045559211, 0.3267214797032494], 
reward next is 0.6733, 
noisyNet noise sample is [array([1.0083556], dtype=float32), 0.35420477]. 
=============================================
[2019-03-27 06:33:41,113] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.3448769e-32 6.4146574e-22 1.3567379e-32 1.9025049e-26], sum to 1.0000
[2019-03-27 06:33:41,118] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2147
[2019-03-27 06:33:41,128] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.53333333333334, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9413913528740723, 6.9112, 6.9112, 168.912956510431, 767906.2771858174, 767906.2771858174, 232880.9396680853], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5526600.0000, 
sim time next is 5527200.0000, 
raw observation next is [27.46666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9406478919604319, 6.911199999999999, 6.9112, 168.912956510431, 767355.8177284313, 767355.817728432, 232703.207944019], 
processed observation next is [1.0, 1.0, 0.500789889415482, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.927619380439551, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21315439381345314, 0.21315439381345333, 0.34731822081196867], 
reward next is 0.6527, 
noisyNet noise sample is [array([-0.5168152], dtype=float32), -0.554822]. 
=============================================
[2019-03-27 06:33:45,641] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6363722e-29 1.5884487e-21 8.5374236e-29 5.3405742e-26], sum to 1.0000
[2019-03-27 06:33:45,650] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1814
[2019-03-27 06:33:45,655] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.86666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9133316096659317, 6.911199999999999, 6.9112, 168.912956510431, 750132.0239185579, 750132.0239185586, 226399.5458220344], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5793600.0000, 
sim time next is 5794200.0000, 
raw observation next is [26.85, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.912333174402092, 6.911199999999999, 6.9112, 168.912956510431, 749495.9534510219, 749495.9534510225, 226172.0105084427], 
processed observation next is [1.0, 0.043478260869565216, 0.4715639810426541, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8930892370757219, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20819332040306165, 0.2081933204030618, 0.3375701649379742], 
reward next is 0.6624, 
noisyNet noise sample is [array([0.8625858], dtype=float32), -0.34454185]. 
=============================================
[2019-03-27 06:33:46,561] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.1745872e-33 6.6323949e-26 1.7417878e-31 2.0620449e-29], sum to 1.0000
[2019-03-27 06:33:46,568] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0041
[2019-03-27 06:33:46,575] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666667, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8782198121311932, 6.911199999999999, 6.9112, 168.912956510431, 725144.1962427127, 725144.1962427133, 218439.7202048135], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5643600.0000, 
sim time next is 5644200.0000, 
raw observation next is [28.33333333333333, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8822007284026254, 6.911199999999999, 6.9112, 168.912956510431, 727809.5592404163, 727809.5592404169, 219320.5408352973], 
processed observation next is [0.0, 0.30434782608695654, 0.541864139020537, 0.7766666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8563423517105189, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20216932201122675, 0.2021693220112269, 0.32734409079895116], 
reward next is 0.6727, 
noisyNet noise sample is [array([-1.1787301], dtype=float32), -1.6395079]. 
=============================================
[2019-03-27 06:33:47,410] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-27 06:33:47,413] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:33:47,414] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:33:47,414] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:33:47,415] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:33:47,415] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:33:47,415] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:33:47,416] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:33:47,416] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:33:47,418] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:33:47,418] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:33:47,749] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run41
[2019-03-27 06:33:47,797] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run41
[2019-03-27 06:33:47,814] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run41
[2019-03-27 06:33:47,882] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run41
[2019-03-27 06:33:47,888] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run41
[2019-03-27 06:33:54,827] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:33:54,829] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.4, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.462478756795475, 6.9112, 6.9112, 168.912956510431, 413840.0250766923, 413840.0250766923, 147270.1761149173]
[2019-03-27 06:33:54,831] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:33:54,834] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.1968055e-31 1.2602416e-24 2.5877655e-29 4.3398501e-27], sampled 0.16814495288558784
[2019-03-27 06:34:05,770] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:34:05,771] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.169843285, 74.21344756833332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6038818001576362, 6.9112, 6.9112, 168.912956510431, 528437.2711289066, 528437.2711289066, 166613.5059236808]
[2019-03-27 06:34:05,771] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:34:05,773] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 1.32447580e-31 1.13490825e-24 4.13957577e-30
 1.37649921e-27], sampled 0.16134040593028498
[2019-03-27 06:34:20,785] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:34:20,787] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [23.2, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6507236656529365, 6.9112, 6.9112, 168.912956510431, 564024.4591096232, 564024.4591096232, 174184.0901686122]
[2019-03-27 06:34:20,790] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:34:20,793] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.3095169e-33 8.9297329e-26 5.6122073e-32 4.0015016e-29], sampled 0.47342064872963785
[2019-03-27 06:34:28,087] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:34:28,088] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.50394835333333, 96.95226275333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6629724095458769, 6.9112, 6.9112, 168.912956510431, 571791.8286257549, 571791.8286257549, 176265.0611614233]
[2019-03-27 06:34:28,089] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:34:28,092] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.0407042e-33 4.9544711e-26 3.0980683e-31 8.8433780e-29], sampled 0.09433938381847029
[2019-03-27 06:34:37,218] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:34:37,221] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.18385332833333, 86.13041056666665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9294994830147638, 6.911199999999999, 6.9112, 168.912956510431, 761735.0677191453, 761735.067719146, 230172.3310039565]
[2019-03-27 06:34:37,222] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:34:37,226] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 9.6100848e-31 2.1603104e-23 1.3985531e-29 7.4407448e-27], sampled 0.5246103084269855
[2019-03-27 06:35:01,027] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:35:01,030] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 68.66666666666667, 1.0, 2.0, 0.7905213054151617, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.982344009311955, 6.9112, 168.9125124286981, 2001807.702153228, 1951335.82605327, 406361.5238035598]
[2019-03-27 06:35:01,031] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:35:01,033] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9975377e-01 5.0815865e-15 2.4621029e-04 5.2190421e-17 1.8795284e-12], sampled 0.9517439778377348
[2019-03-27 06:35:01,037] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2001807.702153228 W.
[2019-03-27 06:35:26,802] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.05998559]
[2019-03-27 06:35:26,803] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.15638508, 78.64049263999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5483773927447463, 6.9112, 6.9112, 168.912956510431, 482891.4641458515, 482891.4641458515, 158445.3161103875]
[2019-03-27 06:35:26,804] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:35:26,807] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.5854522e-32 5.8573593e-25 3.0320229e-30 1.0411906e-27], sampled 0.0768719219957309
[2019-03-27 06:35:43,769] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7314.9462 3106781891.4887 1986.0000
[2019-03-27 06:35:44,134] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7912.3844 2989679897.5692 1548.0000
[2019-03-27 06:35:44,138] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8049.0585 2938232924.3361 1370.0000
[2019-03-27 06:35:44,148] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7008.5745 3185825508.3484 2436.0000
[2019-03-27 06:35:44,223] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7278.1797 3320646341.3955 2139.0000
[2019-03-27 06:35:45,242] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1000000, evaluation results [1000000.0, 7278.179742577459, 3320646341.395497, 2139.0, 7314.946165381508, 3106781891.488672, 1986.0, 8049.058544504463, 2938232924.336112, 1370.0, 7008.574455122986, 3185825508.3483872, 2436.0, 7912.384374105778, 2989679897.5691934, 1548.0]
[2019-03-27 06:35:51,978] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.4511287e-35 4.9703888e-27 2.0055177e-33 1.3244468e-29], sum to 1.0000
[2019-03-27 06:35:51,991] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2190
[2019-03-27 06:35:51,996] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9331640532414811, 6.911200000000001, 6.9112, 168.912956510431, 763110.3419035353, 763110.3419035347, 230981.1236944488], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5776800.0000, 
sim time next is 5777400.0000, 
raw observation next is [27.95, 83.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9328506758324578, 6.9112, 6.9112, 168.912956510431, 762846.3371070576, 762846.3371070576, 230905.3647945168], 
processed observation next is [0.0, 0.8695652173913043, 0.523696682464455, 0.8366666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.918110580283485, 0.0, 0.0, 0.8294399451523027, 0.21190176030751598, 0.21190176030751598, 0.344634872827637], 
reward next is 0.6554, 
noisyNet noise sample is [array([0.72639257], dtype=float32), -0.03396239]. 
=============================================
[2019-03-27 06:36:06,274] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9884319e-01 6.6590401e-15 1.1567434e-03 2.1896176e-17 1.5742300e-11], sum to 1.0000
[2019-03-27 06:36:06,281] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9481
[2019-03-27 06:36:06,288] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 869552.7207686984 W.
[2019-03-27 06:36:06,295] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.2, 92.66666666666667, 1.0, 2.0, 0.3111208982518218, 1.0, 1.0, 0.3111208982518218, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 869552.7207686984, 869552.7207686984, 252057.4515711097], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5980800.0000, 
sim time next is 5981400.0000, 
raw observation next is [26.35, 92.0, 1.0, 2.0, 0.3085714395671575, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5250539813193333, 6.911199999999999, 6.9112, 168.912956510431, 862427.7418368065, 862427.7418368072, 223603.5391886586], 
processed observation next is [1.0, 0.21739130434782608, 0.4478672985781992, 0.92, 1.0, 1.0, 0.16695354164717768, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.42079753819430893, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.23956326162133515, 0.23956326162133534, 0.3337366256547143], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2155409], dtype=float32), 0.7216017]. 
=============================================
[2019-03-27 06:36:12,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.9408850e-34 6.3021993e-26 5.4466983e-33 9.1077528e-29], sum to 1.0000
[2019-03-27 06:36:12,998] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2372
[2019-03-27 06:36:13,001] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9160408522700951, 6.911199999999999, 6.9112, 168.912956510431, 750856.6674212178, 750856.6674212184, 226975.6766372137], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6129600.0000, 
sim time next is 6130200.0000, 
raw observation next is [27.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9151938707920577, 6.9112, 6.9112, 168.912956510431, 750159.5033260094, 750159.5033260094, 226775.5701399312], 
processed observation next is [1.0, 0.9565217391304348, 0.4928909952606636, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8965778912098264, 0.0, 0.0, 0.8294399451523027, 0.20837763981278037, 0.20837763981278037, 0.3384710002088525], 
reward next is 0.6615, 
noisyNet noise sample is [array([2.4275975], dtype=float32), 1.0822248]. 
=============================================
[2019-03-27 06:36:21,944] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.3527603e-37 5.0765764e-31 2.5922824e-35 7.9477606e-32], sum to 1.0000
[2019-03-27 06:36:21,955] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8998
[2019-03-27 06:36:21,961] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.73333333333333, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9056497929145314, 6.9112, 6.9112, 168.912956510431, 742362.8257202517, 742362.8257202517, 224536.4912100736], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6265200.0000, 
sim time next is 6265800.0000, 
raw observation next is [30.75, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9012835639614187, 6.9112, 6.9112, 168.912956510431, 739583.8760587026, 739583.8760587026, 223553.3738784163], 
processed observation next is [0.0, 0.5217391304347826, 0.6563981042654029, 0.655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.879614102391974, 0.0, 0.0, 0.8294399451523027, 0.20543996557186184, 0.20543996557186184, 0.3336617520573378], 
reward next is 0.6663, 
noisyNet noise sample is [array([2.0257773], dtype=float32), 2.2657223]. 
=============================================
[2019-03-27 06:36:26,136] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7793854e-36 4.9228810e-32 9.0839526e-36 4.6529518e-31], sum to 1.0000
[2019-03-27 06:36:26,143] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2003
[2019-03-27 06:36:26,149] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8718286009887694, 6.911200000000001, 6.9112, 168.912956510431, 721685.9310168013, 721685.9310168006, 217061.7911815077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6372000.0000, 
sim time next is 6372600.0000, 
raw observation next is [28.43333333333333, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8748149158594757, 6.9112, 6.9112, 168.912956510431, 723873.1352450701, 723873.1352450701, 217724.7152373997], 
processed observation next is [0.0, 0.782608695652174, 0.546603475513428, 0.7566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8473352632432629, 0.0, 0.0, 0.8294399451523027, 0.20107587090140835, 0.20107587090140835, 0.3249622615483578], 
reward next is 0.6750, 
noisyNet noise sample is [array([-0.2530893], dtype=float32), -0.41832265]. 
=============================================
[2019-03-27 06:36:28,399] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.3603864e-32 5.3916493e-25 1.7401141e-31 5.9059512e-27], sum to 1.0000
[2019-03-27 06:36:28,409] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0377
[2019-03-27 06:36:28,413] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8066614532899028, 6.9112, 6.9112, 168.912956510431, 675018.9527168088, 675018.9527168088, 203186.0015318895], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6552000.0000, 
sim time next is 6552600.0000, 
raw observation next is [27.95, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8101081424970168, 6.911199999999999, 6.9112, 168.912956510431, 677749.9294035789, 677749.9294035796, 203899.9430481207], 
processed observation next is [1.0, 0.8695652173913043, 0.523696682464455, 0.7366666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7684245640207521, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1882638692787719, 0.1882638692787721, 0.3043282732061503], 
reward next is 0.6957, 
noisyNet noise sample is [array([0.54564047], dtype=float32), 1.057396]. 
=============================================
[2019-03-27 06:36:31,746] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.6611917e-01 1.8960858e-14 3.3880804e-02 8.5484385e-17 4.4804080e-10], sum to 1.0000
[2019-03-27 06:36:31,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9070
[2019-03-27 06:36:31,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2066569.086350555 W.
[2019-03-27 06:36:31,772] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.4926626012262582, 1.0, 1.0, 0.4926626012262582, 1.0, 2.0, 0.8463317097332471, 6.9112, 6.9112, 170.5573041426782, 2066569.086350555, 2066569.086350555, 408457.1650647753], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6438000.0000, 
sim time next is 6438600.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.6893524779472874, 1.0, 2.0, 0.6893524779472874, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1927623.79244055, 1927623.79244055, 369596.1200506085], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.6257258770449245, 1.0, 1.0, 0.6257258770449245, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5354510534557083, 0.5354510534557083, 0.551636000075535], 
reward next is 0.4484, 
noisyNet noise sample is [array([-0.06302026], dtype=float32), 0.04689899]. 
=============================================
[2019-03-27 06:36:32,318] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0462438e-33 5.3804050e-27 2.7554460e-32 3.7252471e-28], sum to 1.0000
[2019-03-27 06:36:32,325] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9803
[2019-03-27 06:36:32,328] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.66666666666666, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8673480231168906, 6.9112, 6.9112, 168.912956510431, 717713.5278245476, 717713.5278245476, 216047.9655114819], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6469800.0000, 
sim time next is 6470400.0000, 
raw observation next is [27.63333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8721336245020967, 6.911200000000001, 6.9112, 168.912956510431, 721205.5108399327, 721205.5108399321, 217105.0419794796], 
processed observation next is [1.0, 0.9130434782608695, 0.5086887835703, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8440653957342643, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20033486412220353, 0.20033486412220336, 0.32403737608877553], 
reward next is 0.6760, 
noisyNet noise sample is [array([-0.4217142], dtype=float32), 1.2090832]. 
=============================================
[2019-03-27 06:36:39,644] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-27 06:36:39,645] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:36:39,646] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:36:39,646] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:36:39,647] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:36:39,646] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:36:39,649] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:36:39,650] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:36:39,648] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:36:39,648] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:36:39,652] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:36:39,673] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run42
[2019-03-27 06:36:39,693] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run42
[2019-03-27 06:36:39,694] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run42
[2019-03-27 06:36:39,735] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run42
[2019-03-27 06:36:39,751] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run42
[2019-03-27 06:36:47,788] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:36:47,789] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.4, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5256281368636145, 6.911199999999999, 6.9112, 168.912956510431, 464776.1418924236, 464776.1418924242, 155305.8465813574]
[2019-03-27 06:36:47,790] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:36:47,795] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.0972933e-35 3.2071383e-29 1.4930032e-33 1.6002107e-29], sampled 0.4688898104388759
[2019-03-27 06:36:49,356] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:36:49,357] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.73333333333333, 44.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6680780279791745, 6.911199999999999, 6.9112, 168.912956510431, 587678.1945074529, 587678.1945074535, 176897.7431782983]
[2019-03-27 06:36:49,359] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:36:49,361] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.3563439e-34 5.5608805e-28 3.0171822e-32 3.1964407e-28], sampled 0.7755574969133568
[2019-03-27 06:37:19,066] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:37:19,069] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.59280885, 93.02131657333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5888119994621979, 6.911200000000001, 6.9112, 168.912956510431, 515661.0714374046, 515661.071437404, 164328.2416268476]
[2019-03-27 06:37:19,070] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:37:19,073] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.5242887e-36 5.1318175e-30 2.8135861e-34 3.4827885e-30], sampled 0.4786523599351784
[2019-03-27 06:37:22,802] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:37:22,804] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.01666666666667, 89.0, 1.0, 2.0, 0.770785511119546, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1077244.888244312, 1077244.888244312, 236863.747831607]
[2019-03-27 06:37:22,805] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:37:22,807] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 3.41949518e-21 7.11432345e-12 4.26892849e-22
 1.03374025e-16], sampled 0.08032920057396986
[2019-03-27 06:37:22,809] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1077244.888244312 W.
[2019-03-27 06:37:39,846] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:37:39,847] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.6, 63.0, 1.0, 1.0, 0.6341289713845958, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129006706775, 886174.8985951394, 886174.8985951394, 207272.7423132429]
[2019-03-27 06:37:39,851] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:37:39,856] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.1698180e-24 1.5929795e-16 7.5183020e-25 5.8151850e-20], sampled 0.43867664028876474
[2019-03-27 06:37:39,857] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 886174.8985951394 W.
[2019-03-27 06:37:48,211] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:37:48,213] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.808956498556597, 6.911200000000001, 6.9112, 168.912956510431, 677301.663182531, 677301.6631825304, 203672.1329520313]
[2019-03-27 06:37:48,215] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:37:48,217] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 6.2157910e-34 2.8085027e-27 1.4130140e-32 4.4613609e-28], sampled 0.25234710131806826
[2019-03-27 06:37:54,306] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:37:54,308] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.56129336, 71.8070043, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8753695282542194, 6.9112, 6.9112, 168.912956510431, 724586.5444223064, 724586.5444223064, 217858.2183358789]
[2019-03-27 06:37:54,309] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:37:54,315] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 3.23997245e-28 1.53540797e-20 1.13522265e-27
 2.83610200e-23], sampled 0.8718382831196932
[2019-03-27 06:38:05,356] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:38:05,357] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.86666666666667, 94.0, 1.0, 2.0, 0.9569089374183857, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1337533.639434459, 1337533.639434459, 286070.3225936237]
[2019-03-27 06:38:05,359] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:38:05,362] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9994969e-01 2.1455512e-15 5.0350296e-05 2.4462593e-17 1.0994100e-11], sampled 0.5350424448329634
[2019-03-27 06:38:05,363] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1337533.639434459 W.
[2019-03-27 06:38:27,277] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.059948046]
[2019-03-27 06:38:27,278] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.12080637, 87.98433771, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7675352236842042, 6.9112, 6.9112, 168.912956510431, 676160.0405495547, 676160.0405495547, 195113.6839546707]
[2019-03-27 06:38:27,279] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:38:27,283] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.2691200e-29 2.9314379e-22 8.1376456e-29 1.1250244e-24], sampled 0.6257285405920898
[2019-03-27 06:38:33,930] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7347.6467 3105739550.3141 2010.0000
[2019-03-27 06:38:34,517] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.7084 3319649539.7138 2143.0000
[2019-03-27 06:38:34,563] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.1718 2937986022.1374 1381.0000
[2019-03-27 06:38:34,679] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.0099 3185170740.5601 2464.0000
[2019-03-27 06:38:34,695] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.1538 2989401309.0419 1566.0000
[2019-03-27 06:38:35,711] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1025000, evaluation results [1025000.0, 7286.708372784596, 3319649539.7137733, 2143.0, 7347.646691968014, 3105739550.314067, 2010.0, 8060.171835763581, 2937986022.137388, 1381.0, 7030.009894869936, 3185170740.5600514, 2464.0, 7923.153766730348, 2989401309.041934, 1566.0]
[2019-03-27 06:38:39,299] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.6978863e-31 3.8364773e-23 1.3838046e-30 3.6393719e-26], sum to 1.0000
[2019-03-27 06:38:39,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-27 06:38:39,320] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.9, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8053803581054079, 6.911199999999999, 6.9112, 168.912956510431, 673699.2212934479, 673699.2212934486, 202914.1071715893], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7066800.0000, 
sim time next is 7067400.0000, 
raw observation next is [26.76666666666667, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8070546466180054, 6.9112, 6.9112, 168.912956510431, 675095.4923229417, 675095.4923229417, 203261.6116370539], 
processed observation next is [1.0, 0.8260869565217391, 0.46761453396524505, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7647007885585431, 0.0, 0.0, 0.8294399451523027, 0.18752652564526157, 0.18752652564526157, 0.3033755397567969], 
reward next is 0.6966, 
noisyNet noise sample is [array([-1.8176239], dtype=float32), -0.6372365]. 
=============================================
[2019-03-27 06:38:40,823] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.9923632e-26 1.4238526e-16 7.5531965e-26 4.4952189e-21], sum to 1.0000
[2019-03-27 06:38:40,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2222
[2019-03-27 06:38:40,837] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.68333333333334, 94.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9171625295921788, 6.911200000000001, 6.9112, 168.912956510431, 769005.48115764, 769005.4811576394, 227827.7413789804], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6671400.0000, 
sim time next is 6672000.0000, 
raw observation next is [24.76666666666667, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8588266756571971, 6.911199999999999, 6.9112, 168.912956510431, 719620.7323303864, 719620.7323303871, 214413.2521031964], 
processed observation next is [1.0, 0.21739130434782608, 0.3728278041074251, 0.9466666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8278374093380451, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19989464786955177, 0.19989464786955197, 0.3200197792585021], 
reward next is 0.6800, 
noisyNet noise sample is [array([-0.05026053], dtype=float32), -0.47821626]. 
=============================================
[2019-03-27 06:38:40,849] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[56.56225 ]
 [55.71191 ]
 [54.60383 ]
 [53.592445]
 [50.941986]], R is [[57.86355972]
 [57.94488144]
 [58.01677322]
 [58.0970192 ]
 [58.17008972]].
[2019-03-27 06:38:42,282] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999964e-01 8.6610659e-19 3.5540415e-07 2.6352631e-21 6.9624062e-14], sum to 1.0000
[2019-03-27 06:38:42,297] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0413
[2019-03-27 06:38:42,303] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2056277.059715086 W.
[2019-03-27 06:38:42,308] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.06666666666667, 62.0, 1.0, 2.0, 0.4902113718481066, 1.0, 1.0, 0.4902113718481066, 1.0, 2.0, 0.8290468772030869, 6.911200000000001, 6.9112, 170.5573041426782, 2056277.059715086, 2056277.059715085, 404431.3557701226], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6705600.0000, 
sim time next is 6706200.0000, 
raw observation next is [30.03333333333333, 62.5, 1.0, 2.0, 0.8444504320053732, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.967148233345509, 6.9112, 168.9126229957965, 2077285.332237396, 2037593.808282639, 420386.2248635026], 
processed observation next is [1.0, 0.6086956521739131, 0.622432859399684, 0.625, 1.0, 1.0, 0.8125908819341845, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005594823334550902, 0.0, 0.8294383074427637, 0.5770237033992767, 0.5659982800785108, 0.6274421266619442], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.02057763], dtype=float32), 0.3279978]. 
=============================================
[2019-03-27 06:38:48,591] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9994278e-01 1.6444932e-16 5.7234458e-05 2.9623015e-18 3.2237620e-12], sum to 1.0000
[2019-03-27 06:38:48,598] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5903
[2019-03-27 06:38:48,609] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1273570.733744867 W.
[2019-03-27 06:38:48,614] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.76666666666667, 49.0, 1.0, 2.0, 0.4109608197832159, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7327610763291486, 6.9112, 6.9112, 168.912956510431, 1273570.733744867, 1273570.733744867, 275605.1069290498], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6784800.0000, 
sim time next is 6785400.0000, 
raw observation next is [28.83333333333333, 48.5, 1.0, 2.0, 0.4174471142720917, 1.0, 1.0, 0.4174471142720917, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1285805.341082377, 1285805.341082377, 289897.0194161918], 
processed observation next is [1.0, 0.5217391304347826, 0.5655608214849919, 0.485, 1.0, 1.0, 0.2981290533398695, 1.0, 0.5, 0.2981290533398695, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.35716815030066024, 0.35716815030066024, 0.4326821185316295], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7319072], dtype=float32), 0.14835316]. 
=============================================
[2019-03-27 06:38:50,868] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.1335502e-27 4.0377726e-18 1.1738489e-26 1.6110407e-20], sum to 1.0000
[2019-03-27 06:38:50,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6475
[2019-03-27 06:38:50,881] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9811203970489223, 6.9112, 6.9112, 168.912956510431, 829710.3152231632, 829710.3152231632, 243730.3810009131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7020000.0000, 
sim time next is 7020600.0000, 
raw observation next is [26.05, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.998287131366037, 6.9112, 168.9123394085981, 933005.6137451218, 871223.231161153, 256529.0951782389], 
processed observation next is [1.0, 0.2608695652173913, 0.43364928909952616, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.008708713136603662, 0.0, 0.8294369148997927, 0.2591682260403116, 0.24200645310032026, 0.3828792465346849], 
reward next is 0.1817, 
noisyNet noise sample is [array([-0.46244183], dtype=float32), 1.2140219]. 
=============================================
[2019-03-27 06:39:07,026] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 7.0906830e-31 8.8430091e-21 8.0236213e-30 2.8047505e-23], sum to 1.0000
[2019-03-27 06:39:07,035] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4784
[2019-03-27 06:39:07,040] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8843154509908262, 6.9112, 6.9112, 168.912956510431, 747102.4655124352, 747102.4655124352, 220282.1314753329], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7106400.0000, 
sim time next is 7107000.0000, 
raw observation next is [25.16666666666667, 86.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8887704302357866, 6.911199999999999, 6.9112, 168.912956510431, 750799.7312878654, 750799.731287866, 221303.8524639108], 
processed observation next is [1.0, 0.2608695652173913, 0.39178515007898923, 0.8683333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.864354183214374, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20855548091329595, 0.20855548091329612, 0.3303042574088221], 
reward next is 0.6697, 
noisyNet noise sample is [array([0.69384766], dtype=float32), 1.1464461]. 
=============================================
[2019-03-27 06:39:07,056] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[65.4188 ]
 [65.32103]
 [65.26818]
 [64.8849 ]
 [64.98101]], R is [[65.61721802]
 [65.63226318]
 [65.6475296 ]
 [65.66048431]
 [65.67193604]].
[2019-03-27 06:39:08,167] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9976164e-01 5.4371829e-17 2.3830733e-04 1.4786266e-18 4.2427719e-12], sum to 1.0000
[2019-03-27 06:39:08,175] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5764
[2019-03-27 06:39:08,182] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1308127.459005026 W.
[2019-03-27 06:39:08,188] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.2, 76.0, 1.0, 2.0, 0.935883887538747, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1308127.459005026, 1308127.459005026, 279995.0030019699], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7131600.0000, 
sim time next is 7132200.0000, 
raw observation next is [27.08333333333334, 76.83333333333334, 1.0, 2.0, 0.4413705242321673, 1.0, 1.0, 0.4413705242321673, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1233797.22459071, 1233797.22459071, 283039.5619677277], 
processed observation next is [1.0, 0.5652173913043478, 0.4826224328594, 0.7683333333333334, 1.0, 1.0, 0.3269524388339366, 1.0, 0.5, 0.3269524388339366, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3427214512751972, 0.3427214512751972, 0.422447107414519], 
reward next is 0.5776, 
noisyNet noise sample is [array([0.95318407], dtype=float32), 1.0404584]. 
=============================================
[2019-03-27 06:39:10,493] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.7078503e-36 8.9977011e-28 2.0018184e-33 5.6462946e-29], sum to 1.0000
[2019-03-27 06:39:10,501] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4449
[2019-03-27 06:39:10,505] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.65, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6974775713721333, 6.9112, 6.9112, 168.912956510431, 595491.0337763424, 595491.0337763424, 182273.8850180353], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7512600.0000, 
sim time next is 7513200.0000, 
raw observation next is [23.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6970182214624043, 6.911200000000001, 6.9112, 168.912956510431, 595147.389344456, 595147.3893444554, 182192.0688801594], 
processed observation next is [0.0, 1.0, 0.3175355450236968, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6305100261736638, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1653187192623489, 0.16531871926234873, 0.27192846101516327], 
reward next is 0.7281, 
noisyNet noise sample is [array([-0.7021929], dtype=float32), -0.5315959]. 
=============================================
[2019-03-27 06:39:17,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.2036001e-30 7.1909064e-21 1.8207203e-29 1.9350572e-23], sum to 1.0000
[2019-03-27 06:39:17,664] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4236
[2019-03-27 06:39:17,668] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5849190899480384, 6.911199999999999, 6.9112, 168.912956510431, 512005.7534928402, 512005.7534928408, 163756.5859003222], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7280400.0000, 
sim time next is 7281000.0000, 
raw observation next is [21.85, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5844429242299946, 6.9112, 6.9112, 168.912956510431, 511550.5761409131, 511550.5761409131, 163687.1895530163], 
processed observation next is [1.0, 0.2608695652173913, 0.23459715639810438, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4932230783292616, 0.0, 0.0, 0.8294399451523027, 0.14209738226136476, 0.14209738226136476, 0.2443092381388303], 
reward next is 0.7557, 
noisyNet noise sample is [array([0.11109361], dtype=float32), -1.5990058]. 
=============================================
[2019-03-27 06:39:17,680] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[70.652626]
 [70.57473 ]
 [70.672874]
 [70.57294 ]
 [70.52715 ]], R is [[70.74012756]
 [70.78831482]
 [70.8248291 ]
 [70.87374878]
 [70.92151642]].
[2019-03-27 06:39:18,691] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9998868e-01 6.9670453e-18 1.1360803e-05 1.5222164e-20 7.2637762e-13], sum to 1.0000
[2019-03-27 06:39:18,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0973
[2019-03-27 06:39:18,703] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1395372.849807777 W.
[2019-03-27 06:39:18,707] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333333, 63.66666666666666, 1.0, 2.0, 0.3187828105690161, 1.0, 1.0, 0.3187828105690161, 1.0, 1.0, 0.5464739740698934, 6.911200000000001, 6.9112, 170.5573041426782, 1395372.849807777, 1395372.849807777, 317035.5353466513], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7318200.0000, 
sim time next is 7318800.0000, 
raw observation next is [27.4, 64.0, 1.0, 2.0, 0.4780200292039571, 1.0, 2.0, 0.4780200292039571, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1400604.484037466, 1400604.484037466, 301089.1157179701], 
processed observation next is [1.0, 0.7391304347826086, 0.4976303317535545, 0.64, 1.0, 1.0, 0.37110846892043026, 1.0, 1.0, 0.37110846892043026, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.38905680112151836, 0.38905680112151836, 0.44938673987756733], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.98761994], dtype=float32), 0.47456697]. 
=============================================
[2019-03-27 06:39:28,781] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.7096014e-34 3.5680525e-27 1.3284632e-31 1.9814784e-27], sum to 1.0000
[2019-03-27 06:39:28,791] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8189
[2019-03-27 06:39:28,796] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333333, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7040784544428225, 6.911200000000001, 6.9112, 168.912956510431, 600089.9912196456, 600089.9912196449, 183453.472754205], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [25.6, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7057138414198754, 6.9112, 6.9112, 168.912956510431, 601354.902592889, 601354.902592889, 183748.0553740449], 
processed observation next is [0.0, 0.6086956521739131, 0.4123222748815167, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6411144407559456, 0.0, 0.0, 0.8294399451523027, 0.16704302849802474, 0.16704302849802474, 0.27425082891648495], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.768415], dtype=float32), -0.37215653]. 
=============================================
[2019-03-27 06:39:30,119] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 06:39:30,121] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:39:30,121] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:39:30,123] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:39:30,125] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:39:30,126] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:39:30,126] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:39:30,128] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:39:30,129] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:39:30,129] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:39:30,131] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:39:30,160] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run43
[2019-03-27 06:39:30,160] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run43
[2019-03-27 06:39:30,161] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run43
[2019-03-27 06:39:30,200] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run43
[2019-03-27 06:39:30,201] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run43
[2019-03-27 06:39:33,795] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:39:33,797] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.710772615, 93.306505465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.570884206478699, 6.9112, 6.9112, 168.912956510431, 500797.941601604, 500797.941601604, 161677.5636770707]
[2019-03-27 06:39:33,799] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:39:33,802] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.7878395e-32 3.0056937e-25 1.5112558e-30 4.7517810e-26], sampled 0.4502783096382691
[2019-03-27 06:39:37,902] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:39:37,904] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.06666666666667, 53.0, 1.0, 2.0, 0.5029257488302947, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 823978.8810772432, 823978.8810772427, 196343.2298964988]
[2019-03-27 06:39:37,908] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:39:37,911] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.5286762e-19 1.0496931e-08 1.8886201e-20 6.2408697e-15], sampled 0.9530580657982612
[2019-03-27 06:39:45,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:39:45,783] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.8, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5281948690356895, 6.9112, 6.9112, 168.912956510431, 465962.8299842365, 465962.8299842365, 155687.9760742894]
[2019-03-27 06:39:45,784] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:39:45,785] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.7710924e-32 1.3406351e-24 3.3218045e-30 1.1404846e-25], sampled 0.40468242119331843
[2019-03-27 06:39:52,474] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:39:52,476] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.40333588833334, 93.27626349333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5721921402121882, 6.9112, 6.9112, 168.912956510431, 503240.8130589625, 503240.8130589625, 161825.5478685216]
[2019-03-27 06:39:52,477] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:39:52,483] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.5915124e-35 2.1685709e-27 1.7477897e-33 2.0652972e-28], sampled 0.3744287057439658
[2019-03-27 06:39:58,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:39:58,984] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.3, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8539345635069002, 6.911199999999999, 6.9112, 168.912956510431, 710862.4853376749, 710862.4853376754, 213207.0291100065]
[2019-03-27 06:39:58,985] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:39:58,989] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.3583005e-34 2.2994508e-26 8.8995370e-33 1.1845903e-27], sampled 0.6372240636706122
[2019-03-27 06:40:20,978] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:40:20,980] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.68468720666667, 68.64636993666667, 1.0, 2.0, 0.6704413467858563, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956502129, 936942.6621388156, 936942.6621388156, 214593.0772408492]
[2019-03-27 06:40:20,982] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:40:20,985] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.8198394e-28 4.3843442e-20 1.2487115e-27 1.8193799e-22], sampled 0.6897323331908836
[2019-03-27 06:40:20,987] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 936942.6621388156 W.
[2019-03-27 06:40:35,465] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:40:35,466] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.13333333333333, 73.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.001433975867744, 6.9112, 168.9122826768613, 2364407.193582987, 2300392.360859904, 476662.897041856]
[2019-03-27 06:40:35,469] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:40:35,472] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [6.3098645e-01 7.5567638e-15 3.6901358e-01 3.8967612e-17 6.2705521e-11], sampled 0.40195867711588185
[2019-03-27 06:40:35,473] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2364407.193582987 W.
[2019-03-27 06:40:52,934] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:40:52,938] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.88333333333333, 60.16666666666667, 1.0, 1.0, 0.6112218569937723, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9128695444892, 854150.0688243407, 854150.0688243407, 202854.4707470021]
[2019-03-27 06:40:52,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:40:52,943] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.0583916e-23 8.3881469e-15 4.3054782e-23 3.4492265e-18], sampled 0.8202482328837849
[2019-03-27 06:41:12,638] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:41:12,639] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.68655366333333, 85.85403786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.835205962908298, 6.911199999999999, 6.9112, 168.912956510431, 698615.8487541043, 698615.848754105, 209218.2136265284]
[2019-03-27 06:41:12,640] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:41:12,642] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.7670326e-35 3.0500899e-27 2.4719722e-33 3.1483853e-28], sampled 0.1772374987143971
[2019-03-27 06:41:18,953] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:41:18,954] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.6, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9702882256717762, 6.9112, 6.9112, 168.912956510431, 786717.2695661032, 786717.2695661032, 239767.3021012743]
[2019-03-27 06:41:18,954] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:41:18,959] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 7.7384592e-32 2.7708585e-23 1.9373843e-30 3.2855056e-25], sampled 0.6573611152303278
[2019-03-27 06:41:24,358] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7348.3024 3105671109.9329 2010.0000
[2019-03-27 06:41:24,546] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0250955], dtype=float32), 0.06279597]
[2019-03-27 06:41:24,548] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.43333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9040967926629335, 6.911200000000001, 6.9112, 168.912956510431, 742611.1291705568, 742611.1291705562, 224237.7972444536]
[2019-03-27 06:41:24,549] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:41:24,550] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.2906467e-35 1.4801641e-26 6.0124750e-34 2.3015460e-28], sampled 0.4413123320778405
[2019-03-27 06:41:24,560] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.1591 3319619203.7639 2143.0000
[2019-03-27 06:41:24,572] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7031.8642 3185112334.2085 2464.0000
[2019-03-27 06:41:24,821] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.5107 2989418318.9383 1567.0000
[2019-03-27 06:41:24,833] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8059.6624 2937900393.4097 1381.0000
[2019-03-27 06:41:25,852] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1050000, evaluation results [1050000.0, 7286.15911354119, 3319619203.7639375, 2143.0, 7348.302436431269, 3105671109.932903, 2010.0, 8059.662398685725, 2937900393.409726, 1381.0, 7031.864183744905, 3185112334.208501, 2464.0, 7924.510690562575, 2989418318.9382763, 1567.0]
[2019-03-27 06:41:26,570] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1642117e-34 1.4640026e-26 7.2966387e-33 9.8435574e-27], sum to 1.0000
[2019-03-27 06:41:26,577] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3331
[2019-03-27 06:41:26,582] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.95, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6979201424734611, 6.9112, 6.9112, 168.912956510431, 595888.5956028645, 595888.5956028645, 182353.070187067], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7509000.0000, 
sim time next is 7509600.0000, 
raw observation next is [23.9, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6986703061085082, 6.9112, 6.9112, 168.912956510431, 596411.0850560429, 596411.0850560429, 182486.7165659365], 
processed observation next is [0.0, 0.9565217391304348, 0.33175355450236965, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6325247635469613, 0.0, 0.0, 0.8294399451523027, 0.1656697458489008, 0.1656697458489008, 0.2723682336805023], 
reward next is 0.7276, 
noisyNet noise sample is [array([-0.5823034], dtype=float32), 0.8881102]. 
=============================================
[2019-03-27 06:41:27,579] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:27,579] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:27,650] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run6
[2019-03-27 06:41:28,424] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 6.3935321e-35 5.8369026e-26 3.7960768e-32 1.2266305e-27], sum to 1.0000
[2019-03-27 06:41:28,431] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7132
[2019-03-27 06:41:28,436] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.58333333333333, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.740247028500342, 6.9112, 6.9112, 168.912956510431, 626595.5557816122, 626595.5557816122, 190113.284440404], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7577400.0000, 
sim time next is 7578000.0000, 
raw observation next is [28.5, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7405397027109467, 6.911199999999999, 6.9112, 168.912956510431, 626773.4796244135, 626773.4796244142, 190168.0198179049], 
processed observation next is [0.0, 0.7391304347826086, 0.5497630331753555, 0.65, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6835850033060324, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17410374434011486, 0.17410374434011505, 0.283832865399858], 
reward next is 0.7162, 
noisyNet noise sample is [array([-0.74348295], dtype=float32), 0.567615]. 
=============================================
[2019-03-27 06:41:28,450] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.3297  ]
 [77.25267 ]
 [77.17013 ]
 [77.073524]
 [76.95712 ]], R is [[77.39194489]
 [77.33427429]
 [77.27736664]
 [77.22136688]
 [77.16612244]].
[2019-03-27 06:41:32,509] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:32,509] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:32,577] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run6
[2019-03-27 06:41:34,885] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.3020725e-29 2.3352272e-17 1.4233343e-27 3.4372028e-21], sum to 1.0000
[2019-03-27 06:41:34,894] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7006
[2019-03-27 06:41:34,901] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8290618087980987, 6.9112, 6.9112, 168.912956510431, 694538.838280199, 694538.838280199, 207925.8124262484], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7710000.0000, 
sim time next is 7710600.0000, 
raw observation next is [25.33333333333333, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8345885780840934, 6.9112, 6.9112, 168.912956510431, 698213.6747139937, 698213.6747139937, 209088.5349771151], 
processed observation next is [1.0, 0.21739130434782608, 0.3996840442338071, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7982787537610895, 0.0, 0.0, 0.8294399451523027, 0.19394824297610935, 0.19394824297610935, 0.3120724402643509], 
reward next is 0.6879, 
noisyNet noise sample is [array([1.3709228], dtype=float32), -0.8131959]. 
=============================================
[2019-03-27 06:41:37,655] A3C_AGENT_WORKER-Thread-13 INFO:Local step 66500, global step 1055568: loss 0.1955
[2019-03-27 06:41:37,657] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 66500, global step 1055569: learning rate 0.0000
[2019-03-27 06:41:37,740] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.10124741e-02 1.09911505e-16 9.88987505e-01 4.98229268e-20
 7.85043142e-11], sum to 1.0000
[2019-03-27 06:41:37,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9265
[2019-03-27 06:41:37,756] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.25, 60.5, 1.0, 2.0, 0.5916547540424668, 1.0, 1.0, 0.5916547540424668, 1.0, 2.0, 1.014202420485181, 6.911199999999999, 6.9112, 170.5573041426782, 2482247.472070307, 2482247.472070308, 481399.1148039392], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 7745400.0000, 
sim time next is 7746000.0000, 
raw observation next is [31.13333333333333, 60.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.358360978174767, 6.9112, 168.9103423780435, 2619951.975438723, 2302725.496968, 475997.0575474082], 
processed observation next is [1.0, 0.6521739130434783, 0.6745655608214848, 0.6066666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04471609781747672, 0.0, 0.8294271085655252, 0.7277644376218675, 0.63964597138, 0.7104433694737436], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.02110794], dtype=float32), -0.6666481]. 
=============================================
[2019-03-27 06:41:37,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[43.53051 ]
 [43.39984 ]
 [44.174866]
 [44.854485]
 [45.040466]], R is [[43.14593124]
 [42.99596786]
 [42.56600952]
 [42.14035034]
 [41.71894836]].
[2019-03-27 06:41:41,601] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:41,602] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:41,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run6
[2019-03-27 06:41:42,219] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.9211674e-30 6.4422584e-18 2.5825867e-30 2.3142735e-23], sum to 1.0000
[2019-03-27 06:41:42,225] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0522
[2019-03-27 06:41:42,233] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.46666666666667, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.89825899173492, 6.9112, 6.9112, 168.912956510431, 735333.4575026871, 735333.4575026871, 222777.2095494392], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7843200.0000, 
sim time next is 7843800.0000, 
raw observation next is [28.33333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9012100893939277, 6.9112, 6.9112, 168.912956510431, 737469.180170965, 737469.180170965, 223449.0215665968], 
processed observation next is [1.0, 0.782608695652174, 0.541864139020537, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8795244992608874, 0.0, 0.0, 0.8294399451523027, 0.20485255004749028, 0.20485255004749028, 0.3335060023382042], 
reward next is 0.6665, 
noisyNet noise sample is [array([-0.80513144], dtype=float32), -0.3584713]. 
=============================================
[2019-03-27 06:41:42,543] A3C_AGENT_WORKER-Thread-20 INFO:Local step 66500, global step 1057852: loss 0.4891
[2019-03-27 06:41:42,545] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 66500, global step 1057852: learning rate 0.0000
[2019-03-27 06:41:48,335] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:48,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:48,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run6
[2019-03-27 06:41:49,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:49,171] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:49,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run6
[2019-03-27 06:41:49,496] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:49,498] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:49,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run6
[2019-03-27 06:41:49,577] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:49,577] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:49,583] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.0747940e-33 1.3676394e-25 5.8393157e-31 8.1373166e-26], sum to 1.0000
[2019-03-27 06:41:49,586] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6075
[2019-03-27 06:41:49,595] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5688569855298272, 6.9112, 6.9112, 168.912956510431, 497159.140519501, 497159.140519501, 161435.2371408237], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 307200.0000, 
sim time next is 307800.0000, 
raw observation next is [23.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.570181177021866, 6.911199999999999, 6.9112, 168.912956510431, 498164.0132880309, 498164.0132880316, 161629.17512897], 
processed observation next is [0.0, 0.5652173913043478, 0.3222748815165877, 0.76, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4758307036852024, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1383788925800086, 0.1383788925800088, 0.2412375748193582], 
reward next is 0.7588, 
noisyNet noise sample is [array([0.24262828], dtype=float32), -0.68420565]. 
=============================================
[2019-03-27 06:41:49,633] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run6
[2019-03-27 06:41:49,705] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9319884e-31 5.2681718e-20 3.1262042e-31 7.5207190e-23], sum to 1.0000
[2019-03-27 06:41:49,707] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8991
[2019-03-27 06:41:49,713] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.41666666666666, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.905916588606538, 6.9112, 6.9112, 168.912956510431, 743780.161061396, 743780.161061396, 224649.0964791683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7948200.0000, 
sim time next is 7948800.0000, 
raw observation next is [26.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9066508780258289, 6.9112, 6.9112, 168.912956510431, 744056.553743155, 744056.553743155, 224807.1488025224], 
processed observation next is [1.0, 0.0, 0.45023696682464454, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8861596073485718, 0.0, 0.0, 0.8294399451523027, 0.20668237603976528, 0.20668237603976528, 0.3355330579142125], 
reward next is 0.6645, 
noisyNet noise sample is [array([0.93341476], dtype=float32), -0.025233394]. 
=============================================
[2019-03-27 06:41:49,862] A3C_AGENT_WORKER-Thread-22 INFO:Local step 66500, global step 1061370: loss 0.3484
[2019-03-27 06:41:49,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 66500, global step 1061371: learning rate 0.0000
[2019-03-27 06:41:49,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:49,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:49,937] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:49,937] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:49,956] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run6
[2019-03-27 06:41:50,001] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run6
[2019-03-27 06:41:50,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run6
[2019-03-27 06:41:50,308] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67000, global step 1061613: loss 0.3899
[2019-03-27 06:41:50,310] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67000, global step 1061613: learning rate 0.0000
[2019-03-27 06:41:50,365] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,365] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,390] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run6
[2019-03-27 06:41:50,446] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,446] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,455] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run6
[2019-03-27 06:41:50,507] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,522] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run6
[2019-03-27 06:41:50,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,733] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,742] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,742] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run6
[2019-03-27 06:41:50,770] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run6
[2019-03-27 06:41:50,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 06:41:50,881] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:41:50,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run6
[2019-03-27 06:41:51,682] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9986362e-01 4.9935308e-16 1.3631055e-04 8.8844471e-19 8.9335015e-12], sum to 1.0000
[2019-03-27 06:41:51,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0323
[2019-03-27 06:41:51,689] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1251458.943050966 W.
[2019-03-27 06:41:51,693] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.68333333333333, 73.0, 1.0, 2.0, 0.4070419361162081, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7221876284529685, 6.9112, 6.9112, 168.912956510431, 1251458.943050966, 1251458.943050966, 272649.2276627498], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 35400.0000, 
sim time next is 36000.0000, 
raw observation next is [24.9, 72.0, 1.0, 2.0, 0.425047252657733, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7543864738600529, 6.911200000000001, 6.9112, 168.912956510431, 1307547.445609694, 1307547.445609694, 281362.667019309], 
processed observation next is [1.0, 0.43478260869565216, 0.3791469194312796, 0.72, 1.0, 1.0, 0.30728584657558194, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7004713095854302, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3632076237804706, 0.3632076237804706, 0.419944279133297], 
reward next is 0.5801, 
noisyNet noise sample is [array([-1.0197837], dtype=float32), 0.29592344]. 
=============================================
[2019-03-27 06:41:51,705] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[45.587765]
 [45.152763]
 [45.31996 ]
 [46.211308]
 [48.175457]], R is [[47.20782852]
 [46.73575211]
 [46.26839447]
 [45.80570984]
 [45.34765244]].
[2019-03-27 06:41:52,061] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[69.49618]
 [69.49166]
 [69.48724]], R is [[0.66446694]
 [1.32252511]
 [1.97461658]].
[2019-03-27 06:41:53,274] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67000, global step 1063152: loss 0.2218
[2019-03-27 06:41:53,276] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67000, global step 1063153: learning rate 0.0000
[2019-03-27 06:41:53,476] A3C_AGENT_WORKER-Thread-9 INFO:Local step 66500, global step 1063244: loss 0.1265
[2019-03-27 06:41:53,478] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 66500, global step 1063244: learning rate 0.0000
[2019-03-27 06:41:56,663] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.7719270e-30 1.0248414e-19 1.8033015e-29 3.2934646e-23], sum to 1.0000
[2019-03-27 06:41:56,672] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0506
[2019-03-27 06:41:56,677] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.43333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6696424653025144, 6.9112, 6.9112, 168.912956510431, 576234.0410331846, 576234.0410331846, 177407.0356121013], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 153600.0000, 
sim time next is 154200.0000, 
raw observation next is [22.41666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6741887014307836, 6.9112, 6.9112, 168.912956510431, 580258.5197760034, 580258.5197760034, 178187.2212561556], 
processed observation next is [1.0, 0.782608695652174, 0.26145339652448685, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6026691480863214, 0.0, 0.0, 0.8294399451523027, 0.16118292216000096, 0.16118292216000096, 0.2659510765017248], 
reward next is 0.7340, 
noisyNet noise sample is [array([-1.5446534], dtype=float32), -1.2983565]. 
=============================================
[2019-03-27 06:41:56,767] A3C_AGENT_WORKER-Thread-11 INFO:Local step 66500, global step 1064766: loss 1.7303
[2019-03-27 06:41:56,770] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 66500, global step 1064766: learning rate 0.0000
[2019-03-27 06:41:58,277] A3C_AGENT_WORKER-Thread-21 INFO:Local step 66500, global step 1065476: loss 0.4183
[2019-03-27 06:41:58,281] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 66500, global step 1065477: learning rate 0.0000
[2019-03-27 06:41:58,403] A3C_AGENT_WORKER-Thread-12 INFO:Local step 66500, global step 1065535: loss 0.0713
[2019-03-27 06:41:58,405] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 66500, global step 1065535: learning rate 0.0000
[2019-03-27 06:41:59,390] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.7435191e-33 3.6465462e-24 5.7818817e-32 6.4463837e-27], sum to 1.0000
[2019-03-27 06:41:59,399] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6335
[2019-03-27 06:41:59,403] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5189896688363174, 6.9112, 6.9112, 168.912956510431, 457899.4545029787, 457899.4545029787, 154479.2791495045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 266400.0000, 
sim time next is 267000.0000, 
raw observation next is [20.43333333333334, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.518907481043315, 6.911200000000001, 6.9112, 168.912956510431, 457874.7427059273, 457874.7427059267, 154466.7698189131], 
processed observation next is [0.0, 0.08695652173913043, 0.1674565560821489, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4133018061503841, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12718742852942425, 0.12718742852942408, 0.2305474176401688], 
reward next is 0.7695, 
noisyNet noise sample is [array([1.1625823], dtype=float32), -0.093342096]. 
=============================================
[2019-03-27 06:41:59,416] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.94004 ]
 [76.97411 ]
 [76.966194]
 [77.144035]
 [77.2387  ]], R is [[77.06443024]
 [77.06321716]
 [77.06201935]
 [77.06077576]
 [77.0594635 ]].
[2019-03-27 06:41:59,504] A3C_AGENT_WORKER-Thread-2 INFO:Local step 66500, global step 1066048: loss 0.2889
[2019-03-27 06:41:59,506] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 66500, global step 1066048: learning rate 0.0000
[2019-03-27 06:41:59,650] A3C_AGENT_WORKER-Thread-14 INFO:Local step 66500, global step 1066115: loss 0.3745
[2019-03-27 06:41:59,654] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 66500, global step 1066115: learning rate 0.0000
[2019-03-27 06:42:00,018] A3C_AGENT_WORKER-Thread-19 INFO:Local step 66500, global step 1066286: loss 0.9633
[2019-03-27 06:42:00,023] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 66500, global step 1066289: learning rate 0.0000
[2019-03-27 06:42:00,413] A3C_AGENT_WORKER-Thread-16 INFO:Local step 66500, global step 1066471: loss 0.6532
[2019-03-27 06:42:00,416] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 66500, global step 1066473: learning rate 0.0000
[2019-03-27 06:42:00,588] A3C_AGENT_WORKER-Thread-3 INFO:Local step 66500, global step 1066551: loss 0.5812
[2019-03-27 06:42:00,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 66500, global step 1066551: learning rate 0.0000
[2019-03-27 06:42:00,659] A3C_AGENT_WORKER-Thread-17 INFO:Local step 66500, global step 1066586: loss 1.8527
[2019-03-27 06:42:00,665] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 66500, global step 1066587: learning rate 0.0000
[2019-03-27 06:42:01,017] A3C_AGENT_WORKER-Thread-10 INFO:Local step 66500, global step 1066754: loss 0.5247
[2019-03-27 06:42:01,022] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 66500, global step 1066757: learning rate 0.0000
[2019-03-27 06:42:01,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 66500, global step 1066765: loss 0.5057
[2019-03-27 06:42:01,041] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 66500, global step 1066767: learning rate 0.0000
[2019-03-27 06:42:01,250] A3C_AGENT_WORKER-Thread-15 INFO:Local step 66500, global step 1066864: loss 1.9799
[2019-03-27 06:42:01,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 66500, global step 1066864: learning rate 0.0000
[2019-03-27 06:42:02,192] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67000, global step 1067300: loss 0.1116
[2019-03-27 06:42:02,194] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67000, global step 1067301: learning rate 0.0000
[2019-03-27 06:42:05,269] A3C_AGENT_WORKER-Thread-13 INFO:Local step 67500, global step 1068729: loss 148.0215
[2019-03-27 06:42:05,271] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 67500, global step 1068729: learning rate 0.0000
[2019-03-27 06:42:10,154] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67000, global step 1071021: loss 0.0911
[2019-03-27 06:42:10,156] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67000, global step 1071021: learning rate 0.0000
[2019-03-27 06:42:10,811] A3C_AGENT_WORKER-Thread-20 INFO:Local step 67500, global step 1071326: loss 108.7509
[2019-03-27 06:42:10,812] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 67500, global step 1071326: learning rate 0.0000
[2019-03-27 06:42:11,296] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 1.21622765e-32 1.97973808e-22 5.21447883e-31
 6.66768163e-26], sum to 1.0000
[2019-03-27 06:42:11,297] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4855
[2019-03-27 06:42:11,302] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.73333333333333, 79.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4687162961358107, 6.9112, 6.9112, 168.912956510431, 418193.4120498577, 418193.4120498577, 148066.1551431753], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 763800.0000, 
sim time next is 764400.0000, 
raw observation next is [20.66666666666667, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4698991978358413, 6.9112, 6.9112, 168.912956510431, 419233.0722709419, 419233.0722709419, 148204.2001329376], 
processed observation next is [1.0, 0.8695652173913043, 0.17851500789889443, 0.8, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3535356071168796, 0.0, 0.0, 0.8294399451523027, 0.11645363118637275, 0.11645363118637275, 0.221200298705877], 
reward next is 0.7788, 
noisyNet noise sample is [array([-1.6965036], dtype=float32), 0.39488572]. 
=============================================
[2019-03-27 06:42:13,499] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67000, global step 1072598: loss 0.0534
[2019-03-27 06:42:13,504] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67000, global step 1072601: learning rate 0.0000
[2019-03-27 06:42:13,770] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.1597642e-30 2.2518706e-20 1.0515115e-29 5.5091225e-23], sum to 1.0000
[2019-03-27 06:42:13,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4291
[2019-03-27 06:42:13,782] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.65, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9117719442873405, 6.9112, 6.9112, 168.912956510431, 804724.0981767082, 804724.0981767082, 226242.5775645644], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 399000.0000, 
sim time next is 399600.0000, 
raw observation next is [22.6, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9444454678617306, 6.9112, 6.9112, 168.912956510431, 833468.6755814737, 833468.6755814737, 234090.2446049298], 
processed observation next is [1.0, 0.6521739130434783, 0.27014218009478685, 0.76, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9322505705630859, 0.0, 0.0, 0.8294399451523027, 0.23151907655040938, 0.23151907655040938, 0.3493884247834773], 
reward next is 0.6506, 
noisyNet noise sample is [array([1.2702266], dtype=float32), 0.31639087]. 
=============================================
[2019-03-27 06:42:14,910] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67000, global step 1073259: loss 0.0371
[2019-03-27 06:42:14,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67000, global step 1073259: learning rate 0.0000
[2019-03-27 06:42:15,156] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67000, global step 1073375: loss 0.0269
[2019-03-27 06:42:15,159] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67000, global step 1073375: learning rate 0.0000
[2019-03-27 06:42:16,448] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67000, global step 1073973: loss 0.0344
[2019-03-27 06:42:16,451] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67000, global step 1073974: learning rate 0.0000
[2019-03-27 06:42:16,538] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67000, global step 1074016: loss 0.0300
[2019-03-27 06:42:16,541] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67000, global step 1074017: learning rate 0.0000
[2019-03-27 06:42:16,959] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67000, global step 1074216: loss 0.0386
[2019-03-27 06:42:16,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67000, global step 1074216: learning rate 0.0000
[2019-03-27 06:42:17,358] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67000, global step 1074402: loss 0.0459
[2019-03-27 06:42:17,360] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67000, global step 1074402: learning rate 0.0000
[2019-03-27 06:42:17,581] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67000, global step 1074505: loss 0.0334
[2019-03-27 06:42:17,585] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67000, global step 1074505: learning rate 0.0000
[2019-03-27 06:42:17,602] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67000, global step 1074515: loss 0.0365
[2019-03-27 06:42:17,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67000, global step 1074515: learning rate 0.0000
[2019-03-27 06:42:17,980] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67000, global step 1074690: loss 0.0346
[2019-03-27 06:42:17,982] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67000, global step 1074690: learning rate 0.0000
[2019-03-27 06:42:18,015] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67000, global step 1074702: loss 0.0347
[2019-03-27 06:42:18,018] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67000, global step 1074704: learning rate 0.0000
[2019-03-27 06:42:18,333] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67000, global step 1074854: loss 0.0427
[2019-03-27 06:42:18,335] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67000, global step 1074854: learning rate 0.0000
[2019-03-27 06:42:18,654] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 06:42:18,656] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:42:18,658] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:42:18,658] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:42:18,659] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:42:18,662] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:42:18,663] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:42:18,663] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:42:18,661] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:42:18,665] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:42:18,667] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:42:18,683] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run44
[2019-03-27 06:42:18,684] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run44
[2019-03-27 06:42:18,723] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run44
[2019-03-27 06:42:18,724] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run44
[2019-03-27 06:42:18,761] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run44
[2019-03-27 06:42:52,023] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.065345556]
[2019-03-27 06:42:52,026] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.91884397666667, 76.09882610666668, 1.0, 2.0, 0.5130385644753779, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8938309067842927, 6.9112, 6.9112, 168.9129267977851, 1533774.119471504, 1533774.119471504, 322985.7513484464]
[2019-03-27 06:42:52,028] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:42:52,031] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9942219e-01 3.2135215e-16 5.7786616e-04 1.1942903e-17 1.0505549e-11], sampled 0.22026292183136587
[2019-03-27 06:42:52,032] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1533774.119471504 W.
[2019-03-27 06:43:16,857] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.065345556]
[2019-03-27 06:43:16,858] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 60.0, 1.0, 2.0, 0.8221850581749354, 1.0, 2.0, 0.7316825686017303, 1.0, 1.0, 1.03, 7.005107368312682, 6.9112, 170.5573041426782, 3070446.655721292, 3003176.987891405, 562698.4843289636]
[2019-03-27 06:43:16,860] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:43:16,863] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.9821401e-01 4.2891716e-16 5.0178599e-01 2.1884870e-18 4.1891265e-12], sampled 0.7069424476331441
[2019-03-27 06:43:16,865] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [0, 0, 1, 0, 0] has been changed to [0, 0, 0, 1, 0] for the demand 3070446.655721292 W.
[2019-03-27 06:43:40,109] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.065345556]
[2019-03-27 06:43:40,110] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.56666666666667, 94.66666666666666, 1.0, 2.0, 0.6340790291742778, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 886105.0767214864, 886105.076721487, 207266.3664593749]
[2019-03-27 06:43:40,113] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:43:40,116] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999964e-01 4.7809607e-19 2.9921435e-07 9.1761788e-20 3.3626219e-14], sampled 0.30218746212771064
[2019-03-27 06:43:40,117] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 886105.0767214864 W.
[2019-03-27 06:43:46,380] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.065345556]
[2019-03-27 06:43:46,382] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.2, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9264862556222775, 6.911200000000001, 6.9112, 168.912956510431, 758786.8984414219, 758786.8984414213, 229430.3088048299]
[2019-03-27 06:43:46,383] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:43:46,385] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.5272531e-35 1.9039652e-25 7.4024139e-34 1.0834105e-27], sampled 0.3617082575182702
[2019-03-27 06:44:13,583] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8061.1785 2937763024.7094 1381.0000
[2019-03-27 06:44:13,835] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.3800 2989295519.0765 1566.0000
[2019-03-27 06:44:13,892] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.1396 3319886690.6987 2144.0000
[2019-03-27 06:44:13,961] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7346.9006 3105688724.9038 2010.0000
[2019-03-27 06:44:13,966] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7031.5430 3185055869.3009 2464.0000
[2019-03-27 06:44:14,979] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1075000, evaluation results [1075000.0, 7286.1396242226765, 3319886690.698666, 2144.0, 7346.900636476409, 3105688724.903755, 2010.0, 8061.178488969098, 2937763024.7094064, 1381.0, 7031.543011277068, 3185055869.3008695, 2464.0, 7923.380011218134, 2989295519.0765023, 1566.0]
[2019-03-27 06:44:16,270] A3C_AGENT_WORKER-Thread-22 INFO:Local step 67500, global step 1075580: loss 117.8832
[2019-03-27 06:44:16,276] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 67500, global step 1075580: learning rate 0.0000
[2019-03-27 06:44:17,993] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.8504326e-34 1.2146098e-24 3.7608211e-32 6.3481848e-27], sum to 1.0000
[2019-03-27 06:44:18,001] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6786
[2019-03-27 06:44:18,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.41666666666667, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4771171325715619, 6.911200000000001, 6.9112, 168.912956510431, 424958.8554000512, 424958.8554000505, 149091.305795379], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 784200.0000, 
sim time next is 784800.0000, 
raw observation next is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4777501156928629, 6.9112, 6.9112, 168.912956510431, 425513.1070046628, 425513.1070046628, 149166.6525150232], 
processed observation next is [0.0, 0.08695652173913043, 0.11848341232227487, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3631098971864182, 0.0, 0.0, 0.8294399451523027, 0.118198085279073, 0.118198085279073, 0.22263679479854206], 
reward next is 0.7774, 
noisyNet noise sample is [array([2.8803363], dtype=float32), -1.0861288]. 
=============================================
[2019-03-27 06:44:18,646] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68000, global step 1076649: loss 0.0126
[2019-03-27 06:44:18,649] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68000, global step 1076649: learning rate 0.0000
[2019-03-27 06:44:23,214] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.4503714e-32 1.3825268e-24 9.5894309e-31 5.4154956e-26], sum to 1.0000
[2019-03-27 06:44:23,225] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8278
[2019-03-27 06:44:23,228] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.9, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5210477404202988, 6.9112, 6.9112, 168.912956510431, 459951.6349758428, 459951.6349758428, 154737.8751692653], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 878400.0000, 
sim time next is 879000.0000, 
raw observation next is [20.88333333333333, 87.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5180305029053298, 6.911199999999999, 6.9112, 168.912956510431, 457440.0960175311, 457440.0960175318, 154339.7942024705], 
processed observation next is [0.0, 0.17391304347826086, 0.18878357030015785, 0.8783333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41223232061625587, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12706669333820308, 0.12706669333820328, 0.23035790179473212], 
reward next is 0.7696, 
noisyNet noise sample is [array([-0.8956193], dtype=float32), -0.14715295]. 
=============================================
[2019-03-27 06:44:23,242] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[80.64284 ]
 [80.628136]
 [80.83663 ]
 [81.086655]
 [81.04811 ]], R is [[80.45127869]
 [80.41581726]
 [80.38056183]
 [80.34554291]
 [80.31071472]].
[2019-03-27 06:44:24,234] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68000, global step 1079164: loss 0.0065
[2019-03-27 06:44:24,238] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68000, global step 1079164: learning rate 0.0000
[2019-03-27 06:44:24,312] A3C_AGENT_WORKER-Thread-9 INFO:Local step 67500, global step 1079197: loss 114.1318
[2019-03-27 06:44:24,314] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 67500, global step 1079197: learning rate 0.0000
[2019-03-27 06:44:27,724] A3C_AGENT_WORKER-Thread-11 INFO:Local step 67500, global step 1080729: loss 149.3535
[2019-03-27 06:44:27,727] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 67500, global step 1080730: learning rate 0.0000
[2019-03-27 06:44:29,157] A3C_AGENT_WORKER-Thread-21 INFO:Local step 67500, global step 1081372: loss 115.5388
[2019-03-27 06:44:29,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 67500, global step 1081372: learning rate 0.0000
[2019-03-27 06:44:29,578] A3C_AGENT_WORKER-Thread-12 INFO:Local step 67500, global step 1081565: loss 133.1071
[2019-03-27 06:44:29,579] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 67500, global step 1081565: learning rate 0.0000
[2019-03-27 06:44:30,705] A3C_AGENT_WORKER-Thread-14 INFO:Local step 67500, global step 1082067: loss 119.1810
[2019-03-27 06:44:30,707] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 67500, global step 1082067: learning rate 0.0000
[2019-03-27 06:44:30,745] A3C_AGENT_WORKER-Thread-2 INFO:Local step 67500, global step 1082085: loss 126.9806
[2019-03-27 06:44:30,749] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 67500, global step 1082087: learning rate 0.0000
[2019-03-27 06:44:31,083] A3C_AGENT_WORKER-Thread-19 INFO:Local step 67500, global step 1082240: loss 116.4735
[2019-03-27 06:44:31,084] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 67500, global step 1082240: learning rate 0.0000
[2019-03-27 06:44:31,598] A3C_AGENT_WORKER-Thread-16 INFO:Local step 67500, global step 1082469: loss 131.3204
[2019-03-27 06:44:31,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 67500, global step 1082470: learning rate 0.0000
[2019-03-27 06:44:31,834] A3C_AGENT_WORKER-Thread-3 INFO:Local step 67500, global step 1082554: loss 137.2264
[2019-03-27 06:44:31,835] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 67500, global step 1082554: learning rate 0.0000
[2019-03-27 06:44:31,869] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.1089053e-32 1.4925461e-20 3.1581118e-31 2.9303155e-25], sum to 1.0000
[2019-03-27 06:44:31,879] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4116
[2019-03-27 06:44:31,887] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6314169954937325, 6.9112, 6.9112, 168.912956510431, 546549.2769441821, 546549.2769441821, 171040.1244595048], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1027200.0000, 
sim time next is 1027800.0000, 
raw observation next is [21.9, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.632298731153513, 6.9112, 6.9112, 168.912956510431, 547192.5366920851, 547192.5366920851, 171183.2419132479], 
processed observation next is [1.0, 0.9130434782608695, 0.23696682464454974, 0.965, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5515838184798938, 0.0, 0.0, 0.8294399451523027, 0.15199792685891253, 0.15199792685891253, 0.2554973759899223], 
reward next is 0.7445, 
noisyNet noise sample is [array([0.05627122], dtype=float32), -1.0198133]. 
=============================================
[2019-03-27 06:44:31,909] A3C_AGENT_WORKER-Thread-17 INFO:Local step 67500, global step 1082582: loss 144.0844
[2019-03-27 06:44:31,915] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 67500, global step 1082583: learning rate 0.0000
[2019-03-27 06:44:32,150] A3C_AGENT_WORKER-Thread-10 INFO:Local step 67500, global step 1082674: loss 153.0694
[2019-03-27 06:44:32,152] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 67500, global step 1082674: learning rate 0.0000
[2019-03-27 06:44:32,248] A3C_AGENT_WORKER-Thread-18 INFO:Local step 67500, global step 1082709: loss 163.7294
[2019-03-27 06:44:32,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 67500, global step 1082709: learning rate 0.0000
[2019-03-27 06:44:32,662] A3C_AGENT_WORKER-Thread-15 INFO:Local step 67500, global step 1082879: loss 133.1237
[2019-03-27 06:44:32,664] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 67500, global step 1082880: learning rate 0.0000
[2019-03-27 06:44:33,584] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68000, global step 1083309: loss 0.0071
[2019-03-27 06:44:33,588] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68000, global step 1083309: learning rate 0.0000
[2019-03-27 06:44:33,590] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.0944437e-30 6.4279683e-19 9.6179753e-30 7.8034181e-22], sum to 1.0000
[2019-03-27 06:44:33,600] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4489
[2019-03-27 06:44:33,605] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.5, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.466660256942729, 6.9112, 6.9112, 168.912956510431, 416470.0307441608, 416470.0307441608, 147821.9042683729], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 777600.0000, 
sim time next is 778200.0000, 
raw observation next is [19.5, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4674468737262145, 6.9112, 6.9112, 168.912956510431, 417111.0264477726, 417111.0264477726, 147916.3775337734], 
processed observation next is [0.0, 0.0, 0.12322274881516594, 0.8933333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3505449679587982, 0.0, 0.0, 0.8294399451523027, 0.11586417401327016, 0.11586417401327016, 0.2207707127369752], 
reward next is 0.7792, 
noisyNet noise sample is [array([0.782799], dtype=float32), 1.1377125]. 
=============================================
[2019-03-27 06:44:34,417] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.9399871e-34 5.0476097e-24 1.5269933e-32 4.3130825e-26], sum to 1.0000
[2019-03-27 06:44:34,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2663
[2019-03-27 06:44:34,425] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.53333333333333, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432683546046311, 6.911199999999999, 6.9112, 168.912956510431, 477486.3531816378, 477486.3531816385, 157775.203212933], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 846600.0000, 
sim time next is 847200.0000, 
raw observation next is [22.46666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5424198598875233, 6.9112, 6.9112, 168.912956510431, 476844.6019803797, 476844.6019803797, 157656.1347256089], 
processed observation next is [0.0, 0.8260869565217391, 0.2638230647709322, 0.7966666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4419754388872235, 0.0, 0.0, 0.8294399451523027, 0.13245683388343882, 0.13245683388343882, 0.23530766376956552], 
reward next is 0.7647, 
noisyNet noise sample is [array([-1.1544905], dtype=float32), -0.5720799]. 
=============================================
[2019-03-27 06:44:36,255] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.2918685e-31 1.2464500e-21 4.1086953e-29 9.1713340e-24], sum to 1.0000
[2019-03-27 06:44:36,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6776
[2019-03-27 06:44:36,267] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.93333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5223003130688858, 6.9112, 6.9112, 168.912956510431, 460748.844830786, 460748.844830786, 154913.2640421015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 877200.0000, 
sim time next is 877800.0000, 
raw observation next is [20.91666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5217443620895207, 6.911200000000001, 6.9112, 168.912956510431, 460412.6558931374, 460412.6558931368, 154834.7316061841], 
processed observation next is [0.0, 0.13043478260869565, 0.19036334913112193, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4167614171823423, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12789240441476038, 0.1278924044147602, 0.2310966143375882], 
reward next is 0.7689, 
noisyNet noise sample is [array([-0.02646051], dtype=float32), -0.29876196]. 
=============================================
[2019-03-27 06:44:36,678] A3C_AGENT_WORKER-Thread-13 INFO:Local step 68500, global step 1084890: loss -49.6608
[2019-03-27 06:44:36,680] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 68500, global step 1084890: learning rate 0.0000
[2019-03-27 06:44:41,446] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68000, global step 1087121: loss 0.0073
[2019-03-27 06:44:41,448] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68000, global step 1087123: learning rate 0.0000
[2019-03-27 06:44:41,930] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.6346501e-32 4.8859000e-22 1.1123934e-30 3.7326516e-24], sum to 1.0000
[2019-03-27 06:44:41,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6985
[2019-03-27 06:44:41,944] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.86666666666667, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767204453737864, 6.9112, 6.9112, 168.912956510431, 503540.6873273705, 503540.6873273705, 162584.0264821013], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 926400.0000, 
sim time next is 927000.0000, 
raw observation next is [23.8, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5784418954467205, 6.9112, 6.9112, 168.912956510431, 504887.1789225037, 504887.1789225037, 162838.7657800714], 
processed observation next is [0.0, 0.7391304347826086, 0.3270142180094788, 0.76, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4859047505447811, 0.0, 0.0, 0.8294399451523027, 0.14024643858958435, 0.14024643858958435, 0.24304293400010657], 
reward next is 0.7570, 
noisyNet noise sample is [array([0.59742635], dtype=float32), -0.23325416]. 
=============================================
[2019-03-27 06:44:41,970] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[82.31427 ]
 [82.250305]
 [82.140015]
 [82.032555]
 [81.96839 ]], R is [[82.30236816]
 [82.23668671]
 [82.17312622]
 [82.11010742]
 [82.04798889]].
[2019-03-27 06:44:42,167] A3C_AGENT_WORKER-Thread-20 INFO:Local step 68500, global step 1087456: loss 184.8213
[2019-03-27 06:44:42,169] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 68500, global step 1087456: learning rate 0.0000
[2019-03-27 06:44:44,597] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68000, global step 1088594: loss 0.0064
[2019-03-27 06:44:44,599] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68000, global step 1088594: learning rate 0.0000
[2019-03-27 06:44:45,754] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.1898749e-21 8.2292102e-09 2.5251316e-21 6.4576216e-15], sum to 1.0000
[2019-03-27 06:44:45,765] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2071
[2019-03-27 06:44:45,773] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 899373.4978417328 W.
[2019-03-27 06:44:45,777] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.5820650802195025, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 899373.4978417328, 899373.4978417335, 207781.8698276027], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1002600.0000, 
sim time next is 1003200.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.2696869615583254, 1.0, 1.0, 0.2696869615583254, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 825848.6254040695, 825848.6254040695, 253852.1440356786], 
processed observation next is [1.0, 0.6086956521739131, 0.22274881516587688, 0.96, 1.0, 1.0, 0.1201047729618378, 1.0, 0.5, 0.1201047729618378, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.22940239594557488, 0.22940239594557488, 0.378883797068177], 
reward next is 0.6211, 
noisyNet noise sample is [array([-0.09835439], dtype=float32), -1.0190437]. 
=============================================
[2019-03-27 06:44:46,064] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68000, global step 1089271: loss 0.0084
[2019-03-27 06:44:46,068] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68000, global step 1089274: learning rate 0.0000
[2019-03-27 06:44:46,245] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68000, global step 1089359: loss 0.0105
[2019-03-27 06:44:46,248] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68000, global step 1089359: learning rate 0.0000
[2019-03-27 06:44:46,762] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.8814708e-01 7.7037706e-17 1.1852948e-02 1.5056217e-18 1.5914598e-12], sum to 1.0000
[2019-03-27 06:44:46,771] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8093
[2019-03-27 06:44:46,781] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 993549.7098396294 W.
[2019-03-27 06:44:46,785] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.7, 97.5, 1.0, 2.0, 0.327597177530205, 1.0, 1.0, 0.327597177530205, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 993549.7098396294, 993549.7098396294, 264999.7851931742], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1009800.0000, 
sim time next is 1010400.0000, 
raw observation next is [21.7, 97.66666666666666, 1.0, 2.0, 0.3311439985348936, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5842531838384045, 6.9112, 6.9112, 168.912956510431, 1009089.464480017, 1009089.464480017, 239513.1330825562], 
processed observation next is [1.0, 0.6956521739130435, 0.2274881516587678, 0.9766666666666666, 1.0, 1.0, 0.19414939582517304, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.49299168760781037, 0.0, 0.0, 0.8294399451523027, 0.2803026290222269, 0.2803026290222269, 0.35748228818291966], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.03802907], dtype=float32), -0.4859452]. 
=============================================
[2019-03-27 06:44:47,649] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68000, global step 1090013: loss 0.0097
[2019-03-27 06:44:47,652] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68000, global step 1090013: learning rate 0.0000
[2019-03-27 06:44:47,779] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68000, global step 1090072: loss 0.0134
[2019-03-27 06:44:47,781] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68000, global step 1090072: learning rate 0.0000
[2019-03-27 06:44:47,877] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68000, global step 1090114: loss 0.0112
[2019-03-27 06:44:47,878] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68000, global step 1090115: learning rate 0.0000
[2019-03-27 06:44:48,585] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68000, global step 1090446: loss 0.0162
[2019-03-27 06:44:48,589] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68000, global step 1090447: learning rate 0.0000
[2019-03-27 06:44:48,611] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68000, global step 1090456: loss 0.0151
[2019-03-27 06:44:48,613] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68000, global step 1090456: learning rate 0.0000
[2019-03-27 06:44:48,739] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68000, global step 1090518: loss 0.0162
[2019-03-27 06:44:48,741] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68000, global step 1090519: learning rate 0.0000
[2019-03-27 06:44:48,775] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68000, global step 1090532: loss 0.0171
[2019-03-27 06:44:48,781] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68000, global step 1090533: learning rate 0.0000
[2019-03-27 06:44:49,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68000, global step 1090659: loss 0.0184
[2019-03-27 06:44:49,043] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68000, global step 1090661: learning rate 0.0000
[2019-03-27 06:44:49,397] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68000, global step 1090828: loss 0.0178
[2019-03-27 06:44:49,400] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68000, global step 1090829: learning rate 0.0000
[2019-03-27 06:44:50,516] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.2663580e-01 7.0537741e-17 7.3364221e-02 9.9577698e-19 3.0815615e-12], sum to 1.0000
[2019-03-27 06:44:50,525] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9541
[2019-03-27 06:44:50,532] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.93333333333334, 74.66666666666667, 1.0, 2.0, 0.5098537287380699, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 795483.9604288415, 795483.9604288415, 194903.199821288], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1081200.0000, 
sim time next is 1081800.0000, 
raw observation next is [24.1, 74.0, 1.0, 2.0, 0.2408658414065566, 0.0, 2.0, 0.0, 1.0, 1.0, 0.4315544800662163, 6.911200000000001, 6.9112, 168.912956510431, 752163.233374909, 752163.2333749083, 211993.0690744173], 
processed observation next is [1.0, 0.5217391304347826, 0.3412322274881518, 0.74, 1.0, 1.0, 0.08538053181512842, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.30677375617831254, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20893423149303028, 0.2089342314930301, 0.3164075657827124], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.23674726], dtype=float32), -0.30094945]. 
=============================================
[2019-03-27 06:44:50,795] A3C_AGENT_WORKER-Thread-22 INFO:Local step 68500, global step 1091481: loss -108.8825
[2019-03-27 06:44:50,797] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 68500, global step 1091481: learning rate 0.0000
[2019-03-27 06:44:51,170] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.5903501e-24 9.7422088e-12 7.7835170e-25 1.8864474e-18], sum to 1.0000
[2019-03-27 06:44:51,178] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0533
[2019-03-27 06:44:51,187] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.26666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5895223734047756, 6.9112, 6.9112, 168.912956510431, 512324.9343246977, 512324.9343246977, 164517.4776925557], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1100400.0000, 
sim time next is 1101000.0000, 
raw observation next is [25.13333333333333, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5933181359655255, 6.9112, 6.9112, 168.912956510431, 515907.662497577, 515907.662497577, 165081.6086741851], 
processed observation next is [1.0, 0.7391304347826086, 0.3902053712480251, 0.695, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5040465072750311, 0.0, 0.0, 0.8294399451523027, 0.14330768402710473, 0.14330768402710473, 0.24639046070773893], 
reward next is 0.7536, 
noisyNet noise sample is [array([-1.5100381], dtype=float32), -1.3806596]. 
=============================================
[2019-03-27 06:44:51,207] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.853264]
 [68.01248 ]
 [62.98128 ]
 [56.853138]
 [55.06685 ]], R is [[73.21546173]
 [73.23775482]
 [73.26107025]
 [73.2820816 ]
 [72.549263  ]].
[2019-03-27 06:44:53,620] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69000, global step 1092789: loss 0.0643
[2019-03-27 06:44:53,622] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69000, global step 1092789: learning rate 0.0000
[2019-03-27 06:44:54,456] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.7028140e-29 2.1519874e-15 4.8108521e-28 7.7742411e-22], sum to 1.0000
[2019-03-27 06:44:54,465] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4548
[2019-03-27 06:44:54,470] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7811647256269818, 6.911199999999999, 6.9112, 168.912956510431, 657033.2627142441, 657033.2627142448, 198048.8400952483], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1280400.0000, 
sim time next is 1281000.0000, 
raw observation next is [25.25, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.784029404993834, 6.911199999999999, 6.9112, 168.912956510431, 659733.1560217439, 659733.1560217445, 198631.3103367044], 
processed observation next is [1.0, 0.8260869565217391, 0.39573459715639814, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7366212256022364, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18325921000603998, 0.18325921000604015, 0.29646464229358865], 
reward next is 0.7035, 
noisyNet noise sample is [array([-0.02513627], dtype=float32), -1.7165596]. 
=============================================
[2019-03-27 06:44:54,487] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[78.14933 ]
 [78.682304]
 [79.500244]
 [79.85924 ]
 [80.13315 ]], R is [[78.06243896]
 [77.98622131]
 [77.9102478 ]
 [77.83459473]
 [77.75933075]].
[2019-03-27 06:44:58,069] A3C_AGENT_WORKER-Thread-9 INFO:Local step 68500, global step 1095149: loss 10.4333
[2019-03-27 06:44:58,070] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 68500, global step 1095149: learning rate 0.0000
[2019-03-27 06:44:58,224] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69000, global step 1095250: loss 0.0496
[2019-03-27 06:44:58,225] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69000, global step 1095251: learning rate 0.0000
[2019-03-27 06:44:59,387] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.6236062e-30 8.4575117e-16 8.3310604e-31 2.6437496e-23], sum to 1.0000
[2019-03-27 06:44:59,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8233
[2019-03-27 06:44:59,403] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.794348668301667, 6.9112, 6.9112, 168.912956510431, 665988.6470284841, 665988.6470284841, 200677.8981378503], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1276800.0000, 
sim time next is 1277400.0000, 
raw observation next is [26.15, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7904124792830638, 6.911200000000001, 6.9112, 168.912956510431, 663133.1128216296, 663133.112821629, 199884.8526974788], 
processed observation next is [1.0, 0.782608695652174, 0.43838862559241704, 0.8333333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7444054625403217, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18420364245045268, 0.1842036424504525, 0.29833560104101314], 
reward next is 0.7017, 
noisyNet noise sample is [array([-0.92682326], dtype=float32), 0.378047]. 
=============================================
[2019-03-27 06:45:00,885] A3C_AGENT_WORKER-Thread-11 INFO:Local step 68500, global step 1096607: loss 18.0088
[2019-03-27 06:45:00,886] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 68500, global step 1096607: learning rate 0.0000
[2019-03-27 06:45:02,511] A3C_AGENT_WORKER-Thread-21 INFO:Local step 68500, global step 1097370: loss 83.2457
[2019-03-27 06:45:02,515] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 68500, global step 1097370: learning rate 0.0000
[2019-03-27 06:45:02,730] A3C_AGENT_WORKER-Thread-12 INFO:Local step 68500, global step 1097470: loss -35.8500
[2019-03-27 06:45:02,734] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 68500, global step 1097471: learning rate 0.0000
[2019-03-27 06:45:03,932] A3C_AGENT_WORKER-Thread-14 INFO:Local step 68500, global step 1098028: loss 159.4381
[2019-03-27 06:45:03,934] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 68500, global step 1098030: learning rate 0.0000
[2019-03-27 06:45:04,300] A3C_AGENT_WORKER-Thread-2 INFO:Local step 68500, global step 1098203: loss 19.6549
[2019-03-27 06:45:04,302] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 68500, global step 1098204: learning rate 0.0000
[2019-03-27 06:45:04,345] A3C_AGENT_WORKER-Thread-19 INFO:Local step 68500, global step 1098224: loss 134.1064
[2019-03-27 06:45:04,349] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 68500, global step 1098226: learning rate 0.0000
[2019-03-27 06:45:04,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9418300e-01 2.0373461e-18 5.8170529e-03 2.5326154e-20 2.2206974e-12], sum to 1.0000
[2019-03-27 06:45:04,397] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7375
[2019-03-27 06:45:04,406] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1077827.981601202 W.
[2019-03-27 06:45:04,409] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.58333333333334, 88.5, 1.0, 2.0, 0.3419789577389395, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6160595774806117, 6.911200000000001, 6.9112, 168.9129565104184, 1077827.981601202, 1077827.981601202, 247159.588410507], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1345800.0000, 
sim time next is 1346400.0000, 
raw observation next is [21.5, 88.0, 1.0, 2.0, 0.6717172765459011, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1065116.051778607, 1065116.051778607, 229766.6195722309], 
processed observation next is [1.0, 0.6086956521739131, 0.21800947867298584, 0.88, 1.0, 1.0, 0.6044786464408447, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.29586556993850194, 0.29586556993850194, 0.342935253092882], 
reward next is 0.6571, 
noisyNet noise sample is [array([0.9406549], dtype=float32), 2.354098]. 
=============================================
[2019-03-27 06:45:05,029] A3C_AGENT_WORKER-Thread-16 INFO:Local step 68500, global step 1098537: loss 108.9556
[2019-03-27 06:45:05,030] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 68500, global step 1098537: learning rate 0.0000
[2019-03-27 06:45:05,085] A3C_AGENT_WORKER-Thread-3 INFO:Local step 68500, global step 1098560: loss -99.3041
[2019-03-27 06:45:05,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 68500, global step 1098560: learning rate 0.0000
[2019-03-27 06:45:05,088] A3C_AGENT_WORKER-Thread-17 INFO:Local step 68500, global step 1098561: loss 18.1862
[2019-03-27 06:45:05,091] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 68500, global step 1098562: learning rate 0.0000
[2019-03-27 06:45:05,133] A3C_AGENT_WORKER-Thread-10 INFO:Local step 68500, global step 1098584: loss 47.6289
[2019-03-27 06:45:05,135] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 68500, global step 1098584: learning rate 0.0000
[2019-03-27 06:45:05,318] A3C_AGENT_WORKER-Thread-18 INFO:Local step 68500, global step 1098672: loss 56.6607
[2019-03-27 06:45:05,319] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 68500, global step 1098672: learning rate 0.0000
[2019-03-27 06:45:05,590] A3C_AGENT_WORKER-Thread-15 INFO:Local step 68500, global step 1098795: loss 69.1780
[2019-03-27 06:45:05,593] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 68500, global step 1098796: learning rate 0.0000
[2019-03-27 06:45:06,782] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69000, global step 1099356: loss 0.0520
[2019-03-27 06:45:06,787] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69000, global step 1099356: learning rate 0.0000
[2019-03-27 06:45:07,561] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.00000000e+00 1.03524347e-24 1.11021733e-10 5.01132666e-25
 1.09229250e-17], sum to 1.0000
[2019-03-27 06:45:07,572] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4837
[2019-03-27 06:45:07,578] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 95.33333333333333, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8852854042141604, 6.911200000000001, 6.9112, 168.9129565103944, 747100.2603858158, 747100.2603858152, 220490.13099919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1910400.0000, 
sim time next is 1911000.0000, 
raw observation next is [23.95, 95.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8625548876752244, 6.911199999999999, 6.9112, 168.912956510431, 728947.7098201105, 728947.709820111, 215366.7668638001], 
processed observation next is [1.0, 0.08695652173913043, 0.3341232227488152, 0.9516666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8323840093600295, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2024854749500307, 0.20248547495003086, 0.32144293561761206], 
reward next is 0.6786, 
noisyNet noise sample is [array([0.29139858], dtype=float32), -3.1795058]. 
=============================================
[2019-03-27 06:45:07,591] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[66.01865 ]
 [64.317764]
 [66.917984]
 [71.074715]
 [72.1848  ]], R is [[68.46447754]
 [68.45074463]
 [68.44342804]
 [68.40858459]
 [67.72450256]].
[2019-03-27 06:45:08,166] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:45:08,167] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:45:08,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:45:08,168] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:45:08,170] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:45:08,171] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:45:08,172] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:45:08,173] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:45:08,172] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:45:08,175] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:45:08,176] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:45:08,196] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run45
[2019-03-27 06:45:08,214] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run45
[2019-03-27 06:45:08,216] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run45
[2019-03-27 06:45:08,243] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run45
[2019-03-27 06:45:08,284] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run45
[2019-03-27 06:45:10,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:45:10,472] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.70703539833333, 84.51569667333334, 1.0, 2.0, 0.5023695810021711, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 816052.5585170028, 816052.5585170028, 196025.8196473709]
[2019-03-27 06:45:10,473] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:45:10,474] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 8.7274582e-21 2.0796595e-08 2.2471411e-21 4.2256356e-15], sampled 0.44140650588902575
[2019-03-27 06:45:38,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:45:38,573] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.33333333333333, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.015962420400266, 6.9112, 6.9112, 168.9128561911062, 817501.0754936758, 817501.0754936758, 251112.2892793942]
[2019-03-27 06:45:38,575] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:45:38,579] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 1.22280696e-30 1.08522726e-18 1.09274015e-29
 5.24584392e-23], sampled 0.7956990649739142
[2019-03-27 06:45:39,313] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:45:39,314] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.71666666666667, 96.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8907199445770392, 6.911200000000001, 6.9112, 168.912956510431, 745011.1813455288, 745011.1813455282, 221592.7100847689]
[2019-03-27 06:45:39,315] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:45:39,318] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 5.1938484e-25 9.2090203e-13 1.0507122e-24 9.3024328e-19], sampled 0.6653453751276999
[2019-03-27 06:45:43,117] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:45:43,119] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.6, 84.0, 1.0, 2.0, 0.8848942044591367, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1236815.347597194, 1236815.347597193, 265815.926851036]
[2019-03-27 06:45:43,121] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:45:43,125] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0216473e-01 1.1132155e-15 1.9783524e-01 2.2736485e-17 4.4888013e-11], sampled 0.08265073365937503
[2019-03-27 06:45:43,126] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1236815.347597194 W.
[2019-03-27 06:46:04,060] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:46:04,061] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.13333333333334, 46.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.021926279135839, 6.9112, 168.9121028950842, 907384.2033464393, 828831.5669971925, 254812.3207165276]
[2019-03-27 06:46:04,062] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:46:04,064] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.5903343e-21 2.6808047e-10 1.3304884e-21 5.0012663e-16], sampled 0.4025778555201569
[2019-03-27 06:46:04,065] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 907384.2033464393 W.
[2019-03-27 06:47:02,883] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06597032]
[2019-03-27 06:47:02,884] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.01666666666667, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5732749410046798, 6.911199999999999, 6.9112, 168.912956510431, 503979.9818044975, 503979.9818044982, 161989.2785026919]
[2019-03-27 06:47:02,887] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:47:02,889] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.2400062e-30 5.9829834e-19 5.1174125e-29 8.3774643e-23], sampled 0.9800702571592641
[2019-03-27 06:47:03,524] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7936.6590 2942652940.7183 1289.0000
[2019-03-27 06:47:03,576] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7191.5825 3324459281.7121 2096.0000
[2019-03-27 06:47:03,606] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7818.3085 2993774588.4139 1457.0000
[2019-03-27 06:47:03,716] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6909.4560 3191183288.1196 2351.0000
[2019-03-27 06:47:03,774] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7183.8835 3112748247.1222 1886.0000
[2019-03-27 06:47:04,789] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1100000, evaluation results [1100000.0, 7191.582523588788, 3324459281.712098, 2096.0, 7183.883547179641, 3112748247.122164, 1886.0, 7936.659009807539, 2942652940.7183113, 1289.0, 6909.456038498042, 3191183288.1195803, 2351.0, 7818.30853658411, 2993774588.4139147, 1457.0]
[2019-03-27 06:47:06,908] A3C_AGENT_WORKER-Thread-13 INFO:Local step 69500, global step 1100957: loss 0.2483
[2019-03-27 06:47:06,910] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 69500, global step 1100958: learning rate 0.0000
[2019-03-27 06:47:09,533] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 5.6483495e-26 4.8185248e-15 1.0487770e-26 2.6090003e-19], sum to 1.0000
[2019-03-27 06:47:09,542] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1866
[2019-03-27 06:47:09,549] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.68333333333333, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6736577476667679, 6.911200000000001, 6.9112, 168.912956510431, 589032.288008013, 589032.2880080125, 177961.2375442752], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1566600.0000, 
sim time next is 1567200.0000, 
raw observation next is [21.66666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.588969477184166, 6.9112, 6.9112, 168.912956510431, 515053.3206021808, 515053.3206021808, 164370.4563737181], 
processed observation next is [1.0, 0.13043478260869565, 0.22590837282780438, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49874326485873904, 0.0, 0.0, 0.8294399451523027, 0.14307036683393912, 0.14307036683393912, 0.24532903936375836], 
reward next is 0.7547, 
noisyNet noise sample is [array([1.0931588], dtype=float32), -0.61244684]. 
=============================================
[2019-03-27 06:47:11,580] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69000, global step 1103064: loss 0.0382
[2019-03-27 06:47:11,582] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69000, global step 1103065: learning rate 0.0000
[2019-03-27 06:47:12,261] A3C_AGENT_WORKER-Thread-20 INFO:Local step 69500, global step 1103372: loss -11.8612
[2019-03-27 06:47:12,263] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 69500, global step 1103373: learning rate 0.0000
[2019-03-27 06:47:14,920] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69000, global step 1104569: loss 0.0565
[2019-03-27 06:47:14,923] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69000, global step 1104570: learning rate 0.0000
[2019-03-27 06:47:16,140] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9061477e-01 1.5711560e-18 9.3851918e-03 7.8072408e-20 1.3003374e-14], sum to 1.0000
[2019-03-27 06:47:16,154] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4933
[2019-03-27 06:47:16,163] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1140751.043513526 W.
[2019-03-27 06:47:16,168] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.03333333333333, 85.0, 1.0, 2.0, 0.3859893678746947, 1.0, 1.0, 0.3859893678746947, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1140751.043513526, 1140751.043513526, 276079.287355149], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1603200.0000, 
sim time next is 1603800.0000, 
raw observation next is [24.05, 85.0, 1.0, 2.0, 0.3975220422835193, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6902727819326595, 6.911200000000001, 6.9112, 168.9129565104166, 1182281.588705999, 1182281.588705998, 263543.5654664619], 
processed observation next is [1.0, 0.5652173913043478, 0.3388625592417062, 0.85, 1.0, 1.0, 0.2741229425102642, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.6222838804056824, 8.881784197001253e-17, 0.0, 0.829439945152232, 0.3284115524183331, 0.32841155241833275, 0.3933486051738237], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.10894198], dtype=float32), 0.2938668]. 
=============================================
[2019-03-27 06:47:16,459] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69000, global step 1105262: loss 0.0867
[2019-03-27 06:47:16,462] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69000, global step 1105263: learning rate 0.0000
[2019-03-27 06:47:16,727] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69000, global step 1105379: loss 0.0803
[2019-03-27 06:47:16,730] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69000, global step 1105381: learning rate 0.0000
[2019-03-27 06:47:18,014] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69000, global step 1105959: loss 0.0765
[2019-03-27 06:47:18,017] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69000, global step 1105959: learning rate 0.0000
[2019-03-27 06:47:18,424] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69000, global step 1106145: loss 0.1025
[2019-03-27 06:47:18,425] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69000, global step 1106145: learning rate 0.0000
[2019-03-27 06:47:18,502] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69000, global step 1106181: loss 0.0607
[2019-03-27 06:47:18,504] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69000, global step 1106182: learning rate 0.0000
[2019-03-27 06:47:18,505] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.5763975e-24 1.3870823e-10 3.0359673e-24 1.4068235e-17], sum to 1.0000
[2019-03-27 06:47:18,517] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6811
[2019-03-27 06:47:18,523] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 98.66666666666669, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8155012181381598, 6.911200000000001, 6.9112, 168.912956510431, 689628.8592915381, 689628.8592915375, 205174.2750306117], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1664400.0000, 
sim time next is 1665000.0000, 
raw observation next is [23.55, 98.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8079500139979895, 6.9112, 6.9112, 168.912956510431, 683266.0980582122, 683266.0980582122, 203593.4391213515], 
processed observation next is [1.0, 0.2608695652173913, 0.3151658767772513, 0.985, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7657926999975481, 0.0, 0.0, 0.8294399451523027, 0.1897961383495034, 0.1897961383495034, 0.30387080465873356], 
reward next is 0.6961, 
noisyNet noise sample is [array([-0.35894763], dtype=float32), 0.43604997]. 
=============================================
[2019-03-27 06:47:18,541] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.309494]
 [68.17225 ]
 [68.221695]
 [68.15215 ]
 [68.03016 ]], R is [[68.35562134]
 [68.3658371 ]
 [68.35025024]
 [68.36791229]
 [68.38502502]].
[2019-03-27 06:47:18,630] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 8.3451007e-28 5.1996263e-14 1.9739104e-28 1.4461618e-20], sum to 1.0000
[2019-03-27 06:47:18,638] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6568
[2019-03-27 06:47:18,643] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.1, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7223003721461932, 6.911200000000001, 6.9112, 168.912956510431, 614862.2907928545, 614862.2907928539, 186780.4270814839], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1640400.0000, 
sim time next is 1641000.0000, 
raw observation next is [23.1, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7221020069017042, 6.9112, 6.9112, 168.912956510431, 614692.7642501778, 614692.7642501778, 186743.6669238317], 
processed observation next is [1.0, 1.0, 0.2938388625592418, 0.98, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6611000084167123, 0.0, 0.0, 0.8294399451523027, 0.17074799006949382, 0.17074799006949382, 0.2787218909310921], 
reward next is 0.7213, 
noisyNet noise sample is [array([-0.19618562], dtype=float32), -0.27544785]. 
=============================================
[2019-03-27 06:47:18,656] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[73.53909]
 [73.51402]
 [73.4823 ]
 [73.44285]
 [73.37456]], R is [[73.54940796]
 [73.53513336]
 [73.52104187]
 [73.50723267]
 [73.4937439 ]].
[2019-03-27 06:47:19,202] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69000, global step 1106491: loss 0.1920
[2019-03-27 06:47:19,204] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69000, global step 1106492: learning rate 0.0000
[2019-03-27 06:47:19,265] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69000, global step 1106517: loss 0.0925
[2019-03-27 06:47:19,266] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69000, global step 1106518: learning rate 0.0000
[2019-03-27 06:47:19,323] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69000, global step 1106547: loss 0.1740
[2019-03-27 06:47:19,325] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69000, global step 1106547: learning rate 0.0000
[2019-03-27 06:47:19,361] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69000, global step 1106563: loss 0.1605
[2019-03-27 06:47:19,364] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69000, global step 1106563: learning rate 0.0000
[2019-03-27 06:47:19,556] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69000, global step 1106650: loss 0.0730
[2019-03-27 06:47:19,559] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69000, global step 1106650: learning rate 0.0000
[2019-03-27 06:47:19,703] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69000, global step 1106717: loss 0.0714
[2019-03-27 06:47:19,706] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69000, global step 1106717: learning rate 0.0000
[2019-03-27 06:47:21,495] A3C_AGENT_WORKER-Thread-22 INFO:Local step 69500, global step 1107502: loss 0.1213
[2019-03-27 06:47:21,498] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 69500, global step 1107504: learning rate 0.0000
[2019-03-27 06:47:22,744] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.8485279e-26 4.3915788e-11 5.8379466e-27 4.5863827e-20], sum to 1.0000
[2019-03-27 06:47:22,747] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5761
[2019-03-27 06:47:22,752] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.28333333333333, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8548612676068265, 6.911199999999999, 6.9112, 168.912956510431, 707371.1733267297, 707371.1733267304, 213276.0141870552], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1710600.0000, 
sim time next is 1711200.0000, 
raw observation next is [27.16666666666667, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8563800329819866, 6.9112, 6.9112, 168.912956510431, 708811.6099787478, 708811.6099787478, 213617.1213618048], 
processed observation next is [1.0, 0.8260869565217391, 0.4865718799368091, 0.8333333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8248536987585203, 0.0, 0.0, 0.8294399451523027, 0.1968921138829855, 0.1968921138829855, 0.3188315244206042], 
reward next is 0.6812, 
noisyNet noise sample is [array([-1.1499872], dtype=float32), -0.7198049]. 
=============================================
[2019-03-27 06:47:24,701] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70000, global step 1108932: loss -157.9286
[2019-03-27 06:47:24,706] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70000, global step 1108933: learning rate 0.0000
[2019-03-27 06:47:26,032] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.3829283e-26 1.9039079e-13 1.4602433e-26 1.2036399e-19], sum to 1.0000
[2019-03-27 06:47:26,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7742
[2019-03-27 06:47:26,048] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666666, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7518382398641515, 6.9112, 6.9112, 168.912956510431, 643284.1023015733, 643284.1023015733, 192388.6031205198], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1842000.0000, 
sim time next is 1842600.0000, 
raw observation next is [23.78333333333333, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7612659502680013, 6.9112, 6.9112, 168.912956510431, 650784.5697517538, 650784.5697517538, 194221.8532670813], 
processed observation next is [1.0, 0.30434782608695654, 0.3262243285939968, 0.9033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7088609149609771, 0.0, 0.0, 0.8294399451523027, 0.1807734915977094, 0.1807734915977094, 0.28988336308519597], 
reward next is 0.7101, 
noisyNet noise sample is [array([1.2771113], dtype=float32), -0.09925113]. 
=============================================
[2019-03-27 06:47:29,356] A3C_AGENT_WORKER-Thread-9 INFO:Local step 69500, global step 1111105: loss 0.5364
[2019-03-27 06:47:29,360] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 69500, global step 1111106: learning rate 0.0000
[2019-03-27 06:47:29,611] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70000, global step 1111223: loss -228.7917
[2019-03-27 06:47:29,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70000, global step 1111223: learning rate 0.0000
[2019-03-27 06:47:30,391] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.1145618e-02 9.4135230e-18 9.8885441e-01 1.2163874e-20 2.0031600e-12], sum to 1.0000
[2019-03-27 06:47:30,398] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0169
[2019-03-27 06:47:30,404] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.9, 86.0, 1.0, 2.0, 0.5770953344545606, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9645767344862461, 6.911199999999999, 6.9112, 168.912956510431, 1613496.677925594, 1613496.677925594, 344897.1812810727], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1857600.0000, 
sim time next is 1858200.0000, 
raw observation next is [26.0, 85.83333333333334, 1.0, 2.0, 0.551581772337254, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9227491587815505, 6.911199999999999, 6.9112, 168.912956510431, 1542111.673213212, 1542111.673213213, 330205.4043234182], 
processed observation next is [1.0, 0.5217391304347826, 0.4312796208530806, 0.8583333333333334, 1.0, 1.0, 0.4597370751051253, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9057916570506712, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4283643536703367, 0.42836435367033693, 0.4928438870498779], 
reward next is 0.5072, 
noisyNet noise sample is [array([-0.58498424], dtype=float32), -0.06592353]. 
=============================================
[2019-03-27 06:47:32,450] A3C_AGENT_WORKER-Thread-11 INFO:Local step 69500, global step 1112554: loss -16.1353
[2019-03-27 06:47:32,452] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 69500, global step 1112554: learning rate 0.0000
[2019-03-27 06:47:34,084] A3C_AGENT_WORKER-Thread-21 INFO:Local step 69500, global step 1113324: loss 0.0447
[2019-03-27 06:47:34,087] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 69500, global step 1113324: learning rate 0.0000
[2019-03-27 06:47:34,169] A3C_AGENT_WORKER-Thread-12 INFO:Local step 69500, global step 1113362: loss 0.1600
[2019-03-27 06:47:34,171] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 69500, global step 1113362: learning rate 0.0000
[2019-03-27 06:47:35,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.9367406e-02 2.3465784e-17 9.8063260e-01 6.6892299e-21 3.3082992e-12], sum to 1.0000
[2019-03-27 06:47:35,356] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7052
[2019-03-27 06:47:35,360] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.0, 76.0, 1.0, 2.0, 0.432163799584556, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7207886147637766, 6.911200000000001, 6.9112, 168.9129565104288, 1212078.262302023, 1212078.262302022, 269517.5225881145], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1945800.0000, 
sim time next is 1946400.0000, 
raw observation next is [27.06666666666667, 75.66666666666667, 1.0, 2.0, 0.4334255126372403, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7227086204369549, 6.9112, 6.9112, 168.912956510431, 1215179.01720031, 1215179.01720031, 270016.2446192879], 
processed observation next is [1.0, 0.5217391304347826, 0.48183254344391807, 0.7566666666666667, 1.0, 1.0, 0.3173801357075184, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6618397810206766, 0.0, 0.0, 0.8294399451523027, 0.3375497270000861, 0.3375497270000861, 0.40300932032729536], 
reward next is 0.5970, 
noisyNet noise sample is [array([0.11582902], dtype=float32), -1.7601222]. 
=============================================
[2019-03-27 06:47:35,407] A3C_AGENT_WORKER-Thread-14 INFO:Local step 69500, global step 1113941: loss 0.0213
[2019-03-27 06:47:35,410] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 69500, global step 1113942: learning rate 0.0000
[2019-03-27 06:47:35,929] A3C_AGENT_WORKER-Thread-19 INFO:Local step 69500, global step 1114183: loss 0.0643
[2019-03-27 06:47:35,932] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 69500, global step 1114184: learning rate 0.0000
[2019-03-27 06:47:35,992] A3C_AGENT_WORKER-Thread-2 INFO:Local step 69500, global step 1114211: loss 0.0800
[2019-03-27 06:47:35,994] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 69500, global step 1114212: learning rate 0.0000
[2019-03-27 06:47:36,553] A3C_AGENT_WORKER-Thread-17 INFO:Local step 69500, global step 1114471: loss 0.1323
[2019-03-27 06:47:36,555] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 69500, global step 1114471: learning rate 0.0000
[2019-03-27 06:47:36,569] A3C_AGENT_WORKER-Thread-16 INFO:Local step 69500, global step 1114481: loss 0.1053
[2019-03-27 06:47:36,573] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 69500, global step 1114482: learning rate 0.0000
[2019-03-27 06:47:36,625] A3C_AGENT_WORKER-Thread-3 INFO:Local step 69500, global step 1114505: loss 0.0404
[2019-03-27 06:47:36,630] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 69500, global step 1114506: learning rate 0.0000
[2019-03-27 06:47:36,911] A3C_AGENT_WORKER-Thread-10 INFO:Local step 69500, global step 1114638: loss 0.1160
[2019-03-27 06:47:36,914] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 69500, global step 1114638: learning rate 0.0000
[2019-03-27 06:47:37,039] A3C_AGENT_WORKER-Thread-15 INFO:Local step 69500, global step 1114696: loss 0.0365
[2019-03-27 06:47:37,041] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 69500, global step 1114696: learning rate 0.0000
[2019-03-27 06:47:37,077] A3C_AGENT_WORKER-Thread-18 INFO:Local step 69500, global step 1114714: loss 0.0664
[2019-03-27 06:47:37,083] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 69500, global step 1114716: learning rate 0.0000
[2019-03-27 06:47:38,552] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70000, global step 1115396: loss -233.9427
[2019-03-27 06:47:38,556] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70000, global step 1115397: learning rate 0.0000
[2019-03-27 06:47:41,846] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.5619353e-28 3.0771971e-16 3.9875782e-27 2.2014426e-21], sum to 1.0000
[2019-03-27 06:47:41,852] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7087
[2019-03-27 06:47:41,856] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.76666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8538194728831964, 6.9112, 6.9112, 168.912956510431, 707557.854038222, 707557.854038222, 213081.7444970296], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2046000.0000, 
sim time next is 2046600.0000, 
raw observation next is [26.7, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.850673364969116, 6.9112, 6.9112, 168.912956510431, 705354.5522846185, 705354.5522846185, 212403.8816028467], 
processed observation next is [0.0, 0.6956521739130435, 0.46445497630331756, 0.855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8178943475233122, 0.0, 0.0, 0.8294399451523027, 0.19593182007906068, 0.19593182007906068, 0.3170207188102189], 
reward next is 0.6830, 
noisyNet noise sample is [array([1.3294488], dtype=float32), 0.5605271]. 
=============================================
[2019-03-27 06:47:42,242] A3C_AGENT_WORKER-Thread-13 INFO:Local step 70500, global step 1117103: loss 18.1646
[2019-03-27 06:47:42,250] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 70500, global step 1117106: learning rate 0.0000
[2019-03-27 06:47:44,660] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.3952614e-27 2.1190754e-16 6.4007114e-26 3.9692136e-20], sum to 1.0000
[2019-03-27 06:47:44,669] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8014
[2019-03-27 06:47:44,675] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.01666666666667, 96.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7711244315189717, 6.9112, 6.9112, 168.912956510431, 649923.4768743078, 649923.4768743078, 196068.6014675192], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2087400.0000, 
sim time next is 2088000.0000, 
raw observation next is [24.0, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7726538168211766, 6.9112, 6.9112, 168.912956510431, 651176.1322495863, 651176.1322495863, 196371.6342398335], 
processed observation next is [0.0, 0.17391304347826086, 0.3364928909952607, 0.97, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7227485570989958, 0.0, 0.0, 0.8294399451523027, 0.1808822589582184, 0.1808822589582184, 0.29309199140273656], 
reward next is 0.7069, 
noisyNet noise sample is [array([-1.7437899], dtype=float32), -0.033756547]. 
=============================================
[2019-03-27 06:47:44,687] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[68.93828 ]
 [69.048515]
 [69.21483 ]
 [69.12043 ]
 [69.399605]], R is [[69.05615997]
 [69.0729599 ]
 [69.09008026]
 [69.10729218]
 [69.12445068]].
[2019-03-27 06:47:44,975] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 9.2793128e-29 2.3709974e-17 2.1606111e-27 2.0828840e-22], sum to 1.0000
[2019-03-27 06:47:44,983] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6830
[2019-03-27 06:47:44,990] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8102823847378993, 6.9112, 6.9112, 168.912956510431, 677141.0992138005, 677141.0992138005, 203917.65875625], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2097600.0000, 
sim time next is 2098200.0000, 
raw observation next is [25.35, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8156019833021715, 6.911199999999998, 6.9112, 168.912956510431, 680791.4856151243, 680791.4856151255, 205010.99185161], 
processed observation next is [0.0, 0.2608695652173913, 0.4004739336492892, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.775124369880697, -1.7763568394002506e-16, 0.0, 0.8294399451523027, 0.18910874600420122, 0.18910874600420152, 0.30598655500240296], 
reward next is 0.6940, 
noisyNet noise sample is [array([0.07542861], dtype=float32), 0.026637217]. 
=============================================
[2019-03-27 06:47:45,603] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.1880819e-27 8.0692331e-15 3.7246946e-27 1.5757762e-19], sum to 1.0000
[2019-03-27 06:47:45,611] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9380
[2019-03-27 06:47:45,619] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.85, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8745989972578208, 6.911199999999999, 6.9112, 168.912956510431, 723022.6742631162, 723022.6742631169, 217652.4493347597], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2159400.0000, 
sim time next is 2160000.0000, 
raw observation next is [25.8, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.870077820934283, 6.9112, 6.9112, 168.912956510431, 719812.954775663, 719812.954775663, 216653.8840381278], 
processed observation next is [1.0, 0.0, 0.42180094786729866, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8415583182125402, 0.0, 0.0, 0.8294399451523027, 0.1999480429932397, 0.1999480429932397, 0.32336400602705645], 
reward next is 0.6766, 
noisyNet noise sample is [array([1.5369979], dtype=float32), 0.7893136]. 
=============================================
[2019-03-27 06:47:45,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[72.053246]
 [72.04302 ]
 [72.03569 ]
 [72.01556 ]
 [71.98292 ]], R is [[69.68955994]
 [69.66781616]
 [69.64513397]
 [69.62203979]
 [69.59835815]].
[2019-03-27 06:47:46,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.8840154e-27 3.6407133e-14 5.5295976e-27 1.7024626e-19], sum to 1.0000
[2019-03-27 06:47:46,259] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3189
[2019-03-27 06:47:46,264] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.05, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9981192560938135, 6.911200000000001, 6.9112, 168.9128703671369, 803894.3670526021, 803894.3670526015, 246529.7430192794], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2124600.0000, 
sim time next is 2125200.0000, 
raw observation next is [30.1, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9901313810673317, 6.9112, 6.9112, 168.912956510431, 797168.9587472043, 797168.9587472043, 244468.840059775], 
processed observation next is [0.0, 0.6086956521739131, 0.6255924170616115, 0.7666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9879650988625994, 0.0, 0.0, 0.8294399451523027, 0.22143582187422342, 0.22143582187422342, 0.3648788657608582], 
reward next is 0.6351, 
noisyNet noise sample is [array([1.4402483], dtype=float32), -0.7735546]. 
=============================================
[2019-03-27 06:47:46,572] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70000, global step 1119110: loss -161.6312
[2019-03-27 06:47:46,575] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70000, global step 1119112: learning rate 0.0000
[2019-03-27 06:47:47,275] A3C_AGENT_WORKER-Thread-20 INFO:Local step 70500, global step 1119442: loss 19.8794
[2019-03-27 06:47:47,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 70500, global step 1119444: learning rate 0.0000
[2019-03-27 06:47:49,540] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70000, global step 1120503: loss -207.2635
[2019-03-27 06:47:49,544] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70000, global step 1120503: learning rate 0.0000
[2019-03-27 06:47:51,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70000, global step 1121276: loss -165.6544
[2019-03-27 06:47:51,196] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70000, global step 1121276: learning rate 0.0000
[2019-03-27 06:47:51,269] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70000, global step 1121312: loss -246.8392
[2019-03-27 06:47:51,271] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70000, global step 1121312: learning rate 0.0000
[2019-03-27 06:47:52,043] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 7.1774633e-25 2.1897542e-10 4.6584868e-26 8.0152840e-19], sum to 1.0000
[2019-03-27 06:47:52,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4841
[2019-03-27 06:47:52,059] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.48333333333333, 81.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9397187131494642, 6.9112, 6.9112, 168.912956510431, 765053.40405665, 765053.40405665, 232404.2128861697], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2235000.0000, 
sim time next is 2235600.0000, 
raw observation next is [28.4, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9359355137894775, 6.9112, 6.9112, 168.912956510431, 762642.4945186689, 762642.4945186689, 231522.1584410361], 
processed observation next is [1.0, 0.9130434782608695, 0.5450236966824644, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9218725777920456, 0.0, 0.0, 0.8294399451523027, 0.2118451373662969, 0.2118451373662969, 0.3455554603597554], 
reward next is 0.6544, 
noisyNet noise sample is [array([0.7585439], dtype=float32), -0.1367779]. 
=============================================
[2019-03-27 06:47:52,509] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70000, global step 1121890: loss -229.5918
[2019-03-27 06:47:52,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70000, global step 1121891: learning rate 0.0000
[2019-03-27 06:47:52,725] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [7.8755599e-03 4.2724471e-17 9.9212450e-01 1.5738617e-19 5.3075112e-13], sum to 1.0000
[2019-03-27 06:47:52,734] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7314
[2019-03-27 06:47:52,739] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.65, 71.5, 1.0, 2.0, 0.4046370948492157, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6891659630610101, 6.911199999999999, 6.9112, 168.912956510431, 1131065.067225003, 1131065.067225004, 259606.1401477391], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2362200.0000, 
sim time next is 2362800.0000, 
raw observation next is [29.8, 71.0, 1.0, 2.0, 0.5924071655616138, 0.0, 2.0, 0.0, 1.0, 2.0, 1.010394016416815, 6.911199999999999, 6.9112, 168.912956510431, 1656340.321282614, 1656340.321282614, 358784.2377766384], 
processed observation next is [1.0, 0.34782608695652173, 0.6113744075829385, 0.71, 1.0, 1.0, 0.508924295857366, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0126756297766037, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.460094533689615, 0.460094533689615, 0.5354988623531917], 
reward next is 0.4645, 
noisyNet noise sample is [array([-0.52127874], dtype=float32), -0.38389093]. 
=============================================
[2019-03-27 06:47:53,188] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70000, global step 1122207: loss -209.3495
[2019-03-27 06:47:53,191] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70000, global step 1122207: learning rate 0.0000
[2019-03-27 06:47:53,217] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70000, global step 1122221: loss -179.3931
[2019-03-27 06:47:53,217] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70000, global step 1122221: learning rate 0.0000
[2019-03-27 06:47:53,721] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70000, global step 1122454: loss -211.6132
[2019-03-27 06:47:53,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70000, global step 1122455: learning rate 0.0000
[2019-03-27 06:47:53,763] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70000, global step 1122476: loss -149.6228
[2019-03-27 06:47:53,767] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70000, global step 1122477: learning rate 0.0000
[2019-03-27 06:47:53,788] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70000, global step 1122484: loss -213.7393
[2019-03-27 06:47:53,791] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70000, global step 1122485: learning rate 0.0000
[2019-03-27 06:47:53,910] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70000, global step 1122540: loss -211.4210
[2019-03-27 06:47:53,915] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70000, global step 1122543: learning rate 0.0000
[2019-03-27 06:47:54,153] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70000, global step 1122655: loss -186.3759
[2019-03-27 06:47:54,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70000, global step 1122656: learning rate 0.0000
[2019-03-27 06:47:54,210] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70000, global step 1122680: loss -155.6660
[2019-03-27 06:47:54,216] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70000, global step 1122680: learning rate 0.0000
[2019-03-27 06:47:56,026] A3C_AGENT_WORKER-Thread-22 INFO:Local step 70500, global step 1123525: loss 26.0703
[2019-03-27 06:47:56,030] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 70500, global step 1123526: learning rate 0.0000
[2019-03-27 06:47:56,264] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.3020927e-26 9.1038191e-16 2.5286640e-25 2.1721732e-19], sum to 1.0000
[2019-03-27 06:47:56,273] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6413
[2019-03-27 06:47:56,277] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7078194493310157, 6.9112, 6.9112, 168.912956510431, 604254.4559888901, 604254.4559888901, 184135.2729800051], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2716200.0000, 
sim time next is 2716800.0000, 
raw observation next is [22.33333333333334, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6996155276869206, 6.911200000000001, 6.9112, 168.912956510431, 598459.2025114512, 598459.2025114506, 182660.0993938208], 
processed observation next is [0.0, 0.43478260869565216, 0.2575039494470777, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6336774727889274, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.166238667364292, 0.16623866736429185, 0.27262701402062806], 
reward next is 0.7274, 
noisyNet noise sample is [array([-0.88936555], dtype=float32), 1.391762]. 
=============================================
[2019-03-27 06:47:56,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [3.8163257e-01 1.3971373e-15 6.1836743e-01 1.4998911e-18 4.1882639e-10], sum to 1.0000
[2019-03-27 06:47:56,700] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3618
[2019-03-27 06:47:56,708] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1034724.728228783 W.
[2019-03-27 06:47:56,714] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 81.0, 1.0, 2.0, 0.3701882445110835, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6243247498127226, 6.911200000000001, 6.9112, 168.912956510431, 1034724.728228783, 1034724.728228782, 244740.1672421756], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2352000.0000, 
sim time next is 2352600.0000, 
raw observation next is [27.5, 80.5, 1.0, 2.0, 0.7381116248727769, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1031557.89457807, 1031557.89457807, 229284.8272385669], 
processed observation next is [1.0, 0.21739130434782608, 0.5023696682464456, 0.805, 1.0, 1.0, 0.6844718371961168, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.28654385960501944, 0.28654385960501944, 0.34221616005756256], 
reward next is 0.6578, 
noisyNet noise sample is [array([0.96013045], dtype=float32), 0.15114178]. 
=============================================
[2019-03-27 06:47:59,122] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71000, global step 1124973: loss 0.1536
[2019-03-27 06:47:59,126] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71000, global step 1124973: learning rate 0.0000
[2019-03-27 06:47:59,188] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 06:47:59,190] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:47:59,192] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:47:59,193] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:47:59,194] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:47:59,196] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:47:59,195] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:47:59,196] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:47:59,197] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:47:59,199] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:47:59,199] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:47:59,223] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run46
[2019-03-27 06:47:59,242] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run46
[2019-03-27 06:47:59,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run46
[2019-03-27 06:47:59,265] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run46
[2019-03-27 06:47:59,286] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run46
[2019-03-27 06:48:05,870] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:48:05,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.44612795333333, 91.12891054500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5759626149121648, 6.9112, 6.9112, 168.912956510431, 504253.8158051017, 504253.8158051017, 162440.4953742884]
[2019-03-27 06:48:05,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:48:05,875] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.6539711e-27 5.6559222e-17 6.3840048e-27 5.8186215e-21], sampled 0.9200260926667
[2019-03-27 06:48:06,475] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:48:06,478] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.57028973, 79.42255848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5137416848996538, 6.9112, 6.9112, 168.912956510431, 453658.0625438562, 453658.0625438562, 153786.9571941544]
[2019-03-27 06:48:06,479] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:48:06,482] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.2310180e-27 2.3012428e-17 5.3713847e-26 1.4261545e-20], sampled 0.894608554120453
[2019-03-27 06:48:10,564] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:48:10,565] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.16666666666667, 49.83333333333334, 1.0, 2.0, 0.6262301717348786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1031855.432564975, 1031855.432564975, 221349.0515353472]
[2019-03-27 06:48:10,569] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:48:10,572] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.4398116e-01 1.9395911e-13 3.5601887e-01 2.0430812e-15 1.4072326e-09], sampled 0.7971670456142173
[2019-03-27 06:48:47,151] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:48:47,152] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.0, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9222444398267734, 6.9112, 6.9112, 168.912956510431, 756183.9749321156, 756183.9749321156, 228456.7265777186]
[2019-03-27 06:48:47,154] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:48:47,157] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.0178566e-27 1.8359299e-16 9.6683116e-27 1.9339680e-20], sampled 0.944615704427905
[2019-03-27 06:49:03,676] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:49:03,678] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.552323215, 83.39293767000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.960115252967695, 6.9112, 168.9125444733459, 865124.884179041, 830422.8048412519, 254908.0203781144]
[2019-03-27 06:49:03,681] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:49:03,683] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.5712959e-22 1.6207567e-11 9.1466371e-23 7.3777542e-17], sampled 0.8787796174623755
[2019-03-27 06:49:07,983] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:49:07,984] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.63596468, 72.47617125, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 0.8977516605083465, 6.911200000000001, 6.9112, 168.912956510431, 761088.6310461583, 761088.6310461576, 223422.487168832]
[2019-03-27 06:49:07,985] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:49:07,987] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9989629e-01 5.0046929e-18 1.0370666e-04 1.3132486e-19 6.2141579e-13], sampled 0.8756885291377026
[2019-03-27 06:49:28,334] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.064243995]
[2019-03-27 06:49:28,335] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.2, 90.0, 1.0, 2.0, 0.7252774682936775, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1013612.785182869, 1013612.785182869, 226397.0147926121]
[2019-03-27 06:49:28,337] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:49:28,340] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [8.2039052e-01 2.4321120e-15 1.7960952e-01 1.5149952e-17 1.0764808e-10], sampled 0.37563988661954206
[2019-03-27 06:49:28,341] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1013612.785182869 W.
[2019-03-27 06:49:54,618] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6878.9340 3198913223.8075 2235.0000
[2019-03-27 06:49:54,690] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7157.6534 3329411179.0170 2032.0000
[2019-03-27 06:49:54,707] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7923.6791 2949047218.2944 1213.0000
[2019-03-27 06:49:54,798] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7170.4564 3121646048.6418 1732.0000
[2019-03-27 06:49:54,876] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7784.3813 3000339899.9520 1377.0000
[2019-03-27 06:49:55,896] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1125000, evaluation results [1125000.0, 7157.653372123707, 3329411179.0170217, 2032.0, 7170.456428553786, 3121646048.6418433, 1732.0, 7923.679144477986, 2949047218.294407, 1213.0, 6878.93402097159, 3198913223.8074665, 2235.0, 7784.38133178458, 3000339899.9519577, 1377.0]
[2019-03-27 06:50:00,770] A3C_AGENT_WORKER-Thread-9 INFO:Local step 70500, global step 1127194: loss 18.9581
[2019-03-27 06:50:00,771] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 70500, global step 1127194: learning rate 0.0000
[2019-03-27 06:50:00,908] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 9.3516017e-27 2.7099031e-17 3.3208357e-26 2.9794794e-20], sum to 1.0000
[2019-03-27 06:50:00,913] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4339
[2019-03-27 06:50:00,921] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7931339441959141, 6.911200000000001, 6.9112, 168.912956510431, 665038.1174227727, 665038.117422772, 200431.2600262336], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2701800.0000, 
sim time next is 2702400.0000, 
raw observation next is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7931378726155276, 6.9112, 6.9112, 168.912956510431, 665036.2425720012, 665036.2425720012, 200431.9472202384], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7477291129457654, 0.0, 0.0, 0.8294399451523027, 0.18473228960333365, 0.18473228960333365, 0.29915216003020656], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.47192642], dtype=float32), 0.8476609]. 
=============================================
[2019-03-27 06:50:01,003] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71000, global step 1127302: loss 0.1311
[2019-03-27 06:50:01,009] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71000, global step 1127303: learning rate 0.0000
[2019-03-27 06:50:03,614] A3C_AGENT_WORKER-Thread-11 INFO:Local step 70500, global step 1128476: loss 30.6181
[2019-03-27 06:50:03,616] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 70500, global step 1128476: learning rate 0.0000
[2019-03-27 06:50:05,352] A3C_AGENT_WORKER-Thread-12 INFO:Local step 70500, global step 1129260: loss 20.5728
[2019-03-27 06:50:05,354] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 70500, global step 1129260: learning rate 0.0000
[2019-03-27 06:50:05,403] A3C_AGENT_WORKER-Thread-21 INFO:Local step 70500, global step 1129286: loss 30.5554
[2019-03-27 06:50:05,404] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 70500, global step 1129286: learning rate 0.0000
[2019-03-27 06:50:06,854] A3C_AGENT_WORKER-Thread-14 INFO:Local step 70500, global step 1129939: loss 23.5683
[2019-03-27 06:50:06,856] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 70500, global step 1129939: learning rate 0.0000
[2019-03-27 06:50:07,523] A3C_AGENT_WORKER-Thread-2 INFO:Local step 70500, global step 1130237: loss 21.4095
[2019-03-27 06:50:07,524] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 70500, global step 1130237: learning rate 0.0000
[2019-03-27 06:50:07,813] A3C_AGENT_WORKER-Thread-19 INFO:Local step 70500, global step 1130371: loss 25.1033
[2019-03-27 06:50:07,817] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 70500, global step 1130371: learning rate 0.0000
[2019-03-27 06:50:07,864] A3C_AGENT_WORKER-Thread-3 INFO:Local step 70500, global step 1130388: loss 31.3493
[2019-03-27 06:50:07,867] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 70500, global step 1130389: learning rate 0.0000
[2019-03-27 06:50:08,176] A3C_AGENT_WORKER-Thread-10 INFO:Local step 70500, global step 1130534: loss 30.5475
[2019-03-27 06:50:08,177] A3C_AGENT_WORKER-Thread-16 INFO:Local step 70500, global step 1130534: loss 23.9841
[2019-03-27 06:50:08,178] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 70500, global step 1130534: learning rate 0.0000
[2019-03-27 06:50:08,181] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 70500, global step 1130534: learning rate 0.0000
[2019-03-27 06:50:08,191] A3C_AGENT_WORKER-Thread-17 INFO:Local step 70500, global step 1130540: loss 24.0434
[2019-03-27 06:50:08,193] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 70500, global step 1130540: learning rate 0.0000
[2019-03-27 06:50:08,604] A3C_AGENT_WORKER-Thread-15 INFO:Local step 70500, global step 1130720: loss 20.6751
[2019-03-27 06:50:08,608] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 70500, global step 1130720: learning rate 0.0000
[2019-03-27 06:50:08,728] A3C_AGENT_WORKER-Thread-18 INFO:Local step 70500, global step 1130781: loss 32.4958
[2019-03-27 06:50:08,734] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 70500, global step 1130783: learning rate 0.0000
[2019-03-27 06:50:08,958] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.9619665e-03 4.8730695e-18 9.9803799e-01 2.3169097e-21 8.1721858e-13], sum to 1.0000
[2019-03-27 06:50:08,965] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9463
[2019-03-27 06:50:08,970] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.96666666666667, 77.0, 1.0, 2.0, 0.2517685332839098, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4304591840416879, 6.911199999999999, 6.9112, 168.9129564947274, 703616.4538622596, 703616.4538622602, 207198.1592463962], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2568000.0000, 
sim time next is 2568600.0000, 
raw observation next is [28.9, 77.5, 1.0, 2.0, 0.2498541711905712, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4271991785540463, 6.911200000000001, 6.9112, 168.9129565104271, 698264.6358355493, 698264.6358355487, 206697.917987186], 
processed observation next is [1.0, 0.7391304347826086, 0.5687203791469194, 0.775, 1.0, 1.0, 0.09620984480791711, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3014624128707882, 8.881784197001253e-17, 0.0, 0.8294399451522836, 0.19396239884320815, 0.19396239884320798, 0.3085043552047552], 
reward next is 0.6915, 
noisyNet noise sample is [array([-2.1470091], dtype=float32), 1.3715887]. 
=============================================
[2019-03-27 06:50:09,530] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0912302e-25 2.4317145e-13 1.7245766e-25 5.6972980e-19], sum to 1.0000
[2019-03-27 06:50:09,538] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5422
[2019-03-27 06:50:09,545] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9166641930485997, 6.9112, 6.9112, 168.912956510431, 751039.0788716057, 751039.0788716057, 227108.8137588967], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2577600.0000, 
sim time next is 2578200.0000, 
raw observation next is [27.51666666666667, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9148246123184535, 6.9112, 6.9112, 168.912956510431, 749909.2179798466, 749909.2179798466, 226690.6550141037], 
processed observation next is [1.0, 0.8695652173913043, 0.5031595576619274, 0.8533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8961275759981139, 0.0, 0.0, 0.8294399451523027, 0.20830811610551295, 0.20830811610551295, 0.33834426121508016], 
reward next is 0.6617, 
noisyNet noise sample is [array([0.75805163], dtype=float32), 0.4255706]. 
=============================================
[2019-03-27 06:50:10,035] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71000, global step 1131341: loss 0.0439
[2019-03-27 06:50:10,038] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71000, global step 1131342: learning rate 0.0000
[2019-03-27 06:50:10,097] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.4457625e-29 2.4904658e-19 5.7079749e-28 8.9540673e-23], sum to 1.0000
[2019-03-27 06:50:10,106] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6306
[2019-03-27 06:50:10,116] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8133581832225774, 6.9112, 6.9112, 168.912956510431, 679546.2044620784, 679546.2044620784, 204556.5877799667], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2636400.0000, 
sim time next is 2637000.0000, 
raw observation next is [27.0, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8218164303639223, 6.9112, 6.9112, 168.912956510431, 685476.0028912062, 685476.0028912062, 206308.2222094923], 
processed observation next is [0.0, 0.5217391304347826, 0.4786729857819906, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7827029638584416, 0.0, 0.0, 0.8294399451523027, 0.19041000080311282, 0.19041000080311282, 0.30792271971566015], 
reward next is 0.6921, 
noisyNet noise sample is [array([-1.3960053], dtype=float32), 1.2055936]. 
=============================================
[2019-03-27 06:50:10,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.950356]
 [71.96388 ]
 [71.94268 ]
 [71.91775 ]
 [71.9362  ]], R is [[71.89467621]
 [71.87042236]
 [71.8484726 ]
 [71.82836151]
 [71.80908966]].
[2019-03-27 06:50:10,988] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.5724956e-29 5.6421867e-20 1.4181901e-28 2.4682077e-22], sum to 1.0000
[2019-03-27 06:50:11,001] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6215
[2019-03-27 06:50:11,007] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.95, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7361049684276473, 6.9112, 6.9112, 168.912956510431, 625771.8717359477, 625771.8717359477, 189357.5114457821], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2608200.0000, 
sim time next is 2608800.0000, 
raw observation next is [23.93333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7370847818167513, 6.9112, 6.9112, 168.912956510431, 626735.3034365972, 626735.3034365972, 189544.0038313558], 
processed observation next is [0.0, 0.17391304347826086, 0.3333333333333332, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6793716851423796, 0.0, 0.0, 0.8294399451523027, 0.17409313984349922, 0.17409313984349922, 0.28290149825575495], 
reward next is 0.7171, 
noisyNet noise sample is [array([-0.8343844], dtype=float32), 0.73567533]. 
=============================================
[2019-03-27 06:50:14,046] A3C_AGENT_WORKER-Thread-13 INFO:Local step 71500, global step 1133102: loss 18.3460
[2019-03-27 06:50:14,051] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 71500, global step 1133102: learning rate 0.0000
[2019-03-27 06:50:17,361] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0735604e-29 3.2469269e-20 3.2207365e-28 1.4958562e-22], sum to 1.0000
[2019-03-27 06:50:17,367] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5859
[2019-03-27 06:50:17,371] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7931378726155276, 6.9112, 6.9112, 168.912956510431, 665036.2425720012, 665036.2425720012, 200431.9472202384], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2702400.0000, 
sim time next is 2703000.0000, 
raw observation next is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.793093634227326, 6.9112, 6.9112, 168.912956510431, 664997.6485445339, 664997.6485445339, 200422.8828562894], 
processed observation next is [0.0, 0.2608695652173913, 0.3364928909952607, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.747675163691861, 0.0, 0.0, 0.8294399451523027, 0.1847215690401483, 0.1847215690401483, 0.29913863112879013], 
reward next is 0.7009, 
noisyNet noise sample is [array([1.6433998], dtype=float32), -0.22554196]. 
=============================================
[2019-03-27 06:50:17,393] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[75.059425]
 [75.02254 ]
 [74.9786  ]
 [74.92341 ]
 [74.836266]], R is [[75.04358673]
 [74.9940033 ]
 [74.94491577]
 [74.89633942]
 [74.84831238]].
[2019-03-27 06:50:18,532] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71000, global step 1135200: loss 0.0365
[2019-03-27 06:50:18,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71000, global step 1135200: learning rate 0.0000
[2019-03-27 06:50:19,311] A3C_AGENT_WORKER-Thread-20 INFO:Local step 71500, global step 1135562: loss 28.5429
[2019-03-27 06:50:19,313] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 71500, global step 1135562: learning rate 0.0000
[2019-03-27 06:50:21,271] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71000, global step 1136477: loss 0.0504
[2019-03-27 06:50:21,274] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71000, global step 1136478: learning rate 0.0000
[2019-03-27 06:50:22,880] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71000, global step 1137229: loss 0.0496
[2019-03-27 06:50:22,882] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71000, global step 1137230: learning rate 0.0000
[2019-03-27 06:50:22,959] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71000, global step 1137263: loss 0.0469
[2019-03-27 06:50:22,961] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71000, global step 1137263: learning rate 0.0000
[2019-03-27 06:50:24,218] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71000, global step 1137849: loss 0.0388
[2019-03-27 06:50:24,220] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71000, global step 1137849: learning rate 0.0000
[2019-03-27 06:50:24,929] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71000, global step 1138184: loss 0.0446
[2019-03-27 06:50:24,933] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71000, global step 1138185: learning rate 0.0000
[2019-03-27 06:50:25,195] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71000, global step 1138304: loss 0.0551
[2019-03-27 06:50:25,199] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71000, global step 1138304: learning rate 0.0000
[2019-03-27 06:50:25,294] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71000, global step 1138352: loss 0.0420
[2019-03-27 06:50:25,295] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71000, global step 1138352: learning rate 0.0000
[2019-03-27 06:50:25,570] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71000, global step 1138481: loss 0.0499
[2019-03-27 06:50:25,571] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71000, global step 1138481: learning rate 0.0000
[2019-03-27 06:50:25,624] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71000, global step 1138506: loss 0.0438
[2019-03-27 06:50:25,626] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71000, global step 1138506: learning rate 0.0000
[2019-03-27 06:50:25,636] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71000, global step 1138509: loss 0.0433
[2019-03-27 06:50:25,638] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71000, global step 1138509: learning rate 0.0000
[2019-03-27 06:50:25,882] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71000, global step 1138624: loss 0.0500
[2019-03-27 06:50:25,885] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71000, global step 1138626: learning rate 0.0000
[2019-03-27 06:50:26,108] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71000, global step 1138734: loss 0.0380
[2019-03-27 06:50:26,113] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71000, global step 1138735: learning rate 0.0000
[2019-03-27 06:50:27,714] A3C_AGENT_WORKER-Thread-22 INFO:Local step 71500, global step 1139486: loss 92.0095
[2019-03-27 06:50:27,716] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 71500, global step 1139486: learning rate 0.0000
[2019-03-27 06:50:31,382] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72000, global step 1141151: loss 4.3954
[2019-03-27 06:50:31,385] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72000, global step 1141152: learning rate 0.0000
[2019-03-27 06:50:31,621] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.9369198e-29 4.6695034e-17 2.2038715e-28 1.8428708e-22], sum to 1.0000
[2019-03-27 06:50:31,630] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6321
[2019-03-27 06:50:31,635] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.558303737864265, 6.9112, 6.9112, 168.912956510431, 490629.5866254861, 490629.5866254861, 159860.6366216317], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3006000.0000, 
sim time next is 3006600.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.557448300844475, 6.9112, 6.9112, 168.912956510431, 489877.750946229, 489877.750946229, 159740.4795723669], 
processed observation next is [1.0, 0.8260869565217391, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4603028059078964, 0.0, 0.0, 0.8294399451523027, 0.13607715304061915, 0.13607715304061915, 0.23841862622741328], 
reward next is 0.7616, 
noisyNet noise sample is [array([-0.8176274], dtype=float32), 0.25716293]. 
=============================================
[2019-03-27 06:50:35,879] A3C_AGENT_WORKER-Thread-9 INFO:Local step 71500, global step 1143253: loss 19.4812
[2019-03-27 06:50:35,880] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 71500, global step 1143253: learning rate 0.0000
[2019-03-27 06:50:35,906] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 5.117725e-29 7.147741e-16 8.000489e-29 3.139267e-23], sum to 1.0000
[2019-03-27 06:50:35,913] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6086
[2019-03-27 06:50:35,920] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5462879970506139, 6.9112, 6.9112, 168.912956510431, 480068.0505538478, 480068.0505538478, 158190.9900667077], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3030000.0000, 
sim time next is 3030600.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5457150417199633, 6.9112, 6.9112, 168.912956510431, 479564.4341337842, 479564.4341337842, 158112.3479465352], 
processed observation next is [1.0, 0.043478260869565216, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4459939533170284, 0.0, 0.0, 0.8294399451523027, 0.13321234281494004, 0.13321234281494004, 0.23598857902467943], 
reward next is 0.7640, 
noisyNet noise sample is [array([0.68528247], dtype=float32), -1.8905392]. 
=============================================
[2019-03-27 06:50:36,582] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72000, global step 1143584: loss 4.0846
[2019-03-27 06:50:36,585] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72000, global step 1143584: learning rate 0.0000
[2019-03-27 06:50:38,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.5368198e-01 2.7313006e-16 8.4631807e-01 1.9143476e-18 7.5967614e-11], sum to 1.0000
[2019-03-27 06:50:38,349] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0646
[2019-03-27 06:50:38,357] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1072419.908883996 W.
[2019-03-27 06:50:38,360] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.3836693196515604, 1.0, 1.0, 0.3836693196515604, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1072419.908883996, 1072419.908883996, 268084.0493256144], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3485400.0000, 
sim time next is 3486000.0000, 
raw observation next is [28.66666666666667, 71.33333333333334, 1.0, 2.0, 0.4049558195819505, 1.0, 2.0, 0.4049558195819505, 1.0, 1.0, 0.6858016433048797, 6.9112, 6.9112, 170.5573041426782, 1698374.345163626, 1698374.345163626, 353124.6423606818], 
processed observation next is [1.0, 0.34782608695652173, 0.5576619273301741, 0.7133333333333334, 1.0, 1.0, 0.2830793007011452, 1.0, 1.0, 0.2830793007011452, 1.0, 0.5, 0.616831272323024, 0.0, 0.0, 0.8375144448122397, 0.47177065143434055, 0.47177065143434055, 0.527051705015943], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6676725], dtype=float32), -1.3707789]. 
=============================================
[2019-03-27 06:50:38,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.172867]
 [53.616962]
 [52.93952 ]
 [52.468323]
 [51.296318]], R is [[50.55140686]
 [50.64577103]
 [50.75168228]
 [50.85832596]
 [50.95378113]].
[2019-03-27 06:50:38,439] A3C_AGENT_WORKER-Thread-11 INFO:Local step 71500, global step 1144447: loss 33.2289
[2019-03-27 06:50:38,442] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 71500, global step 1144448: learning rate 0.0000
[2019-03-27 06:50:39,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.1022543e-25 1.5308458e-13 8.3484841e-26 1.1597879e-19], sum to 1.0000
[2019-03-27 06:50:39,853] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6990
[2019-03-27 06:50:39,864] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9128006799425671, 6.911200000000001, 6.9112, 168.912956510431, 749198.064729427, 749198.0647294263, 226253.7832429883], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3374400.0000, 
sim time next is 3375000.0000, 
raw observation next is [26.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9096825898513086, 6.911200000000001, 6.9112, 168.912956510431, 747110.8380309978, 747110.8380309972, 225540.547417316], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8898568168918397, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20753078834194383, 0.20753078834194366, 0.33662768271241195], 
reward next is 0.6634, 
noisyNet noise sample is [array([0.58129954], dtype=float32), 0.94447136]. 
=============================================
[2019-03-27 06:50:39,876] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.70084]
 [67.85696]
 [68.63686]
 [69.14536]
 [70.02825]], R is [[67.67773438]
 [67.66326904]
 [67.6485672 ]
 [67.63370514]
 [67.61882782]].
[2019-03-27 06:50:40,088] A3C_AGENT_WORKER-Thread-21 INFO:Local step 71500, global step 1145208: loss -5.4744
[2019-03-27 06:50:40,089] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 71500, global step 1145208: learning rate 0.0000
[2019-03-27 06:50:40,267] A3C_AGENT_WORKER-Thread-12 INFO:Local step 71500, global step 1145290: loss -5.8093
[2019-03-27 06:50:40,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 71500, global step 1145290: learning rate 0.0000
[2019-03-27 06:50:40,377] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.8047243e-29 1.8922305e-15 2.1997389e-28 2.8292002e-21], sum to 1.0000
[2019-03-27 06:50:40,387] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4635
[2019-03-27 06:50:40,391] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333334, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8644596534733882, 6.9112, 6.9112, 168.912956510431, 715236.6926207957, 715236.6926207957, 215400.2542660612], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3189000.0000, 
sim time next is 3189600.0000, 
raw observation next is [26.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8749645846836195, 6.9112, 6.9112, 168.912956510431, 722148.2976788848, 722148.2976788848, 217692.8596885588], 
processed observation next is [1.0, 0.9565217391304348, 0.4312796208530806, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8475177861995359, 0.0, 0.0, 0.8294399451523027, 0.2005967493552458, 0.2005967493552458, 0.3249147159530728], 
reward next is 0.6751, 
noisyNet noise sample is [array([-0.22902423], dtype=float32), 0.115767814]. 
=============================================
[2019-03-27 06:50:41,573] A3C_AGENT_WORKER-Thread-14 INFO:Local step 71500, global step 1145897: loss -20.3610
[2019-03-27 06:50:41,577] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 71500, global step 1145897: learning rate 0.0000
[2019-03-27 06:50:42,152] A3C_AGENT_WORKER-Thread-2 INFO:Local step 71500, global step 1146166: loss 16.9934
[2019-03-27 06:50:42,154] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 71500, global step 1146166: learning rate 0.0000
[2019-03-27 06:50:42,344] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.4653819e-27 8.8826217e-16 1.4964110e-28 2.2680424e-21], sum to 1.0000
[2019-03-27 06:50:42,351] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1096
[2019-03-27 06:50:42,354] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.16666666666667, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7028331328324925, 6.9112, 6.9112, 168.912956510431, 609318.3751228197, 609318.3751228197, 183195.0248593034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3139800.0000, 
sim time next is 3140400.0000, 
raw observation next is [22.33333333333334, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021050413997562, 6.9112, 6.9112, 168.912956510431, 884800.8871292019, 884800.8871292019, 254169.6182467986], 
processed observation next is [1.0, 0.34782608695652173, 0.2575039494470777, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0256712365823928, 0.0, 0.0, 0.8294399451523027, 0.2457780242025561, 0.2457780242025561, 0.3793576391743263], 
reward next is 0.6206, 
noisyNet noise sample is [array([0.32612422], dtype=float32), 0.8920188]. 
=============================================
[2019-03-27 06:50:42,475] A3C_AGENT_WORKER-Thread-3 INFO:Local step 71500, global step 1146310: loss -2.0298
[2019-03-27 06:50:42,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 71500, global step 1146310: learning rate 0.0000
[2019-03-27 06:50:42,566] A3C_AGENT_WORKER-Thread-19 INFO:Local step 71500, global step 1146354: loss 131.7277
[2019-03-27 06:50:42,568] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 71500, global step 1146354: learning rate 0.0000
[2019-03-27 06:50:42,675] A3C_AGENT_WORKER-Thread-17 INFO:Local step 71500, global step 1146405: loss 22.8068
[2019-03-27 06:50:42,677] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 71500, global step 1146406: learning rate 0.0000
[2019-03-27 06:50:42,927] A3C_AGENT_WORKER-Thread-10 INFO:Local step 71500, global step 1146525: loss -6.5274
[2019-03-27 06:50:42,930] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 71500, global step 1146525: learning rate 0.0000
[2019-03-27 06:50:42,975] A3C_AGENT_WORKER-Thread-16 INFO:Local step 71500, global step 1146548: loss 50.5758
[2019-03-27 06:50:42,978] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 71500, global step 1146548: learning rate 0.0000
[2019-03-27 06:50:43,079] A3C_AGENT_WORKER-Thread-15 INFO:Local step 71500, global step 1146596: loss 48.6276
[2019-03-27 06:50:43,083] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 71500, global step 1146596: learning rate 0.0000
[2019-03-27 06:50:43,276] A3C_AGENT_WORKER-Thread-18 INFO:Local step 71500, global step 1146705: loss 13.5843
[2019-03-27 06:50:43,276] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 71500, global step 1146705: learning rate 0.0000
[2019-03-27 06:50:44,389] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72000, global step 1147374: loss 3.3003
[2019-03-27 06:50:44,392] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72000, global step 1147375: learning rate 0.0000
[2019-03-27 06:50:44,790] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.9712594e-29 8.0385594e-18 6.3352633e-28 1.2156448e-22], sum to 1.0000
[2019-03-27 06:50:44,796] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2201
[2019-03-27 06:50:44,800] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.33333333333334, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9783489253256389, 6.911199999999999, 6.9112, 168.912956510431, 789946.9347181612, 789946.9347181619, 241612.888529183], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3324000.0000, 
sim time next is 3324600.0000, 
raw observation next is [31.5, 68.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.983841607363287, 6.9112, 6.9112, 168.912956510431, 793418.4535766068, 793418.4535766068, 242946.3935462962], 
processed observation next is [0.0, 0.4782608695652174, 0.6919431279620853, 0.685, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9802946431259597, 0.0, 0.0, 0.8294399451523027, 0.22039401488239077, 0.22039401488239077, 0.3626065575317854], 
reward next is 0.6374, 
noisyNet noise sample is [array([-0.00711074], dtype=float32), -0.53616506]. 
=============================================
[2019-03-27 06:50:45,431] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.9390095e-28 6.4967596e-15 1.3998142e-27 1.1991709e-20], sum to 1.0000
[2019-03-27 06:50:45,439] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5401
[2019-03-27 06:50:45,444] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891724055738276, 6.9112, 6.9112, 168.912956510431, 733777.457917772, 733777.457917772, 221426.7314712169], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3614400.0000, 
sim time next is 3615000.0000, 
raw observation next is [29.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8890963407086651, 6.9112, 6.9112, 168.912956510431, 732219.4897511872, 732219.4897511872, 220847.057504823], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.74, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8647516350105671, 0.0, 0.0, 0.8294399451523027, 0.2033943027086631, 0.2033943027086631, 0.32962247388779553], 
reward next is 0.6704, 
noisyNet noise sample is [array([0.06892265], dtype=float32), -0.984059]. 
=============================================
[2019-03-27 06:50:45,459] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[70.48672 ]
 [70.8572  ]
 [71.244446]
 [72.12435 ]
 [72.5814  ]], R is [[70.29167175]
 [70.25826263]
 [70.22332001]
 [70.18689728]
 [70.14886475]].
[2019-03-27 06:50:48,739] A3C_AGENT_WORKER-Thread-13 INFO:Local step 72500, global step 1149409: loss 6.2474
[2019-03-27 06:50:48,741] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 72500, global step 1149409: learning rate 0.0000
[2019-03-27 06:50:50,001] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-27 06:50:50,003] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:50:50,004] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:50:50,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:50:50,007] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:50:50,007] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:50:50,008] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:50:50,008] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:50:50,009] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:50:50,011] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:50:50,010] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:50:50,026] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run47
[2019-03-27 06:50:50,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run47
[2019-03-27 06:50:50,048] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run47
[2019-03-27 06:50:50,067] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run47
[2019-03-27 06:50:50,108] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run47
[2019-03-27 06:51:08,334] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:08,336] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.24802762666667, 76.94591840333332, 1.0, 2.0, 0.6251871864873368, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.974453307777337, 6.9112, 168.9124851651488, 1748067.079418802, 1703193.131090141, 369308.1259662022]
[2019-03-27 06:51:08,338] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:51:08,340] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1768513e-01 2.4875863e-15 1.8231490e-01 2.5505222e-17 1.1874020e-10], sampled 0.7926457317393458
[2019-03-27 06:51:08,341] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1748067.079418802 W.
[2019-03-27 06:51:16,504] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:16,505] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.562086025, 94.11320066666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5665643201598746, 6.9112, 6.9112, 168.912956510431, 499254.0681959952, 499254.0681959952, 160984.2675191313]
[2019-03-27 06:51:16,506] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:51:16,508] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.7835788e-28 4.3041425e-18 1.3901294e-27 6.0506369e-22], sampled 0.5914675797990607
[2019-03-27 06:51:29,425] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:29,426] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.93333333333333, 67.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9446038778495647, 6.9112, 6.9112, 168.912956510431, 770812.3213947746, 770812.3213947746, 233675.5902676904]
[2019-03-27 06:51:29,427] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:51:29,429] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.8122963e-28 1.0259299e-17 1.1426956e-27 1.2770459e-21], sampled 0.27259028613193104
[2019-03-27 06:51:31,323] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:31,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.5027127, 91.08555677666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9263933998186163, 6.911200000000001, 6.9112, 168.912956510431, 757461.3503407857, 757461.3503407851, 229352.2519022982]
[2019-03-27 06:51:31,326] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:51:31,330] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 8.7231620e-29 1.2279991e-17 2.9587402e-28 4.9942539e-22], sampled 0.37409007935691196
[2019-03-27 06:51:31,395] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:31,398] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.2, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8918457317696469, 6.9112, 6.9112, 168.912956510431, 737050.5224120785, 737050.5224120785, 221574.2265531233]
[2019-03-27 06:51:31,399] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:51:31,401] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.0259951e-27 5.1364761e-16 1.4640745e-27 5.0757503e-21], sampled 0.923992529523889
[2019-03-27 06:51:50,133] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:51:50,134] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.9712318, 87.54822346, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9713506377573433, 6.9112, 6.9112, 168.912956510431, 789679.5966769634, 789679.5966769634, 240141.6572181818]
[2019-03-27 06:51:50,136] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:51:50,139] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 6.7225767e-23 1.2125607e-10 2.6699180e-23 2.5629849e-17], sampled 0.8719267853627602
[2019-03-27 06:52:16,692] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:52:16,693] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.8, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9214270468370634, 6.9112, 6.9112, 168.912956510431, 757360.8226193504, 757360.8226193504, 228339.7177779953]
[2019-03-27 06:52:16,694] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:52:16,697] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.4393699e-28 4.8783303e-18 8.6455149e-28 6.3284951e-22], sampled 0.5771568774611302
[2019-03-27 06:52:28,089] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:52:28,092] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.26666666666667, 74.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.002846090932501, 6.911200000000001, 6.9112, 168.9128475942049, 809772.9041410993, 809772.9041410987, 247866.0194061123]
[2019-03-27 06:52:28,093] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:52:28,098] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.9036448e-26 1.4099584e-13 9.3588100e-27 5.1820468e-20], sampled 0.990618936047979
[2019-03-27 06:52:43,652] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0649795]
[2019-03-27 06:52:43,652] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.200030465, 91.64242502333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8706749065182214, 6.911199999999999, 6.9112, 168.912956510431, 723106.2199491487, 723106.2199491493, 216881.1733455114]
[2019-03-27 06:52:43,655] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:52:43,660] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.4301360e-29 2.9099395e-19 9.1265336e-29 8.8513702e-23], sampled 0.6155227609247901
[2019-03-27 06:52:45,079] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7782.8038 2997072608.7293 1421.0000
[2019-03-27 06:52:45,231] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7169.5788 3326780006.4391 2065.0000
[2019-03-27 06:52:45,622] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6889.6500 3195033780.0483 2291.0000
[2019-03-27 06:52:45,677] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7177.9578 3116927650.2470 1789.0000
[2019-03-27 06:52:45,679] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7938.4303 2945780695.1889 1249.0000
[2019-03-27 06:52:46,696] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1150000, evaluation results [1150000.0, 7169.578784820862, 3326780006.4390903, 2065.0, 7177.957845580894, 3116927650.2470174, 1789.0, 7938.430272897655, 2945780695.188877, 1249.0, 6889.650002442392, 3195033780.048348, 2291.0, 7782.803845057192, 2997072608.7292895, 1421.0]
[2019-03-27 06:52:48,120] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [5.9393741e-02 6.5661793e-19 9.4060630e-01 3.1944606e-22 3.9251198e-14], sum to 1.0000
[2019-03-27 06:52:48,129] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8657
[2019-03-27 06:52:48,133] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.2622630682409776, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4538974730473033, 6.911199999999999, 6.9112, 168.9129564761402, 732955.6048397663, 732955.604839767, 210483.3761522464], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3432000.0000, 
sim time next is 3432600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.2595927051818298, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4491827498407764, 6.911200000000001, 6.9112, 168.9129565104224, 725490.1009434869, 725490.1009434863, 209736.1667913316], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.1079430182913612, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.32827164614728827, 8.881784197001253e-17, 0.0, 0.8294399451522604, 0.20152502803985747, 0.2015250280398573, 0.3130390549124352], 
reward next is 0.6870, 
noisyNet noise sample is [array([0.10320912], dtype=float32), -1.9854407]. 
=============================================
[2019-03-27 06:52:49,439] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72000, global step 1151235: loss 2.6822
[2019-03-27 06:52:49,442] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72000, global step 1151235: learning rate 0.0000
[2019-03-27 06:52:50,595] A3C_AGENT_WORKER-Thread-20 INFO:Local step 72500, global step 1151758: loss 5.9508
[2019-03-27 06:52:50,596] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 72500, global step 1151758: learning rate 0.0000
[2019-03-27 06:52:52,126] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72000, global step 1152447: loss 2.8446
[2019-03-27 06:52:52,130] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72000, global step 1152447: learning rate 0.0000
[2019-03-27 06:52:52,220] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.5400154e-24 1.0843140e-12 5.7502063e-25 9.9159589e-19], sum to 1.0000
[2019-03-27 06:52:52,226] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7427
[2019-03-27 06:52:52,234] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9096825898513086, 6.911200000000001, 6.9112, 168.912956510431, 747110.8380309978, 747110.8380309972, 225540.547417316], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3375000.0000, 
sim time next is 3375600.0000, 
raw observation next is [26.43333333333333, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9053347297691579, 6.9112, 6.9112, 168.912956510431, 744024.3292767715, 744024.3292767715, 224542.7182276738], 
processed observation next is [1.0, 0.043478260869565216, 0.4518167456556081, 0.9166666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.884554548498973, 0.0, 0.0, 0.8294399451523027, 0.2066734247991032, 0.2066734247991032, 0.33513838541443847], 
reward next is 0.6649, 
noisyNet noise sample is [array([-0.5449731], dtype=float32), 1.0840316]. 
=============================================
[2019-03-27 06:52:53,714] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72000, global step 1153158: loss 2.7084
[2019-03-27 06:52:53,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72000, global step 1153159: learning rate 0.0000
[2019-03-27 06:52:53,878] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72000, global step 1153205: loss 2.6906
[2019-03-27 06:52:53,880] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72000, global step 1153205: learning rate 0.0000
[2019-03-27 06:52:55,311] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72000, global step 1153857: loss 2.5784
[2019-03-27 06:52:55,312] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72000, global step 1153857: learning rate 0.0000
[2019-03-27 06:52:55,616] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72000, global step 1153989: loss 2.5772
[2019-03-27 06:52:55,618] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72000, global step 1153989: learning rate 0.0000
[2019-03-27 06:52:56,258] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72000, global step 1154279: loss 2.4516
[2019-03-27 06:52:56,260] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72000, global step 1154279: learning rate 0.0000
[2019-03-27 06:52:56,274] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72000, global step 1154286: loss 2.4266
[2019-03-27 06:52:56,276] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72000, global step 1154287: learning rate 0.0000
[2019-03-27 06:52:56,462] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72000, global step 1154369: loss 2.4487
[2019-03-27 06:52:56,464] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72000, global step 1154369: learning rate 0.0000
[2019-03-27 06:52:56,687] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72000, global step 1154466: loss 2.4806
[2019-03-27 06:52:56,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72000, global step 1154467: learning rate 0.0000
[2019-03-27 06:52:56,786] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72000, global step 1154515: loss 2.4427
[2019-03-27 06:52:56,788] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72000, global step 1154515: learning rate 0.0000
[2019-03-27 06:52:56,848] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72000, global step 1154538: loss 2.4491
[2019-03-27 06:52:56,851] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72000, global step 1154538: learning rate 0.0000
[2019-03-27 06:52:57,097] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72000, global step 1154649: loss 2.4428
[2019-03-27 06:52:57,099] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72000, global step 1154649: learning rate 0.0000
[2019-03-27 06:52:57,408] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.5714285e-01 1.2556234e-15 8.4285712e-01 3.4345025e-17 1.5292106e-10], sum to 1.0000
[2019-03-27 06:52:57,419] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5792
[2019-03-27 06:52:57,428] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [28.33333333333334, 72.66666666666667, 1.0, 2.0, 0.3831286812099785, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6429042718726619, 6.9112, 6.9112, 168.912956510431, 1070913.185520441, 1070913.185520441, 249331.3479186788], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3485400.0000, 
sim time next is 3486000.0000, 
raw observation next is [28.66666666666667, 71.33333333333334, 1.0, 2.0, 0.6070181046747548, 0.0, 2.0, 0.0, 1.0, 2.0, 1.020389673675383, 6.911199999999999, 6.9112, 168.912956510431, 1697224.429320909, 1697224.42932091, 364589.8718729254], 
processed observation next is [1.0, 0.34782608695652173, 0.5576619273301741, 0.7133333333333334, 1.0, 1.0, 0.5265278369575359, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0248654557016865, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.4714512303669192, 0.47145123036691944, 0.5441639878700378], 
reward next is 0.4558, 
noisyNet noise sample is [array([-1.0316985], dtype=float32), -1.381769]. 
=============================================
[2019-03-27 06:52:57,442] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[44.309998]
 [43.673115]
 [42.93826 ]
 [42.11155 ]
 [41.601913]], R is [[42.52972031]
 [42.73228836]
 [42.91733551]
 [43.10232162]
 [43.27533722]].
[2019-03-27 06:52:58,947] A3C_AGENT_WORKER-Thread-22 INFO:Local step 72500, global step 1155481: loss 13.8931
[2019-03-27 06:52:58,954] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 72500, global step 1155481: learning rate 0.0000
[2019-03-27 06:52:59,689] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.2469248e-07 7.8061980e-19 9.9999988e-01 1.5117693e-22 7.9113182e-15], sum to 1.0000
[2019-03-27 06:52:59,695] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3354
[2019-03-27 06:52:59,696] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2571988.73963604 W.
[2019-03-27 06:52:59,703] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 60.33333333333333, 1.0, 2.0, 0.6130229928130932, 1.0, 2.0, 0.6130229928130932, 1.0, 2.0, 1.03, 6.950116959016198, 6.9112, 170.5573041426782, 2571988.73963604, 2544110.938852058, 492748.6418041384], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3512400.0000, 
sim time next is 3513000.0000, 
raw observation next is [33.0, 59.66666666666667, 1.0, 2.0, 0.8993806786626166, 1.0, 2.0, 0.8993806786626166, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2515560.672548906, 2515560.672548907, 471153.5194900692], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.5966666666666667, 1.0, 1.0, 0.8787719020031526, 1.0, 1.0, 0.8787719020031526, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6987668534858072, 0.6987668534858075, 0.7032142081941332], 
reward next is 0.2968, 
noisyNet noise sample is [array([-0.34183294], dtype=float32), 1.6263045]. 
=============================================
[2019-03-27 06:52:59,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[43.68616 ]
 [42.84292 ]
 [42.087616]
 [42.237926]
 [42.15352 ]], R is [[44.06472778]
 [43.69404984]
 [43.2571106 ]
 [42.82453918]
 [42.39629364]].
[2019-03-27 06:53:03,701] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73000, global step 1157559: loss 0.0096
[2019-03-27 06:53:03,702] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73000, global step 1157559: learning rate 0.0000
[2019-03-27 06:53:04,365] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.7123373e-04 1.7553260e-14 9.9972874e-01 7.8487785e-18 1.9426391e-10], sum to 1.0000
[2019-03-27 06:53:04,372] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6054
[2019-03-27 06:53:04,377] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 72.0, 1.0, 2.0, 0.919071232255995, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.975014101075173, 6.9112, 168.9125272203106, 2181731.283826768, 2136459.479270189, 440466.7713461756], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3659400.0000, 
sim time next is 3660000.0000, 
raw observation next is [29.0, 72.66666666666666, 1.0, 2.0, 0.8114607883723239, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.976899414039471, 6.9112, 168.9125131253827, 2031113.353582119, 1984504.050409776, 411704.4435072173], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.7266666666666666, 1.0, 1.0, 0.7728443233401493, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.006569941403947066, 0.0, 0.829437767928733, 0.5641981537728109, 0.5512511251138267, 0.6144842440406229], 
reward next is 0.0570, 
noisyNet noise sample is [array([-0.3964889], dtype=float32), -1.367184]. 
=============================================
[2019-03-27 06:53:04,394] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[35.326424]
 [37.94834 ]
 [40.57395 ]
 [41.224857]
 [40.522392]], R is [[34.57215118]
 [34.24994659]
 [34.00230026]
 [34.24693298]
 [34.53570175]].
[2019-03-27 06:53:04,465] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.2735580e-05 1.0391991e-16 9.9998724e-01 1.1023235e-19 2.8287509e-12], sum to 1.0000
[2019-03-27 06:53:04,472] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9839
[2019-03-27 06:53:04,474] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 2726081.001682733 W.
[2019-03-27 06:53:04,480] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.66666666666667, 64.33333333333334, 1.0, 2.0, 0.9745653416876829, 1.0, 1.0, 0.9745653416876829, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2726081.001682733, 2726081.001682733, 513806.6628122479], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3591600.0000, 
sim time next is 3592200.0000, 
raw observation next is [32.83333333333333, 63.66666666666666, 1.0, 2.0, 0.6691969713541149, 1.0, 2.0, 0.65518852519132, 1.0, 1.0, 1.03, 7.00509530349155, 6.9112, 170.5573041426782, 2749092.35904519, 2681831.333737445, 511775.9239795099], 
processed observation next is [1.0, 0.5652173913043478, 0.7551342812006318, 0.6366666666666666, 1.0, 1.0, 0.6014421341615842, 1.0, 1.0, 0.5845644881823132, 1.0, 0.5, 1.0365853658536586, 0.009389530349154995, 0.0, 0.8375144448122397, 0.7636367664014416, 0.7449531482604014, 0.7638446626559849], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.91863686], dtype=float32), -0.020491425]. 
=============================================
[2019-03-27 06:53:04,880] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.9040630e-04 9.8281688e-16 9.9950957e-01 4.8825618e-19 6.6448617e-12], sum to 1.0000
[2019-03-27 06:53:04,888] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1314
[2019-03-27 06:53:04,893] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.6409479617353838, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005514151454767, 6.9112, 168.9123185194173, 1792172.522121065, 1725263.069757117, 372365.9528528554], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3991200.0000, 
sim time next is 3991800.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.6213018156308482, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.966796347725023, 6.9112, 168.912526600667, 1737194.418667287, 1697752.556498475, 368563.0958552947], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5437371272660821, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005559634772502342, 0.0, 0.829437834098548, 0.4825540051853575, 0.4715979323606875, 0.5500941729183504], 
reward next is 0.1719, 
noisyNet noise sample is [array([-1.3092644], dtype=float32), 0.542834]. 
=============================================
[2019-03-27 06:53:07,246] A3C_AGENT_WORKER-Thread-9 INFO:Local step 72500, global step 1159210: loss -8.8502
[2019-03-27 06:53:07,249] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 72500, global step 1159210: learning rate 0.0000
[2019-03-27 06:53:08,488] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.99996543e-01 6.18808905e-19 3.51629001e-06 1.08879256e-20
 1.72910677e-13], sum to 1.0000
[2019-03-27 06:53:08,496] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0411
[2019-03-27 06:53:08,506] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 869996.8232810905 W.
[2019-03-27 06:53:08,510] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.0, 71.0, 1.0, 1.0, 0.2075198207460142, 1.0, 1.0, 0.2075198207460142, 1.0, 2.0, 0.3603933007824109, 6.9112, 6.9112, 170.5573041426782, 869996.8232810905, 869996.8232810905, 271964.0122752297], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3920400.0000, 
sim time next is 3921000.0000, 
raw observation next is [32.0, 70.33333333333334, 1.0, 2.0, 0.3141830563173296, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5456320668987629, 6.9112, 6.9112, 168.9129564843997, 878118.1589793306, 878118.1589793306, 226629.3010533084], 
processed observation next is [0.0, 0.391304347826087, 0.7156398104265403, 0.7033333333333335, 1.0, 1.0, 0.17371452568352966, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.4458927645106864, 0.0, 0.0, 0.829439945024477, 0.24392171082759181, 0.24392171082759181, 0.33825268813926623], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.45419025], dtype=float32), 0.6230109]. 
=============================================
[2019-03-27 06:53:08,528] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.22278 ]
 [51.484287]
 [49.892536]
 [53.61309 ]
 [52.161816]], R is [[47.57321167]
 [47.09748077]
 [46.62650681]
 [46.16024399]
 [45.69864273]].
[2019-03-27 06:53:08,653] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73000, global step 1159867: loss 0.0108
[2019-03-27 06:53:08,658] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73000, global step 1159870: learning rate 0.0000
[2019-03-27 06:53:09,916] A3C_AGENT_WORKER-Thread-11 INFO:Local step 72500, global step 1160453: loss -9.6153
[2019-03-27 06:53:09,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 72500, global step 1160453: learning rate 0.0000
[2019-03-27 06:53:11,490] A3C_AGENT_WORKER-Thread-21 INFO:Local step 72500, global step 1161183: loss 41.7475
[2019-03-27 06:53:11,493] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 72500, global step 1161184: learning rate 0.0000
[2019-03-27 06:53:11,637] A3C_AGENT_WORKER-Thread-12 INFO:Local step 72500, global step 1161254: loss -8.2794
[2019-03-27 06:53:11,639] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 72500, global step 1161255: learning rate 0.0000
[2019-03-27 06:53:12,762] A3C_AGENT_WORKER-Thread-14 INFO:Local step 72500, global step 1161774: loss -18.4940
[2019-03-27 06:53:12,764] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 72500, global step 1161774: learning rate 0.0000
[2019-03-27 06:53:13,207] A3C_AGENT_WORKER-Thread-2 INFO:Local step 72500, global step 1161980: loss 39.5687
[2019-03-27 06:53:13,210] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 72500, global step 1161980: learning rate 0.0000
[2019-03-27 06:53:13,713] A3C_AGENT_WORKER-Thread-19 INFO:Local step 72500, global step 1162214: loss 73.5526
[2019-03-27 06:53:13,715] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 72500, global step 1162214: learning rate 0.0000
[2019-03-27 06:53:13,740] A3C_AGENT_WORKER-Thread-3 INFO:Local step 72500, global step 1162226: loss 39.6454
[2019-03-27 06:53:13,741] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 72500, global step 1162226: learning rate 0.0000
[2019-03-27 06:53:13,903] A3C_AGENT_WORKER-Thread-17 INFO:Local step 72500, global step 1162303: loss -12.6255
[2019-03-27 06:53:13,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 72500, global step 1162303: learning rate 0.0000
[2019-03-27 06:53:14,166] A3C_AGENT_WORKER-Thread-16 INFO:Local step 72500, global step 1162423: loss 12.0480
[2019-03-27 06:53:14,168] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 72500, global step 1162423: learning rate 0.0000
[2019-03-27 06:53:14,217] A3C_AGENT_WORKER-Thread-10 INFO:Local step 72500, global step 1162447: loss 3.9500
[2019-03-27 06:53:14,220] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 72500, global step 1162448: learning rate 0.0000
[2019-03-27 06:53:14,276] A3C_AGENT_WORKER-Thread-15 INFO:Local step 72500, global step 1162477: loss 9.9735
[2019-03-27 06:53:14,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 72500, global step 1162477: learning rate 0.0000
[2019-03-27 06:53:14,586] A3C_AGENT_WORKER-Thread-18 INFO:Local step 72500, global step 1162621: loss 54.7077
[2019-03-27 06:53:14,594] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 72500, global step 1162625: learning rate 0.0000
[2019-03-27 06:53:16,232] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [4.3927164e-07 1.1534929e-16 9.9999952e-01 3.1029673e-21 1.2182681e-13], sum to 1.0000
[2019-03-27 06:53:16,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6057
[2019-03-27 06:53:16,248] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3365758.598086684 W.
[2019-03-27 06:53:16,253] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 57.33333333333333, 1.0, 2.0, 0.9627403809942121, 1.0, 2.0, 0.8019602300113685, 1.0, 1.0, 1.03, 7.005118458142225, 6.9112, 170.5573041426782, 3365758.598086684, 3298480.98616079, 617172.9521220791], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4185600.0000, 
sim time next is 4186200.0000, 
raw observation next is [35.0, 56.66666666666667, 1.0, 2.0, 0.8729004640327904, 1.0, 2.0, 0.7570402715306579, 1.0, 2.0, 1.03, 7.005111369159055, 6.9112, 170.5573041426782, 3176993.550318236, 3109721.016519348, 581503.409641241], 
processed observation next is [1.0, 0.43478260869565216, 0.8578199052132701, 0.5666666666666668, 1.0, 1.0, 0.8468680289551692, 1.0, 1.0, 0.7072774355791058, 1.0, 1.0, 1.0365853658536586, 0.009391136915905474, 0.0, 0.8375144448122397, 0.8824982084217322, 0.8638113934775967, 0.8679155367779716], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.07813641], dtype=float32), -0.673221]. 
=============================================
[2019-03-27 06:53:16,423] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73000, global step 1163474: loss 0.0111
[2019-03-27 06:53:16,425] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73000, global step 1163474: learning rate 0.0000
[2019-03-27 06:53:20,348] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [4.8013933e-02 7.5881288e-16 9.5198607e-01 3.3563592e-18 2.6471098e-10], sum to 1.0000
[2019-03-27 06:53:20,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0287
[2019-03-27 06:53:20,373] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1586028.736033685 W.
[2019-03-27 06:53:20,378] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [29.0, 89.0, 1.0, 2.0, 0.5672782790950477, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9851747689944775, 6.911199999999999, 6.9112, 168.912956510431, 1586028.736033685, 1586028.736033686, 347073.984933506], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4336200.0000, 
sim time next is 4336800.0000, 
raw observation next is [29.0, 89.0, 1.0, 2.0, 1.03366408608803, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9126278131781, 1444892.299486231, 1444892.29948623, 309356.1706188539], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.89, 1.0, 1.0, 1.0405591398650964, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294383310983127, 0.4013589720795086, 0.4013589720795083, 0.4617256277893341], 
reward next is 0.5383, 
noisyNet noise sample is [array([-0.8776713], dtype=float32), -0.51220226]. 
=============================================
[2019-03-27 06:53:21,466] A3C_AGENT_WORKER-Thread-13 INFO:Local step 73500, global step 1165815: loss 219.5477
[2019-03-27 06:53:21,466] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 73500, global step 1165815: learning rate 0.0000
[2019-03-27 06:53:24,363] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73000, global step 1167165: loss 0.1399
[2019-03-27 06:53:24,366] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73000, global step 1167165: learning rate 0.0000
[2019-03-27 06:53:26,454] A3C_AGENT_WORKER-Thread-20 INFO:Local step 73500, global step 1168131: loss 247.9155
[2019-03-27 06:53:26,457] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 73500, global step 1168131: learning rate 0.0000
[2019-03-27 06:53:26,737] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7226173e-25 6.5446590e-14 8.7305948e-27 3.6596688e-19], sum to 1.0000
[2019-03-27 06:53:26,741] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1257
[2019-03-27 06:53:26,747] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9302314387006012, 6.9112, 6.9112, 168.912956510431, 759583.6708194437, 759583.6708194437, 230225.1057359312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4050600.0000, 
sim time next is 4051200.0000, 
raw observation next is [28.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9320647248243822, 6.9112, 6.9112, 168.912956510431, 761081.2257639385, 761081.2257639385, 230665.1970330832], 
processed observation next is [1.0, 0.9130434782608695, 0.5260663507109005, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9171521034443684, 0.0, 0.0, 0.8294399451523027, 0.21141145160109404, 0.21141145160109404, 0.3442764134822138], 
reward next is 0.6557, 
noisyNet noise sample is [array([0.63267285], dtype=float32), -0.44818524]. 
=============================================
[2019-03-27 06:53:26,990] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73000, global step 1168379: loss 0.1668
[2019-03-27 06:53:26,993] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73000, global step 1168380: learning rate 0.0000
[2019-03-27 06:53:28,679] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73000, global step 1169169: loss 0.0913
[2019-03-27 06:53:28,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73000, global step 1169170: learning rate 0.0000
[2019-03-27 06:53:28,768] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73000, global step 1169212: loss 0.0755
[2019-03-27 06:53:28,770] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73000, global step 1169212: learning rate 0.0000
[2019-03-27 06:53:29,871] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73000, global step 1169724: loss 0.0600
[2019-03-27 06:53:29,872] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73000, global step 1169724: learning rate 0.0000
[2019-03-27 06:53:30,259] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73000, global step 1169906: loss 0.1650
[2019-03-27 06:53:30,263] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73000, global step 1169906: learning rate 0.0000
[2019-03-27 06:53:30,718] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73000, global step 1170115: loss 0.0590
[2019-03-27 06:53:30,725] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73000, global step 1170116: learning rate 0.0000
[2019-03-27 06:53:30,781] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73000, global step 1170148: loss 0.1468
[2019-03-27 06:53:30,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73000, global step 1170148: learning rate 0.0000
[2019-03-27 06:53:31,187] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73000, global step 1170337: loss 0.0366
[2019-03-27 06:53:31,190] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73000, global step 1170337: learning rate 0.0000
[2019-03-27 06:53:31,330] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73000, global step 1170405: loss 0.1060
[2019-03-27 06:53:31,332] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73000, global step 1170405: learning rate 0.0000
[2019-03-27 06:53:31,433] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73000, global step 1170452: loss 0.1817
[2019-03-27 06:53:31,435] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73000, global step 1170452: learning rate 0.0000
[2019-03-27 06:53:31,459] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73000, global step 1170464: loss 0.0396
[2019-03-27 06:53:31,460] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73000, global step 1170464: learning rate 0.0000
[2019-03-27 06:53:31,771] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73000, global step 1170611: loss 0.1690
[2019-03-27 06:53:31,773] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73000, global step 1170612: learning rate 0.0000
[2019-03-27 06:53:33,513] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [4.7382149e-03 4.6587544e-14 9.9526179e-01 1.5674623e-17 1.3660340e-09], sum to 1.0000
[2019-03-27 06:53:33,522] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7110
[2019-03-27 06:53:33,527] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.0, 79.0, 1.0, 2.0, 0.9109385285966011, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005988458024886, 6.9112, 168.91231595523, 2170347.527379422, 2103101.587902026, 437098.2538161917], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4093200.0000, 
sim time next is 4093800.0000, 
raw observation next is [30.16666666666666, 79.00000000000001, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.504082967008251, 6.9112, 168.9101025486754, 2704670.201188455, 2284065.725610204, 474788.4050450838], 
processed observation next is [1.0, 0.391304347826087, 0.6287519747235385, 0.7900000000000001, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.05928829670082507, 0.0, 0.8294259308935334, 0.7512972781079041, 0.63446270155839, 0.7086394105150504], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.22545084], dtype=float32), 0.28373107]. 
=============================================
[2019-03-27 06:53:33,979] A3C_AGENT_WORKER-Thread-22 INFO:Local step 73500, global step 1171643: loss 227.7330
[2019-03-27 06:53:33,980] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 73500, global step 1171643: learning rate 0.0000
[2019-03-27 06:53:38,167] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74000, global step 1173607: loss 5.1367
[2019-03-27 06:53:38,170] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74000, global step 1173607: learning rate 0.0000
[2019-03-27 06:53:41,228] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-27 06:53:41,231] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:53:41,232] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:53:41,234] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:53:41,235] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:53:41,235] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:53:41,237] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:53:41,238] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:53:41,239] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:53:41,239] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:53:41,240] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:53:41,264] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run48
[2019-03-27 06:53:41,286] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run48
[2019-03-27 06:53:41,286] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run48
[2019-03-27 06:53:41,307] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run48
[2019-03-27 06:53:41,347] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run48
[2019-03-27 06:54:11,396] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:54:11,397] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8044923714177187, 6.9112, 6.9112, 168.912956510431, 675389.3848682782, 675389.3848682782, 202785.5160306449]
[2019-03-27 06:54:11,399] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:54:11,404] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.1329752e-29 2.7518192e-19 6.8449560e-29 9.4644588e-22], sampled 0.021221145420646348
[2019-03-27 06:54:16,973] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:54:16,974] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.2, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6699942626242491, 6.9112, 6.9112, 168.912956510431, 575958.5110913296, 575958.5110913296, 177469.38930288]
[2019-03-27 06:54:16,975] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:54:16,977] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.1898438e-27 8.4659237e-19 2.8095422e-27 7.7805941e-21], sampled 0.9316514002402158
[2019-03-27 06:54:28,690] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:54:28,691] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.86666666666667, 65.0, 1.0, 2.0, 0.697317729437305, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00135008184499, 6.9112, 168.9123463455573, 1871375.356903234, 1807420.017142973, 384244.1199850022]
[2019-03-27 06:54:28,691] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:54:28,693] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.8495476e-01 2.1447319e-13 7.1504521e-01 2.7228928e-16 1.4257466e-08], sampled 0.3066435483603509
[2019-03-27 06:54:29,453] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:54:29,454] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.13333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.919677416088108, 6.9112, 6.9112, 168.912956510431, 769104.946357038, 769104.946357038, 228374.4583099198]
[2019-03-27 06:54:29,455] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 06:54:29,457] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.1821814e-24 6.2524982e-15 5.8108683e-25 2.8794972e-18], sampled 0.523472957492068
[2019-03-27 06:54:33,061] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:54:33,063] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.36379884, 81.3343327, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9750225222265485, 6.9112, 6.9112, 168.912956510431, 817521.4609198094, 817521.4609198094, 242030.190458683]
[2019-03-27 06:54:33,066] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:54:33,070] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.2788758e-25 1.3254824e-15 6.9159406e-25 1.6916071e-18], sampled 0.9278997420426581
[2019-03-27 06:55:21,221] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.0630501]
[2019-03-27 06:55:21,222] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.33885798333333, 85.91572568333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.835255072701512, 6.9112, 6.9112, 168.912956510431, 700207.9355922166, 700207.9355922166, 209266.8426439397]
[2019-03-27 06:55:21,224] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:55:21,229] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.0570074e-28 3.7142953e-19 5.8337583e-28 4.6166949e-21], sampled 0.5429429925209417
[2019-03-27 06:55:33,622] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7939.5662 2946164899.4251 1258.0000
[2019-03-27 06:55:33,742] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7194.9055 3327005098.5758 2048.0000
[2019-03-27 06:55:33,746] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 6889.8191 3195401915.2905 2283.0000
[2019-03-27 06:55:33,840] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7796.9902 2997040827.8490 1431.0000
[2019-03-27 06:55:33,915] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7166.8061 3117982283.6004 1784.0000
[2019-03-27 06:55:34,933] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1175000, evaluation results [1175000.0, 7194.905495350406, 3327005098.5758147, 2048.0, 7166.806109086018, 3117982283.600388, 1784.0, 7939.566213783643, 2946164899.4251027, 1258.0, 6889.819127160239, 3195401915.2905464, 2283.0, 7796.99021290744, 2997040827.8490486, 1431.0]
[2019-03-27 06:55:35,285] A3C_AGENT_WORKER-Thread-9 INFO:Local step 73500, global step 1175162: loss 263.0173
[2019-03-27 06:55:35,286] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 73500, global step 1175162: learning rate 0.0000
[2019-03-27 06:55:36,256] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1026690e-06 5.7309658e-18 9.9999785e-01 6.0217719e-22 1.3093135e-14], sum to 1.0000
[2019-03-27 06:55:36,265] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3198
[2019-03-27 06:55:36,272] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 2 has been changed to 4 for the demand 3137723.204556695 W.
[2019-03-27 06:55:36,276] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [37.5, 46.5, 1.0, 2.0, 0.8542086205212434, 1.0, 2.0, 0.7476943497748844, 1.0, 1.0, 1.03, 7.00510989451404, 6.9112, 170.5573041426782, 3137723.204556695, 3070451.727106016, 574460.9097414825], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4293000.0000, 
sim time next is 4293600.0000, 
raw observation next is [37.33333333333333, 47.0, 1.0, 2.0, 0.8219426798351155, 1.0, 2.0, 0.7315613794318204, 1.0, 2.0, 1.03, 7.005107349193533, 6.9112, 170.5573041426782, 3069937.470155673, 3002667.816021609, 562611.0234806332], 
processed observation next is [1.0, 0.6956521739130435, 0.9684044233807265, 0.47, 1.0, 1.0, 0.7854731082350789, 1.0, 1.0, 0.6765799752190608, 1.0, 1.0, 1.0365853658536586, 0.009390734919353338, 0.0, 0.8375144448122397, 0.8527604083765759, 0.8340743933393359, 0.8397179454934823], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8340768], dtype=float32), -0.8485883]. 
=============================================
[2019-03-27 06:55:37,121] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74000, global step 1175990: loss 4.6023
[2019-03-27 06:55:37,122] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74000, global step 1175990: learning rate 0.0000
[2019-03-27 06:55:38,118] A3C_AGENT_WORKER-Thread-11 INFO:Local step 73500, global step 1176439: loss 218.3527
[2019-03-27 06:55:38,120] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 73500, global step 1176439: learning rate 0.0000
[2019-03-27 06:55:39,876] A3C_AGENT_WORKER-Thread-21 INFO:Local step 73500, global step 1177232: loss 224.6882
[2019-03-27 06:55:39,881] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 73500, global step 1177233: learning rate 0.0000
[2019-03-27 06:55:39,939] A3C_AGENT_WORKER-Thread-12 INFO:Local step 73500, global step 1177258: loss 189.8576
[2019-03-27 06:55:39,941] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 73500, global step 1177258: learning rate 0.0000
[2019-03-27 06:55:40,948] A3C_AGENT_WORKER-Thread-14 INFO:Local step 73500, global step 1177712: loss 223.4069
[2019-03-27 06:55:40,950] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 73500, global step 1177712: learning rate 0.0000
[2019-03-27 06:55:41,593] A3C_AGENT_WORKER-Thread-2 INFO:Local step 73500, global step 1178000: loss 206.3826
[2019-03-27 06:55:41,595] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 73500, global step 1178000: learning rate 0.0000
[2019-03-27 06:55:42,045] A3C_AGENT_WORKER-Thread-19 INFO:Local step 73500, global step 1178201: loss 181.3210
[2019-03-27 06:55:42,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 73500, global step 1178202: learning rate 0.0000
[2019-03-27 06:55:42,303] A3C_AGENT_WORKER-Thread-3 INFO:Local step 73500, global step 1178317: loss 241.8542
[2019-03-27 06:55:42,305] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 73500, global step 1178317: learning rate 0.0000
[2019-03-27 06:55:42,568] A3C_AGENT_WORKER-Thread-17 INFO:Local step 73500, global step 1178437: loss 217.4046
[2019-03-27 06:55:42,572] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 73500, global step 1178439: learning rate 0.0000
[2019-03-27 06:55:42,659] A3C_AGENT_WORKER-Thread-15 INFO:Local step 73500, global step 1178476: loss 213.5740
[2019-03-27 06:55:42,662] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 73500, global step 1178477: learning rate 0.0000
[2019-03-27 06:55:42,674] A3C_AGENT_WORKER-Thread-16 INFO:Local step 73500, global step 1178481: loss 212.2174
[2019-03-27 06:55:42,678] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 73500, global step 1178482: learning rate 0.0000
[2019-03-27 06:55:42,787] A3C_AGENT_WORKER-Thread-10 INFO:Local step 73500, global step 1178532: loss 256.3287
[2019-03-27 06:55:42,790] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 73500, global step 1178532: learning rate 0.0000
[2019-03-27 06:55:42,807] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.4024375e-25 8.9122957e-14 1.9455880e-25 8.1444653e-17], sum to 1.0000
[2019-03-27 06:55:42,815] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1945
[2019-03-27 06:55:42,820] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8087697168424524, 6.9112, 6.9112, 168.912956510431, 677146.4880560861, 677146.4880560861, 203633.2458139635], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4758600.0000, 
sim time next is 4759200.0000, 
raw observation next is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8088029336840216, 6.911200000000001, 6.9112, 168.912956510431, 677174.6703606546, 677174.670360654, 203640.1746467924], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7668328459561238, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18810407510018184, 0.18810407510018168, 0.303940559174317], 
reward next is 0.6961, 
noisyNet noise sample is [array([1.4047456], dtype=float32), 0.8822466]. 
=============================================
[2019-03-27 06:55:43,127] A3C_AGENT_WORKER-Thread-18 INFO:Local step 73500, global step 1178682: loss 232.4141
[2019-03-27 06:55:43,129] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 73500, global step 1178682: learning rate 0.0000
[2019-03-27 06:55:43,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.9151569e-04 2.0764453e-13 9.9910849e-01 1.7673490e-17 3.7916661e-09], sum to 1.0000
[2019-03-27 06:55:43,834] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5956
[2019-03-27 06:55:43,842] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 2 has been changed to 3 for the demand 2752755.011327858 W.
[2019-03-27 06:55:43,847] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.66666666666667, 68.66666666666667, 1.0, 2.0, 0.6709408827583151, 1.0, 2.0, 0.6560604808934201, 1.0, 2.0, 1.03, 7.005095440983511, 6.9112, 170.5573041426782, 2752755.011327858, 2685493.887529029, 512308.1961103173], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4371600.0000, 
sim time next is 4372200.0000, 
raw observation next is [33.0, 65.5, 1.0, 2.0, 0.9455007390908482, 1.0, 2.0, 0.9455007390908482, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2644694.643345905, 2644694.643345905, 496929.5250570967], 
processed observation next is [1.0, 0.6086956521739131, 0.7630331753554502, 0.655, 1.0, 1.0, 0.9343382398684918, 1.0, 1.0, 0.9343382398684918, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7346374009294181, 0.7346374009294181, 0.7416858582941741], 
reward next is 0.2583, 
noisyNet noise sample is [array([0.22738262], dtype=float32), 0.58167195]. 
=============================================
[2019-03-27 06:55:44,695] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74000, global step 1179385: loss 10.7240
[2019-03-27 06:55:44,701] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74000, global step 1179386: learning rate 0.0000
[2019-03-27 06:55:48,819] A3C_AGENT_WORKER-Thread-13 INFO:Local step 74500, global step 1181238: loss -396.9541
[2019-03-27 06:55:48,820] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 74500, global step 1181238: learning rate 0.0000
[2019-03-27 06:55:49,139] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.4729130e-28 2.8064793e-19 6.0267071e-28 6.9023545e-21], sum to 1.0000
[2019-03-27 06:55:49,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2377
[2019-03-27 06:55:49,160] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.33333333333333, 54.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9172924418548656, 6.911199999999999, 6.9112, 168.912956510431, 749949.7613797254, 749949.7613797261, 227186.7726173035], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4542000.0000, 
sim time next is 4542600.0000, 
raw observation next is [33.66666666666667, 52.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9056029835919747, 6.9112, 6.9112, 168.912956510431, 742041.7401686095, 742041.7401686095, 224513.4469598643], 
processed observation next is [0.0, 0.5652173913043478, 0.7946287519747238, 0.5216666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.884881687307286, 0.0, 0.0, 0.8294399451523027, 0.20612270560239154, 0.20612270560239154, 0.3350946969550213], 
reward next is 0.6649, 
noisyNet noise sample is [array([0.0049452], dtype=float32), -1.0257661]. 
=============================================
[2019-03-27 06:55:50,749] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.4148694e-30 4.1004737e-22 1.0837189e-30 1.9438984e-23], sum to 1.0000
[2019-03-27 06:55:50,759] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4890
[2019-03-27 06:55:50,763] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9354479554857744, 6.911200000000001, 6.9112, 168.912956510431, 764009.2399946371, 764009.2399946364, 231487.2516419988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4536000.0000, 
sim time next is 4536600.0000, 
raw observation next is [31.16666666666667, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9427742250366649, 6.9112, 6.9112, 168.912956510431, 770129.9184442759, 770129.9184442759, 233268.0553761387], 
processed observation next is [0.0, 0.5217391304347826, 0.6761453396524489, 0.655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9302124695569084, 0.0, 0.0, 0.8294399451523027, 0.21392497734563218, 0.21392497734563218, 0.34816127668080404], 
reward next is 0.6518, 
noisyNet noise sample is [array([-0.135151], dtype=float32), -0.46185383]. 
=============================================
[2019-03-27 06:55:53,011] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74000, global step 1183106: loss 7.3634
[2019-03-27 06:55:53,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74000, global step 1183107: learning rate 0.0000
[2019-03-27 06:55:54,774] A3C_AGENT_WORKER-Thread-20 INFO:Local step 74500, global step 1183923: loss -327.0915
[2019-03-27 06:55:54,778] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 74500, global step 1183923: learning rate 0.0000
[2019-03-27 06:55:56,156] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74000, global step 1184558: loss 6.4824
[2019-03-27 06:55:56,157] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74000, global step 1184558: learning rate 0.0000
[2019-03-27 06:55:57,724] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74000, global step 1185297: loss 5.9833
[2019-03-27 06:55:57,727] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74000, global step 1185299: learning rate 0.0000
[2019-03-27 06:55:57,801] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74000, global step 1185330: loss 8.2417
[2019-03-27 06:55:57,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74000, global step 1185331: learning rate 0.0000
[2019-03-27 06:55:58,678] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74000, global step 1185722: loss 8.5431
[2019-03-27 06:55:58,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74000, global step 1185723: learning rate 0.0000
[2019-03-27 06:55:59,523] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74000, global step 1186114: loss 9.6607
[2019-03-27 06:55:59,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74000, global step 1186115: learning rate 0.0000
[2019-03-27 06:55:59,811] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74000, global step 1186251: loss 8.0318
[2019-03-27 06:55:59,814] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74000, global step 1186252: learning rate 0.0000
[2019-03-27 06:56:00,101] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74000, global step 1186386: loss 8.4087
[2019-03-27 06:56:00,103] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74000, global step 1186386: learning rate 0.0000
[2019-03-27 06:56:00,112] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5612210e-01 8.9139378e-17 4.3877944e-02 3.7547903e-20 1.0555816e-10], sum to 1.0000
[2019-03-27 06:56:00,123] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6620
[2019-03-27 06:56:00,127] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.2620820478893796, 0.0, 1.0, 0.0, 1.0, 1.0, 0.453984699905372, 6.9112, 6.9112, 168.9129565104269, 732449.5266259222, 732449.5266259222, 210465.121752592], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4641600.0000, 
sim time next is 4642200.0000, 
raw observation next is [31.0, 70.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8958929150876623, 6.911200000000001, 6.9112, 168.912956510431, 723763.0801129199, 723763.0801129193, 221773.6652630572], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8730401403508076, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20104530003136664, 0.20104530003136648, 0.3310054705418764], 
reward next is 0.6690, 
noisyNet noise sample is [array([0.38607782], dtype=float32), -0.6183681]. 
=============================================
[2019-03-27 06:56:00,349] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74000, global step 1186498: loss 6.3551
[2019-03-27 06:56:00,352] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74000, global step 1186498: learning rate 0.0000
[2019-03-27 06:56:00,421] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74000, global step 1186532: loss 5.2818
[2019-03-27 06:56:00,425] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74000, global step 1186532: learning rate 0.0000
[2019-03-27 06:56:00,468] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74000, global step 1186555: loss 7.2633
[2019-03-27 06:56:00,470] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74000, global step 1186555: learning rate 0.0000
[2019-03-27 06:56:00,495] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74000, global step 1186565: loss 5.1467
[2019-03-27 06:56:00,497] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74000, global step 1186565: learning rate 0.0000
[2019-03-27 06:56:00,864] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74000, global step 1186736: loss 7.5608
[2019-03-27 06:56:00,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74000, global step 1186737: learning rate 0.0000
[2019-03-27 06:56:02,275] A3C_AGENT_WORKER-Thread-22 INFO:Local step 74500, global step 1187390: loss -437.8196
[2019-03-27 06:56:02,279] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 74500, global step 1187391: learning rate 0.0000
[2019-03-27 06:56:05,754] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75000, global step 1189012: loss 0.3289
[2019-03-27 06:56:05,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75000, global step 1189013: learning rate 0.0000
[2019-03-27 06:56:10,327] A3C_AGENT_WORKER-Thread-9 INFO:Local step 74500, global step 1191136: loss -435.3360
[2019-03-27 06:56:10,329] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 74500, global step 1191137: learning rate 0.0000
[2019-03-27 06:56:11,196] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75000, global step 1191547: loss 0.5285
[2019-03-27 06:56:11,200] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75000, global step 1191548: learning rate 0.0000
[2019-03-27 06:56:11,530] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9976963e-01 1.8463215e-16 2.3036808e-04 1.2611134e-19 2.7144935e-09], sum to 1.0000
[2019-03-27 06:56:11,539] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4284
[2019-03-27 06:56:11,546] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2447709.893675185 W.
[2019-03-27 06:56:11,551] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.58333333333333, 64.66666666666667, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.132058652126124, 6.9112, 168.9115103307932, 2447709.893675185, 2291026.505974148, 475971.0319573776], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4891800.0000, 
sim time next is 4892400.0000, 
raw observation next is [31.5, 65.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.344514599876378, 6.9112, 168.9101869926118, 2598768.942609209, 2291365.692223868, 475528.1415777878], 
processed observation next is [1.0, 0.6521739130434783, 0.6919431279620853, 0.65, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04333145998763781, 0.0, 0.8294263455519197, 0.7218802618358914, 0.6364904700621855, 0.7097434948922207], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53214574], dtype=float32), 0.6319392]. 
=============================================
[2019-03-27 06:56:13,436] A3C_AGENT_WORKER-Thread-11 INFO:Local step 74500, global step 1192567: loss -534.8011
[2019-03-27 06:56:13,437] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 74500, global step 1192567: learning rate 0.0000
[2019-03-27 06:56:15,014] A3C_AGENT_WORKER-Thread-21 INFO:Local step 74500, global step 1193298: loss -492.1818
[2019-03-27 06:56:15,018] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 74500, global step 1193299: learning rate 0.0000
[2019-03-27 06:56:15,126] A3C_AGENT_WORKER-Thread-12 INFO:Local step 74500, global step 1193351: loss -644.1874
[2019-03-27 06:56:15,130] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 74500, global step 1193351: learning rate 0.0000
[2019-03-27 06:56:16,006] A3C_AGENT_WORKER-Thread-14 INFO:Local step 74500, global step 1193760: loss -449.3043
[2019-03-27 06:56:16,009] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 74500, global step 1193760: learning rate 0.0000
[2019-03-27 06:56:16,933] A3C_AGENT_WORKER-Thread-2 INFO:Local step 74500, global step 1194193: loss -444.7560
[2019-03-27 06:56:16,935] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 74500, global step 1194193: learning rate 0.0000
[2019-03-27 06:56:17,232] A3C_AGENT_WORKER-Thread-19 INFO:Local step 74500, global step 1194331: loss -617.0278
[2019-03-27 06:56:17,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 74500, global step 1194331: learning rate 0.0000
[2019-03-27 06:56:17,309] A3C_AGENT_WORKER-Thread-3 INFO:Local step 74500, global step 1194368: loss -448.5193
[2019-03-27 06:56:17,314] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 74500, global step 1194368: learning rate 0.0000
[2019-03-27 06:56:17,694] A3C_AGENT_WORKER-Thread-17 INFO:Local step 74500, global step 1194547: loss -468.0865
[2019-03-27 06:56:17,695] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 74500, global step 1194548: learning rate 0.0000
[2019-03-27 06:56:17,711] A3C_AGENT_WORKER-Thread-15 INFO:Local step 74500, global step 1194554: loss -496.0189
[2019-03-27 06:56:17,712] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 74500, global step 1194555: learning rate 0.0000
[2019-03-27 06:56:17,737] A3C_AGENT_WORKER-Thread-16 INFO:Local step 74500, global step 1194567: loss -493.4310
[2019-03-27 06:56:17,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 74500, global step 1194568: learning rate 0.0000
[2019-03-27 06:56:17,763] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9986756e-01 1.5436111e-16 1.3236873e-04 1.3272527e-18 5.2599938e-09], sum to 1.0000
[2019-03-27 06:56:17,775] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4489
[2019-03-27 06:56:17,783] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1848028.396474376 W.
[2019-03-27 06:56:17,787] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 65.0, 1.0, 2.0, 0.6609122790015638, 1.0, 2.0, 0.6609122790015638, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1848028.396474376, 1848028.396474376, 357834.3347167242], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4969200.0000, 
sim time next is 4969800.0000, 
raw observation next is [30.3, 65.0, 1.0, 2.0, 0.6101971183949365, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.915851517957954, 6.9112, 168.9128804570399, 1706120.106499796, 1702820.161053338, 367487.6554844101], 
processed observation next is [1.0, 0.5217391304347826, 0.6350710900473934, 0.65, 1.0, 1.0, 0.530357973969803, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.00046515179579538214, 0.0, 0.829439571695335, 0.4739222518054989, 0.4730056002925939, 0.548489038036433], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6815538], dtype=float32), 2.7845526]. 
=============================================
[2019-03-27 06:56:17,932] A3C_AGENT_WORKER-Thread-10 INFO:Local step 74500, global step 1194655: loss -511.4653
[2019-03-27 06:56:17,936] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 74500, global step 1194655: learning rate 0.0000
[2019-03-27 06:56:18,134] A3C_AGENT_WORKER-Thread-18 INFO:Local step 74500, global step 1194750: loss -642.8951
[2019-03-27 06:56:18,143] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 74500, global step 1194751: learning rate 0.0000
[2019-03-27 06:56:18,600] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75000, global step 1194967: loss 0.1369
[2019-03-27 06:56:18,602] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75000, global step 1194967: learning rate 0.0000
[2019-03-27 06:56:20,709] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.9942867e-37 2.5179264e-29 5.8228626e-36 1.4320871e-26], sum to 1.0000
[2019-03-27 06:56:20,717] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5319
[2019-03-27 06:56:20,723] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8188843242721439, 6.9112, 6.9112, 168.912956510431, 684405.3479702373, 684405.3479702373, 205724.3230551654], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5000400.0000, 
sim time next is 5001000.0000, 
raw observation next is [27.0, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8202848703641811, 6.9112, 6.9112, 168.912956510431, 685940.7219201197, 685940.7219201197, 206029.4165845607], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7808352077611963, 0.0, 0.0, 0.8294399451523027, 0.19053908942225548, 0.19053908942225548, 0.30750659191725477], 
reward next is 0.6925, 
noisyNet noise sample is [array([-0.330445], dtype=float32), -0.20987424]. 
=============================================
[2019-03-27 06:56:20,743] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[67.146034]
 [66.799614]
 [66.09738 ]
 [66.22177 ]
 [65.72257 ]], R is [[67.54601288]
 [67.56349945]
 [67.57730865]
 [67.58750153]
 [67.59448242]].
[2019-03-27 06:56:23,936] A3C_AGENT_WORKER-Thread-13 INFO:Local step 75500, global step 1197442: loss 64.9955
[2019-03-27 06:56:23,937] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 75500, global step 1197443: learning rate 0.0000
[2019-03-27 06:56:25,949] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9087750e-37 6.6246343e-33 1.2218014e-35 5.4370025e-26], sum to 1.0000
[2019-03-27 06:56:25,957] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3395
[2019-03-27 06:56:25,963] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8709462057900554, 6.9112, 6.9112, 168.912956510431, 721696.412124088, 721696.412124088, 216888.5081958797], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5094600.0000, 
sim time next is 5095200.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8718522399577014, 6.9112, 6.9112, 168.912956510431, 722447.478955866, 722447.478955866, 217092.1946143786], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8437222438508553, 0.0, 0.0, 0.8294399451523027, 0.20067985526551832, 0.20067985526551832, 0.32401820091698297], 
reward next is 0.6760, 
noisyNet noise sample is [array([-0.8048979], dtype=float32), -0.24574693]. 
=============================================
[2019-03-27 06:56:27,094] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75000, global step 1198919: loss 0.9488
[2019-03-27 06:56:27,098] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75000, global step 1198920: learning rate 0.0000
[2019-03-27 06:56:29,404] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-27 06:56:29,406] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:56:29,407] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:56:29,407] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:56:29,408] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:56:29,409] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:56:29,408] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:56:29,411] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:56:29,410] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:56:29,409] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:56:29,417] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:56:29,440] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run49
[2019-03-27 06:56:29,440] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run49
[2019-03-27 06:56:29,477] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run49
[2019-03-27 06:56:29,507] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run49
[2019-03-27 06:56:29,527] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run49
[2019-03-27 06:56:53,453] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:56:53,454] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.120493, 99.33066518, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8230156681162729, 6.911200000000001, 6.9112, 168.912956510431, 688415.9906433185, 688415.9906433178, 206612.2775783924]
[2019-03-27 06:56:53,454] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 06:56:53,459] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 5.17199434e-35 1.14862936e-29 1.99689123e-33
 2.46987099e-25], sampled 0.39068620927510156
[2019-03-27 06:57:03,098] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:57:03,100] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.40419471, 55.03599243, 1.0, 2.0, 1.001300313326629, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1428012.989923483, 1428012.989923483, 303761.3468710984]
[2019-03-27 06:57:03,101] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:57:03,106] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999988e-01 9.4937661e-18 9.3147342e-08 1.1608146e-19 2.1576149e-10], sampled 0.15437554144336185
[2019-03-27 06:57:03,107] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1428012.989923483 W.
[2019-03-27 06:57:09,312] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:57:09,313] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [21.78318595333333, 92.70767881333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6166002138594014, 6.9112, 6.9112, 168.912956510431, 536297.5910207671, 536297.5910207671, 168652.4409477855]
[2019-03-27 06:57:09,317] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:57:09,319] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.6409304e-35 9.3438090e-31 1.0483612e-33 3.8697489e-26], sampled 0.6329853660444823
[2019-03-27 06:57:15,432] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:57:15,484] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.83333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.873213949566429, 6.9112, 6.9112, 168.912956510431, 720445.442047145, 720445.442047145, 217288.7284988279]
[2019-03-27 06:57:15,485] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:57:15,488] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 9.3934565e-37 5.7511541e-31 3.3641974e-35 1.5236580e-26], sampled 0.04280040805919949
[2019-03-27 06:57:45,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:57:45,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 70.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 9.175872814541513, 6.9112, 168.8999565339485, 3892179.277249566, 2285666.089502926, 469810.0081432578]
[2019-03-27 06:57:45,212] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:57:45,215] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9949026e-01 2.9297419e-15 5.0976040e-04 6.0913241e-18 1.3481533e-08], sampled 0.8636466943452953
[2019-03-27 06:57:45,217] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3892179.277249566 W.
[2019-03-27 06:57:49,054] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:57:49,055] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.1, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9889160774170337, 6.9112, 6.9112, 168.912956510431, 795729.8993595662, 795729.8993595662, 244132.7331057899]
[2019-03-27 06:57:49,057] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:57:49,061] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.2915944e-35 2.5866488e-30 1.1169202e-33 3.7415737e-25], sampled 0.9750958031953729
[2019-03-27 06:58:05,781] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.06319598]
[2019-03-27 06:58:05,782] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.26666666666667, 83.33333333333334, 1.0, 2.0, 0.9277755791972299, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1296787.186144644, 1296787.186144644, 277690.8585930695]
[2019-03-27 06:58:05,783] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:58:05,786] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999487e-01 7.0609826e-16 5.1490515e-06 7.6276028e-18 3.8631840e-09], sampled 0.9954969094814817
[2019-03-27 06:58:05,787] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1296787.186144644 W.
[2019-03-27 06:58:24,452] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.7172 3319609216.8578 2143.0000
[2019-03-27 06:58:24,478] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.3257 2937886237.4215 1381.0000
[2019-03-27 06:58:25,077] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7348.3238 3105708155.7267 2010.0000
[2019-03-27 06:58:25,106] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.5470 3185154209.0198 2464.0000
[2019-03-27 06:58:25,145] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7925.3300 2989284041.6894 1566.0000
[2019-03-27 06:58:26,164] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1200000, evaluation results [1200000.0, 7286.717222018816, 3319609216.857821, 2143.0, 7348.323799039375, 3105708155.7267327, 2010.0, 8060.325661280392, 2937886237.421504, 1381.0, 7030.547037659309, 3185154209.0198216, 2464.0, 7925.330044897125, 2989284041.689442, 1566.0]
[2019-03-27 06:58:26,326] A3C_AGENT_WORKER-Thread-20 INFO:Local step 75500, global step 1200077: loss 76.7330
[2019-03-27 06:58:26,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 75500, global step 1200077: learning rate 0.0000
[2019-03-27 06:58:27,044] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8955768e-01 2.5990754e-14 1.0442336e-02 4.0350989e-17 3.3114759e-08], sum to 1.0000
[2019-03-27 06:58:27,053] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2143
[2019-03-27 06:58:27,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2516682.986581527 W.
[2019-03-27 06:58:27,070] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 68.0, 1.0, 2.0, 0.5998543549735874, 1.0, 2.0, 0.5998543549735874, 1.0, 1.0, 1.03, 6.924407246674391, 6.9112, 170.5573041426782, 2516682.986581527, 2507222.098552215, 487925.4754212862], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5226000.0000, 
sim time next is 5226600.0000, 
raw observation next is [31.83333333333333, 67.5, 1.0, 2.0, 0.6001293559485599, 1.0, 2.0, 0.6001293559485599, 1.0, 2.0, 1.03, 6.924944131581897, 6.9112, 170.5573041426782, 2517837.912901919, 2507992.432374278, 488025.2546867325], 
processed observation next is [1.0, 0.4782608695652174, 0.7077409162717218, 0.675, 1.0, 1.0, 0.51822813969706, 1.0, 1.0, 0.51822813969706, 1.0, 1.0, 1.0365853658536586, 0.0013744131581897357, 0.0, 0.8375144448122397, 0.699399420250533, 0.6966645645484105, 0.7283959025175112], 
reward next is 0.2029, 
noisyNet noise sample is [array([0.16500746], dtype=float32), 0.32018808]. 
=============================================
[2019-03-27 06:58:27,189] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75000, global step 1200464: loss 0.0858
[2019-03-27 06:58:27,192] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75000, global step 1200465: learning rate 0.0000
[2019-03-27 06:58:28,803] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75000, global step 1201197: loss 0.1353
[2019-03-27 06:58:28,804] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75000, global step 1201197: learning rate 0.0000
[2019-03-27 06:58:29,120] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75000, global step 1201340: loss 0.1029
[2019-03-27 06:58:29,123] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75000, global step 1201340: learning rate 0.0000
[2019-03-27 06:58:29,889] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75000, global step 1201679: loss 0.9532
[2019-03-27 06:58:29,892] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75000, global step 1201679: learning rate 0.0000
[2019-03-27 06:58:30,702] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75000, global step 1202043: loss 0.0063
[2019-03-27 06:58:30,706] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75000, global step 1202044: learning rate 0.0000
[2019-03-27 06:58:31,237] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75000, global step 1202284: loss 0.2889
[2019-03-27 06:58:31,240] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75000, global step 1202286: learning rate 0.0000
[2019-03-27 06:58:31,278] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75000, global step 1202303: loss 0.0213
[2019-03-27 06:58:31,282] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75000, global step 1202304: learning rate 0.0000
[2019-03-27 06:58:31,629] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75000, global step 1202457: loss 0.1223
[2019-03-27 06:58:31,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75000, global step 1202458: learning rate 0.0000
[2019-03-27 06:58:31,738] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75000, global step 1202506: loss 0.1678
[2019-03-27 06:58:31,743] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75000, global step 1202508: learning rate 0.0000
[2019-03-27 06:58:31,801] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75000, global step 1202532: loss 0.4853
[2019-03-27 06:58:31,807] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75000, global step 1202532: learning rate 0.0000
[2019-03-27 06:58:31,997] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75000, global step 1202620: loss 0.4898
[2019-03-27 06:58:32,001] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75000, global step 1202622: learning rate 0.0000
[2019-03-27 06:58:32,062] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75000, global step 1202648: loss 0.0102
[2019-03-27 06:58:32,066] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75000, global step 1202648: learning rate 0.0000
[2019-03-27 06:58:33,614] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.9182728e-36 4.2784952e-31 1.0316592e-33 4.4545994e-25], sum to 1.0000
[2019-03-27 06:58:33,621] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3321
[2019-03-27 06:58:33,626] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.2, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9045256241859578, 6.911200000000001, 6.9112, 168.912956510431, 742728.2732834636, 742728.2732834629, 224328.0875742401], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5684400.0000, 
sim time next is 5685000.0000, 
raw observation next is [28.98333333333333, 75.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9098690175686341, 6.911200000000001, 6.9112, 168.912956510431, 747139.920075564, 747139.9200755634, 225579.2279484361], 
processed observation next is [0.0, 0.8260869565217391, 0.5726698262243285, 0.755, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.890084167766627, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20753886668765664, 0.2075388666876565, 0.3366854148484121], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.054873], dtype=float32), -0.777708]. 
=============================================
[2019-03-27 06:58:33,640] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[68.354355]
 [68.1942  ]
 [68.08951 ]
 [68.0054  ]
 [67.89998 ]], R is [[68.46411133]
 [68.44465637]
 [68.42482758]
 [68.40471649]
 [68.38485718]].
[2019-03-27 06:58:34,079] A3C_AGENT_WORKER-Thread-22 INFO:Local step 75500, global step 1203549: loss -96.0718
[2019-03-27 06:58:34,080] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 75500, global step 1203549: learning rate 0.0000
[2019-03-27 06:58:37,258] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.4380957e-01 1.3246661e-11 5.6182846e-02 2.5966451e-14 7.4965233e-06], sum to 1.0000
[2019-03-27 06:58:37,264] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7891
[2019-03-27 06:58:37,272] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2382730.563538909 W.
[2019-03-27 06:58:37,276] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [33.1, 67.33333333333334, 1.0, 2.0, 0.8519355731120205, 1.0, 2.0, 0.8519355731120205, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2382730.563538909, 2382730.563538909, 445959.2983632653], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5389800.0000, 
sim time next is 5390400.0000, 
raw observation next is [33.3, 66.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.033347669227421, 6.9112, 168.9121016547183, 2370412.85935619, 2283757.537366188, 475814.9571156167], 
processed observation next is [1.0, 0.391304347826087, 0.7772511848341231, 0.6666666666666667, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.012214766922742103, 0.0, 0.8294357474193986, 0.6584480164878306, 0.63437709371283, 0.7101715777845026], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7045695], dtype=float32), -2.7900906]. 
=============================================
[2019-03-27 06:58:37,648] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76000, global step 1205129: loss 0.7502
[2019-03-27 06:58:37,651] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76000, global step 1205131: learning rate 0.0000
[2019-03-27 06:58:39,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.2050373e-33 5.6402052e-28 6.3699738e-33 9.2430540e-24], sum to 1.0000
[2019-03-27 06:58:39,965] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0410
[2019-03-27 06:58:39,969] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.25, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9688291167317559, 6.9112, 6.9112, 168.912956510431, 787280.5157203196, 787280.5157203196, 239492.852607024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5663400.0000, 
sim time next is 5664000.0000, 
raw observation next is [32.3, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9457196117546606, 6.9112, 6.9112, 168.912956510431, 768739.7231019561, 768739.7231019561, 233803.1817845323], 
processed observation next is [0.0, 0.5652173913043478, 0.7298578199052131, 0.6133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9338044045788543, 0.0, 0.0, 0.8294399451523027, 0.21353881197276559, 0.21353881197276559, 0.3489599728127348], 
reward next is 0.6510, 
noisyNet noise sample is [array([1.7363236], dtype=float32), -0.07923502]. 
=============================================
[2019-03-27 06:58:39,979] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[60.880928]
 [60.871628]
 [60.800537]
 [60.782608]
 [60.76507 ]], R is [[60.97402573]
 [61.00683212]
 [61.04669952]
 [61.08514786]
 [61.1222229 ]].
[2019-03-27 06:58:41,003] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5961004e-01 5.9752301e-13 4.0351253e-02 5.6434306e-16 3.8666654e-05], sum to 1.0000
[2019-03-27 06:58:41,012] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3158
[2019-03-27 06:58:41,021] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 3488859.591612873 W.
[2019-03-27 06:58:41,028] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.16666666666666, 63.33333333333334, 1.0, 2.0, 1.021321151967906, 1.0, 2.0, 0.8312506154982157, 1.0, 2.0, 1.03, 7.005123081719097, 6.9112, 170.5573041426782, 3488859.591612873, 3421578.667630789, 642059.7600727695], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5400600.0000, 
sim time next is 5401200.0000, 
raw observation next is [36.33333333333334, 62.66666666666667, 1.0, 2.0, 0.7594476352670982, 1.0, 2.0, 0.7003138571478117, 1.0, 2.0, 1.03, 7.005102420014991, 6.9112, 170.5573041426782, 2938655.542104086, 2871389.418941119, 540765.9599819263], 
processed observation next is [1.0, 0.5217391304347826, 0.9210110584518172, 0.6266666666666667, 1.0, 1.0, 0.710177873815781, 1.0, 1.0, 0.6389323580094116, 1.0, 1.0, 1.0365853658536586, 0.009390242001499072, 0.0, 0.8375144448122397, 0.8162932061400239, 0.7976081719280886, 0.8071133731073526], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1581159], dtype=float32), -0.48132148]. 
=============================================
[2019-03-27 06:58:42,148] A3C_AGENT_WORKER-Thread-9 INFO:Local step 75500, global step 1207094: loss 19.9850
[2019-03-27 06:58:42,150] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 75500, global step 1207094: learning rate 0.0000
[2019-03-27 06:58:43,098] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76000, global step 1207533: loss 0.4159
[2019-03-27 06:58:43,100] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76000, global step 1207533: learning rate 0.0000
[2019-03-27 06:58:44,559] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9963260e-01 2.8719519e-14 3.6666496e-04 1.3820350e-16 6.9635342e-07], sum to 1.0000
[2019-03-27 06:58:44,572] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4552
[2019-03-27 06:58:44,577] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2173790.362895275 W.
[2019-03-27 06:58:44,584] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.43333333333333, 74.66666666666667, 1.0, 2.0, 0.7772967847655837, 1.0, 2.0, 0.7772967847655837, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2173790.362895275, 2173790.362895275, 408981.4276474845], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5473200.0000, 
sim time next is 5473800.0000, 
raw observation next is [31.65, 74.0, 1.0, 2.0, 0.5809507147265496, 1.0, 2.0, 0.5809507147265496, 1.0, 1.0, 1.00891926814284, 6.911199999999999, 6.9112, 170.5573041426782, 2437295.602426161, 2437295.602426162, 475638.8889701841], 
processed observation next is [1.0, 0.34782608695652173, 0.6990521327014217, 0.74, 1.0, 1.0, 0.4951213430440356, 1.0, 1.0, 0.4951213430440356, 1.0, 0.5, 1.0108771562717562, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6770265562294892, 0.6770265562294895, 0.7099087895077374], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3800032], dtype=float32), -0.30144593]. 
=============================================
[2019-03-27 06:58:45,144] A3C_AGENT_WORKER-Thread-11 INFO:Local step 75500, global step 1208478: loss 135.4866
[2019-03-27 06:58:45,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 75500, global step 1208478: learning rate 0.0000
[2019-03-27 06:58:46,914] A3C_AGENT_WORKER-Thread-21 INFO:Local step 75500, global step 1209298: loss -16.7374
[2019-03-27 06:58:46,916] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 75500, global step 1209299: learning rate 0.0000
[2019-03-27 06:58:47,091] A3C_AGENT_WORKER-Thread-12 INFO:Local step 75500, global step 1209382: loss -114.2245
[2019-03-27 06:58:47,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 75500, global step 1209382: learning rate 0.0000
[2019-03-27 06:58:48,037] A3C_AGENT_WORKER-Thread-14 INFO:Local step 75500, global step 1209807: loss 199.6187
[2019-03-27 06:58:48,039] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 75500, global step 1209808: learning rate 0.0000
[2019-03-27 06:58:48,831] A3C_AGENT_WORKER-Thread-2 INFO:Local step 75500, global step 1210183: loss -8.3861
[2019-03-27 06:58:48,832] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 75500, global step 1210183: learning rate 0.0000
[2019-03-27 06:58:49,345] A3C_AGENT_WORKER-Thread-19 INFO:Local step 75500, global step 1210423: loss -37.9632
[2019-03-27 06:58:49,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 75500, global step 1210423: learning rate 0.0000
[2019-03-27 06:58:49,426] A3C_AGENT_WORKER-Thread-3 INFO:Local step 75500, global step 1210457: loss -45.6113
[2019-03-27 06:58:49,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 75500, global step 1210458: learning rate 0.0000
[2019-03-27 06:58:49,586] A3C_AGENT_WORKER-Thread-15 INFO:Local step 75500, global step 1210534: loss -58.7361
[2019-03-27 06:58:49,588] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 75500, global step 1210535: learning rate 0.0000
[2019-03-27 06:58:49,652] A3C_AGENT_WORKER-Thread-17 INFO:Local step 75500, global step 1210563: loss 103.9570
[2019-03-27 06:58:49,653] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 75500, global step 1210563: learning rate 0.0000
[2019-03-27 06:58:49,800] A3C_AGENT_WORKER-Thread-16 INFO:Local step 75500, global step 1210630: loss -164.0373
[2019-03-27 06:58:49,801] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 75500, global step 1210631: learning rate 0.0000
[2019-03-27 06:58:50,097] A3C_AGENT_WORKER-Thread-10 INFO:Local step 75500, global step 1210775: loss 1.8325
[2019-03-27 06:58:50,099] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 75500, global step 1210775: learning rate 0.0000
[2019-03-27 06:58:50,125] A3C_AGENT_WORKER-Thread-18 INFO:Local step 75500, global step 1210786: loss 131.2722
[2019-03-27 06:58:50,127] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 75500, global step 1210786: learning rate 0.0000
[2019-03-27 06:58:50,427] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76000, global step 1210927: loss 0.7265
[2019-03-27 06:58:50,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76000, global step 1210929: learning rate 0.0000
[2019-03-27 06:58:52,102] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 8.5068715e-20 8.9729967e-11 2.6711229e-21 1.7891422e-10], sum to 1.0000
[2019-03-27 06:58:52,111] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4183
[2019-03-27 06:58:52,119] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1826790.389885856 W.
[2019-03-27 06:58:52,122] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.3, 80.0, 1.0, 2.0, 0.4355489188789428, 1.0, 1.0, 0.4355489188789428, 1.0, 1.0, 0.7297525622303528, 6.911199999999999, 6.9112, 170.5573041426782, 1826790.389885856, 1826790.389885856, 369199.9877198988], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6010200.0000, 
sim time next is 6010800.0000, 
raw observation next is [26.06666666666667, 82.0, 1.0, 2.0, 0.5922491849910372, 1.0, 2.0, 0.5922491849910372, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1655885.816981882, 1655885.816981882, 331393.5137103294], 
processed observation next is [1.0, 0.5652173913043478, 0.4344391785150081, 0.82, 1.0, 1.0, 0.5087339578205267, 1.0, 1.0, 0.5087339578205267, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.45996828249496724, 0.45996828249496724, 0.4946171846422827], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.471172], dtype=float32), 0.7974344]. 
=============================================
[2019-03-27 06:58:52,274] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0009587e-36 2.7931729e-33 5.8260237e-34 1.3605314e-25], sum to 1.0000
[2019-03-27 06:58:52,280] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2586
[2019-03-27 06:58:52,286] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.838584477310783, 6.9112, 6.9112, 168.912956510431, 698525.4422616044, 698525.4422616044, 209869.8495089748], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5630400.0000, 
sim time next is 5631000.0000, 
raw observation next is [25.6, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8376519753241524, 6.9112, 6.9112, 168.912956510431, 697968.7981143754, 697968.7981143754, 209674.63152326], 
processed observation next is [0.0, 0.17391304347826086, 0.4123222748815167, 0.9100000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8020146040538443, 0.0, 0.0, 0.8294399451523027, 0.19388022169843763, 0.19388022169843763, 0.31294721122874625], 
reward next is 0.6871, 
noisyNet noise sample is [array([2.7643852], dtype=float32), 0.61998135]. 
=============================================
[2019-03-27 06:58:52,301] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[68.092545]
 [68.127884]
 [68.166794]
 [68.57526 ]
 [68.76612 ]], R is [[68.12301636]
 [68.12854767]
 [68.13277435]
 [68.13577271]
 [68.13785553]].
[2019-03-27 06:58:53,135] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 2.5229762e-35 1.1499098e-36 5.9505954e-26], sum to 1.0000
[2019-03-27 06:58:53,144] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4198
[2019-03-27 06:58:53,150] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9330807171736212, 6.9112, 6.9112, 168.912956510431, 759902.8968467367, 759902.8968467367, 230815.027332924], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5760000.0000, 
sim time next is 5760600.0000, 
raw observation next is [32.73333333333333, 59.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9688129566471918, 6.9112, 6.9112, 168.912956510431, 788583.1719508063, 788583.1719508063, 239554.9999701288], 
processed observation next is [0.0, 0.6956521739130435, 0.7503949447077406, 0.5916666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9619670203014533, 0.0, 0.0, 0.8294399451523027, 0.2190508810974462, 0.2190508810974462, 0.3575447760748191], 
reward next is 0.6425, 
noisyNet noise sample is [array([-0.2676325], dtype=float32), 0.43289188]. 
=============================================
[2019-03-27 06:58:55,334] A3C_AGENT_WORKER-Thread-13 INFO:Local step 76500, global step 1213206: loss 22.9777
[2019-03-27 06:58:55,335] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 76500, global step 1213206: learning rate 0.0000
[2019-03-27 06:58:55,950] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.2958647e-38 4.7141872e-35 6.8986961e-36 4.3599803e-26], sum to 1.0000
[2019-03-27 06:58:55,959] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5638
[2019-03-27 06:58:55,963] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.25, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9688291167317559, 6.9112, 6.9112, 168.912956510431, 787280.5157203196, 787280.5157203196, 239492.852607024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5663400.0000, 
sim time next is 5664000.0000, 
raw observation next is [32.3, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9457196117546606, 6.9112, 6.9112, 168.912956510431, 768739.7231019561, 768739.7231019561, 233803.1817845323], 
processed observation next is [0.0, 0.5652173913043478, 0.7298578199052131, 0.6133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9338044045788543, 0.0, 0.0, 0.8294399451523027, 0.21353881197276559, 0.21353881197276559, 0.3489599728127348], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.5482809], dtype=float32), -1.1167538]. 
=============================================
[2019-03-27 06:58:55,981] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[69.23442 ]
 [69.208046]
 [69.11927 ]
 [69.08552 ]
 [69.05054 ]], R is [[69.25971985]
 [69.20967102]
 [69.16751862]
 [69.12475586]
 [69.08143616]].
[2019-03-27 06:58:59,018] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76000, global step 1214923: loss 1.1903
[2019-03-27 06:58:59,025] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76000, global step 1214924: learning rate 0.0000
[2019-03-27 06:59:01,028] A3C_AGENT_WORKER-Thread-20 INFO:Local step 76500, global step 1215866: loss -34.7664
[2019-03-27 06:59:01,030] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 76500, global step 1215866: learning rate 0.0000
[2019-03-27 06:59:01,039] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.9978330e-21 2.5550709e-11 6.5168170e-22 4.5812801e-11], sum to 1.0000
[2019-03-27 06:59:01,050] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0500
[2019-03-27 06:59:01,059] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 971057.9980486481 W.
[2019-03-27 06:59:01,063] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.68333333333333, 95.16666666666667, 1.0, 2.0, 0.2316149730470645, 1.0, 2.0, 0.2316149730470645, 1.0, 1.0, 0.3946825859991953, 6.9112, 6.9112, 170.5573041426782, 971057.9980486481, 971057.9980486481, 278766.5877343065], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5890200.0000, 
sim time next is 5890800.0000, 
raw observation next is [25.66666666666667, 95.33333333333334, 1.0, 2.0, 0.3260979718125613, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5533775332700015, 6.9112, 6.9112, 168.912956510431, 911433.7462284554, 911433.7462284554, 229241.5017806437], 
processed observation next is [1.0, 0.17391304347826086, 0.4154818325434442, 0.9533333333333335, 1.0, 1.0, 0.18806984555730274, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.45533845520731886, 0.0, 0.0, 0.8294399451523027, 0.2531760406190154, 0.2531760406190154, 0.3421514951949906], 
reward next is 0.6578, 
noisyNet noise sample is [array([2.2108424], dtype=float32), -0.14856721]. 
=============================================
[2019-03-27 06:59:02,208] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76000, global step 1216416: loss 1.4910
[2019-03-27 06:59:02,212] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76000, global step 1216418: learning rate 0.0000
[2019-03-27 06:59:04,135] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76000, global step 1217319: loss 1.2618
[2019-03-27 06:59:04,136] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76000, global step 1217319: learning rate 0.0000
[2019-03-27 06:59:04,193] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76000, global step 1217344: loss 0.6910
[2019-03-27 06:59:04,195] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76000, global step 1217344: learning rate 0.0000
[2019-03-27 06:59:05,047] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76000, global step 1217740: loss 0.5849
[2019-03-27 06:59:05,050] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76000, global step 1217740: learning rate 0.0000
[2019-03-27 06:59:05,794] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76000, global step 1218088: loss 1.0520
[2019-03-27 06:59:05,798] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76000, global step 1218089: learning rate 0.0000
[2019-03-27 06:59:06,179] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999893e-01 1.7332216e-17 2.1650985e-07 1.7188464e-19 8.1015736e-07], sum to 1.0000
[2019-03-27 06:59:06,194] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5575
[2019-03-27 06:59:06,203] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2467462.521645201 W.
[2019-03-27 06:59:06,208] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.4, 62.66666666666667, 1.0, 2.0, 0.8822012568240418, 1.0, 2.0, 0.8822012568240418, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2467462.521645201, 2467462.521645202, 461874.5651528258], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5845200.0000, 
sim time next is 5845800.0000, 
raw observation next is [32.34999999999999, 62.83333333333333, 1.0, 2.0, 0.5968610284819215, 1.0, 2.0, 0.5968610284819215, 1.0, 1.0, 1.03, 6.918563401943972, 6.9112, 170.5573041426782, 2504111.930922863, 2498837.226586354, 486842.5061771823], 
processed observation next is [1.0, 0.6521739130434783, 0.7322274881516582, 0.6283333333333333, 1.0, 1.0, 0.5142903957613512, 1.0, 1.0, 0.5142903957613512, 1.0, 0.5, 1.0365853658536586, 0.0007363401943972115, 0.0, 0.8375144448122397, 0.6955866474785731, 0.6941214518295428, 0.7266306062346004], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.05764621], dtype=float32), -0.4731001]. 
=============================================
[2019-03-27 06:59:06,374] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76000, global step 1218369: loss 0.6480
[2019-03-27 06:59:06,378] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76000, global step 1218369: learning rate 0.0000
[2019-03-27 06:59:06,524] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76000, global step 1218440: loss 0.3158
[2019-03-27 06:59:06,526] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76000, global step 1218440: learning rate 0.0000
[2019-03-27 06:59:06,718] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76000, global step 1218528: loss 1.0132
[2019-03-27 06:59:06,721] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76000, global step 1218529: learning rate 0.0000
[2019-03-27 06:59:06,790] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76000, global step 1218563: loss 0.5779
[2019-03-27 06:59:06,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76000, global step 1218563: learning rate 0.0000
[2019-03-27 06:59:06,826] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76000, global step 1218578: loss 0.6393
[2019-03-27 06:59:06,830] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76000, global step 1218582: learning rate 0.0000
[2019-03-27 06:59:07,132] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76000, global step 1218720: loss 2.8794
[2019-03-27 06:59:07,141] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76000, global step 1218723: learning rate 0.0000
[2019-03-27 06:59:07,296] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76000, global step 1218796: loss 1.1872
[2019-03-27 06:59:07,298] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76000, global step 1218796: learning rate 0.0000
[2019-03-27 06:59:08,199] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.4703098e-34 1.0160743e-28 3.2125684e-33 2.4191665e-22], sum to 1.0000
[2019-03-27 06:59:08,208] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0224
[2019-03-27 06:59:08,214] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8922415910520929, 6.911199999999999, 6.9112, 168.912956510431, 734705.5451753053, 734705.545175306, 221565.4294412418], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5880600.0000, 
sim time next is 5881200.0000, 
raw observation next is [26.1, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.89160003020262, 6.9112, 6.9112, 168.912956510431, 734233.6853797697, 734233.6853797697, 221420.0520834692], 
processed observation next is [1.0, 0.043478260869565216, 0.4360189573459717, 0.9333333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8678049148812438, 0.0, 0.0, 0.8294399451523027, 0.20395380149438047, 0.20395380149438047, 0.3304776896768197], 
reward next is 0.6695, 
noisyNet noise sample is [array([0.13816506], dtype=float32), 0.03426022]. 
=============================================
[2019-03-27 06:59:08,491] A3C_AGENT_WORKER-Thread-22 INFO:Local step 76500, global step 1219347: loss -1.6134
[2019-03-27 06:59:08,493] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 76500, global step 1219349: learning rate 0.0000
[2019-03-27 06:59:10,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9998677e-01 4.6271208e-15 1.1591609e-06 1.2812720e-17 1.2060226e-05], sum to 1.0000
[2019-03-27 06:59:10,220] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0071
[2019-03-27 06:59:10,228] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2652032.767481233 W.
[2019-03-27 06:59:10,234] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.96666666666667, 70.33333333333334, 1.0, 2.0, 0.6320809327971626, 1.0, 2.0, 0.6320809327971626, 1.0, 2.0, 1.03, 6.987326629006104, 6.9112, 170.5573041426782, 2652032.767481233, 2597500.166490879, 499904.4316184688], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5915400.0000, 
sim time next is 5916000.0000, 
raw observation next is [31.83333333333334, 70.66666666666667, 1.0, 2.0, 0.6532007374613822, 1.0, 2.0, 0.6471904082449537, 1.0, 2.0, 1.03, 7.005094042367855, 6.9112, 170.5573041426782, 2715496.748181421, 2648236.626267878, 506954.232331495], 
processed observation next is [1.0, 0.4782608695652174, 0.7077409162717223, 0.7066666666666667, 1.0, 1.0, 0.5821695632064845, 1.0, 1.0, 0.5749282027047634, 1.0, 1.0, 1.0365853658536586, 0.00938940423678547, 0.0, 0.8375144448122397, 0.7543046522726169, 0.7356212850744105, 0.7566481079574552], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9556809], dtype=float32), -0.19944455]. 
=============================================
[2019-03-27 06:59:10,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[31.718103]
 [31.510239]
 [31.21109 ]
 [31.561428]
 [30.81406 ]], R is [[31.92844772]
 [31.60916328]
 [31.29307175]
 [30.98014069]
 [30.67033958]].
[2019-03-27 06:59:12,002] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77000, global step 1220985: loss 582.2614
[2019-03-27 06:59:12,003] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77000, global step 1220986: learning rate 0.0000
[2019-03-27 06:59:13,873] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.0582428e-20 5.7962506e-12 4.8361859e-22 6.0085963e-09], sum to 1.0000
[2019-03-27 06:59:13,880] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5324
[2019-03-27 06:59:13,887] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1641801.845544223 W.
[2019-03-27 06:59:13,894] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.53333333333334, 78.0, 1.0, 2.0, 0.5819714756163468, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9745041996355857, 6.9112, 6.9112, 168.912956510431, 1641801.845544223, 1641801.845544223, 349289.7333610293], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6009600.0000, 
sim time next is 6010200.0000, 
raw observation next is [26.3, 80.0, 1.0, 2.0, 0.6128008119878238, 0.0, 2.0, 0.0, 1.0, 2.0, 1.023494447120504, 6.911200000000001, 6.9112, 168.912956510431, 1722531.605331701, 1722531.6053317, 367335.2969772058], 
processed observation next is [1.0, 0.5652173913043478, 0.4454976303317536, 0.8, 1.0, 1.0, 0.5334949542021973, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0286517647811024, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.47848100148102807, 0.4784810014810278, 0.5482616372794116], 
reward next is 0.4517, 
noisyNet noise sample is [array([0.12729968], dtype=float32), 0.44935867]. 
=============================================
[2019-03-27 06:59:16,481] A3C_AGENT_WORKER-Thread-9 INFO:Local step 76500, global step 1223071: loss 16.3077
[2019-03-27 06:59:16,485] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 76500, global step 1223072: learning rate 0.0000
[2019-03-27 06:59:17,325] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77000, global step 1223462: loss 626.5547
[2019-03-27 06:59:17,328] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77000, global step 1223463: learning rate 0.0000
[2019-03-27 06:59:19,550] A3C_AGENT_WORKER-Thread-11 INFO:Local step 76500, global step 1224501: loss -23.2232
[2019-03-27 06:59:19,552] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 76500, global step 1224503: learning rate 0.0000
[2019-03-27 06:59:20,630] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 06:59:20,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 06:59:20,633] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:59:20,634] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 06:59:20,635] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 06:59:20,635] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:59:20,636] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:59:20,638] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 06:59:20,637] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 06:59:20,640] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:59:20,643] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 06:59:20,657] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run50
[2019-03-27 06:59:20,680] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run50
[2019-03-27 06:59:20,680] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run50
[2019-03-27 06:59:20,733] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run50
[2019-03-27 06:59:20,752] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run50
[2019-03-27 06:59:23,417] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 06:59:23,419] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.3, 43.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.846252000622027, 6.9112, 6.9112, 168.912956510431, 758384.0088332974, 758384.0088332974, 210576.0792377589]
[2019-03-27 06:59:23,421] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:59:23,423] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.7724905e-34 1.2906439e-32 8.6577040e-33 1.2398813e-22], sampled 0.14891567706642328
[2019-03-27 06:59:25,143] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 06:59:25,144] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5666007898256807, 6.911199999999999, 6.9112, 168.912956510431, 495543.5162170163, 495543.5162170169, 161103.383369555]
[2019-03-27 06:59:25,146] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 06:59:25,148] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 2.55675072e-35 9.76211416e-34 1.91477377e-33
 1.14784445e-23], sampled 0.6483752229673402
[2019-03-27 06:59:34,913] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 06:59:34,913] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.05205232, 70.8119392, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6178775426902622, 6.911199999999999, 6.9112, 168.912956510431, 536397.1810345136, 536397.1810345142, 168868.8510664601]
[2019-03-27 06:59:34,916] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 06:59:34,919] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.7186053e-36 1.3540789e-34 2.1476447e-34 3.2305008e-24], sampled 0.23737308756408904
[2019-03-27 06:59:47,178] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 06:59:47,180] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.33333333333334, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.66255097026759, 6.911199999999999, 6.9112, 168.912956510431, 572848.2825175155, 572848.2825175162, 176181.5518173064]
[2019-03-27 06:59:47,182] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:59:47,186] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.7515185e-34 5.0325540e-32 2.3529052e-32 3.3033181e-22], sampled 0.49938569269729005
[2019-03-27 06:59:53,677] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 06:59:53,679] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.66666666666667, 81.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8349673471805453, 6.9112, 6.9112, 168.912956510431, 698823.0247583282, 698823.0247583282, 209177.2656053287]
[2019-03-27 06:59:53,680] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 06:59:53,683] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.2352255e-34 2.9818033e-32 8.0831767e-33 2.4918778e-22], sampled 0.6239982212417589
[2019-03-27 07:00:13,324] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 07:00:13,326] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.938247265, 71.76596027166667, 1.0, 2.0, 0.6258787266679049, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129025539347, 874640.6988950517, 874640.6988950511, 205660.4884774623]
[2019-03-27 07:00:13,327] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:00:13,330] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 7.12425408e-22 1.05124675e-14 2.64916090e-23
 6.71836586e-10], sampled 0.9322428079682101
[2019-03-27 07:00:13,331] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 874640.6988950517 W.
[2019-03-27 07:01:03,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02531717], dtype=float32), 0.061763104]
[2019-03-27 07:01:03,094] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.17612660166667, 79.30840256833332, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9733608729371388, 6.9112, 6.9112, 168.912956510431, 821969.3564217713, 821969.3564217713, 241737.614474377]
[2019-03-27 07:01:03,095] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:01:03,097] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 5.3809238e-25 1.5910086e-20 9.0627861e-25 1.2121721e-14], sampled 0.6860697559790562
[2019-03-27 07:01:15,992] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.7083 3319623909.1621 2143.0000
[2019-03-27 07:01:16,326] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7348.4079 3105587199.2298 2010.0000
[2019-03-27 07:01:16,357] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.3623 2937736105.9860 1381.0000
[2019-03-27 07:01:16,457] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.6333 2989305751.6220 1566.0000
[2019-03-27 07:01:16,469] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7029.1302 3185189082.0348 2464.0000
[2019-03-27 07:01:17,488] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1225000, evaluation results [1225000.0, 7286.708266798068, 3319623909.162109, 2143.0, 7348.407911634859, 3105587199.229759, 2010.0, 8060.362315912595, 2937736105.98599, 1381.0, 7029.130211347183, 3185189082.034765, 2464.0, 7924.6333343952965, 2989305751.6220117, 1566.0]
[2019-03-27 07:01:18,205] A3C_AGENT_WORKER-Thread-21 INFO:Local step 76500, global step 1225322: loss 59.8865
[2019-03-27 07:01:18,206] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 76500, global step 1225322: learning rate 0.0000
[2019-03-27 07:01:18,375] A3C_AGENT_WORKER-Thread-12 INFO:Local step 76500, global step 1225399: loss -19.6004
[2019-03-27 07:01:18,379] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 76500, global step 1225401: learning rate 0.0000
[2019-03-27 07:01:19,076] A3C_AGENT_WORKER-Thread-14 INFO:Local step 76500, global step 1225716: loss 73.2412
[2019-03-27 07:01:19,078] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 76500, global step 1225716: learning rate 0.0000
[2019-03-27 07:01:19,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.5240198e-33 8.0437596e-29 6.2198768e-32 2.6504789e-20], sum to 1.0000
[2019-03-27 07:01:19,920] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8476
[2019-03-27 07:01:19,928] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.03333333333333, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9164137130123685, 6.9112, 6.9112, 168.912956510431, 750309.002293083, 750309.002293083, 227026.8549059779], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6135600.0000, 
sim time next is 6136200.0000, 
raw observation next is [27.0, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9156598532216048, 6.911200000000001, 6.9112, 168.912956510431, 749789.5710812876, 749789.5710812869, 226853.088991059], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.895, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8971461624653716, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20827488085591322, 0.20827488085591303, 0.3385866999866552], 
reward next is 0.6614, 
noisyNet noise sample is [array([-1.6796229], dtype=float32), -0.7472431]. 
=============================================
[2019-03-27 07:01:20,073] A3C_AGENT_WORKER-Thread-2 INFO:Local step 76500, global step 1226161: loss 120.9587
[2019-03-27 07:01:20,076] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 76500, global step 1226161: learning rate 0.0000
[2019-03-27 07:01:20,576] A3C_AGENT_WORKER-Thread-19 INFO:Local step 76500, global step 1226389: loss 2.0743
[2019-03-27 07:01:20,578] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 76500, global step 1226389: learning rate 0.0000
[2019-03-27 07:01:20,666] A3C_AGENT_WORKER-Thread-3 INFO:Local step 76500, global step 1226430: loss -52.6001
[2019-03-27 07:01:20,671] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 76500, global step 1226431: learning rate 0.0000
[2019-03-27 07:01:20,949] A3C_AGENT_WORKER-Thread-15 INFO:Local step 76500, global step 1226558: loss 11.9315
[2019-03-27 07:01:20,954] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 76500, global step 1226560: learning rate 0.0000
[2019-03-27 07:01:20,982] A3C_AGENT_WORKER-Thread-16 INFO:Local step 76500, global step 1226571: loss 145.9263
[2019-03-27 07:01:20,984] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 76500, global step 1226572: learning rate 0.0000
[2019-03-27 07:01:21,076] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9999809e-01 5.8086232e-16 3.2003393e-09 1.8647303e-17 1.8957470e-06], sum to 1.0000
[2019-03-27 07:01:21,084] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1010
[2019-03-27 07:01:21,085] A3C_AGENT_WORKER-Thread-17 INFO:Local step 76500, global step 1226615: loss 150.3194
[2019-03-27 07:01:21,086] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 76500, global step 1226615: learning rate 0.0000
[2019-03-27 07:01:21,093] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 951184.2856563547 W.
[2019-03-27 07:01:21,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.06666666666667, 89.66666666666667, 1.0, 2.0, 0.3403137808554641, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5825826725876617, 6.911200000000001, 6.9112, 168.912956510431, 951184.2856563547, 951184.2856563542, 234797.1965420597], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6157200.0000, 
sim time next is 6157800.0000, 
raw observation next is [27.15, 89.5, 1.0, 2.0, 0.2275956038007653, 1.0, 1.0, 0.2275956038007653, 1.0, 2.0, 0.3915400784507623, 6.911200000000001, 6.9112, 170.5573041426782, 954199.0830063756, 954199.0830063749, 277763.7272856285], 
processed observation next is [1.0, 0.2608695652173913, 0.485781990521327, 0.895, 1.0, 1.0, 0.0693922937358618, 1.0, 0.5, 0.0693922937358618, 1.0, 1.0, 0.2579757054277589, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2650553008351043, 0.26505530083510415, 0.41457272729198286], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.17124812], dtype=float32), 0.43585765]. 
=============================================
[2019-03-27 07:01:21,527] A3C_AGENT_WORKER-Thread-10 INFO:Local step 76500, global step 1226810: loss 201.1322
[2019-03-27 07:01:21,528] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 76500, global step 1226810: learning rate 0.0000
[2019-03-27 07:01:21,534] A3C_AGENT_WORKER-Thread-18 INFO:Local step 76500, global step 1226813: loss 12.6235
[2019-03-27 07:01:21,538] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 76500, global step 1226813: learning rate 0.0000
[2019-03-27 07:01:21,861] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77000, global step 1226961: loss 432.2040
[2019-03-27 07:01:21,863] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77000, global step 1226962: learning rate 0.0000
[2019-03-27 07:01:23,253] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.6153476e-25 2.1862888e-19 2.1800182e-26 3.3924148e-12], sum to 1.0000
[2019-03-27 07:01:23,260] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4806
[2019-03-27 07:01:23,265] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8538025150530782, 6.911199999999999, 6.9112, 168.912956510431, 699923.403313584, 699923.4033135847, 212797.249101896], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6198000.0000, 
sim time next is 6198600.0000, 
raw observation next is [28.58333333333333, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8788129771564, 6.9112, 6.9112, 168.912956510431, 720490.964693757, 720490.964693757, 218373.9344407165], 
processed observation next is [1.0, 0.7391304347826086, 0.5537124802527644, 0.785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8522109477517072, 0.0, 0.0, 0.8294399451523027, 0.20013637908159918, 0.20013637908159918, 0.3259312454339052], 
reward next is 0.6741, 
noisyNet noise sample is [array([-1.025448], dtype=float32), 1.7112757]. 
=============================================
[2019-03-27 07:01:23,525] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 7.0465926e-32 5.6896054e-28 1.5033949e-31 4.0164193e-18], sum to 1.0000
[2019-03-27 07:01:23,536] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9519
[2019-03-27 07:01:23,541] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.45, 90.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8908050815454699, 6.911199999999998, 6.9112, 168.912956510431, 733311.8261486973, 733311.8261486986, 221226.9762051287], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6486600.0000, 
sim time next is 6487200.0000, 
raw observation next is [26.4, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.89070049930474, 6.911199999999999, 6.9112, 168.912956510431, 733520.5598054687, 733520.5598054692, 221214.3868733529], 
processed observation next is [1.0, 0.08695652173913043, 0.45023696682464454, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8667079259813903, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20375571105707463, 0.2037557110570748, 0.3301707266766461], 
reward next is 0.6698, 
noisyNet noise sample is [array([0.55603987], dtype=float32), 0.003343575]. 
=============================================
[2019-03-27 07:01:24,892] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.7481102e-37 2.5630506e-34 3.9267888e-35 3.4580692e-24], sum to 1.0000
[2019-03-27 07:01:24,903] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9202
[2019-03-27 07:01:24,911] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.43333333333334, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9025966291876977, 6.911200000000001, 6.9112, 168.912956510431, 740987.5021478765, 740987.5021478758, 223872.2365732956], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6207600.0000, 
sim time next is 6208200.0000, 
raw observation next is [27.4, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9023585873899614, 6.911199999999999, 6.9112, 168.912956510431, 740887.7084957134, 740887.708495714, 223820.7932768209], 
processed observation next is [1.0, 0.8695652173913043, 0.4976303317535545, 0.855, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8809251065731236, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20580214124880927, 0.20580214124880944, 0.3340608854877924], 
reward next is 0.6659, 
noisyNet noise sample is [array([0.7347156], dtype=float32), 0.6695017]. 
=============================================
[2019-03-27 07:01:26,464] A3C_AGENT_WORKER-Thread-13 INFO:Local step 77500, global step 1229021: loss 0.0560
[2019-03-27 07:01:26,468] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 77500, global step 1229021: learning rate 0.0000
[2019-03-27 07:01:26,518] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.8807519e-38 6.9307711e-36 2.7290493e-35 2.6650108e-25], sum to 1.0000
[2019-03-27 07:01:26,526] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5637
[2019-03-27 07:01:26,534] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8864238600319678, 6.911200000000001, 6.9112, 168.912956510431, 730867.7198315278, 730867.7198315272, 220267.6756895347], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6332400.0000, 
sim time next is 6333000.0000, 
raw observation next is [27.9, 80.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.885307853482234, 6.9112, 6.9112, 168.912956510431, 729979.741927517, 729979.741927517, 220013.9376543119], 
processed observation next is [0.0, 0.30434782608695654, 0.5213270142180094, 0.8033333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8601315286368706, 0.0, 0.0, 0.8294399451523027, 0.20277215053542139, 0.20277215053542139, 0.32837901142434617], 
reward next is 0.6716, 
noisyNet noise sample is [array([0.39562008], dtype=float32), 0.26132992]. 
=============================================
[2019-03-27 07:01:26,548] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.762955]
 [70.70513 ]
 [70.71895 ]
 [70.73053 ]
 [70.73065 ]], R is [[70.78205872]
 [70.7454834 ]
 [70.70883942]
 [70.67236328]
 [70.63650513]].
[2019-03-27 07:01:30,709] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 8.5354631e-38 2.2387901e-36 7.5208701e-36 2.8135807e-23], sum to 1.0000
[2019-03-27 07:01:30,717] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6019
[2019-03-27 07:01:30,724] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.3, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8831654077440599, 6.9112, 6.9112, 168.912956510431, 728424.1880645432, 728424.1880645432, 219533.2766038986], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6366000.0000, 
sim time next is 6366600.0000, 
raw observation next is [29.95, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8788970122800305, 6.9112, 6.9112, 168.912956510431, 725548.1012805, 725548.1012805, 218587.379815971], 
processed observation next is [0.0, 0.6956521739130435, 0.6184834123222749, 0.675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8523134296097932, 0.0, 0.0, 0.8294399451523027, 0.2015411392445833, 0.2015411392445833, 0.3262498206208523], 
reward next is 0.6738, 
noisyNet noise sample is [array([-1.6679124], dtype=float32), -1.5114441]. 
=============================================
[2019-03-27 07:01:30,959] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77000, global step 1231040: loss 636.2586
[2019-03-27 07:01:30,961] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77000, global step 1231041: learning rate 0.0000
[2019-03-27 07:01:32,372] A3C_AGENT_WORKER-Thread-20 INFO:Local step 77500, global step 1231615: loss 0.1005
[2019-03-27 07:01:32,374] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 77500, global step 1231615: learning rate 0.0000
[2019-03-27 07:01:34,384] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77000, global step 1232553: loss 691.2374
[2019-03-27 07:01:34,386] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77000, global step 1232553: learning rate 0.0000
[2019-03-27 07:01:35,807] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9977952e-01 4.0625022e-15 1.1364867e-06 7.0407364e-18 2.1927802e-04], sum to 1.0000
[2019-03-27 07:01:35,813] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5816
[2019-03-27 07:01:35,820] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2394817.525178714 W.
[2019-03-27 07:01:35,824] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.9, 69.0, 1.0, 2.0, 0.8562530797492514, 1.0, 2.0, 0.8562530797492514, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2394817.525178714, 2394817.525178714, 448179.5573632343], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6436800.0000, 
sim time next is 6437400.0000, 
raw observation next is [29.9, 69.0, 1.0, 2.0, 0.8338315682341346, 1.0, 2.0, 0.8338315682341346, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2332049.247833064, 2332049.247833064, 436671.340211481], 
processed observation next is [1.0, 0.5217391304347826, 0.6161137440758293, 0.69, 1.0, 1.0, 0.799797070161608, 1.0, 1.0, 0.799797070161608, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.6477914577314067, 0.6477914577314067, 0.6517482689723597], 
reward next is 0.3483, 
noisyNet noise sample is [array([0.06303479], dtype=float32), 0.07272187]. 
=============================================
[2019-03-27 07:01:36,077] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77000, global step 1233340: loss 530.7321
[2019-03-27 07:01:36,079] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77000, global step 1233340: learning rate 0.0000
[2019-03-27 07:01:36,265] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77000, global step 1233424: loss 425.1250
[2019-03-27 07:01:36,267] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77000, global step 1233424: learning rate 0.0000
[2019-03-27 07:01:36,952] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77000, global step 1233739: loss 558.9117
[2019-03-27 07:01:36,956] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77000, global step 1233739: learning rate 0.0000
[2019-03-27 07:01:37,943] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77000, global step 1234187: loss 436.5101
[2019-03-27 07:01:37,946] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77000, global step 1234187: learning rate 0.0000
[2019-03-27 07:01:38,257] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77000, global step 1234333: loss 353.3301
[2019-03-27 07:01:38,259] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77000, global step 1234334: learning rate 0.0000
[2019-03-27 07:01:38,423] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77000, global step 1234412: loss 392.4824
[2019-03-27 07:01:38,426] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77000, global step 1234412: learning rate 0.0000
[2019-03-27 07:01:38,651] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77000, global step 1234515: loss 361.9212
[2019-03-27 07:01:38,654] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77000, global step 1234515: learning rate 0.0000
[2019-03-27 07:01:38,789] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77000, global step 1234575: loss 566.9121
[2019-03-27 07:01:38,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77000, global step 1234577: learning rate 0.0000
[2019-03-27 07:01:38,886] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77000, global step 1234624: loss 665.3468
[2019-03-27 07:01:38,891] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77000, global step 1234625: learning rate 0.0000
[2019-03-27 07:01:39,206] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77000, global step 1234773: loss 438.7831
[2019-03-27 07:01:39,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77000, global step 1234774: learning rate 0.0000
[2019-03-27 07:01:39,539] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77000, global step 1234927: loss 668.9249
[2019-03-27 07:01:39,542] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77000, global step 1234928: learning rate 0.0000
[2019-03-27 07:01:40,202] A3C_AGENT_WORKER-Thread-22 INFO:Local step 77500, global step 1235241: loss 0.1884
[2019-03-27 07:01:40,204] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 77500, global step 1235241: learning rate 0.0000
[2019-03-27 07:01:42,849] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999917e-01 2.3902283e-18 1.0866346e-11 7.6136119e-21 7.8663095e-07], sum to 1.0000
[2019-03-27 07:01:42,855] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2872
[2019-03-27 07:01:42,864] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1425655.103042882 W.
[2019-03-27 07:01:42,868] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.4, 49.0, 1.0, 2.0, 0.3366637797497078, 1.0, 1.0, 0.3366637797497078, 1.0, 2.0, 0.5640626146478332, 6.9112, 6.9112, 170.5573041426782, 1425655.103042882, 1425655.103042882, 319427.9744061565], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7043400.0000, 
sim time next is 7044000.0000, 
raw observation next is [31.5, 48.33333333333334, 1.0, 2.0, 0.5659895602156798, 1.0, 2.0, 0.5659895602156798, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1609436.278464367, 1609436.278464367, 325269.2376926184], 
processed observation next is [1.0, 0.5217391304347826, 0.6919431279620853, 0.48333333333333345, 1.0, 1.0, 0.4770958556815419, 1.0, 1.0, 0.4770958556815419, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4470656329067686, 0.4470656329067686, 0.48547647416808715], 
reward next is 0.5145, 
noisyNet noise sample is [array([0.3445471], dtype=float32), 1.310704]. 
=============================================
[2019-03-27 07:01:42,884] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[39.2201  ]
 [37.961334]
 [37.1734  ]
 [36.95352 ]
 [37.05522 ]], R is [[39.54109192]
 [39.14567947]
 [38.75422287]
 [38.36668015]
 [38.19450378]].
[2019-03-27 07:01:43,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9970621e-01 4.3678262e-16 5.0523483e-09 3.3168859e-18 2.9371705e-04], sum to 1.0000
[2019-03-27 07:01:43,429] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6152
[2019-03-27 07:01:43,435] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2247634.245086619 W.
[2019-03-27 07:01:43,441] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.46666666666667, 56.0, 1.0, 2.0, 0.5357838901050609, 1.0, 1.0, 0.5357838901050609, 1.0, 2.0, 0.9083605883414964, 6.9112, 6.9112, 170.5573041426782, 2247634.245086619, 2247634.245086619, 436389.7501395969], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6523800.0000, 
sim time next is 6524400.0000, 
raw observation next is [31.53333333333333, 56.0, 1.0, 2.0, 0.4287823487524028, 1.0, 2.0, 0.4287823487524028, 1.0, 2.0, 0.7275756600218477, 6.911199999999999, 6.9112, 170.5573041426782, 1798386.052166935, 1798386.052166936, 366762.2859881569], 
processed observation next is [1.0, 0.5217391304347826, 0.693522906793049, 0.56, 1.0, 1.0, 0.31178596235229256, 1.0, 1.0, 0.31178596235229256, 1.0, 1.0, 0.6677751951485947, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.49955168115748194, 0.4995516811574822, 0.5474063969972491], 
reward next is 0.4526, 
noisyNet noise sample is [array([-0.28209868], dtype=float32), 1.1077871]. 
=============================================
[2019-03-27 07:01:43,609] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78000, global step 1236820: loss -35.3615
[2019-03-27 07:01:43,612] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78000, global step 1236821: learning rate 0.0000
[2019-03-27 07:01:48,585] A3C_AGENT_WORKER-Thread-9 INFO:Local step 77500, global step 1239143: loss 0.2673
[2019-03-27 07:01:48,589] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 77500, global step 1239143: learning rate 0.0000
[2019-03-27 07:01:48,667] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78000, global step 1239177: loss -54.0354
[2019-03-27 07:01:48,669] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78000, global step 1239177: learning rate 0.0000
[2019-03-27 07:01:50,954] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.7122564e-21 1.5893013e-16 5.8370229e-23 1.3231229e-08], sum to 1.0000
[2019-03-27 07:01:50,969] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1326
[2019-03-27 07:01:50,977] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 950388.6683012812 W.
[2019-03-27 07:01:50,981] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.78333333333333, 91.66666666666667, 1.0, 2.0, 0.2266871460949263, 1.0, 1.0, 0.2266871460949263, 1.0, 2.0, 0.3838614993931694, 6.9112, 6.9112, 170.5573041426782, 950388.6683012812, 950388.6683012812, 277062.4485843605], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 6678600.0000, 
sim time next is 6679200.0000, 
raw observation next is [25.86666666666667, 91.33333333333334, 1.0, 2.0, 0.3555440118468881, 1.0, 2.0, 0.3555440118468881, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 993768.5408654227, 993768.5408654227, 261503.7789190996], 
processed observation next is [1.0, 0.30434782608695654, 0.42496050552922615, 0.9133333333333334, 1.0, 1.0, 0.22354700222516638, 1.0, 1.0, 0.22354700222516638, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.27604681690706184, 0.27604681690706184, 0.3903041476404472], 
reward next is 0.6097, 
noisyNet noise sample is [array([0.76212543], dtype=float32), 0.6923415]. 
=============================================
[2019-03-27 07:01:51,607] A3C_AGENT_WORKER-Thread-11 INFO:Local step 77500, global step 1240549: loss 0.2351
[2019-03-27 07:01:51,610] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 77500, global step 1240549: learning rate 0.0000
[2019-03-27 07:01:52,555] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9115127e-01 1.7655177e-14 1.1229756e-06 2.8946425e-17 8.8474862e-03], sum to 1.0000
[2019-03-27 07:01:52,565] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9384
[2019-03-27 07:01:52,572] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1622611.239224873 W.
[2019-03-27 07:01:52,582] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.48333333333333, 67.66666666666667, 1.0, 2.0, 0.5803528268130068, 0.0, 1.0, 0.0, 1.0, 1.0, 0.96747945870093, 6.911199999999999, 6.9112, 168.9129565018092, 1622611.239224873, 1622611.239224873, 346257.9477141061], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7125000.0000, 
sim time next is 7125600.0000, 
raw observation next is [28.36666666666667, 68.33333333333334, 1.0, 2.0, 0.4124891357957532, 1.0, 1.0, 0.4124891357957532, 1.0, 2.0, 0.6921703093950958, 6.9112, 6.9112, 170.5573041426782, 1729994.383742392, 1729994.383742392, 356301.7243066364], 
processed observation next is [1.0, 0.4782608695652174, 0.543443917851501, 0.6833333333333335, 1.0, 1.0, 0.2921555852960882, 1.0, 0.5, 0.2921555852960882, 1.0, 1.0, 0.6245979382867021, 0.0, 0.0, 0.8375144448122397, 0.4805539954839978, 0.4805539954839978, 0.531793618368114], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7048303], dtype=float32), 1.9141538]. 
=============================================
[2019-03-27 07:01:53,212] A3C_AGENT_WORKER-Thread-21 INFO:Local step 77500, global step 1241271: loss 0.2061
[2019-03-27 07:01:53,215] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 77500, global step 1241271: learning rate 0.0000
[2019-03-27 07:01:53,561] A3C_AGENT_WORKER-Thread-12 INFO:Local step 77500, global step 1241432: loss 0.1617
[2019-03-27 07:01:53,567] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 77500, global step 1241433: learning rate 0.0000
[2019-03-27 07:01:54,269] A3C_AGENT_WORKER-Thread-14 INFO:Local step 77500, global step 1241762: loss 0.1554
[2019-03-27 07:01:54,275] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 77500, global step 1241763: learning rate 0.0000
[2019-03-27 07:01:55,240] A3C_AGENT_WORKER-Thread-2 INFO:Local step 77500, global step 1242214: loss 0.1021
[2019-03-27 07:01:55,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 77500, global step 1242215: learning rate 0.0000
[2019-03-27 07:01:55,433] A3C_AGENT_WORKER-Thread-19 INFO:Local step 77500, global step 1242302: loss 0.0889
[2019-03-27 07:01:55,434] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 77500, global step 1242302: learning rate 0.0000
[2019-03-27 07:01:55,879] A3C_AGENT_WORKER-Thread-3 INFO:Local step 77500, global step 1242508: loss 0.0783
[2019-03-27 07:01:55,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 77500, global step 1242509: learning rate 0.0000
[2019-03-27 07:01:56,089] A3C_AGENT_WORKER-Thread-15 INFO:Local step 77500, global step 1242602: loss 0.0633
[2019-03-27 07:01:56,092] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 77500, global step 1242603: learning rate 0.0000
[2019-03-27 07:01:56,205] A3C_AGENT_WORKER-Thread-17 INFO:Local step 77500, global step 1242656: loss 0.0485
[2019-03-27 07:01:56,212] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 77500, global step 1242656: learning rate 0.0000
[2019-03-27 07:01:56,230] A3C_AGENT_WORKER-Thread-16 INFO:Local step 77500, global step 1242670: loss 0.0556
[2019-03-27 07:01:56,233] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 77500, global step 1242671: learning rate 0.0000
[2019-03-27 07:01:56,616] A3C_AGENT_WORKER-Thread-18 INFO:Local step 77500, global step 1242849: loss 0.0406
[2019-03-27 07:01:56,618] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 77500, global step 1242849: learning rate 0.0000
[2019-03-27 07:01:56,645] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78000, global step 1242862: loss -17.9221
[2019-03-27 07:01:56,647] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78000, global step 1242862: learning rate 0.0000
[2019-03-27 07:01:56,972] A3C_AGENT_WORKER-Thread-10 INFO:Local step 77500, global step 1243009: loss 0.0265
[2019-03-27 07:01:56,975] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 77500, global step 1243010: learning rate 0.0000
[2019-03-27 07:02:00,703] A3C_AGENT_WORKER-Thread-13 INFO:Local step 78500, global step 1244752: loss 8.9508
[2019-03-27 07:02:00,705] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 78500, global step 1244754: learning rate 0.0000
[2019-03-27 07:02:01,151] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.1747120e-36 1.3473689e-36 1.2403563e-34 8.0784708e-23], sum to 1.0000
[2019-03-27 07:02:01,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9275
[2019-03-27 07:02:01,161] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6625841347755815, 6.9112, 6.9112, 168.912956510431, 570824.3978629658, 570824.3978629658, 176202.9150450026], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6853200.0000, 
sim time next is 6853800.0000, 
raw observation next is [24.8, 78.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.666363776294414, 6.911199999999999, 6.9112, 168.912956510431, 573762.7834650266, 573762.7834650272, 176845.9643166266], 
processed observation next is [0.0, 0.30434782608695654, 0.3744075829383887, 0.7833333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5931265564566024, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15937855096250741, 0.15937855096250755, 0.26394920047257703], 
reward next is 0.7361, 
noisyNet noise sample is [array([-0.0497188], dtype=float32), 1.4432046]. 
=============================================
[2019-03-27 07:02:02,132] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.6049599e-36 3.6282795e-35 2.5825728e-33 1.2731054e-22], sum to 1.0000
[2019-03-27 07:02:02,139] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9618
[2019-03-27 07:02:02,146] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.05, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6093939934656335, 6.9112, 6.9112, 168.912956510431, 530618.8737611003, 530618.8737611003, 167520.401496072], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6841800.0000, 
sim time next is 6842400.0000, 
raw observation next is [23.03333333333333, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6101816559288056, 6.9112, 6.9112, 168.912956510431, 531150.203740674, 531150.203740674, 167645.1464033863], 
processed observation next is [0.0, 0.17391304347826086, 0.29067930489731436, 0.8333333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5246117755229336, 0.0, 0.0, 0.8294399451523027, 0.14754172326129833, 0.14754172326129833, 0.2502166364229646], 
reward next is 0.7498, 
noisyNet noise sample is [array([-1.5256332], dtype=float32), -0.30368754]. 
=============================================
[2019-03-27 07:02:02,988] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.2358469e-35 1.9068204e-34 8.7412276e-34 8.7152434e-22], sum to 1.0000
[2019-03-27 07:02:03,000] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2163
[2019-03-27 07:02:03,009] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7909845526234176, 6.911200000000001, 6.9112, 168.912956510431, 663589.5628702575, 663589.5628702568, 200000.867977952], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6958800.0000, 
sim time next is 6959400.0000, 
raw observation next is [31.81666666666667, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7866243646433512, 6.9112, 6.9112, 168.912956510431, 660139.3914418204, 660139.3914418204, 199120.0767709662], 
processed observation next is [0.0, 0.5652173913043478, 0.7069510268562403, 0.52, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.739785810540672, 0.0, 0.0, 0.8294399451523027, 0.18337205317828345, 0.18337205317828345, 0.29719414443427794], 
reward next is 0.7028, 
noisyNet noise sample is [array([0.8295039], dtype=float32), -0.6528435]. 
=============================================
[2019-03-27 07:02:03,941] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 1.5308629e-36 1.0739785e-36 3.3456593e-24], sum to 1.0000
[2019-03-27 07:02:03,952] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6691
[2019-03-27 07:02:03,957] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.46666666666667, 59.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6452657960333428, 6.9112, 6.9112, 168.912956510431, 557958.4867546587, 557958.4867546587, 173297.7654782958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6894600.0000, 
sim time next is 6895200.0000, 
raw observation next is [27.33333333333334, 60.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6463657830674961, 6.911199999999999, 6.9112, 168.912956510431, 558768.4986753551, 558768.4986753558, 173480.2093410568], 
processed observation next is [0.0, 0.8260869565217391, 0.4944707740916275, 0.6066666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5687387598384099, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15521347185426532, 0.1552134718542655, 0.25892568558366685], 
reward next is 0.7411, 
noisyNet noise sample is [array([0.06546268], dtype=float32), -0.08114626]. 
=============================================
[2019-03-27 07:02:05,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.0694063e-35 4.0477175e-34 2.2183988e-33 1.3851473e-21], sum to 1.0000
[2019-03-27 07:02:05,172] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5422
[2019-03-27 07:02:05,177] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7261920364755584, 6.9112, 6.9112, 168.912956510431, 619006.1099668499, 619006.1099668499, 187509.290852095], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6924000.0000, 
sim time next is 6924600.0000, 
raw observation next is [24.1, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7230375701906255, 6.9112, 6.9112, 168.912956510431, 616474.4550568531, 616474.4550568531, 186923.636722554], 
processed observation next is [0.0, 0.13043478260869565, 0.3412322274881518, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6622409392568605, 0.0, 0.0, 0.8294399451523027, 0.17124290418245922, 0.17124290418245922, 0.2789905025709761], 
reward next is 0.7210, 
noisyNet noise sample is [array([-0.04456028], dtype=float32), -0.093798354]. 
=============================================
[2019-03-27 07:02:05,658] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78000, global step 1247065: loss 23.7327
[2019-03-27 07:02:05,661] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78000, global step 1247065: learning rate 0.0000
[2019-03-27 07:02:06,342] A3C_AGENT_WORKER-Thread-20 INFO:Local step 78500, global step 1247381: loss 13.3697
[2019-03-27 07:02:06,344] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 78500, global step 1247382: learning rate 0.0000
[2019-03-27 07:02:08,909] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78000, global step 1248571: loss 33.3903
[2019-03-27 07:02:08,911] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78000, global step 1248571: learning rate 0.0000
[2019-03-27 07:02:10,453] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78000, global step 1249292: loss -61.4753
[2019-03-27 07:02:10,456] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78000, global step 1249294: learning rate 0.0000
[2019-03-27 07:02:10,726] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78000, global step 1249418: loss -13.9913
[2019-03-27 07:02:10,728] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78000, global step 1249418: learning rate 0.0000
[2019-03-27 07:02:10,912] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9936789e-01 3.9532833e-16 2.6420266e-09 5.1430836e-18 6.3208776e-04], sum to 1.0000
[2019-03-27 07:02:10,923] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8463
[2019-03-27 07:02:10,931] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 930935.1019914206 W.
[2019-03-27 07:02:10,934] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [25.3, 86.0, 1.0, 2.0, 0.3299893990985233, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5526933431182451, 6.911200000000001, 6.9112, 168.912956510431, 930935.1019914206, 930935.10199142, 230330.0803524193], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7012800.0000, 
sim time next is 7013400.0000, 
raw observation next is [25.25, 86.33333333333334, 1.0, 2.0, 0.6394466257151176, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 908463.2424587941, 908463.2424587935, 210263.1394696199], 
processed observation next is [1.0, 0.17391304347826086, 0.39573459715639814, 0.8633333333333334, 1.0, 1.0, 0.5655983442350814, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25235090068299837, 0.2523509006829982, 0.31382558129794014], 
reward next is 0.6862, 
noisyNet noise sample is [array([0.05516737], dtype=float32), 1.3104533]. 
=============================================
[2019-03-27 07:02:11,622] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78000, global step 1249838: loss 56.5720
[2019-03-27 07:02:11,623] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78000, global step 1249838: learning rate 0.0000
[2019-03-27 07:02:11,968] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-27 07:02:11,969] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:02:11,969] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:02:11,971] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:02:11,972] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:02:11,971] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:02:11,974] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:02:11,975] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:02:11,972] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:02:11,973] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:02:11,978] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:02:12,006] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run51
[2019-03-27 07:02:12,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run51
[2019-03-27 07:02:12,047] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run51
[2019-03-27 07:02:12,066] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run51
[2019-03-27 07:02:12,067] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run51
[2019-03-27 07:02:34,851] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:02:34,853] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.75, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6625707204542102, 6.9112, 6.9112, 168.912956510431, 569315.7200329085, 569315.7200329085, 176206.6190216015]
[2019-03-27 07:02:34,854] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:02:34,859] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.4809278e-33 1.5744628e-31 1.3966112e-31 2.3603193e-19], sampled 0.6225618253391272
[2019-03-27 07:02:35,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:02:35,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 96.0, 1.0, 2.0, 0.7751033497751769, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1146259.366412556, 1146259.366412557, 246418.4817312327]
[2019-03-27 07:02:35,751] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:02:35,754] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999201e-01 7.0119723e-17 3.3844419e-10 9.9952948e-18 8.0169320e-06], sampled 0.12169992443722322
[2019-03-27 07:02:35,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1146259.366412556 W.
[2019-03-27 07:02:48,920] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:02:48,922] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.35, 75.0, 1.0, 2.0, 0.8835234970646474, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1234898.397704368, 1234898.397704368, 265443.6492816472]
[2019-03-27 07:02:48,922] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:02:48,925] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999964e-01 3.1348207e-19 4.9794939e-13 4.8290181e-20 3.8455076e-07], sampled 0.31939085953017887
[2019-03-27 07:02:48,925] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1234898.397704368 W.
[2019-03-27 07:02:52,322] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:02:52,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.30876546, 88.52384222, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6717287657601277, 6.911199999999999, 6.9112, 168.912956510431, 578600.1261121064, 578600.1261121071, 177761.8958690925]
[2019-03-27 07:02:52,326] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:02:52,329] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 7.5902741e-36 4.7496956e-34 5.6016778e-34 5.5346792e-21], sampled 0.8636807347602986
[2019-03-27 07:02:59,388] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:02:59,391] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.8, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9367766199445023, 6.9112, 6.9112, 168.912956510431, 766706.6441308488, 766706.6441308488, 231881.0806064019]
[2019-03-27 07:02:59,392] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:02:59,394] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.3550045e-33 2.8055843e-31 4.0289275e-32 1.5616783e-18], sampled 0.5042763113310824
[2019-03-27 07:03:01,673] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:03:01,673] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.33127542, 67.08510510666667, 1.0, 2.0, 0.503624934510371, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8594521592387872, 6.911199999999999, 6.9112, 168.912956491156, 1407945.082986058, 1407945.082986058, 307322.1253037835]
[2019-03-27 07:03:01,675] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:03:01,678] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999988e-01 5.1958743e-23 3.5800700e-16 4.9010899e-24 8.9597549e-08], sampled 0.326957347499081
[2019-03-27 07:03:01,680] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1407945.082986058 W.
[2019-03-27 07:03:01,969] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:03:01,970] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8659103618379512, 6.911200000000001, 6.9112, 168.912956510431, 720111.6532529552, 720111.6532529546, 215842.9068342854]
[2019-03-27 07:03:01,972] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:03:01,978] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.0030604e-36 4.6978867e-35 1.4792662e-34 2.8630740e-21], sampled 0.32486017831783
[2019-03-27 07:03:08,433] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:03:08,434] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.83333333333334, 60.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.164244659323325, 6.9112, 168.9114440768286, 1008387.948502453, 828870.965449079, 254813.5649025347]
[2019-03-27 07:03:08,434] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:03:08,438] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.7151451e-20 4.4926441e-15 1.4509194e-20 1.2220139e-08], sampled 0.3785417772787327
[2019-03-27 07:03:08,440] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1008387.948502453 W.
[2019-03-27 07:03:30,661] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:03:30,662] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.8, 73.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.755845775390968, 6.9112, 168.908367886469, 2053369.895480401, 1454165.390153745, 311356.5103419363]
[2019-03-27 07:03:30,664] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:03:30,666] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9565190e-01 1.0045874e-14 5.3264763e-08 3.1448719e-16 4.3481588e-03], sampled 0.03154281163878303
[2019-03-27 07:03:30,667] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2053369.895480401 W.
[2019-03-27 07:04:01,084] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02532196], dtype=float32), 0.06408827]
[2019-03-27 07:04:01,086] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.53391483333333, 94.69148760333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6583083540681183, 6.9112, 6.9112, 168.912956510431, 568126.5113427726, 568126.5113427726, 175475.703898991]
[2019-03-27 07:04:01,087] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:04:01,090] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.0989197e-36 3.5087048e-34 6.1945820e-34 3.5386629e-21], sampled 0.9740841361062522
[2019-03-27 07:04:07,327] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.6845 3185262776.6699 2453.0000
[2019-03-27 07:04:07,475] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7916.1551 2989598269.3996 1573.0000
[2019-03-27 07:04:07,556] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7341.5122 3105990145.1974 2010.0000
[2019-03-27 07:04:07,611] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7276.1034 3319277347.2780 2139.0000
[2019-03-27 07:04:07,715] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8057.5797 2938075212.1503 1372.0000
[2019-03-27 07:04:08,735] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 1250000, evaluation results [1250000.0, 7276.103411265756, 3319277347.278038, 2139.0, 7341.512184388081, 3105990145.1973667, 2010.0, 8057.579672242063, 2938075212.15028, 1372.0, 7030.6844637149825, 3185262776.669945, 2453.0, 7916.155136851328, 2989598269.399592, 1573.0]
[2019-03-27 07:04:09,399] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78000, global step 1250301: loss -198.1310
[2019-03-27 07:04:09,400] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78000, global step 1250301: learning rate 0.0000
[2019-03-27 07:04:09,462] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78000, global step 1250330: loss -16.3286
[2019-03-27 07:04:09,466] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78000, global step 1250331: learning rate 0.0000
[2019-03-27 07:04:10,036] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78000, global step 1250585: loss -1.7646
[2019-03-27 07:04:10,038] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78000, global step 1250585: learning rate 0.0000
[2019-03-27 07:04:10,065] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78000, global step 1250596: loss 39.8662
[2019-03-27 07:04:10,067] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78000, global step 1250598: learning rate 0.0000
[2019-03-27 07:04:10,232] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78000, global step 1250669: loss -27.5520
[2019-03-27 07:04:10,234] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78000, global step 1250669: learning rate 0.0000
[2019-03-27 07:04:10,363] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78000, global step 1250728: loss 5.2376
[2019-03-27 07:04:10,365] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78000, global step 1250729: learning rate 0.0000
[2019-03-27 07:04:10,754] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78000, global step 1250903: loss -133.7483
[2019-03-27 07:04:10,755] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78000, global step 1250903: learning rate 0.0000
[2019-03-27 07:04:10,934] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78000, global step 1250986: loss -64.0732
[2019-03-27 07:04:10,939] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78000, global step 1250989: learning rate 0.0000
[2019-03-27 07:04:11,096] A3C_AGENT_WORKER-Thread-22 INFO:Local step 78500, global step 1251061: loss 11.1142
[2019-03-27 07:04:11,098] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 78500, global step 1251062: learning rate 0.0000
[2019-03-27 07:04:14,330] A3C_AGENT_WORKER-Thread-13 INFO:Local step 79000, global step 1252509: loss 139.4958
[2019-03-27 07:04:14,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 79000, global step 1252509: learning rate 0.0000
[2019-03-27 07:04:17,625] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9681276e-01 2.4410796e-17 5.1187561e-09 7.3412264e-19 3.1872478e-03], sum to 1.0000
[2019-03-27 07:04:17,633] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5048
[2019-03-27 07:04:17,642] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1336024.023980853 W.
[2019-03-27 07:04:17,646] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.16666666666667, 86.5, 1.0, 2.0, 0.4593651275917306, 1.0, 2.0, 0.4593651275917306, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1336024.023980853, 1336024.023980853, 294243.9168056991], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7228200.0000, 
sim time next is 7228800.0000, 
raw observation next is [24.2, 86.0, 1.0, 2.0, 0.8818558172860923, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1300761.868053043, 1300761.868053043, 274772.4261485623], 
processed observation next is [1.0, 0.6956521739130435, 0.3459715639810427, 0.86, 1.0, 1.0, 0.857657611188063, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.3613227411258453, 0.3613227411258453, 0.41010809872919746], 
reward next is 0.5899, 
noisyNet noise sample is [array([-1.3494819], dtype=float32), -0.6653462]. 
=============================================
[2019-03-27 07:04:19,977] A3C_AGENT_WORKER-Thread-20 INFO:Local step 79000, global step 1255034: loss -41.7949
[2019-03-27 07:04:19,979] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 79000, global step 1255035: learning rate 0.0000
[2019-03-27 07:04:20,119] A3C_AGENT_WORKER-Thread-9 INFO:Local step 78500, global step 1255103: loss 18.9994
[2019-03-27 07:04:20,122] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 78500, global step 1255104: learning rate 0.0000
[2019-03-27 07:04:22,742] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.5475243e-31 1.7809078e-27 4.6632576e-31 1.5639513e-16], sum to 1.0000
[2019-03-27 07:04:22,750] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9781
[2019-03-27 07:04:22,755] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.583366483388225, 6.911199999999999, 6.9112, 168.912956510431, 510886.6264841023, 510886.6264841029, 163520.9515730287], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7276800.0000, 
sim time next is 7277400.0000, 
raw observation next is [21.55, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5882499416510376, 6.911199999999999, 6.9112, 168.912956510431, 515125.9540722623, 515125.954072263, 164245.3059777009], 
processed observation next is [1.0, 0.21739130434782608, 0.22037914691943136, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49786578250126534, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14309054279785063, 0.14309054279785083, 0.24514224772791177], 
reward next is 0.7549, 
noisyNet noise sample is [array([0.71471685], dtype=float32), 0.95194346]. 
=============================================
[2019-03-27 07:04:23,487] A3C_AGENT_WORKER-Thread-11 INFO:Local step 78500, global step 1256534: loss 10.1924
[2019-03-27 07:04:23,489] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 78500, global step 1256534: learning rate 0.0000
[2019-03-27 07:04:25,062] A3C_AGENT_WORKER-Thread-21 INFO:Local step 78500, global step 1257271: loss 17.5005
[2019-03-27 07:04:25,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 78500, global step 1257271: learning rate 0.0000
[2019-03-27 07:04:25,089] A3C_AGENT_WORKER-Thread-12 INFO:Local step 78500, global step 1257284: loss 18.7178
[2019-03-27 07:04:25,092] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 78500, global step 1257284: learning rate 0.0000
[2019-03-27 07:04:25,944] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.6176259e-34 3.7464163e-32 1.4694156e-30 8.7696499e-19], sum to 1.0000
[2019-03-27 07:04:25,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0375
[2019-03-27 07:04:25,958] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5943251072085084, 6.911199999999999, 6.9112, 168.912956510431, 517606.0639663989, 517606.0639663996, 165218.6687676492], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7455600.0000, 
sim time next is 7456200.0000, 
raw observation next is [21.51666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5962781562913118, 6.911199999999999, 6.9112, 168.912956510431, 519165.1105835736, 519165.1105835743, 165515.8878949178], 
processed observation next is [0.0, 0.30434782608695654, 0.21879936808846778, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5076562881601363, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14421253071765933, 0.14421253071765952, 0.24703863864913106], 
reward next is 0.7530, 
noisyNet noise sample is [array([1.5112212], dtype=float32), -1.1559186]. 
=============================================
[2019-03-27 07:04:26,327] A3C_AGENT_WORKER-Thread-14 INFO:Local step 78500, global step 1257859: loss 9.9104
[2019-03-27 07:04:26,328] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 78500, global step 1257860: learning rate 0.0000
[2019-03-27 07:04:27,291] A3C_AGENT_WORKER-Thread-19 INFO:Local step 78500, global step 1258306: loss 18.6298
[2019-03-27 07:04:27,294] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 78500, global step 1258307: learning rate 0.0000
[2019-03-27 07:04:27,369] A3C_AGENT_WORKER-Thread-2 INFO:Local step 78500, global step 1258340: loss 18.3981
[2019-03-27 07:04:27,371] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 78500, global step 1258340: learning rate 0.0000
[2019-03-27 07:04:28,030] A3C_AGENT_WORKER-Thread-15 INFO:Local step 78500, global step 1258646: loss 13.9331
[2019-03-27 07:04:28,034] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 78500, global step 1258646: learning rate 0.0000
[2019-03-27 07:04:28,096] A3C_AGENT_WORKER-Thread-3 INFO:Local step 78500, global step 1258676: loss 18.4421
[2019-03-27 07:04:28,097] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 78500, global step 1258677: learning rate 0.0000
[2019-03-27 07:04:28,179] A3C_AGENT_WORKER-Thread-17 INFO:Local step 78500, global step 1258713: loss 18.4462
[2019-03-27 07:04:28,183] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 78500, global step 1258713: learning rate 0.0000
[2019-03-27 07:04:28,261] A3C_AGENT_WORKER-Thread-22 INFO:Local step 79000, global step 1258751: loss -64.4996
[2019-03-27 07:04:28,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 79000, global step 1258751: learning rate 0.0000
[2019-03-27 07:04:28,284] A3C_AGENT_WORKER-Thread-16 INFO:Local step 78500, global step 1258761: loss 18.3267
[2019-03-27 07:04:28,286] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 78500, global step 1258761: learning rate 0.0000
[2019-03-27 07:04:28,545] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.5316146e-30 3.1010233e-24 3.0269412e-28 1.9627217e-14], sum to 1.0000
[2019-03-27 07:04:28,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-27 07:04:28,558] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.85, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7435907460798225, 6.9112, 6.9112, 168.912956510431, 639351.2937903373, 639351.2937903373, 190801.4550584932], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7360200.0000, 
sim time next is 7360800.0000, 
raw observation next is [23.76666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7311195146690356, 6.911200000000001, 6.9112, 168.912956510431, 628245.6697787711, 628245.6697787705, 188440.2687805354], 
processed observation next is [1.0, 0.17391304347826086, 0.32543443917851517, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6720969691085799, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17451268604965864, 0.17451268604965847, 0.2812541325082618], 
reward next is 0.7187, 
noisyNet noise sample is [array([-0.94250035], dtype=float32), -1.0335191]. 
=============================================
[2019-03-27 07:04:28,640] A3C_AGENT_WORKER-Thread-18 INFO:Local step 78500, global step 1258925: loss 13.8607
[2019-03-27 07:04:28,642] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 78500, global step 1258925: learning rate 0.0000
[2019-03-27 07:04:28,812] A3C_AGENT_WORKER-Thread-10 INFO:Local step 78500, global step 1259007: loss 18.1518
[2019-03-27 07:04:28,815] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 78500, global step 1259007: learning rate 0.0000
[2019-03-27 07:04:29,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999833e-01 1.0081508e-19 9.8197579e-13 4.2354761e-21 1.6539151e-06], sum to 1.0000
[2019-03-27 07:04:29,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8653
[2019-03-27 07:04:29,267] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1052771.984370154 W.
[2019-03-27 07:04:29,271] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [21.16666666666667, 92.83333333333333, 1.0, 1.0, 0.6666456678512209, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9126989728597, 1052771.984370154, 1052771.984370154, 228197.6527097641], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7387800.0000, 
sim time next is 7388400.0000, 
raw observation next is [21.13333333333333, 92.66666666666667, 1.0, 2.0, 0.2315834652090542, 1.0, 1.0, 0.2315834652090542, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 728509.159805781, 728509.159805781, 249202.7240663982], 
processed observation next is [1.0, 0.5217391304347826, 0.20063191153238533, 0.9266666666666667, 1.0, 1.0, 0.07419694603500505, 1.0, 0.5, 0.07419694603500505, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.20236365550160582, 0.20236365550160582, 0.37194436427820626], 
reward next is 0.6281, 
noisyNet noise sample is [array([-0.1924459], dtype=float32), 0.09426221]. 
=============================================
[2019-03-27 07:04:29,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9998724e-01 5.3930191e-18 4.6628902e-11 1.3894288e-18 1.2765323e-05], sum to 1.0000
[2019-03-27 07:04:29,281] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6627
[2019-03-27 07:04:29,285] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 92.66666666666667, 1.0, 2.0, 0.2317843910193623, 1.0, 1.0, 0.2317843910193623, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 728509.1598057816, 728509.159805781, 249173.5805826138], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7388400.0000, 
sim time next is 7389000.0000, 
raw observation next is [21.1, 92.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.723483613467066, 6.9112, 6.9112, 168.9129565104162, 632521.9916734892, 632521.9916734892, 186863.0341885448], 
processed observation next is [1.0, 0.5217391304347826, 0.1990521327014219, 0.925, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.6627848944720316, 0.0, 0.0, 0.82943994515223, 0.1757005532426359, 0.1757005532426359, 0.27890005102767884], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.5380183], dtype=float32), 2.139535]. 
=============================================
[2019-03-27 07:04:29,309] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[50.114006]
 [52.88263 ]
 [54.14287 ]
 [49.49665 ]
 [45.306786]], R is [[52.71419525]
 [52.81515121]
 [52.92269135]
 [52.39346313]
 [52.51267242]].
[2019-03-27 07:04:32,538] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7030926e-34 1.8579529e-32 2.2967951e-33 1.8932179e-17], sum to 1.0000
[2019-03-27 07:04:32,545] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1673
[2019-03-27 07:04:32,547] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.56666666666667, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7029452989413976, 6.911200000000001, 6.9112, 168.912956510431, 599475.3961793832, 599475.3961793826, 183251.236763565], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7518000.0000, 
sim time next is 7518600.0000, 
raw observation next is [23.55, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7029683879101862, 6.9112, 6.9112, 168.912956510431, 599604.469408341, 599604.469408341, 183255.9857794929], 
processed observation next is [0.0, 0.0, 0.3151658767772513, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6377663267197393, 0.0, 0.0, 0.8294399451523027, 0.1665567970578725, 0.1665567970578725, 0.2735163966858103], 
reward next is 0.7265, 
noisyNet noise sample is [array([-0.10956783], dtype=float32), 2.1850271]. 
=============================================
[2019-03-27 07:04:33,093] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:33,095] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:33,189] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run7
[2019-03-27 07:04:33,851] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.3193621e-34 8.8282306e-32 6.6630335e-32 8.3246901e-20], sum to 1.0000
[2019-03-27 07:04:33,860] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4050
[2019-03-27 07:04:33,864] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.55, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5986086204201999, 6.911199999999999, 6.9112, 168.912956510431, 520993.1127877971, 520993.1127877978, 165872.4176847893], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7457400.0000, 
sim time next is 7458000.0000, 
raw observation next is [21.56666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5989200513179228, 6.911200000000001, 6.9112, 168.912956510431, 521171.5912018389, 521171.5912018382, 165921.3334307118], 
processed observation next is [0.0, 0.30434782608695654, 0.22116903633491333, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5108781113633205, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14476988644495525, 0.14476988644495506, 0.24764378123986835], 
reward next is 0.7524, 
noisyNet noise sample is [array([0.10810039], dtype=float32), -0.5626259]. 
=============================================
[2019-03-27 07:04:33,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.80462]
 [77.78661]
 [77.75879]
 [77.69105]
 [77.61707]], R is [[77.78993988]
 [77.76446533]
 [77.73943329]
 [77.71499634]
 [77.69124603]].
[2019-03-27 07:04:36,821] A3C_AGENT_WORKER-Thread-9 INFO:Local step 79000, global step 1262868: loss 5.1445
[2019-03-27 07:04:36,826] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 79000, global step 1262871: learning rate 0.0000
[2019-03-27 07:04:36,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.5633330e-35 3.5553146e-31 2.5984038e-33 1.6230029e-18], sum to 1.0000
[2019-03-27 07:04:36,890] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5778
[2019-03-27 07:04:36,897] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6975088044661185, 6.911199999999999, 6.9112, 168.912956510431, 595894.2537914377, 595894.2537914383, 182280.9898537283], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7507200.0000, 
sim time next is 7507800.0000, 
raw observation next is [24.05, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6968660318956762, 6.911200000000001, 6.9112, 168.912956510431, 595228.1077983001, 595228.1077982995, 182165.7798204324], 
processed observation next is [0.0, 0.9130434782608695, 0.3388625592417062, 0.885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6303244291410685, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16534114105508335, 0.1653411410550832, 0.27188922361258566], 
reward next is 0.7281, 
noisyNet noise sample is [array([-0.81895614], dtype=float32), 0.52863395]. 
=============================================
[2019-03-27 07:04:38,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:38,392] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:38,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run7
[2019-03-27 07:04:39,355] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.7370053e-29 9.4436038e-24 9.3889813e-29 6.1213925e-13], sum to 1.0000
[2019-03-27 07:04:39,362] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5008
[2019-03-27 07:04:39,368] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.28333333333333, 94.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7357648340215954, 6.9112, 6.9112, 168.912956510431, 628160.9977933567, 628160.9977933567, 189311.243996649], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7621800.0000, 
sim time next is 7622400.0000, 
raw observation next is [23.36666666666667, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290706565056504, 6.9112, 6.9112, 168.912956510431, 622088.4001608702, 622088.4001608702, 188050.5196059103], 
processed observation next is [1.0, 0.21739130434782608, 0.30647709320695127, 0.9466666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6695983615922566, 0.0, 0.0, 0.8294399451523027, 0.17280233337801948, 0.17280233337801948, 0.2806724173222542], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.7416607], dtype=float32), -0.49753886]. 
=============================================
[2019-03-27 07:04:39,587] A3C_AGENT_WORKER-Thread-11 INFO:Local step 79000, global step 1264283: loss -3.4919
[2019-03-27 07:04:39,588] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 79000, global step 1264283: learning rate 0.0000
[2019-03-27 07:04:40,648] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.6495308e-28 3.3969474e-23 3.5497928e-27 4.4479897e-12], sum to 1.0000
[2019-03-27 07:04:40,656] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1259
[2019-03-27 07:04:40,661] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8570057273231539, 6.911199999999999, 6.9112, 168.912956510431, 738230.8209667326, 738230.8209667332, 214209.2884786988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 115200.0000, 
sim time next is 115800.0000, 
raw observation next is [22.98333333333333, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8427333297539881, 6.911199999999999, 6.9112, 168.912956510431, 725837.356430714, 725837.3564307146, 211072.1248970553], 
processed observation next is [1.0, 0.34782608695652173, 0.2883096366508688, 0.9116666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.808211377748766, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20162148789742057, 0.2016214878974207, 0.3150330222344109], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.91117775], dtype=float32), -0.9259584]. 
=============================================
[2019-03-27 07:04:41,055] A3C_AGENT_WORKER-Thread-21 INFO:Local step 79000, global step 1264968: loss -20.9820
[2019-03-27 07:04:41,060] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 79000, global step 1264969: learning rate 0.0000
[2019-03-27 07:04:41,362] A3C_AGENT_WORKER-Thread-12 INFO:Local step 79000, global step 1265110: loss -133.3286
[2019-03-27 07:04:41,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 79000, global step 1265110: learning rate 0.0000
[2019-03-27 07:04:41,489] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.3894690e-01 6.8672220e-18 2.9436665e-08 4.7713193e-20 6.1053038e-02], sum to 1.0000
[2019-03-27 07:04:41,500] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2957
[2019-03-27 07:04:41,505] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1830564.117538002 W.
[2019-03-27 07:04:41,509] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.96666666666667, 73.0, 1.0, 2.0, 0.6681527231292055, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.97996593062202, 6.9112, 168.9125469076204, 1830564.117538002, 1781779.317914281, 378822.2403400354], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7663200.0000, 
sim time next is 7663800.0000, 
raw observation next is [28.83333333333333, 74.0, 1.0, 2.0, 0.4307679925623263, 1.0, 1.0, 0.4307679925623263, 1.0, 2.0, 0.7367521610734873, 6.911199999999999, 6.9112, 170.5573041426782, 1806721.201012453, 1806721.201012454, 368830.4451655388], 
processed observation next is [1.0, 0.6956521739130435, 0.5655608214849919, 0.74, 1.0, 1.0, 0.3141783042919594, 1.0, 0.5, 0.3141783042919594, 1.0, 1.0, 0.6789660500896186, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.501867000281237, 0.5018670002812372, 0.5504932017396101], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.9788428], dtype=float32), -0.011631041]. 
=============================================
[2019-03-27 07:04:42,571] A3C_AGENT_WORKER-Thread-14 INFO:Local step 79000, global step 1265671: loss -78.3904
[2019-03-27 07:04:42,575] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 79000, global step 1265671: learning rate 0.0000
[2019-03-27 07:04:43,455] A3C_AGENT_WORKER-Thread-19 INFO:Local step 79000, global step 1266080: loss 2.4631
[2019-03-27 07:04:43,458] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 79000, global step 1266080: learning rate 0.0000
[2019-03-27 07:04:43,578] A3C_AGENT_WORKER-Thread-2 INFO:Local step 79000, global step 1266139: loss -76.4028
[2019-03-27 07:04:43,580] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 79000, global step 1266140: learning rate 0.0000
[2019-03-27 07:04:44,229] A3C_AGENT_WORKER-Thread-3 INFO:Local step 79000, global step 1266441: loss -18.2199
[2019-03-27 07:04:44,233] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 79000, global step 1266441: learning rate 0.0000
[2019-03-27 07:04:44,243] A3C_AGENT_WORKER-Thread-17 INFO:Local step 79000, global step 1266448: loss -8.6288
[2019-03-27 07:04:44,247] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 79000, global step 1266449: learning rate 0.0000
[2019-03-27 07:04:44,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 79000, global step 1266495: loss -50.6588
[2019-03-27 07:04:44,354] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 79000, global step 1266496: learning rate 0.0000
[2019-03-27 07:04:44,559] A3C_AGENT_WORKER-Thread-16 INFO:Local step 79000, global step 1266590: loss -83.8262
[2019-03-27 07:04:44,562] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 79000, global step 1266591: learning rate 0.0000
[2019-03-27 07:04:44,803] A3C_AGENT_WORKER-Thread-18 INFO:Local step 79000, global step 1266708: loss 18.6285
[2019-03-27 07:04:44,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 79000, global step 1266708: learning rate 0.0000
[2019-03-27 07:04:45,177] A3C_AGENT_WORKER-Thread-10 INFO:Local step 79000, global step 1266883: loss 1.3002
[2019-03-27 07:04:45,179] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 79000, global step 1266883: learning rate 0.0000
[2019-03-27 07:04:45,901] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:45,902] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:45,964] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run7
[2019-03-27 07:04:46,169] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.9953378e-27 1.2515182e-23 4.6201341e-27 1.7741451e-11], sum to 1.0000
[2019-03-27 07:04:46,176] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9864
[2019-03-27 07:04:46,182] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8276411818716725, 6.911199999999999, 6.9112, 168.912956510431, 696387.5950469036, 696387.5950469042, 207687.8770480514], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7705800.0000, 
sim time next is 7706400.0000, 
raw observation next is [24.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8132259752150979, 6.911200000000001, 6.9112, 168.912956510431, 684259.3430898135, 684259.3430898128, 204637.2885875396], 
processed observation next is [1.0, 0.17391304347826086, 0.3601895734597157, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7722267990428023, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1900720397471704, 0.1900720397471702, 0.3054287889366263], 
reward next is 0.6946, 
noisyNet noise sample is [array([-1.0199848], dtype=float32), 1.0030735]. 
=============================================
[2019-03-27 07:04:49,267] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.1094711e-30 3.0596052e-23 5.0077239e-29 2.6288804e-12], sum to 1.0000
[2019-03-27 07:04:49,275] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1725
[2019-03-27 07:04:49,278] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.4, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8507964877398021, 6.9112, 6.9112, 168.912956510431, 706206.5040660374, 706206.5040660374, 212454.8390663379], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7779600.0000, 
sim time next is 7780200.0000, 
raw observation next is [26.4, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8468280311745828, 6.9112, 6.9112, 168.912956510431, 703384.5230968969, 703384.5230968969, 211601.2950489073], 
processed observation next is [1.0, 0.043478260869565216, 0.45023696682464454, 0.8666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8132049160665644, 0.0, 0.0, 0.8294399451523027, 0.19538458974913803, 0.19538458974913803, 0.31582282843120496], 
reward next is 0.6842, 
noisyNet noise sample is [array([0.03696772], dtype=float32), -0.70807105]. 
=============================================
[2019-03-27 07:04:51,353] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1120614e-32 5.7382805e-27 1.0704222e-32 4.2801971e-14], sum to 1.0000
[2019-03-27 07:04:51,365] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1109
[2019-03-27 07:04:51,369] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.73333333333333, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8973628919104377, 6.9112, 6.9112, 168.912956510431, 735205.1416437647, 735205.1416437647, 222595.9055205996], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7842000.0000, 
sim time next is 7842600.0000, 
raw observation next is [28.6, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977341672165186, 6.9112, 6.9112, 168.912956510431, 735200.7958745282, 735200.7958745282, 222668.5827701826], 
processed observation next is [1.0, 0.782608695652174, 0.5545023696682465, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8752855697762421, 0.0, 0.0, 0.8294399451523027, 0.20422244329848008, 0.20422244329848008, 0.33234116831370536], 
reward next is 0.6677, 
noisyNet noise sample is [array([-0.8944928], dtype=float32), -0.2577939]. 
=============================================
[2019-03-27 07:04:52,881] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.2839147e-27 1.5348853e-22 3.4635693e-27 3.5363143e-10], sum to 1.0000
[2019-03-27 07:04:52,890] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7344
[2019-03-27 07:04:52,894] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.1, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8592246294432033, 6.9112, 6.9112, 168.912956510431, 711033.5777661914, 711033.5777661914, 214241.5269920429], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7866000.0000, 
sim time next is 7866600.0000, 
raw observation next is [26.08333333333334, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8608798236163698, 6.9112, 6.9112, 168.912956510431, 712200.6193020872, 712200.6193020872, 214601.5151694891], 
processed observation next is [1.0, 0.043478260869565216, 0.43522906793049004, 0.9133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.830341248312646, 0.0, 0.0, 0.8294399451523027, 0.1978335053616909, 0.1978335053616909, 0.32030076890968523], 
reward next is 0.6797, 
noisyNet noise sample is [array([1.5452207], dtype=float32), -1.9845023]. 
=============================================
[2019-03-27 07:04:53,909] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:53,910] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:53,988] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run7
[2019-03-27 07:04:54,608] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.0143360e-33 1.6989449e-28 5.8701108e-32 1.8941030e-13], sum to 1.0000
[2019-03-27 07:04:54,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1252
[2019-03-27 07:04:54,621] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.901209985084231, 6.911199999999999, 6.9112, 168.912956510431, 737469.1801709644, 737469.180170965, 223449.0010740374], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7843800.0000, 
sim time next is 7844400.0000, 
raw observation next is [28.2, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9052950696817004, 6.911199999999999, 6.9112, 168.912956510431, 740549.837199248, 740549.8371992486, 224388.069528504], 
processed observation next is [1.0, 0.8260869565217391, 0.5355450236966824, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.884506182538659, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20570828811090222, 0.2057082881109024, 0.3349075664604538], 
reward next is 0.6651, 
noisyNet noise sample is [array([-0.17497668], dtype=float32), -0.5782903]. 
=============================================
[2019-03-27 07:04:56,897] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:56,897] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:56,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run7
[2019-03-27 07:04:57,856] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:57,856] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:57,908] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run7
[2019-03-27 07:04:58,176] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:58,177] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:58,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run7
[2019-03-27 07:04:59,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:59,092] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:59,142] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run7
[2019-03-27 07:04:59,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:59,722] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:59,757] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:04:59,758] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:04:59,763] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.8782325e-01 1.7517652e-16 6.2260708e-09 1.8211221e-18 1.2176731e-02], sum to 1.0000
[2019-03-27 07:04:59,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5034
[2019-03-27 07:04:59,764] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1207348.587504997 W.
[2019-03-27 07:04:59,769] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.11666666666667, 71.16666666666667, 1.0, 2.0, 0.3948781728510122, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6981567071384763, 6.911199999999999, 6.9112, 168.912956510431, 1207348.587504997, 1207348.587504997, 266284.9353486108], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 36600.0000, 
sim time next is 37200.0000, 
raw observation next is [25.33333333333334, 70.33333333333334, 1.0, 2.0, 0.375067883951502, 1.0, 1.0, 0.375067883951502, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1139027.373461713, 1139027.373461713, 276647.3004289018], 
processed observation next is [1.0, 0.43478260869565216, 0.3996840442338076, 0.7033333333333335, 1.0, 1.0, 0.24706973970060478, 1.0, 0.5, 0.24706973970060478, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.31639649262825364, 0.31639649262825364, 0.4129064185505997], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.68756694], dtype=float32), 1.0675745]. 
=============================================
[2019-03-27 07:04:59,769] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run7
[2019-03-27 07:04:59,833] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run7
[2019-03-27 07:05:00,086] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,087] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,115] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run7
[2019-03-27 07:05:00,115] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,116] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,166] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run7
[2019-03-27 07:05:00,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,185] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,225] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,230] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run7
[2019-03-27 07:05:00,284] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run7
[2019-03-27 07:05:00,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,329] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run7
[2019-03-27 07:05:00,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:05:00,411] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:00,423] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run7
[2019-03-27 07:05:00,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9992931e-01 6.4900668e-20 6.5234748e-13 5.7300615e-21 7.0723931e-05], sum to 1.0000
[2019-03-27 07:05:00,837] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9073
[2019-03-27 07:05:00,843] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 968977.4398124119 W.
[2019-03-27 07:05:00,849] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.9, 54.33333333333333, 1.0, 2.0, 0.2968840536105948, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5449874252139775, 6.911200000000001, 6.9112, 168.912956510431, 968977.4398124119, 968977.4398124112, 232164.4777910394], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 562200.0000, 
sim time next is 562800.0000, 
raw observation next is [24.8, 54.66666666666667, 1.0, 2.0, 0.205772209866829, 1.0, 1.0, 0.205772209866829, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 669357.3275977158, 669357.3275977158, 246647.60445224], 
processed observation next is [1.0, 0.5217391304347826, 0.3744075829383887, 0.5466666666666667, 1.0, 1.0, 0.043099048032324096, 1.0, 0.5, 0.043099048032324096, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.1859325909993655, 0.1859325909993655, 0.36813075291379105], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8851929], dtype=float32), -1.4429682]. 
=============================================
[2019-03-27 07:05:01,026] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 1.15914945e-29 9.95153887e-27 5.45785736e-29
 3.76585868e-14], sum to 1.0000
[2019-03-27 07:05:01,038] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1952
[2019-03-27 07:05:01,049] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.7, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8299338522944222, 6.9112, 6.9112, 168.912956510431, 740454.6143606111, 740454.6143606111, 207364.8967437093], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 471600.0000, 
sim time next is 472200.0000, 
raw observation next is [22.85, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8348963026621532, 6.911200000000001, 6.9112, 168.912956510431, 744831.6158958232, 744831.6158958225, 208427.172866875], 
processed observation next is [1.0, 0.4782608695652174, 0.28199052132701435, 0.6516666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7986540276367722, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2068976710821731, 0.2068976710821729, 0.31108533263712684], 
reward next is 0.6889, 
noisyNet noise sample is [array([-0.40932631], dtype=float32), 0.7050089]. 
=============================================
[2019-03-27 07:05:01,237] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 07:05:01,238] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:05:01,239] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:01,239] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:05:01,240] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:01,240] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:05:01,241] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:05:01,241] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:01,242] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:05:01,242] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:01,244] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:05:01,254] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run52
[2019-03-27 07:05:01,269] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run52
[2019-03-27 07:05:01,286] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run52
[2019-03-27 07:05:01,304] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run52
[2019-03-27 07:05:01,324] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run52
[2019-03-27 07:05:40,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02631544], dtype=float32), 0.06763723]
[2019-03-27 07:05:40,494] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.3, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8466493280544538, 6.9112, 6.9112, 168.912956510431, 706712.236616832, 706712.236616832, 211663.0197295071]
[2019-03-27 07:05:40,494] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:05:40,498] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.2130907e-33 4.5846255e-31 1.0869104e-31 3.6729453e-17], sampled 0.7859338926609145
[2019-03-27 07:06:23,990] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02631544], dtype=float32), 0.06763723]
[2019-03-27 07:06:23,992] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.8, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.977240500543042, 6.9112, 168.9123877878441, 876460.0502971158, 829608.8040199114, 254859.0329621686]
[2019-03-27 07:06:23,994] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:06:23,999] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.8897489e-34 2.6994102e-32 3.1997891e-32 1.0339645e-17], sampled 0.036189127661496956
[2019-03-27 07:06:24,001] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 876460.0502971158 W.
[2019-03-27 07:06:31,488] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02631544], dtype=float32), 0.06763723]
[2019-03-27 07:06:31,491] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.26499184, 69.63479374, 1.0, 2.0, 0.7935519487381477, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565104284, 1109079.731845408, 1109079.731845408, 242332.2660600171]
[2019-03-27 07:06:31,492] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:06:31,494] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.6842598e-26 1.3546554e-22 7.7476396e-26 1.8678828e-11], sampled 0.2543139548493959
[2019-03-27 07:06:31,496] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1109079.731845408 W.
[2019-03-27 07:06:39,379] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02631544], dtype=float32), 0.06763723]
[2019-03-27 07:06:39,381] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.33333333333333, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9252162526739839, 6.9112, 6.9112, 168.912956510431, 759250.7966506116, 759250.7966506116, 229191.650332896]
[2019-03-27 07:06:39,382] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:06:39,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.1347553e-34 1.1077935e-32 4.4401779e-33 1.1243634e-17], sampled 0.12624295708834932
[2019-03-27 07:06:50,308] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02631544], dtype=float32), 0.06763723]
[2019-03-27 07:06:50,309] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.8, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6984081883707249, 6.911200000000001, 6.9112, 168.912956510431, 596156.6687155137, 596156.6687155131, 182439.6650584436]
[2019-03-27 07:06:50,313] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:06:50,314] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.9723303e-35 7.6144432e-33 1.1960793e-33 2.4855413e-18], sampled 0.2855152577893679
[2019-03-27 07:06:56,670] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7270.7959 3318829147.7948 2094.0000
[2019-03-27 07:06:56,900] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.2653 2989263040.8092 1525.0000
[2019-03-27 07:06:56,970] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8056.2395 2938702051.3692 1332.0000
[2019-03-27 07:06:56,988] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7337.1074 3107683789.0462 1970.0000
[2019-03-27 07:06:57,025] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7021.1781 3185267802.0206 2367.0000
[2019-03-27 07:06:58,042] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1275000, evaluation results [1275000.0, 7270.795927510698, 3318829147.794829, 2094.0, 7337.107402849354, 3107683789.046218, 1970.0, 8056.2394819863885, 2938702051.369192, 1332.0, 7021.178120111217, 3185267802.0205812, 2367.0, 7915.265272041498, 2989263040.8092175, 1525.0]
[2019-03-27 07:06:58,075] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [0.14440605 0.17625152 0.24118614 0.12000814 0.3181482 ], sum to 1.0000
[2019-03-27 07:06:58,079] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3892
[2019-03-27 07:06:58,086] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.95, 88.16666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.2014978073796613, 6.9112, 6.9112, 170.5573041426782, 525509.9952246582, 525509.9952246582, 233898.4183255517], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 600.0000, 
sim time next is 1200.0000, 
raw observation next is [21.6, 87.33333333333334, 1.0, 2.0, 0.17, 0.0, 1.0, 0.0, 1.0, 2.0, 0.2907837988190422, 6.911199999999999, 6.9112, 168.912956510431, 509014.9601516128, 509014.9601516134, 192069.8927645991], 
processed observation next is [1.0, 0.0, 0.22274881516587688, 0.8733333333333334, 1.0, 1.0, 0.0, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.1351021936817588, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14139304448655912, 0.1413930444865593, 0.2866714817382076], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2302842], dtype=float32), -0.48979536]. 
=============================================
[2019-03-27 07:06:59,168] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.1362601e-31 1.9986284e-26 4.3761345e-30 6.7776053e-15], sum to 1.0000
[2019-03-27 07:06:59,180] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1624
[2019-03-27 07:06:59,191] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.0, 82.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4184209553018997, 6.911199999999999, 6.9112, 168.912956510431, 376717.4235899877, 376717.4235899884, 142331.9455336961], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 599400.0000, 
sim time next is 600000.0000, 
raw observation next is [18.86666666666667, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4140527249716222, 6.9112, 6.9112, 168.912956510431, 372957.7030028827, 372957.7030028827, 141874.910118256], 
processed observation next is [1.0, 0.9565217391304348, 0.09320695102685649, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2854301524044173, 0.0, 0.0, 0.8294399451523027, 0.1035993619452452, 0.1035993619452452, 0.21175359719142686], 
reward next is 0.7882, 
noisyNet noise sample is [array([0.47506714], dtype=float32), -0.59156364]. 
=============================================
[2019-03-27 07:06:59,210] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[76.995094]
 [76.957436]
 [76.91746 ]
 [76.769035]
 [76.5377  ]], R is [[77.05013275]
 [77.06719971]
 [77.0835495 ]
 [77.09953308]
 [77.11528778]].
[2019-03-27 07:07:03,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.0397127e-30 1.9579623e-25 1.9342175e-29 1.7704881e-14], sum to 1.0000
[2019-03-27 07:07:03,163] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7559
[2019-03-27 07:07:03,168] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6203307187729775, 6.911199999999999, 6.9112, 168.912956510431, 539304.4242716545, 539304.4242716552, 169242.7328113576], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 93600.0000, 
sim time next is 94200.0000, 
raw observation next is [22.41666666666667, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.946227126784769, 6.9112, 6.9112, 168.912956510431, 822520.922189616, 822520.922189616, 234973.2250580736], 
processed observation next is [1.0, 0.08695652173913043, 0.26145339652448685, 0.8916666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9344233253472791, 0.0, 0.0, 0.8294399451523027, 0.22847803394156, 0.22847803394156, 0.3507063060568263], 
reward next is 0.6493, 
noisyNet noise sample is [array([0.0376649], dtype=float32), 0.63260126]. 
=============================================
[2019-03-27 07:07:03,212] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 7.35349868e-34 2.15702536e-30 1.11182385e-32
 3.75085332e-15], sum to 1.0000
[2019-03-27 07:07:03,220] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7653
[2019-03-27 07:07:03,228] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.26666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6117305667036388, 6.911200000000001, 6.9112, 168.912956510431, 532557.1297186621, 532557.1297186614, 167884.2656339991], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 85200.0000, 
sim time next is 85800.0000, 
raw observation next is [22.28333333333333, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6132485383035206, 6.911199999999999, 6.9112, 168.912956510431, 533788.4978333927, 533788.4978333933, 168121.946825759], 
processed observation next is [1.0, 1.0, 0.25513428120063186, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5283518759799031, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14827458273149796, 0.14827458273149813, 0.25092827884441643], 
reward next is 0.7491, 
noisyNet noise sample is [array([0.31487063], dtype=float32), -0.31106475]. 
=============================================
[2019-03-27 07:07:13,260] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.3483627e-33 3.0135405e-29 1.1194941e-30 7.2189865e-16], sum to 1.0000
[2019-03-27 07:07:13,268] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.9029
[2019-03-27 07:07:13,277] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.520654581542046, 6.9112, 6.9112, 168.912956510431, 459369.1685770766, 459369.1685770766, 154695.7706132212], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 261600.0000, 
sim time next is 262200.0000, 
raw observation next is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5198699422920341, 6.911200000000001, 6.9112, 168.912956510431, 458676.4110728984, 458676.4110728977, 154593.6538145508], 
processed observation next is [0.0, 0.0, 0.1706161137440759, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41447553938052933, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12741011418691622, 0.12741011418691603, 0.23073679673813555], 
reward next is 0.7693, 
noisyNet noise sample is [array([-0.20942251], dtype=float32), -1.3473017]. 
=============================================
[2019-03-27 07:07:14,933] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.5033745e-32 5.8414546e-31 9.5150644e-30 8.3656696e-18], sum to 1.0000
[2019-03-27 07:07:14,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8124
[2019-03-27 07:07:14,948] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5147067007300544, 6.9112, 6.9112, 168.912956510431, 454294.7908719257, 454294.7908719257, 153919.0580769993], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 284400.0000, 
sim time next is 285000.0000, 
raw observation next is [21.15, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5171585538922957, 6.9112, 6.9112, 168.912956510431, 456185.0715017262, 456185.0715017262, 154245.7929610665], 
processed observation next is [0.0, 0.30434782608695654, 0.2014218009478673, 0.8733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4111689681613362, 0.0, 0.0, 0.8294399451523027, 0.12671807541714616, 0.12671807541714616, 0.23021760143442763], 
reward next is 0.7698, 
noisyNet noise sample is [array([-0.98007053], dtype=float32), 0.41300434]. 
=============================================
[2019-03-27 07:07:14,966] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.526955]
 [77.499374]
 [77.54223 ]
 [77.59081 ]
 [77.63483 ]], R is [[77.54298401]
 [77.53782654]
 [77.53317261]
 [77.52892303]
 [77.52500916]].
[2019-03-27 07:07:23,770] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.00000000e+00 1.47578595e-30 1.67975000e-25 1.35091964e-29
 5.26325640e-14], sum to 1.0000
[2019-03-27 07:07:23,778] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3257
[2019-03-27 07:07:23,783] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4391999348263951, 6.911200000000001, 6.9112, 168.912956510431, 393091.6959793719, 393091.6959793713, 144686.4652641321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 438000.0000, 
sim time next is 438600.0000, 
raw observation next is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380819683718032, 6.9112, 6.9112, 168.912956510431, 392091.3341572003, 392091.3341572003, 144566.3085357126], 
processed observation next is [1.0, 0.043478260869565216, 0.127962085308057, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.31473410777049166, 0.0, 0.0, 0.8294399451523027, 0.10891425948811119, 0.10891425948811119, 0.21577060975479492], 
reward next is 0.7842, 
noisyNet noise sample is [array([1.4944375], dtype=float32), -0.08312217]. 
=============================================
[2019-03-27 07:07:25,849] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.2517285e-30 1.0740132e-25 1.0843320e-28 3.2718115e-13], sum to 1.0000
[2019-03-27 07:07:25,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2130
[2019-03-27 07:07:25,863] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.85, 65.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8348963026621532, 6.911200000000001, 6.9112, 168.912956510431, 744831.6158958232, 744831.6158958225, 208427.172866875], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 472200.0000, 
sim time next is 472800.0000, 
raw observation next is [23.0, 64.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8251017037383752, 6.9112, 6.9112, 168.912956510431, 736011.6630349633, 736011.6630349633, 206350.9471325935], 
processed observation next is [1.0, 0.4782608695652174, 0.28909952606635075, 0.6433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7867093948028966, 0.0, 0.0, 0.8294399451523027, 0.2044476841763787, 0.2044476841763787, 0.3079864882576022], 
reward next is 0.6920, 
noisyNet noise sample is [array([-1.0474327], dtype=float32), 0.5921142]. 
=============================================
[2019-03-27 07:07:33,851] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.4310580e-29 6.3452410e-24 9.1309610e-28 3.6497118e-13], sum to 1.0000
[2019-03-27 07:07:33,858] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2081
[2019-03-27 07:07:33,867] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [16.98333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3796320644008293, 6.911199999999999, 6.9112, 168.912956510431, 343855.8416639633, 343855.841663964, 138378.3707377507], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 619800.0000, 
sim time next is 620400.0000, 
raw observation next is [16.96666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3705435247216051, 6.9112, 6.9112, 168.912956510431, 335655.8152497928, 335655.8152497928, 137560.5876900406], 
processed observation next is [1.0, 0.17391304347826086, 0.003159557661927487, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.23237015209951845, 0.0, 0.0, 0.8294399451523027, 0.09323772645827579, 0.09323772645827579, 0.2053143099851352], 
reward next is 0.7947, 
noisyNet noise sample is [array([0.66195184], dtype=float32), -2.362487]. 
=============================================
[2019-03-27 07:07:38,190] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.0042203e-30 5.4674987e-24 4.5154266e-30 8.5814704e-14], sum to 1.0000
[2019-03-27 07:07:38,197] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8828
[2019-03-27 07:07:38,203] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.96666666666667, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4116190305607031, 6.9112, 6.9112, 168.912956510431, 370562.3451075865, 370562.3451075865, 141649.7089813518], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 696000.0000, 
sim time next is 696600.0000, 
raw observation next is [17.9, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4108695388688975, 6.9112, 6.9112, 168.912956510431, 369961.1697761447, 369961.1697761447, 141568.3752275801], 
processed observation next is [1.0, 0.043478260869565216, 0.04739336492890995, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2815482181328018, 0.0, 0.0, 0.8294399451523027, 0.10276699160448464, 0.10276699160448464, 0.21129608242922404], 
reward next is 0.7887, 
noisyNet noise sample is [array([0.96388584], dtype=float32), -2.0263193]. 
=============================================
[2019-03-27 07:07:38,850] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 6.3830180e-31 2.4489506e-24 8.2034095e-29 5.6416928e-12], sum to 1.0000
[2019-03-27 07:07:38,857] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6012
[2019-03-27 07:07:38,860] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7850332870511377, 6.911199999999999, 6.9112, 168.912956510431, 660665.1396174054, 660665.139617406, 198835.6885811443], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1287600.0000, 
sim time next is 1288200.0000, 
raw observation next is [24.65, 92.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.784503912647832, 6.911200000000001, 6.9112, 168.912956510431, 660271.5983369745, 660271.5983369738, 198729.732326855], 
processed observation next is [1.0, 0.9130434782608695, 0.3672985781990521, 0.9266666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7371998934729658, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18340877731582625, 0.18340877731582605, 0.29661154078635077], 
reward next is 0.7034, 
noisyNet noise sample is [array([-1.733116], dtype=float32), -1.4168236]. 
=============================================
[2019-03-27 07:07:42,245] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.9372550e-32 6.9691960e-26 2.6824435e-31 5.8194857e-14], sum to 1.0000
[2019-03-27 07:07:42,248] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3384
[2019-03-27 07:07:42,253] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.55, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4681550404001292, 6.9112, 6.9112, 168.912956510431, 417835.6658879847, 417835.6658879847, 147992.3651328], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 775800.0000, 
sim time next is 776400.0000, 
raw observation next is [19.53333333333333, 88.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4672726099091576, 6.9112, 6.9112, 168.912956510431, 417037.6318998868, 417037.6318998868, 147891.154837553], 
processed observation next is [1.0, 1.0, 0.12480252764612951, 0.8866666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.35033245110872874, 0.0, 0.0, 0.8294399451523027, 0.11584378663885746, 0.11584378663885746, 0.2207330669217209], 
reward next is 0.7793, 
noisyNet noise sample is [array([1.3956394], dtype=float32), 1.4268335]. 
=============================================
[2019-03-27 07:07:48,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 9.6731251e-31 2.8215946e-26 2.4267000e-29 1.2967777e-14], sum to 1.0000
[2019-03-27 07:07:48,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6482
[2019-03-27 07:07:48,184] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.96666666666667, 88.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237683758929932, 6.9112, 6.9112, 168.912956510431, 461737.2882740874, 461737.2882740874, 155116.9212375647], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 876000.0000, 
sim time next is 876600.0000, 
raw observation next is [20.95, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5230781639596582, 6.911200000000001, 6.9112, 168.912956510431, 461280.7366350644, 461280.7366350638, 155020.8380822053], 
processed observation next is [0.0, 0.13043478260869565, 0.19194312796208532, 0.885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41838800482885147, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12813353795418456, 0.1281335379541844, 0.23137438519732134], 
reward next is 0.7686, 
noisyNet noise sample is [array([0.70983297], dtype=float32), 0.28702563]. 
=============================================
[2019-03-27 07:07:49,339] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.9197239e-28 2.2258116e-22 4.1878966e-28 5.0640147e-12], sum to 1.0000
[2019-03-27 07:07:49,350] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8920
[2019-03-27 07:07:49,354] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.6, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6274323759344533, 6.9112, 6.9112, 168.912956510431, 545748.1667554025, 545748.1667554025, 170364.4469016228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1227600.0000, 
sim time next is 1228200.0000, 
raw observation next is [21.75, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6646372677376837, 6.9112, 6.9112, 168.912956510431, 577912.448543163, 577912.448543163, 176490.9918802745], 
processed observation next is [1.0, 0.21739130434782608, 0.2298578199052133, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5910210582166874, 0.0, 0.0, 0.8294399451523027, 0.16053123570643418, 0.16053123570643418, 0.26341939086608135], 
reward next is 0.7366, 
noisyNet noise sample is [array([-0.6276305], dtype=float32), 0.26700917]. 
=============================================
[2019-03-27 07:07:50,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.7635014e-33 1.9941094e-29 3.9296739e-31 9.4952208e-17], sum to 1.0000
[2019-03-27 07:07:50,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6799
[2019-03-27 07:07:50,336] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.63333333333333, 69.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.567621152102173, 6.911200000000001, 6.9112, 168.912956510431, 496224.8312151646, 496224.8312151639, 161254.5034238958], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 918600.0000, 
sim time next is 919200.0000, 
raw observation next is [24.56666666666667, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5667167291172013, 6.9112, 6.9112, 168.912956510431, 495460.0831677268, 495460.0831677268, 161124.4169133012], 
processed observation next is [0.0, 0.6521739130434783, 0.3633491311216432, 0.6966666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4716057672160991, 0.0, 0.0, 0.8294399451523027, 0.13762780087992413, 0.13762780087992413, 0.24048420434821072], 
reward next is 0.7595, 
noisyNet noise sample is [array([-0.36450878], dtype=float32), -2.4048555]. 
=============================================
[2019-03-27 07:07:50,555] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 6.3062407e-33 8.0704111e-28 6.9468556e-31 1.5208785e-16], sum to 1.0000
[2019-03-27 07:07:50,563] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6471
[2019-03-27 07:07:50,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5657562835017578, 6.9112, 6.9112, 168.912956510431, 494670.7814844513, 494670.7814844513, 160985.9701345858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 919800.0000, 
sim time next is 920400.0000, 
raw observation next is [24.43333333333333, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5648617883315421, 6.9112, 6.9112, 168.912956510431, 493946.926019905, 493946.926019905, 160856.9775170266], 
processed observation next is [0.0, 0.6521739130434783, 0.3570300157977882, 0.7033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4693436443067586, 0.0, 0.0, 0.8294399451523027, 0.1372074794499736, 0.1372074794499736, 0.24008504107018894], 
reward next is 0.7599, 
noisyNet noise sample is [array([-1.4865937], dtype=float32), 0.3830535]. 
=============================================
[2019-03-27 07:07:51,747] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 07:07:51,749] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:07:51,750] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:07:51,751] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:07:51,751] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:07:51,751] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:07:51,752] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:07:51,753] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:07:51,753] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:07:51,756] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:07:51,754] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:07:51,784] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run53
[2019-03-27 07:07:51,808] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run53
[2019-03-27 07:07:51,840] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run53
[2019-03-27 07:07:51,842] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run53
[2019-03-27 07:07:51,842] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run53
[2019-03-27 07:08:04,239] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:08:04,240] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.6, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5415717833508467, 6.9112, 6.9112, 168.912956510431, 475818.0563652861, 475818.0563652861, 157549.6141575895]
[2019-03-27 07:08:04,240] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:08:04,243] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.0251149e-32 2.2427741e-28 1.0055313e-30 2.5895107e-16], sampled 0.876725049069602
[2019-03-27 07:08:32,681] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:08:32,683] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.76666666666667, 78.66666666666667, 1.0, 2.0, 0.9569690839903839, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1337617.763159446, 1337617.763159446, 286087.1010283321]
[2019-03-27 07:08:32,684] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:08:32,686] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [5.8510506e-01 1.1651928e-15 1.1060807e-05 2.2278326e-17 4.1488382e-01], sampled 0.6550878350887078
[2019-03-27 07:08:42,716] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:08:42,717] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.56551837666667, 70.13662332999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8634228875112553, 6.911199999999999, 6.9112, 168.912956510431, 718322.7862733281, 718322.7862733287, 215295.970568061]
[2019-03-27 07:08:42,720] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:08:42,723] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.3647226e-30 4.4355741e-25 1.1102616e-29 3.5038002e-13], sampled 0.02909275188137672
[2019-03-27 07:08:48,127] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:08:48,128] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.588067305, 84.89017226, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8819707844588788, 6.911200000000001, 6.9112, 168.912956510431, 729211.0510869863, 729211.0510869857, 219325.4165504522]
[2019-03-27 07:08:48,129] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:08:48,133] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 6.7169101e-31 2.7244344e-25 6.9787057e-30 1.2417454e-12], sampled 0.3857001638266696
[2019-03-27 07:09:20,525] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:09:20,528] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.14225327833333, 80.26198928833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9940524251180314, 6.911200000000001, 6.9112, 168.912956510431, 802942.7094183764, 802942.7094183757, 245618.77114394]
[2019-03-27 07:09:20,533] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:09:20,535] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 9.7343087e-32 4.7192086e-27 1.7699266e-30 1.4991413e-14], sampled 0.52426690709317
[2019-03-27 07:09:28,724] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:09:28,728] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.76077622333333, 55.65614342333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6374430136400089, 6.9112, 6.9112, 168.912956510431, 553096.7446057812, 553096.7446057812, 171996.5460499427]
[2019-03-27 07:09:28,729] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:09:28,730] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 6.7586283e-30 2.9125070e-25 1.1617131e-28 9.3486315e-14], sampled 0.4523977990030278
[2019-03-27 07:09:33,118] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:09:33,120] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.60388135, 87.4917459, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.92579550933758, 6.911200000000001, 6.9112, 168.912956510431, 759263.397095633, 759263.3970956323, 229310.888361659]
[2019-03-27 07:09:33,122] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:09:33,126] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.1467669e-32 3.1303158e-27 1.8285560e-31 1.2558712e-14], sampled 0.41382377090096745
[2019-03-27 07:09:42,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.069250375]
[2019-03-27 07:09:42,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.04889302333333, 98.07096348166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8915153246748418, 6.911199999999999, 6.9112, 168.912956510431, 734893.6922767345, 734893.6922767352, 221428.1414334343]
[2019-03-27 07:09:42,089] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:09:42,091] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.0693260e-29 7.3896427e-24 1.4303494e-28 1.5736494e-12], sampled 0.1649577737276856
[2019-03-27 07:09:45,337] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7056.6724 3186298964.0877 2041.0000
[2019-03-27 07:09:45,357] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7927.0464 2991402148.6559 1348.0000
[2019-03-27 07:09:45,645] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8050.5064 2942715614.2666 1156.0000
[2019-03-27 07:09:45,847] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7270.9603 3319247526.4059 1907.0000
[2019-03-27 07:09:45,882] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7307.1291 3112903748.4900 1773.0000
[2019-03-27 07:09:46,898] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1300000, evaluation results [1300000.0, 7270.960290694696, 3319247526.40587, 1907.0, 7307.129079447835, 3112903748.4899573, 1773.0, 8050.506393699937, 2942715614.2666283, 1156.0, 7056.6724081210905, 3186298964.0877433, 2041.0, 7927.046424019217, 2991402148.655858, 1348.0]
[2019-03-27 07:09:52,857] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.3016523e-27 5.0507567e-21 9.9208041e-26 2.7811737e-11], sum to 1.0000
[2019-03-27 07:09:52,868] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1122
[2019-03-27 07:09:52,871] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.3, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5423924624157309, 6.911200000000001, 6.9112, 168.912956510431, 476804.7620459746, 476804.762045974, 157652.8304985561], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1053600.0000, 
sim time next is 1054200.0000, 
raw observation next is [20.15, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5343767724928763, 6.911199999999999, 6.9112, 168.912956510431, 470426.6481691363, 470426.6481691369, 156546.9295781199], 
processed observation next is [1.0, 0.17391304347826086, 0.15402843601895733, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43216679572301986, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1306740689358712, 0.13067406893587136, 0.2336521336986864], 
reward next is 0.7663, 
noisyNet noise sample is [array([-0.84908456], dtype=float32), -0.4005222]. 
=============================================
[2019-03-27 07:10:01,696] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999976e-01 5.8060335e-26 8.7667232e-15 2.8369629e-26 1.7947120e-07], sum to 1.0000
[2019-03-27 07:10:01,704] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2458
[2019-03-27 07:10:01,709] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.578040763648521, 6.9112, 6.9112, 168.912956510431, 501528.1997772818, 501528.1997772818, 162832.8886310156], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1186200.0000, 
sim time next is 1186800.0000, 
raw observation next is [27.0, 60.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5846789653098394, 6.9112, 6.9112, 168.912956510431, 507300.323228315, 507300.323228315, 163809.4745038555], 
processed observation next is [1.0, 0.7391304347826086, 0.4786729857819906, 0.6033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4935109333046822, 0.0, 0.0, 0.8294399451523027, 0.14091675645230972, 0.14091675645230972, 0.24449175299082912], 
reward next is 0.7555, 
noisyNet noise sample is [array([1.7765625], dtype=float32), 0.025504526]. 
=============================================
[2019-03-27 07:10:02,082] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 7.16568477e-29 1.04893864e-23 9.04846606e-29
 1.57038202e-11], sum to 1.0000
[2019-03-27 07:10:02,091] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4756
[2019-03-27 07:10:02,096] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6267228164303116, 6.911199999999999, 6.9112, 168.912956510431, 543514.3397522982, 543514.3397522989, 170276.1628756435], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1197600.0000, 
sim time next is 1198200.0000, 
raw observation next is [24.3, 77.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6272215414152098, 6.9112, 6.9112, 168.912956510431, 543808.0363463858, 543808.0363463858, 170357.5373575548], 
processed observation next is [1.0, 0.8695652173913043, 0.3507109004739337, 0.7716666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5453921236770851, 0.0, 0.0, 0.8294399451523027, 0.15105778787399607, 0.15105778787399607, 0.2542649811306788], 
reward next is 0.7457, 
noisyNet noise sample is [array([0.7078227], dtype=float32), 0.80104196]. 
=============================================
[2019-03-27 07:10:12,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.2090588e-31 3.0563809e-26 7.7622115e-29 2.2110321e-14], sum to 1.0000
[2019-03-27 07:10:12,017] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2917
[2019-03-27 07:10:12,024] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6137642089292448, 6.9112, 6.9112, 168.912956510431, 532615.9710408411, 532615.9710408411, 168228.4988502015], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1492800.0000, 
sim time next is 1493400.0000, 
raw observation next is [22.5, 90.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6194274502028534, 6.9112, 6.9112, 168.912956510431, 536977.74493707, 536977.74493707, 169123.187264113], 
processed observation next is [0.0, 0.2608695652173913, 0.2654028436018958, 0.9083333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5358871343937236, 0.0, 0.0, 0.8294399451523027, 0.14916048470474166, 0.14916048470474166, 0.2524226675583776], 
reward next is 0.7476, 
noisyNet noise sample is [array([0.33300215], dtype=float32), -0.34949508]. 
=============================================
[2019-03-27 07:10:20,666] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.5267157e-31 8.5888572e-25 4.3448814e-29 1.8752979e-14], sum to 1.0000
[2019-03-27 07:10:20,676] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-27 07:10:20,681] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.36666666666667, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6256428792184098, 6.9112, 6.9112, 168.912956510431, 540696.9328101261, 540696.9328101261, 170125.2671547489], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1514400.0000, 
sim time next is 1515000.0000, 
raw observation next is [29.43333333333333, 51.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6290205756411597, 6.9112, 6.9112, 168.912956510431, 543278.6023775876, 543278.6023775876, 170667.36938479], 
processed observation next is [0.0, 0.5217391304347826, 0.5939968404423379, 0.51, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5475860678550727, 0.0, 0.0, 0.8294399451523027, 0.15091072288266322, 0.15091072288266322, 0.2547274169922239], 
reward next is 0.7453, 
noisyNet noise sample is [array([-0.01426481], dtype=float32), -0.33688128]. 
=============================================
[2019-03-27 07:10:20,694] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[75.18349 ]
 [75.12416 ]
 [75.06806 ]
 [75.02296 ]
 [74.965065]], R is [[75.24871063]
 [75.24230194]
 [75.23660278]
 [75.23136902]
 [75.22651672]].
[2019-03-27 07:10:34,164] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.4404614e-01 9.5436377e-20 2.1988180e-09 1.1469601e-21 5.5953916e-02], sum to 1.0000
[2019-03-27 07:10:34,170] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1697
[2019-03-27 07:10:34,180] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1196817.414367796 W.
[2019-03-27 07:10:34,184] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.55, 84.0, 1.0, 2.0, 0.3932340573693862, 0.0, 2.0, 0.0, 1.0, 1.0, 0.6932127222707448, 6.9112, 6.9112, 168.912956510431, 1196817.414367796, 1196817.414367796, 264920.7476739492], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1769400.0000, 
sim time next is 1770000.0000, 
raw observation next is [23.46666666666667, 84.66666666666666, 1.0, 2.0, 0.7642732239377884, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1166042.850710461, 1166042.850710461, 248129.5268960573], 
processed observation next is [1.0, 0.4782608695652174, 0.31121642969984215, 0.8466666666666666, 1.0, 1.0, 0.7159918360696246, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.32390079186401693, 0.32390079186401693, 0.37034257745680194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7657567], dtype=float32), -0.7251939]. 
=============================================
[2019-03-27 07:10:34,197] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[69.41431 ]
 [69.0318  ]
 [69.330826]
 [68.330956]
 [66.90102 ]], R is [[68.0535202 ]
 [67.97758484]
 [67.92815399]
 [67.82946777]
 [67.71155548]].
[2019-03-27 07:10:41,027] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-27 07:10:41,029] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:10:41,031] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:10:41,035] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:10:41,036] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:10:41,036] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:10:41,037] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:10:41,037] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:10:41,039] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:10:41,037] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:10:41,042] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:10:41,068] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run54
[2019-03-27 07:10:41,087] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run54
[2019-03-27 07:10:41,109] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run54
[2019-03-27 07:10:41,110] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run54
[2019-03-27 07:10:41,130] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run54
[2019-03-27 07:10:46,983] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:10:46,984] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.66666666666667, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4847832093424629, 6.9112, 6.9112, 168.912956510431, 431827.0978858096, 431827.0978858096, 150002.0961251094]
[2019-03-27 07:10:46,985] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:10:46,988] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.1317882e-29 7.2219008e-25 2.1889491e-28 2.4703571e-13], sampled 0.9054367292875005
[2019-03-27 07:10:51,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:10:51,778] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [17.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3924865681486502, 6.9112, 6.9112, 168.912956510431, 354364.6273674652, 354364.6273674652, 139690.9898437769]
[2019-03-27 07:10:51,778] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:10:51,782] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 9.3539777e-30 4.6178128e-25 2.0376416e-28 1.1762143e-13], sampled 0.37093498138112224
[2019-03-27 07:10:54,593] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:10:54,595] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.0, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6252205219895932, 6.911199999999999, 6.9112, 168.912956510431, 542758.4645308068, 542758.4645308073, 170029.2803864114]
[2019-03-27 07:10:54,595] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:10:54,596] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.7573204e-30 5.6223625e-25 3.5741110e-29 7.5128863e-13], sampled 0.12528076199617832
[2019-03-27 07:11:05,195] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:11:05,197] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.17221097, 95.21329263, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8400177311525442, 6.9112, 6.9112, 168.912956510431, 700573.4558846485, 700573.4558846485, 210204.1076918368]
[2019-03-27 07:11:05,197] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:11:05,201] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.6009618e-29 1.9729594e-23 2.4625386e-28 1.4559076e-11], sampled 0.0851933775473831
[2019-03-27 07:11:05,294] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:11:05,295] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.89475564, 93.91688493000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7473186061853688, 6.9112, 6.9112, 168.912956510431, 632718.6477138575, 632718.6477138575, 191465.9103548891]
[2019-03-27 07:11:05,295] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:11:05,298] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 1.08969304e-29 9.78236905e-24 6.85462421e-29
 1.26560472e-11], sampled 0.8133962102513123
[2019-03-27 07:11:21,677] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:11:21,677] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.26269188, 78.42105275, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7468626792191747, 6.911199999999999, 6.9112, 168.912956510431, 634184.8477467399, 634184.8477467404, 191400.0704584782]
[2019-03-27 07:11:21,679] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:11:21,681] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 6.4343845e-30 2.6467857e-24 6.5100109e-29 2.1855167e-12], sampled 0.08375905054293253
[2019-03-27 07:11:45,206] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:11:45,206] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.6274471, 85.931596895, 1.0, 2.0, 0.604559989363419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 844836.7600486394, 844836.7600486394, 201596.7532477204]
[2019-03-27 07:11:45,209] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:11:45,212] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9561298e-01 2.2676778e-18 4.9279991e-10 1.8234643e-19 4.3870141e-03], sampled 0.9706703358978214
[2019-03-27 07:11:47,933] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:11:47,934] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.01768075, 94.18392105666668, 1.0, 2.0, 0.4576616333212958, 1.0, 1.0, 0.4576616333212958, 1.0, 2.0, 0.7948069060641724, 6.911199999999999, 6.9112, 184.5923449428631, 1919488.448912623, 1919488.448912624, 391224.2924180942]
[2019-03-27 07:11:47,935] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:11:47,939] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [7.5232619e-01 8.6886235e-19 2.4011149e-08 1.2566278e-20 2.4767378e-01], sampled 0.6912360299965289
[2019-03-27 07:11:47,941] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1919488.448912623 W.
[2019-03-27 07:12:10,800] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:12:10,802] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.45903035333333, 72.74633760666667, 1.0, 2.0, 0.8098854050808161, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1144944.712814818, 1144944.712814818, 248193.1588299573]
[2019-03-27 07:12:10,803] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:12:10,806] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [5.7936859e-01 7.8281693e-17 1.8942895e-07 1.1018273e-18 4.2063123e-01], sampled 0.38367368066957785
[2019-03-27 07:12:10,808] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1144944.712814818 W.
[2019-03-27 07:12:16,449] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06975092]
[2019-03-27 07:12:16,451] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.4, 76.0, 1.0, 1.0, 0.7797868279977267, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9126131023071, 1089831.52777861, 1089831.527778609, 239010.7904534165]
[2019-03-27 07:12:16,452] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:12:16,454] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999106e-01 2.5132778e-22 9.2023385e-16 1.7597925e-22 8.9921032e-06], sampled 0.8966679722152494
[2019-03-27 07:12:16,458] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1089831.52777861 W.
[2019-03-27 07:12:35,995] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7283.2566 3330090205.4528 1530.0000
[2019-03-27 07:12:36,392] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7878.4137 3005165398.4398 998.0000
[2019-03-27 07:12:36,569] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7982.4716 2963223871.6647 898.0000
[2019-03-27 07:12:36,741] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7280.4884 3131947485.2186 1392.0000
[2019-03-27 07:12:36,837] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7096.6292 3195962832.5334 1484.0000
[2019-03-27 07:12:37,853] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1325000, evaluation results [1325000.0, 7283.256619006391, 3330090205.452784, 1530.0, 7280.48837509007, 3131947485.218569, 1392.0, 7982.4715846881545, 2963223871.664705, 898.0, 7096.629175019584, 3195962832.533382, 1484.0, 7878.4136875550375, 3005165398.4397564, 998.0]
[2019-03-27 07:12:40,113] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.9224537e-27 1.5065263e-20 2.0100284e-26 6.1132721e-09], sum to 1.0000
[2019-03-27 07:12:40,124] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6187
[2019-03-27 07:12:40,127] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.8, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276318104078066, 6.911199999999999, 6.9112, 168.912956510431, 617571.7663213384, 617571.7663213391, 187756.0011334968], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1926000.0000, 
sim time next is 1926600.0000, 
raw observation next is [24.91666666666667, 86.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8212130892711488, 6.9112, 6.9112, 168.912956510431, 696694.9731691432, 696694.9731691432, 206410.219120319], 
processed observation next is [1.0, 0.30434782608695654, 0.37993680884676173, 0.8633333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7819671820379862, 0.0, 0.0, 0.8294399451523027, 0.1935263814358731, 0.1935263814358731, 0.3080749539109239], 
reward next is 0.6919, 
noisyNet noise sample is [array([-0.3201459], dtype=float32), -0.68682545]. 
=============================================
[2019-03-27 07:12:40,700] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6113305e-01 1.4572960e-17 9.8864143e-07 1.4901015e-19 8.3886600e-01], sum to 1.0000
[2019-03-27 07:12:40,710] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7199
[2019-03-27 07:12:40,717] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 87.0, 1.0, 2.0, 0.221423817224132, 1.0, 2.0, 0.221423817224132, 1.0, 2.0, 0.3729977071645121, 6.9112, 6.9112, 170.5573041426782, 928312.545731878, 928312.545731878, 275333.7708029698], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2260800.0000, 
sim time next is 2261400.0000, 
raw observation next is [25.95, 87.16666666666667, 1.0, 2.0, 0.2538093393869525, 1.0, 2.0, 0.2538093393869525, 1.0, 2.0, 0.4276166724863428, 6.9112, 6.9112, 170.5573041426782, 1064155.222499483, 1064155.222499483, 285682.6956191251], 
processed observation next is [1.0, 0.17391304347826086, 0.42890995260663506, 0.8716666666666667, 1.0, 1.0, 0.10097510769512348, 1.0, 1.0, 0.10097510769512348, 1.0, 1.0, 0.30197155181261315, 0.0, 0.0, 0.8375144448122397, 0.2955986729165231, 0.2955986729165231, 0.4263920830136195], 
reward next is 0.5736, 
noisyNet noise sample is [array([-0.0426019], dtype=float32), -0.43052667]. 
=============================================
[2019-03-27 07:12:46,155] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 9.4299007e-29 6.8663400e-24 4.4355505e-28 1.3278947e-10], sum to 1.0000
[2019-03-27 07:12:46,161] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.8455
[2019-03-27 07:12:46,165] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8408594669523655, 6.911199999999999, 6.9112, 168.912956510431, 698927.1293813366, 698927.1293813373, 210318.5926183687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2014800.0000, 
sim time next is 2015400.0000, 
raw observation next is [25.5, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8451659471139041, 6.9112, 6.9112, 168.912956510431, 701717.8754074966, 701717.8754074966, 211230.075402365], 
processed observation next is [0.0, 0.30434782608695654, 0.40758293838862564, 0.9416666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.811177984285249, 0.0, 0.0, 0.8294399451523027, 0.19492163205763793, 0.19492163205763793, 0.3152687692572612], 
reward next is 0.6847, 
noisyNet noise sample is [array([-0.53937024], dtype=float32), 0.3888781]. 
=============================================
[2019-03-27 07:12:49,764] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.7915691e-28 3.7448190e-23 4.9235460e-29 1.5727147e-10], sum to 1.0000
[2019-03-27 07:12:49,776] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4827
[2019-03-27 07:12:49,781] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.33333333333334, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7799407912317139, 6.9112, 6.9112, 168.912956510431, 655868.5273271379, 655868.5273271379, 197800.4411604291], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2079600.0000, 
sim time next is 2080200.0000, 
raw observation next is [24.31666666666667, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7800991310425283, 6.911200000000001, 6.9112, 168.912956510431, 655960.7706544079, 655960.7706544073, 197831.4237595823], 
processed observation next is [0.0, 0.043478260869565216, 0.3515007898894157, 0.9583333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7318282085884491, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18221132518178, 0.18221132518177982, 0.29527078173071986], 
reward next is 0.7047, 
noisyNet noise sample is [array([0.07984246], dtype=float32), -0.23022738]. 
=============================================
[2019-03-27 07:12:56,522] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [4.3358266e-02 7.5928847e-21 3.2886436e-09 1.2507981e-23 9.5664179e-01], sum to 1.0000
[2019-03-27 07:12:56,531] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0854
[2019-03-27 07:12:56,535] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.7, 66.33333333333334, 1.0, 2.0, 0.5626537996515648, 1.0, 2.0, 0.5626537996515648, 1.0, 2.0, 0.9771435775398696, 6.911200000000001, 6.9112, 170.5573041426782, 2360461.013351772, 2360461.013351772, 461175.9546210304], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2208000.0000, 
sim time next is 2208600.0000, 
raw observation next is [31.8, 66.0, 1.0, 2.0, 0.5989030022993579, 1.0, 2.0, 0.5989030022993579, 1.0, 2.0, 1.03, 6.922549922928749, 6.9112, 170.5573041426782, 2512687.582641244, 2504557.171162035, 487580.5580146487], 
processed observation next is [1.0, 0.5652173913043478, 0.7061611374407584, 0.66, 1.0, 1.0, 0.5167506051799492, 1.0, 1.0, 0.5167506051799492, 1.0, 1.0, 1.0365853658536586, 0.001134992292874859, 0.0, 0.8375144448122397, 0.6979687729559011, 0.6957103253227874, 0.7277321761412667], 
reward next is 0.2155, 
noisyNet noise sample is [array([-0.66638607], dtype=float32), -1.3211372]. 
=============================================
[2019-03-27 07:12:57,546] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [3.7968126e-03 1.7828493e-21 4.9093014e-09 2.1792872e-24 9.9620324e-01], sum to 1.0000
[2019-03-27 07:12:57,556] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7452
[2019-03-27 07:12:57,562] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.06666666666667, 65.33333333333334, 1.0, 2.0, 0.5412958306144545, 1.0, 2.0, 0.5412958306144545, 1.0, 2.0, 0.9400518485107014, 6.9112, 6.9112, 170.5573041426782, 2270778.056560873, 2270778.056560873, 444877.8902221763], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2211600.0000, 
sim time next is 2212200.0000, 
raw observation next is [32.05, 65.5, 1.0, 2.0, 0.5472662807054943, 1.0, 2.0, 0.5472662807054943, 1.0, 2.0, 0.9504205458608208, 6.911200000000001, 6.9112, 170.5573041426782, 2295847.564565222, 2295847.564565221, 449370.7372181379], 
processed observation next is [1.0, 0.6086956521739131, 0.7180094786729857, 0.655, 1.0, 1.0, 0.4545376875969811, 1.0, 1.0, 0.4545376875969811, 1.0, 1.0, 0.9395372510497815, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6377354346014505, 0.6377354346014502, 0.6707025928628924], 
reward next is 0.3293, 
noisyNet noise sample is [array([-0.9440452], dtype=float32), -1.3477557]. 
=============================================
[2019-03-27 07:12:57,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.7131902e-02 1.1065741e-17 1.6906046e-08 2.4951849e-19 9.7286814e-01], sum to 1.0000
[2019-03-27 07:12:57,915] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3283
[2019-03-27 07:12:57,921] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 87.33333333333334, 1.0, 2.0, 0.4568865330740766, 1.0, 2.0, 0.4568865330740766, 1.0, 2.0, 0.789192184119912, 6.9112, 6.9112, 170.5573041426782, 1916365.190245874, 1916365.190245874, 385917.0423904678], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2539200.0000, 
sim time next is 2539800.0000, 
raw observation next is [27.45, 86.5, 1.0, 2.0, 0.470498040003183, 1.0, 2.0, 0.470498040003183, 1.0, 2.0, 0.8127409180958458, 6.911199999999999, 6.9112, 170.5573041426782, 1973509.887399438, 1973509.887399438, 394609.5961555315], 
processed observation next is [1.0, 0.391304347826087, 0.5, 0.865, 1.0, 1.0, 0.3620458313291362, 1.0, 1.0, 0.3620458313291362, 1.0, 1.0, 0.7716352659705437, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5481971909442883, 0.5481971909442883, 0.5889695465007933], 
reward next is 0.4110, 
noisyNet noise sample is [array([0.8487817], dtype=float32), 1.4783398]. 
=============================================
[2019-03-27 07:12:58,623] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [7.6086439e-02 1.0873177e-20 1.3851794e-11 5.1040686e-23 9.2391348e-01], sum to 1.0000
[2019-03-27 07:12:58,632] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1067
[2019-03-27 07:12:58,638] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.68333333333333, 71.83333333333334, 1.0, 2.0, 0.4139243759210203, 1.0, 2.0, 0.4139243759210203, 1.0, 2.0, 0.7130669461851226, 6.911200000000001, 6.9112, 170.5573041426782, 1736018.708751088, 1736018.708751087, 359888.0505159324], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2551800.0000, 
sim time next is 2552400.0000, 
raw observation next is [29.8, 71.0, 1.0, 2.0, 0.3844460105054543, 1.0, 2.0, 0.3844460105054543, 1.0, 2.0, 0.6617052097318877, 6.911200000000001, 6.9112, 170.5573041426782, 1612292.02474798, 1612292.024747979, 343650.8827216471], 
processed observation next is [1.0, 0.5652173913043478, 0.6113744075829385, 0.71, 1.0, 1.0, 0.258368687355969, 1.0, 1.0, 0.258368687355969, 1.0, 1.0, 0.5874453777218143, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.44785889576332777, 0.4478588957633275, 0.5129117652561896], 
reward next is 0.4871, 
noisyNet noise sample is [array([0.2964579], dtype=float32), -0.1559233]. 
=============================================
[2019-03-27 07:13:03,735] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999988e-01 1.1715392e-28 1.4374927e-21 5.7976182e-28 9.2593972e-08], sum to 1.0000
[2019-03-27 07:13:03,742] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8956
[2019-03-27 07:13:03,748] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.78333333333333, 77.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9929806971712031, 6.9112, 6.9112, 168.912956510431, 800268.9147948896, 800268.9147948896, 245242.2870839064], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2321400.0000, 
sim time next is 2322000.0000, 
raw observation next is [29.7, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9984662442617976, 6.911200000000001, 6.9112, 168.9128665618388, 805398.4514730801, 805398.4514730795, 246689.2051456163], 
processed observation next is [1.0, 0.9130434782608695, 0.6066350710900474, 0.78, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9981295661729238, 8.881784197001253e-17, 0.0, 0.8294395034635363, 0.22372179207585557, 0.2237217920758554, 0.36819284350091985], 
reward next is 0.6318, 
noisyNet noise sample is [array([1.0908223], dtype=float32), 0.53517103]. 
=============================================
[2019-03-27 07:13:03,778] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[64.719574]
 [64.19963 ]
 [64.14896 ]
 [63.790348]
 [63.88284 ]], R is [[65.126297  ]
 [65.10900116]
 [65.09012604]
 [65.06843567]
 [65.04411316]].
[2019-03-27 07:13:03,994] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9999583e-01 1.5183022e-26 5.0771669e-19 2.6384339e-27 4.2122792e-06], sum to 1.0000
[2019-03-27 07:13:04,003] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3673
[2019-03-27 07:13:04,008] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666666, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9404658788038569, 6.911199999999999, 6.9112, 168.912956510431, 766350.0565213942, 766350.0565213948, 232618.3823423622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2506200.0000, 
sim time next is 2506800.0000, 
raw observation next is [26.63333333333333, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9392497097696552, 6.9112, 6.9112, 168.912956510431, 765500.8184588561, 765500.8184588561, 232330.5433196622], 
processed observation next is [1.0, 0.0, 0.46129541864139006, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9259142802068964, 0.0, 0.0, 0.8294399451523027, 0.21263911623857112, 0.21263911623857112, 0.3467620049547197], 
reward next is 0.6532, 
noisyNet noise sample is [array([0.5598224], dtype=float32), 0.4452561]. 
=============================================
[2019-03-27 07:13:23,682] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.3635896e-28 4.3357739e-22 9.8960317e-29 3.4235754e-09], sum to 1.0000
[2019-03-27 07:13:23,692] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2068
[2019-03-27 07:13:23,696] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8233621668606798, 6.911200000000001, 6.9112, 168.912956510431, 714057.5529147636, 714057.552914763, 206850.01861433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2859000.0000, 
sim time next is 2859600.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7065128753693019, 6.9112, 6.9112, 168.912956510431, 612691.2463478635, 612691.2463478635, 183856.618491093], 
processed observation next is [1.0, 0.08695652173913043, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6420888724015875, 0.0, 0.0, 0.8294399451523027, 0.17019201287440652, 0.17019201287440652, 0.2744128634195418], 
reward next is 0.7256, 
noisyNet noise sample is [array([1.2691835], dtype=float32), 0.9650028]. 
=============================================
[2019-03-27 07:13:24,354] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.7224396e-33 1.4742168e-29 5.0491517e-31 2.7190921e-14], sum to 1.0000
[2019-03-27 07:13:24,363] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5588
[2019-03-27 07:13:24,371] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892225252512192, 6.911199999999999, 6.9112, 168.912956510431, 590966.8437370453, 590966.8437370459, 180813.7544057624], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2674200.0000, 
sim time next is 2674800.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.689095361915469, 6.911200000000001, 6.9112, 168.912956510431, 590857.7785036261, 590857.7785036255, 180791.323971712], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6208480023359377, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1641271606954517, 0.16412716069545155, 0.2698377969727045], 
reward next is 0.7302, 
noisyNet noise sample is [array([-0.5941121], dtype=float32), -2.5007775]. 
=============================================
[2019-03-27 07:13:26,600] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [5.19980490e-01 3.49903313e-18 1.11388472e-08 1.05992274e-19
 4.80019450e-01], sum to 1.0000
[2019-03-27 07:13:26,608] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3422
[2019-03-27 07:13:26,615] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1082181.798512094 W.
[2019-03-27 07:13:26,620] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2520251915469081, 1.0, 2.0, 0.2520251915469081, 1.0, 1.0, 0.4264162525713599, 6.9112, 6.9112, 170.5573041426782, 1082181.798512094, 1082181.798512094, 287841.4593389765], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2815800.0000, 
sim time next is 2816400.0000, 
raw observation next is [25.0, 83.0, 1.0, 2.0, 0.3992244367530078, 1.0, 2.0, 0.3992244367530078, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1148060.061047301, 1148060.061047301, 275845.3400972983], 
processed observation next is [1.0, 0.6086956521739131, 0.38388625592417064, 0.83, 1.0, 1.0, 0.2761740201843467, 1.0, 1.0, 0.2761740201843467, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.31890557251313917, 0.31890557251313917, 0.41170946283178855], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3946077], dtype=float32), -0.11956868]. 
=============================================
[2019-03-27 07:13:29,766] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.3116320e-30 1.4156202e-24 2.6726410e-29 3.5569545e-13], sum to 1.0000
[2019-03-27 07:13:29,774] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4859
[2019-03-27 07:13:29,779] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5925573148340023, 6.911199999999999, 6.9112, 168.912956510431, 515956.7768636273, 515956.7768636279, 164955.0125512213], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2962800.0000, 
sim time next is 2963400.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6013050316191789, 6.9112, 6.9112, 168.912956510431, 523209.2688497411, 523209.2688497411, 166284.8994432739], 
processed observation next is [1.0, 0.30434782608695654, 0.19431279620853087, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.513786623925828, 0.0, 0.0, 0.8294399451523027, 0.14533590801381696, 0.14533590801381696, 0.24818641707951328], 
reward next is 0.7518, 
noisyNet noise sample is [array([1.4858501], dtype=float32), -0.76454973]. 
=============================================
[2019-03-27 07:13:31,150] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 5.0521186e-31 1.3048172e-24 2.2727175e-30 3.6573236e-12], sum to 1.0000
[2019-03-27 07:13:31,159] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1391
[2019-03-27 07:13:31,163] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.33333333333334, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6185755386989895, 6.911200000000001, 6.9112, 168.912956510431, 537272.8732681106, 537272.87326811, 168974.4861380657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3127200.0000, 
sim time next is 3127800.0000, 
raw observation next is [21.16666666666666, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6122535167778892, 6.9112, 6.9112, 168.912956510431, 532063.7906343807, 532063.7906343807, 167981.7637789148], 
processed observation next is [1.0, 0.17391304347826086, 0.2022116903633489, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5271384350949868, 0.0, 0.0, 0.8294399451523027, 0.14779549739843906, 0.14779549739843906, 0.2507190504162908], 
reward next is 0.7493, 
noisyNet noise sample is [array([-0.7734167], dtype=float32), -2.2938135]. 
=============================================
[2019-03-27 07:13:31,761] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0300906e-32 1.7822077e-25 1.5510112e-31 4.0790275e-12], sum to 1.0000
[2019-03-27 07:13:31,770] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5986
[2019-03-27 07:13:31,780] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6843025096615334, 6.9112, 6.9112, 168.912956510431, 586746.3865893141, 586746.3865893141, 179949.0987426843], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2843400.0000, 
sim time next is 2844000.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6850110364962593, 6.911199999999999, 6.9112, 168.912956510431, 587354.552770745, 587354.5527707456, 180073.2133740345], 
processed observation next is [1.0, 0.9565217391304348, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6158671176783649, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16315404243631806, 0.16315404243631823, 0.26876599011049923], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.380003], dtype=float32), 1.7988858]. 
=============================================
[2019-03-27 07:13:31,787] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[75.854385]
 [75.413   ]
 [75.31003 ]
 [75.15494 ]
 [75.06552 ]], R is [[75.91855621]
 [75.89079285]
 [75.8639679 ]
 [75.83595276]
 [75.80643463]].
[2019-03-27 07:13:32,080] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 07:13:32,081] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:13:32,082] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:13:32,082] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:13:32,083] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:13:32,084] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:13:32,084] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:13:32,084] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:13:32,085] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:13:32,086] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:13:32,087] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:13:32,114] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run55
[2019-03-27 07:13:32,136] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run55
[2019-03-27 07:13:32,156] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run55
[2019-03-27 07:13:32,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run55
[2019-03-27 07:13:32,204] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run55
[2019-03-27 07:14:29,707] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.07001347]
[2019-03-27 07:14:29,708] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.3, 48.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.955206015921467, 6.9112, 168.9125381476103, 860032.4026024904, 828813.0976616419, 254811.9621118396]
[2019-03-27 07:14:29,710] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:14:29,713] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999237e-01 2.5876574e-21 1.4648656e-15 1.9102912e-21 7.6311735e-06], sampled 0.04855460058492722
[2019-03-27 07:14:47,005] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.07001347]
[2019-03-27 07:14:47,007] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9473884646493791, 6.911200000000001, 6.9112, 168.912956510431, 769927.7497968861, 769927.7497968855, 234201.7782844596]
[2019-03-27 07:14:47,009] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:14:47,013] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 1.16255304e-32 4.79275467e-28 1.15028564e-31
 2.35840048e-13], sampled 0.10116262278659327
[2019-03-27 07:14:48,488] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.07001347]
[2019-03-27 07:14:48,489] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.3, 55.66666666666667, 1.0, 2.0, 0.5555234724969271, 1.0, 1.0, 0.5555234724969271, 1.0, 2.0, 0.9647605573074869, 6.9112, 6.9112, 169.0403247858759, 2330539.273577314, 2330539.273577314, 455364.1268244803]
[2019-03-27 07:14:48,489] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:14:48,492] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.2005095e-02 1.8974659e-20 2.9175867e-11 1.0721643e-22 9.3799484e-01], sampled 0.7053230555956921
[2019-03-27 07:15:05,166] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.07001347]
[2019-03-27 07:15:05,167] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.0, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9944553752562315, 6.9112, 6.9112, 168.912956510431, 803796.7421801588, 803796.7421801588, 245751.5345990218]
[2019-03-27 07:15:05,169] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:15:05,172] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.7497007e-33 4.8062848e-28 4.6051131e-32 4.4008902e-13], sampled 0.049889539479211376
[2019-03-27 07:15:27,589] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7905.4675 2990684267.7020 1275.0000
[2019-03-27 07:15:27,793] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7320.8956 3114850699.5850 1680.0000
[2019-03-27 07:15:27,882] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7285.6872 3317741979.0027 1851.0000
[2019-03-27 07:15:27,891] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7075.8458 3183444648.8301 1889.0000
[2019-03-27 07:15:27,895] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8026.0229 2944846739.1471 1141.0000
[2019-03-27 07:15:28,911] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1350000, evaluation results [1350000.0, 7285.6871524303315, 3317741979.0027, 1851.0, 7320.895563764023, 3114850699.5850086, 1680.0, 8026.022853932433, 2944846739.147059, 1141.0, 7075.845776686812, 3183444648.830115, 1889.0, 7905.467485313861, 2990684267.7020173, 1275.0]
[2019-03-27 07:15:38,827] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999952e-01 1.9228625e-24 8.7924336e-17 3.0991061e-24 4.3221110e-07], sum to 1.0000
[2019-03-27 07:15:38,828] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6109
[2019-03-27 07:15:38,829] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 977356.155620334 W.
[2019-03-27 07:15:38,840] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 88.00000000000001, 1.0, 1.0, 0.6223888243181895, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129496889416, 977356.155620334, 977356.155620334, 217712.9417343379], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2974200.0000, 
sim time next is 2974800.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.6033199046514738, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565087276, 947773.5542570536, 947773.554257053, 213667.3914044226], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.88, 1.0, 1.0, 0.5220721742788841, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451439383, 0.26327043173807047, 0.26327043173807024, 0.3189065543349591], 
reward next is 0.6811, 
noisyNet noise sample is [array([0.11546292], dtype=float32), 0.79249305]. 
=============================================
[2019-03-27 07:15:41,225] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.1656048e-33 1.2362227e-27 7.2728270e-32 3.7461648e-14], sum to 1.0000
[2019-03-27 07:15:41,230] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2300
[2019-03-27 07:15:41,235] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5518042766563284, 6.911200000000001, 6.9112, 168.912956510431, 484916.7636848349, 484916.7636848342, 158952.6677248426], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3015000.0000, 
sim time next is 3015600.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5520168937469507, 6.9112, 6.9112, 168.912956510431, 485103.6508356546, 485103.6508356546, 158982.1897595791], 
processed observation next is [1.0, 0.9130434782608695, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4536791387157936, 0.0, 0.0, 0.8294399451523027, 0.13475101412101517, 0.13475101412101517, 0.2372868503874315], 
reward next is 0.7627, 
noisyNet noise sample is [array([-0.8388902], dtype=float32), -1.3439264]. 
=============================================
[2019-03-27 07:15:45,759] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9884415e-01 9.7504983e-26 4.8861726e-16 1.8303589e-27 1.1558777e-03], sum to 1.0000
[2019-03-27 07:15:45,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6889
[2019-03-27 07:15:45,775] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.1744509356787452, 1.0, 2.0, 0.1744509356787452, 1.0, 2.0, 0.3029635834679689, 6.911200000000001, 6.9112, 170.5573041426782, 731313.0413393051, 731313.0413393045, 263226.4307202446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3432000.0000, 
sim time next is 3432600.0000, 
raw observation next is [31.0, 70.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8993589935946094, 6.9112, 6.9112, 168.912956510431, 724700.8467263288, 724700.8467263288, 222473.9607644418], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.8772670653592797, 0.0, 0.0, 0.8294399451523027, 0.20130579075731356, 0.20130579075731356, 0.3320506877081221], 
reward next is 0.6679, 
noisyNet noise sample is [array([-0.4205362], dtype=float32), 0.7129061]. 
=============================================
[2019-03-27 07:15:48,403] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.2414212e-01 6.7293117e-24 3.9823691e-14 1.2682109e-25 7.5857840e-02], sum to 1.0000
[2019-03-27 07:15:48,412] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9700
[2019-03-27 07:15:48,417] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.5, 65.0, 1.0, 2.0, 0.1825789527062452, 1.0, 2.0, 0.1825789527062452, 1.0, 2.0, 0.3170792610684308, 6.911200000000001, 6.9112, 170.5573041426782, 765398.5321102376, 765398.532110237, 265233.5990204043], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3605400.0000, 
sim time next is 3606000.0000, 
raw observation next is [32.33333333333334, 65.66666666666667, 1.0, 2.0, 0.185702337664557, 1.0, 2.0, 0.185702337664557, 1.0, 2.0, 0.3225035478218287, 6.9112, 6.9112, 170.5573041426782, 778496.9853470655, 778496.9853470655, 266029.0390649601], 
processed observation next is [1.0, 0.7391304347826086, 0.7314375987361774, 0.6566666666666667, 1.0, 1.0, 0.018918479113924067, 1.0, 1.0, 0.018918479113924067, 1.0, 1.0, 0.17378481441686427, 0.0, 0.0, 0.8375144448122397, 0.21624916259640709, 0.21624916259640709, 0.39705826726113447], 
reward next is 0.6029, 
noisyNet noise sample is [array([-2.1554918], dtype=float32), -1.4098899]. 
=============================================
[2019-03-27 07:15:48,429] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[79.933586]
 [78.07294 ]
 [74.53252 ]
 [69.9003  ]
 [68.989296]], R is [[79.97886658]
 [79.78320312]
 [79.58886719]
 [79.35202026]
 [78.5585022 ]].
[2019-03-27 07:15:57,796] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.0598187e-30 1.1311209e-26 5.9132044e-29 1.8413544e-13], sum to 1.0000
[2019-03-27 07:15:57,804] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4876
[2019-03-27 07:15:57,807] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.723564581565371, 6.9112, 6.9112, 168.912956510431, 616551.6015760098, 616551.6015760098, 187019.1820338913], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3304800.0000, 
sim time next is 3305400.0000, 
raw observation next is [25.16666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7306870762007753, 6.911200000000001, 6.9112, 168.912956510431, 622013.9468405113, 622013.9468405107, 188344.3341688217], 
processed observation next is [0.0, 0.2608695652173913, 0.39178515007898923, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6715696051228968, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17278165190014202, 0.17278165190014186, 0.2811109465206294], 
reward next is 0.7189, 
noisyNet noise sample is [array([-1.2313601], dtype=float32), 0.99746144]. 
=============================================
[2019-03-27 07:16:07,814] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.0712456e-01 1.6494587e-17 8.4747348e-10 9.3117124e-20 1.9287539e-01], sum to 1.0000
[2019-03-27 07:16:07,820] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9310
[2019-03-27 07:16:07,829] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.33333333333334, 79.0, 1.0, 2.0, 0.3741408957357392, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6285651971087081, 6.9112, 6.9112, 168.912956510431, 1045778.347248228, 1045778.347248228, 245926.5111325265], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3478800.0000, 
sim time next is 3479400.0000, 
raw observation next is [27.5, 79.0, 1.0, 2.0, 0.2654287279847461, 1.0, 1.0, 0.2654287279847461, 1.0, 2.0, 0.448894714526898, 6.911199999999999, 6.9112, 170.5573041426782, 1112897.518641244, 1112897.518641244, 289890.6244533387], 
processed observation next is [1.0, 0.2608695652173913, 0.5023696682464456, 0.79, 1.0, 1.0, 0.11497437106595913, 1.0, 0.5, 0.11497437106595913, 1.0, 1.0, 0.3279203835693878, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.3091381996225678, 0.3091381996225678, 0.43267257381095325], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5446772], dtype=float32), 0.38872084]. 
=============================================
[2019-03-27 07:16:09,640] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.2485265e-05 9.3117059e-23 5.9016290e-13 2.0554578e-25 9.9998748e-01], sum to 1.0000
[2019-03-27 07:16:09,648] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2221
[2019-03-27 07:16:09,652] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 0.6206445386151797, 1.0, 2.0, 0.6206445386151797, 1.0, 2.0, 1.03, 6.964997358387993, 6.9112, 170.5573041426782, 2603998.888589557, 2565461.652439612, 495585.3623374661], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3511800.0000, 
sim time next is 3512400.0000, 
raw observation next is [33.0, 60.33333333333333, 1.0, 2.0, 0.6120939499143871, 1.0, 2.0, 0.6120939499143871, 1.0, 2.0, 1.03, 6.948303110323544, 6.9112, 170.5573041426782, 2568086.857398189, 2541508.390215402, 492405.1240548023], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.6033333333333333, 1.0, 1.0, 0.532643313149864, 1.0, 1.0, 0.532643313149864, 1.0, 1.0, 1.0365853658536586, 0.0037103110323544186, 0.0, 0.8375144448122397, 0.7133574603883859, 0.7059745528376117, 0.7349330209773168], 
reward next is 0.0796, 
noisyNet noise sample is [array([2.0453804], dtype=float32), -0.95614713]. 
=============================================
[2019-03-27 07:16:11,663] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999952e-01 8.8212848e-26 5.1004974e-20 5.0288223e-27 4.4676145e-07], sum to 1.0000
[2019-03-27 07:16:11,673] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7169
[2019-03-27 07:16:11,681] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8160821889664659, 6.911200000000001, 6.9112, 168.912956510431, 682082.9082992213, 682082.9082992207, 205134.74326159], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3547800.0000, 
sim time next is 3548400.0000, 
raw observation next is [27.33333333333334, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8134006085509677, 6.9112, 6.9112, 168.912956510431, 680143.0305494744, 680143.0305494744, 204579.4721799456], 
processed observation next is [1.0, 0.043478260869565216, 0.4944707740916275, 0.7733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7724397665255704, 0.0, 0.0, 0.8294399451523027, 0.18892861959707621, 0.18892861959707621, 0.30534249579096356], 
reward next is 0.6947, 
noisyNet noise sample is [array([0.40636155], dtype=float32), 0.5845667]. 
=============================================
[2019-03-27 07:16:23,195] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 07:16:23,197] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:16:23,198] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:16:23,199] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:16:23,199] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:16:23,200] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:16:23,200] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:16:23,201] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:16:23,201] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:16:23,203] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:16:23,203] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:16:23,232] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run56
[2019-03-27 07:16:23,255] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run56
[2019-03-27 07:16:23,273] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run56
[2019-03-27 07:16:23,276] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run56
[2019-03-27 07:16:23,291] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run56
[2019-03-27 07:16:34,805] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.067665935]
[2019-03-27 07:16:34,806] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [19.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4802604117079814, 6.9112, 6.9112, 168.912956510431, 427342.1188710238, 427342.1188710238, 149487.2548987025]
[2019-03-27 07:16:34,807] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:16:34,809] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 6.71486055e-31 1.44127088e-28 1.03063854e-29
 2.15858935e-15], sampled 0.7211927285187484
[2019-03-27 07:17:26,220] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.067665935]
[2019-03-27 07:17:26,222] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.3, 64.33333333333334, 1.0, 2.0, 0.6204203315534536, 1.0, 2.0, 0.6204203315534536, 1.0, 2.0, 1.03, 6.961334827490684, 6.9112, 178.6582176852504, 2602934.275031887, 2565314.879553427, 497627.5927961644]
[2019-03-27 07:17:26,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:17:26,228] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.5343866e-03 5.6480402e-17 5.5313478e-08 1.5899624e-19 9.9246562e-01], sampled 0.4058604868035328
[2019-03-27 07:17:31,336] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.067665935]
[2019-03-27 07:17:31,339] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.16666666666667, 69.5, 1.0, 2.0, 0.571248437770778, 1.0, 2.0, 0.571248437770778, 1.0, 2.0, 0.9920696216626841, 6.911200000000001, 6.9112, 170.5573041426782, 2396552.054931919, 2396552.054931919, 467911.7280978712]
[2019-03-27 07:17:31,340] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:17:31,343] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [4.07298096e-02 7.91155281e-20 1.44331595e-11 1.37087163e-22
 9.59270239e-01], sampled 0.8324056052707288
[2019-03-27 07:18:05,287] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.067665935]
[2019-03-27 07:18:05,288] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.1, 84.0, 1.0, 2.0, 0.6974337883236524, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 974681.9446645194, 974681.9446645188, 220293.4359794345]
[2019-03-27 07:18:05,288] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:18:05,295] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.99841332e-01 1.82073930e-19 1.10130024e-13 1.09513802e-20
 1.58635608e-04], sampled 0.20257063454042168
[2019-03-27 07:18:05,296] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 974681.9446645194 W.
[2019-03-27 07:18:18,381] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7342.1418 3332567998.1559 1374.0000
[2019-03-27 07:18:18,584] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7369.7244 3135616480.4772 1168.0000
[2019-03-27 07:18:18,608] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7154.6382 3200629590.4764 1255.0000
[2019-03-27 07:18:18,803] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7928.1428 3008390882.1826 905.0000
[2019-03-27 07:18:18,805] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 7988.8128 2968834243.5808 818.0000
[2019-03-27 07:18:19,823] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1375000, evaluation results [1375000.0, 7342.141759916011, 3332567998.155884, 1374.0, 7369.724409928939, 3135616480.4772067, 1168.0, 7988.812786884402, 2968834243.5808363, 818.0, 7154.638150264757, 3200629590.476415, 1255.0, 7928.142750308073, 3008390882.182625, 905.0]
[2019-03-27 07:18:22,648] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9999976e-01 1.2935131e-23 8.7643643e-19 3.1166871e-25 2.5994413e-07], sum to 1.0000
[2019-03-27 07:18:22,659] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0156
[2019-03-27 07:18:22,663] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.83333333333334, 63.66666666666666, 1.0, 2.0, 0.2048480819295609, 1.0, 1.0, 0.2048480819295609, 1.0, 2.0, 0.3557533740157597, 6.9112, 6.9112, 170.5573041426782, 858791.4601645023, 858791.4601645023, 271202.1466584094], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3840600.0000, 
sim time next is 3841200.0000, 
raw observation next is [34.0, 63.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.105821424802888, 6.9112, 168.9117592197015, 966924.9498497113, 828854.7914194488, 254813.2875419881], 
processed observation next is [0.0, 0.4782608695652174, 0.8104265402843602, 0.63, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01946214248028877, 0.0, 0.8294340659066988, 0.268590263847142, 0.230237442060958, 0.38031833961490763], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6865669], dtype=float32), -0.022752969]. 
=============================================
[2019-03-27 07:18:23,000] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.0214980e-29 5.3782299e-27 5.5381416e-29 2.2216237e-12], sum to 1.0000
[2019-03-27 07:18:23,010] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6535
[2019-03-27 07:18:23,015] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.41666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9958023360404413, 6.9112, 6.9112, 168.9129565104308, 804777.7802085128, 804777.7802085128, 246090.9935558867], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3895800.0000, 
sim time next is 3896400.0000, 
raw observation next is [27.33333333333334, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9931340856143299, 6.9112, 6.9112, 168.912956510431, 803052.3535764628, 803052.3535764628, 245431.0417407216], 
processed observation next is [0.0, 0.08695652173913043, 0.4944707740916275, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.991626933676012, 0.0, 0.0, 0.8294399451523027, 0.22307009821568413, 0.22307009821568413, 0.3663149876727188], 
reward next is 0.6337, 
noisyNet noise sample is [array([-0.15036295], dtype=float32), -0.47966495]. 
=============================================
[2019-03-27 07:18:25,386] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999475e-01 7.5429542e-21 7.3969422e-15 3.7234914e-22 5.2371443e-06], sum to 1.0000
[2019-03-27 07:18:25,398] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5591
[2019-03-27 07:18:25,402] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.83333333333334, 63.66666666666666, 1.0, 2.0, 0.6129912072499275, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956477137, 856623.6387191061, 856623.6387191067, 203192.0699781715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3840600.0000, 
sim time next is 3841200.0000, 
raw observation next is [34.0, 63.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.112999188301655, 6.9112, 168.9117144305412, 972019.0153467063, 828856.7785064651, 254813.2882116529], 
processed observation next is [0.0, 0.4782608695652174, 0.8104265402843602, 0.63, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.020179918830165455, 0.0, 0.8294338459714171, 0.27000528204075175, 0.23023799402957365, 0.3803183406144073], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.169083], dtype=float32), -0.14157516]. 
=============================================
[2019-03-27 07:18:31,862] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.99999046e-01 2.04252623e-21 1.00071596e-16 4.17417279e-22
 9.95042569e-07], sum to 1.0000
[2019-03-27 07:18:31,869] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5289
[2019-03-27 07:18:31,875] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.0, 63.0, 1.0, 2.0, 0.3076416258082432, 1.0, 2.0, 0.3076416258082432, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 859824.5937581293, 859824.5937581293, 251385.4795143148], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3949200.0000, 
sim time next is 3949800.0000, 
raw observation next is [34.0, 62.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.178353778761867, 6.9112, 168.9113951011268, 1018401.204898824, 828874.8714945646, 254813.1993545429], 
processed observation next is [0.0, 0.7391304347826086, 0.8104265402843602, 0.625, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.026715377876186698, 0.0, 0.8294322779178028, 0.28288922358300667, 0.23024301985960127, 0.3803182079918551], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4791856], dtype=float32), 0.8047068]. 
=============================================
[2019-03-27 07:18:39,938] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.8487718e-01 1.0844119e-21 4.1486579e-14 7.7835584e-25 2.1512279e-01], sum to 1.0000
[2019-03-27 07:18:39,944] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1178
[2019-03-27 07:18:39,948] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [35.5, 53.0, 1.0, 2.0, 0.1842798851581479, 1.0, 2.0, 0.1842798851581479, 1.0, 2.0, 0.3200332182304284, 6.9112, 6.9112, 170.5573041426782, 772531.6657200772, 772531.6657200772, 265665.4505064405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4210200.0000, 
sim time next is 4210800.0000, 
raw observation next is [35.33333333333334, 54.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9704324621409247, 6.9112, 6.9112, 168.912956510431, 780851.6181005916, 780851.6181005916, 239475.9335772894], 
processed observation next is [1.0, 0.7391304347826086, 0.8736176935229073, 0.54, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9639420270011275, 0.0, 0.0, 0.8294399451523027, 0.21690322725016434, 0.21690322725016434, 0.35742676653326777], 
reward next is 0.6426, 
noisyNet noise sample is [array([-0.8404876], dtype=float32), -0.37488976]. 
=============================================
[2019-03-27 07:18:42,509] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999964e-01 1.5590130e-23 1.7053422e-18 5.5224787e-24 3.6008115e-07], sum to 1.0000
[2019-03-27 07:18:42,516] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6760
[2019-03-27 07:18:42,522] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.914874147007243, 6.9112, 168.9127454362645, 831408.4966854183, 828801.9336012729, 254811.9262156565], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4138200.0000, 
sim time next is 4138800.0000, 
raw observation next is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.928332621787966, 6.9112, 168.9126617909033, 840960.1093163564, 828805.6589677752, 254811.9275316642], 
processed observation next is [1.0, 0.9130434782608695, 0.5734597156398105, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0017132621787966152, 0.0, 0.8294384979444984, 0.23360003036565455, 0.23022379415771532, 0.3803163097487525], 
reward next is 0.5340, 
noisyNet noise sample is [array([0.7663989], dtype=float32), -1.6910564]. 
=============================================
[2019-03-27 07:18:50,631] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.1410466e-02 1.7310447e-17 4.9809523e-10 6.6711151e-21 9.4858956e-01], sum to 1.0000
[2019-03-27 07:18:50,643] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8241
[2019-03-27 07:18:50,648] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [38.0, 53.66666666666666, 1.0, 2.0, 0.8161910930055676, 1.0, 2.0, 0.7286855860170464, 1.0, 2.0, 1.03, 7.00510689550472, 6.9112, 170.5573041426782, 3057854.665100009, 2990585.335961698, 560541.7980692384], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4281000.0000, 
sim time next is 4281600.0000, 
raw observation next is [38.0, 53.33333333333334, 1.0, 2.0, 0.9986995289043348, 1.0, 2.0, 0.81993980396643, 1.0, 2.0, 1.03, 7.005121296164946, 6.9112, 170.5573041426782, 3441321.32103654, 3374041.676119526, 632297.5637657273], 
processed observation next is [1.0, 0.5652173913043478, 1.0, 0.5333333333333334, 1.0, 1.0, 0.9984331673546202, 1.0, 1.0, 0.7830600047788313, 1.0, 1.0, 1.0365853658536586, 0.009392129616494582, 0.0, 0.8375144448122397, 0.9559225891768166, 0.9372337989220906, 0.9437277071130259], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.4190105], dtype=float32), 0.42214763]. 
=============================================
[2019-03-27 07:18:53,951] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.2514272e-31 5.8940814e-30 9.5627230e-32 1.4172686e-16], sum to 1.0000
[2019-03-27 07:18:53,960] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6336
[2019-03-27 07:18:53,969] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8602195441344835, 6.911200000000001, 6.9112, 168.912956510431, 713877.8346131871, 713877.8346131865, 214528.7161836298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4522800.0000, 
sim time next is 4523400.0000, 
raw observation next is [27.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8551662588011684, 6.9112, 6.9112, 168.912956510431, 710521.4421212187, 710521.4421212187, 213437.3040626544], 
processed observation next is [0.0, 0.34782608695652173, 0.5023696682464456, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8233734863428883, 0.0, 0.0, 0.8294399451523027, 0.19736706725589406, 0.19736706725589406, 0.3185631403920215], 
reward next is 0.6814, 
noisyNet noise sample is [array([0.71465415], dtype=float32), -1.6904898]. 
=============================================
[2019-03-27 07:18:58,274] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9997127e-01 7.6332914e-21 1.2820486e-14 4.3118013e-21 2.8731572e-05], sum to 1.0000
[2019-03-27 07:18:58,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8321
[2019-03-27 07:18:58,290] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 989816.6200340393 W.
[2019-03-27 07:18:58,298] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.0, 84.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.138076788708075, 6.9112, 168.9115887031604, 989816.6200340393, 828863.7209877203, 254813.1147646444], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4410600.0000, 
sim time next is 4411200.0000, 
raw observation next is [30.0, 84.0, 1.0, 1.0, 0.6422781753646788, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9127717776521, 897567.9622226136, 897567.9622226136, 208885.5840614472], 
processed observation next is [0.0, 0.043478260869565216, 0.6208530805687204, 0.84, 1.0, 0.5, 0.5690098498369623, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294390380297872, 0.249324433950726, 0.249324433950726, 0.31176952844992123], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36401707], dtype=float32), 0.3654788]. 
=============================================
[2019-03-27 07:18:58,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 7.1774494e-21 9.1692316e-17 8.1546407e-22 1.0908926e-07], sum to 1.0000
[2019-03-27 07:18:58,912] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5102
[2019-03-27 07:18:58,920] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 891935.2894598988 W.
[2019-03-27 07:18:58,925] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.0, 85.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.000158177756062, 6.9112, 168.9123019739993, 891935.2894598988, 828825.5410063063, 254812.2391426122], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4419600.0000, 
sim time next is 4420200.0000, 
raw observation next is [29.0, 84.83333333333333, 1.0, 1.0, 0.2007638563496101, 1.0, 1.0, 0.2007638563496101, 1.0, 2.0, 0.3486604248574239, 6.9112, 6.9112, 170.5573041426782, 841662.3059849038, 841662.3059849038, 270055.1724860988], 
processed observation next is [0.0, 0.13043478260869565, 0.5734597156398105, 0.8483333333333333, 1.0, 0.5, 0.03706488716820494, 1.0, 0.5, 0.03706488716820494, 1.0, 1.0, 0.2056834449480779, 0.0, 0.0, 0.8375144448122397, 0.23379508499580662, 0.23379508499580662, 0.4030674216210429], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15053743], dtype=float32), 1.1708149]. 
=============================================
[2019-03-27 07:19:04,541] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.1578114e-01 5.1517953e-14 2.7336647e-08 2.8761009e-16 7.8421879e-01], sum to 1.0000
[2019-03-27 07:19:04,550] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9280
[2019-03-27 07:19:04,558] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 76.5, 1.0, 2.0, 1.00263840846023, 1.0, 2.0, 1.00263840846023, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2804695.907155327, 2804695.907155327, 530590.9152377099], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4611000.0000, 
sim time next is 4611600.0000, 
raw observation next is [32.0, 75.0, 1.0, 2.0, 0.6992885807003884, 1.0, 2.0, 0.6702343298644567, 1.0, 1.0, 1.03, 7.005097676061292, 6.9112, 170.5573041426782, 2812293.808288489, 2745031.083412528, 521105.7461421996], 
processed observation next is [1.0, 0.391304347826087, 0.7156398104265403, 0.75, 1.0, 1.0, 0.6376970851811907, 1.0, 1.0, 0.6026919636921165, 1.0, 0.5, 1.0365853658536586, 0.00938976760612924, 0.0, 0.8375144448122397, 0.7811927245245803, 0.7625086342812578, 0.777769770361492], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.965519], dtype=float32), 0.050871614]. 
=============================================
[2019-03-27 07:19:06,128] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.8389829e-37 1.1920969e-35 3.5633183e-35 3.7050506e-21], sum to 1.0000
[2019-03-27 07:19:06,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5881
[2019-03-27 07:19:06,141] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9263311211305537, 6.911199999999999, 6.9112, 168.912956510431, 755121.7445071979, 755121.7445071986, 229232.542985943], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4548000.0000, 
sim time next is 4548600.0000, 
raw observation next is [34.0, 53.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9241478934675355, 6.911200000000001, 6.9112, 168.912956510431, 753282.8700948237, 753282.8700948231, 228709.3982364458], 
processed observation next is [0.0, 0.6521739130434783, 0.8104265402843602, 0.53, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.90749743105797, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20924524169300657, 0.2092452416930064, 0.34135731080066534], 
reward next is 0.6586, 
noisyNet noise sample is [array([0.05086817], dtype=float32), -1.8234683]. 
=============================================
[2019-03-27 07:19:10,326] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [6.3911939e-01 1.6436562e-16 3.7858325e-09 7.3931170e-19 3.6088058e-01], sum to 1.0000
[2019-03-27 07:19:10,335] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7329
[2019-03-27 07:19:10,346] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 71.0, 1.0, 2.0, 0.7685084242897592, 1.0, 2.0, 0.7048442516591421, 1.0, 2.0, 1.03, 7.005103134603418, 6.9112, 170.5573041426782, 2957688.481628588, 2890421.846576863, 543840.6127160355], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4621200.0000, 
sim time next is 4621800.0000, 
raw observation next is [32.0, 71.0, 1.0, 2.0, 0.7605362491682437, 1.0, 2.0, 0.7008581640983844, 1.0, 2.0, 1.03, 7.005102505868493, 6.9112, 170.5573041426782, 2940942.250645917, 2873676.065982594, 541131.2917263649], 
processed observation next is [1.0, 0.4782608695652174, 0.7156398104265403, 0.71, 1.0, 1.0, 0.7114894568292093, 1.0, 1.0, 0.6395881495161257, 1.0, 1.0, 1.0365853658536586, 0.00939025058684928, 0.0, 0.8375144448122397, 0.8169284029571992, 0.7982433516618317, 0.8076586443677087], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.01535057], dtype=float32), 1.1014637]. 
=============================================
[2019-03-27 07:19:14,054] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 07:19:14,056] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:19:14,057] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:19:14,057] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:19:14,058] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:19:14,058] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:19:14,060] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:19:14,063] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:19:14,062] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:19:14,065] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:19:14,066] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:19:14,098] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run57
[2019-03-27 07:19:14,099] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run57
[2019-03-27 07:19:14,100] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run57
[2019-03-27 07:19:14,139] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run57
[2019-03-27 07:19:14,177] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run57
[2019-03-27 07:19:27,010] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06581142]
[2019-03-27 07:19:27,012] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.6, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5415717833508467, 6.9112, 6.9112, 168.912956510431, 475818.0563652861, 475818.0563652861, 157549.6141575895]
[2019-03-27 07:19:27,013] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:19:27,015] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.0200658e-37 2.6832425e-38 1.0409242e-35 1.8445930e-23], sampled 0.1990141793613709
[2019-03-27 07:19:36,070] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06581142]
[2019-03-27 07:19:36,070] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.96643448, 81.81813633, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7406175536134458, 6.911199999999999, 6.9112, 168.912956510431, 629643.6152683147, 629643.6152683154, 190213.2546441766]
[2019-03-27 07:19:36,071] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:19:36,075] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 3.62296503e-37 1.30463432e-37 2.57167772e-35
 1.02978944e-22], sampled 0.1302047637537681
[2019-03-27 07:19:38,850] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06581142]
[2019-03-27 07:19:38,853] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.053059505, 80.192756895, 1.0, 2.0, 0.7082233576545371, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 989767.6764214046, 989767.676421404, 222632.3178011945]
[2019-03-27 07:19:38,855] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:19:38,857] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 2.46955076e-25 8.34684510e-22 1.22712774e-25
 1.43496074e-11], sampled 0.6335145819663521
[2019-03-27 07:19:38,860] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 989767.6764214046 W.
[2019-03-27 07:19:49,264] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06581142]
[2019-03-27 07:19:49,265] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.63987608333333, 71.41475065666667, 1.0, 2.0, 0.6759764073139268, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 944681.3567794982, 944681.3567794975, 215755.2024086725]
[2019-03-27 07:19:49,266] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:19:49,271] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.5236447e-24 3.8715453e-21 5.1099520e-25 3.2799455e-10], sampled 0.02430760456116665
[2019-03-27 07:19:49,272] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 944681.3567794982 W.
[2019-03-27 07:21:08,702] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02660249], dtype=float32), 0.06581142]
[2019-03-27 07:21:08,703] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.200030465, 91.64242502333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8771675152677516, 6.911199999999999, 6.9112, 168.912956510431, 728500.2603726421, 728500.2603726428, 218345.8613922322]
[2019-03-27 07:21:08,704] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:21:08,707] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8528681e-37 2.9501599e-23], sampled 0.047008421014452684
[2019-03-27 07:21:08,727] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7262.7737 3319826874.6202 2174.0000
[2019-03-27 07:21:08,938] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7032.9052 3185171561.2455 2456.0000
[2019-03-27 07:21:09,043] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7344.2586 3106037632.8590 2005.0000
[2019-03-27 07:21:09,249] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7920.8739 2989529408.4329 1570.0000
[2019-03-27 07:21:09,318] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8058.7145 2937984971.5702 1382.0000
[2019-03-27 07:21:10,336] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 1400000, evaluation results [1400000.0, 7262.77371565375, 3319826874.6202044, 2174.0, 7344.2585726428915, 3106037632.859037, 2005.0, 8058.714466548045, 2937984971.5701866, 1382.0, 7032.905184161525, 3185171561.245547, 2456.0, 7920.873903728852, 2989529408.4328966, 1570.0]
[2019-03-27 07:21:22,921] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5359740e-38 4.5459497e-22], sum to 1.0000
[2019-03-27 07:21:22,931] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2735
[2019-03-27 07:21:22,936] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.16666666666667, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.883059434447192, 6.9112, 6.9112, 168.912956510431, 728721.0720619676, 728721.0720619676, 219523.4151936561], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5082600.0000, 
sim time next is 5083200.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8825859522665861, 6.911199999999999, 6.9112, 168.912956510431, 728665.397652746, 728665.3976527466, 219427.9076800112], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8568121369104708, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20240705490354055, 0.20240705490354075, 0.32750433982091226], 
reward next is 0.6725, 
noisyNet noise sample is [array([1.8600469], dtype=float32), -0.7901468]. 
=============================================
[2019-03-27 07:21:26,770] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0056152e-01 1.1109676e-15 4.0086277e-09 9.5194654e-19 8.9943844e-01], sum to 1.0000
[2019-03-27 07:21:26,780] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8223
[2019-03-27 07:21:26,788] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.36666666666667, 51.33333333333334, 1.0, 2.0, 0.786020171055127, 1.0, 2.0, 0.7136001250418261, 1.0, 2.0, 1.03, 7.005104515746988, 6.9112, 170.5573041426782, 2994474.181392727, 2927206.556971681, 549875.0971377172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5311200.0000, 
sim time next is 5311800.0000, 
raw observation next is [36.34999999999999, 51.5, 1.0, 2.0, 0.7874909063471541, 1.0, 2.0, 0.7143354926878396, 1.0, 2.0, 1.03, 7.005104631746917, 6.9112, 170.5573041426782, 2997563.701314351, 2930295.993797837, 550387.1251369935], 
processed observation next is [1.0, 0.4782608695652174, 0.9218009478672979, 0.515, 1.0, 1.0, 0.7439649474062098, 1.0, 1.0, 0.6558258948046259, 1.0, 1.0, 1.0365853658536586, 0.009390463174691721, 0.0, 0.8375144448122397, 0.8326565836984309, 0.813971109388288, 0.8214733210999903], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.1846013], dtype=float32), 0.2743036]. 
=============================================
[2019-03-27 07:21:28,478] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.9873001e-26 2.2201807e-22 1.0532387e-27 1.6404859e-09], sum to 1.0000
[2019-03-27 07:21:28,491] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0902
[2019-03-27 07:21:28,497] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333334, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8515318839569465, 6.9112, 6.9112, 168.912956510431, 699446.3638309042, 699446.3638309042, 212354.7909995459], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4988400.0000, 
sim time next is 4989000.0000, 
raw observation next is [30.16666666666666, 68.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8615695494782982, 6.911200000000001, 6.9112, 168.912956510431, 707513.0591795044, 707513.0591795037, 214559.6074291657], 
processed observation next is [1.0, 0.7391304347826086, 0.6287519747235385, 0.6883333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8311823774125588, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1965314053276401, 0.1965314053276399, 0.3202382200435309], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.48765436], dtype=float32), -0.96053016]. 
=============================================
[2019-03-27 07:21:28,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[53.417614]
 [48.60269 ]
 [44.469864]
 [41.138206]
 [37.35913 ]], R is [[56.37645721]
 [56.49574661]
 [55.93078995]
 [56.01216125]
 [56.03115082]].
[2019-03-27 07:21:31,150] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9287328e-37 2.6649116e-23], sum to 1.0000
[2019-03-27 07:21:31,157] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2055
[2019-03-27 07:21:31,161] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8838121638803167, 6.9112, 6.9112, 168.912956510431, 729951.9943890817, 729951.9943890817, 219717.2486178718], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5086200.0000, 
sim time next is 5086800.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8837780698969964, 6.9112, 6.9112, 168.912956510431, 729924.2131311885, 729924.2131311885, 219709.4897232964], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8582659388987761, 0.0, 0.0, 0.8294399451523027, 0.20275672586977458, 0.20275672586977458, 0.32792461152730806], 
reward next is 0.6721, 
noisyNet noise sample is [array([1.1532847], dtype=float32), 0.38501257]. 
=============================================
[2019-03-27 07:21:34,360] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.9114064e-36 4.4334155e-22], sum to 1.0000
[2019-03-27 07:21:34,366] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0455
[2019-03-27 07:21:34,372] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.83333333333334, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8845734197462669, 6.9112, 6.9112, 168.912956510431, 730737.4756872487, 730737.4756872487, 219896.5322288816], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5087400.0000, 
sim time next is 5088000.0000, 
raw observation next is [27.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881308949503709, 6.911200000000001, 6.9112, 168.912956510431, 728349.6647396589, 728349.6647396584, 219164.1039075704], 
processed observation next is [0.0, 0.9130434782608695, 0.5102685624012641, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8552548164679378, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20231935131657192, 0.20231935131657178, 0.32711060284711996], 
reward next is 0.6729, 
noisyNet noise sample is [array([-0.7137515], dtype=float32), -0.7465506]. 
=============================================
[2019-03-27 07:21:34,387] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[71.54241]
 [71.50076]
 [71.43375]
 [71.43649]
 [71.45004]], R is [[71.55929565]
 [71.51550293]
 [71.47241974]
 [71.42976379]
 [71.38749695]].
[2019-03-27 07:21:35,642] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.0528991e-37 3.7469358e-37 4.2115440e-35 2.0414154e-20], sum to 1.0000
[2019-03-27 07:21:35,651] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2344
[2019-03-27 07:21:35,656] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8334476011710914, 6.911199999999999, 6.9112, 168.912956510431, 695112.4379774907, 695112.4379774913, 208787.1770060105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5121600.0000, 
sim time next is 5122200.0000, 
raw observation next is [26.83333333333333, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8442283091374031, 6.911199999999999, 6.9112, 168.912956510431, 702499.4700279715, 702499.4700279721, 211073.3037154057], 
processed observation next is [0.0, 0.2608695652173913, 0.470774091627172, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8100345233382963, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19513874167443654, 0.1951387416744367, 0.3150347816647846], 
reward next is 0.6850, 
noisyNet noise sample is [array([0.6720709], dtype=float32), 1.5660883]. 
=============================================
[2019-03-27 07:21:37,639] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2434574e-37 0.0000000e+00 8.2612572e-36 7.4768423e-22], sum to 1.0000
[2019-03-27 07:21:37,652] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4889
[2019-03-27 07:21:37,656] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9483082577091497, 6.911200000000001, 6.9112, 168.912956510431, 770667.229134756, 770667.2291347554, 234425.9882653941], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5146800.0000, 
sim time next is 5147400.0000, 
raw observation next is [32.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9482458555694536, 6.911199999999999, 6.9112, 168.912956510431, 770622.413844326, 770622.4138443267, 234411.03777049], 
processed observation next is [0.0, 0.5652173913043478, 0.7156398104265403, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9368851897188457, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2140617816234239, 0.2140617816234241, 0.34986722055297015], 
reward next is 0.6501, 
noisyNet noise sample is [array([1.3970824], dtype=float32), 1.4503738]. 
=============================================
[2019-03-27 07:21:41,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.8618670e-01 5.8442911e-17 1.5740069e-11 1.1583085e-19 7.1381336e-01], sum to 1.0000
[2019-03-27 07:21:41,208] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1141
[2019-03-27 07:21:41,216] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 3080239.371105466 W.
[2019-03-27 07:21:41,222] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [35.91666666666666, 53.83333333333333, 1.0, 2.0, 0.8268464870691324, 1.0, 2.0, 0.7340132830488287, 1.0, 2.0, 1.03, 7.005107736015883, 6.9112, 170.5573041426782, 3080239.371105466, 3012969.439874819, 564387.3193869025], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5331000.0000, 
sim time next is 5331600.0000, 
raw observation next is [35.9, 54.0, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.509282018269708, 6.9112, 170.5573041426782, 3338259.268752845, 2909828.790645213, 550381.7316268948], 
processed observation next is [1.0, 0.7391304347826086, 0.9004739336492891, 0.54, 1.0, 1.0, 1.0481927710843375, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.2195121951219512, 0.05980820182697082, 0.0, 0.8375144448122397, 0.9272942413202347, 0.8082857751792258, 0.8214652710849176], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.08878525], dtype=float32), -0.15183043]. 
=============================================
[2019-03-27 07:21:42,830] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 4.1080902e-26 8.1200222e-24 8.1933482e-27 2.2618236e-08], sum to 1.0000
[2019-03-27 07:21:42,840] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8142
[2019-03-27 07:21:42,846] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [33.46666666666667, 66.33333333333334, 1.0, 2.0, 0.6135091520066922, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956479866, 857347.7319692498, 857347.7319692498, 203291.0397865523], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5337600.0000, 
sim time next is 5338200.0000, 
raw observation next is [33.23333333333333, 67.66666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.470432889674666, 6.9112, 168.9089990968359, 1225685.507347267, 828955.7431879551, 254813.4441658521], 
processed observation next is [1.0, 0.782608695652174, 0.7740916271721956, 0.6766666666666665, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.05592328896746661, 0.0, 0.829420512439839, 0.3404681964853519, 0.2302654842188764, 0.3803185733818688], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.09216787], dtype=float32), -0.76945364]. 
=============================================
[2019-03-27 07:21:48,029] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8234957e-01 1.3430559e-15 3.6430162e-10 2.3315562e-18 1.7650440e-02], sum to 1.0000
[2019-03-27 07:21:48,039] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0787
[2019-03-27 07:21:48,048] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1279591.461333609 W.
[2019-03-27 07:21:48,053] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.0, 81.83333333333333, 1.0, 2.0, 0.4577402253179969, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7933103076182164, 6.911200000000001, 6.9112, 168.912956510431, 1279591.461333609, 1279591.461333608, 286016.411909093], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5903400.0000, 
sim time next is 5904000.0000, 
raw observation next is [29.2, 81.0, 1.0, 2.0, 0.5082134535809549, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8809576677783738, 6.911199999999999, 6.9112, 168.912956510431, 1420781.433426854, 1420781.433426855, 312346.3856023538], 
processed observation next is [1.0, 0.34782608695652173, 0.5829383886255924, 0.81, 1.0, 1.0, 0.4074860886517529, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8548264241199679, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3946615092852372, 0.39466150928523747, 0.4661886352273937], 
reward next is 0.5338, 
noisyNet noise sample is [array([1.0405602], dtype=float32), -0.77935064]. 
=============================================
[2019-03-27 07:21:48,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[31.20665 ]
 [31.12972 ]
 [30.641624]
 [31.568127]
 [31.659569]], R is [[31.72909546]
 [31.4118042 ]
 [31.09768677]
 [31.28120995]
 [31.47530746]].
[2019-03-27 07:21:50,100] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [8.3398867e-01 5.0101184e-16 1.0138165e-11 7.1659008e-19 1.6601139e-01], sum to 1.0000
[2019-03-27 07:21:50,108] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4324
[2019-03-27 07:21:50,116] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1487304.573586422 W.
[2019-03-27 07:21:50,121] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.4, 93.33333333333334, 1.0, 2.0, 0.3546638067592201, 1.0, 1.0, 0.3546638067592201, 1.0, 2.0, 0.6159337432275873, 6.911199999999999, 6.9112, 170.5573041426782, 1487304.573586422, 1487304.573586423, 329213.3488605039], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5373600.0000, 
sim time next is 5374200.0000, 
raw observation next is [28.35, 93.66666666666667, 1.0, 2.0, 0.5233633253492679, 1.0, 2.0, 0.5233633253492679, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1463154.475567149, 1463154.47556715, 307684.563996306], 
processed observation next is [1.0, 0.17391304347826086, 0.5426540284360191, 0.9366666666666668, 1.0, 1.0, 0.4257389462039372, 1.0, 1.0, 0.4257389462039372, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4064317987686525, 0.40643179876865276, 0.4592306925318], 
reward next is 0.5408, 
noisyNet noise sample is [array([-0.9396977], dtype=float32), 0.1017554]. 
=============================================
[2019-03-27 07:21:53,650] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [7.72709966e-01 1.12500280e-15 1.07916634e-10 3.50066847e-18
 2.27290079e-01], sum to 1.0000
[2019-03-27 07:21:53,662] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6073
[2019-03-27 07:21:53,669] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1451353.980882829 W.
[2019-03-27 07:21:53,675] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [30.63333333333333, 77.66666666666667, 1.0, 2.0, 0.5191417816498067, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9015775919150556, 6.911199999999999, 6.9112, 168.912956510431, 1451353.980882829, 1451353.980882829, 318740.4942487826], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5470800.0000, 
sim time next is 5471400.0000, 
raw observation next is [30.81666666666667, 76.83333333333333, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 7.215783533654444, 6.9112, 168.9112187116906, 1669982.734601753, 1453902.915951594, 311355.571226026], 
processed observation next is [1.0, 0.30434782608695654, 0.6595576619273303, 0.7683333333333333, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.030458353365444425, 0.0, 0.8294314117649196, 0.4638840929449314, 0.403861921097665, 0.4647098078000388], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.31905994], dtype=float32), 1.3794379]. 
=============================================
[2019-03-27 07:21:55,829] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9478263e-01 5.1475871e-18 1.7969565e-12 2.1807462e-20 5.2174153e-03], sum to 1.0000
[2019-03-27 07:21:55,835] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-27 07:21:55,845] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1285502.420480297 W.
[2019-03-27 07:21:55,852] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.2, 78.0, 1.0, 2.0, 0.3065707458177063, 1.0, 2.0, 0.3065707458177063, 1.0, 1.0, 0.5300213001436094, 6.9112, 6.9112, 170.5573041426782, 1285502.420480297, 1285502.420480297, 306963.4169733012], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5817600.0000, 
sim time next is 5818200.0000, 
raw observation next is [29.35, 77.33333333333333, 1.0, 2.0, 0.499396205818127, 0.0, 1.0, 0.0, 1.0, 2.0, 0.8612665974705518, 6.911200000000001, 6.9112, 168.912956510431, 1396115.381082489, 1396115.381082489, 306745.5562808132], 
processed observation next is [1.0, 0.34782608695652173, 0.590047393364929, 0.7733333333333333, 1.0, 1.0, 0.39686289857605667, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.8308129237445754, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.38780982807846914, 0.38780982807846914, 0.45782918847882564], 
reward next is 0.5422, 
noisyNet noise sample is [array([-0.21800184], dtype=float32), -0.7398705]. 
=============================================
[2019-03-27 07:22:04,628] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-27 07:22:04,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:22:04,631] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:22:04,632] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:22:04,633] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:22:04,633] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:22:04,634] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:22:04,634] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:22:04,635] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:22:04,637] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:22:04,638] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:22:04,659] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run58
[2019-03-27 07:22:04,683] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run58
[2019-03-27 07:22:04,684] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run58
[2019-03-27 07:22:04,720] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run58
[2019-03-27 07:22:04,722] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run58
[2019-03-27 07:22:05,741] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:22:05,741] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.93333333333333, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6678083403548334, 6.9112, 6.9112, 168.912956510431, 576392.9595825021, 576392.9595825021, 177083.3523237458]
[2019-03-27 07:22:05,742] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:22:05,744] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.3246981e-16 4.1977567e-17 1.0397681e-15 2.3845301e-10], sampled 0.11281484219330518
[2019-03-27 07:22:26,674] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:22:26,674] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.72669882666667, 92.81785345666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5144970955565363, 6.9112, 6.9112, 168.912956510431, 455969.100064591, 455969.100064591, 153812.4389311858]
[2019-03-27 07:22:26,675] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:22:26,677] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.1071696e-37 0.0000000e+00 1.6766174e-35 7.6052179e-24], sampled 0.12556491282327875
[2019-03-27 07:22:45,274] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:22:45,274] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.95, 52.5, 1.0, 2.0, 0.9321104843129363, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1302849.965528699, 1302849.965528698, 278921.5508194212]
[2019-03-27 07:22:45,275] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:22:45,277] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9973792e-01 9.3117191e-17 1.7246328e-12 4.9382128e-18 2.6202589e-04], sampled 0.36594096540683685
[2019-03-27 07:22:45,278] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1302849.965528699 W.
[2019-03-27 07:22:56,851] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:22:56,852] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.66293999, 78.66640305666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8758625884979905, 6.9112, 6.9112, 168.912956510431, 726020.7364993398, 726020.7364993398, 218004.6098766731]
[2019-03-27 07:22:56,854] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:22:56,856] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.7896372e-36 2.9160689e-37 4.4067289e-35 4.0171332e-21], sampled 0.0804337245235015
[2019-03-27 07:23:02,309] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:23:02,312] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.83333333333334, 79.83333333333334, 1.0, 1.0, 0.6616213730353558, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9127521816499, 924611.3722418041, 924611.3722418034, 212785.9400801473]
[2019-03-27 07:23:02,316] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:23:02,320] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.0967425e-25 8.2141712e-24 4.3885328e-25 1.8768886e-12], sampled 0.7762251511374905
[2019-03-27 07:23:02,322] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 924611.3722418041 W.
[2019-03-27 07:23:09,247] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:23:09,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [37.0, 46.0, 1.0, 1.0, 0.597332561931207, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129051311387, 834732.8898053309, 834732.8898053309, 200249.3234714732]
[2019-03-27 07:23:09,249] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:23:09,251] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 6.5837976e-25 6.2026058e-24 1.1048606e-24 1.4667801e-12], sampled 0.5532593664265368
[2019-03-27 07:23:17,494] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:23:17,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8568127140336289, 6.9112, 6.9112, 168.912956510431, 710269.8284146391, 710269.8284146391, 213749.3265458194]
[2019-03-27 07:23:17,498] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:23:17,501] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.6653584e-38 5.8835412e-24], sampled 0.7511432745684476
[2019-03-27 07:23:29,122] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:23:29,123] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.67626617833333, 89.49585395, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9097437492444576, 6.9112, 6.9112, 168.912956510431, 749858.5508126465, 749858.5508126465, 225662.6915956935]
[2019-03-27 07:23:29,124] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:23:29,127] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.0720847e-25], sampled 0.8540682055505716
[2019-03-27 07:23:51,428] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06512173]
[2019-03-27 07:23:51,429] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.31279509833333, 83.62743689666665, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6531250833084594, 6.9112, 6.9112, 168.912956510431, 565419.4668342371, 565419.4668342371, 174591.4484784735]
[2019-03-27 07:23:51,431] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:23:51,433] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.0149078e-37 0.0000000e+00 3.4911729e-35 3.6428776e-23], sampled 0.9029157740174941
[2019-03-27 07:23:59,938] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7344.1311 3106226069.8558 1992.0000
[2019-03-27 07:23:59,973] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7024.7383 3186029300.8571 2445.0000
[2019-03-27 07:24:00,083] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7234.0967 3319947643.4886 2224.0000
[2019-03-27 07:24:00,124] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7916.3442 2989335043.0085 1565.0000
[2019-03-27 07:24:00,335] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.9977 2938229667.1221 1370.0000
[2019-03-27 07:24:01,351] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1425000, evaluation results [1425000.0, 7234.096687123816, 3319947643.488565, 2224.0, 7344.131149862794, 3106226069.8557878, 1992.0, 8060.997667143167, 2938229667.122096, 1370.0, 7024.738333149524, 3186029300.857121, 2445.0, 7916.344170249636, 2989335043.0085387, 1565.0]
[2019-03-27 07:24:02,524] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.3593299e-37 0.0000000e+00 5.8089298e-36 2.4099466e-22], sum to 1.0000
[2019-03-27 07:24:02,531] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1439
[2019-03-27 07:24:02,537] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.45, 60.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8812504946156359, 6.911199999999999, 6.9112, 168.912956510431, 726444.820945256, 726444.8209452567, 219082.7754998079], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5741400.0000, 
sim time next is 5742000.0000, 
raw observation next is [31.6, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8819620521572226, 6.9112, 6.9112, 168.912956510431, 726906.8906554563, 726906.8906554563, 219239.8086075475], 
processed observation next is [0.0, 0.4782608695652174, 0.6966824644549764, 0.6, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8560512831185639, 0.0, 0.0, 0.8294399451523027, 0.20191858073762675, 0.20191858073762675, 0.32722359493663805], 
reward next is 0.6728, 
noisyNet noise sample is [array([1.889107], dtype=float32), -1.093421]. 
=============================================
[2019-03-27 07:24:02,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[69.11388]
 [69.10762]
 [69.10608]
 [69.0916 ]
 [69.07411]], R is [[69.17851257]
 [69.15973663]
 [69.14130402]
 [69.12303925]
 [69.10468292]].
[2019-03-27 07:24:11,490] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.6616824e-37 1.1150533e-37 1.2253300e-35 2.8941281e-21], sum to 1.0000
[2019-03-27 07:24:11,501] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0526
[2019-03-27 07:24:11,506] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.915120168964873, 6.9112, 6.9112, 168.912956510431, 749521.4657144416, 749521.4657144416, 226733.4403119813], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6361200.0000, 
sim time next is 6361800.0000, 
raw observation next is [31.0, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9492920738529647, 6.911200000000001, 6.9112, 168.912956510431, 776852.0980397784, 776852.0980397778, 234922.81906777], 
processed observation next is [0.0, 0.6521739130434783, 0.6682464454976303, 0.655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9381610656743471, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.215792249455494, 0.21579224945549383, 0.3506310732354776], 
reward next is 0.6494, 
noisyNet noise sample is [array([1.0367136], dtype=float32), 0.0552536]. 
=============================================
[2019-03-27 07:24:15,561] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.7746565e-38 0.0000000e+00 2.2888236e-36 1.1767924e-22], sum to 1.0000
[2019-03-27 07:24:15,566] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6369
[2019-03-27 07:24:15,576] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 88.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8885144454525762, 6.911199999999999, 6.9112, 168.912956510431, 732507.6408724061, 732507.6408724068, 220742.9944683877], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6324000.0000, 
sim time next is 6324600.0000, 
raw observation next is [26.63333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8880518453971453, 6.9112, 6.9112, 168.912956510431, 732231.057325339, 732231.057325339, 220640.9678951032], 
processed observation next is [0.0, 0.17391304347826086, 0.46129541864139006, 0.8883333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8634778602404212, 0.0, 0.0, 0.8294399451523027, 0.20339751592370525, 0.20339751592370525, 0.3293148774553779], 
reward next is 0.6707, 
noisyNet noise sample is [array([-0.57508236], dtype=float32), -0.10085082]. 
=============================================
[2019-03-27 07:24:27,354] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.7922937e-37 1.9392990e-38 3.4343326e-36 6.5257264e-21], sum to 1.0000
[2019-03-27 07:24:27,361] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9613
[2019-03-27 07:24:27,365] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9285691406713702, 6.9112, 6.9112, 168.912956510431, 757881.3422833523, 757881.3422833523, 229810.9468497045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6253200.0000, 
sim time next is 6253800.0000, 
raw observation next is [28.95, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9284696103213687, 6.9112, 6.9112, 168.912956510431, 757789.1972115694, 757789.1972115694, 229786.639223315], 
processed observation next is [0.0, 0.391304347826087, 0.5710900473933649, 0.7816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9127678174650836, 0.0, 0.0, 0.8294399451523027, 0.21049699922543594, 0.21049699922543594, 0.34296513316912686], 
reward next is 0.6570, 
noisyNet noise sample is [array([0.6897075], dtype=float32), 0.32248032]. 
=============================================
[2019-03-27 07:24:32,070] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.6562200e-01 1.8743645e-19 4.2316674e-13 2.5692104e-22 3.3437800e-01], sum to 1.0000
[2019-03-27 07:24:32,077] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6821
[2019-03-27 07:24:32,084] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.05, 72.5, 1.0, 2.0, 0.6180991003994055, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.950157150961792, 6.9112, 168.912685556163, 1728232.155842111, 1700594.656481703, 368356.9114183163], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6179400.0000, 
sim time next is 6180000.0000, 
raw observation next is [30.13333333333333, 72.0, 1.0, 2.0, 0.4042746713830006, 1.0, 1.0, 0.4042746713830006, 1.0, 2.0, 0.7005150883030248, 6.911200000000001, 6.9112, 170.5573041426782, 1695515.367094898, 1695515.367094897, 355045.1980369464], 
processed observation next is [1.0, 0.5217391304347826, 0.6271721958925749, 0.72, 1.0, 1.0, 0.28225864022048264, 1.0, 0.5, 0.28225864022048264, 1.0, 1.0, 0.6347744979305179, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.47097649085969384, 0.4709764908596936, 0.5299182060252932], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3204937], dtype=float32), 1.2491243]. 
=============================================
[2019-03-27 07:24:32,106] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[39.482624]
 [40.06015 ]
 [39.725174]
 [40.18501 ]
 [40.38665 ]], R is [[39.20904922]
 [38.81695938]
 [38.90050125]
 [38.86715698]
 [38.86899185]].
[2019-03-27 07:24:33,095] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0852130e-01 7.5885428e-16 3.4043827e-11 1.0563925e-18 8.9147872e-01], sum to 1.0000
[2019-03-27 07:24:33,104] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7928
[2019-03-27 07:24:33,110] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.55, 82.0, 1.0, 2.0, 0.5123464311918046, 1.0, 2.0, 0.5123464311918046, 1.0, 2.0, 0.8897763154262424, 6.9112, 6.9112, 170.5573041426782, 2149219.568894709, 2149219.568894709, 423788.4484832673], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6168600.0000, 
sim time next is 6169200.0000, 
raw observation next is [28.63333333333333, 81.33333333333333, 1.0, 2.0, 0.5131043776923326, 1.0, 2.0, 0.5131043776923326, 1.0, 2.0, 0.8910926178409215, 6.911199999999999, 6.9112, 170.5573041426782, 2152402.239848557, 2152402.239848558, 424325.8553386037], 
processed observation next is [1.0, 0.391304347826087, 0.55608214849921, 0.8133333333333332, 1.0, 1.0, 0.4133787683040152, 1.0, 1.0, 0.4133787683040152, 1.0, 1.0, 0.867186119318197, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5978895110690436, 0.5978895110690439, 0.6333221721471697], 
reward next is 0.3667, 
noisyNet noise sample is [array([1.105411], dtype=float32), 0.5343487]. 
=============================================
[2019-03-27 07:24:37,952] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9998105e-01 4.6218080e-20 2.2304605e-15 8.7909740e-22 1.8902816e-05], sum to 1.0000
[2019-03-27 07:24:37,958] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1689
[2019-03-27 07:24:37,966] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 921535.0152482406 W.
[2019-03-27 07:24:37,972] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.66666666666667, 87.50000000000001, 1.0, 2.0, 0.3297118727573257, 1.0, 1.0, 0.3297118727573257, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 921535.0152482406, 921535.0152482406, 255869.3873010556], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6592200.0000, 
sim time next is 6592800.0000, 
raw observation next is [26.73333333333334, 87.0, 1.0, 2.0, 0.6551886983058212, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 915617.8774526103, 915617.8774526109, 211468.8176178082], 
processed observation next is [1.0, 0.30434782608695654, 0.4660347551342816, 0.87, 1.0, 1.0, 0.5845646967540014, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25433829929239177, 0.25433829929239193, 0.3156251009221018], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.60495687], dtype=float32), 0.46587119]. 
=============================================
[2019-03-27 07:24:44,034] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 2.2656275e-38 0.0000000e+00 2.5452568e-36 1.5690865e-21], sum to 1.0000
[2019-03-27 07:24:44,047] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6563
[2019-03-27 07:24:44,054] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.76666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8691629898612516, 6.9112, 6.9112, 168.912956510431, 720124.2912340583, 720124.2912340583, 216485.1381322088], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6369600.0000, 
sim time next is 6370200.0000, 
raw observation next is [28.7, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8693535446250997, 6.911200000000001, 6.9112, 168.912956510431, 720145.3400570109, 720145.3400570103, 216523.278692775], 
processed observation next is [0.0, 0.7391304347826086, 0.5592417061611374, 0.735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8406750544208533, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20004037223805857, 0.20004037223805843, 0.3231690726757836], 
reward next is 0.6768, 
noisyNet noise sample is [array([0.49350902], dtype=float32), 0.31889513]. 
=============================================
[2019-03-27 07:24:55,400] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 07:24:55,404] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:24:55,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:24:55,407] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:24:55,408] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:24:55,410] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:24:55,410] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:24:55,412] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:24:55,413] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:24:55,414] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:24:55,415] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:24:55,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run59
[2019-03-27 07:24:55,455] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run59
[2019-03-27 07:24:55,457] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run59
[2019-03-27 07:24:55,458] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run59
[2019-03-27 07:24:55,475] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run59
[2019-03-27 07:25:06,445] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:25:06,446] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [24.92727155333333, 54.92357103333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5880288200216877, 6.9112, 6.9112, 168.912956510431, 522474.002712474, 522474.002712474, 163912.3404458089]
[2019-03-27 07:25:06,447] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:25:06,451] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 4.2346919e-36 4.4736281e-37 4.0927444e-34 1.0607948e-20], sampled 0.4477095245768793
[2019-03-27 07:25:29,487] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:25:29,490] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.95, 70.5, 1.0, 2.0, 0.8209997552999065, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.985639743952071, 6.9112, 168.9117721310336, 2044463.799777038, 1991654.053691754, 413838.189664955]
[2019-03-27 07:25:29,491] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:25:29,495] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.3010980e-01 6.3209414e-15 5.0478571e-10 3.8191583e-16 6.9890276e-02], sampled 0.910551516173648
[2019-03-27 07:25:29,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2044463.799777038 W.
[2019-03-27 07:25:30,959] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:25:30,961] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.35, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7142674134357135, 6.911199999999998, 6.9112, 168.912956510431, 610409.9329878849, 610409.932987886, 185313.4400443949]
[2019-03-27 07:25:30,961] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:25:30,964] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.5584922e-35 1.0714133e-35 2.1641679e-33 2.8320322e-19], sampled 0.8711216461188452
[2019-03-27 07:26:10,203] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:10,203] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.91419503666667, 85.69421030000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8629475605787783, 6.911200000000001, 6.9112, 168.912956510431, 718327.1846366618, 718327.1846366612, 215201.8649039323]
[2019-03-27 07:26:10,205] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:26:10,208] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.1186153e-32 9.7377999e-32 2.7040393e-31 5.3807022e-16], sampled 0.9447620150503635
[2019-03-27 07:26:11,032] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:11,033] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.0, 84.0, 1.0, 1.0, 0.6426637229467688, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9127701283085, 898106.9833025979, 898106.9833025986, 208962.2352847485]
[2019-03-27 07:26:11,036] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:26:11,038] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.9627798e-23 1.6042580e-20 2.0098398e-23 5.2112066e-09], sampled 0.6648254657675112
[2019-03-27 07:26:11,039] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 898106.9833025979 W.
[2019-03-27 07:26:17,726] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:17,727] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.2, 94.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.120777082443208, 6.9112, 168.9116720038696, 977538.9964508297, 828858.9317322943, 254812.750010308]
[2019-03-27 07:26:17,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:26:17,732] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.6626038e-24 1.1427072e-22 9.5407536e-24 6.6395084e-11], sampled 0.5139413936262207
[2019-03-27 07:26:17,734] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 977538.9964508297 W.
[2019-03-27 07:26:26,362] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:26,362] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.04617254, 82.49751090166667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.026694656059945, 6.9112, 6.9112, 168.9127757404959, 827525.5017868023, 827525.5017868023, 254018.0738803342]
[2019-03-27 07:26:26,363] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:26:26,365] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.3218995e-35 4.6179103e-36 7.9662683e-34 7.2872885e-19], sampled 0.7148199022935202
[2019-03-27 07:26:27,194] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:27,195] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.52162176, 91.91088113, 1.0, 1.0, 0.5957635173644448, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128861981451, 832539.3941282217, 832539.3941282224, 199957.4922825898]
[2019-03-27 07:26:27,196] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:26:27,200] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.7221840e-32 7.8606558e-31 4.7954541e-31 2.6644652e-15], sampled 0.5417539602789498
[2019-03-27 07:26:35,226] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.0266023], dtype=float32), 0.06671819]
[2019-03-27 07:26:35,226] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.2, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7186895330775147, 6.9112, 6.9112, 168.912956510431, 613015.4431024941, 613015.4431024941, 186120.9043025888]
[2019-03-27 07:26:35,228] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:26:35,231] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 1.61888155e-37 2.69370343e-38 1.18495154e-35
 8.37756811e-21], sampled 0.28442190033707326
[2019-03-27 07:26:50,109] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7273.4829 3321484701.4069 2015.0000
[2019-03-27 07:26:50,919] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7901.3825 2993719890.7962 1440.0000
[2019-03-27 07:26:51,018] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7344.8077 3111021152.4631 1791.0000
[2019-03-27 07:26:51,103] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8078.7756 2942385614.8839 1210.0000
[2019-03-27 07:26:51,128] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7019.4680 3190696784.4911 2258.0000
[2019-03-27 07:26:52,147] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1450000, evaluation results [1450000.0, 7273.4829282427, 3321484701.40695, 2015.0, 7344.807746019834, 3111021152.4631205, 1791.0, 8078.775590564955, 2942385614.883864, 1210.0, 7019.468022434773, 3190696784.4911284, 2258.0, 7901.382514137626, 2993719890.7961607, 1440.0]
[2019-03-27 07:26:53,716] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.6192048e-27 2.3895381e-25 2.5920756e-27 5.6416743e-11], sum to 1.0000
[2019-03-27 07:26:53,726] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0828
[2019-03-27 07:26:53,730] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.85, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8528660420582738, 6.911199999999999, 6.9112, 168.912956510431, 714060.8127822543, 714060.812782255, 213081.9379972114], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6672600.0000, 
sim time next is 6673200.0000, 
raw observation next is [24.93333333333334, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8571695702174362, 6.911199999999999, 6.9112, 168.912956510431, 717065.2541081898, 717065.2541081905, 214017.2506845474], 
processed observation next is [1.0, 0.21739130434782608, 0.3807266982622437, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8258165490456539, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19918479280783052, 0.19918479280783072, 0.31942873236499614], 
reward next is 0.6806, 
noisyNet noise sample is [array([-0.7847078], dtype=float32), 0.6754391]. 
=============================================
[2019-03-27 07:27:01,809] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.9335770e-35 9.1090150e-34 1.8810079e-33 5.2595856e-17], sum to 1.0000
[2019-03-27 07:27:01,821] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4626
[2019-03-27 07:27:01,828] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333334, 69.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6576475977302179, 6.911200000000001, 6.9112, 168.912956510431, 567287.1956160339, 567287.1956160332, 175366.4391452997], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6731400.0000, 
sim time next is 6732000.0000, 
raw observation next is [25.7, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.653693466067328, 6.9112, 6.9112, 168.912956510431, 564494.007154932, 564494.007154932, 174700.1841420482], 
processed observation next is [1.0, 0.9565217391304348, 0.4170616113744076, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5776749586186927, 0.0, 0.0, 0.8294399451523027, 0.15680389087637, 0.15680389087637, 0.26074654349559434], 
reward next is 0.7393, 
noisyNet noise sample is [array([-0.11817007], dtype=float32), 0.37719086]. 
=============================================
[2019-03-27 07:27:01,847] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[71.02368 ]
 [71.41565 ]
 [71.55524 ]
 [72.00876 ]
 [72.162224]], R is [[70.91995239]
 [70.94901276]
 [70.97663116]
 [71.00244904]
 [71.02648163]].
[2019-03-27 07:27:04,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.6387177e-33 4.5043966e-31 9.0414482e-32 2.4752975e-15], sum to 1.0000
[2019-03-27 07:27:04,245] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0167
[2019-03-27 07:27:04,252] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.16666666666666, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9361501246956454, 6.9112, 6.9112, 168.912956510431, 791467.3507146196, 791467.3507146196, 232524.6439435089], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7103400.0000, 
sim time next is 7104000.0000, 
raw observation next is [24.33333333333333, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8600971675034119, 6.9112, 6.9112, 168.912956510431, 727061.4753997443, 727061.4753997443, 214822.3285789675], 
processed observation next is [1.0, 0.21739130434782608, 0.35229067930489716, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8293867896383073, 0.0, 0.0, 0.8294399451523027, 0.20196152094437342, 0.20196152094437342, 0.32063034116263806], 
reward next is 0.6794, 
noisyNet noise sample is [array([-0.85046023], dtype=float32), 1.6732264]. 
=============================================
[2019-03-27 07:27:04,261] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[67.28407 ]
 [67.311424]
 [67.05251 ]
 [67.03426 ]
 [67.183205]], R is [[67.67749023]
 [67.65366364]
 [67.65367889]
 [67.63520813]
 [67.61322021]].
[2019-03-27 07:27:12,028] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.0162446e-36 1.2104118e-36 7.0415027e-35 4.2942817e-20], sum to 1.0000
[2019-03-27 07:27:12,035] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7033
[2019-03-27 07:27:12,039] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.65, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7164855675122427, 6.911200000000001, 6.9112, 168.912956510431, 611712.3635586941, 611712.3635586936, 185718.0662160471], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6929400.0000, 
sim time next is 6930000.0000, 
raw observation next is [23.6, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7154702725538201, 6.911200000000001, 6.9112, 168.912956510431, 610895.9947022655, 610895.9947022649, 185531.8465880346], 
processed observation next is [0.0, 0.21739130434782608, 0.3175355450236968, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6530125275046585, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1696933318617404, 0.16969333186174024, 0.2769132038627382], 
reward next is 0.7231, 
noisyNet noise sample is [array([-0.43861663], dtype=float32), 0.3379772]. 
=============================================
[2019-03-27 07:27:12,055] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[75.26177 ]
 [75.24097 ]
 [75.335365]
 [75.3016  ]
 [75.35806 ]], R is [[75.33786011]
 [75.30728912]
 [75.27667999]
 [75.24606323]
 [75.21568298]].
[2019-03-27 07:27:17,418] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 4.3332772e-37 0.0000000e+00 1.8653286e-35 5.0269604e-21], sum to 1.0000
[2019-03-27 07:27:17,425] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4524
[2019-03-27 07:27:17,432] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.71666666666667, 74.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7504178982130156, 6.9112, 6.9112, 168.912956510431, 636186.8733373553, 636186.8733373553, 192072.8452786282], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6994200.0000, 
sim time next is 6994800.0000, 
raw observation next is [26.6, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7544853577058481, 6.9112, 6.9112, 168.912956510431, 639089.9337824238, 639089.9337824238, 192852.9637082348], 
processed observation next is [0.0, 1.0, 0.4597156398104266, 0.76, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7005918996412782, 0.0, 0.0, 0.8294399451523027, 0.17752498160622884, 0.17752498160622884, 0.287840244340649], 
reward next is 0.7122, 
noisyNet noise sample is [array([1.4185417], dtype=float32), 1.5733336]. 
=============================================
[2019-03-27 07:27:21,600] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999988e-01 2.9706403e-26 2.3956397e-21 5.4286086e-26 1.5773209e-07], sum to 1.0000
[2019-03-27 07:27:21,611] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0740
[2019-03-27 07:27:21,616] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9655430119188996, 6.911199999999999, 6.9112, 168.912956510431, 805342.9971687314, 805342.997168732, 239522.5693653935], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7182000.0000, 
sim time next is 7182600.0000, 
raw observation next is [25.8, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.103157606139405, 6.9112, 168.9119072177608, 995401.9841788327, 859221.4976753897, 256230.3792985404], 
processed observation next is [1.0, 0.13043478260869565, 0.42180094786729866, 0.8916666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01919576061394048, 0.0, 0.8294347926449238, 0.27650055116078687, 0.23867263824316381, 0.38243340193812003], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.72946966], dtype=float32), -0.32034525]. 
=============================================
[2019-03-27 07:27:22,305] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.0713516e-30 1.1454888e-27 3.3435838e-29 2.9455546e-12], sum to 1.0000
[2019-03-27 07:27:22,311] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6982
[2019-03-27 07:27:22,317] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.4, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8494342388777002, 6.9112, 6.9112, 168.912956510431, 716214.6686024172, 716214.6686024172, 212434.7577304188], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7097400.0000, 
sim time next is 7098000.0000, 
raw observation next is [24.36666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8336690724525154, 6.9112, 6.9112, 168.912956510431, 703030.7176296968, 703030.7176296968, 209009.571351118], 
processed observation next is [1.0, 0.13043478260869565, 0.3538704581358612, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7971574054298968, 0.0, 0.0, 0.8294399451523027, 0.19528631045269357, 0.19528631045269357, 0.3119545841061463], 
reward next is 0.6880, 
noisyNet noise sample is [array([-0.9081393], dtype=float32), -1.2249998]. 
=============================================
[2019-03-27 07:27:22,348] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[63.25196 ]
 [62.663826]
 [61.367813]
 [60.84093 ]
 [57.675697]], R is [[63.23150253]
 [63.28212357]
 [63.32689285]
 [63.34475708]
 [63.36644363]].
[2019-03-27 07:27:25,810] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.8612682e-01 1.8075958e-18 4.5108205e-12 4.6221434e-20 1.1387325e-01], sum to 1.0000
[2019-03-27 07:27:25,821] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5276
[2019-03-27 07:27:25,829] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1393794.499899487 W.
[2019-03-27 07:27:25,833] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.43333333333333, 63.66666666666666, 1.0, 2.0, 0.319168033109153, 1.0, 2.0, 0.319168033109153, 1.0, 2.0, 0.5462632860486226, 6.9112, 6.9112, 170.5573041426782, 1393794.499899487, 1393794.499899487, 316824.6032905725], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7318200.0000, 
sim time next is 7318800.0000, 
raw observation next is [27.4, 64.0, 1.0, 2.0, 0.4778053076723496, 1.0, 2.0, 0.4778053076723496, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1400604.094144174, 1400604.094144175, 301092.6671015241], 
processed observation next is [1.0, 0.7391304347826086, 0.4976303317535545, 0.64, 1.0, 1.0, 0.37084976827993926, 1.0, 1.0, 0.37084976827993926, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.38905669281782607, 0.3890566928178264, 0.44939204045003595], 
reward next is 0.5506, 
noisyNet noise sample is [array([-2.1030898], dtype=float32), 2.4100072]. 
=============================================
[2019-03-27 07:27:27,768] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999642e-01 2.6626782e-22 3.7895936e-18 1.5416336e-22 3.5582032e-06], sum to 1.0000
[2019-03-27 07:27:27,784] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1915
[2019-03-27 07:27:27,789] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 89.66666666666667, 1.0, 1.0, 0.1984642998070724, 1.0, 1.0, 0.1984642998070724, 1.0, 2.0, 0.3353341275287827, 6.9112, 6.9112, 170.5573041426782, 832018.1357176555, 832018.1357176555, 268915.4204245535], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7184400.0000, 
sim time next is 7185000.0000, 
raw observation next is [25.8, 89.83333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9619971217022854, 6.9112, 6.9112, 168.9129564923243, 797636.1427663008, 797636.1427663008, 238479.6534476888], 
processed observation next is [1.0, 0.13043478260869565, 0.42180094786729866, 0.8983333333333333, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9536550264662017, 0.0, 0.0, 0.8294399450633905, 0.22156559521286134, 0.22156559521286134, 0.35593978126520714], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.41205364], dtype=float32), -1.3035015]. 
=============================================
[2019-03-27 07:27:27,805] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[54.036514]
 [57.737175]
 [57.051376]
 [62.252876]
 [59.979523]], R is [[55.4004631 ]
 [54.84645844]
 [54.29799271]
 [54.38550186]
 [53.8416481 ]].
[2019-03-27 07:27:28,299] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [5.1607555e-01 2.3919365e-19 1.4277075e-12 4.9303543e-21 4.8392445e-01], sum to 1.0000
[2019-03-27 07:27:28,306] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4903
[2019-03-27 07:27:28,318] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1771206.665474072 W.
[2019-03-27 07:27:28,325] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.1, 62.0, 1.0, 2.0, 0.4223074223509461, 1.0, 2.0, 0.4223074223509461, 1.0, 2.0, 0.7142125363388157, 6.9112, 6.9112, 170.5573041426782, 1771206.665474072, 1771206.665474072, 362664.4152557999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7646400.0000, 
sim time next is 7647000.0000, 
raw observation next is [30.16666666666667, 61.66666666666667, 1.0, 2.0, 0.6322292284480023, 1.0, 2.0, 0.6322292284480023, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1767759.321682065, 1767759.321682065, 346451.0968905804], 
processed observation next is [1.0, 0.5217391304347826, 0.6287519747235389, 0.6166666666666667, 1.0, 1.0, 0.5569026848771113, 1.0, 1.0, 0.5569026848771113, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.49104425602279583, 0.49104425602279583, 0.517091189388926], 
reward next is 0.4829, 
noisyNet noise sample is [array([-0.7846604], dtype=float32), 0.025800765]. 
=============================================
[2019-03-27 07:27:28,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[53.944904]
 [53.81763 ]
 [52.29495 ]
 [51.917274]
 [51.074413]], R is [[54.15794373]
 [54.07507324]
 [54.01228333]
 [53.94834518]
 [53.8719635 ]].
[2019-03-27 07:27:34,569] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999344e-01 5.3420782e-22 3.0533698e-16 1.0883852e-22 6.5556742e-06], sum to 1.0000
[2019-03-27 07:27:34,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1967
[2019-03-27 07:27:34,589] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1022049.545166462 W.
[2019-03-27 07:27:34,593] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [24.13333333333333, 76.0, 1.0, 2.0, 0.2230956285051817, 1.0, 1.0, 0.2230956285051817, 1.0, 2.0, 0.3941849689999336, 6.9112, 6.9112, 170.5573041426782, 1022049.545166462, 1022049.545166462, 286029.6017693758], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7291200.0000, 
sim time next is 7291800.0000, 
raw observation next is [24.35, 75.0, 1.0, 2.0, 0.3494349264016944, 1.0, 2.0, 0.3494349264016944, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1067616.514586528, 1067616.514586528, 270929.5947200408], 
processed observation next is [1.0, 0.391304347826087, 0.35308056872037924, 0.75, 1.0, 1.0, 0.21618665831529443, 1.0, 1.0, 0.21618665831529443, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.29656014294070226, 0.29656014294070226, 0.4043725294328967], 
reward next is 0.5956, 
noisyNet noise sample is [array([-1.6080104], dtype=float32), -1.0701712]. 
=============================================
[2019-03-27 07:27:38,810] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 3.3228443e-37 3.9049289e-38 4.5476542e-35 3.7753602e-21], sum to 1.0000
[2019-03-27 07:27:38,821] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7993
[2019-03-27 07:27:38,829] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.51666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5962781562913118, 6.911199999999999, 6.9112, 168.912956510431, 519165.1105835736, 519165.1105835743, 165515.8878949178], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7456200.0000, 
sim time next is 7456800.0000, 
raw observation next is [21.53333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5978241981574193, 6.911200000000001, 6.9112, 168.912956510431, 520405.6269740293, 520405.6269740287, 165751.7549311134], 
processed observation next is [0.0, 0.30434782608695654, 0.21958925750394942, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5095417050700235, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14455711860389703, 0.14455711860389686, 0.24739067900166178], 
reward next is 0.7526, 
noisyNet noise sample is [array([-0.6917266], dtype=float32), 0.43824196]. 
=============================================
[2019-03-27 07:27:40,334] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:27:40,336] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:40,401] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run8
[2019-03-27 07:27:46,072] A3C_AGENT_WORKER-Thread-12 INFO:Evaluating...
[2019-03-27 07:27:46,073] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:27:46,074] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:27:46,074] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,075] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:27:46,077] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,079] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,078] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:27:46,081] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:27:46,084] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,084] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run60
[2019-03-27 07:27:46,130] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run60
[2019-03-27 07:27:46,153] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run60
[2019-03-27 07:27:46,153] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run60
[2019-03-27 07:27:46,154] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run60
[2019-03-27 07:27:46,513] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:27:46,513] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:27:46,516] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run8
[2019-03-27 07:27:59,167] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:27:59,168] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.96323585, 74.73996123, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7115902405364649, 6.9112, 6.9112, 168.912956510431, 606573.3779189101, 606573.3779189101, 184816.4811987551]
[2019-03-27 07:27:59,169] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:27:59,171] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 1.72086716e-36 1.19609115e-36 1.50793575e-34
 6.01701453e-20], sampled 0.6642942330645611
[2019-03-27 07:28:04,534] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:28:04,534] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.05, 37.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6063975278820813, 6.9112, 6.9112, 168.912956510431, 545479.511433768, 545479.511433768, 166188.9359650941]
[2019-03-27 07:28:04,535] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:28:04,540] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.6727880e-36 6.1182508e-36 5.7621034e-34 1.8583905e-19], sampled 0.7395966608768298
[2019-03-27 07:28:35,188] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:28:35,190] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.69863345333333, 81.86234965333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.787056443492798, 6.9112, 6.9112, 168.912956510431, 666748.893636893, 666748.893636893, 199314.4603206249]
[2019-03-27 07:28:35,192] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:28:35,197] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.0041218e-37 5.7215514e-37 7.6443207e-36 5.8546520e-19], sampled 0.521680735203522
[2019-03-27 07:28:38,102] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:28:38,103] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.36550935, 78.54677682, 1.0, 2.0, 0.7609857793522551, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1063541.987327651, 1063541.987327651, 234561.7882525972]
[2019-03-27 07:28:38,104] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:28:38,109] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.7531688e-01 5.0873384e-17 3.0341438e-11 2.6212746e-18 2.4683084e-02], sampled 0.915127204918251
[2019-03-27 07:28:38,110] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1063541.987327651 W.
[2019-03-27 07:28:44,535] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:28:44,536] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.80335893333334, 78.06566559000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9165041741221254, 6.911200000000001, 6.9112, 168.912956510431, 751724.0544225937, 751724.054422593, 227105.0721906847]
[2019-03-27 07:28:44,537] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:28:44,539] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 6.7504127e-29 1.5848139e-25 4.9065963e-29 2.9705857e-10], sampled 0.5001294847009259
[2019-03-27 07:29:01,563] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:29:01,568] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.71666666666667, 84.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.080330802498675, 6.9112, 168.9118843605869, 948834.1854799851, 828847.7347554136, 254812.7782425956]
[2019-03-27 07:29:01,569] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:29:01,573] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999857e-01 2.5543576e-21 1.0833071e-17 1.7137046e-21 1.3763098e-06], sampled 0.023027947991283382
[2019-03-27 07:29:01,574] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 948834.1854799851 W.
[2019-03-27 07:29:10,578] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:29:10,579] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.91666666666667, 56.16666666666666, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.071970620796242, 6.9112, 168.9119243139986, 942900.9351171661, 828845.4204033985, 254812.6479812103]
[2019-03-27 07:29:10,580] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:29:10,584] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 9.7986099e-25 9.1149800e-22 3.5060734e-24 6.8965506e-10], sampled 0.884125820325752
[2019-03-27 07:29:10,586] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 942900.9351171661 W.
[2019-03-27 07:29:24,879] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02666834], dtype=float32), 0.0689089]
[2019-03-27 07:29:24,881] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.15477115, 59.70444775, 1.0, 2.0, 0.690587092826442, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1035077.736651294, 1035077.736651294, 227843.3512096009]
[2019-03-27 07:29:24,882] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:29:24,884] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9994957e-01 4.5155838e-20 5.6209500e-15 7.1849772e-21 5.0424340e-05], sampled 0.960269575453038
[2019-03-27 07:29:24,886] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1035077.736651294 W.
[2019-03-27 07:29:41,559] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8073.6140 2941865384.4275 1204.0000
[2019-03-27 07:29:41,726] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7274.2253 3319652424.5709 2026.0000
[2019-03-27 07:29:41,793] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7345.9165 3110594997.1106 1801.0000
[2019-03-27 07:29:41,819] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.9509 2991604355.1865 1427.0000
[2019-03-27 07:29:41,993] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7048.9399 3187607658.0193 2174.0000
[2019-03-27 07:29:43,009] A3C_AGENT_WORKER-Thread-12 INFO:Global step: 1475000, evaluation results [1475000.0, 7274.225314959521, 3319652424.5708885, 2026.0, 7345.9165087779265, 3110594997.1106043, 1801.0, 8073.614040009433, 2941865384.427469, 1204.0, 7048.939890080727, 3187607658.019339, 2174.0, 7915.950895509772, 2991604355.186511, 1427.0]
[2019-03-27 07:29:44,673] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.0727915e-35 4.3807641e-36 1.6130340e-34 4.7398855e-19], sum to 1.0000
[2019-03-27 07:29:44,680] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5064
[2019-03-27 07:29:44,686] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666667, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7731678482141537, 6.9112, 6.9112, 168.912956510431, 648895.9474373192, 648895.9474373192, 196421.7053922506], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7572000.0000, 
sim time next is 7572600.0000, 
raw observation next is [29.5, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7656674338273417, 6.9112, 6.9112, 168.912956510431, 643735.1257590854, 643735.1257590854, 194961.0934932542], 
processed observation next is [0.0, 0.6521739130434783, 0.5971563981042655, 0.62, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7142285778382216, 0.0, 0.0, 0.8294399451523027, 0.17881531271085704, 0.17881531271085704, 0.2909867067063495], 
reward next is 0.7090, 
noisyNet noise sample is [array([1.1500567], dtype=float32), -0.052401353]. 
=============================================
[2019-03-27 07:29:50,586] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:29:50,587] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:29:50,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run8
[2019-03-27 07:29:51,782] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.00000000e+00 1.35799401e-35 1.04469535e-35 1.56332265e-34
 1.33656055e-16], sum to 1.0000
[2019-03-27 07:29:51,792] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-27 07:29:51,801] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.85, 84.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8608016480535617, 6.9112, 6.9112, 168.912956510431, 713360.5735815706, 713360.5735815706, 214625.4222231354], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7672200.0000, 
sim time next is 7672800.0000, 
raw observation next is [26.7, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8589044774642735, 6.9112, 6.9112, 168.912956510431, 712035.0144809416, 712035.0144809416, 214212.9362241737], 
processed observation next is [1.0, 0.8260869565217391, 0.46445497630331756, 0.8566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8279322895905773, 0.0, 0.0, 0.8294399451523027, 0.19778750402248377, 0.19778750402248377, 0.3197208003345876], 
reward next is 0.6803, 
noisyNet noise sample is [array([0.8391605], dtype=float32), 0.34901986]. 
=============================================
[2019-03-27 07:29:55,266] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.6957225e-03 3.6907583e-18 1.2905027e-10 5.2028695e-21 9.9730432e-01], sum to 1.0000
[2019-03-27 07:29:55,277] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6566
[2019-03-27 07:29:55,283] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.03333333333333, 75.66666666666667, 1.0, 2.0, 0.4677755939003634, 1.0, 2.0, 0.4677755939003634, 1.0, 2.0, 0.8069001955942284, 6.9112, 6.9112, 170.5573041426782, 1962080.096556378, 1962080.096556378, 392660.2821316578], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7723200.0000, 
sim time next is 7723800.0000, 
raw observation next is [29.25, 74.5, 1.0, 2.0, 0.4770926322364664, 1.0, 2.0, 0.4770926322364664, 1.0, 2.0, 0.8233117425988769, 6.911199999999999, 6.9112, 170.5573041426782, 2001196.821550614, 2001196.821550614, 398768.3184216072], 
processed observation next is [1.0, 0.391304347826087, 0.5853080568720379, 0.745, 1.0, 1.0, 0.3699911231764656, 1.0, 1.0, 0.3699911231764656, 1.0, 1.0, 0.7845265153644838, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5558880059862816, 0.5558880059862816, 0.5951765946591152], 
reward next is 0.4048, 
noisyNet noise sample is [array([0.19260164], dtype=float32), 0.32606152]. 
=============================================
[2019-03-27 07:29:59,205] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:29:59,206] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:29:59,460] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run8
[2019-03-27 07:30:01,133] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.5967317e-01 5.6139407e-21 1.4850065e-13 9.3629535e-23 4.0326793e-02], sum to 1.0000
[2019-03-27 07:30:01,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5987
[2019-03-27 07:30:01,154] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1607651.204182435 W.
[2019-03-27 07:30:01,160] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.575010376001337, 1.0, 2.0, 0.575010376001337, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1607651.204182435, 1607651.204182436, 325211.2085032222], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7821000.0000, 
sim time next is 7821600.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 7.903557259248116, 6.9112, 168.9074582918623, 2158226.674283974, 1454237.196300246, 311353.0959651952], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.09923572592481156, 0.0, 0.829412946382035, 0.599507409523326, 0.40395477675006836, 0.46470611338088835], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.54835004], dtype=float32), 1.3116384]. 
=============================================
[2019-03-27 07:30:02,371] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:02,371] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:02,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run8
[2019-03-27 07:30:03,994] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:03,995] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:04,073] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run8
[2019-03-27 07:30:04,276] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:04,277] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:04,340] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run8
[2019-03-27 07:30:05,436] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.4036163e-31 5.5369672e-26 4.4597038e-31 7.5493406e-10], sum to 1.0000
[2019-03-27 07:30:05,440] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0705
[2019-03-27 07:30:05,448] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.96666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8181677300556098, 6.911200000000001, 6.9112, 168.912956510431, 676670.2512573178, 676670.2512573171, 205363.344868659], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7926600.0000, 
sim time next is 7927200.0000, 
raw observation next is [29.8, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8309494406078825, 6.9112, 6.9112, 168.912956510431, 687066.6670211147, 687066.6670211147, 208068.3442024341], 
processed observation next is [1.0, 0.782608695652174, 0.6113744075829385, 0.68, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7938407812291248, 0.0, 0.0, 0.8294399451523027, 0.19085185195030965, 0.19085185195030965, 0.3105497674663195], 
reward next is 0.6895, 
noisyNet noise sample is [array([2.3026342], dtype=float32), 1.5553452]. 
=============================================
[2019-03-27 07:30:05,978] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:05,978] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:06,037] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run8
[2019-03-27 07:30:06,225] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 8.022783e-33 7.598583e-30 1.241901e-32 8.144513e-13], sum to 1.0000
[2019-03-27 07:30:06,236] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6834
[2019-03-27 07:30:06,239] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.56666666666667, 90.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8957366921380938, 6.9112, 6.9112, 168.912956510431, 736839.7747948368, 736839.7747948368, 222342.0878835999], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7944600.0000, 
sim time next is 7945200.0000, 
raw observation next is [26.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8952190753295616, 6.911200000000001, 6.9112, 168.912956510431, 736381.4693973575, 736381.469397357, 222221.2798239668], 
processed observation next is [1.0, 1.0, 0.4549763033175356, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8722183845482457, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20455040816593265, 0.20455040816593248, 0.33167355197606985], 
reward next is 0.6683, 
noisyNet noise sample is [array([-1.2266724], dtype=float32), 1.6067779]. 
=============================================
[2019-03-27 07:30:06,242] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:06,243] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:06,303] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run8
[2019-03-27 07:30:06,850] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:06,851] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:06,904] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run8
[2019-03-27 07:30:07,421] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,422] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,435] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,436] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,479] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run8
[2019-03-27 07:30:07,511] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run8
[2019-03-27 07:30:07,568] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,568] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,603] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run8
[2019-03-27 07:30:07,697] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,697] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run8
[2019-03-27 07:30:07,739] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run8
[2019-03-27 07:30:07,823] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:30:07,823] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:07,842] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run8
[2019-03-27 07:30:11,907] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [8.80242288e-01 1.02789302e-19 1.62379929e-13 4.41917405e-21
 1.19757645e-01], sum to 1.0000
[2019-03-27 07:30:11,916] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9739
[2019-03-27 07:30:11,920] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.6, 71.0, 1.0, 2.0, 0.5486493534812754, 1.0, 1.0, 0.5486493534812754, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1587320.811712343, 1587320.811712344, 322381.1388690427], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 61200.0000, 
sim time next is 61800.0000, 
raw observation next is [26.43333333333333, 71.66666666666667, 1.0, 2.0, 0.1785305191988764, 1.0, 2.0, 0.1785305191988764, 1.0, 1.0, 0.3041406462000024, 6.9112, 6.9112, 170.5573041426782, 774130.4890828267, 774130.4890828267, 267268.4487874801], 
processed observation next is [1.0, 0.7391304347826086, 0.4518167456556081, 0.7166666666666667, 1.0, 1.0, 0.01027773397454985, 1.0, 1.0, 0.01027773397454985, 1.0, 0.5, 0.15139103195122247, 0.0, 0.0, 0.8375144448122397, 0.21503624696745186, 0.21503624696745186, 0.39890813251862706], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.603522], dtype=float32), -0.8445724]. 
=============================================
[2019-03-27 07:30:12,483] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 6.0669800e-36 2.9976630e-35 1.1492932e-33 3.1901178e-21], sum to 1.0000
[2019-03-27 07:30:12,489] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4845
[2019-03-27 07:30:12,494] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.537306265388055, 6.911199999999999, 6.9112, 168.912956510431, 472137.6107390649, 472137.6107390655, 156969.5119925259], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 289800.0000, 
sim time next is 290400.0000, 
raw observation next is [22.16666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5380055548090554, 6.9112, 6.9112, 168.912956510431, 472652.8191173339, 472652.8191173339, 157067.0296691753], 
processed observation next is [0.0, 0.34782608695652173, 0.24960505529225935, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4365921400110432, 0.0, 0.0, 0.8294399451523027, 0.13129244975481497, 0.13129244975481497, 0.23442840249130642], 
reward next is 0.7656, 
noisyNet noise sample is [array([-0.03402664], dtype=float32), -1.00461]. 
=============================================
[2019-03-27 07:30:13,819] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7939678e-36 2.1378909e-21], sum to 1.0000
[2019-03-27 07:30:13,827] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3878
[2019-03-27 07:30:13,831] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.53333333333333, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.518552573718039, 6.9112, 6.9112, 168.912956510431, 457763.0814410559, 457763.0814410559, 154412.9022701014], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 255000.0000, 
sim time next is 255600.0000, 
raw observation next is [20.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5166665046132264, 6.9112, 6.9112, 168.912956510431, 456234.4313794903, 456234.4313794903, 154163.4154083558], 
processed observation next is [0.0, 1.0, 0.1706161137440759, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4105689080649102, 0.0, 0.0, 0.8294399451523027, 0.12673178649430286, 0.12673178649430286, 0.2300946498632176], 
reward next is 0.7699, 
noisyNet noise sample is [array([0.20076886], dtype=float32), 0.22736633]. 
=============================================
[2019-03-27 07:30:14,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.4471805e-38 1.8761945e-38 6.8713808e-36 4.9550696e-21], sum to 1.0000
[2019-03-27 07:30:14,944] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7655
[2019-03-27 07:30:14,949] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.63333333333334, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5539872608318478, 6.9112, 6.9112, 168.912956510431, 486341.1507683891, 486341.1507683891, 159271.6623282122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 233400.0000, 
sim time next is 234000.0000, 
raw observation next is [21.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5536599747599065, 6.911199999999999, 6.9112, 168.912956510431, 486206.4938149715, 486206.4938149721, 159221.3912455658], 
processed observation next is [0.0, 0.7391304347826086, 0.22274881516587688, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4556828960486664, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13505735939304764, 0.1350573593930478, 0.23764386753069525], 
reward next is 0.7624, 
noisyNet noise sample is [array([-1.2685165], dtype=float32), 0.1455839]. 
=============================================
[2019-03-27 07:30:14,967] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[80.7454 ]
 [80.72179]
 [80.69421]
 [80.65209]
 [80.59463]], R is [[80.79779816]
 [80.75210571]
 [80.7066803 ]
 [80.66130066]
 [80.61597443]].
[2019-03-27 07:30:16,446] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.2030893e-01 9.6343089e-20 2.5597033e-12 1.4423898e-21 7.7969104e-01], sum to 1.0000
[2019-03-27 07:30:16,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2355
[2019-03-27 07:30:16,458] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.8, 95.0, 1.0, 2.0, 0.2495028004991078, 1.0, 2.0, 0.2495028004991078, 1.0, 1.0, 0.4286707199380964, 6.9112, 6.9112, 170.5573041426782, 1095579.198522347, 1095579.198522347, 289925.8421092198], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 126000.0000, 
sim time next is 126600.0000, 
raw observation next is [22.8, 95.16666666666667, 1.0, 2.0, 0.3121509559704444, 1.0, 2.0, 0.3121509559704444, 1.0, 2.0, 0.5344717163615588, 6.9112, 6.9112, 170.5573041426782, 1363949.198915178, 1363949.198915178, 313830.7667994706], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.9516666666666667, 1.0, 1.0, 0.1712662120125836, 1.0, 1.0, 0.1712662120125836, 1.0, 1.0, 0.4322825809287302, 0.0, 0.0, 0.8375144448122397, 0.37887477747643833, 0.37887477747643833, 0.4684041295514486], 
reward next is 0.5316, 
noisyNet noise sample is [array([-0.7810782], dtype=float32), -1.002176]. 
=============================================
[2019-03-27 07:30:23,200] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 3.6803430e-36 2.1405827e-37 7.8691864e-36 6.6255404e-19], sum to 1.0000
[2019-03-27 07:30:23,208] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3461
[2019-03-27 07:30:23,213] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.66666666666667, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5688569855298272, 6.9112, 6.9112, 168.912956510431, 497159.140519501, 497159.140519501, 161435.2371408237], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 307200.0000, 
sim time next is 307800.0000, 
raw observation next is [23.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.570181177021866, 6.911199999999999, 6.9112, 168.912956510431, 498164.0132880309, 498164.0132880316, 161629.17512897], 
processed observation next is [0.0, 0.5652173913043478, 0.3222748815165877, 0.76, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4758307036852024, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1383788925800086, 0.1383788925800088, 0.2412375748193582], 
reward next is 0.7588, 
noisyNet noise sample is [array([1.3413705], dtype=float32), 0.15670249]. 
=============================================
[2019-03-27 07:30:31,667] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999666e-01 8.7553877e-25 2.5896277e-18 2.6163489e-25 3.3632350e-06], sum to 1.0000
[2019-03-27 07:30:31,674] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9268
[2019-03-27 07:30:31,682] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 946824.8541152526 W.
[2019-03-27 07:30:31,687] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.0, 82.0, 1.0, 2.0, 0.2972245834906485, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5387672563669587, 6.911199999999999, 6.9112, 168.912956510431, 946824.8541152526, 946824.8541152532, 231097.8686496843], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 406800.0000, 
sim time next is 407400.0000, 
raw observation next is [21.91666666666667, 81.83333333333334, 1.0, 2.0, 0.3525176609356603, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 563761.5262129023, 563761.5262129023, 172093.6331902997], 
processed observation next is [1.0, 0.7391304347826086, 0.23775671406003188, 0.8183333333333335, 1.0, 1.0, 0.21990079630802442, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.15660042394802842, 0.15660042394802842, 0.2568561689407458], 
reward next is 0.7431, 
noisyNet noise sample is [array([0.35182077], dtype=float32), 1.9498339]. 
=============================================
[2019-03-27 07:30:34,538] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.2045255e-34 6.9293873e-31 2.4662374e-32 2.0050083e-15], sum to 1.0000
[2019-03-27 07:30:34,548] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9730
[2019-03-27 07:30:34,555] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.78333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4227328471180814, 6.9112, 6.9112, 168.912956510431, 379870.5742341023, 379870.5742341023, 142835.3955875177], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 519000.0000, 
sim time next is 519600.0000, 
raw observation next is [18.76666666666667, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4213352835277946, 6.911200000000001, 6.9112, 168.912956510431, 378658.161109756, 378658.1611097553, 142688.2175878654], 
processed observation next is [1.0, 0.0, 0.08846761453396543, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.29431132137535926, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10518282253048777, 0.10518282253048758, 0.21296748893711254], 
reward next is 0.7870, 
noisyNet noise sample is [array([1.4128367], dtype=float32), -1.4485329]. 
=============================================
[2019-03-27 07:30:34,795] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-27 07:30:34,796] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:30:34,797] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:30:34,800] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:30:34,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:34,801] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:30:34,802] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:34,802] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:30:34,801] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:34,805] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:34,806] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:30:35,526] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run61
[2019-03-27 07:30:35,601] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run61
[2019-03-27 07:30:35,645] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run61
[2019-03-27 07:30:35,676] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run61
[2019-03-27 07:30:35,762] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run61
[2019-03-27 07:31:01,214] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:01,217] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.90102752, 82.04450187666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9847269447842785, 6.911200000000001, 6.9112, 168.912956510431, 795520.5498863641, 795520.5498863634, 243248.1981388417]
[2019-03-27 07:31:01,219] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:31:01,222] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3442680e-36 6.4819117e-21], sampled 0.7991048064657599
[2019-03-27 07:31:05,161] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:05,162] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.1, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.712997874339512, 6.911200000000001, 6.9112, 168.912956510431, 610380.8554621196, 610380.8554621189, 185083.6100375528]
[2019-03-27 07:31:05,166] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:31:05,168] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.7763123e-37 6.0507094e-36 8.2750727e-36 3.6967268e-18], sampled 0.06879329878576579
[2019-03-27 07:31:23,039] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:23,041] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.16588190333334, 92.38591598833335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6334692292644526, 6.911199999999999, 6.9112, 168.912956510431, 551693.7009247012, 551693.7009247018, 171320.1753052069]
[2019-03-27 07:31:23,043] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:31:23,048] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.7126343e-36 5.5202805e-35 2.2640079e-34 2.6333690e-18], sampled 0.06552490231624841
[2019-03-27 07:31:25,214] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:25,217] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.9, 57.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8738770816496247, 6.911200000000001, 6.9112, 168.912956510431, 723465.7122281936, 723465.7122281931, 217525.8552392235]
[2019-03-27 07:31:25,218] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:31:25,220] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.0107933e-37 4.8150004e-36 1.6052803e-35 4.8326365e-18], sampled 0.9600931050266284
[2019-03-27 07:31:28,658] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:28,660] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.13333333333333, 51.33333333333333, 1.0, 2.0, 0.6094458937308743, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.943432193552161, 6.9112, 168.9127287403823, 1704017.98624729, 1681151.389629319, 366318.4692399084]
[2019-03-27 07:31:28,662] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:31:28,664] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9272341e-01 4.6511314e-24 3.8291716e-17 2.3012202e-25 7.2765909e-03], sampled 0.6828949586620865
[2019-03-27 07:31:28,665] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1704017.98624729 W.
[2019-03-27 07:31:35,832] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:31:35,833] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.76591477333334, 94.198341615, 1.0, 2.0, 0.9260327904809409, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1294349.739206553, 1294349.739206553, 277197.6591227674]
[2019-03-27 07:31:35,834] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:31:35,839] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9860460e-01 6.5539903e-21 1.2262915e-15 1.1625992e-21 1.3954745e-03], sampled 0.875606956057597
[2019-03-27 07:31:35,841] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1294349.739206553 W.
[2019-03-27 07:32:00,113] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07152329]
[2019-03-27 07:32:00,115] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.59999999999999, 55.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8844935862179669, 6.9112, 6.9112, 168.912956510431, 728068.9514670399, 728068.9514670399, 219780.8661341064]
[2019-03-27 07:32:00,116] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:32:00,119] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.1221561e-36 3.4323043e-35 1.6293233e-34 9.3214776e-18], sampled 0.13793949809800665
[2019-03-27 07:32:31,854] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7902.0811 2990886022.5357 1475.0000
[2019-03-27 07:32:31,901] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7040.5547 3186320831.6701 2227.0000
[2019-03-27 07:32:32,014] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8059.9687 2939905600.0878 1255.0000
[2019-03-27 07:32:32,032] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7280.0002 3318984093.2431 2038.0000
[2019-03-27 07:32:32,053] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7345.7535 3108036300.1438 1857.0000
[2019-03-27 07:32:33,071] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1500000, evaluation results [1500000.0, 7280.000196564017, 3318984093.243051, 2038.0, 7345.75349020203, 3108036300.1438413, 1857.0, 8059.968703167862, 2939905600.087756, 1255.0, 7040.554681397654, 3186320831.670054, 2227.0, 7902.081099435029, 2990886022.535695, 1475.0]
[2019-03-27 07:32:36,149] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0550027e-37 4.4239232e-36 4.2196950e-36 8.8015177e-20], sum to 1.0000
[2019-03-27 07:32:36,160] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7450
[2019-03-27 07:32:36,166] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5376233712024568, 6.9112, 6.9112, 168.912956510431, 472648.2819308657, 472648.2819308657, 157004.9193751083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 907200.0000, 
sim time next is 907800.0000, 
raw observation next is [23.45, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.539169661235421, 6.911199999999999, 6.9112, 168.912956510431, 473890.9216368221, 473890.9216368227, 157217.7312298363], 
processed observation next is [0.0, 0.5217391304347826, 0.3104265402843602, 0.7333333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4380117819944158, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13163636712133947, 0.13163636712133964, 0.2346533301937855], 
reward next is 0.7653, 
noisyNet noise sample is [array([-1.9567556], dtype=float32), 0.81645435]. 
=============================================
[2019-03-27 07:32:37,278] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.3658658e-32 6.3675565e-29 1.5463678e-31 3.0864860e-15], sum to 1.0000
[2019-03-27 07:32:37,286] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8666
[2019-03-27 07:32:37,294] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.9, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3985584585167431, 6.911200000000001, 6.9112, 168.912956510431, 359379.3679825559, 359379.3679825553, 140315.6112380195], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 532800.0000, 
sim time next is 533400.0000, 
raw observation next is [17.85, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3934239091762417, 6.9112, 6.9112, 168.912956510431, 354842.9229105911, 354842.9229105911, 139816.1687200133], 
processed observation next is [1.0, 0.17391304347826086, 0.04502369668246459, 0.9016666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.26027305997102645, 0.0, 0.0, 0.8294399451523027, 0.0985674785862753, 0.0985674785862753, 0.20868084883584073], 
reward next is 0.7913, 
noisyNet noise sample is [array([-0.3146941], dtype=float32), -0.5731125]. 
=============================================
[2019-03-27 07:32:51,006] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.0765284e-31 3.6141077e-27 2.6236970e-30 1.0353723e-12], sum to 1.0000
[2019-03-27 07:32:51,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9861
[2019-03-27 07:32:51,022] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 870384.8047612701 W.
[2019-03-27 07:32:51,026] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.63333333333333, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001748867438129, 6.911200000000001, 6.9112, 168.9129365391514, 870384.8047612701, 870384.8047612695, 249041.9180118341], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 999600.0000, 
sim time next is 1000200.0000, 
raw observation next is [21.61666666666667, 95.83333333333333, 1.0, 1.0, 0.2865858799141833, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5091903121473871, 6.911200000000001, 6.9112, 168.912956510431, 882944.9823007962, 882944.9823007956, 224872.8371852337], 
processed observation next is [1.0, 0.5652173913043478, 0.22353870458135885, 0.9583333333333333, 1.0, 0.5, 0.14046491555925694, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4014516001797403, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2452624950835545, 0.24526249508355433, 0.3356311002764682], 
reward next is 0.6644, 
noisyNet noise sample is [array([1.4418734], dtype=float32), 1.8299118]. 
=============================================
[2019-03-27 07:32:53,541] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.9634990e-35 5.7370748e-35 1.7089181e-33 6.6321656e-19], sum to 1.0000
[2019-03-27 07:32:53,548] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.3284
[2019-03-27 07:32:53,552] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.01666666666667, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5276731002560157, 6.9112, 6.9112, 168.912956510431, 464791.6358541474, 464791.6358541474, 155645.100150721], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 813000.0000, 
sim time next is 813600.0000, 
raw observation next is [24.2, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292231497389421, 6.9112, 6.9112, 168.912956510431, 466062.1251034748, 466062.1251034748, 155853.7274504398], 
processed observation next is [0.0, 0.43478260869565216, 0.3459715639810427, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42588188992553916, 0.0, 0.0, 0.8294399451523027, 0.12946170141763189, 0.12946170141763189, 0.23261750365737283], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.33058104], dtype=float32), -1.4684665]. 
=============================================
[2019-03-27 07:32:56,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.7400096e-36 4.5471882e-34 1.3182399e-32 5.0869060e-17], sum to 1.0000
[2019-03-27 07:32:56,487] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0432
[2019-03-27 07:32:56,493] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.93333333333333, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5699661657385768, 6.911199999999999, 6.9112, 168.912956510431, 497794.5797429986, 497794.5797429992, 161602.3491272733], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 925800.0000, 
sim time next is 926400.0000, 
raw observation next is [23.86666666666667, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767204453737864, 6.9112, 6.9112, 168.912956510431, 503540.6873273705, 503540.6873273705, 162584.0264821013], 
processed observation next is [0.0, 0.7391304347826086, 0.33017377567140627, 0.7533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4838054211875444, 0.0, 0.0, 0.8294399451523027, 0.13987241314649182, 0.13987241314649182, 0.2426627260926885], 
reward next is 0.7573, 
noisyNet noise sample is [array([0.5813077], dtype=float32), -1.6213626]. 
=============================================
[2019-03-27 07:33:05,180] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.0364040e-32 3.5307238e-27 1.9327846e-31 4.9325957e-11], sum to 1.0000
[2019-03-27 07:33:05,184] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6890
[2019-03-27 07:33:05,189] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.06666666666667, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6543514988466458, 6.911200000000001, 6.9112, 168.912956510431, 564311.300097655, 564311.3000976543, 174815.6791246153], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1034400.0000, 
sim time next is 1035000.0000, 
raw observation next is [22.1, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6548948975354306, 6.9112, 6.9112, 168.912956510431, 564686.0933807458, 564686.0933807458, 174907.0575510617], 
processed observation next is [1.0, 1.0, 0.24644549763033188, 0.975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5791401189456471, 0.0, 0.0, 0.8294399451523027, 0.1568572481613183, 0.1568572481613183, 0.261055309777704], 
reward next is 0.7389, 
noisyNet noise sample is [array([0.77892554], dtype=float32), 0.607375]. 
=============================================
[2019-03-27 07:33:05,198] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.861885]
 [76.83622 ]
 [76.77369 ]
 [76.69648 ]
 [76.66339 ]], R is [[76.85142517]
 [76.82199097]
 [76.79311371]
 [76.76522827]
 [76.73977661]].
[2019-03-27 07:33:06,446] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.7927929e-31 5.2718293e-28 2.6139267e-30 2.4453623e-12], sum to 1.0000
[2019-03-27 07:33:06,454] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5942
[2019-03-27 07:33:06,463] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.85, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5568144087775558, 6.9112, 6.9112, 168.912956510431, 488194.5129736612, 488194.5129736612, 159685.399976887], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1065000.0000, 
sim time next is 1065600.0000, 
raw observation next is [20.9, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5619427961256707, 6.9112, 6.9112, 168.912956510431, 492449.6841941559, 492449.6841941559, 160414.9690607733], 
processed observation next is [1.0, 0.34782608695652173, 0.1895734597156398, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4657838977142325, 0.0, 0.0, 0.8294399451523027, 0.1367915789428211, 0.1367915789428211, 0.23942532695637805], 
reward next is 0.7606, 
noisyNet noise sample is [array([-0.4048004], dtype=float32), 1.004968]. 
=============================================
[2019-03-27 07:33:11,640] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 2.4675467e-31 1.1663908e-25 2.9619317e-31 1.0322362e-10], sum to 1.0000
[2019-03-27 07:33:11,652] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5929
[2019-03-27 07:33:11,659] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.18333333333334, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8048741532787269, 6.911199999999999, 6.9112, 168.912956510431, 687380.1757642854, 687380.175764286, 203018.6272731386], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1324200.0000, 
sim time next is 1324800.0000, 
raw observation next is [23.1, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7618063120621844, 6.911200000000001, 6.9112, 168.912956510431, 651081.9185339112, 651081.9185339105, 194327.0846183484], 
processed observation next is [1.0, 0.34782608695652173, 0.2938388625592418, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7095198927587614, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.180856088481642, 0.1808560884816418, 0.29004042480350506], 
reward next is 0.7100, 
noisyNet noise sample is [array([0.38713196], dtype=float32), 2.7671995]. 
=============================================
[2019-03-27 07:33:21,093] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 4.2190502e-29 5.6012339e-25 2.7346342e-28 6.4117855e-10], sum to 1.0000
[2019-03-27 07:33:21,103] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4879
[2019-03-27 07:33:21,108] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.43333333333334, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7510345272425681, 6.911199999999999, 6.9112, 168.912956510431, 634802.0317618322, 634802.0317618328, 192166.8348225978], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1315200.0000, 
sim time next is 1315800.0000, 
raw observation next is [24.35, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7491005171624614, 6.9112, 6.9112, 168.912956510431, 633474.8924364913, 633474.8924364913, 191798.4828837331], 
processed observation next is [1.0, 0.21739130434782608, 0.35308056872037924, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.694025020929831, 0.0, 0.0, 0.8294399451523027, 0.17596524789902537, 0.17596524789902537, 0.2862663923637807], 
reward next is 0.7137, 
noisyNet noise sample is [array([-1.2319456], dtype=float32), -1.5308826]. 
=============================================
[2019-03-27 07:33:25,605] A3C_AGENT_WORKER-Thread-15 INFO:Evaluating...
[2019-03-27 07:33:25,607] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:33:25,609] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:33:25,609] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:33:25,610] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:33:25,610] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:33:25,612] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:33:25,613] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:33:25,615] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:33:25,617] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:33:25,617] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:33:25,639] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run62
[2019-03-27 07:33:25,661] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run62
[2019-03-27 07:33:25,685] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run62
[2019-03-27 07:33:25,686] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run62
[2019-03-27 07:33:25,705] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run62
[2019-03-27 07:33:33,807] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:33:33,808] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [18.642152165, 83.967758745, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3931269780661161, 6.9112, 6.9112, 168.912956510431, 355384.6561098967, 355384.6561098967, 139705.7112496787]
[2019-03-27 07:33:33,809] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:33:33,812] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.2016200e-35 3.8133896e-33 1.2794713e-33 6.1416235e-17], sampled 0.022126368919679895
[2019-03-27 07:34:00,441] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:00,444] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.0857302, 76.37271249, 1.0, 2.0, 0.6319231814987404, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 883091.0963419885, 883091.0963419892, 206835.2696507811]
[2019-03-27 07:34:00,445] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:34:00,448] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3192530e-01 4.1618658e-18 6.6041070e-12 4.9103881e-19 6.8074718e-02], sampled 0.43011433237474694
[2019-03-27 07:34:00,449] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 883091.0963419885 W.
[2019-03-27 07:34:06,684] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:06,686] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.1, 53.5, 1.0, 2.0, 0.861169392638566, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1203636.416692154, 1203636.416692154, 259478.8494868465]
[2019-03-27 07:34:06,687] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:34:06,691] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.5663553e-01 1.7179604e-18 3.7873996e-12 2.3357453e-19 4.3364435e-02], sampled 0.3673292956144679
[2019-03-27 07:34:06,692] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1203636.416692154 W.
[2019-03-27 07:34:08,481] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:08,484] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.86168957, 93.34877958, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6325460752649343, 6.9112, 6.9112, 168.912956510431, 547319.4901576231, 547319.4901576231, 171223.5568883784]
[2019-03-27 07:34:08,485] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:34:08,488] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 4.4572160e-33 9.5482566e-31 1.2833636e-31 5.8553342e-15], sampled 0.6395466791795309
[2019-03-27 07:34:13,924] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:13,926] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.33333333333333, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7574710882183098, 6.9112, 6.9112, 168.912956510431, 641259.7541544046, 641259.7541544046, 193428.4625519671]
[2019-03-27 07:34:13,927] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:34:13,930] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 7.3872694e-33 4.4323495e-30 1.3574789e-31 4.8853889e-14], sampled 0.49637987542840445
[2019-03-27 07:34:15,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:15,748] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 63.0, 1.0, 2.0, 0.643634536327679, 1.0, 2.0, 0.6424073076781021, 1.0, 2.0, 1.03, 7.005093288212542, 6.9112, 170.5573041426782, 2695406.05261226, 2628146.470930845, 504116.4783948424]
[2019-03-27 07:34:15,750] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:34:15,752] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.5922783e-02 2.2188701e-23 1.9080491e-15 2.2917400e-25 9.8407722e-01], sampled 0.40328309005729046
[2019-03-27 07:34:55,777] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:55,780] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.76666666666667, 90.66666666666667, 1.0, 2.0, 0.713882396021366, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 997680.1015222329, 997680.1015222329, 223870.4283390131]
[2019-03-27 07:34:55,781] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:34:55,785] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.8946098e-01 1.9311422e-19 3.0148087e-12 1.4243090e-20 1.1053897e-01], sampled 0.9342870642356047
[2019-03-27 07:34:56,800] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:34:56,802] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.56666666666666, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8829333318577741, 6.9112, 6.9112, 168.912956510431, 727454.0499943179, 727454.0499943179, 219451.1518409165]
[2019-03-27 07:34:56,803] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:34:56,806] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 5.6394624e-32 3.2297301e-28 3.2277547e-31 9.4943576e-12], sampled 0.11840397980276918
[2019-03-27 07:35:01,671] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:35:01,673] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.94928294, 71.24667145, 1.0, 2.0, 0.6856347844491403, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.987704506242055, 6.9112, 168.9124424955994, 1855026.964571044, 1800752.19992373, 382245.4594886552]
[2019-03-27 07:35:01,673] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:35:01,677] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.7824309e-01 9.2237133e-20 2.3864225e-13 9.2553247e-21 1.2175691e-01], sampled 0.7627775029069804
[2019-03-27 07:35:01,679] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1855026.964571044 W.
[2019-03-27 07:35:04,088] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:35:04,088] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.5, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5679907193424438, 6.9112, 6.9112, 168.912956510431, 499859.6428419989, 499859.6428419989, 161211.201350934]
[2019-03-27 07:35:04,089] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:35:04,090] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.0293478e-33 4.7744264e-31 1.0147441e-31 2.9167245e-15], sampled 0.38965916377207743
[2019-03-27 07:35:15,476] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.072111584]
[2019-03-27 07:35:15,479] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.11666666666667, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219254238062498, 6.9112, 6.9112, 168.912956510431, 617172.5990499681, 617172.5990499681, 186724.7068948759]
[2019-03-27 07:35:15,480] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:35:15,485] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 4.5744733e-32 1.8905936e-29 9.5661937e-31 2.6313573e-13], sampled 0.25700488409652056
[2019-03-27 07:35:18,055] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7384.2356 3124068411.4681 1334.0000
[2019-03-27 07:35:18,157] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8073.7310 2958339922.8223 870.0000
[2019-03-27 07:35:18,210] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7188.7060 3192561458.6399 1437.0000
[2019-03-27 07:35:18,385] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7376.7012 3328120951.1177 1442.0000
[2019-03-27 07:35:18,471] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7932.4284 3004235212.1571 1019.0000
[2019-03-27 07:35:19,488] A3C_AGENT_WORKER-Thread-15 INFO:Global step: 1525000, evaluation results [1525000.0, 7376.701243679866, 3328120951.117736, 1442.0, 7384.2355939013, 3124068411.4680877, 1334.0, 8073.730992472338, 2958339922.822254, 870.0, 7188.705957036634, 3192561458.6399074, 1437.0, 7932.428394880963, 3004235212.157073, 1019.0]
[2019-03-27 07:35:23,694] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.6467584e-32 2.7616060e-29 4.1776942e-31 3.8020968e-14], sum to 1.0000
[2019-03-27 07:35:23,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8789
[2019-03-27 07:35:23,700] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6039119750984546, 6.9112, 6.9112, 168.912956510431, 525551.458223587, 525551.458223587, 166681.9630453186], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1476000.0000, 
sim time next is 1476600.0000, 
raw observation next is [21.33333333333333, 96.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6009461570212882, 6.9112, 6.9112, 168.912956510431, 523185.4357217235, 523185.4357217235, 166224.9581971261], 
processed observation next is [0.0, 0.08695652173913043, 0.21011058451816728, 0.9616666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5133489719771807, 0.0, 0.0, 0.8294399451523027, 0.14532928770047873, 0.14532928770047873, 0.24809695253302405], 
reward next is 0.7519, 
noisyNet noise sample is [array([-2.6520214], dtype=float32), 0.72523105]. 
=============================================
[2019-03-27 07:35:26,451] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.9116827e-34 1.4541908e-32 1.0017739e-33 2.5834920e-16], sum to 1.0000
[2019-03-27 07:35:26,460] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3336
[2019-03-27 07:35:26,466] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.7, 51.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6499733060953979, 6.9112, 6.9112, 168.912956510431, 559244.8657543177, 559244.8657543177, 174094.2420053981], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1518000.0000, 
sim time next is 1518600.0000, 
raw observation next is [29.75, 51.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6554507042217965, 6.9112, 6.9112, 168.912956510431, 563479.9992026711, 563479.9992026711, 175008.051499821], 
processed observation next is [0.0, 0.5652173913043478, 0.6090047393364929, 0.5183333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5798179319778006, 0.0, 0.0, 0.8294399451523027, 0.15652222200074198, 0.15652222200074198, 0.2612060470146582], 
reward next is 0.7388, 
noisyNet noise sample is [array([0.6118471], dtype=float32), 1.6967757]. 
=============================================
[2019-03-27 07:35:32,788] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9999976e-01 1.1284695e-27 5.6621855e-23 2.3281078e-27 2.6209310e-07], sum to 1.0000
[2019-03-27 07:35:32,991] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3413
[2019-03-27 07:35:32,992] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 886934.568449268 W.
[2019-03-27 07:35:33,000] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [24.83333333333333, 91.33333333333334, 1.0, 1.0, 0.316675394905397, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5277084440107539, 6.9112, 6.9112, 168.9129182176022, 886934.568449268, 886934.568449268, 225106.3613185751], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1752600.0000, 
sim time next is 1753200.0000, 
raw observation next is [24.9, 91.0, 1.0, 2.0, 0.2693257396410389, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4485561022956786, 6.911199999999999, 6.9112, 168.9129565008692, 753679.4645458214, 753679.464545822, 210936.8924283001], 
processed observation next is [1.0, 0.30434782608695654, 0.3791469194312796, 0.91, 1.0, 1.0, 0.11966956583257697, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.32750744182399827, -8.881784197001253e-17, 0.0, 0.8294399451053499, 0.20935540681828374, 0.20935540681828388, 0.3148311827288061], 
reward next is 0.6852, 
noisyNet noise sample is [array([0.8018759], dtype=float32), -0.72161233]. 
=============================================
[2019-03-27 07:35:34,110] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4075788e-27 2.1932186e-22 3.3580423e-28 3.0242884e-08], sum to 1.0000
[2019-03-27 07:35:34,115] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1143
[2019-03-27 07:35:34,121] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.73115488415914, 6.9112, 6.9112, 168.912956510431, 619853.3233610058, 619853.3233610058, 188407.7399599258], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1654200.0000, 
sim time next is 1654800.0000, 
raw observation next is [23.3, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.727639504317648, 6.911199999999999, 6.9112, 168.912956510431, 616870.4574160738, 616870.4574160744, 187749.6917458796], 
processed observation next is [1.0, 0.13043478260869565, 0.3033175355450238, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6678530540459122, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17135290483779828, 0.17135290483779844, 0.2802234205162382], 
reward next is 0.7198, 
noisyNet noise sample is [array([-0.5232963], dtype=float32), 0.041780848]. 
=============================================
[2019-03-27 07:35:35,968] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.1077025e-02 1.8983492e-21 2.6590568e-13 9.7376618e-23 9.6892303e-01], sum to 1.0000
[2019-03-27 07:35:35,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2788
[2019-03-27 07:35:35,984] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 87.0, 1.0, 2.0, 0.4582542057832782, 1.0, 1.0, 0.4582542057832782, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1281021.685663683, 1281021.685663683, 287789.8957217652], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1683000.0000, 
sim time next is 1683600.0000, 
raw observation next is [26.3, 86.66666666666666, 1.0, 2.0, 0.3274801073507962, 1.0, 2.0, 0.3274801073507962, 1.0, 1.0, 0.5545568417617837, 6.9112, 6.9112, 170.5573041426782, 1373235.028767411, 1373235.028767411, 314795.1020220096], 
processed observation next is [1.0, 0.4782608695652174, 0.4454976303317536, 0.8666666666666666, 1.0, 1.0, 0.1897350690973448, 1.0, 1.0, 0.1897350690973448, 1.0, 0.5, 0.4567766362948581, 0.0, 0.0, 0.8375144448122397, 0.38145417465761416, 0.38145417465761416, 0.46984343585374566], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.3943145], dtype=float32), -0.79616684]. 
=============================================
[2019-03-27 07:35:37,898] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.5134003e-32 8.2329683e-30 2.7881297e-31 2.8567526e-13], sum to 1.0000
[2019-03-27 07:35:37,907] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8060
[2019-03-27 07:35:37,914] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.8, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9196237746110528, 6.911199999999999, 6.9112, 168.912956510431, 751459.3925727669, 751459.3925727676, 227721.0100798798], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2109600.0000, 
sim time next is 2110200.0000, 
raw observation next is [29.0, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9237697062124418, 6.911200000000001, 6.9112, 168.912956510431, 753992.2469766083, 753992.2469766077, 228666.8075620852], 
processed observation next is [0.0, 0.43478260869565216, 0.5734597156398105, 0.7816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9070362270883435, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20944229082683563, 0.20944229082683546, 0.3412937426299779], 
reward next is 0.6587, 
noisyNet noise sample is [array([-1.5373896], dtype=float32), -1.5877693]. 
=============================================
[2019-03-27 07:35:42,576] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.7622638e-33 4.0579123e-31 1.8309072e-32 2.9629276e-15], sum to 1.0000
[2019-03-27 07:35:42,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3076
[2019-03-27 07:35:42,590] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8476482680851846, 6.9112, 6.9112, 168.912956510431, 703365.9504080118, 703365.9504080118, 211758.5402613404], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2025600.0000, 
sim time next is 2026200.0000, 
raw observation next is [25.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8470423077310244, 6.911199999999999, 6.9112, 168.912956510431, 702863.6352198946, 702863.6352198952, 211626.2253540771], 
processed observation next is [0.0, 0.43478260869565216, 0.40758293838862564, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8134662289402735, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19523989867219294, 0.1952398986721931, 0.3158600378419061], 
reward next is 0.6841, 
noisyNet noise sample is [array([-0.8374991], dtype=float32), -0.86213464]. 
=============================================
[2019-03-27 07:35:42,903] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.0381748e-31 4.6199400e-27 1.6416851e-31 1.3292186e-12], sum to 1.0000
[2019-03-27 07:35:42,913] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8697
[2019-03-27 07:35:42,918] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.15, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7844525923130297, 6.911200000000001, 6.9112, 168.912956510431, 665063.6750821503, 665063.6750821496, 198793.8127924638], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1927800.0000, 
sim time next is 1928400.0000, 
raw observation next is [25.26666666666667, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8028582112894114, 6.911200000000001, 6.9112, 168.912956510431, 680478.1975876169, 680478.1975876162, 202556.4724396286], 
processed observation next is [1.0, 0.30434782608695654, 0.3965244865718801, 0.8433333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7595831844992822, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1890217215521158, 0.1890217215521156, 0.3023230931934755], 
reward next is 0.6977, 
noisyNet noise sample is [array([-0.21115674], dtype=float32), -0.29422045]. 
=============================================
[2019-03-27 07:35:45,710] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.00000000e+00 2.78350057e-28 5.84566883e-23 5.88469628e-28
 1.11742455e-08], sum to 1.0000
[2019-03-27 07:35:45,720] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7911
[2019-03-27 07:35:45,729] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7269040371496828, 6.9112, 6.9112, 168.912956510431, 616791.2632780032, 616791.2632780032, 187618.4127469311], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1915200.0000, 
sim time next is 1915800.0000, 
raw observation next is [23.65, 94.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7771860199390737, 6.911200000000001, 6.9112, 168.912956510431, 659884.8310636559, 659884.8310636552, 197343.4836020978], 
processed observation next is [1.0, 0.17391304347826086, 0.31990521327014215, 0.9483333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7282756340720411, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18330134196212663, 0.18330134196212644, 0.29454251283895194], 
reward next is 0.7055, 
noisyNet noise sample is [array([-0.50473535], dtype=float32), -0.01574582]. 
=============================================
[2019-03-27 07:35:48,476] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6858978e-02 1.3267257e-23 5.6958476e-16 9.0819837e-26 9.8314106e-01], sum to 1.0000
[2019-03-27 07:35:48,490] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4982
[2019-03-27 07:35:48,499] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 65.0, 1.0, 2.0, 0.5652012894308699, 1.0, 2.0, 0.5652012894308699, 1.0, 2.0, 0.9815677248187787, 6.911200000000001, 6.9112, 170.5573041426782, 2371158.453328004, 2371158.453328003, 463161.7972704897], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2298600.0000, 
sim time next is 2299200.0000, 
raw observation next is [31.93333333333333, 65.0, 1.0, 2.0, 0.5581038404254299, 1.0, 2.0, 0.5581038404254299, 1.0, 2.0, 0.9692418030585823, 6.9112, 6.9112, 170.5573041426782, 2341355.015083289, 2341355.015083289, 457651.2534845719], 
processed observation next is [1.0, 0.6086956521739131, 0.7124802527646128, 0.65, 1.0, 1.0, 0.46759498846437336, 1.0, 1.0, 0.46759498846437336, 1.0, 1.0, 0.9624900037299784, 0.0, 0.0, 0.8375144448122397, 0.6503763930786913, 0.6503763930786913, 0.6830615723650326], 
reward next is 0.3169, 
noisyNet noise sample is [array([1.252059], dtype=float32), 0.4007641]. 
=============================================
[2019-03-27 07:35:48,764] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.6560457e-30 6.7423710e-25 3.9744188e-31 2.8964775e-08], sum to 1.0000
[2019-03-27 07:35:48,772] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6814
[2019-03-27 07:35:48,777] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.3, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7633578637727114, 6.911199999999999, 6.9112, 168.912956510431, 644639.3238196954, 644639.323819696, 194556.8750705938], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1902000.0000, 
sim time next is 1902600.0000, 
raw observation next is [24.3, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7662636965773033, 6.9112, 6.9112, 168.912956510431, 646743.6525760957, 646743.6525760957, 195122.9192448091], 
processed observation next is [1.0, 0.0, 0.3507109004739337, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7149557275332967, 0.0, 0.0, 0.8294399451523027, 0.17965101460447103, 0.17965101460447103, 0.29122823767881956], 
reward next is 0.7088, 
noisyNet noise sample is [array([0.07351195], dtype=float32), -0.58540606]. 
=============================================
[2019-03-27 07:35:51,642] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [8.96623075e-01 3.45567020e-23 1.17505577e-15 7.81505172e-25
 1.03376955e-01], sum to 1.0000
[2019-03-27 07:35:51,649] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1098
[2019-03-27 07:35:51,657] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1212348.73525669 W.
[2019-03-27 07:35:51,663] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 76.0, 1.0, 2.0, 0.4337020182517483, 1.0, 2.0, 0.4337020182517483, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1212348.73525669, 1212348.73525669, 280937.3465551775], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1945800.0000, 
sim time next is 1946400.0000, 
raw observation next is [27.06666666666667, 75.66666666666667, 1.0, 2.0, 0.8658846493681516, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1213812.233273685, 1213812.233273686, 261245.8832250185], 
processed observation next is [1.0, 0.5217391304347826, 0.48183254344391807, 0.7566666666666667, 1.0, 1.0, 0.8384152402025923, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.33717006479824585, 0.33717006479824607, 0.3899192286940575], 
reward next is 0.6101, 
noisyNet noise sample is [array([0.75793606], dtype=float32), -0.6095553]. 
=============================================
[2019-03-27 07:35:54,594] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.00000000e+00 1.09681866e-32 1.23924797e-29 9.03296761e-32
 2.32805854e-13], sum to 1.0000
[2019-03-27 07:35:54,603] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6163
[2019-03-27 07:35:54,607] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.53333333333333, 77.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9726967867325895, 6.9112, 6.9112, 168.912956510431, 787105.0051842524, 787105.0051842524, 240287.214458326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2139000.0000, 
sim time next is 2139600.0000, 
raw observation next is [29.36666666666667, 78.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9675335685551529, 6.9112, 6.9112, 168.912956510431, 783357.7214741973, 783357.7214741973, 239020.2049214881], 
processed observation next is [0.0, 0.782608695652174, 0.5908372827804109, 0.7866666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9604067909209182, 0.0, 0.0, 0.8294399451523027, 0.21759936707616592, 0.21759936707616592, 0.3567465745096837], 
reward next is 0.6433, 
noisyNet noise sample is [array([0.37400103], dtype=float32), 0.76911366]. 
=============================================
[2019-03-27 07:36:00,949] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.99986291e-01 2.00603396e-25 4.75919069e-18 2.19550282e-26
 1.37130055e-05], sum to 1.0000
[2019-03-27 07:36:00,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1792
[2019-03-27 07:36:00,965] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9329131520030808, 6.9112, 6.9112, 168.912956510431, 780409.8656894437, 780409.8656894437, 231557.4471636264], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2178000.0000, 
sim time next is 2178600.0000, 
raw observation next is [24.71666666666667, 96.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8907989383451819, 6.9112, 6.9112, 168.912956510431, 745011.1813455118, 745011.1813455118, 221609.1738987567], 
processed observation next is [1.0, 0.21739130434782608, 0.3704581358609796, 0.9616666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8668279735916851, 0.0, 0.0, 0.8294399451523027, 0.2069475503737533, 0.2069475503737533, 0.33075996104292044], 
reward next is 0.6692, 
noisyNet noise sample is [array([1.0314586], dtype=float32), -0.7367572]. 
=============================================
[2019-03-27 07:36:03,316] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 8.5991376e-28 2.0877136e-21 6.1055224e-28 6.3170442e-09], sum to 1.0000
[2019-03-27 07:36:03,327] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1247
[2019-03-27 07:36:03,331] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.5, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8558814217364058, 6.911199999999999, 6.9112, 168.912956510431, 709815.7400262067, 709815.7400262073, 213554.0059654498], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2164800.0000, 
sim time next is 2165400.0000, 
raw observation next is [25.45, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8524901409597918, 6.9112, 6.9112, 168.912956510431, 707496.4177415373, 707496.4177415373, 212823.0173945143], 
processed observation next is [1.0, 0.043478260869565216, 0.4052132701421801, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8201099279997461, 0.0, 0.0, 0.8294399451523027, 0.1965267827059826, 0.1965267827059826, 0.31764629461867805], 
reward next is 0.6824, 
noisyNet noise sample is [array([-1.6960624], dtype=float32), 1.4010268]. 
=============================================
[2019-03-27 07:36:05,410] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [2.8104338e-01 1.3264556e-23 4.7412034e-16 5.7233870e-25 7.1895659e-01], sum to 1.0000
[2019-03-27 07:36:05,421] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7944
[2019-03-27 07:36:05,424] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.26666666666667, 68.0, 1.0, 2.0, 0.6022384045097068, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.926331482851198, 6.9112, 168.9128156295475, 1683849.772646436, 1673114.986879642, 365094.3153884365], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2205600.0000, 
sim time next is 2206200.0000, 
raw observation next is [31.38333333333333, 67.5, 1.0, 2.0, 0.3989832227310249, 1.0, 1.0, 0.3989832227310249, 1.0, 2.0, 0.6929019121157837, 6.9112, 6.9112, 170.5573041426782, 1673305.870356709, 1673305.870356709, 352326.3816879972], 
processed observation next is [1.0, 0.5217391304347826, 0.6864139020537123, 0.675, 1.0, 1.0, 0.27588340088075286, 1.0, 0.5, 0.27588340088075286, 1.0, 1.0, 0.6254901367265654, 0.0, 0.0, 0.8375144448122397, 0.46480718621019695, 0.46480718621019695, 0.5258602711761152], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13419652], dtype=float32), 1.05197]. 
=============================================
[2019-03-27 07:36:13,343] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-27 07:36:13,345] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:36:13,346] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:36:13,347] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:36:13,348] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:36:13,348] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:36:13,349] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:36:13,351] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:36:13,350] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:36:13,353] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:36:13,352] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:36:13,382] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run63
[2019-03-27 07:36:13,406] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run63
[2019-03-27 07:36:13,407] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run63
[2019-03-27 07:36:13,426] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run63
[2019-03-27 07:36:13,466] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run63
[2019-03-27 07:36:14,525] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:36:14,527] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.31666666666667, 78.83333333333334, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.7251345961244599, 6.911199999999999, 6.9112, 168.912956510431, 617603.6810132663, 617603.6810132669, 187308.7885143697]
[2019-03-27 07:36:14,528] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:36:14,529] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [0.27439585 0.04517646 0.15432571 0.03252476 0.49357724], sampled 0.05287391100508365
[2019-03-27 07:36:22,874] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:36:22,875] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.5, 48.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9003491000207612, 6.9112, 6.9112, 168.912956510431, 787270.2812129853, 787270.2812129853, 223866.583318404]
[2019-03-27 07:36:22,878] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:36:22,881] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.5417193e-33 1.2197880e-30 4.3715583e-32 4.6609661e-15], sampled 0.9567110384478436
[2019-03-27 07:36:28,756] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:36:28,757] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.85, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5378645878640882, 6.9112, 6.9112, 168.912956510431, 474269.0107201024, 474269.0107201024, 156988.5001999762]
[2019-03-27 07:36:28,759] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:36:28,761] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.1263321e-35 3.7666053e-33 3.6985304e-34 2.3348263e-17], sampled 0.9600092898895852
[2019-03-27 07:36:45,127] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:36:45,129] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.993414995, 87.630556605, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.829735184750405, 6.911200000000001, 6.9112, 168.9129565104308, 692783.1706113223, 692783.1706113217, 208010.9594638571]
[2019-03-27 07:36:45,131] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:36:45,134] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.3120692e-32 4.9190026e-29 5.5287396e-32 4.4482080e-13], sampled 0.2289672401833528
[2019-03-27 07:36:56,325] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:36:56,328] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5601390974469901, 6.9112, 6.9112, 168.912956510431, 490769.21008797, 490769.21008797, 160162.5783614505]
[2019-03-27 07:36:56,329] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:36:56,334] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.0601538e-33 3.7145276e-31 5.8798374e-32 2.1294153e-16], sampled 0.7607744020941959
[2019-03-27 07:37:05,324] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:37:05,326] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.46461314, 79.03385822, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8190040558009047, 6.9112, 6.9112, 168.912956510431, 688616.2576464604, 688616.2576464604, 205843.1184578224]
[2019-03-27 07:37:05,328] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:37:05,330] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 8.60813687e-34 3.89243513e-31 8.20270464e-33
 1.08337225e-14], sampled 0.9187397678507685
[2019-03-27 07:37:07,945] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:37:07,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.4, 64.0, 1.0, 2.0, 0.4931631215037222, 1.0, 2.0, 0.4931631215037222, 1.0, 2.0, 0.8541174066818932, 6.9112, 6.9112, 178.6582176852504, 2068580.083178318, 2068580.083178318, 412086.4629371786]
[2019-03-27 07:37:07,947] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:37:07,949] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.56533420e-01 2.91322478e-20 1.14336735e-11 2.39689946e-22
 8.43466640e-01], sampled 0.47982966221907086
[2019-03-27 07:37:17,416] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:37:17,417] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.61492679333334, 59.97489789333333, 1.0, 2.0, 0.4412147628207146, 1.0, 2.0, 0.4412147628207146, 1.0, 2.0, 0.7662441310678512, 6.9112, 6.9112, 171.5212843490159, 1850565.757140785, 1850565.757140785, 377078.2323156062]
[2019-03-27 07:37:17,419] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:37:17,421] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.2779629e-01 1.2412045e-21 2.0373554e-15 1.0456446e-23 8.7220377e-01], sampled 0.7064309224140146
[2019-03-27 07:37:56,159] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:37:56,159] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.493954055, 80.08180849499999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7396797947812103, 6.9112, 6.9112, 168.912956510431, 630877.2172713758, 630877.2172713758, 190050.1295652908]
[2019-03-27 07:37:56,161] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:37:56,164] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.9108242e-33 8.9000601e-30 8.2960132e-32 1.9672305e-14], sampled 0.11285491962677052
[2019-03-27 07:38:00,752] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07161339]
[2019-03-27 07:38:00,754] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.44750853833334, 76.08313672666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8223674157975741, 6.911199999999999, 6.9112, 168.912956510431, 689536.4002705887, 689536.4002705894, 206514.4215258945]
[2019-03-27 07:38:00,756] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:38:00,761] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 4.0734131e-35 1.4896758e-32 9.5644640e-34 2.2294638e-16], sampled 0.308367861759425
[2019-03-27 07:38:08,762] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7308.5393 3321187456.4834 1678.0000
[2019-03-27 07:38:08,862] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7137.1985 3186119656.9851 1704.0000
[2019-03-27 07:38:09,305] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8053.5285 2948290317.4949 989.0000
[2019-03-27 07:38:09,363] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.4273 2994115114.6173 1156.0000
[2019-03-27 07:38:09,372] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7356.2462 3115186769.9250 1508.0000
[2019-03-27 07:38:10,389] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1550000, evaluation results [1550000.0, 7308.539323510525, 3321187456.4833937, 1678.0, 7356.246203946589, 3115186769.9249635, 1508.0, 8053.528520317797, 2948290317.494853, 989.0, 7137.19854927097, 3186119656.985053, 1704.0, 7915.427274111591, 2994115114.617321, 1156.0]
[2019-03-27 07:38:12,462] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [3.1825945e-01 3.1401104e-20 4.9754445e-12 1.1016938e-20 6.8174052e-01], sum to 1.0000
[2019-03-27 07:38:12,473] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-27 07:38:12,477] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.6, 65.33333333333334, 1.0, 2.0, 0.4913205345172414, 1.0, 2.0, 0.4913205345172414, 1.0, 2.0, 0.8532612862728103, 6.911200000000001, 6.9112, 170.5573041426782, 2060934.111320216, 2060934.111320216, 409195.4883425127], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2370000.0000, 
sim time next is 2370600.0000, 
raw observation next is [31.75, 65.0, 1.0, 2.0, 0.495510476977972, 1.0, 2.0, 0.495510476977972, 1.0, 2.0, 0.8605378306919538, 6.9112, 6.9112, 170.5573041426782, 2078526.644357748, 2078526.644357748, 412054.9985805566], 
processed observation next is [1.0, 0.43478260869565216, 0.7037914691943128, 0.65, 1.0, 1.0, 0.3921812975638217, 1.0, 1.0, 0.3921812975638217, 1.0, 1.0, 0.8299241837706753, 0.0, 0.0, 0.8375144448122397, 0.5773685123215967, 0.5773685123215967, 0.6150074605679949], 
reward next is 0.3850, 
noisyNet noise sample is [array([0.94516784], dtype=float32), -1.6203117]. 
=============================================
[2019-03-27 07:38:16,519] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9997473e-01 1.6223936e-24 4.2747629e-17 2.0877123e-25 2.5307851e-05], sum to 1.0000
[2019-03-27 07:38:16,526] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8074
[2019-03-27 07:38:16,534] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9209225698959501, 6.9112, 6.9112, 168.912956510431, 789127.2015565811, 789127.2015565811, 228948.4366345462], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3069600.0000, 
sim time next is 3070200.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.941430166475425, 6.9112, 6.9112, 168.912956510431, 807130.6990049059, 807130.6990049059, 233908.6128920897], 
processed observation next is [1.0, 0.5217391304347826, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9285733737505183, 0.0, 0.0, 0.8294399451523027, 0.22420297194580718, 0.22420297194580718, 0.34911733267476075], 
reward next is 0.6509, 
noisyNet noise sample is [array([0.21176828], dtype=float32), 0.14352003]. 
=============================================
[2019-03-27 07:38:39,253] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 3.7815782e-33 3.2537190e-29 2.4225515e-33 3.4687075e-15], sum to 1.0000
[2019-03-27 07:38:39,263] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0317
[2019-03-27 07:38:39,267] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.613967211579247, 6.9112, 6.9112, 168.912956510431, 532415.1094333314, 532415.1094333314, 168265.2263575591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2864400.0000, 
sim time next is 2865000.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.617209826550234, 6.9112, 6.9112, 168.912956510431, 535227.7222545915, 535227.7222545915, 168772.3729905666], 
processed observation next is [1.0, 0.13043478260869565, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5331827153051635, 0.0, 0.0, 0.8294399451523027, 0.1486743672929421, 0.1486743672929421, 0.2518990641650248], 
reward next is 0.7481, 
noisyNet noise sample is [array([-0.55019855], dtype=float32), -0.66434515]. 
=============================================
[2019-03-27 07:38:39,278] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[74.45005 ]
 [74.66338 ]
 [74.636086]
 [74.82381 ]
 [74.84112 ]], R is [[74.31569672]
 [74.32139587]
 [74.32969666]
 [74.33779907]
 [74.34024811]].
[2019-03-27 07:38:47,578] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9992824e-01 2.9587597e-24 1.1728128e-16 6.8106496e-24 7.1761860e-05], sum to 1.0000
[2019-03-27 07:38:47,590] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0805
[2019-03-27 07:38:47,601] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 947772.3711841125 W.
[2019-03-27 07:38:47,609] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.0, 88.0, 1.0, 2.0, 0.604340815708244, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9129565087509, 947772.3711841125, 947772.3711841131, 213731.9864545643], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2974800.0000, 
sim time next is 2975400.0000, 
raw observation next is [22.0, 88.0, 1.0, 2.0, 0.2067923211158195, 1.0, 1.0, 0.2067923211158195, 1.0, 1.0, 0.3683581494054439, 6.911200000000001, 6.9112, 170.5573041426782, 959612.2993318144, 959612.2993318138, 282142.5166525947], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 0.88, 1.0, 1.0, 0.04432809772990299, 1.0, 0.5, 0.04432809772990299, 1.0, 0.5, 0.22970506025054135, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2665589720366151, 0.26655897203661494, 0.42110823380984286], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.15177053], dtype=float32), 0.02963832]. 
=============================================
[2019-03-27 07:38:59,958] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.7416690e-32 2.4780928e-31 1.6235317e-30 8.3491719e-14], sum to 1.0000
[2019-03-27 07:38:59,969] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4984
[2019-03-27 07:38:59,973] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.918856617375665, 6.9112, 6.9112, 168.912956510431, 752649.8975572637, 752649.8975572637, 227619.7042025352], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3824400.0000, 
sim time next is 3825000.0000, 
raw observation next is [27.5, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9218867811565966, 6.9112, 6.9112, 168.912956510431, 754632.4073264817, 754632.4073264817, 228317.042050467], 
processed observation next is [0.0, 0.2608695652173913, 0.5023696682464456, 0.865, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9047399770202397, 0.0, 0.0, 0.8294399451523027, 0.2096201131462449, 0.2096201131462449, 0.3407717045529358], 
reward next is 0.6592, 
noisyNet noise sample is [array([1.2515527], dtype=float32), 0.3760116]. 
=============================================
[2019-03-27 07:38:59,988] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.67004 ]
 [68.715515]
 [68.69174 ]
 [68.628914]
 [68.64823 ]], R is [[68.5712204 ]
 [68.54577637]
 [68.52178192]
 [68.49881744]
 [68.47601318]].
[2019-03-27 07:39:04,339] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 07:39:04,341] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:39:04,342] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:39:04,342] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:39:04,343] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:39:04,343] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:39:04,346] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:39:04,346] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:39:04,344] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:39:04,348] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:39:04,348] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:39:04,379] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run64
[2019-03-27 07:39:04,399] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run64
[2019-03-27 07:39:04,419] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run64
[2019-03-27 07:39:04,438] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run64
[2019-03-27 07:39:04,458] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run64
[2019-03-27 07:39:37,762] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:39:37,765] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.93333333333334, 70.66666666666667, 1.0, 2.0, 0.5897475534016422, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104272, 861811.4048451781, 861811.4048451788, 203639.1152697576]
[2019-03-27 07:39:37,767] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:39:37,771] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.6706314e-26 2.9606008e-22 4.4471605e-26 3.4034051e-09], sampled 0.5807141542502815
[2019-03-27 07:39:45,874] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:39:45,875] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.65944674, 79.00250277, 1.0, 2.0, 0.5686385860100894, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 853561.8622499992, 853561.8622499992, 202350.6367666816]
[2019-03-27 07:39:45,876] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:39:45,878] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.3406856e-01 6.3252315e-19 1.7872565e-12 1.7281989e-20 6.5931484e-02], sampled 0.719078469121065
[2019-03-27 07:39:57,009] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:39:57,011] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.82817204, 66.40159285499999, 1.0, 2.0, 0.6053038572774829, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564919705, 845876.6853132711, 845876.6853132711, 201738.4907184441]
[2019-03-27 07:39:57,013] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:39:57,017] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 9.1683770e-28 1.3995120e-24 1.4385197e-27 1.2871459e-09], sampled 0.4138317229464631
[2019-03-27 07:40:07,277] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:40:07,278] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 79.0, 1.0, 1.0, 0.6491099062972052, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9127465330075, 907119.2154980282, 907119.2154980289, 210250.81145346]
[2019-03-27 07:40:07,280] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:40:07,283] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.2604530e-01 2.5003269e-19 2.3604971e-13 7.3396721e-21 7.3954687e-02], sampled 0.6195959920604378
[2019-03-27 07:40:07,285] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 907119.2154980282 W.
[2019-03-27 07:40:12,205] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:40:12,206] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.33333333333334, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7780646346755018, 6.911199999999999, 6.9112, 168.912956510431, 656257.5409933337, 656257.5409933343, 197459.8630914711]
[2019-03-27 07:40:12,207] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:40:12,210] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.6039390e-36 9.0451557e-36 2.4128835e-35 3.8276162e-17], sampled 0.9876411828052709
[2019-03-27 07:40:25,446] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:40:25,447] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [36.5, 56.0, 1.0, 2.0, 0.5137684905695262, 1.0, 2.0, 0.5137684905695262, 1.0, 2.0, 0.8922459622831223, 6.9112, 6.9112, 169.0403247858759, 2155210.361941785, 2155210.361941785, 424500.5229859363]
[2019-03-27 07:40:25,448] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:40:25,453] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.8749170e-01 1.4550516e-18 2.3269255e-12 2.9109623e-20 8.1250829e-01], sampled 0.5063848981148352
[2019-03-27 07:40:37,223] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.07127756]
[2019-03-27 07:40:37,227] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.43333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8667884473928793, 6.9112, 6.9112, 168.912956510431, 721364.4209912744, 721364.4209912744, 216054.964688882]
[2019-03-27 07:40:37,228] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:40:37,231] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 2.83864070e-34 1.60529576e-31 1.77745454e-33
 1.16993995e-14], sampled 0.903578486555256
[2019-03-27 07:40:59,761] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7410.9683 3126386624.5071 1229.0000
[2019-03-27 07:40:59,999] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8087.7996 2960842443.3765 833.0000
[2019-03-27 07:41:00,029] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7227.5605 3197339342.1050 1360.0000
[2019-03-27 07:41:00,179] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.2826 3005484513.8161 960.0000
[2019-03-27 07:41:00,211] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7375.9700 3331470722.4129 1422.0000
[2019-03-27 07:41:01,225] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1575000, evaluation results [1575000.0, 7375.969960394455, 3331470722.412879, 1422.0, 7410.96833451471, 3126386624.507079, 1229.0, 8087.799593049909, 2960842443.37653, 833.0, 7227.56054416936, 3197339342.1049967, 1360.0, 7924.282586941847, 3005484513.8160596, 960.0]
[2019-03-27 07:41:01,486] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.6252404e-33 1.7949131e-31 2.6952856e-31 4.3857248e-16], sum to 1.0000
[2019-03-27 07:41:01,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4939
[2019-03-27 07:41:01,504] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.723564581565371, 6.9112, 6.9112, 168.912956510431, 616551.6015760098, 616551.6015760098, 187019.1820338913], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3304800.0000, 
sim time next is 3305400.0000, 
raw observation next is [25.16666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7306870762007753, 6.911200000000001, 6.9112, 168.912956510431, 622013.9468405113, 622013.9468405107, 188344.3341688217], 
processed observation next is [0.0, 0.2608695652173913, 0.39178515007898923, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6715696051228968, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17278165190014202, 0.17278165190014186, 0.2811109465206294], 
reward next is 0.7189, 
noisyNet noise sample is [array([0.59228575], dtype=float32), -0.5604331]. 
=============================================
[2019-03-27 07:41:06,527] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [2.8742882e-06 5.7570217e-23 1.0936997e-15 3.5885329e-26 9.9999714e-01], sum to 1.0000
[2019-03-27 07:41:06,535] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5164
[2019-03-27 07:41:06,540] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 60.0, 1.0, 2.0, 0.834757168891859, 1.0, 2.0, 0.737968623960192, 1.0, 2.0, 1.03, 7.005108360040095, 6.9112, 170.5573041426782, 3096858.282700627, 3029587.904456052, 567271.5952554441], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3765600.0000, 
sim time next is 3766200.0000, 
raw observation next is [34.83333333333334, 60.0, 1.0, 2.0, 0.851761786159891, 1.0, 2.0, 0.7464709325942082, 1.0, 2.0, 1.03, 7.005109701484183, 6.9112, 170.5573041426782, 3132582.656335182, 3065311.317159642, 573549.3587700839], 
processed observation next is [1.0, 0.6086956521739131, 0.8499210110584523, 0.6, 1.0, 1.0, 0.8213997423613144, 1.0, 1.0, 0.6945432922821785, 1.0, 1.0, 1.0365853658536586, 0.009390970148418276, 0.0, 0.8375144448122397, 0.870161848981995, 0.8514753658776784, 0.8560438190598266], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.7272133], dtype=float32), 1.4239225]. 
=============================================
[2019-03-27 07:41:08,891] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.0392576e-33 2.7064450e-30 2.8013893e-33 2.1979840e-11], sum to 1.0000
[2019-03-27 07:41:08,899] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1779
[2019-03-27 07:41:08,905] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9548562594939124, 6.9112, 6.9112, 168.912956510431, 775241.8918838747, 775241.8918838747, 235993.7643769644], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3526800.0000, 
sim time next is 3527400.0000, 
raw observation next is [29.16666666666667, 78.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9535871344268992, 6.9112, 6.9112, 168.912956510431, 774875.7434302403, 774875.7434302403, 235715.320488401], 
processed observation next is [1.0, 0.8260869565217391, 0.581358609794629, 0.7833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9433989444230477, 0.0, 0.0, 0.8294399451523027, 0.21524326206395564, 0.21524326206395564, 0.3518139111767179], 
reward next is 0.6482, 
noisyNet noise sample is [array([-1.5302507], dtype=float32), -0.33536676]. 
=============================================
[2019-03-27 07:41:15,125] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.1732799e-04 2.9809302e-22 4.0212682e-15 3.1598659e-26 9.9928266e-01], sum to 1.0000
[2019-03-27 07:41:15,135] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6198
[2019-03-27 07:41:15,144] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.66666666666667, 1.0, 2.0, 0.6023872490560538, 1.0, 2.0, 0.6023872490560538, 1.0, 2.0, 1.03, 6.929352239179625, 6.9112, 170.5573041426782, 2527320.465750969, 2514317.278440723, 488845.2151199037], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3513000.0000, 
sim time next is 3513600.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.5913507440052747, 1.0, 2.0, 0.5913507440052747, 1.0, 2.0, 1.026980679657747, 6.9112, 6.9112, 170.5573041426782, 2480970.752320814, 2480970.752320814, 484062.4648740289], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.59, 1.0, 1.0, 0.5076514988015357, 1.0, 1.0, 0.5076514988015357, 1.0, 1.0, 1.0329032678753012, 0.0, 0.0, 0.8375144448122397, 0.6891585423113372, 0.6891585423113372, 0.7224812908567596], 
reward next is 0.2775, 
noisyNet noise sample is [array([0.6956171], dtype=float32), 0.17259279]. 
=============================================
[2019-03-27 07:41:21,322] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9765933e-01 1.3851093e-20 5.0245541e-15 1.6727870e-22 2.3406635e-03], sum to 1.0000
[2019-03-27 07:41:21,333] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2184
[2019-03-27 07:41:21,341] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666667, 76.33333333333334, 1.0, 1.0, 0.3045590649891315, 1.0, 1.0, 0.3045590649891315, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 851205.7554382482, 851205.7554382482, 250774.2206315947], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4238400.0000, 
sim time next is 4239000.0000, 
raw observation next is [30.5, 77.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.991336402208056, 6.9112, 168.9123492963501, 885674.416429139, 828823.0989924353, 254812.3521158364], 
processed observation next is [1.0, 0.043478260869565216, 0.6445497630331753, 0.77, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.008013640220805574, 0.0, 0.8294369634531816, 0.24602067123031637, 0.2302286386090098, 0.38031694345647227], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.3389877], dtype=float32), 0.24105774]. 
=============================================
[2019-03-27 07:41:21,359] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[46.390533]
 [48.3493  ]
 [46.95149 ]
 [48.649498]
 [47.847786]], R is [[46.55694962]
 [46.09138107]
 [45.63046646]
 [45.17416382]
 [44.72242355]].
[2019-03-27 07:41:22,455] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.0696211e-34 8.3508153e-32 8.0126279e-33 1.2176488e-16], sum to 1.0000
[2019-03-27 07:41:22,464] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3716
[2019-03-27 07:41:22,467] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9248113798503783, 6.9112, 6.9112, 168.912956510431, 756581.8924191659, 756581.8924191659, 228993.460810366], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3873600.0000, 
sim time next is 3874200.0000, 
raw observation next is [30.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9262302094251958, 6.9112, 6.9112, 168.912956510431, 759242.9792850275, 759242.9792850275, 229398.0270755895], 
processed observation next is [0.0, 0.8695652173913043, 0.6208530805687204, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9100368407624339, 0.0, 0.0, 0.8294399451523027, 0.2109008275791743, 0.2109008275791743, 0.34238511503819324], 
reward next is 0.6576, 
noisyNet noise sample is [array([0.16226786], dtype=float32), 0.012040827]. 
=============================================
[2019-03-27 07:41:28,345] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.2311388e-05 8.8678641e-21 5.7480380e-15 6.9345891e-24 9.9998772e-01], sum to 1.0000
[2019-03-27 07:41:28,353] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9010
[2019-03-27 07:41:28,357] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.33333333333333, 60.0, 1.0, 2.0, 0.7109569097328711, 1.0, 2.0, 0.676068494380698, 1.0, 2.0, 1.03, 7.005098596114015, 6.9112, 170.5573041426782, 2836801.676446564, 2769538.292499411, 524812.794981372], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3768000.0000, 
sim time next is 3768600.0000, 
raw observation next is [34.16666666666667, 60.0, 1.0, 2.0, 0.6625502497621062, 1.0, 2.0, 0.6518651643953157, 1.0, 2.0, 1.03, 7.005094779463843, 6.9112, 170.5573041426782, 2735132.671500773, 2667872.02157539, 509761.2878213857], 
processed observation next is [1.0, 0.6086956521739131, 0.8183254344391787, 0.6, 1.0, 1.0, 0.5934340358579593, 1.0, 1.0, 0.5805604390305008, 1.0, 1.0, 1.0365853658536586, 0.00938947794638434, 0.0, 0.8375144448122397, 0.7597590754168815, 0.7410755615487195, 0.7608377430169936], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7004933], dtype=float32), 1.6755209]. 
=============================================
[2019-03-27 07:41:29,043] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.8504206e-06 2.5796966e-22 1.1205249e-16 1.3938553e-25 9.9999011e-01], sum to 1.0000
[2019-03-27 07:41:29,053] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6978
[2019-03-27 07:41:29,061] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.33333333333333, 62.33333333333333, 1.0, 2.0, 0.7100782269304831, 1.0, 2.0, 0.6756291529795041, 1.0, 2.0, 1.03, 7.005098526828245, 6.9112, 170.5573041426782, 2834956.096196681, 2767692.761881744, 524531.3304683411], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4372800.0000, 
sim time next is 4373400.0000, 
raw observation next is [33.66666666666667, 59.16666666666667, 1.0, 2.0, 0.7171434344034987, 1.0, 2.0, 0.6791617567160119, 1.0, 2.0, 1.03, 7.005099083938762, 6.9112, 170.5573041426782, 2849795.894082411, 2782532.160686549, 526798.3002736738], 
processed observation next is [1.0, 0.6086956521739131, 0.7946287519747238, 0.5916666666666667, 1.0, 1.0, 0.659208957112649, 1.0, 1.0, 0.6134478996578456, 1.0, 1.0, 1.0365853658536586, 0.009389908393876212, 0.0, 0.8375144448122397, 0.7916099705784475, 0.772925600190708, 0.7862661198114534], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.13575558], dtype=float32), 0.90870154]. 
=============================================
[2019-03-27 07:41:34,694] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [6.78986078e-03 9.14996691e-20 6.54255296e-13 1.19763774e-23
 9.93210137e-01], sum to 1.0000
[2019-03-27 07:41:34,703] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3541
[2019-03-27 07:41:34,710] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [34.33333333333334, 56.16666666666667, 1.0, 2.0, 0.7408431670080023, 1.0, 2.0, 0.6910116230182637, 1.0, 2.0, 1.03, 7.005100952822723, 6.9112, 170.5573041426782, 2899576.221146703, 2832311.148993239, 534539.2919609462], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4374600.0000, 
sim time next is 4375200.0000, 
raw observation next is [34.66666666666667, 56.33333333333334, 1.0, 2.0, 0.7076898404890978, 1.0, 2.0, 0.6744349597588115, 1.0, 2.0, 1.03, 7.005098338500575, 6.9112, 170.5573041426782, 2829939.556978833, 2762676.357570668, 523769.0594044273], 
processed observation next is [1.0, 0.6521739130434783, 0.8420221169036337, 0.5633333333333335, 1.0, 1.0, 0.6478190849266238, 1.0, 1.0, 0.6077529635648331, 1.0, 1.0, 1.0365853658536586, 0.009389833850057538, 0.0, 0.8375144448122397, 0.7860943213830092, 0.7674100993251857, 0.7817448647827273], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.01741009], dtype=float32), 0.7601714]. 
=============================================
[2019-03-27 07:41:36,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.0728281e-28 1.8587180e-25 1.1632652e-28 2.0685942e-12], sum to 1.0000
[2019-03-27 07:41:36,858] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6998
[2019-03-27 07:41:36,867] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 86.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.920654482629019, 6.9112, 168.9127160583139, 835783.8476582321, 829076.5218310981, 254828.1571430253], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3889800.0000, 
sim time next is 3890400.0000, 
raw observation next is [28.33333333333333, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.927856349435105, 6.9112, 168.9126520765614, 841442.7921054626, 829626.225846073, 254860.7606753738], 
processed observation next is [0.0, 0.0, 0.541864139020537, 0.8733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0016656349435105078, 0.0, 0.8294384502426324, 0.23373410891818405, 0.23045172940168696, 0.38038919503787133], 
reward next is 0.5363, 
noisyNet noise sample is [array([0.38196778], dtype=float32), -0.20905292]. 
=============================================
[2019-03-27 07:41:37,826] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 3.6338080e-34 3.7940046e-33 3.2413239e-33 9.6082421e-18], sum to 1.0000
[2019-03-27 07:41:37,831] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6942
[2019-03-27 07:41:37,838] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.011892778343341, 6.9112, 6.9112, 168.9127945543738, 818699.4453300696, 818699.4453300696, 250306.107587663], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3904800.0000, 
sim time next is 3905400.0000, 
raw observation next is [27.16666666666666, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9911659852553678, 6.9112, 6.9112, 168.912956510431, 802573.190327287, 802573.190327287, 244988.5217047931], 
processed observation next is [0.0, 0.17391304347826086, 0.4865718799368086, 0.9316666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9892268112870339, 0.0, 0.0, 0.8294399451523027, 0.22293699731313527, 0.22293699731313527, 0.3656545100071539], 
reward next is 0.6343, 
noisyNet noise sample is [array([2.683399], dtype=float32), -0.8165995]. 
=============================================
[2019-03-27 07:41:43,455] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [2.7515882e-01 3.2301084e-18 1.7622246e-12 2.5469613e-20 7.2484118e-01], sum to 1.0000
[2019-03-27 07:41:43,464] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2365
[2019-03-27 07:41:43,470] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1804609.713333661 W.
[2019-03-27 07:41:43,474] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 84.0, 1.0, 2.0, 0.4302649841169205, 1.0, 1.0, 0.4302649841169205, 1.0, 2.0, 0.7445577581163192, 6.9112, 6.9112, 170.5573041426782, 1804609.713333661, 1804609.713333661, 369869.1067920752], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4005000.0000, 
sim time next is 4005600.0000, 
raw observation next is [27.66666666666667, 84.0, 1.0, 2.0, 0.6740107459321801, 1.0, 2.0, 0.6740107459321801, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1884686.254374776, 1884686.254374776, 363195.2895487521], 
processed observation next is [1.0, 0.34782608695652173, 0.5102685624012641, 0.84, 1.0, 1.0, 0.6072418625688917, 1.0, 1.0, 0.6072418625688917, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5235239595485489, 0.5235239595485489, 0.5420825217145553], 
reward next is 0.4579, 
noisyNet noise sample is [array([0.06556237], dtype=float32), 0.38414752]. 
=============================================
[2019-03-27 07:41:49,619] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.4447448e-04 6.7375500e-19 1.0860595e-12 3.5521659e-23 9.9965549e-01], sum to 1.0000
[2019-03-27 07:41:49,631] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7996
[2019-03-27 07:41:49,639] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.33333333333334, 66.0, 1.0, 2.0, 0.9874593431859657, 1.0, 2.0, 0.8143197111072453, 1.0, 2.0, 1.03, 7.005120409012982, 6.9112, 170.5573041426782, 3417701.275638994, 3350422.26622502, 627518.8295927538], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4117200.0000, 
sim time next is 4117800.0000, 
raw observation next is [35.16666666666666, 66.5, 1.0, 2.0, 0.9766451445331109, 1.0, 2.0, 0.8089126117808182, 1.0, 2.0, 1.03, 7.005119555514479, 6.9112, 170.5573041426782, 3394976.818134329, 3327698.420116051, 622965.4380762508], 
processed observation next is [1.0, 0.6521739130434783, 0.865718799368088, 0.665, 1.0, 1.0, 0.9718616199194108, 1.0, 1.0, 0.7697742310612268, 1.0, 1.0, 1.0365853658536586, 0.00939195555144794, 0.0, 0.8375144448122397, 0.9430491161484247, 0.9243606722544586, 0.929799161307837], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.33132705], dtype=float32), -0.20893197]. 
=============================================
[2019-03-27 07:41:49,913] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999988e-01 7.3812137e-25 5.8724250e-22 8.5123998e-25 1.1807178e-07], sum to 1.0000
[2019-03-27 07:41:49,922] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9463
[2019-03-27 07:41:49,929] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 899490.3221934972 W.
[2019-03-27 07:41:49,934] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.66666666666667, 76.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.010803478107664, 6.9112, 168.9122367515623, 899490.3221934972, 828828.487836814, 254812.444687737], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4133400.0000, 
sim time next is 4134000.0000, 
raw observation next is [30.33333333333334, 78.0, 1.0, 1.0, 0.3024495869046253, 1.0, 1.0, 0.3024495869046253, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 845307.6958164091, 845307.6958164091, 250362.110253374], 
processed observation next is [1.0, 0.8695652173913043, 0.6366508688783573, 0.78, 1.0, 0.5, 0.15957781554774134, 1.0, 0.5, 0.15957781554774134, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23480769328233586, 0.23480769328233586, 0.3736747914229463], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.74124765], dtype=float32), 0.31851283]. 
=============================================
[2019-03-27 07:41:49,958] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[36.948914]
 [34.37928 ]
 [35.409504]
 [33.769085]
 [34.333576]], R is [[34.49930191]
 [34.15430832]
 [33.81276703]
 [33.47463989]
 [33.76589966]].
[2019-03-27 07:41:55,024] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 07:41:55,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:41:55,027] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:41:55,029] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:41:55,029] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:41:55,030] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:41:55,031] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:41:55,033] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:41:55,035] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:41:55,031] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:41:55,036] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:41:55,063] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run65
[2019-03-27 07:41:55,082] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run65
[2019-03-27 07:41:55,105] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run65
[2019-03-27 07:41:55,125] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run65
[2019-03-27 07:41:55,144] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run65
[2019-03-27 07:42:15,408] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:15,409] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.15, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4424329887868436, 6.9112, 6.9112, 168.912956510431, 397059.9622791082, 397059.9622791082, 144956.1699579707]
[2019-03-27 07:42:15,412] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:42:15,416] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.00000000e+00 3.16901159e-37 1.68857990e-37 1.12502666e-35
 1.29302570e-22], sampled 0.7863192846394831
[2019-03-27 07:42:22,887] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:22,890] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.73005584333334, 88.17681266, 1.0, 2.0, 0.8681206697760014, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1213357.60638315, 1213357.60638315, 261317.9581396938]
[2019-03-27 07:42:22,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:42:22,894] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [7.4235469e-01 1.7047466e-15 1.0570801e-09 1.2950179e-17 2.5764531e-01], sampled 0.13526218614021257
[2019-03-27 07:42:22,896] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1213357.60638315 W.
[2019-03-27 07:42:26,852] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:26,853] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.86666666666667, 95.66666666666667, 1.0, 2.0, 0.6136397413985974, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 857530.2976508441, 857530.2976508441, 203305.9632519844]
[2019-03-27 07:42:26,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:42:26,859] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9098891e-01 6.0772794e-17 2.6342484e-11 4.9834726e-19 9.0111420e-03], sampled 0.9375412624844085
[2019-03-27 07:42:27,488] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:27,490] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.74262113, 72.22509623, 1.0, 2.0, 0.3170256875227233, 1.0, 2.0, 0.3170256875227233, 1.0, 2.0, 0.5505687772300268, 6.9112, 6.9112, 184.5923449428631, 1329306.256077728, 1329306.256077728, 315795.4217041488]
[2019-03-27 07:42:27,492] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:42:27,496] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [2.3182417e-01 1.6994036e-15 2.0391542e-09 3.6867568e-18 7.6817584e-01], sampled 0.015125689422527344
[2019-03-27 07:42:27,496] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1329306.256077728 W.
[2019-03-27 07:42:32,591] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:32,592] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.67439909, 100.0, 1.0, 2.0, 0.7315608572472526, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1022398.373482159, 1022398.37348216, 227811.1967400641]
[2019-03-27 07:42:32,594] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:42:32,596] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999988e-01 3.2869264e-22 2.8932379e-18 3.6393912e-23 8.6011106e-08], sampled 0.860524292429114
[2019-03-27 07:42:32,596] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1022398.373482159 W.
[2019-03-27 07:42:42,603] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:42,605] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.91557025193206, 6.9112, 168.9127430318636, 833209.0953030084, 830108.6920883533, 254889.5718398621]
[2019-03-27 07:42:42,607] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:42:42,609] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.6191629e-33 5.6594370e-33 1.1521251e-32 5.9215441e-18], sampled 0.8671937696075344
[2019-03-27 07:42:48,569] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:42:48,571] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.8, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9822273615645155, 6.9112, 6.9112, 168.912956510431, 795262.9204743385, 795262.9204743385, 242711.2180304886]
[2019-03-27 07:42:48,573] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:42:48,580] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 9.9988556e-31 4.0778546e-30 4.4001387e-30 1.9219767e-16], sampled 0.8664208022302001
[2019-03-27 07:43:11,888] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:43:11,889] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.68720235666667, 64.42062853333334, 1.0, 2.0, 0.3070504713728834, 1.0, 1.0, 0.3070504713728834, 1.0, 1.0, 0.5332451256321453, 6.9112, 6.9112, 184.5923449428631, 1287456.417987513, 1287456.417987513, 311484.0337869285]
[2019-03-27 07:43:11,890] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:43:11,894] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [3.0297694e-01 1.4996825e-14 6.0852963e-09 6.9641672e-17 6.9702309e-01], sampled 0.9624038346101887
[2019-03-27 07:43:23,243] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:43:23,245] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.11666666666667, 93.33333333333334, 1.0, 2.0, 1.003761967382151, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129113919663, 1403066.433556263, 1403066.433556263, 300076.2348302341]
[2019-03-27 07:43:23,247] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:43:23,250] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.6973478e-01 4.3804699e-15 4.7334239e-09 1.1404308e-17 8.3026522e-01], sampled 0.88330343649928
[2019-03-27 07:43:33,824] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.067820214]
[2019-03-27 07:43:33,827] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.63333333333333, 87.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8297550871580531, 6.9112, 6.9112, 168.912956510431, 694603.944030414, 694603.944030414, 208061.632453175]
[2019-03-27 07:43:33,829] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:43:33,831] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.2974413e-35 1.3776289e-34 9.2073540e-35 5.6986458e-19], sampled 0.1526095104690125
[2019-03-27 07:43:51,153] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7281.5773 3321384836.7074 1857.0000
[2019-03-27 07:43:51,368] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8068.8749 2943854322.9942 1101.0000
[2019-03-27 07:43:51,443] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7374.5991 3110207504.7139 1620.0000
[2019-03-27 07:43:51,474] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7054.0779 3187839351.3582 2017.0000
[2019-03-27 07:43:51,615] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7906.6190 2991891126.5706 1323.0000
[2019-03-27 07:43:52,631] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1600000, evaluation results [1600000.0, 7281.577289691006, 3321384836.707447, 1857.0, 7374.599105840488, 3110207504.7139273, 1620.0, 8068.874910913123, 2943854322.994165, 1101.0, 7054.0779249186235, 3187839351.3582363, 2017.0, 7906.619027044939, 2991891126.5705857, 1323.0]
[2019-03-27 07:44:00,546] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.9674412e-33 2.0697954e-33 9.2364610e-32 5.1964972e-20], sum to 1.0000
[2019-03-27 07:44:00,554] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9429
[2019-03-27 07:44:00,560] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8924969159885114, 6.9112, 6.9112, 168.912956510431, 735659.0437611971, 735659.0437611971, 221652.3342648697], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4460400.0000, 
sim time next is 4461000.0000, 
raw observation next is [30.33333333333333, 66.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8977260970513552, 6.911199999999999, 6.9112, 168.912956510431, 740722.0960106829, 740722.0960106836, 222888.8628312655], 
processed observation next is [0.0, 0.6521739130434783, 0.6366508688783569, 0.6683333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8752757281114087, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20575613778074525, 0.20575613778074545, 0.33266994452427684], 
reward next is 0.6673, 
noisyNet noise sample is [array([-0.67655957], dtype=float32), -0.7081015]. 
=============================================
[2019-03-27 07:44:00,572] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[49.905743]
 [48.604176]
 [45.947956]
 [43.44288 ]
 [40.517643]], R is [[50.73807144]
 [50.8998642 ]
 [51.04904556]
 [51.18503952]
 [50.67319107]].
[2019-03-27 07:44:15,203] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 4.2696917e-38 1.9784387e-38 6.7375735e-37 2.2376609e-23], sum to 1.0000
[2019-03-27 07:44:15,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5182
[2019-03-27 07:44:15,218] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8603219210843822, 6.9112, 6.9112, 168.912956510431, 712957.3532896775, 712957.3532896775, 214518.8076908155], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5133600.0000, 
sim time next is 5134200.0000, 
raw observation next is [30.16666666666666, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8624919457158704, 6.911200000000001, 6.9112, 168.912956510431, 714464.7514776031, 714464.7514776024, 214991.1555797802], 
processed observation next is [0.0, 0.43478260869565216, 0.6287519747235385, 0.655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8323072508730127, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19846243096600086, 0.19846243096600066, 0.32088232176086595], 
reward next is 0.6791, 
noisyNet noise sample is [array([2.544054], dtype=float32), -0.6571073]. 
=============================================
[2019-03-27 07:44:15,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.2020140e-01 6.7095994e-17 2.8645622e-13 6.3309322e-20 1.7979860e-01], sum to 1.0000
[2019-03-27 07:44:15,334] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8872
[2019-03-27 07:44:15,339] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5654780263458052, 1.0, 2.0, 0.5654780263458052, 1.0, 2.0, 0.98055633063578, 6.911199999999999, 6.9112, 170.5573041426782, 2372320.53476528, 2372320.534765281, 463069.6524009947], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4716000.0000, 
sim time next is 4716600.0000, 
raw observation next is [30.83333333333334, 67.5, 1.0, 2.0, 0.5163741248742303, 1.0, 2.0, 0.5163741248742303, 1.0, 2.0, 0.8960264181853554, 6.9112, 6.9112, 170.5573041426782, 2166132.247877279, 2166132.247877279, 426514.4192498345], 
processed observation next is [1.0, 0.6086956521739131, 0.6603475513428123, 0.675, 1.0, 1.0, 0.41731822274003644, 1.0, 1.0, 0.41731822274003644, 1.0, 1.0, 0.8732029490065311, 0.0, 0.0, 0.8375144448122397, 0.601703402188133, 0.601703402188133, 0.6365886854475141], 
reward next is 0.3634, 
noisyNet noise sample is [array([-0.21843384], dtype=float32), -1.69644]. 
=============================================
[2019-03-27 07:44:21,879] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.97204578e-01 3.39779855e-17 3.04862277e-12 5.35137583e-20
 1.02795385e-01], sum to 1.0000
[2019-03-27 07:44:21,887] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6704
[2019-03-27 07:44:21,894] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1764280.541060703 W.
[2019-03-27 07:44:21,900] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.4206573902869368, 1.0, 2.0, 0.4206573902869368, 1.0, 2.0, 0.727170771437768, 6.9112, 6.9112, 170.5573041426782, 1764280.541060703, 1764280.541060703, 364119.2423148758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4884000.0000, 
sim time next is 4884600.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.4224996857832085, 1.0, 2.0, 0.4224996857832085, 1.0, 2.0, 0.7303868947790986, 6.911200000000001, 6.9112, 170.5573041426782, 1772013.707522625, 1772013.707522624, 365193.9024930695], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.3042164888954319, 1.0, 1.0, 0.3042164888954319, 1.0, 1.0, 0.671203530218413, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4922260298673959, 0.49222602986739555, 0.5450655261090589], 
reward next is 0.4549, 
noisyNet noise sample is [array([-0.40455478], dtype=float32), 1.9135896]. 
=============================================
[2019-03-27 07:44:22,047] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.1271303e-28 1.5641470e-25 5.2734783e-28 3.1066323e-11], sum to 1.0000
[2019-03-27 07:44:22,054] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3118
[2019-03-27 07:44:22,059] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 871817.5325092521 W.
[2019-03-27 07:44:22,064] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.0, 75.0, 1.0, 2.0, 0.3119296716925709, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5417186830112398, 6.911200000000001, 6.9112, 168.912956510431, 871817.5325092521, 871817.5325092515, 225888.9679850931], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5341200.0000, 
sim time next is 5341800.0000, 
raw observation next is [31.75, 76.5, 1.0, 2.0, 0.31367964684021, 1.0, 1.0, 0.31367964684021, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 876707.0978934267, 876707.0978934267, 252592.0582120936], 
processed observation next is [1.0, 0.8260869565217391, 0.7037914691943128, 0.765, 1.0, 1.0, 0.17310800824121686, 1.0, 0.5, 0.17310800824121686, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24352974941484073, 0.24352974941484073, 0.37700307195834865], 
reward next is 0.0000, 
noisyNet noise sample is [array([-2.5279558], dtype=float32), 0.4195265]. 
=============================================
[2019-03-27 07:44:31,753] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2868393e-37 3.9328653e-25], sum to 1.0000
[2019-03-27 07:44:31,759] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4620
[2019-03-27 07:44:31,764] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8875510760664918, 6.911199999999999, 6.9112, 168.912956510431, 730100.8392509497, 730100.8392509504, 220460.0760950433], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5061600.0000, 
sim time next is 5062200.0000, 
raw observation next is [31.16666666666667, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9072507808684513, 6.911199999999999, 6.9112, 168.912956510431, 747134.1094698196, 747134.1094698202, 225051.9069551557], 
processed observation next is [0.0, 0.6086956521739131, 0.6761453396524489, 0.6233333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8868911961810383, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20753725263050543, 0.2075372526305056, 0.3358983685897846], 
reward next is 0.6641, 
noisyNet noise sample is [array([-0.11064884], dtype=float32), 0.67924947]. 
=============================================
[2019-03-27 07:44:32,146] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.9190953e-01 1.8797226e-14 1.1513535e-09 6.5923515e-17 4.0809053e-01], sum to 1.0000
[2019-03-27 07:44:32,152] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2196
[2019-03-27 07:44:32,162] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 3219799.587405927 W.
[2019-03-27 07:44:32,168] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.33333333333334, 71.33333333333334, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 9.399218107303343, 6.9112, 168.8986055746529, 3219799.587405927, 1454863.873740236, 308180.902710029], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4954800.0000, 
sim time next is 4955400.0000, 
raw observation next is [29.5, 70.0, 1.0, 2.0, 0.5589826893135117, 1.0, 1.0, 0.5589826893135117, 1.0, 1.0, 0.9581386205170896, 6.9112, 6.9112, 170.5573041426782, 2345045.417773349, 2345045.417773349, 455732.44106013], 
processed observation next is [1.0, 0.34782608695652173, 0.5971563981042655, 0.7, 1.0, 1.0, 0.4686538425463996, 1.0, 0.5, 0.4686538425463996, 1.0, 0.5, 0.948949537215963, 0.0, 0.0, 0.8375144448122397, 0.6514015049370414, 0.6514015049370414, 0.6801976732240747], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8233523], dtype=float32), -0.7834533]. 
=============================================
[2019-03-27 07:44:33,954] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 3.3993976e-38 2.5553832e-37 2.5564906e-25], sum to 1.0000
[2019-03-27 07:44:33,960] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5927
[2019-03-27 07:44:33,965] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8568016392164056, 6.911200000000001, 6.9112, 168.912956510431, 712394.8416375022, 712394.8416375016, 213814.1485409866], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5101200.0000, 
sim time next is 5101800.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.854232274770525, 6.911200000000001, 6.9112, 168.912956510431, 710540.4599146695, 710540.4599146689, 213255.6872539773], 
processed observation next is [0.0, 0.043478260869565216, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8222344814274694, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19737234997629707, 0.19737234997629693, 0.3182920705283243], 
reward next is 0.6817, 
noisyNet noise sample is [array([-1.1688334], dtype=float32), 1.4179343]. 
=============================================
[2019-03-27 07:44:43,022] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0382820e-37 1.4600068e-37 2.4945721e-35 6.7211220e-21], sum to 1.0000
[2019-03-27 07:44:43,037] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.2052
[2019-03-27 07:44:43,044] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.1, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8833966453732549, 6.9112, 6.9112, 168.912956510431, 729732.2027074888, 729732.2027074888, 219626.9823085113], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5618400.0000, 
sim time next is 5619000.0000, 
raw observation next is [26.05, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8805771788224406, 6.911199999999999, 6.9112, 168.912956510431, 727694.291853428, 727694.2918534287, 218996.0109904025], 
processed observation next is [0.0, 0.0, 0.43364928909952616, 0.9183333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8543624131980982, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2021373032926189, 0.20213730329261909, 0.3268597178961231], 
reward next is 0.6731, 
noisyNet noise sample is [array([-0.6814706], dtype=float32), 0.9490063]. 
=============================================
[2019-03-27 07:44:43,055] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[66.364975]
 [65.596725]
 [65.31867 ]
 [65.27595 ]
 [65.5808  ]], R is [[66.87721252]
 [66.88063812]
 [66.88388062]
 [66.88669586]
 [66.88851166]].
[2019-03-27 07:44:43,322] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.1082534e-38 3.0504669e-24], sum to 1.0000
[2019-03-27 07:44:43,334] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0968
[2019-03-27 07:44:43,342] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8708854689663331, 6.911200000000001, 6.9112, 168.912956510431, 721646.1178474359, 721646.1178474353, 216874.8636170184], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5095800.0000, 
sim time next is 5096400.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8696255808675319, 6.911199999999999, 6.9112, 168.912956510431, 720601.7797672334, 720601.779767234, 216592.0171950997], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8410068059360146, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2001671610464537, 0.20016716104645388, 0.32327166745537267], 
reward next is 0.6767, 
noisyNet noise sample is [array([-1.5407469], dtype=float32), 0.016851505]. 
=============================================
[2019-03-27 07:44:46,535] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-27 07:44:46,537] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:44:46,538] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:44:46,538] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:44:46,539] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:44:46,539] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:44:46,541] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:44:46,540] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:44:46,541] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:44:46,543] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:44:46,542] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:44:46,567] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run66
[2019-03-27 07:44:46,588] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run66
[2019-03-27 07:44:46,605] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run66
[2019-03-27 07:44:46,607] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run66
[2019-03-27 07:44:46,652] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run66
[2019-03-27 07:44:58,326] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.06828563]
[2019-03-27 07:44:58,328] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.7, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7449751675456704, 6.9112, 6.9112, 168.912956510431, 633902.4856587674, 633902.4856587674, 191049.9427816753]
[2019-03-27 07:44:58,329] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:44:58,333] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.2879152e-38 0.0000000e+00 1.0177459e-36 7.4328945e-25], sampled 0.49371889491434706
[2019-03-27 07:45:00,774] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.06828563]
[2019-03-27 07:45:00,775] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.85, 80.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5283769461971543, 6.911199999999999, 6.9112, 168.912956510431, 466660.1378950385, 466660.137895039, 155691.0906517908]
[2019-03-27 07:45:00,776] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:45:00,780] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.7937363e-38 0.0000000e+00 1.5328146e-36 6.2197329e-25], sampled 0.684695009382469
[2019-03-27 07:45:45,223] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.06828563]
[2019-03-27 07:45:45,224] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [35.66666666666667, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.95097791894152, 6.9112, 168.9125177376694, 857031.6788129515, 828811.9273700877, 254811.8527833656]
[2019-03-27 07:45:45,225] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:45:45,227] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.3284138e-29 4.2800479e-30 7.4923478e-29 6.7102479e-17], sampled 0.40774050847337684
[2019-03-27 07:45:54,505] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.06828563]
[2019-03-27 07:45:54,506] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.86666666666667, 68.0, 1.0, 2.0, 0.6775565574848246, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 6.979295167397333, 6.9112, 168.9125506630555, 1843722.939131921, 1795413.999797694, 380804.7895551]
[2019-03-27 07:45:54,508] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:45:54,511] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.5132283e-23 4.3563360e-20 2.5886407e-24 1.3983921e-08], sampled 0.8882024323735885
[2019-03-27 07:45:54,512] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1843722.939131921 W.
[2019-03-27 07:46:09,340] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.06828563]
[2019-03-27 07:46:09,340] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.937811055, 77.31839911333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8689041160094284, 6.9112, 6.9112, 168.912956510431, 721624.9274499976, 721624.9274499976, 216482.9584643263]
[2019-03-27 07:46:09,343] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:46:09,346] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.8402034e-27], sampled 0.35835348494837616
[2019-03-27 07:46:41,979] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8059.1966 2938607440.2494 1343.0000
[2019-03-27 07:46:42,349] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7255.2022 3319939097.8339 2202.0000
[2019-03-27 07:46:42,399] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7357.4804 3105568609.0605 1935.0000
[2019-03-27 07:46:42,539] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7917.4313 2989547122.3406 1558.0000
[2019-03-27 07:46:42,717] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7017.5640 3186428536.9062 2432.0000
[2019-03-27 07:46:43,735] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 1625000, evaluation results [1625000.0, 7255.202205936505, 3319939097.833915, 2202.0, 7357.480376737352, 3105568609.0605464, 1935.0, 8059.196551402984, 2938607440.2493825, 1343.0, 7017.564040578848, 3186428536.9061923, 2432.0, 7917.431254398165, 2989547122.3406363, 1558.0]
[2019-03-27 07:46:45,229] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0044092e-02 3.4626959e-18 2.1359733e-13 1.1919817e-20 9.8995590e-01], sum to 1.0000
[2019-03-27 07:46:45,235] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7659
[2019-03-27 07:46:45,241] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.0, 67.0, 1.0, 2.0, 0.5804099217710218, 1.0, 2.0, 0.5804099217710218, 1.0, 2.0, 1.007980089622051, 6.9112, 6.9112, 170.5573041426782, 2435024.572361656, 2435024.572361656, 475203.8808805172], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5233200.0000, 
sim time next is 5233800.0000, 
raw observation next is [32.0, 67.0, 1.0, 2.0, 0.5652499507898007, 1.0, 2.0, 0.5652499507898007, 1.0, 2.0, 0.9816522335066841, 6.911200000000001, 6.9112, 170.5573041426782, 2371362.793396872, 2371362.793396871, 463200.3267098831], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.67, 1.0, 1.0, 0.4762047599877116, 1.0, 1.0, 0.4762047599877116, 1.0, 1.0, 0.9776246750081512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6587118870546866, 0.6587118870546864, 0.6913437712087808], 
reward next is 0.3087, 
noisyNet noise sample is [array([-2.0914483], dtype=float32), -0.2050095]. 
=============================================
[2019-03-27 07:46:46,558] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.8278065e-03 9.0251678e-17 6.1909909e-12 9.7450992e-18 9.9117213e-01], sum to 1.0000
[2019-03-27 07:46:46,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6780
[2019-03-27 07:46:46,575] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.8, 75.33333333333333, 1.0, 2.0, 0.5560741689632763, 1.0, 2.0, 0.5560741689632763, 1.0, 2.0, 0.965716934951431, 6.9112, 6.9112, 170.5573041426782, 2332832.197880292, 2332832.197880292, 456087.9023666056], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5820000.0000, 
sim time next is 5820600.0000, 
raw observation next is [29.95, 74.66666666666667, 1.0, 2.0, 0.5620217342978938, 1.0, 2.0, 0.5620217342978938, 1.0, 2.0, 0.9760458890477495, 6.9112, 6.9112, 170.5573041426782, 2357806.853513199, 2357806.853513199, 460684.4212527571], 
processed observation next is [1.0, 0.34782608695652173, 0.6184834123222749, 0.7466666666666667, 1.0, 1.0, 0.4723153425275829, 1.0, 1.0, 0.4723153425275829, 1.0, 1.0, 0.9707876695704262, 0.0, 0.0, 0.8375144448122397, 0.6549463481981108, 0.6549463481981108, 0.6875886884369509], 
reward next is 0.3124, 
noisyNet noise sample is [array([1.8928944], dtype=float32), 0.2785752]. 
=============================================
[2019-03-27 07:46:46,676] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [7.7231359e-01 4.4554424e-15 5.3864566e-09 7.2157107e-18 2.2768635e-01], sum to 1.0000
[2019-03-27 07:46:46,687] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5392
[2019-03-27 07:46:46,692] A3C_AGENT_WORKER-Thread-10 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1071117.108790641 W.
[2019-03-27 07:46:46,697] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.33333333333334, 87.33333333333334, 1.0, 2.0, 0.3832034621211465, 1.0, 2.0, 0.3832034621211465, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1071117.108790641, 1071117.108790641, 267972.8128534225], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5203200.0000, 
sim time next is 5203800.0000, 
raw observation next is [26.5, 86.5, 1.0, 2.0, 0.7991852422181441, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1116957.04551935, 1116957.04551935, 243708.8027156428], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.865, 1.0, 1.0, 0.7580545086965592, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31026584597759727, 0.31026584597759727, 0.3637444816651385], 
reward next is 0.6363, 
noisyNet noise sample is [array([0.47530696], dtype=float32), 1.4717283]. 
=============================================
[2019-03-27 07:47:06,982] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [2.0833146e-02 1.8358050e-15 5.0834500e-11 3.8359463e-18 9.7916692e-01], sum to 1.0000
[2019-03-27 07:47:06,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3284
[2019-03-27 07:47:06,998] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 80.0, 1.0, 2.0, 0.5202966487529449, 1.0, 2.0, 0.5202966487529449, 1.0, 2.0, 0.9035832141528194, 6.9112, 6.9112, 170.5573041426782, 2182603.565261641, 2182603.565261641, 429464.9395596362], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [28.88333333333333, 79.5, 1.0, 2.0, 0.4965760019898702, 1.0, 2.0, 0.4965760019898702, 1.0, 2.0, 0.8623882952631149, 6.9112, 6.9112, 170.5573041426782, 2083000.566665225, 2083000.566665225, 412785.7651369861], 
processed observation next is [1.0, 0.43478260869565216, 0.5679304897314374, 0.795, 1.0, 1.0, 0.39346506263839776, 1.0, 1.0, 0.39346506263839776, 1.0, 1.0, 0.8321808478818473, 0.0, 0.0, 0.8375144448122397, 0.5786112685181181, 0.5786112685181181, 0.6160981569208748], 
reward next is 0.3839, 
noisyNet noise sample is [array([-1.4883127], dtype=float32), 0.16762677]. 
=============================================
[2019-03-27 07:47:07,012] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[28.854162]
 [28.607628]
 [27.58017 ]
 [26.638422]
 [26.094173]], R is [[29.88113403]
 [29.94132996]
 [30.00654984]
 [30.07316208]
 [30.13990974]].
[2019-03-27 07:47:11,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6669053e-27], sum to 1.0000
[2019-03-27 07:47:11,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2155
[2019-03-27 07:47:11,580] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.35, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9296643558082544, 6.9112, 6.9112, 168.912956510431, 758545.0581727669, 758545.0581727669, 230062.5343070616], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6251400.0000, 
sim time next is 6252000.0000, 
raw observation next is [28.5, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9287935333688111, 6.9112, 6.9112, 168.912956510431, 757887.8363718415, 757887.8363718415, 229856.4682734633], 
processed observation next is [0.0, 0.34782608695652173, 0.5497630331753555, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9131628455717209, 0.0, 0.0, 0.8294399451523027, 0.2105243989921782, 0.2105243989921782, 0.3430693556320348], 
reward next is 0.6569, 
noisyNet noise sample is [array([-0.03764959], dtype=float32), -0.26424956]. 
=============================================
[2019-03-27 07:47:11,604] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[68.99743 ]
 [69.00243 ]
 [68.99157 ]
 [68.92124 ]
 [68.827995]], R is [[68.94421387]
 [68.91139984]
 [68.87897491]
 [68.84736633]
 [68.81637573]].
[2019-03-27 07:47:16,840] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.2184112e-38 5.6381573e-22], sum to 1.0000
[2019-03-27 07:47:16,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0761
[2019-03-27 07:47:16,855] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.28333333333333, 86.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9161808029251907, 6.911200000000001, 6.9112, 168.912956510431, 751806.918324652, 751806.9183246514, 227044.2446153227], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6126600.0000, 
sim time next is 6127200.0000, 
raw observation next is [27.3, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.914192319538559, 6.9112, 6.9112, 168.912956510431, 749713.0219583681, 749713.0219583681, 226555.3328829794], 
processed observation next is [1.0, 0.9565217391304348, 0.4928909952606636, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8953564872421449, 0.0, 0.0, 0.8294399451523027, 0.20825361721065783, 0.20825361721065783, 0.33814228788504386], 
reward next is 0.6619, 
noisyNet noise sample is [array([0.84871954], dtype=float32), -1.8437625]. 
=============================================
[2019-03-27 07:47:23,620] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [7.9776126e-01 1.0132524e-18 2.3119778e-14 1.2094185e-20 2.0223880e-01], sum to 1.0000
[2019-03-27 07:47:23,628] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2264
[2019-03-27 07:47:23,638] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2054166.667853737 W.
[2019-03-27 07:47:23,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.53333333333333, 63.33333333333333, 1.0, 2.0, 0.8279324420146155, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005983229498887, 6.9112, 168.9123931710229, 2054166.667853737, 1986924.406919769, 414842.5555005044], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5835000.0000, 
sim time next is 5835600.0000, 
raw observation next is [32.6, 63.0, 1.0, 2.0, 0.6992692079892292, 1.0, 1.0, 0.6992692079892292, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1955379.069426351, 1955379.069426351, 373818.3162248828], 
processed observation next is [1.0, 0.5652173913043478, 0.7440758293838864, 0.63, 1.0, 1.0, 0.6376737445653363, 1.0, 0.5, 0.6376737445653363, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5431608526184308, 0.5431608526184308, 0.5579377854102728], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4891542], dtype=float32), 0.38165748]. 
=============================================
[2019-03-27 07:47:24,203] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.5430545e-33 2.8092014e-33 2.7076078e-33 1.3531722e-16], sum to 1.0000
[2019-03-27 07:47:24,209] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5282
[2019-03-27 07:47:24,217] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.921800828196619, 6.9112, 6.9112, 168.912956510431, 744766.3756012879, 744766.3756012879, 227822.46668979], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5853000.0000, 
sim time next is 5853600.0000, 
raw observation next is [30.8, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9334819863858116, 6.9112, 6.9112, 168.912956510431, 754519.772621221, 754519.772621221, 230623.5343485365], 
processed observation next is [1.0, 0.782608695652174, 0.6587677725118484, 0.71, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9188804712022092, 0.0, 0.0, 0.8294399451523027, 0.20958882572811696, 0.20958882572811696, 0.34421423037095], 
reward next is 0.6558, 
noisyNet noise sample is [array([0.8436101], dtype=float32), -0.7194128]. 
=============================================
[2019-03-27 07:47:29,186] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.7738534e-01 2.1067624e-18 1.3526382e-13 6.6014566e-21 2.2614714e-02], sum to 1.0000
[2019-03-27 07:47:29,195] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4851
[2019-03-27 07:47:29,202] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2296986.023223808 W.
[2019-03-27 07:47:29,206] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [30.26666666666667, 78.33333333333334, 1.0, 2.0, 0.8213061126851781, 1.0, 2.0, 0.8213061126851781, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2296986.023223808, 2296986.023223807, 430384.1310909477], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5934000.0000, 
sim time next is 5934600.0000, 
raw observation next is [30.3, 78.5, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.060510258045245, 6.9112, 168.9120242273574, 2389700.569134452, 2283775.31785226, 475746.2617147464], 
processed observation next is [1.0, 0.6956521739130435, 0.6350710900473934, 0.785, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 1.0365853658536586, 0.014931025804524456, 0.0, 0.8294353672156102, 0.6638057136484589, 0.6343820327367389, 0.7100690473354424], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.856158], dtype=float32), 1.4594616]. 
=============================================
[2019-03-27 07:47:29,237] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.8624710e-35 7.6209701e-36 3.1029244e-34 1.8109576e-17], sum to 1.0000
[2019-03-27 07:47:29,246] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7655
[2019-03-27 07:47:29,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.56666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9927889991457135, 6.9112, 6.9112, 168.912956510431, 798847.4121429699, 798847.4121429699, 245120.2535251363], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5941200.0000, 
sim time next is 5941800.0000, 
raw observation next is [29.45, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9965547173658996, 6.9112, 6.9112, 168.9128806108486, 801878.6402490415, 801878.6402490415, 246084.1320436652], 
processed observation next is [1.0, 0.782608695652174, 0.5947867298578199, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9957984358120726, 0.0, 0.0, 0.8294395724506061, 0.22274406673584485, 0.22274406673584485, 0.3672897493189033], 
reward next is 0.6327, 
noisyNet noise sample is [array([-1.3800607], dtype=float32), -0.060196377]. 
=============================================
[2019-03-27 07:47:29,671] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.1754940e-38 2.9101288e-26], sum to 1.0000
[2019-03-27 07:47:29,678] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6610
[2019-03-27 07:47:29,682] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8920096625399837, 6.9112, 6.9112, 168.912956510431, 733716.3506362874, 733716.3506362874, 221480.6910855356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6354000.0000, 
sim time next is 6354600.0000, 
raw observation next is [30.95, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8974389598134751, 6.911199999999999, 6.9112, 168.912956510431, 739497.611133854, 739497.6111338547, 222784.6507146549], 
processed observation next is [0.0, 0.5652173913043478, 0.6658767772511848, 0.6283333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8749255607481404, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20541600309273722, 0.20541600309273741, 0.3325144040517237], 
reward next is 0.6675, 
noisyNet noise sample is [array([0.34374037], dtype=float32), -1.7437788]. 
=============================================
[2019-03-27 07:47:37,823] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-27 07:47:37,825] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:47:37,827] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:47:37,828] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:47:37,829] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:47:37,830] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:47:37,830] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:47:37,831] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:47:37,833] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:47:37,834] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:47:37,835] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:47:37,863] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run67
[2019-03-27 07:47:37,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run67
[2019-03-27 07:47:37,905] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run67
[2019-03-27 07:47:37,905] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run67
[2019-03-27 07:47:37,955] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run67
[2019-03-27 07:48:26,000] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:48:26,001] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.6, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9784909948038442, 6.9112, 6.9112, 168.912956510431, 793554.6368394971, 793554.6368394971, 241837.2493527403]
[2019-03-27 07:48:26,002] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:48:26,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.5735939e-36 1.8708486e-38 1.6216592e-34 1.8177496e-22], sampled 0.47657585601781804
[2019-03-27 07:48:32,515] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:48:32,517] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.43333333333334, 67.66666666666666, 1.0, 2.0, 0.8925910527959469, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1247579.541886001, 1247579.541886001, 267910.2503383018]
[2019-03-27 07:48:32,518] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:48:32,522] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9998891e-01 2.0388112e-18 4.2421761e-15 1.7610203e-19 1.1068228e-05], sampled 0.20577425612132882
[2019-03-27 07:48:32,523] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1247579.541886001 W.
[2019-03-27 07:49:02,087] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:49:02,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.97356481, 89.325548165, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7697734021042585, 6.911199999999999, 6.9112, 168.912956510431, 651075.7354188716, 651075.7354188723, 195836.03884704]
[2019-03-27 07:49:02,090] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:49:02,092] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 5.8150876e-38 0.0000000e+00 1.1145733e-36 2.1552977e-23], sampled 0.6733578405802134
[2019-03-27 07:49:08,327] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:49:08,328] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.33524533833333, 99.45241125833334, 1.0, 2.0, 0.6556625304144189, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104251, 916280.3374454214, 916280.3374454207, 211568.3726601537]
[2019-03-27 07:49:08,329] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:49:08,331] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.4142916e-25 8.3634382e-25 2.1720173e-25 3.7986050e-13], sampled 0.32046541203655543
[2019-03-27 07:49:08,332] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 916280.3374454214 W.
[2019-03-27 07:49:23,526] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:49:23,529] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.672158265, 99.49127732500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7279900540311935, 6.9112, 6.9112, 168.912956510431, 621008.955895363, 621008.955895363, 187847.4774676805]
[2019-03-27 07:49:23,530] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:49:23,533] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4648876e-38 5.8702856e-26], sampled 0.22309063798990147
[2019-03-27 07:49:24,750] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.0676568]
[2019-03-27 07:49:24,752] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.40233427, 81.18976312, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6247375354467852, 6.911200000000001, 6.9112, 168.912956510431, 542215.0948427496, 542215.0948427491, 169954.1389239798]
[2019-03-27 07:49:24,754] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:49:24,756] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.0519809e-38 0.0000000e+00 5.9245855e-36 8.9284431e-25], sampled 0.13106448690540795
[2019-03-27 07:49:33,721] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8066.7485 2939209263.3273 1302.0000
[2019-03-27 07:49:33,784] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7010.8725 3187919935.7598 2409.0000
[2019-03-27 07:49:33,908] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7242.3538 3320893191.2551 2171.0000
[2019-03-27 07:49:34,088] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7912.1594 2990585324.8276 1547.0000
[2019-03-27 07:49:34,236] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7372.3002 3105780883.7487 1882.0000
[2019-03-27 07:49:35,253] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 1650000, evaluation results [1650000.0, 7242.35377966081, 3320893191.255094, 2171.0, 7372.300151599294, 3105780883.7486663, 1882.0, 8066.748500356682, 2939209263.3272724, 1302.0, 7010.872494768097, 3187919935.7597685, 2409.0, 7912.159363026148, 2990585324.8275623, 1547.0]
[2019-03-27 07:49:40,280] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [6.2018238e-02 1.2716303e-16 3.7868649e-11 8.9613012e-20 9.3798172e-01], sum to 1.0000
[2019-03-27 07:49:40,288] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9446
[2019-03-27 07:49:40,295] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.8, 80.0, 1.0, 2.0, 0.5202966487529447, 1.0, 2.0, 0.5202966487529447, 1.0, 1.0, 0.903583214152819, 6.911199999999999, 6.9112, 170.5573041426782, 2182603.56526164, 2182603.56526164, 429464.9468891664], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6170400.0000, 
sim time next is 6171000.0000, 
raw observation next is [28.88333333333333, 79.5, 1.0, 2.0, 0.4965760019898702, 1.0, 2.0, 0.4965760019898702, 1.0, 2.0, 0.8623882952631149, 6.9112, 6.9112, 170.5573041426782, 2083000.566665225, 2083000.566665225, 412785.7644155059], 
processed observation next is [1.0, 0.43478260869565216, 0.5679304897314374, 0.795, 1.0, 1.0, 0.39346506263839776, 1.0, 1.0, 0.39346506263839776, 1.0, 1.0, 0.8321808478818473, 0.0, 0.0, 0.8375144448122397, 0.5786112685181181, 0.5786112685181181, 0.6160981558440387], 
reward next is 0.3839, 
noisyNet noise sample is [array([0.29160953], dtype=float32), 1.4663584]. 
=============================================
[2019-03-27 07:49:40,316] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[36.773613]
 [36.505455]
 [36.420563]
 [35.598785]
 [34.873337]], R is [[37.1097641 ]
 [36.73866653]
 [36.76422501]
 [36.76325989]
 [36.7631073 ]].
[2019-03-27 07:49:42,110] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9918729e-01 2.9198090e-21 9.2082414e-17 2.2899543e-24 8.1267784e-04], sum to 1.0000
[2019-03-27 07:49:42,120] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1363
[2019-03-27 07:49:42,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1006241.0786163 W.
[2019-03-27 07:49:42,133] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [28.91666666666667, 76.5, 1.0, 2.0, 0.2400028414368376, 1.0, 2.0, 0.2400028414368376, 1.0, 2.0, 0.4129963383276173, 6.911199999999999, 6.9112, 170.5573041426782, 1006241.0786163, 1006241.078616301, 281750.4510532134], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 6196200.0000, 
sim time next is 6196800.0000, 
raw observation next is [28.83333333333334, 77.0, 1.0, 2.0, 0.4936730050537901, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 689828.4529432243, 689828.4529432243, 182613.5667544232], 
processed observation next is [1.0, 0.7391304347826086, 0.5655608214849924, 0.77, 1.0, 1.0, 0.38996747596842174, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.1916190147064512, 0.1916190147064512, 0.27255756232003464], 
reward next is 0.7274, 
noisyNet noise sample is [array([-1.3930364], dtype=float32), 1.5069587]. 
=============================================
[2019-03-27 07:49:45,247] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.177524e-25], sum to 1.0000
[2019-03-27 07:49:45,258] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6647
[2019-03-27 07:49:45,262] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666666, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9209489992327021, 6.9112, 6.9112, 168.912956510431, 752494.217547921, 752494.217547921, 228033.0289417249], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6262800.0000, 
sim time next is 6263400.0000, 
raw observation next is [30.68333333333333, 67.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9180854919714755, 6.911200000000001, 6.9112, 168.912956510431, 750647.4480241525, 750647.448024152, 227376.6256403496], 
processed observation next is [0.0, 0.4782608695652174, 0.6532385466034754, 0.6733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9001042585017992, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20851318000670904, 0.20851318000670888, 0.3393680979706711], 
reward next is 0.6606, 
noisyNet noise sample is [array([-0.2649361], dtype=float32), 0.10111926]. 
=============================================
[2019-03-27 07:49:50,808] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.1375404e-37 3.0281353e-25], sum to 1.0000
[2019-03-27 07:49:50,818] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0587
[2019-03-27 07:49:50,823] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.83333333333334, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9643809096784944, 6.9112, 6.9112, 168.912956510431, 784646.3347441991, 784646.3347441991, 238433.4429810701], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6351000.0000, 
sim time next is 6351600.0000, 
raw observation next is [31.66666666666667, 63.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9336443089953669, 6.9112, 6.9112, 168.912956510431, 761027.6653690584, 761027.6653690584, 230982.1524360543], 
processed observation next is [0.0, 0.5217391304347826, 0.6998420221169038, 0.6300000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9190784256041058, 0.0, 0.0, 0.8294399451523027, 0.21139657371362733, 0.21139657371362733, 0.34474948124784227], 
reward next is 0.6553, 
noisyNet noise sample is [array([-0.3241358], dtype=float32), 0.570115]. 
=============================================
[2019-03-27 07:49:52,045] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [8.1116062e-01 1.0458931e-18 9.3901979e-15 1.8314770e-21 1.8883941e-01], sum to 1.0000
[2019-03-27 07:49:52,054] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3028
[2019-03-27 07:49:52,067] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1924159.713317344 W.
[2019-03-27 07:49:52,071] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.48333333333333, 61.66666666666667, 1.0, 2.0, 0.4587431821350793, 1.0, 2.0, 0.4587431821350793, 1.0, 2.0, 0.7798801259210033, 6.9112, 6.9112, 170.5573041426782, 1924159.713317344, 1924159.713317344, 384996.6954603144], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6538200.0000, 
sim time next is 6538800.0000, 
raw observation next is [30.36666666666667, 62.33333333333334, 1.0, 2.0, 0.455514980856831, 1.0, 2.0, 0.455514980856831, 1.0, 2.0, 0.7742334441835085, 6.9112, 6.9112, 170.5573041426782, 1910607.221219179, 1910607.221219179, 382970.2616789407], 
processed observation next is [1.0, 0.6956521739130435, 0.6382306477093209, 0.6233333333333334, 1.0, 1.0, 0.3439939528395555, 1.0, 1.0, 0.3439939528395555, 1.0, 1.0, 0.7246749319311078, 0.0, 0.0, 0.8375144448122397, 0.5307242281164386, 0.5307242281164386, 0.5715974054909563], 
reward next is 0.4284, 
noisyNet noise sample is [array([-0.3593862], dtype=float32), -1.0789374]. 
=============================================
[2019-03-27 07:49:53,635] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [8.0760213e-04 2.7967069e-16 2.8283913e-11 1.1568505e-19 9.9919242e-01], sum to 1.0000
[2019-03-27 07:49:53,646] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1949
[2019-03-27 07:49:53,653] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.45, 59.66666666666667, 1.0, 2.0, 0.4062376884748875, 1.0, 2.0, 0.4062376884748875, 1.0, 2.0, 0.6781599314065111, 6.911199999999999, 6.9112, 170.5573041426782, 1703754.744240589, 1703754.744240589, 352335.4318640857], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7033800.0000, 
sim time next is 7034400.0000, 
raw observation next is [29.6, 59.0, 1.0, 2.0, 0.4369126921228172, 1.0, 2.0, 0.4369126921228172, 1.0, 2.0, 0.7297705081510986, 6.9112, 6.9112, 170.5573041426782, 1832515.253738282, 1832515.253738282, 369615.5823138875], 
processed observation next is [1.0, 0.43478260869565216, 0.6018957345971565, 0.59, 1.0, 1.0, 0.3215815567744786, 1.0, 1.0, 0.3215815567744786, 1.0, 1.0, 0.6704518392086568, 0.0, 0.0, 0.8375144448122397, 0.5090320149273005, 0.5090320149273005, 0.5516650482296828], 
reward next is 0.4483, 
noisyNet noise sample is [array([-1.2766738], dtype=float32), 1.5732235]. 
=============================================
[2019-03-27 07:49:55,018] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.4942177e-32 2.1924316e-30 6.1514214e-33 9.7422267e-16], sum to 1.0000
[2019-03-27 07:49:55,028] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2168
[2019-03-27 07:49:55,033] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.16666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8288024825212524, 6.911199999999999, 6.9112, 168.912956510431, 691267.0256857803, 691267.025685781, 207792.7393576029], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6659400.0000, 
sim time next is 6660000.0000, 
raw observation next is [25.1, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8260703962032917, 6.9112, 6.9112, 168.912956510431, 689207.0923656292, 689207.0923656292, 207216.098741904], 
processed observation next is [1.0, 0.08695652173913043, 0.38862559241706174, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7878907270771849, 0.0, 0.0, 0.8294399451523027, 0.1914464145460081, 0.1914464145460081, 0.3092777593162746], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.8867073], dtype=float32), -0.42619613]. 
=============================================
[2019-03-27 07:49:55,051] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[56.716732]
 [56.687454]
 [56.835335]
 [56.919197]
 [57.02937 ]], R is [[56.92090225]
 [57.0415535 ]
 [57.1605072 ]
 [57.27837753]
 [57.39516068]].
[2019-03-27 07:49:55,469] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.661974e-24], sum to 1.0000
[2019-03-27 07:49:55,477] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8821
[2019-03-27 07:49:55,480] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.3, 71.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8138791947693216, 6.9112, 6.9112, 168.912956510431, 680669.6979250896, 680669.6979250896, 204682.9249836143], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6550200.0000, 
sim time next is 6550800.0000, 
raw observation next is [28.2, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8095388957510679, 6.9112, 6.9112, 168.912956510431, 677163.9376616077, 677163.9376616077, 203778.4949775452], 
processed observation next is [1.0, 0.8260869565217391, 0.5355450236966824, 0.72, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.767730360672034, 0.0, 0.0, 0.8294399451523027, 0.18810109379489104, 0.18810109379489104, 0.30414700742917194], 
reward next is 0.6959, 
noisyNet noise sample is [array([-1.822914], dtype=float32), 0.0076074614]. 
=============================================
[2019-03-27 07:50:02,932] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.2213078e-01 3.2516167e-19 1.1743230e-14 7.3085254e-22 7.7786922e-01], sum to 1.0000
[2019-03-27 07:50:02,944] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8535
[2019-03-27 07:50:02,949] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.3773616735737622, 1.0, 1.0, 0.3773616735737622, 1.0, 1.0, 0.6511012542955075, 6.911200000000001, 6.9112, 170.5573041426782, 1582559.753297028, 1582559.753297027, 340157.0852246223], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6613200.0000, 
sim time next is 6613800.0000, 
raw observation next is [31.08333333333334, 65.0, 1.0, 2.0, 0.3756252900838957, 1.0, 2.0, 0.3756252900838957, 1.0, 2.0, 0.6479231441749708, 6.9112, 6.9112, 170.5573041426782, 1575272.446930068, 1575272.446930068, 339234.0060249562], 
processed observation next is [1.0, 0.5652173913043478, 0.6721958925750398, 0.65, 1.0, 1.0, 0.24774131335409122, 1.0, 1.0, 0.24774131335409122, 1.0, 1.0, 0.5706379807011839, 0.0, 0.0, 0.8375144448122397, 0.4375756797027967, 0.4375756797027967, 0.5063194119775465], 
reward next is 0.4937, 
noisyNet noise sample is [array([-0.6988253], dtype=float32), 1.3627452]. 
=============================================
[2019-03-27 07:50:13,571] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 5.5605695e-33 2.5211533e-31 4.3966107e-32 7.4554642e-19], sum to 1.0000
[2019-03-27 07:50:13,581] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5338
[2019-03-27 07:50:13,586] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6247114385294196, 6.911200000000001, 6.9112, 168.912956510431, 548351.653543969, 548351.6535439685, 169811.6298351666], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6751200.0000, 
sim time next is 6751800.0000, 
raw observation next is [21.95, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.628039935756559, 6.911199999999999, 6.9112, 168.912956510431, 551418.800703751, 551418.8007037516, 170336.2327768765], 
processed observation next is [1.0, 0.13043478260869565, 0.2393364928909953, 0.845, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5463901655567793, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1531718890843753, 0.15317188908437546, 0.2542331832490694], 
reward next is 0.7458, 
noisyNet noise sample is [array([0.16687816], dtype=float32), 0.8047631]. 
=============================================
[2019-03-27 07:50:22,767] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.4793464e-38 0.0000000e+00 1.1321080e-36 8.6105454e-24], sum to 1.0000
[2019-03-27 07:50:22,775] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9268
[2019-03-27 07:50:22,780] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.8, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7278270818046931, 6.9112, 6.9112, 168.912956510431, 619883.8812531757, 619883.8812531757, 187811.0365333011], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6916800.0000, 
sim time next is 6917400.0000, 
raw observation next is [24.75, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7282389352668995, 6.911200000000001, 6.9112, 168.912956510431, 620249.6057836277, 620249.6057836271, 187888.1033059874], 
processed observation next is [0.0, 0.043478260869565216, 0.3720379146919432, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6685840673986578, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1722915571621188, 0.17229155716211864, 0.28043000493430953], 
reward next is 0.7196, 
noisyNet noise sample is [array([-0.03065845], dtype=float32), -0.19164702]. 
=============================================
[2019-03-27 07:50:22,897] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.5153043e-37 0.0000000e+00 4.2585885e-35 1.9117638e-21], sum to 1.0000
[2019-03-27 07:50:22,904] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.2165
[2019-03-27 07:50:22,908] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.45, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7251047251483533, 6.911199999999999, 6.9112, 168.912956510431, 617743.96967423, 617743.9696742307, 187304.6690742101], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6921000.0000, 
sim time next is 6921600.0000, 
raw observation next is [24.4, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7291034623056525, 6.911200000000001, 6.9112, 168.912956510431, 621184.5767911518, 621184.5767911512, 188051.1548915208], 
processed observation next is [0.0, 0.08695652173913043, 0.3554502369668246, 0.8733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6696383686654299, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1725512713308755, 0.17255127133087533, 0.28067336550973254], 
reward next is 0.7193, 
noisyNet noise sample is [array([1.8665469], dtype=float32), 0.07075028]. 
=============================================
[2019-03-27 07:50:25,154] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9472473e-03 7.3392680e-19 1.5748659e-13 2.6953514e-22 9.9605274e-01], sum to 1.0000
[2019-03-27 07:50:25,162] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3627
[2019-03-27 07:50:25,172] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.51666666666667, 67.5, 1.0, 2.0, 0.4377539088057436, 1.0, 2.0, 0.4377539088057436, 1.0, 2.0, 0.7358198007039496, 6.9112, 6.9112, 170.5573041426782, 1836046.538578345, 1836046.538578345, 370880.0849442445], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7123800.0000, 
sim time next is 7124400.0000, 
raw observation next is [28.6, 67.0, 1.0, 2.0, 0.4524351983764913, 1.0, 2.0, 0.4524351983764913, 1.0, 2.0, 0.76066911503641, 6.911200000000001, 6.9112, 170.5573041426782, 1897677.974152636, 1897677.974152636, 379666.1951132785], 
processed observation next is [1.0, 0.4782608695652174, 0.5545023696682465, 0.67, 1.0, 1.0, 0.34028337153794136, 1.0, 1.0, 0.34028337153794136, 1.0, 1.0, 0.7081330671175732, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5271327705979545, 0.5271327705979545, 0.5666659628556395], 
reward next is 0.4333, 
noisyNet noise sample is [array([-0.5748619], dtype=float32), 0.36043477]. 
=============================================
[2019-03-27 07:50:29,148] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 07:50:29,151] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:50:29,152] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:50:29,153] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:50:29,154] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:50:29,155] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:50:29,157] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:50:29,156] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:50:29,158] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:50:29,160] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:50:29,159] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:50:29,179] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run68
[2019-03-27 07:50:29,205] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run68
[2019-03-27 07:50:29,225] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run68
[2019-03-27 07:50:29,226] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run68
[2019-03-27 07:50:29,242] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run68
[2019-03-27 07:52:20,188] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02767554], dtype=float32), 0.070240535]
[2019-03-27 07:52:20,191] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.5, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9400058721859791, 6.9112, 6.9112, 168.912956510431, 768222.3284771317, 768222.3284771317, 232612.1064149399]
[2019-03-27 07:52:20,193] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:52:20,196] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7710170e-38 5.5006596e-23], sampled 0.5669944291009783
[2019-03-27 07:52:24,345] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7007.4912 3188934928.5905 2375.0000
[2019-03-27 07:52:24,614] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8079.6041 2940283787.1623 1244.0000
[2019-03-27 07:52:24,675] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7243.8020 3320905595.3240 2129.0000
[2019-03-27 07:52:24,821] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7379.3014 3106315178.2255 1837.0000
[2019-03-27 07:52:24,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7910.6379 2991918572.0252 1517.0000
[2019-03-27 07:52:25,970] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 1675000, evaluation results [1675000.0, 7243.802012049758, 3320905595.3240438, 2129.0, 7379.301440387581, 3106315178.225471, 1837.0, 8079.604075100627, 2940283787.1622715, 1244.0, 7007.491156199336, 3188934928.5905304, 2375.0, 7910.637868366344, 2991918572.0251546, 1517.0]
[2019-03-27 07:52:27,000] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0623331e-36 5.0617216e-25], sum to 1.0000
[2019-03-27 07:52:27,009] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8747
[2019-03-27 07:52:27,014] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.23333333333333, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5796954092926365, 6.9112, 6.9112, 168.912956510431, 506334.9479582717, 506334.9479582717, 163014.4081599962], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7447200.0000, 
sim time next is 7447800.0000, 
raw observation next is [21.21666666666667, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5794232971577735, 6.9112, 6.9112, 168.912956510431, 506079.5579301456, 506079.5579301456, 162974.9417084234], 
processed observation next is [0.0, 0.17391304347826086, 0.20458135860979476, 0.9483333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4871015818997238, 0.0, 0.0, 0.8294399451523027, 0.140577654980596, 0.140577654980596, 0.2432461816543633], 
reward next is 0.7568, 
noisyNet noise sample is [array([1.2743436], dtype=float32), -0.61588526]. 
=============================================
[2019-03-27 07:52:30,913] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.8572899e-37 6.4196481e-38 3.1577407e-37 2.5931035e-20], sum to 1.0000
[2019-03-27 07:52:30,923] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4865
[2019-03-27 07:52:30,930] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7963976132829308, 6.9112, 6.9112, 168.912956510431, 669613.1630227771, 669613.1630227771, 201137.5193564771], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7162200.0000, 
sim time next is 7162800.0000, 
raw observation next is [25.86666666666667, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.789324440714106, 6.911199999999999, 6.9112, 168.912956510431, 663947.791400167, 663947.7914001676, 199698.9790256825], 
processed observation next is [1.0, 0.9130434782608695, 0.42496050552922615, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7430785862367146, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18442994205560195, 0.18442994205560212, 0.29805817765027237], 
reward next is 0.7019, 
noisyNet noise sample is [array([0.07380483], dtype=float32), -0.77648]. 
=============================================
[2019-03-27 07:52:32,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.3538930e-34 1.5523577e-35 5.4441225e-33 1.8194400e-17], sum to 1.0000
[2019-03-27 07:52:32,437] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2037
[2019-03-27 07:52:32,441] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.21666666666667, 90.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6589470205007713, 6.9112, 6.9112, 168.912956510431, 572208.7360456684, 572208.7360456684, 175542.4283631891], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7366200.0000, 
sim time next is 7366800.0000, 
raw observation next is [22.03333333333333, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6215249129996631, 6.9112, 6.9112, 168.912956510431, 540638.7765830187, 540638.7765830187, 169425.9985322396], 
processed observation next is [1.0, 0.2608695652173913, 0.2432859399684044, 0.9033333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5384450158532476, 0.0, 0.0, 0.8294399451523027, 0.15017743793972743, 0.15017743793972743, 0.2528746246749845], 
reward next is 0.7471, 
noisyNet noise sample is [array([1.2172487], dtype=float32), -0.87082565]. 
=============================================
[2019-03-27 07:52:35,565] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9992085e-01 6.5104337e-23 1.4476390e-17 1.4287886e-24 7.9202895e-05], sum to 1.0000
[2019-03-27 07:52:35,570] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.7823
[2019-03-27 07:52:35,580] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1716931.45505475 W.
[2019-03-27 07:52:35,584] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.4093769852469973, 1.0, 1.0, 0.4093769852469973, 1.0, 2.0, 0.710952440336239, 6.911200000000001, 6.9112, 170.5573041426782, 1716931.45505475, 1716931.45505475, 358140.1223793394], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7822800.0000, 
sim time next is 7823400.0000, 
raw observation next is [30.88333333333334, 69.66666666666667, 1.0, 2.0, 0.3880662196022858, 1.0, 2.0, 0.3880662196022858, 1.0, 2.0, 0.6739426879892673, 6.911199999999999, 6.9112, 170.5573041426782, 1627486.007858434, 1627486.007858435, 346380.661151771], 
processed observation next is [1.0, 0.5652173913043478, 0.6627172195892579, 0.6966666666666668, 1.0, 1.0, 0.26273038506299495, 1.0, 1.0, 0.26273038506299495, 1.0, 1.0, 0.6023691316942283, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4520794466273428, 0.45207944662734306, 0.5169860614205538], 
reward next is 0.4830, 
noisyNet noise sample is [array([-0.17644547], dtype=float32), -0.36072025]. 
=============================================
[2019-03-27 07:52:35,972] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 2.93979212e-37 3.78601608e-37 1.07766845e-35
 1.64232148e-19], sum to 1.0000
[2019-03-27 07:52:35,981] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8616
[2019-03-27 07:52:35,989] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.03333333333333, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5686449971430475, 6.9112, 6.9112, 168.912956510431, 498224.968041146, 498224.968041146, 161373.1631434282], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7426200.0000, 
sim time next is 7426800.0000, 
raw observation next is [21.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5713108217506908, 6.9112, 6.9112, 168.912956510431, 500233.0627675824, 500233.0627675824, 161765.3728682795], 
processed observation next is [1.0, 1.0, 0.19431279620853087, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4772083192081595, 0.0, 0.0, 0.8294399451523027, 0.13895362854655066, 0.13895362854655066, 0.24144085502728282], 
reward next is 0.7586, 
noisyNet noise sample is [array([-0.07595336], dtype=float32), -1.9560186]. 
=============================================
[2019-03-27 07:52:38,332] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 5.5614677e-38 0.0000000e+00 1.4669021e-36 2.3906165e-23], sum to 1.0000
[2019-03-27 07:52:38,339] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6095
[2019-03-27 07:52:38,343] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6531271204799867, 6.9112, 6.9112, 168.912956510431, 562537.1515428284, 562537.1515428284, 174615.7532631611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7470600.0000, 
sim time next is 7471200.0000, 
raw observation next is [23.7, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6557833052465017, 6.911199999999999, 6.9112, 168.912956510431, 564499.4048139412, 564499.4048139419, 175060.8958263061], 
processed observation next is [0.0, 0.4782608695652174, 0.3222748815165877, 0.8633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5802235429835387, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15680539022609477, 0.15680539022609497, 0.26128491914374047], 
reward next is 0.7387, 
noisyNet noise sample is [array([1.1986564], dtype=float32), 0.59194875]. 
=============================================
[2019-03-27 07:52:42,625] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [7.2434849e-01 3.6522249e-18 3.1950034e-13 4.3312195e-19 2.7565154e-01], sum to 1.0000
[2019-03-27 07:52:42,635] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8655
[2019-03-27 07:52:42,642] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.53333333333333, 62.66666666666667, 1.0, 2.0, 0.8677454967899709, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1296670.27253461, 1296670.27253461, 273022.2313862006], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7316400.0000, 
sim time next is 7317000.0000, 
raw observation next is [27.5, 63.0, 1.0, 2.0, 0.307017799285013, 1.0, 1.0, 0.307017799285013, 1.0, 1.0, 0.5272723157905649, 6.911199999999999, 6.9112, 170.5573041426782, 1347478.874462837, 1347478.874462838, 312309.7850341484], 
processed observation next is [1.0, 0.6956521739130435, 0.5023696682464456, 0.63, 1.0, 1.0, 0.16508168588555783, 1.0, 0.5, 0.16508168588555783, 1.0, 0.5, 0.4235028241348352, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.374299687350788, 0.37429968735078833, 0.4661340075136543], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.8168089], dtype=float32), 0.3426872]. 
=============================================
[2019-03-27 07:52:42,657] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[51.54535 ]
 [51.856   ]
 [51.431385]
 [50.565823]
 [51.9902  ]], R is [[51.02461624]
 [51.10687256]
 [50.59580612]
 [50.08984756]
 [50.16909027]].
[2019-03-27 07:52:43,846] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:52:43,847] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:52:43,907] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run9
[2019-03-27 07:52:48,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:52:48,860] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:52:48,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run9
[2019-03-27 07:52:50,338] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.0101697e-38 1.8225534e-38 1.3368995e-35 6.8887028e-21], sum to 1.0000
[2019-03-27 07:52:50,349] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4449
[2019-03-27 07:52:50,353] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.53333333333333, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7040784544428225, 6.911200000000001, 6.9112, 168.912956510431, 600089.9912196456, 600089.9912196449, 183453.472754205], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7482000.0000, 
sim time next is 7482600.0000, 
raw observation next is [25.6, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7057138414198754, 6.9112, 6.9112, 168.912956510431, 601354.902592889, 601354.902592889, 183748.0553740449], 
processed observation next is [0.0, 0.6086956521739131, 0.4123222748815167, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6411144407559456, 0.0, 0.0, 0.8294399451523027, 0.16704302849802474, 0.16704302849802474, 0.27425082891648495], 
reward next is 0.7257, 
noisyNet noise sample is [array([0.6852781], dtype=float32), 0.03405421]. 
=============================================
[2019-03-27 07:52:55,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:52:55,561] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:52:55,628] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run9
[2019-03-27 07:52:55,770] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 9.8775839e-30 8.1766396e-28 3.0151041e-29 2.7381938e-13], sum to 1.0000
[2019-03-27 07:52:55,774] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7057
[2019-03-27 07:52:55,777] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541971167068927, 6.9112, 6.9112, 168.912956510431, 638235.8368343628, 638235.8368343628, 192789.0903789737], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7610400.0000, 
sim time next is 7611000.0000, 
raw observation next is [23.86666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.332058850261001, 6.9112, 168.9110849819868, 1170873.940971971, 872305.4958801704, 256545.7381168591], 
processed observation next is [1.0, 0.08695652173913043, 0.33017377567140627, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04208588502610011, 0.0, 0.8294307550908522, 0.3252427613811031, 0.2423070821889362, 0.3829040867415808], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.49387142], dtype=float32), 1.3579729]. 
=============================================
[2019-03-27 07:52:55,793] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[62.274315]
 [62.01541 ]
 [61.956703]
 [62.035362]
 [62.067696]], R is [[60.76586151]
 [60.8704567 ]
 [60.97285461]
 [61.07294464]
 [61.1708107 ]].
[2019-03-27 07:52:59,767] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.3023573e-01 1.5335781e-19 2.5998792e-14 2.4950002e-22 8.6976433e-01], sum to 1.0000
[2019-03-27 07:52:59,782] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6164
[2019-03-27 07:52:59,789] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.58333333333334, 64.5, 1.0, 2.0, 0.4310595422449006, 1.0, 2.0, 0.4310595422449006, 1.0, 1.0, 0.7289009851284852, 6.9112, 6.9112, 170.5573041426782, 1850018.759950362, 1850018.759950362, 371223.0201931613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 53400.0000, 
sim time next is 54000.0000, 
raw observation next is [27.5, 65.0, 1.0, 2.0, 0.427053874483898, 1.0, 2.0, 0.427053874483898, 1.0, 2.0, 0.7213065197294756, 6.9112, 6.9112, 170.5573041426782, 1829808.481692348, 1829808.481692348, 368495.6593954188], 
processed observation next is [1.0, 0.6521739130434783, 0.5023696682464456, 0.65, 1.0, 1.0, 0.309703463233612, 1.0, 1.0, 0.309703463233612, 1.0, 1.0, 0.6601299021091165, 0.0, 0.0, 0.8375144448122397, 0.50828013380343, 0.50828013380343, 0.5499935214856998], 
reward next is 0.4500, 
noisyNet noise sample is [array([-1.5457454], dtype=float32), -0.72975993]. 
=============================================
[2019-03-27 07:52:59,805] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[50.417244]
 [49.79702 ]
 [49.48169 ]
 [49.902363]
 [51.732555]], R is [[51.57849121]
 [51.06270599]
 [50.55207825]
 [50.04655838]
 [49.54609299]].
[2019-03-27 07:53:01,385] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [3.6567375e-01 1.7862504e-19 1.3730164e-14 1.1773641e-21 6.3432622e-01], sum to 1.0000
[2019-03-27 07:53:01,402] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8791
[2019-03-27 07:53:01,407] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.73333333333333, 67.33333333333334, 1.0, 2.0, 0.4871391826784912, 1.0, 2.0, 0.4871391826784912, 1.0, 2.0, 0.8316724000643301, 6.9112, 6.9112, 170.5573041426782, 2043377.93620013, 2043377.93620013, 403828.7893762587], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7659600.0000, 
sim time next is 7660200.0000, 
raw observation next is [29.61666666666667, 68.16666666666666, 1.0, 2.0, 0.4973483490549006, 1.0, 2.0, 0.4973483490549006, 1.0, 2.0, 0.8498818040187663, 6.9112, 6.9112, 170.5573041426782, 2086243.50622154, 2086243.50622154, 410808.77532155], 
processed observation next is [1.0, 0.6521739130434783, 0.6026856240126385, 0.6816666666666665, 1.0, 1.0, 0.3943956012709646, 1.0, 1.0, 0.3943956012709646, 1.0, 1.0, 0.8169290292911785, 0.0, 0.0, 0.8375144448122397, 0.579512085061539, 0.579512085061539, 0.6131474258530597], 
reward next is 0.3869, 
noisyNet noise sample is [array([-0.74749994], dtype=float32), -0.03421254]. 
=============================================
[2019-03-27 07:53:03,230] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.2025974e-31 2.2872869e-29 4.3452417e-31 1.4973725e-10], sum to 1.0000
[2019-03-27 07:53:03,239] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0055
[2019-03-27 07:53:03,244] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.63333333333333, 67.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7829938133219781, 6.9112, 6.9112, 168.912956510431, 649019.0422519861, 649019.0422519861, 198175.8801510122], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7753200.0000, 
sim time next is 7753800.0000, 
raw observation next is [29.46666666666667, 68.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8051550520240423, 6.9112, 6.9112, 168.912956510431, 667409.9362700986, 667409.9362700986, 202697.0580238071], 
processed observation next is [1.0, 0.7391304347826086, 0.5955766192733019, 0.6883333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7623842097854174, 0.0, 0.0, 0.8294399451523027, 0.18539164896391627, 0.18539164896391627, 0.3025329224235927], 
reward next is 0.6975, 
noisyNet noise sample is [array([0.19224888], dtype=float32), 0.4326422]. 
=============================================
[2019-03-27 07:53:05,263] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:05,264] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:05,339] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run9
[2019-03-27 07:53:08,249] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.1644433e-37 2.8109429e-22], sum to 1.0000
[2019-03-27 07:53:08,257] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8867
[2019-03-27 07:53:08,262] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5249226120977225, 6.911199999999999, 6.9112, 168.912956510431, 462513.7222599693, 462513.72225997, 155277.2374071164], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 329400.0000, 
sim time next is 330000.0000, 
raw observation next is [21.43333333333333, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5235057677825985, 6.9112, 6.9112, 168.912956510431, 461361.9366500977, 461361.9366500977, 155087.744026452], 
processed observation next is [0.0, 0.8260869565217391, 0.21484992101105835, 0.8533333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4189094729056079, 0.0, 0.0, 0.8294399451523027, 0.12815609351391602, 0.12815609351391602, 0.23147424481560003], 
reward next is 0.7685, 
noisyNet noise sample is [array([-0.5220762], dtype=float32), 1.4658594]. 
=============================================
[2019-03-27 07:53:08,282] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[77.34754 ]
 [77.3061  ]
 [77.24864 ]
 [77.14379 ]
 [77.021805]], R is [[77.36543274]
 [77.3600235 ]
 [77.35437775]
 [77.34840393]
 [77.34190369]].
[2019-03-27 07:53:08,900] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:08,901] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:08,971] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run9
[2019-03-27 07:53:12,011] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:12,012] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:12,024] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:12,025] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:12,100] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run9
[2019-03-27 07:53:12,101] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run9
[2019-03-27 07:53:13,537] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [4.2126756e-02 4.2907248e-17 4.2028525e-12 3.7860132e-19 9.5787328e-01], sum to 1.0000
[2019-03-27 07:53:13,545] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.6584
[2019-03-27 07:53:13,551] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.56666666666667, 81.0, 1.0, 2.0, 0.402255246564283, 1.0, 2.0, 0.402255246564283, 1.0, 1.0, 0.6859295431122632, 6.9112, 6.9112, 170.5573041426782, 1687039.295745609, 1687039.295745609, 352340.080409723], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7892400.0000, 
sim time next is 7893000.0000, 
raw observation next is [27.7, 80.5, 1.0, 2.0, 0.4334963101493871, 1.0, 2.0, 0.4334963101493871, 1.0, 2.0, 0.7410954752905737, 6.911199999999999, 6.9112, 170.5573041426782, 1818173.981745841, 1818173.981745842, 370387.0186954518], 
processed observation next is [1.0, 0.34782608695652173, 0.5118483412322274, 0.805, 1.0, 1.0, 0.31746543391492427, 1.0, 1.0, 0.31746543391492427, 1.0, 1.0, 0.684262774744602, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5050483282627336, 0.5050483282627338, 0.5528164458141072], 
reward next is 0.4472, 
noisyNet noise sample is [array([0.15042615], dtype=float32), 0.5671599]. 
=============================================
[2019-03-27 07:53:13,577] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[47.044956]
 [48.00832 ]
 [48.54101 ]
 [47.236217]
 [47.94237 ]], R is [[46.77114487]
 [46.77755356]
 [46.89008331]
 [47.03372574]
 [46.56338882]].
[2019-03-27 07:53:14,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:14,333] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:14,406] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run9
[2019-03-27 07:53:14,711] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:14,712] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:14,772] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run9
[2019-03-27 07:53:16,048] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:16,049] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:16,116] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run9
[2019-03-27 07:53:16,629] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:16,631] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:16,693] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run9
[2019-03-27 07:53:16,741] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:16,742] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:16,788] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run9
[2019-03-27 07:53:16,871] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:16,872] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:16,908] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run9
[2019-03-27 07:53:16,924] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:16,927] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:16,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run9
[2019-03-27 07:53:17,039] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:17,040] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run9
[2019-03-27 07:53:17,150] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 07:53:17,151] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,170] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run9
[2019-03-27 07:53:17,798] A3C_AGENT_WORKER-Thread-9 INFO:Evaluating...
[2019-03-27 07:53:17,799] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:53:17,799] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,800] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:53:17,801] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,802] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:53:17,802] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:53:17,804] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,804] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:53:17,804] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,805] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:53:17,815] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run69
[2019-03-27 07:53:17,839] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run69
[2019-03-27 07:53:17,858] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run69
[2019-03-27 07:53:17,877] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run69
[2019-03-27 07:53:17,905] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run69
[2019-03-27 07:53:45,312] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:53:45,314] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.4, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6640943118314416, 6.9112, 6.9112, 168.912956510431, 574021.9305114633, 574021.9305114633, 176444.4751732971]
[2019-03-27 07:53:45,315] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:53:45,317] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.9754546e-36 6.1892107e-37 2.2890879e-34 6.0339782e-20], sampled 0.11766808780678217
[2019-03-27 07:54:04,363] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:04,365] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.86666666666667, 63.33333333333333, 1.0, 2.0, 0.7877765295633377, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.005980764811966, 6.9112, 168.9123160243098, 1997966.339774821, 1930725.858079254, 404834.1491796188]
[2019-03-27 07:54:04,367] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 07:54:04,369] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9982256e-01 2.6592136e-20 1.7390158e-16 7.9688278e-21 1.7747097e-04], sampled 0.8675568804792397
[2019-03-27 07:54:04,371] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1997966.339774821 W.
[2019-03-27 07:54:10,419] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:10,420] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.0, 70.0, 1.0, 2.0, 0.8943348813798614, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.988649453546309, 6.9112, 168.9124957263254, 2147106.934248165, 2092161.776185347, 433129.1690343701]
[2019-03-27 07:54:10,421] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:54:10,426] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [2.1301834e-01 5.6466186e-16 6.7558924e-11 1.9155294e-17 7.8698164e-01], sampled 0.2081460798740109
[2019-03-27 07:54:10,427] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2147106.934248165 W.
[2019-03-27 07:54:14,899] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:14,901] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [36.76666666666667, 49.0, 1.0, 2.0, 0.612351447539368, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956473142, 855729.2473209435, 855729.2473209435, 203069.2426222243]
[2019-03-27 07:54:14,903] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:54:14,906] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999368e-01 9.2062722e-21 3.1987925e-17 3.6384698e-21 6.3473954e-06], sampled 0.44735453974679673
[2019-03-27 07:54:22,490] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:22,491] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [37.11666666666667, 47.33333333333334, 1.0, 2.0, 0.8765727316104841, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1225177.726375963, 1225177.726375963, 263579.5887376218]
[2019-03-27 07:54:22,492] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:54:22,496] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9967313e-01 7.9725050e-20 2.3464208e-15 2.5184212e-20 3.2683156e-04], sampled 0.5989076442271198
[2019-03-27 07:54:22,499] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1225177.726375963 W.
[2019-03-27 07:54:23,662] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:23,663] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.13444293, 79.98116809, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.106411100893515, 6.9112, 168.9117437044384, 967343.4339452918, 828854.9546872675, 254812.5304268156]
[2019-03-27 07:54:23,664] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:54:23,666] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.3232745e-30 1.5137549e-29 2.7526032e-29 2.1806179e-14], sampled 0.6436355171466613
[2019-03-27 07:54:23,667] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 967343.4339452918 W.
[2019-03-27 07:54:36,558] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:36,560] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.1, 88.0, 1.0, 2.0, 0.3928751648359546, 1.0, 2.0, 0.3928751648359546, 1.0, 2.0, 0.6822942355176593, 6.911199999999999, 6.9112, 170.5573041426782, 1647669.438351648, 1647669.438351649, 348980.7599073297]
[2019-03-27 07:54:36,562] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:54:36,566] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.7049791e-01 3.4033659e-16 1.4385858e-11 2.0149041e-17 6.2950206e-01], sampled 0.5479879616282983
[2019-03-27 07:54:51,864] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:54:51,867] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.7, 60.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9558545941835734, 6.9112, 6.9112, 168.912956510431, 776023.591791735, 776023.591791735, 236238.0786796576]
[2019-03-27 07:54:51,869] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:54:51,872] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 3.56214576e-37 1.20150962e-37 1.10086194e-35
 5.76698536e-19], sampled 0.33954357638674393
[2019-03-27 07:55:06,113] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:55:06,114] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.96666666666667, 92.0, 1.0, 1.0, 0.6707358758325481, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9126783639938, 1066900.55626855, 1066900.556268551, 229818.8056655511]
[2019-03-27 07:55:06,115] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:55:06,116] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.4917473e-30 1.6936113e-30 2.9304661e-29 9.0499065e-16], sampled 0.8266563216646183
[2019-03-27 07:55:06,118] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1066900.55626855 W.
[2019-03-27 07:55:11,814] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:55:11,814] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.8, 79.33333333333333, 1.0, 2.0, 0.6310290498698266, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 881841.0591491337, 881841.0591491337, 206666.0492721985]
[2019-03-27 07:55:11,817] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 07:55:11,820] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9979001e-01 1.3348150e-20 9.9051920e-17 3.2885084e-21 2.1005768e-04], sampled 0.17308817352703032
[2019-03-27 07:55:11,821] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 881841.0591491337 W.
[2019-03-27 07:55:12,736] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:55:12,736] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.05, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9109495204703194, 6.9112, 6.9112, 168.912956510431, 744888.8867115227, 744888.8867115227, 225698.3977212861]
[2019-03-27 07:55:12,737] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:55:12,740] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.288771e-22], sampled 0.23964311231391666
[2019-03-27 07:55:13,680] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02825493], dtype=float32), 0.072981365]
[2019-03-27 07:55:13,682] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.79216215833333, 75.31240763, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.215515653356074, 6.9112, 168.9112746832859, 1055513.365852137, 839623.5172114412, 255409.3303756856]
[2019-03-27 07:55:13,684] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:55:13,687] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.6404530e-37 0.0000000e+00 2.5344746e-35 5.6220923e-22], sampled 0.6231898024811724
[2019-03-27 07:55:13,688] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1055513.365852137 W.
[2019-03-27 07:55:14,286] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7280.9015 3320146484.0217 2015.0000
[2019-03-27 07:55:14,296] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7058.0512 3187310865.2297 2124.0000
[2019-03-27 07:55:14,318] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7920.6990 2992573111.4835 1429.0000
[2019-03-27 07:55:14,362] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8068.0787 2941717469.4048 1176.0000
[2019-03-27 07:55:14,462] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7388.4709 3108085656.7991 1765.0000
[2019-03-27 07:55:15,480] A3C_AGENT_WORKER-Thread-9 INFO:Global step: 1700000, evaluation results [1700000.0, 7280.901493836275, 3320146484.0217237, 2015.0, 7388.470859815016, 3108085656.799091, 1765.0, 8068.078669031151, 2941717469.4048233, 1176.0, 7058.0512456220595, 3187310865.2297273, 2124.0, 7920.699016723462, 2992573111.4834766, 1429.0]
[2019-03-27 07:55:19,082] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.2753737e-35 5.3221035e-35 3.3163675e-33 1.7776852e-18], sum to 1.0000
[2019-03-27 07:55:19,092] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7574
[2019-03-27 07:55:19,096] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [17.6, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4057838040479443, 6.911200000000001, 6.9112, 168.912956510431, 367157.5882223534, 367157.5882223528, 140886.9694551349], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 624600.0000, 
sim time next is 625200.0000, 
raw observation next is [17.83333333333333, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3927821884300009, 6.9112, 6.9112, 168.912956510431, 355133.0624680157, 355133.0624680157, 139666.4325080613], 
processed observation next is [1.0, 0.21739130434782608, 0.044233807266982464, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.259490473695123, 0.0, 0.0, 0.8294399451523027, 0.09864807290778214, 0.09864807290778214, 0.20845736195233028], 
reward next is 0.7915, 
noisyNet noise sample is [array([-0.43516886], dtype=float32), 1.7001241]. 
=============================================
[2019-03-27 07:55:19,483] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.2029139e-33 1.0154920e-30 1.8526449e-32 4.8279451e-15], sum to 1.0000
[2019-03-27 07:55:19,491] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1233
[2019-03-27 07:55:19,500] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6157127148951701, 6.9112, 6.9112, 168.912956510431, 535770.6797168505, 535770.6797168505, 168509.3564472383], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 88200.0000, 
sim time next is 88800.0000, 
raw observation next is [22.3, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6161956072154033, 6.911200000000001, 6.9112, 168.912956510431, 536190.0994677328, 536190.0994677322, 168584.9125472638], 
processed observation next is [1.0, 0.0, 0.25592417061611383, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.531945862457809, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14894169429659246, 0.1489416942965923, 0.2516192724586027], 
reward next is 0.7484, 
noisyNet noise sample is [array([-0.31895167], dtype=float32), 0.028598351]. 
=============================================
[2019-03-27 07:55:24,700] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.8455690e-37 1.4973706e-35 4.9748075e-35 2.1095399e-18], sum to 1.0000
[2019-03-27 07:55:24,709] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5360
[2019-03-27 07:55:24,713] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.16666666666666, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5395450716029457, 6.9112, 6.9112, 168.912956510431, 475323.1578026265, 475323.1578026265, 157231.274679956], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 177000.0000, 
sim time next is 177600.0000, 
raw observation next is [20.13333333333333, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5395372919728835, 6.911200000000001, 6.9112, 168.912956510431, 475464.3975567184, 475464.3975567178, 157224.8726274876], 
processed observation next is [0.0, 0.043478260869565216, 0.15323854660347538, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.438460112162053, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1320734437657551, 0.13207344376575494, 0.23466398899625016], 
reward next is 0.7653, 
noisyNet noise sample is [array([-1.8046664], dtype=float32), 0.22766027]. 
=============================================
[2019-03-27 07:55:28,048] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.5836286e-38 1.2312084e-38 1.5991562e-35 2.1607473e-23], sum to 1.0000
[2019-03-27 07:55:28,056] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2592
[2019-03-27 07:55:28,062] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.13333333333333, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5511402397380988, 6.911199999999999, 6.9112, 168.912956510431, 484301.3616666102, 484301.3616666108, 158861.5847912312], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 214800.0000, 
sim time next is 215400.0000, 
raw observation next is [21.21666666666667, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5532731379642186, 6.9112, 6.9112, 168.912956510431, 485981.2259200464, 485981.2259200464, 159164.0309180335], 
processed observation next is [0.0, 0.4782608695652174, 0.20458135860979476, 0.9033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4552111438588032, 0.0, 0.0, 0.8294399451523027, 0.13499478497779066, 0.13499478497779066, 0.23755825510154255], 
reward next is 0.7624, 
noisyNet noise sample is [array([-0.33442733], dtype=float32), 2.4202058]. 
=============================================
[2019-03-27 07:55:28,142] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 8.8054675e-38 2.0973942e-38 6.4072750e-36 7.0892282e-22], sum to 1.0000
[2019-03-27 07:55:28,151] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-27 07:55:28,157] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.45, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.522938818036655, 6.9112, 6.9112, 168.912956510431, 460736.3540841753, 460736.3540841753, 155018.0442714446], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 286200.0000, 
sim time next is 286800.0000, 
raw observation next is [21.6, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5265366796259681, 6.911200000000001, 6.9112, 168.912956510431, 463633.9896210014, 463633.9896210007, 155500.5119248972], 
processed observation next is [0.0, 0.30434782608695654, 0.22274881516587688, 0.8533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4226057068609366, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12878721933916706, 0.12878721933916687, 0.23209031630581672], 
reward next is 0.7679, 
noisyNet noise sample is [array([1.3906536], dtype=float32), 1.1336092]. 
=============================================
[2019-03-27 07:55:34,302] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.1128193e-37 1.5109960e-38 1.8774073e-35 7.0569347e-21], sum to 1.0000
[2019-03-27 07:55:34,306] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7563
[2019-03-27 07:55:34,309] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.43333333333333, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5235057677825985, 6.9112, 6.9112, 168.912956510431, 461361.9366500977, 461361.9366500977, 155087.744026452], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 330000.0000, 
sim time next is 330600.0000, 
raw observation next is [21.36666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5220686014699012, 6.911200000000001, 6.9112, 168.912956510431, 460192.6131244791, 460192.6131244785, 154896.0905721651], 
processed observation next is [0.0, 0.8260869565217391, 0.21169036334913136, 0.8566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4171568310608551, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12783128142346642, 0.12783128142346625, 0.2311881948838285], 
reward next is 0.7688, 
noisyNet noise sample is [array([-0.43427557], dtype=float32), -0.84429944]. 
=============================================
[2019-03-27 07:55:35,542] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.5063533e-32 2.3090812e-29 5.8347289e-31 2.2007019e-15], sum to 1.0000
[2019-03-27 07:55:35,547] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6670
[2019-03-27 07:55:35,553] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380819683718032, 6.9112, 6.9112, 168.912956510431, 392091.3341572003, 392091.3341572003, 144566.3085357126], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 438600.0000, 
sim time next is 439200.0000, 
raw observation next is [19.6, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4380079897986804, 6.9112, 6.9112, 168.912956510431, 392025.231553235, 392025.231553235, 144558.3627430701], 
processed observation next is [1.0, 0.08695652173913043, 0.127962085308057, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3146438899983907, 0.0, 0.0, 0.8294399451523027, 0.10889589765367638, 0.10889589765367638, 0.21575875036279119], 
reward next is 0.7842, 
noisyNet noise sample is [array([2.2761755], dtype=float32), -0.8613475]. 
=============================================
[2019-03-27 07:55:39,920] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.9039919e-35 3.0898945e-35 4.0599031e-34 1.5486404e-16], sum to 1.0000
[2019-03-27 07:55:39,929] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8110
[2019-03-27 07:55:39,934] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.85, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4294395550112745, 6.9112, 6.9112, 168.912956510431, 385719.082205185, 385719.082205185, 143546.2576579197], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 516600.0000, 
sim time next is 517200.0000, 
raw observation next is [18.83333333333333, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4286021175926546, 6.9112, 6.9112, 168.912956510431, 385011.7829843339, 385011.7829843339, 143454.9842249587], 
processed observation next is [1.0, 1.0, 0.0916271721958924, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.30317331413738363, 0.0, 0.0, 0.8294399451523027, 0.10694771749564831, 0.10694771749564831, 0.2141119167536697], 
reward next is 0.7859, 
noisyNet noise sample is [array([1.0378584], dtype=float32), -1.2947905]. 
=============================================
[2019-03-27 07:55:41,558] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.1895956e-33 2.1128117e-31 1.8528004e-32 2.2446525e-17], sum to 1.0000
[2019-03-27 07:55:41,567] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2600
[2019-03-27 07:55:41,570] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.8, 76.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4494010088947544, 6.9112, 6.9112, 168.912956510431, 402064.8347357412, 402064.8347357412, 145809.1115374012], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 546000.0000, 
sim time next is 546600.0000, 
raw observation next is [21.0, 75.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4488154575685846, 6.9112, 6.9112, 168.912956510431, 401287.8421324504, 401287.8421324504, 145761.7321070585], 
processed observation next is [1.0, 0.30434782608695654, 0.19431279620853087, 0.7583333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3278237287421763, 0.0, 0.0, 0.8294399451523027, 0.11146884503679177, 0.11146884503679177, 0.2175548240403858], 
reward next is 0.7824, 
noisyNet noise sample is [array([-0.6519885], dtype=float32), 0.64300525]. 
=============================================
[2019-03-27 07:55:43,287] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.99999881e-01 7.58400570e-25 5.60365640e-22 1.43475618e-25
 1.02049576e-07], sum to 1.0000
[2019-03-27 07:55:43,297] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5027
[2019-03-27 07:55:43,305] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 982000.7206287119 W.
[2019-03-27 07:55:43,314] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.0, 79.66666666666667, 1.0, 2.0, 0.3137182646984046, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5628570024820647, 6.911200000000001, 6.9112, 168.9129565051853, 982000.7206287119, 982000.7206287113, 235667.5467583061], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1154400.0000, 
sim time next is 1155000.0000, 
raw observation next is [23.2, 78.83333333333333, 1.0, 2.0, 0.2162712066022398, 1.0, 1.0, 0.2162712066022398, 1.0, 2.0, 0.3854043206169527, 6.911199999999999, 6.9112, 170.5573041426782, 1004296.709392562, 1004296.709392562, 285197.7024774539], 
processed observation next is [1.0, 0.34782608695652173, 0.29857819905213273, 0.7883333333333333, 1.0, 1.0, 0.05574844168944554, 1.0, 0.5, 0.05574844168944554, 1.0, 1.0, 0.250493073923113, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2789713081646006, 0.2789713081646006, 0.42566821265291627], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.25777298], dtype=float32), -0.22457124]. 
=============================================
[2019-03-27 07:55:43,326] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[60.480114]
 [64.09809 ]
 [70.783   ]
 [72.34367 ]
 [72.93165 ]], R is [[57.53538895]
 [56.96003723]
 [56.99378204]
 [56.90483475]
 [57.04767227]].
[2019-03-27 07:55:49,614] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.7465436e-34 1.1210303e-34 9.0652778e-32 4.0392712e-16], sum to 1.0000
[2019-03-27 07:55:49,624] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1893
[2019-03-27 07:55:49,631] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5392784814009405, 6.9112, 6.9112, 168.912956510431, 474221.064246657, 474221.064246657, 157224.865867614], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 869400.0000, 
sim time next is 870000.0000, 
raw observation next is [21.16666666666667, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5372378548083921, 6.9112, 6.9112, 168.912956510431, 472572.1071909757, 472572.1071909757, 156944.290237721], 
processed observation next is [0.0, 0.043478260869565216, 0.2022116903633494, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4356559204980392, 0.0, 0.0, 0.8294399451523027, 0.13127002977527102, 0.13127002977527102, 0.23424520931003134], 
reward next is 0.7658, 
noisyNet noise sample is [array([1.3625965], dtype=float32), 0.6791716]. 
=============================================
[2019-03-27 07:55:49,647] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[75.166176]
 [75.140686]
 [75.219505]
 [75.15628 ]
 [75.04126 ]], R is [[75.13480377]
 [75.14878845]
 [75.16229248]
 [75.17540741]
 [75.18809509]].
[2019-03-27 07:55:55,924] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.6143943e-01 1.7430205e-18 1.3356062e-12 1.5964725e-20 8.3856058e-01], sum to 1.0000
[2019-03-27 07:55:55,933] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0818
[2019-03-27 07:55:55,942] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1078238.086327402 W.
[2019-03-27 07:55:55,949] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.13333333333333, 74.66666666666667, 1.0, 2.0, 0.2348002367355767, 1.0, 2.0, 0.2348002367355767, 1.0, 2.0, 0.415489488162034, 6.9112, 6.9112, 170.5573041426782, 1078238.086327402, 1078238.086327402, 290235.2224600998], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1158000.0000, 
sim time next is 1158600.0000, 
raw observation next is [24.31666666666667, 73.83333333333333, 1.0, 2.0, 0.7180931574426325, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1112755.700335567, 1112755.700335566, 238489.4654459638], 
processed observation next is [1.0, 0.391304347826087, 0.3515007898894157, 0.7383333333333333, 1.0, 1.0, 0.6603532017381114, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30909880564876857, 0.3090988056487683, 0.35595442603875194], 
reward next is 0.6440, 
noisyNet noise sample is [array([0.3810989], dtype=float32), 1.3492081]. 
=============================================
[2019-03-27 07:56:00,057] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 2.08237860e-34 1.27054570e-34 1.14602346e-32
 3.23057731e-15], sum to 1.0000
[2019-03-27 07:56:00,067] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8112
[2019-03-27 07:56:00,073] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4767070422039577, 6.9112, 6.9112, 168.912956510431, 424576.881604003, 424576.881604003, 149043.8606708963], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 786000.0000, 
sim time next is 786600.0000, 
raw observation next is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4760469126082872, 6.911200000000001, 6.9112, 168.912956510431, 423988.3716942294, 423988.3716942288, 148966.0716965325], 
processed observation next is [0.0, 0.08695652173913043, 0.11848341232227487, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36103282025400874, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11777454769284151, 0.11777454769284133, 0.22233742044258584], 
reward next is 0.7777, 
noisyNet noise sample is [array([0.33338958], dtype=float32), 1.610181]. 
=============================================
[2019-03-27 07:56:03,350] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.7648323e-36 2.7363525e-38 3.0232492e-35 5.0467944e-19], sum to 1.0000
[2019-03-27 07:56:03,355] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2904
[2019-03-27 07:56:03,358] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613115436100753, 6.911200000000001, 6.9112, 168.912956510431, 492077.1015525088, 492077.1015525082, 160320.529328531], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 842400.0000, 
sim time next is 843000.0000, 
raw observation next is [22.93333333333333, 78.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5594104570357795, 6.9112, 6.9112, 168.912956510431, 490571.6716944638, 490571.6716944638, 160047.4965250248], 
processed observation next is [0.0, 0.782608695652174, 0.28593996840442326, 0.7816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46269567931192623, 0.0, 0.0, 0.8294399451523027, 0.13626990880401774, 0.13626990880401774, 0.23887686048511164], 
reward next is 0.7611, 
noisyNet noise sample is [array([-1.7406002], dtype=float32), 1.8405925]. 
=============================================
[2019-03-27 07:56:03,378] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[82.28481 ]
 [82.16259 ]
 [82.11895 ]
 [82.07898 ]
 [82.031624]], R is [[82.32154083]
 [82.25904846]
 [82.19734192]
 [82.13636017]
 [82.07588196]].
[2019-03-27 07:56:05,352] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.2257141e-31 4.2128605e-28 1.2697882e-29 9.2069347e-12], sum to 1.0000
[2019-03-27 07:56:05,361] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3980
[2019-03-27 07:56:05,365] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5917626198251313, 6.9112, 6.9112, 168.912956510431, 514372.6652571354, 514372.6652571354, 164851.103630298], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 974400.0000, 
sim time next is 975000.0000, 
raw observation next is [21.9, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5916898600286233, 6.9112, 6.9112, 168.912956510431, 514308.967366375, 514308.967366375, 164840.203328374], 
processed observation next is [1.0, 0.2608695652173913, 0.23696682464454974, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5020608049129552, 0.0, 0.0, 0.8294399451523027, 0.1428636020462153, 0.1428636020462153, 0.24603015422145372], 
reward next is 0.7540, 
noisyNet noise sample is [array([-0.21366307], dtype=float32), 1.2218896]. 
=============================================
[2019-03-27 07:56:05,378] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[70.5676  ]
 [70.51707 ]
 [70.502914]
 [70.45597 ]
 [70.418015]], R is [[70.64466858]
 [70.69217682]
 [70.73905945]
 [70.78702545]
 [70.83415222]].
[2019-03-27 07:56:07,573] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 07:56:07,574] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:56:07,574] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:56:07,575] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:56:07,575] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:56:07,576] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:56:07,576] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:56:07,576] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:56:07,577] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:56:07,578] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:56:07,579] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:56:07,597] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run70
[2019-03-27 07:56:07,613] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run70
[2019-03-27 07:56:07,633] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run70
[2019-03-27 07:56:07,656] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run70
[2019-03-27 07:56:07,678] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run70
[2019-03-27 07:56:09,263] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074516654]
[2019-03-27 07:56:09,263] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.06025958, 80.790570465, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4679204887269883, 6.9112, 6.9112, 168.912956510431, 418354.8905838087, 418354.8905838087, 147917.8353308767]
[2019-03-27 07:56:09,264] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:56:09,268] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.9913774e-32 1.0516010e-34 2.6800414e-30 7.6414674e-20], sampled 0.7549939850940914
[2019-03-27 07:56:27,407] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074516654]
[2019-03-27 07:56:27,408] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.03333333333333, 95.0, 1.0, 2.0, 0.7360958621870632, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564546227, 1091731.724511134, 1091731.724511134, 237183.8030886917]
[2019-03-27 07:56:27,412] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:56:27,415] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.0178132e-26 6.8645587e-24 1.7927211e-26 1.8446352e-08], sampled 0.6477281583534571
[2019-03-27 07:56:27,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1091731.724511134 W.
[2019-03-27 07:57:33,190] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074516654]
[2019-03-27 07:57:33,192] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.6, 68.0, 1.0, 2.0, 0.57326073539642, 1.0, 2.0, 0.57326073539642, 1.0, 2.0, 0.9955643171614303, 6.9112, 6.9112, 170.5573041426782, 2405002.348081159, 2405002.348081159, 469503.6250932429]
[2019-03-27 07:57:33,193] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 07:57:33,196] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [3.0487332e-01 9.5078288e-21 2.9386859e-15 8.4033427e-22 6.9512665e-01], sampled 0.7615473826845476
[2019-03-27 07:57:39,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074516654]
[2019-03-27 07:57:39,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.80306551333333, 86.91589006833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.815906063878187, 6.911200000000001, 6.9112, 168.912956510431, 685885.7988340415, 685885.7988340409, 205187.9928189452]
[2019-03-27 07:57:39,462] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:57:39,466] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.0049607e-36 1.6856653e-36 3.5762823e-35 1.8334303e-17], sampled 0.9863571641757262
[2019-03-27 07:58:03,306] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8109.0772 2951787982.0590 980.0000
[2019-03-27 07:58:03,628] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7949.4172 3000534736.5550 1156.0000
[2019-03-27 07:58:03,884] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7370.2883 3325701466.0989 1646.0000
[2019-03-27 07:58:03,953] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7426.6769 3115708002.6357 1514.0000
[2019-03-27 07:58:03,973] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7158.7171 3191392654.4938 1747.0000
[2019-03-27 07:58:04,988] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1725000, evaluation results [1725000.0, 7370.288346388106, 3325701466.0988703, 1646.0, 7426.676854002026, 3115708002.635707, 1514.0, 8109.077175125339, 2951787982.0590224, 980.0, 7158.717085857982, 3191392654.493791, 1747.0, 7949.417246530776, 3000534736.555032, 1156.0]
[2019-03-27 07:58:08,169] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [5.5377644e-01 3.4854166e-20 3.4171135e-14 1.3615850e-21 4.4622356e-01], sum to 1.0000
[2019-03-27 07:58:08,180] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2735
[2019-03-27 07:58:08,186] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.95, 94.5, 1.0, 2.0, 0.17, 1.0, 1.0, 0.17, 1.0, 1.0, 0.2904551176314076, 6.9112, 6.9112, 170.5573041426782, 751402.015112872, 751402.015112872, 266743.5773627261], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 991800.0000, 
sim time next is 992400.0000, 
raw observation next is [21.93333333333333, 94.66666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.008214699824094, 6.9112, 6.9112, 168.912956510431, 871142.0713266823, 871142.0713266823, 250811.823281295], 
processed observation next is [1.0, 0.4782608695652174, 0.23854660347551332, 0.9466666666666665, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0100179266147487, 0.0, 0.0, 0.8294399451523027, 0.2419839087018562, 0.2419839087018562, 0.37434600489745523], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10882439], dtype=float32), -0.28188908]. 
=============================================
[2019-03-27 07:58:12,966] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 7.4811446e-31 1.7565089e-29 7.2132885e-31 1.1001801e-12], sum to 1.0000
[2019-03-27 07:58:12,972] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0743
[2019-03-27 07:58:12,976] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.75, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9121357621304319, 6.9112, 6.9112, 168.912956510431, 800531.1360702472, 800531.1360702472, 226530.4173065504], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1071000.0000, 
sim time next is 1071600.0000, 
raw observation next is [21.83333333333334, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8816866110432543, 6.9112, 6.9112, 168.912956510431, 773972.062139592, 773972.062139592, 219460.0341592681], 
processed observation next is [1.0, 0.391304347826087, 0.23380726698262277, 0.8566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8557153793210417, 0.0, 0.0, 0.8294399451523027, 0.21499223948322, 0.21499223948322, 0.3275522897899524], 
reward next is 0.6724, 
noisyNet noise sample is [array([-0.23264961], dtype=float32), 0.96760035]. 
=============================================
[2019-03-27 07:58:13,869] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9827540e-01 3.5677692e-22 2.2000504e-16 4.8048767e-23 1.7246174e-03], sum to 1.0000
[2019-03-27 07:58:13,883] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1385
[2019-03-27 07:58:13,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1218347.03921967 W.
[2019-03-27 07:58:13,894] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 67.5, 1.0, 2.0, 0.3965769976477327, 0.0, 2.0, 0.0, 1.0, 1.0, 0.7032859293186376, 6.9112, 6.9112, 168.912956510431, 1218347.03921967, 1218347.03921967, 267706.7492796442], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1092600.0000, 
sim time next is 1093200.0000, 
raw observation next is [25.7, 67.33333333333333, 1.0, 2.0, 0.4072867897464628, 1.0, 1.0, 0.4072867897464628, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1239577.266342619, 1239577.266342619, 285547.2984183889], 
processed observation next is [1.0, 0.6521739130434783, 0.4170616113744076, 0.6733333333333333, 1.0, 1.0, 0.28588769848971424, 1.0, 0.5, 0.28588769848971424, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.34432701842850527, 0.34432701842850527, 0.42618999763938636], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6864977], dtype=float32), -0.7098627]. 
=============================================
[2019-03-27 07:58:19,328] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.1405246e-31 3.1235269e-28 4.9837448e-31 8.4576138e-11], sum to 1.0000
[2019-03-27 07:58:19,339] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1026
[2019-03-27 07:58:19,343] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.35, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7491005171637894, 6.9112, 6.9112, 168.912956510431, 633474.8924364913, 633474.8924364913, 191798.4828839728], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1315800.0000, 
sim time next is 1316400.0000, 
raw observation next is [24.26666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7437041650032755, 6.911200000000001, 6.9112, 168.912956510431, 629226.1205875443, 629226.1205875437, 190768.1129085844], 
processed observation next is [1.0, 0.21739130434782608, 0.34913112164297017, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6874441036625311, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17478503349654007, 0.17478503349653993, 0.28472852672923044], 
reward next is 0.7153, 
noisyNet noise sample is [array([-0.25322515], dtype=float32), -0.40446424]. 
=============================================
[2019-03-27 07:58:20,544] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [3.1806061e-01 4.6534246e-22 1.7867185e-16 1.1122041e-23 6.8193930e-01], sum to 1.0000
[2019-03-27 07:58:20,554] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6706
[2019-03-27 07:58:20,558] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.8, 82.0, 1.0, 2.0, 0.2553690822027211, 1.0, 2.0, 0.2553690822027211, 1.0, 2.0, 0.4445126806773232, 6.9112, 6.9112, 170.5573041426782, 1143405.332489287, 1143405.332489287, 294548.1735106528], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1767600.0000, 
sim time next is 1768200.0000, 
raw observation next is [23.71666666666667, 82.66666666666667, 1.0, 2.0, 0.2658298642177593, 1.0, 2.0, 0.2658298642177593, 1.0, 2.0, 0.4630315429859298, 6.911199999999999, 6.9112, 170.5573041426782, 1191475.338579863, 1191475.338579864, 298597.2553169731], 
processed observation next is [1.0, 0.4782608695652174, 0.32306477093206964, 0.8266666666666667, 1.0, 1.0, 0.11545766773224009, 1.0, 1.0, 0.11545766773224009, 1.0, 1.0, 0.34516041827552413, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.3309653718277397, 0.33096537182774, 0.44566754524921354], 
reward next is 0.5543, 
noisyNet noise sample is [array([0.36482418], dtype=float32), 0.46092832]. 
=============================================
[2019-03-27 07:58:23,614] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.4683017e-36 2.4217810e-36 2.5953784e-36 5.2911177e-14], sum to 1.0000
[2019-03-27 07:58:23,625] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9465
[2019-03-27 07:58:23,630] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 83.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.790413646770243, 6.911200000000001, 6.9112, 168.912956510431, 663133.1128216296, 663133.112821629, 199885.0689693687], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1277400.0000, 
sim time next is 1278000.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7872206712224866, 6.9112, 6.9112, 168.912956510431, 660905.2686308747, 660905.2686308747, 199246.4603116145], 
processed observation next is [1.0, 0.8260869565217391, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7405130136859592, 0.0, 0.0, 0.8294399451523027, 0.18358479684190965, 0.18358479684190965, 0.29738277658449924], 
reward next is 0.7026, 
noisyNet noise sample is [array([0.8499497], dtype=float32), 0.7238765]. 
=============================================
[2019-03-27 07:58:23,646] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[77.877594]
 [78.94256 ]
 [80.06103 ]
 [80.65667 ]
 [82.291176]], R is [[77.5269928 ]
 [77.45339203]
 [77.3793335 ]
 [77.30478668]
 [77.23020935]].
[2019-03-27 07:58:23,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3800539e-02 2.6110657e-22 1.4835569e-16 2.4897742e-24 9.1619951e-01], sum to 1.0000
[2019-03-27 07:58:23,727] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3864
[2019-03-27 07:58:23,731] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 73.0, 1.0, 2.0, 0.4546598413922788, 1.0, 2.0, 0.4546598413922788, 1.0, 2.0, 0.7735237538489582, 6.911199999999999, 6.9112, 170.5573041426782, 1907017.241189054, 1907017.241189055, 382567.8797526155], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1260000.0000, 
sim time next is 1260600.0000, 
raw observation next is [28.46666666666667, 73.16666666666667, 1.0, 2.0, 0.4549560181767354, 1.0, 2.0, 0.4549560181767354, 1.0, 2.0, 0.7740331449577829, 6.9112, 6.9112, 170.5573041426782, 1908260.626182118, 1908260.626182118, 382751.4762060515], 
processed observation next is [1.0, 0.6086956521739131, 0.5481832543443919, 0.7316666666666667, 1.0, 1.0, 0.3433205038273921, 1.0, 1.0, 0.3433205038273921, 1.0, 1.0, 0.724430664582662, 0.0, 0.0, 0.8375144448122397, 0.5300723961616994, 0.5300723961616994, 0.571270860009032], 
reward next is 0.4287, 
noisyNet noise sample is [array([-0.11545188], dtype=float32), 1.1564099]. 
=============================================
[2019-03-27 07:58:26,955] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 7.0286357e-31 5.3239934e-27 3.8888603e-30 5.8365496e-10], sum to 1.0000
[2019-03-27 07:58:26,959] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0171
[2019-03-27 07:58:26,965] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.1, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7399434648214505, 6.911199999999999, 6.9112, 168.912956510431, 626681.1483727191, 626681.1483727198, 190059.913974181], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1317600.0000, 
sim time next is 1318200.0000, 
raw observation next is [24.01666666666667, 93.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8652544522793963, 6.9112, 6.9112, 168.912956510431, 733309.3756783827, 733309.3756783827, 216000.5103944172], 
processed observation next is [1.0, 0.2608695652173913, 0.33728278041074267, 0.9316666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.835676161316337, 0.0, 0.0, 0.8294399451523027, 0.20369704879955075, 0.20369704879955075, 0.3223888214842048], 
reward next is 0.6776, 
noisyNet noise sample is [array([0.4758331], dtype=float32), 0.91373104]. 
=============================================
[2019-03-27 07:58:41,387] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.8224819e-31 1.5842261e-27 2.5072382e-30 8.9391862e-12], sum to 1.0000
[2019-03-27 07:58:41,395] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4750
[2019-03-27 07:58:41,401] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.62731378719246, 6.911200000000001, 6.9112, 168.912956510431, 542418.572054986, 542418.5720549854, 170388.9684511292], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1832400.0000, 
sim time next is 1833000.0000, 
raw observation next is [21.91666666666667, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6765388798065747, 6.9112, 6.9112, 168.912956510431, 584746.9237708475, 584746.9237708475, 178575.9397733051], 
processed observation next is [1.0, 0.21739130434782608, 0.23775671406003188, 0.975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6055352192763106, 0.0, 0.0, 0.8294399451523027, 0.16242970104745763, 0.16242970104745763, 0.26653125339299266], 
reward next is 0.7335, 
noisyNet noise sample is [array([1.1822478], dtype=float32), 1.2367032]. 
=============================================
[2019-03-27 07:58:41,419] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[69.51523 ]
 [69.40523 ]
 [69.42633 ]
 [69.684326]
 [69.72806 ]], R is [[69.47055817]
 [69.52154541]
 [69.57257843]
 [69.62326813]
 [69.6733551 ]].
[2019-03-27 07:58:54,054] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.3704491e-31 4.3670858e-27 1.0135029e-30 3.6002392e-11], sum to 1.0000
[2019-03-27 07:58:54,063] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6325
[2019-03-27 07:58:54,070] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.75, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7417792756452627, 6.911199999999999, 6.9112, 168.912956510431, 632436.7785811314, 632436.778581132, 190448.2462309082], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1920600.0000, 
sim time next is 1921200.0000, 
raw observation next is [23.86666666666667, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7476361015000548, 6.911200000000001, 6.9112, 168.912956510431, 637203.9112639973, 637203.9112639967, 191567.7988874952], 
processed observation next is [1.0, 0.21739130434782608, 0.33017377567140627, 0.9133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6922391481707986, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17700108646222149, 0.17700108646222132, 0.2859220878917839], 
reward next is 0.7141, 
noisyNet noise sample is [array([-0.7190243], dtype=float32), 1.6642365]. 
=============================================
[2019-03-27 07:58:54,511] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.1171370e-36 1.9716918e-34 5.0838139e-35 1.0587686e-14], sum to 1.0000
[2019-03-27 07:58:54,519] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3651
[2019-03-27 07:58:54,527] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8121069498607975, 6.9112, 6.9112, 168.912956510431, 678549.2782577785, 678549.2782577785, 204295.7528087538], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1882800.0000, 
sim time next is 1883400.0000, 
raw observation next is [25.81666666666666, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8062463896534735, 6.9112, 6.9112, 168.912956510431, 674415.8407097274, 674415.8407097274, 203093.5601447612], 
processed observation next is [1.0, 0.8260869565217391, 0.4225908372827801, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7637151093335043, 0.0, 0.0, 0.8294399451523027, 0.18733773353047983, 0.18733773353047983, 0.30312471663397195], 
reward next is 0.6969, 
noisyNet noise sample is [array([1.414714], dtype=float32), 0.73995155]. 
=============================================
[2019-03-27 07:58:58,916] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 07:58:58,918] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 07:58:58,919] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:58:58,919] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 07:58:58,921] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 07:58:58,921] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:58:58,922] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:58:58,924] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 07:58:58,922] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 07:58:58,926] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:58:58,927] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 07:58:58,948] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run71
[2019-03-27 07:58:58,971] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run71
[2019-03-27 07:58:59,000] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run71
[2019-03-27 07:58:59,019] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run71
[2019-03-27 07:58:59,020] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run71
[2019-03-27 07:59:36,435] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 07:59:36,439] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.27251383, 79.33985786, 1.0, 2.0, 0.3336406146104763, 1.0, 1.0, 0.3336406146104763, 1.0, 1.0, 0.5792174485317544, 6.9112, 6.9112, 171.5212843490159, 1399079.849888864, 1399079.849888864, 319373.1635737104]
[2019-03-27 07:59:36,443] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:59:36,445] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.9379187e-01 3.4495115e-18 2.8195397e-12 1.9036202e-19 8.0620807e-01], sampled 0.3097275789345606
[2019-03-27 07:59:48,119] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 07:59:48,122] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.657273155, 84.06103073, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8256759076305147, 6.911200000000001, 6.9112, 168.912956510431, 693034.3773995746, 693034.377399574, 207233.0826148246]
[2019-03-27 07:59:48,124] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 07:59:48,132] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.7749236e-37 5.2270125e-21], sampled 0.2537024353595252
[2019-03-27 07:59:55,267] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 07:59:55,268] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.35941360666667, 91.87969575000001, 1.0, 2.0, 0.6255580457003754, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 874192.375417578, 874192.3754175786, 205602.5831960719]
[2019-03-27 07:59:55,272] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 07:59:55,275] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9999595e-01 6.3125502e-24 7.8086057e-20 4.1614050e-24 4.0863433e-06], sampled 0.43825986974756426
[2019-03-27 07:59:55,279] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 874192.375417578 W.
[2019-03-27 08:00:09,595] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:09,596] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.05060873333333, 86.6549848, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.706159410203519, 6.911199999999999, 6.9112, 168.912956510431, 603938.2379085879, 603938.2379085886, 183838.3697930154]
[2019-03-27 08:00:09,598] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:00:09,602] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.2774529e-33 9.0481120e-31 5.2477412e-32 1.4808571e-13], sampled 0.7590413211251575
[2019-03-27 08:00:16,754] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:16,755] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.5, 78.66666666666667, 1.0, 1.0, 1.04, 1.0, 1.0, 1.04, 1.0, 2.0, 1.03, 8.873548876728734, 6.9112, 178.6582176852504, 5214465.407849131, 3741988.446118495, 695966.9395533046]
[2019-03-27 08:00:16,756] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:00:16,760] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.3797702e-02 5.3870196e-20 4.1566202e-15 1.0584464e-21 9.7620231e-01], sampled 0.2423180292939472
[2019-03-27 08:00:16,810] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:16,811] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.53333333333333, 77.66666666666667, 1.0, 2.0, 0.4359263364418638, 1.0, 2.0, 0.4359263364418638, 1.0, 2.0, 0.7570598833571157, 6.9112, 6.9112, 178.6582176852504, 1828303.986885751, 1828303.986885751, 375706.5804234592]
[2019-03-27 08:00:16,812] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:00:16,818] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [4.4726036e-02 2.3146293e-21 1.5020208e-14 5.0733456e-23 9.5527393e-01], sampled 0.23618225633842038
[2019-03-27 08:00:23,248] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:23,249] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [35.85674095333334, 53.28420112, 1.0, 2.0, 0.6482635353787319, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104253, 905935.9226887746, 905935.9226887753, 210080.0924417403]
[2019-03-27 08:00:23,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:00:23,254] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.8593199e-01 4.8229806e-20 2.8583027e-15 8.5531695e-21 1.4068025e-02], sampled 0.6810127685341797
[2019-03-27 08:00:23,255] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 905935.9226887746 W.
[2019-03-27 08:00:23,544] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:23,546] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [34.36666666666667, 59.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.13220547999836, 6.9112, 168.9116073668013, 985649.7372114537, 828862.095585197, 254812.9200190256]
[2019-03-27 08:00:23,548] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:00:23,553] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999988e-01 5.2139596e-24 2.2706489e-20 8.7580939e-24 7.5397494e-08], sampled 0.05279208881066433
[2019-03-27 08:00:23,554] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 985649.7372114537 W.
[2019-03-27 08:00:40,580] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:40,581] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.63978813, 58.90129339000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6001195263697773, 6.9112, 6.9112, 168.912956510431, 526039.1193374639, 526039.1193374639, 166016.3777855886]
[2019-03-27 08:00:40,582] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:00:40,585] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.6661245e-36 7.9950598e-36 1.1802200e-34 4.4212307e-18], sampled 0.24000658185941626
[2019-03-27 08:00:48,119] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07451686]
[2019-03-27 08:00:48,121] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.7, 79.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8216823850879703, 6.911199999999999, 6.9112, 168.912956510431, 688669.6192244968, 688669.6192244975, 206362.3086879362]
[2019-03-27 08:00:48,122] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:00:48,127] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.9435612e-34 4.6945593e-33 1.0025505e-32 1.2940567e-15], sampled 0.0034186600342585027
[2019-03-27 08:00:54,737] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7938.0687 2996534000.0486 1128.0000
[2019-03-27 08:00:54,930] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7347.0038 3323735304.4004 1647.0000
[2019-03-27 08:00:55,097] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8070.6715 2949223675.8365 956.0000
[2019-03-27 08:00:55,152] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7141.5374 3188780698.1656 1679.0000
[2019-03-27 08:00:55,257] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7391.1407 3113574964.8571 1481.0000
[2019-03-27 08:00:56,274] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 1750000, evaluation results [1750000.0, 7347.0038300278275, 3323735304.4004254, 1647.0, 7391.140673873764, 3113574964.857087, 1481.0, 8070.671467126053, 2949223675.836517, 956.0, 7141.537426659398, 3188780698.165613, 1679.0, 7938.068682613074, 2996534000.048645, 1128.0]
[2019-03-27 08:01:00,909] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.4549081e-01 2.9600109e-21 8.0917540e-15 2.2204907e-22 8.5450917e-01], sum to 1.0000
[2019-03-27 08:01:00,917] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7210
[2019-03-27 08:01:00,923] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.46666666666667, 74.33333333333333, 1.0, 2.0, 0.4281332193325912, 1.0, 1.0, 0.4281332193325912, 1.0, 2.0, 0.719760135274728, 6.9112, 6.9112, 170.5573041426782, 1795661.211798494, 1795661.211798494, 365316.0640407698], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1950000.0000, 
sim time next is 1950600.0000, 
raw observation next is [27.53333333333333, 74.16666666666667, 1.0, 2.0, 0.4254591072674875, 1.0, 2.0, 0.4254591072674875, 1.0, 2.0, 0.7163329669112111, 6.9112, 6.9112, 170.5573041426782, 1784436.206658023, 1784436.206658023, 363956.8424405142], 
processed observation next is [1.0, 0.5652173913043478, 0.5039494470774091, 0.7416666666666667, 1.0, 1.0, 0.3077820569487801, 1.0, 1.0, 0.3077820569487801, 1.0, 1.0, 0.6540645937941598, 0.0, 0.0, 0.8375144448122397, 0.495676724071673, 0.495676724071673, 0.543219167821663], 
reward next is 0.4568, 
noisyNet noise sample is [array([-0.5030359], dtype=float32), 0.69200695]. 
=============================================
[2019-03-27 08:01:03,895] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.6729777e-37 8.7699519e-34 9.0737014e-36 9.7760192e-18], sum to 1.0000
[2019-03-27 08:01:03,902] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.3389
[2019-03-27 08:01:03,908] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.55, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7825273288216356, 6.911199999999999, 6.9112, 168.912956510431, 657875.5376726583, 657875.5376726589, 198317.0821284495], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2071800.0000, 
sim time next is 2072400.0000, 
raw observation next is [24.53333333333333, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.782193124560192, 6.9112, 6.9112, 168.912956510431, 657740.7315000216, 657740.7315000216, 198252.6601761666], 
processed observation next is [0.0, 1.0, 0.36176935229067925, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7343818592197462, 0.0, 0.0, 0.8294399451523027, 0.18270575875000603, 0.18270575875000603, 0.29589949280024863], 
reward next is 0.7041, 
noisyNet noise sample is [array([-0.22503778], dtype=float32), -0.41398814]. 
=============================================
[2019-03-27 08:01:13,382] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.0602972e-35 5.9073694e-35 2.6871815e-34 1.5172618e-17], sum to 1.0000
[2019-03-27 08:01:13,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5010
[2019-03-27 08:01:13,400] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666666, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6814317492730755, 6.911200000000001, 6.9112, 168.912956510431, 585125.0563520129, 585125.0563520123, 179446.8119918662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2731200.0000, 
sim time next is 2731800.0000, 
raw observation next is [22.83333333333334, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6813707006108729, 6.911200000000001, 6.9112, 168.912956510431, 584766.6491672527, 584766.649167252, 179436.6278951587], 
processed observation next is [0.0, 0.6086956521739131, 0.2812006319115327, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6114276836717962, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16243518032423687, 0.16243518032423668, 0.2678158625300876], 
reward next is 0.7322, 
noisyNet noise sample is [array([0.8470071], dtype=float32), 0.85473156]. 
=============================================
[2019-03-27 08:01:15,903] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.8772435e-34 8.5281616e-33 5.5265835e-34 2.4074559e-15], sum to 1.0000
[2019-03-27 08:01:15,905] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7356
[2019-03-27 08:01:15,918] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8355080964515369, 6.911200000000001, 6.9112, 168.912956510431, 695073.5940608928, 695073.5940608921, 209180.3927606604], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2652600.0000, 
sim time next is 2653200.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8358291389098887, 6.9112, 6.9112, 168.912956510431, 695339.9968591583, 695339.9968591583, 209249.5073870892], 
processed observation next is [0.0, 0.7391304347826086, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7997916328169373, 0.0, 0.0, 0.8294399451523027, 0.19314999912754396, 0.19314999912754396, 0.31231269759267044], 
reward next is 0.6877, 
noisyNet noise sample is [array([-1.4386977], dtype=float32), -0.043157145]. 
=============================================
[2019-03-27 08:01:15,952] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.1289712e-02 1.5633675e-19 1.6957465e-13 2.6979998e-21 9.6871030e-01], sum to 1.0000
[2019-03-27 08:01:15,958] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8712
[2019-03-27 08:01:15,961] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.9, 65.0, 1.0, 2.0, 0.4360722651117803, 1.0, 2.0, 0.4360722651117803, 1.0, 2.0, 0.7512442995512172, 6.9112, 6.9112, 170.5573041426782, 1828987.295428403, 1828987.295428403, 372815.7146823812], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2282400.0000, 
sim time next is 2283000.0000, 
raw observation next is [31.1, 64.5, 1.0, 2.0, 0.3781481691509468, 1.0, 2.0, 0.3781481691509468, 1.0, 2.0, 0.6514684501326541, 6.911199999999999, 6.9112, 170.5573041426782, 1585860.557855678, 1585860.557855679, 340435.3479118011], 
processed observation next is [1.0, 0.43478260869565216, 0.6729857819905214, 0.645, 1.0, 1.0, 0.2507809266878877, 1.0, 1.0, 0.2507809266878877, 1.0, 1.0, 0.5749615245520171, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.44051682162657724, 0.4405168216265775, 0.5081124595698523], 
reward next is 0.4919, 
noisyNet noise sample is [array([0.30493355], dtype=float32), -0.73586893]. 
=============================================
[2019-03-27 08:01:15,979] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[60.429314]
 [59.448563]
 [58.784927]
 [58.378166]
 [58.150528]], R is [[62.05570221]
 [61.87870407]
 [61.65855026]
 [61.44423294]
 [61.23551178]].
[2019-03-27 08:01:18,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.6224363e-01 1.1671621e-21 9.2825926e-15 7.0057477e-22 2.3775633e-01], sum to 1.0000
[2019-03-27 08:01:18,597] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7796
[2019-03-27 08:01:18,604] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.06666666666667, 86.66666666666667, 1.0, 2.0, 0.2291585596750451, 1.0, 1.0, 0.2291585596750451, 1.0, 2.0, 0.3859844729756505, 6.9112, 6.9112, 170.5573041426782, 960754.7418921164, 960754.7418921164, 277672.8164905626], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2259600.0000, 
sim time next is 2260200.0000, 
raw observation next is [26.03333333333333, 86.83333333333333, 1.0, 2.0, 0.2234546644162166, 1.0, 2.0, 0.2234546644162166, 1.0, 2.0, 0.3765066034276423, 6.9112, 6.9112, 170.5573041426782, 936830.5291638976, 936830.5291638976, 275947.1987768576], 
processed observation next is [1.0, 0.13043478260869565, 0.4328593996840442, 0.8683333333333333, 1.0, 1.0, 0.06440321014001997, 1.0, 1.0, 0.06440321014001997, 1.0, 1.0, 0.2396421993020028, 0.0, 0.0, 0.8375144448122397, 0.2602307025455271, 0.2602307025455271, 0.41186149071172773], 
reward next is 0.5881, 
noisyNet noise sample is [array([-0.17726317], dtype=float32), 0.8969347]. 
=============================================
[2019-03-27 08:01:19,387] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.0503456e-34 1.8621313e-33 2.7204664e-33 3.8943957e-16], sum to 1.0000
[2019-03-27 08:01:19,401] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.6188
[2019-03-27 08:01:19,406] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7055632675376613, 6.911200000000001, 6.9112, 168.912956510431, 602438.267845867, 602438.2678458664, 183727.2489316412], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2835600.0000, 
sim time next is 2836200.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7072190966232582, 6.9112, 6.9112, 168.912956510431, 603852.4830929274, 603852.4830929274, 184027.0201151756], 
processed observation next is [1.0, 0.8260869565217391, 0.3364928909952607, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6429501178332416, 0.0, 0.0, 0.8294399451523027, 0.1677368008591465, 0.1677368008591465, 0.2746671942017546], 
reward next is 0.7253, 
noisyNet noise sample is [array([-0.9361618], dtype=float32), -0.44549182]. 
=============================================
[2019-03-27 08:01:24,677] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.6249658e-01 1.7307906e-18 5.7081442e-14 3.5587919e-21 6.3750345e-01], sum to 1.0000
[2019-03-27 08:01:24,687] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9095
[2019-03-27 08:01:24,693] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.75, 65.0, 1.0, 2.0, 0.4955103783303214, 1.0, 2.0, 0.4955103783303214, 1.0, 2.0, 0.8605376593736078, 6.9112, 6.9112, 170.5573041426782, 2078526.230157238, 2078526.230157238, 412054.9300768641], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2370600.0000, 
sim time next is 2371200.0000, 
raw observation next is [31.90000000000001, 64.66666666666667, 1.0, 2.0, 0.5635790884437774, 1.0, 2.0, 0.5635790884437774, 1.0, 2.0, 0.9787504981742633, 6.9112, 6.9112, 170.5573041426782, 2364346.483047375, 2364346.483047375, 461896.0973095429], 
processed observation next is [1.0, 0.43478260869565216, 0.7109004739336497, 0.6466666666666667, 1.0, 1.0, 0.4741916728238281, 1.0, 1.0, 0.4741916728238281, 1.0, 1.0, 0.9740859733832478, 0.0, 0.0, 0.8375144448122397, 0.6567629119576042, 0.6567629119576042, 0.6893971601634968], 
reward next is 0.3106, 
noisyNet noise sample is [array([0.75024813], dtype=float32), 1.6601645]. 
=============================================
[2019-03-27 08:01:30,717] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.3675945e-01 6.3409929e-21 7.2211089e-16 1.9908180e-22 1.6324057e-01], sum to 1.0000
[2019-03-27 08:01:30,719] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4190
[2019-03-27 08:01:30,721] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1834700.567230714 W.
[2019-03-27 08:01:30,727] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.5, 84.66666666666667, 1.0, 2.0, 0.6711088122569505, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.986603854382757, 6.9112, 168.9125067352304, 1834700.567230714, 1781206.620173297, 379224.8248448018], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2475600.0000, 
sim time next is 2476200.0000, 
raw observation next is [27.6, 84.33333333333333, 1.0, 2.0, 0.6269069993435759, 1.0, 1.0, 0.6269069993435759, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1752865.80694238, 1752865.806942381, 344401.5367102618], 
processed observation next is [1.0, 0.6521739130434783, 0.5071090047393366, 0.8433333333333333, 1.0, 1.0, 0.5504903606549106, 1.0, 0.5, 0.5504903606549106, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4869071685951056, 0.4869071685951058, 0.5140321443436743], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.46574888], dtype=float32), -0.6973393]. 
=============================================
[2019-03-27 08:01:32,766] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 3.4210547e-32 2.3237951e-28 3.0176788e-31 6.0886400e-12], sum to 1.0000
[2019-03-27 08:01:32,775] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2718
[2019-03-27 08:01:32,787] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.53333333333333, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9410066447502367, 6.911200000000001, 6.9112, 168.912956510431, 767332.2046853792, 767332.2046853785, 232775.2864749408], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2508600.0000, 
sim time next is 2509200.0000, 
raw observation next is [26.5, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9392386801144574, 6.9112, 6.9112, 168.912956510431, 766022.3197241866, 766022.3197241866, 232353.0288837662], 
processed observation next is [1.0, 0.043478260869565216, 0.4549763033175356, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9259008294078749, 0.0, 0.0, 0.8294399451523027, 0.21278397770116292, 0.21278397770116292, 0.34679556549815854], 
reward next is 0.6532, 
noisyNet noise sample is [array([-0.55394536], dtype=float32), -0.7824185]. 
=============================================
[2019-03-27 08:01:34,379] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.0001818e-38 4.9203338e-37 4.3897977e-36 4.1544852e-19], sum to 1.0000
[2019-03-27 08:01:34,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0884
[2019-03-27 08:01:34,396] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7066818166528432, 6.911199999999999, 6.9112, 168.912956510431, 604284.2195635884, 604284.219563589, 183932.7613818471], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2662200.0000, 
sim time next is 2662800.0000, 
raw observation next is [23.33333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7023512508504528, 6.911200000000001, 6.9112, 168.912956510431, 601011.171667493, 601011.1716674924, 183151.9410396783], 
processed observation next is [0.0, 0.8260869565217391, 0.30489731437598716, 0.9233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6370137205493327, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1669475476854147, 0.16694754768541453, 0.2733611060293706], 
reward next is 0.7266, 
noisyNet noise sample is [array([-1.4334524], dtype=float32), 0.46416464]. 
=============================================
[2019-03-27 08:01:35,369] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [5.9957325e-01 6.9288315e-21 2.3220436e-15 5.7152607e-22 4.0042669e-01], sum to 1.0000
[2019-03-27 08:01:35,372] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.3160
[2019-03-27 08:01:35,377] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2046609.457074803 W.
[2019-03-27 08:01:35,382] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.3, 80.66666666666667, 1.0, 2.0, 0.4879088387111532, 1.0, 2.0, 0.4879088387111532, 1.0, 2.0, 0.8427756251680543, 6.9112, 6.9112, 170.5573041426782, 2046609.457074803, 2046609.457074803, 406084.1098862238], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2544600.0000, 
sim time next is 2545200.0000, 
raw observation next is [28.4, 80.0, 1.0, 2.0, 0.4744783612907403, 1.0, 2.0, 0.4744783612907403, 1.0, 2.0, 0.8193925981156936, 6.9112, 6.9112, 170.5573041426782, 1990220.902268981, 1990220.902268981, 397159.5151711267], 
processed observation next is [1.0, 0.4782608695652174, 0.5450236966824644, 0.8, 1.0, 1.0, 0.3668413991454702, 1.0, 1.0, 0.3668413991454702, 1.0, 1.0, 0.779747070872797, 0.0, 0.0, 0.8375144448122397, 0.5528391395191614, 0.5528391395191614, 0.592775395777801], 
reward next is 0.4072, 
noisyNet noise sample is [array([0.44776002], dtype=float32), 0.49589428]. 
=============================================
[2019-03-27 08:01:36,458] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 1.6991601e-34 2.6145935e-31 6.0107779e-34 6.3964459e-13], sum to 1.0000
[2019-03-27 08:01:36,469] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3377
[2019-03-27 08:01:36,475] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.03333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8153873375007487, 6.911200000000001, 6.9112, 168.912956510431, 682706.1949369672, 682706.1949369666, 205018.1700628797], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2593200.0000, 
sim time next is 2593800.0000, 
raw observation next is [24.95, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8112973284249901, 6.911199999999999, 6.9112, 168.912956510431, 679856.8996106597, 679856.8996106603, 204174.474054612], 
processed observation next is [0.0, 0.0, 0.3815165876777251, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.769874790762183, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1888491387807388, 0.18884913878073897, 0.30473802097703284], 
reward next is 0.6953, 
noisyNet noise sample is [array([-0.93924963], dtype=float32), -0.03635942]. 
=============================================
[2019-03-27 08:01:37,428] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.3664055e-35 4.5107738e-32 1.0836056e-33 2.2960815e-14], sum to 1.0000
[2019-03-27 08:01:37,436] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0493
[2019-03-27 08:01:37,441] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.3, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8780070903200053, 6.9112, 6.9112, 168.912956510431, 726343.5460024896, 726343.5460024896, 218440.3870155029], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2585400.0000, 
sim time next is 2586000.0000, 
raw observation next is [26.2, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8730983833858917, 6.9112, 6.9112, 168.912956510431, 722868.206990218, 722868.206990218, 217351.9687913321], 
processed observation next is [1.0, 0.9565217391304348, 0.44075829383886256, 0.8966666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8452419309584044, 0.0, 0.0, 0.8294399451523027, 0.20079672416394945, 0.20079672416394945, 0.3244059235691524], 
reward next is 0.6756, 
noisyNet noise sample is [array([0.8931789], dtype=float32), 0.3193756]. 
=============================================
[2019-03-27 08:01:37,454] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[75.32026 ]
 [75.49787 ]
 [75.645035]
 [75.76813 ]
 [75.60506 ]], R is [[75.26886749]
 [75.19015503]
 [75.11095428]
 [75.03170776]
 [74.95199585]].
[2019-03-27 08:01:44,172] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.7004625e-35 1.9979256e-35 9.3472528e-34 1.4333296e-16], sum to 1.0000
[2019-03-27 08:01:44,179] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6812
[2019-03-27 08:01:44,190] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.793093634227326, 6.9112, 6.9112, 168.912956510431, 664997.6485445339, 664997.6485445339, 200422.8828562894], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2703000.0000, 
sim time next is 2703600.0000, 
raw observation next is [24.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7930266364164499, 6.911199999999999, 6.9112, 168.912956510431, 664941.0253757458, 664941.0253757464, 200409.1967057784], 
processed observation next is [0.0, 0.30434782608695654, 0.3364928909952607, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.747593459044451, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18470584038215163, 0.1847058403821518, 0.2991182040384752], 
reward next is 0.7009, 
noisyNet noise sample is [array([0.41397303], dtype=float32), 0.401186]. 
=============================================
[2019-03-27 08:01:48,681] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 4.3783775e-35 2.6629179e-32 1.4072722e-35 2.7522199e-14], sum to 1.0000
[2019-03-27 08:01:48,690] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6223
[2019-03-27 08:01:48,696] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.863422952181641, 6.911200000000001, 6.9112, 168.912956510431, 715460.2823147633, 715460.2823147627, 215205.7533194226], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3453000.0000, 
sim time next is 3453600.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8630504091801321, 6.911199999999999, 6.9112, 168.912956510431, 715151.5167799335, 715151.516779934, 215122.8228292842], 
processed observation next is [1.0, 1.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8329883038782099, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19865319910553708, 0.19865319910553725, 0.3210788400437078], 
reward next is 0.6789, 
noisyNet noise sample is [array([-1.2406385], dtype=float32), -0.5249547]. 
=============================================
[2019-03-27 08:01:49,701] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999917e-01 7.7316384e-24 1.7655779e-20 2.5353748e-25 8.8215353e-07], sum to 1.0000
[2019-03-27 08:01:49,708] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7743
[2019-03-27 08:01:49,717] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 988568.4084545736 W.
[2019-03-27 08:01:49,725] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.66666666666666, 84.66666666666666, 1.0, 1.0, 0.6323139137137005, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9128504294633, 988568.4084545736, 988568.408454573, 219464.2854551501], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 2803200.0000, 
sim time next is 2803800.0000, 
raw observation next is [22.83333333333334, 83.83333333333334, 1.0, 2.0, 0.6317609439826712, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129564839423, 985929.9011795657, 985929.9011795657, 219168.4042606816], 
processed observation next is [1.0, 0.43478260869565216, 0.2812006319115327, 0.8383333333333334, 1.0, 1.0, 0.5563384867261099, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399450222311, 0.2738694169943238, 0.2738694169943238, 0.3271170212845994], 
reward next is 0.6729, 
noisyNet noise sample is [array([-1.4080164], dtype=float32), 0.341714]. 
=============================================
[2019-03-27 08:01:50,162] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:01:50,164] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:01:50,166] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:01:50,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:01:50,168] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:01:50,169] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:01:50,170] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:01:50,170] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:01:50,171] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:01:50,173] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:01:50,175] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:01:50,201] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run72
[2019-03-27 08:01:50,223] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run72
[2019-03-27 08:01:50,224] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run72
[2019-03-27 08:01:50,245] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run72
[2019-03-27 08:01:50,267] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run72
[2019-03-27 08:02:13,321] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:13,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.8, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.594128124671247, 6.9112, 6.9112, 168.912956510431, 516632.8492831832, 516632.8492831832, 165203.2033829496]
[2019-03-27 08:02:13,448] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:02:13,451] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.6617488e-36 9.9865506e-37 1.0046474e-34 6.1246521e-20], sampled 0.5549697633922006
[2019-03-27 08:02:19,562] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:19,563] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.43333333333333, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6796224197375017, 6.9112, 6.9112, 168.912956510431, 585826.6950688653, 585826.6950688653, 179122.8995736637]
[2019-03-27 08:02:19,564] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:02:19,566] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.00000000e+00 2.53906977e-36 1.27305755e-36 1.28996328e-34
 9.28225894e-20], sampled 0.9041203959719687
[2019-03-27 08:02:25,729] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:25,730] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.45, 65.5, 1.0, 2.0, 0.7004279199282625, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1067969.099994445, 1067969.099994445, 232263.7341580558]
[2019-03-27 08:02:25,730] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:02:25,734] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9994636e-01 7.3370694e-21 1.8054880e-16 2.2859873e-21 5.3695661e-05], sampled 0.9761038367277278
[2019-03-27 08:02:25,738] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1067969.099994445 W.
[2019-03-27 08:02:28,541] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:28,541] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.2, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7792274321506303, 6.9112, 6.9112, 168.912956510431, 658633.2624177248, 658633.2624177248, 197714.9777431124]
[2019-03-27 08:02:28,543] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:02:28,545] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6413217e-38 1.4736035e-22], sampled 0.44961431409394226
[2019-03-27 08:02:34,462] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:34,465] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.88679843166667, 98.24989651333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6263234404104969, 6.911199999999999, 6.9112, 168.912956510431, 545945.9559310754, 545945.955931076, 170165.6391678685]
[2019-03-27 08:02:34,466] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:02:34,468] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 6.5807162e-38 1.2180678e-37 2.9449906e-36 7.1302426e-20], sampled 0.7858498167880158
[2019-03-27 08:02:39,348] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:02:39,350] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.46666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9239389785795599, 6.9112, 6.9112, 168.912956510431, 759156.7173634674, 759156.7173634674, 228926.9636167917]
[2019-03-27 08:02:39,351] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:02:39,353] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.7046267e-36 4.4727940e-36 1.0970434e-34 3.2319651e-18], sampled 0.534331918790515
[2019-03-27 08:03:41,739] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.074484184]
[2019-03-27 08:03:41,739] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.3, 61.0, 1.0, 2.0, 0.9753208603829828, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129564997417, 1363285.701722044, 1363285.701722043, 291493.4001873679]
[2019-03-27 08:03:41,740] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:03:41,742] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9802518e-01 1.0153061e-21 3.2084036e-17 1.2584068e-22 1.9748418e-03], sampled 0.6518684529668172
[2019-03-27 08:03:41,743] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1363285.701722044 W.
[2019-03-27 08:03:45,954] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7916.8052 2991523212.1788 1381.0000
[2019-03-27 08:03:45,981] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7404.3907 3106605766.9487 1673.0000
[2019-03-27 08:03:46,006] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8081.5931 2940985175.6999 1133.0000
[2019-03-27 08:03:46,021] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7296.0359 3319482711.9263 1899.0000
[2019-03-27 08:03:46,302] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7086.9043 3185581198.5043 2053.0000
[2019-03-27 08:03:47,319] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1775000, evaluation results [1775000.0, 7296.035945017578, 3319482711.9263196, 1899.0, 7404.39073906951, 3106605766.948675, 1673.0, 8081.593057540409, 2940985175.69994, 1133.0, 7086.904278556207, 3185581198.5043097, 2053.0, 7916.8052182185775, 2991523212.1788263, 1381.0]
[2019-03-27 08:03:52,716] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 7.7854887e-37 1.1774525e-37 2.0129965e-35 4.4745053e-19], sum to 1.0000
[2019-03-27 08:03:52,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5708
[2019-03-27 08:03:52,731] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5589826406963955, 6.911200000000001, 6.9112, 168.912956510431, 491020.2512022325, 491020.2512022319, 159962.6036852809], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2923200.0000, 
sim time next is 2923800.0000, 
raw observation next is [20.08333333333334, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.558847015123244, 6.911200000000001, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524185, 159940.7010608758], 
processed observation next is [1.0, 0.8695652173913043, 0.15086887835703036, 0.995, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46200855502834626, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13638670984789422, 0.13638670984789403, 0.2387174642699639], 
reward next is 0.7613, 
noisyNet noise sample is [array([-0.833311], dtype=float32), 0.2813856]. 
=============================================
[2019-03-27 08:03:53,646] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.7419261e-35 3.5589828e-36 6.4254431e-34 2.5901614e-17], sum to 1.0000
[2019-03-27 08:03:53,655] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3508
[2019-03-27 08:03:53,663] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.08333333333334, 99.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5588470151234637, 6.911200000000001, 6.9112, 168.912956510431, 490992.1554524192, 490992.1554524185, 159940.7010609127], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2923800.0000, 
sim time next is 2924400.0000, 
raw observation next is [20.16666666666667, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5592135916944722, 6.911200000000001, 6.9112, 168.912956510431, 491248.2889387395, 491248.2889387388, 159994.3966677267], 
processed observation next is [1.0, 0.8695652173913043, 0.15481832543443946, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46245559962740507, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13645785803853874, 0.13645785803853855, 0.23879760696675625], 
reward next is 0.7612, 
noisyNet noise sample is [array([-0.60206217], dtype=float32), -0.30174604]. 
=============================================
[2019-03-27 08:03:54,555] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.1615727e-30 5.5775153e-28 1.2693815e-29 6.2489671e-12], sum to 1.0000
[2019-03-27 08:03:54,562] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1399
[2019-03-27 08:03:54,569] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1671707.014637346 W.
[2019-03-27 08:03:54,575] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.024457901437476, 6.9112, 168.9070186556678, 1671707.014637346, 881951.3075053348, 256635.2249860649], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 3072000.0000, 
sim time next is 3072600.0000, 
raw observation next is [23.0, 97.0, 1.0, 1.0, 0.4734588116334444, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8142575416334032, 6.911199999999999, 6.9112, 168.9120500444488, 1388218.172084457, 1388218.172084458, 297439.3467492759], 
processed observation next is [1.0, 0.5652173913043478, 0.28909952606635075, 0.97, 1.0, 0.5, 0.3656130260643908, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.773484806870004, -8.881784197001253e-17, 0.0, 0.8294354939893481, 0.3856161589123492, 0.3856161589123494, 0.443939323506382], 
reward next is 0.5561, 
noisyNet noise sample is [array([-0.44218466], dtype=float32), 0.28070855]. 
=============================================
[2019-03-27 08:03:57,744] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.7724302e-33 2.7138681e-30 1.9009767e-31 6.8055628e-14], sum to 1.0000
[2019-03-27 08:03:57,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5334
[2019-03-27 08:03:57,757] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.611202816012495, 6.9112, 6.9112, 168.912956510431, 531439.1029385976, 531439.1029385976, 167813.8538654131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3128400.0000, 
sim time next is 3129000.0000, 
raw observation next is [21.16666666666667, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6124466756505899, 6.9112, 6.9112, 168.912956510431, 532561.5974290697, 532561.5974290697, 168006.4442634695], 
processed observation next is [1.0, 0.21739130434782608, 0.2022116903633494, 0.9900000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5273739946958412, 0.0, 0.0, 0.8294399451523027, 0.14793377706363048, 0.14793377706363048, 0.25075588696040224], 
reward next is 0.7492, 
noisyNet noise sample is [array([-0.8674443], dtype=float32), 0.61898315]. 
=============================================
[2019-03-27 08:03:57,765] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.12985 ]
 [70.98466 ]
 [70.88173 ]
 [71.04682 ]
 [71.027214]], R is [[71.3062439 ]
 [71.34272003]
 [71.37857819]
 [71.41259766]
 [71.44473267]].
[2019-03-27 08:04:00,536] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.4302531e-33 9.7048696e-32 5.9612070e-33 2.3952086e-15], sum to 1.0000
[2019-03-27 08:04:00,547] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9374
[2019-03-27 08:04:00,552] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5916827611374694, 6.911200000000001, 6.9112, 168.912956510431, 514689.3123271012, 514689.3123271005, 164832.731775893], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3045000.0000, 
sim time next is 3045600.0000, 
raw observation next is [21.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5915590379861845, 6.911200000000001, 6.9112, 168.912956510431, 514580.9445559173, 514580.9445559166, 164814.2022043983], 
processed observation next is [1.0, 0.2608695652173913, 0.19431279620853087, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5019012658368103, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14293915126553258, 0.1429391512655324, 0.2459913465737288], 
reward next is 0.7540, 
noisyNet noise sample is [array([0.38803834], dtype=float32), -1.2555064]. 
=============================================
[2019-03-27 08:04:09,881] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3952943e-03 2.8650638e-20 6.3126734e-16 2.3629552e-22 9.9860471e-01], sum to 1.0000
[2019-03-27 08:04:09,888] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9415
[2019-03-27 08:04:09,894] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.5, 79.5, 1.0, 2.0, 0.5635444657923359, 1.0, 2.0, 0.5635444657923359, 1.0, 2.0, 0.978690370078595, 6.9112, 6.9112, 170.5573041426782, 2364201.095504155, 2364201.095504155, 461869.4227520516], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3400200.0000, 
sim time next is 3400800.0000, 
raw observation next is [29.66666666666667, 78.0, 1.0, 2.0, 0.5321735479571721, 1.0, 2.0, 0.5321735479571721, 1.0, 2.0, 0.9242094603199758, 6.9112, 6.9112, 170.5573041426782, 2232475.192214687, 2232475.192214687, 438107.9313835744], 
processed observation next is [1.0, 0.34782608695652173, 0.6050552922590839, 0.78, 1.0, 1.0, 0.4363536722375567, 1.0, 1.0, 0.4363536722375567, 1.0, 1.0, 0.9075725125853363, 0.0, 0.0, 0.8375144448122397, 0.620131997837413, 0.620131997837413, 0.6538924349008572], 
reward next is 0.3461, 
noisyNet noise sample is [array([-1.0392513], dtype=float32), -2.249297]. 
=============================================
[2019-03-27 08:04:19,738] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [2.2203720e-01 1.6853249e-19 7.2426780e-15 3.2817514e-21 7.7796280e-01], sum to 1.0000
[2019-03-27 08:04:19,748] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3483
[2019-03-27 08:04:19,753] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.83333333333334, 84.83333333333333, 1.0, 2.0, 0.3701749925520246, 1.0, 1.0, 0.3701749925520246, 1.0, 2.0, 0.6428715433221618, 6.9112, 6.9112, 170.5573041426782, 1552398.796454462, 1552398.796454462, 336993.3426646751], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3397800.0000, 
sim time next is 3398400.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.3749800296165813, 1.0, 2.0, 0.3749800296165813, 1.0, 2.0, 0.6512163036532574, 6.9112, 6.9112, 170.5573041426782, 1572564.411054231, 1572564.411054231, 339471.1974485239], 
processed observation next is [1.0, 0.34782608695652173, 0.5734597156398105, 0.84, 1.0, 1.0, 0.2469638911043148, 1.0, 1.0, 0.2469638911043148, 1.0, 1.0, 0.5746540288454359, 0.0, 0.0, 0.8375144448122397, 0.4368234475150642, 0.4368234475150642, 0.5066734290276476], 
reward next is 0.4933, 
noisyNet noise sample is [array([0.264517], dtype=float32), -0.6929079]. 
=============================================
[2019-03-27 08:04:21,186] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [7.6382691e-03 7.6280367e-21 1.8798062e-14 1.7822781e-22 9.9236166e-01], sum to 1.0000
[2019-03-27 08:04:21,194] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2541
[2019-03-27 08:04:21,199] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 79.0, 1.0, 2.0, 0.2350454209522907, 1.0, 2.0, 0.2350454209522907, 1.0, 2.0, 0.395046268985128, 6.9112, 6.9112, 170.5573041426782, 985446.940413071, 985446.940413071, 279443.2531698404], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3469200.0000, 
sim time next is 3469800.0000, 
raw observation next is [27.0, 79.0, 1.0, 2.0, 0.2381031509635276, 1.0, 2.0, 0.2381031509635276, 1.0, 2.0, 0.4002598833170231, 6.9112, 6.9112, 170.5573041426782, 998272.688077431, 998272.688077431, 280419.26704652], 
processed observation next is [1.0, 0.13043478260869565, 0.4786729857819906, 0.79, 1.0, 1.0, 0.08205198911268385, 1.0, 1.0, 0.08205198911268385, 1.0, 1.0, 0.2686096138012477, 0.0, 0.0, 0.8375144448122397, 0.27729796891039754, 0.27729796891039754, 0.4185362194724179], 
reward next is 0.5815, 
noisyNet noise sample is [array([-0.69933885], dtype=float32), -1.5346789]. 
=============================================
[2019-03-27 08:04:23,051] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [5.8105206e-03 4.2887291e-24 4.2590025e-19 4.5324752e-26 9.9418950e-01], sum to 1.0000
[2019-03-27 08:04:23,061] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0667
[2019-03-27 08:04:23,068] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333334, 67.5, 1.0, 2.0, 0.2610313043973522, 1.0, 2.0, 0.2610313043973522, 1.0, 2.0, 0.4533250513667228, 6.9112, 6.9112, 170.5573041426782, 1094450.459311024, 1094450.459311024, 289312.7178293546], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3517800.0000, 
sim time next is 3518400.0000, 
raw observation next is [31.66666666666667, 68.0, 1.0, 2.0, 0.1817953591711884, 1.0, 2.0, 0.1817953591711884, 1.0, 2.0, 0.315718418236379, 6.911200000000001, 6.9112, 170.5573041426782, 762112.4226437715, 762112.4226437708, 265035.9213411258], 
processed observation next is [1.0, 0.7391304347826086, 0.6998420221169038, 0.68, 1.0, 1.0, 0.014211276109865513, 1.0, 1.0, 0.014211276109865513, 1.0, 1.0, 0.16551026614192557, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.21169789517882542, 0.21169789517882523, 0.3955760020016803], 
reward next is 0.6044, 
noisyNet noise sample is [array([1.5639253], dtype=float32), 0.61198175]. 
=============================================
[2019-03-27 08:04:23,391] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9589843e-01 5.0596586e-21 1.4037456e-15 3.8561029e-23 4.1015474e-03], sum to 1.0000
[2019-03-27 08:04:23,402] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4076
[2019-03-27 08:04:23,407] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.5, 81.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9794645328510301, 6.9112, 6.9112, 168.912956510431, 818772.0581975036, 818772.0581975036, 243089.5242260822], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3562200.0000, 
sim time next is 3562800.0000, 
raw observation next is [26.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.005206602671588, 6.911200000000001, 6.9112, 168.9128563876458, 842024.8367338995, 842024.836733899, 249775.2000109268], 
processed observation next is [1.0, 0.21739130434782608, 0.4628751974723541, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.006349515453156, 8.881784197001253e-17, 0.0, 0.8294394535035909, 0.23389578798163876, 0.2338957879816386, 0.3727988059864579], 
reward next is 0.6272, 
noisyNet noise sample is [array([-0.46765423], dtype=float32), -1.1594816]. 
=============================================
[2019-03-27 08:04:24,004] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 6.0938323e-31 1.4647169e-27 5.9801434e-30 2.1748891e-11], sum to 1.0000
[2019-03-27 08:04:24,005] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-27 08:04:24,011] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8579928584015939, 6.9112, 6.9112, 168.912956510431, 710959.2798855753, 710959.2798855753, 214000.6618672444], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3456600.0000, 
sim time next is 3457200.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8575951577770233, 6.9112, 6.9112, 168.912956510431, 710629.622705914, 710629.622705914, 213912.7129741632], 
processed observation next is [1.0, 0.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8263355582646627, 0.0, 0.0, 0.8294399451523027, 0.19739711741830943, 0.19739711741830943, 0.31927270593158685], 
reward next is 0.6807, 
noisyNet noise sample is [array([0.510641], dtype=float32), 0.1876052]. 
=============================================
[2019-03-27 08:04:28,413] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9932444e-01 3.1656856e-23 2.6427767e-18 4.2030907e-24 6.7561428e-04], sum to 1.0000
[2019-03-27 08:04:28,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7801
[2019-03-27 08:04:28,431] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1032555.123288351 W.
[2019-03-27 08:04:28,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.0, 74.0, 1.0, 2.0, 0.3656397401897896, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6128186493423036, 6.911199999999999, 6.9112, 168.9129562156215, 1032555.123288351, 1032555.123288352, 243236.812216671], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3724200.0000, 
sim time next is 3724800.0000, 
raw observation next is [27.0, 74.0, 1.0, 2.0, 0.6526320006443489, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9129565103574, 931230.0126442034, 931230.0126442028, 213472.8239928353], 
processed observation next is [1.0, 0.08695652173913043, 0.4786729857819906, 0.74, 1.0, 1.0, 0.5814843381257215, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451519412, 0.25867500351227873, 0.25867500351227857, 0.31861615521318704], 
reward next is 0.6814, 
noisyNet noise sample is [array([2.1860604], dtype=float32), 1.3886544]. 
=============================================
[2019-03-27 08:04:30,330] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 6.1022224e-26 1.3248319e-20 3.1695114e-27 3.7255123e-08], sum to 1.0000
[2019-03-27 08:04:30,340] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7521
[2019-03-27 08:04:30,346] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.003392702843504, 6.9112, 6.9112, 168.9128699084293, 840776.0022545451, 840776.0022545451, 249308.8832187916], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3562800.0000, 
sim time next is 3563400.0000, 
raw observation next is [26.83333333333333, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.015119689799388, 6.9112, 6.9112, 168.9128693297858, 850591.0311595052, 850591.0311595052, 252386.6730757168], 
processed observation next is [1.0, 0.21739130434782608, 0.470774091627172, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0184386460968144, 0.0, 0.0, 0.8294395170554232, 0.2362752864331959, 0.2362752864331959, 0.3766965269786818], 
reward next is 0.6233, 
noisyNet noise sample is [array([-0.7678412], dtype=float32), -1.1745296]. 
=============================================
[2019-03-27 08:04:31,443] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [8.3278048e-01 3.5340481e-18 6.9773424e-13 8.4998495e-20 1.6721953e-01], sum to 1.0000
[2019-03-27 08:04:31,449] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5146
[2019-03-27 08:04:31,454] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.33333333333334, 82.33333333333334, 1.0, 2.0, 0.5961674813901823, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 833104.1279063327, 833104.1279063327, 200025.7909130067], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3648000.0000, 
sim time next is 3648600.0000, 
raw observation next is [26.5, 81.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.028452382279603, 6.9112, 6.9112, 168.9127292087259, 862515.066581821, 862515.066581821, 255951.5423861927], 
processed observation next is [1.0, 0.21739130434782608, 0.4549763033175356, 0.815, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 1.0346980271702475, 0.0, 0.0, 0.8294388289968714, 0.23958751849495027, 0.23958751849495027, 0.38201722744207867], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.9977334], dtype=float32), 0.11948349]. 
=============================================
[2019-03-27 08:04:31,578] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.2841416e-02 1.8048664e-17 2.2015014e-12 1.2138848e-19 9.7715855e-01], sum to 1.0000
[2019-03-27 08:04:31,591] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4224
[2019-03-27 08:04:31,595] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333334, 68.66666666666667, 1.0, 2.0, 0.5165747377778696, 1.0, 2.0, 0.5165747377778696, 1.0, 2.0, 0.8925931786946605, 6.911200000000001, 6.9112, 170.5573041426782, 2166974.648026464, 2166974.648026463, 425949.4484144556], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3576000.0000, 
sim time next is 3576600.0000, 
raw observation next is [30.5, 68.0, 1.0, 2.0, 0.5168451942904615, 1.0, 2.0, 0.5168451942904615, 1.0, 2.0, 0.8937018169874769, 6.911200000000001, 6.9112, 170.5573041426782, 2168110.331787534, 2168110.331787534, 426262.2763343367], 
processed observation next is [1.0, 0.391304347826087, 0.6445497630331753, 0.68, 1.0, 1.0, 0.41788577625356804, 1.0, 1.0, 0.41788577625356804, 1.0, 1.0, 0.870368069496923, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6022528699409817, 0.6022528699409817, 0.636212352737816], 
reward next is 0.3638, 
noisyNet noise sample is [array([-1.2457315], dtype=float32), 0.07593081]. 
=============================================
[2019-03-27 08:04:38,330] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 1.158243e-37 9.942007e-21], sum to 1.0000
[2019-03-27 08:04:38,338] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-27 08:04:38,343] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.33333333333334, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9377936057297676, 6.9112, 6.9112, 168.912956510431, 762533.2465050385, 762533.2465050385, 231892.2411604391], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3786000.0000, 
sim time next is 3786600.0000, 
raw observation next is [30.16666666666666, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9464073285145942, 6.911200000000001, 6.9112, 168.912956510431, 768373.9279863451, 768373.9279863446, 233924.5528363101], 
processed observation next is [1.0, 0.8260869565217391, 0.6287519747235385, 0.735, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9346430835543832, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2134372022184292, 0.21343720221842905, 0.3491411236362837], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.156947], dtype=float32), 0.7928187]. 
=============================================
[2019-03-27 08:04:41,129] A3C_AGENT_WORKER-Thread-18 INFO:Evaluating...
[2019-03-27 08:04:41,131] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:04:41,132] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:04:41,134] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:04:41,134] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:04:41,134] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:04:41,135] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:04:41,136] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:04:41,137] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:04:41,137] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:04:41,140] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:04:41,164] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run73
[2019-03-27 08:04:41,165] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run73
[2019-03-27 08:04:41,208] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run73
[2019-03-27 08:04:41,208] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run73
[2019-03-27 08:04:41,209] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run73
[2019-03-27 08:04:55,915] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:04:55,917] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.45, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5432471584268784, 6.9112, 6.9112, 168.912956510431, 477753.7306399799, 477753.7306399799, 157763.1008963822]
[2019-03-27 08:04:55,918] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:04:55,923] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 7.7531326e-35 1.0958258e-35 2.3229118e-33 2.3488034e-20], sampled 0.738881505701916
[2019-03-27 08:05:00,452] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:05:00,453] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.47128609666667, 84.47493774166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7343821858393359, 6.9112, 6.9112, 168.912956510431, 625437.3144221068, 625437.3144221068, 189040.892473453]
[2019-03-27 08:05:00,454] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:05:00,457] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.2005566e-37 0.0000000e+00 3.3132643e-36 9.6862779e-22], sampled 0.6279026361244857
[2019-03-27 08:05:42,539] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:05:42,540] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.72033601, 76.63273229, 1.0, 2.0, 0.6989970125052497, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 976867.5960772727, 976867.5960772721, 220628.6006540323]
[2019-03-27 08:05:42,542] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:05:42,544] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9998939e-01 5.6068751e-20 6.9108320e-17 1.9191023e-20 1.0553005e-05], sampled 0.7258725534144133
[2019-03-27 08:05:42,546] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 976867.5960772727 W.
[2019-03-27 08:05:53,874] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:05:53,876] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.43333333333333, 64.83333333333334, 1.0, 2.0, 0.5897086211138, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9994624397880729, 6.911199999999999, 6.9112, 168.9129028545103, 1648789.467880598, 1648789.467880598, 355668.5937581271]
[2019-03-27 08:05:53,877] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:05:53,881] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9808323e-01 3.9319269e-22 4.7439020e-19 1.4631677e-23 1.9167985e-03], sampled 0.7651615088304127
[2019-03-27 08:05:53,882] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1648789.467880598 W.
[2019-03-27 08:06:00,381] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:06:00,383] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.0, 78.83333333333334, 1.0, 2.0, 0.4646245194995768, 1.0, 2.0, 0.4646245194995768, 1.0, 2.0, 0.8068991366942005, 6.911199999999999, 6.9112, 178.6582176852504, 1948770.560330162, 1948770.560330162, 393590.3721995679]
[2019-03-27 08:06:00,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:06:00,387] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [2.0380603e-02 2.8818820e-19 3.5233776e-13 1.1247178e-21 9.7961938e-01], sampled 0.11181793035795196
[2019-03-27 08:06:05,487] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:06:05,489] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.28333333333333, 85.66666666666667, 1.0, 2.0, 0.9782442232166472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1367374.556536263, 1367374.556536263, 292369.4215036625]
[2019-03-27 08:06:05,491] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:06:05,496] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [7.2558963e-01 1.3136512e-17 3.8187257e-13 2.5412516e-19 2.7441031e-01], sampled 0.3643865557782081
[2019-03-27 08:06:05,498] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1367374.556536263 W.
[2019-03-27 08:06:18,124] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:06:18,125] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.18118399833333, 77.38625629500001, 1.0, 2.0, 0.3291046324647146, 1.0, 1.0, 0.3291046324647146, 1.0, 1.0, 0.5715459100261329, 6.9112, 6.9112, 171.5212843490159, 1380046.605283039, 1380046.605283039, 317317.065667117]
[2019-03-27 08:06:18,126] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:06:18,128] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.6510029e-01 5.7416770e-17 1.1125518e-11 8.1293336e-19 8.3489972e-01], sampled 0.1693917077846907
[2019-03-27 08:06:22,555] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07180645]
[2019-03-27 08:06:22,558] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.03733607666667, 74.94572018333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.712001100547819, 6.9112, 6.9112, 168.912956510431, 609974.4360875213, 609974.4360875213, 184902.3915562817]
[2019-03-27 08:06:22,561] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:06:22,567] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.2241225e-37 4.2244903e-38 5.9775247e-36 4.0868898e-21], sampled 0.9526896159497465
[2019-03-27 08:06:36,612] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7420.9610 3110118666.5587 1603.0000
[2019-03-27 08:06:37,159] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7296.0106 3324565343.1152 1851.0000
[2019-03-27 08:06:37,224] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8098.8828 2945540639.9449 1073.0000
[2019-03-27 08:06:37,308] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7920.7208 2996029531.5037 1325.0000
[2019-03-27 08:06:37,438] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7099.0237 3190572306.7797 1983.0000
[2019-03-27 08:06:38,457] A3C_AGENT_WORKER-Thread-18 INFO:Global step: 1800000, evaluation results [1800000.0, 7296.010641471202, 3324565343.1151943, 1851.0, 7420.961008157644, 3110118666.558657, 1603.0, 8098.882794213916, 2945540639.9448657, 1073.0, 7099.023656934093, 3190572306.779696, 1983.0, 7920.720775774318, 2996029531.5036664, 1325.0]
[2019-03-27 08:06:53,465] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [3.9658247e-05 1.8778863e-18 3.1331255e-15 7.8856941e-23 9.9996030e-01], sum to 1.0000
[2019-03-27 08:06:53,475] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0260
[2019-03-27 08:06:53,484] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.83333333333334, 50.5, 1.0, 2.0, 0.8487621161875034, 1.0, 2.0, 0.7449710976080142, 1.0, 2.0, 1.03, 7.005109464843499, 6.9112, 170.5573041426782, 3126280.686024031, 3059009.516363838, 572433.7904495252], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4201800.0000, 
sim time next is 4202400.0000, 
raw observation next is [36.66666666666667, 51.0, 1.0, 2.0, 0.8051490422212395, 1.0, 2.0, 0.7231645606248822, 1.0, 2.0, 1.03, 7.005106024525347, 6.9112, 170.5573041426782, 3034658.099235956, 2967389.394015599, 556597.4555330275], 
processed observation next is [1.0, 0.6521739130434783, 0.9368088467614536, 0.51, 1.0, 1.0, 0.7652398099051079, 1.0, 1.0, 0.666463326054075, 1.0, 1.0, 1.0365853658536586, 0.009390602452534669, 0.0, 0.8375144448122397, 0.8429605831210989, 0.8242748316709997, 0.8307424709448172], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.7474233], dtype=float32), -0.28615108]. 
=============================================
[2019-03-27 08:06:55,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [8.9032197e-01 5.4252837e-17 7.5983301e-14 1.2927968e-19 1.0967807e-01], sum to 1.0000
[2019-03-27 08:06:55,955] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-27 08:06:55,965] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1545214.622973625 W.
[2019-03-27 08:06:55,970] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.83333333333333, 84.83333333333333, 1.0, 2.0, 0.5526908259474125, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9598411870215086, 6.9112, 6.9112, 168.9126575279144, 1545214.622973625, 1545214.622973625, 338223.3450697277], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4607400.0000, 
sim time next is 4608000.0000, 
raw observation next is [30.0, 84.0, 1.0, 2.0, 0.5117682669457586, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8887722353326984, 6.9112, 6.9112, 168.9129564357737, 1430726.10599527, 1430726.10599527, 314633.1222848647], 
processed observation next is [1.0, 0.34782608695652173, 0.6208530805687204, 0.84, 1.0, 1.0, 0.4117689963201911, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8643563845520712, 0.0, 0.0, 0.8294399447857012, 0.39742391833201945, 0.39742391833201945, 0.46960167505203687], 
reward next is 0.5304, 
noisyNet noise sample is [array([0.10983733], dtype=float32), -0.1852744]. 
=============================================
[2019-03-27 08:06:55,991] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[32.936504]
 [33.397064]
 [34.943394]
 [35.428524]
 [36.971607]], R is [[33.18539429]
 [33.34873199]
 [33.01524353]
 [33.19971848]
 [33.36359787]].
[2019-03-27 08:07:09,117] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.6981597e-28 2.1561578e-26 2.7296407e-29 2.3673613e-12], sum to 1.0000
[2019-03-27 08:07:09,128] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0138
[2019-03-27 08:07:09,131] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8109873761795299, 6.9112, 6.9112, 168.912956510431, 679004.3352443101, 679004.3352443101, 204095.9276583685], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4843800.0000, 
sim time next is 4844400.0000, 
raw observation next is [27.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8093506603316172, 6.9112, 6.9112, 168.912956510431, 677633.5496063553, 677633.5496063553, 203754.3316545437], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.76750080528246, 0.0, 0.0, 0.8294399451523027, 0.1882315415573209, 0.1882315415573209, 0.3041109427679757], 
reward next is 0.6959, 
noisyNet noise sample is [array([0.80091053], dtype=float32), 0.37803742]. 
=============================================
[2019-03-27 08:07:09,240] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.2388700e-26 3.8457193e-25 4.3214794e-27 3.0147884e-10], sum to 1.0000
[2019-03-27 08:07:09,251] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7462
[2019-03-27 08:07:09,261] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 878406.5973090528 W.
[2019-03-27 08:07:09,266] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.16666666666666, 66.33333333333333, 1.0, 1.0, 0.3142874668788118, 1.0, 1.0, 0.3142874668788118, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 878406.5973090528, 878406.5973090528, 252711.535419999], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4308600.0000, 
sim time next is 4309200.0000, 
raw observation next is [33.0, 67.0, 1.0, 2.0, 0.3049406919564401, 1.0, 2.0, 0.3049406919564401, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 852272.780467848, 852272.780467848, 250852.6268526752], 
processed observation next is [1.0, 0.9130434782608695, 0.7630331753554502, 0.67, 1.0, 1.0, 0.16257914693546996, 1.0, 1.0, 0.16257914693546996, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23674243901884665, 0.23674243901884665, 0.3744069057502615], 
reward next is 0.6256, 
noisyNet noise sample is [array([0.5224845], dtype=float32), 0.06497328]. 
=============================================
[2019-03-27 08:07:15,377] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7370979e-37 0.0000000e+00 6.2473055e-36 3.3631403e-23], sum to 1.0000
[2019-03-27 08:07:15,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1692
[2019-03-27 08:07:15,392] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9354479554857744, 6.911200000000001, 6.9112, 168.912956510431, 764009.2399946371, 764009.2399946364, 231487.2516419988], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4536000.0000, 
sim time next is 4536600.0000, 
raw observation next is [31.16666666666667, 65.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9427742250366649, 6.9112, 6.9112, 168.912956510431, 770129.9184442759, 770129.9184442759, 233268.0553761387], 
processed observation next is [0.0, 0.5217391304347826, 0.6761453396524489, 0.655, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9302124695569084, 0.0, 0.0, 0.8294399451523027, 0.21392497734563218, 0.21392497734563218, 0.34816127668080404], 
reward next is 0.6518, 
noisyNet noise sample is [array([2.0910068], dtype=float32), 0.80334]. 
=============================================
[2019-03-27 08:07:18,490] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9999964e-01 1.3394003e-20 9.8319283e-18 5.1308014e-21 3.2055863e-07], sum to 1.0000
[2019-03-27 08:07:18,504] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5426
[2019-03-27 08:07:18,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 897692.7596322795 W.
[2019-03-27 08:07:18,518] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.0, 71.0, 1.0, 2.0, 0.3211837199898835, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5577899045431349, 6.911200000000001, 6.9112, 168.912956510431, 897692.7596322795, 897692.7596322788, 229034.0570622419], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4449600.0000, 
sim time next is 4450200.0000, 
raw observation next is [33.0, 70.33333333333334, 1.0, 2.0, 0.3360137430178283, 1.0, 1.0, 0.3360137430178283, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 939156.2704759905, 939156.2704759905, 257232.7324386599], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.7033333333333335, 1.0, 1.0, 0.2000165578528052, 1.0, 0.5, 0.2000165578528052, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.26087674179888626, 0.26087674179888626, 0.38392945140098494], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.24630152], dtype=float32), 0.12902978]. 
=============================================
[2019-03-27 08:07:20,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.9281511e-38 2.4584956e-26], sum to 1.0000
[2019-03-27 08:07:20,460] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9405
[2019-03-27 08:07:20,465] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333334, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9160377950428668, 6.911200000000001, 6.9112, 168.912956510431, 749056.655939734, 749056.6559397334, 226896.384828895], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5040600.0000, 
sim time next is 5041200.0000, 
raw observation next is [28.66666666666667, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9102474393570511, 6.9112, 6.9112, 168.912956510431, 745293.4815419449, 745293.4815419449, 225576.4884929523], 
processed observation next is [0.0, 0.34782608695652173, 0.5576619273301741, 0.78, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8905456577525012, 0.0, 0.0, 0.8294399451523027, 0.2070259670949847, 0.2070259670949847, 0.33668132610888407], 
reward next is 0.6633, 
noisyNet noise sample is [array([-1.1764317], dtype=float32), 0.56240815]. 
=============================================
[2019-03-27 08:07:22,633] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9988678e-26], sum to 1.0000
[2019-03-27 08:07:22,640] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.3361
[2019-03-27 08:07:22,646] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.66666666666667, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9400450849739526, 6.911199999999999, 6.9112, 168.912956510431, 765660.688187807, 765660.6881878077, 232499.7043383145], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4540800.0000, 
sim time next is 4541400.0000, 
raw observation next is [33.0, 56.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9278838296123547, 6.9112, 6.9112, 168.912956510431, 757081.090670322, 757081.090670322, 229635.7302553401], 
processed observation next is [0.0, 0.5652173913043478, 0.7630331753554502, 0.565, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9120534507467739, 0.0, 0.0, 0.8294399451523027, 0.2103003029639783, 0.2103003029639783, 0.3427398959034927], 
reward next is 0.6573, 
noisyNet noise sample is [array([0.02333806], dtype=float32), 0.16437203]. 
=============================================
[2019-03-27 08:07:24,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.3744224e-01 2.9155768e-20 1.7209207e-16 2.6187824e-22 6.2557779e-02], sum to 1.0000
[2019-03-27 08:07:24,711] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8589
[2019-03-27 08:07:24,718] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2522883.954004186 W.
[2019-03-27 08:07:24,723] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.6013308722314976, 1.0, 2.0, 0.6013308722314976, 1.0, 2.0, 1.03, 6.927289859838277, 6.9112, 170.5573041426782, 2522883.954004186, 2511358.132908375, 488461.0971303352], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4640400.0000, 
sim time next is 4641000.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.2648382890788517, 1.0, 2.0, 0.2648382890788517, 1.0, 2.0, 0.4599365247694148, 6.9112, 6.9112, 170.5573041426782, 1110420.626791491, 1110420.626791491, 290697.8801263891], 
processed observation next is [1.0, 0.7391304347826086, 0.6682464454976303, 0.7, 1.0, 1.0, 0.11426299889018277, 1.0, 1.0, 0.11426299889018277, 1.0, 1.0, 0.34138600581635953, 0.0, 0.0, 0.8375144448122397, 0.3084501741087475, 0.3084501741087475, 0.43387743302446136], 
reward next is 0.5661, 
noisyNet noise sample is [array([1.8250715], dtype=float32), 1.4267421]. 
=============================================
[2019-03-27 08:07:24,736] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[32.160305]
 [32.115955]
 [32.147324]
 [31.824432]
 [30.85759 ]], R is [[38.16756821]
 [37.97639847]
 [37.62185669]
 [37.25209427]
 [37.15571976]].
[2019-03-27 08:07:32,232] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.9555472e-36 1.6789014e-36 5.2387300e-36 4.0131091e-19], sum to 1.0000
[2019-03-27 08:07:32,239] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0080
[2019-03-27 08:07:32,243] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8472691804860171, 6.911200000000001, 6.9112, 168.912956510431, 703950.0734656829, 703950.0734656823, 211703.7248333229], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4750200.0000, 
sim time next is 4750800.0000, 
raw observation next is [27.66666666666666, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8423587838152101, 6.9112, 6.9112, 168.912956510431, 700763.0955392516, 700763.0955392516, 210661.3200552386], 
processed observation next is [1.0, 1.0, 0.5102685624012636, 0.7733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8077546144087927, 0.0, 0.0, 0.8294399451523027, 0.1946564154275699, 0.1946564154275699, 0.31441988067946064], 
reward next is 0.6856, 
noisyNet noise sample is [array([-2.4961417], dtype=float32), 0.780401]. 
=============================================
[2019-03-27 08:07:32,267] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-27 08:07:32,268] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:07:32,268] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:07:32,269] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:07:32,270] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:07:32,271] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:07:32,271] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:07:32,272] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:07:32,272] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:07:32,273] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:07:32,274] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:07:32,297] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run74
[2019-03-27 08:07:32,298] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run74
[2019-03-27 08:07:32,338] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run74
[2019-03-27 08:07:32,339] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run74
[2019-03-27 08:07:32,380] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run74
[2019-03-27 08:07:43,088] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:07:43,093] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [16.461350025, 81.073089485, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3436701002877334, 6.9112, 6.9112, 168.912956510431, 311577.2652869296, 311577.2652869296, 106138.7360768514]
[2019-03-27 08:07:43,095] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:07:43,099] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7207306e-37 2.5587125e-27], sampled 0.41802172007382254
[2019-03-27 08:07:45,181] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:07:45,182] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.0, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6286594797839913, 6.911200000000001, 6.9112, 168.912956510431, 546379.0955165186, 546379.095516518, 170567.7620858797]
[2019-03-27 08:07:45,184] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:07:45,188] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.7605086e-38 0.0000000e+00 9.2950051e-37 3.5827728e-25], sampled 0.3113707809190195
[2019-03-27 08:07:48,345] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:07:48,346] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.3, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5325180730175799, 6.9112, 6.9112, 168.912956510431, 469335.7895881882, 469335.7895881882, 156278.9927965954]
[2019-03-27 08:07:48,347] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:07:48,350] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 3.464556e-37 6.482634e-27], sampled 0.8125907575372845
[2019-03-27 08:07:53,625] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:07:53,626] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.6, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.730845949141811, 6.9112, 6.9112, 168.912956510431, 619811.9741891414, 619811.9741891414, 188352.262612112]
[2019-03-27 08:07:53,627] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:07:53,631] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.7699493e-38 8.4833462e-27], sampled 0.14811995989685967
[2019-03-27 08:07:55,398] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:07:55,400] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.06666666666667, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.609196632852701, 6.9112, 6.9112, 168.912956510431, 529851.4239202309, 529851.4239202309, 167500.4721107161]
[2019-03-27 08:07:55,403] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:07:55,405] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2787963e-28], sampled 0.9561250234085175
[2019-03-27 08:08:10,766] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:08:10,766] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.30080909833334, 89.42736526166668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8147384199555179, 6.9112, 6.9112, 168.912956510431, 681848.1336102306, 681848.1336102306, 204874.1979595926]
[2019-03-27 08:08:10,769] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:08:10,774] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 1.76528042e-38 0.00000000e+00 1.05711015e-36
 6.49523664e-26], sampled 0.2538881035829975
[2019-03-27 08:08:38,944] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:08:38,945] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [38.26666666666667, 42.83333333333334, 1.0, 2.0, 0.7618444240464354, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1064742.61752688, 1064742.617526881, 234765.1808788812]
[2019-03-27 08:08:38,948] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:08:38,952] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 8.4816447e-24 4.5080788e-22 8.2746176e-24 3.1265105e-11], sampled 0.0003138890649346804
[2019-03-27 08:08:38,953] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1064742.61752688 W.
[2019-03-27 08:08:39,478] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:08:39,479] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.95, 61.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8903568038836415, 6.9112, 6.9112, 168.912956510431, 736622.0439308651, 736622.0439308651, 221260.3755283429]
[2019-03-27 08:08:39,481] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:08:39,484] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 9.1370467e-38 0.0000000e+00 1.6704432e-36 1.9865987e-23], sampled 0.08568018342323758
[2019-03-27 08:08:45,770] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:08:45,774] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.76666666666667, 79.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.965002915258519, 6.9112, 168.9124421790818, 866985.3332377003, 828815.8096244837, 254811.9309713476]
[2019-03-27 08:08:45,775] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:08:45,779] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.0390264e-30 1.1101854e-29 4.1604409e-30 9.8254922e-16], sampled 0.4963014838183334
[2019-03-27 08:09:08,539] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:09:08,541] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.63333333333334, 85.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9460276612956142, 6.9112, 6.9112, 168.912956510431, 773468.8892582874, 773468.8892582874, 234091.9936632234]
[2019-03-27 08:09:08,543] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:09:08,548] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.4005503e-36 2.9625425e-38 1.1870870e-35 5.4184823e-22], sampled 0.8141493401248441
[2019-03-27 08:09:09,555] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:09:09,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [26.7, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8649798793418044, 6.9112, 6.9112, 168.912956510431, 716001.5143104362, 716001.5143104362, 215527.5235396066]
[2019-03-27 08:09:09,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:09:09,560] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0996452e-27], sampled 0.13555446588733322
[2019-03-27 08:09:11,402] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:09:11,406] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.91217868333333, 80.35799521833334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7754892764450758, 6.911199999999999, 6.9112, 168.912956510431, 655114.5517625412, 655114.5517625419, 196961.3978577579]
[2019-03-27 08:09:11,406] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:09:11,408] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.159891e-26], sampled 0.02065200893569541
[2019-03-27 08:09:27,167] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07003545]
[2019-03-27 08:09:27,168] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.43333333333334, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5816656499299354, 6.9112, 6.9112, 168.912956510431, 510643.6042533359, 510643.6042533359, 163234.7068980014]
[2019-03-27 08:09:27,172] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:09:27,177] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5093715e-38 1.0438915e-26], sampled 0.04649813899343913
[2019-03-27 08:09:28,101] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8072.1330 2938412333.7713 1324.0000
[2019-03-27 08:09:28,359] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7249.5446 3319959628.4948 2204.0000
[2019-03-27 08:09:28,445] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7023.5344 3186035577.3210 2422.0000
[2019-03-27 08:09:28,517] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7371.2289 3105053873.3938 1900.0000
[2019-03-27 08:09:28,531] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7912.4404 2989753023.2594 1563.0000
[2019-03-27 08:09:29,549] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 1825000, evaluation results [1825000.0, 7249.544581014234, 3319959628.494806, 2204.0, 7371.228874112683, 3105053873.3937526, 1900.0, 8072.132993597195, 2938412333.7712855, 1324.0, 7023.5344251321985, 3186035577.320951, 2422.0, 7912.440408905361, 2989753023.2593627, 1563.0]
[2019-03-27 08:09:31,224] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.7511688e-01 3.3341190e-19 7.5544327e-16 7.6656505e-22 1.2488308e-01], sum to 1.0000
[2019-03-27 08:09:31,233] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5768
[2019-03-27 08:09:31,240] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1603456.225286065 W.
[2019-03-27 08:09:31,247] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.83333333333333, 63.5, 1.0, 2.0, 0.3823407165893009, 1.0, 1.0, 0.3823407165893009, 1.0, 2.0, 0.6628448972822208, 6.9112, 6.9112, 170.5573041426782, 1603456.225286065, 1603456.225286065, 343176.1550543987], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4798200.0000, 
sim time next is 4798800.0000, 
raw observation next is [32.0, 63.0, 1.0, 2.0, 0.6584774575521651, 1.0, 2.0, 0.6584774575521651, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1841214.352622145, 1841214.352622144, 356858.0830834852], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.63, 1.0, 1.0, 0.5885270572917652, 1.0, 1.0, 0.5885270572917652, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5114484312839291, 0.5114484312839289, 0.5326240046022167], 
reward next is 0.4674, 
noisyNet noise sample is [array([1.4870666], dtype=float32), 0.70670277]. 
=============================================
[2019-03-27 08:09:35,589] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6906832e-27 6.3117298e-25 1.0648575e-27 1.1421508e-12], sum to 1.0000
[2019-03-27 08:09:35,599] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1031
[2019-03-27 08:09:35,615] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 944899.6148403019 W.
[2019-03-27 08:09:35,619] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.76666666666667, 84.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.074786829968708, 6.9112, 168.9119194007622, 944899.6148403019, 828846.1999977598, 254812.8391853136], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5355600.0000, 
sim time next is 5356200.0000, 
raw observation next is [29.73333333333333, 84.0, 1.0, 1.0, 0.3125203475941478, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5427444917127732, 6.911200000000001, 6.9112, 168.9128233110818, 873469.1017410473, 873469.1017410466, 226072.7805643511], 
processed observation next is [1.0, 1.0, 0.6082148499210109, 0.84, 1.0, 0.5, 0.17171126216162388, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.44237133135704043, 8.881784197001253e-17, 0.0, 0.8294392910825192, 0.24263030603917982, 0.24263030603917962, 0.3374220605438076], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.1255574], dtype=float32), -0.1752286]. 
=============================================
[2019-03-27 08:09:35,769] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.7356761e-01 3.7454527e-18 1.3573958e-14 3.6441713e-20 2.6432341e-02], sum to 1.0000
[2019-03-27 08:09:35,770] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0062
[2019-03-27 08:09:35,773] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2333452.613613213 W.
[2019-03-27 08:09:35,782] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5562219187107151, 1.0, 2.0, 0.5562219187107151, 1.0, 2.0, 0.9646509190218783, 6.9112, 6.9112, 170.5573041426782, 2333452.613613213, 2333452.613613213, 455933.1733878019], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4813200.0000, 
sim time next is 4813800.0000, 
raw observation next is [30.83333333333334, 66.66666666666667, 1.0, 2.0, 0.3705499067574771, 1.0, 2.0, 0.3705499067574771, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1035731.245076407, 1035731.245076407, 264965.3922056816], 
processed observation next is [1.0, 0.7391304347826086, 0.6603475513428123, 0.6666666666666667, 1.0, 1.0, 0.24162639368370736, 1.0, 1.0, 0.24162639368370736, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.28770312363233524, 0.28770312363233524, 0.39547073463534566], 
reward next is 0.6045, 
noisyNet noise sample is [array([0.70248705], dtype=float32), 0.7301268]. 
=============================================
[2019-03-27 08:09:43,574] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 6.3706409e-37 7.8353050e-37 3.4042285e-36 1.3936712e-19], sum to 1.0000
[2019-03-27 08:09:43,586] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.4263
[2019-03-27 08:09:43,590] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.58333333333334, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8407493238695989, 6.911200000000001, 6.9112, 168.912956510431, 700082.9934063216, 700082.993406321, 210331.4079337347], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5010600.0000, 
sim time next is 5011200.0000, 
raw observation next is [26.5, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.834994716859964, 6.9112, 6.9112, 168.912956510431, 696086.2909834951, 696086.2909834951, 209110.9759197143], 
processed observation next is [0.0, 0.0, 0.4549763033175356, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7987740449511754, 0.0, 0.0, 0.8294399451523027, 0.19335730305097085, 0.19335730305097085, 0.31210593420852883], 
reward next is 0.6879, 
noisyNet noise sample is [array([-1.8777735], dtype=float32), 1.7869761]. 
=============================================
[2019-03-27 08:09:48,150] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9826846e-38 1.8230262e-38 2.6687790e-37 1.2142358e-22], sum to 1.0000
[2019-03-27 08:09:48,158] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0467
[2019-03-27 08:09:48,163] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8608060474266602, 6.9112, 6.9112, 168.912956510431, 713298.0968898295, 713298.0968898295, 214624.2278076802], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5006400.0000, 
sim time next is 5007000.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8630166251710222, 6.911199999999999, 6.9112, 168.912956510431, 715125.5328461556, 715125.5328461563, 215115.3712667124], 
processed observation next is [1.0, 0.9565217391304348, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8329471038671001, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19864598134615433, 0.19864598134615452, 0.321067718308526], 
reward next is 0.6789, 
noisyNet noise sample is [array([0.09183025], dtype=float32), -0.70690227]. 
=============================================
[2019-03-27 08:09:48,176] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[66.30072 ]
 [66.353424]
 [66.39619 ]
 [66.44449 ]
 [66.69501 ]], R is [[66.2715683 ]
 [66.28852081]
 [66.30606079]
 [66.3239212 ]
 [66.34165192]].
[2019-03-27 08:09:48,234] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7322911e-25], sum to 1.0000
[2019-03-27 08:09:48,244] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5556
[2019-03-27 08:09:48,251] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8269545034340704, 6.9112, 6.9112, 168.912956510431, 690783.4200185259, 690783.4200185259, 207426.6508542708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5001600.0000, 
sim time next is 5002200.0000, 
raw observation next is [27.0, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8336743009758204, 6.9112, 6.9112, 168.912956510431, 695333.028532831, 695333.028532831, 208836.7148114491], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7971637816778296, 0.0, 0.0, 0.8294399451523027, 0.19314806348134195, 0.19314806348134195, 0.31169658927081956], 
reward next is 0.6883, 
noisyNet noise sample is [array([1.6359609], dtype=float32), -0.045574464]. 
=============================================
[2019-03-27 08:09:51,881] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.729208e-28], sum to 1.0000
[2019-03-27 08:09:51,890] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4045
[2019-03-27 08:09:51,896] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9022018230627538, 6.911199999999999, 6.9112, 168.912956510431, 740525.4421315795, 740525.4421315801, 223774.731229228], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5072400.0000, 
sim time next is 5073000.0000, 
raw observation next is [30.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9471132323557993, 6.9112, 6.9112, 168.912956510431, 777104.9170712325, 777104.9170712325, 234479.4001769543], 
processed observation next is [0.0, 0.7391304347826086, 0.6208530805687204, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.935503941897316, 0.0, 0.0, 0.8294399451523027, 0.21586247696423125, 0.21586247696423125, 0.3499692539954542], 
reward next is 0.6500, 
noisyNet noise sample is [array([-2.1914504], dtype=float32), -0.7443186]. 
=============================================
[2019-03-27 08:09:51,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[73.12791]
 [72.95374]
 [72.89041]
 [72.84553]
 [72.80616]], R is [[73.02050781]
 [72.95631409]
 [72.89401245]
 [72.83338165]
 [72.7742157 ]].
[2019-03-27 08:09:54,050] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.90652597e-01 2.81202505e-19 3.67067488e-14 1.89464104e-21
 1.09347396e-01], sum to 1.0000
[2019-03-27 08:09:54,058] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5908
[2019-03-27 08:09:54,068] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 978333.9225084685 W.
[2019-03-27 08:09:54,073] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [25.73333333333333, 95.0, 1.0, 2.0, 0.3500244328745595, 1.0, 2.0, 0.3500244328745595, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 978333.9225084685, 978333.9225084685, 260269.2186895834], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5545200.0000, 
sim time next is 5545800.0000, 
raw observation next is [25.7, 95.0, 1.0, 2.0, 0.3398668651433882, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5764400811351147, 6.9112, 6.9112, 168.912956510431, 949934.5880417931, 949934.5880417931, 233986.0883532561], 
processed observation next is [1.0, 0.17391304347826086, 0.4170616113744076, 0.95, 1.0, 1.0, 0.20465887366673277, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.48346351357940814, 0.0, 0.0, 0.8294399451523027, 0.26387071890049807, 0.26387071890049807, 0.34923296769142703], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.88002384], dtype=float32), 1.8439701]. 
=============================================
[2019-03-27 08:09:54,182] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.7315537e-37 1.8853310e-27], sum to 1.0000
[2019-03-27 08:09:54,192] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7109
[2019-03-27 08:09:54,198] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8635980899661418, 6.911200000000001, 6.9112, 168.912956510431, 715622.1910551882, 715622.1910551875, 215245.3044401204], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5131200.0000, 
sim time next is 5131800.0000, 
raw observation next is [30.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.860749919750504, 6.911199999999999, 6.9112, 168.912956510431, 713297.7500051999, 713297.7500052005, 214613.2969943726], 
processed observation next is [0.0, 0.391304347826087, 0.6208530805687204, 0.66, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8301828289640293, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19813826389033332, 0.19813826389033348, 0.32031835372294415], 
reward next is 0.6797, 
noisyNet noise sample is [array([0.46966535], dtype=float32), 0.20015724]. 
=============================================
[2019-03-27 08:10:08,845] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.5540462e-26], sum to 1.0000
[2019-03-27 08:10:08,852] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2121
[2019-03-27 08:10:08,858] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.85, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9203399005839404, 6.911200000000001, 6.9112, 168.912956510431, 752575.652433318, 752575.6524333173, 227914.5772414256], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6034200.0000, 
sim time next is 6034800.0000, 
raw observation next is [27.8, 84.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9199080722232132, 6.9112, 6.9112, 168.912956510431, 752245.455993728, 752245.455993728, 227813.1850224172], 
processed observation next is [1.0, 0.8695652173913043, 0.5165876777251186, 0.8466666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9023269173453818, 0.0, 0.0, 0.8294399451523027, 0.2089570711093689, 0.2089570711093689, 0.3400196791379361], 
reward next is 0.6600, 
noisyNet noise sample is [array([0.47448817], dtype=float32), -0.31443974]. 
=============================================
[2019-03-27 08:10:09,982] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.1993315e-28 1.3048058e-26 3.4331528e-29 1.2458039e-13], sum to 1.0000
[2019-03-27 08:10:09,990] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3051
[2019-03-27 08:10:10,002] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 3216334.282849586 W.
[2019-03-27 08:10:10,006] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 10.24192689810054, 6.9112, 169.2664442381925, 3216334.282849586, 848457.0280156558, 255859.4222366881], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6055800.0000, 
sim time next is 6056400.0000, 
raw observation next is [26.2, 93.0, 1.0, 1.0, 0.4500988879858824, 1.0, 1.0, 0.4500988879858824, 1.0, 2.0, 0.7737690013944875, 6.9112, 6.9112, 170.5573041426782, 1887870.004290948, 1887870.004290948, 381082.8320435836], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.93, 1.0, 0.5, 0.33746853974202695, 1.0, 0.5, 0.33746853974202695, 1.0, 1.0, 0.7241085382859602, 0.0, 0.0, 0.8375144448122397, 0.5244083345252634, 0.5244083345252634, 0.5687803463337069], 
reward next is 0.4312, 
noisyNet noise sample is [array([-2.1448097], dtype=float32), -1.3064283]. 
=============================================
[2019-03-27 08:10:10,689] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [6.0401525e-04 3.5992635e-16 2.0864380e-12 5.2500306e-19 9.9939597e-01], sum to 1.0000
[2019-03-27 08:10:10,696] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8259
[2019-03-27 08:10:10,700] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.01666666666667, 60.66666666666666, 1.0, 2.0, 0.8619924385431696, 1.0, 2.0, 0.7515862587858476, 1.0, 2.0, 1.03, 7.005110508587121, 6.9112, 170.5573041426782, 3154076.349192888, 3086804.431856682, 577378.7319729578], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5395800.0000, 
sim time next is 5396400.0000, 
raw observation next is [35.2, 60.0, 1.0, 2.0, 0.8731736983383241, 1.0, 2.0, 0.7571768886834245, 1.0, 2.0, 1.03, 7.00511139071586, 6.9112, 170.5573041426782, 3177567.606955123, 3110295.057714219, 581608.2591281165], 
processed observation next is [1.0, 0.4782608695652174, 0.8672985781990523, 0.6, 1.0, 1.0, 0.8471972269136435, 1.0, 1.0, 0.7074420345583428, 1.0, 1.0, 1.0365853658536586, 0.009391139071585997, 0.0, 0.8375144448122397, 0.8826576685986454, 0.8639708493650609, 0.8680720285494277], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.28187436], dtype=float32), -0.44561365]. 
=============================================
[2019-03-27 08:10:12,422] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 7.4119889e-35 1.6806114e-37 4.0872703e-33 8.4425381e-20], sum to 1.0000
[2019-03-27 08:10:12,429] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.4522
[2019-03-27 08:10:12,438] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8630272151787184, 6.9112, 6.9112, 168.912956510431, 715458.901171882, 715458.901171882, 215128.4267919281], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5623800.0000, 
sim time next is 5624400.0000, 
raw observation next is [25.7, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8641481736411811, 6.911199999999999, 6.9112, 168.912956510431, 716629.713924035, 716629.7139240355, 215385.9921389352], 
processed observation next is [0.0, 0.08695652173913043, 0.4170616113744076, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8343270410258307, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19906380942334304, 0.1990638094233432, 0.32147163005811225], 
reward next is 0.6785, 
noisyNet noise sample is [array([0.42053288], dtype=float32), -0.46615636]. 
=============================================
[2019-03-27 08:10:14,087] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9482876e-01 4.9489542e-18 4.2737975e-15 1.9244588e-20 5.1711961e-03], sum to 1.0000
[2019-03-27 08:10:14,095] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1322
[2019-03-27 08:10:14,103] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1122710.90304373 W.
[2019-03-27 08:10:14,108] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.7, 86.0, 1.0, 2.0, 0.4016520284342396, 1.0, 1.0, 0.4016520284342396, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1122710.90304373, 1122710.90304373, 272553.473576362], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5464800.0000, 
sim time next is 5465400.0000, 
raw observation next is [28.9, 85.16666666666667, 1.0, 2.0, 0.5018256850245603, 1.0, 2.0, 0.5018256850245603, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 1402902.800111493, 1402902.800111492, 300830.2242697129], 
processed observation next is [1.0, 0.2608695652173913, 0.5687203791469194, 0.8516666666666667, 1.0, 1.0, 0.3997899819573015, 1.0, 1.0, 0.3997899819573015, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.38969522225319253, 0.3896952222531922, 0.44900033473091483], 
reward next is 0.5510, 
noisyNet noise sample is [array([-0.5308791], dtype=float32), 0.8751517]. 
=============================================
[2019-03-27 08:10:23,651] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-27 08:10:23,653] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:10:23,653] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:10:23,654] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:10:23,655] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:10:23,656] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:10:23,657] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:10:23,659] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:10:23,660] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:10:23,662] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:10:23,665] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:10:23,687] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run75
[2019-03-27 08:10:23,710] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run75
[2019-03-27 08:10:23,732] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run75
[2019-03-27 08:10:23,750] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run75
[2019-03-27 08:10:23,767] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run75
[2019-03-27 08:10:28,132] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.06965118]
[2019-03-27 08:10:28,133] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.46666666666667, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5388486788404139, 6.911199999999999, 6.9112, 168.912956510431, 473710.9967790074, 473710.9967790081, 157170.9727901973]
[2019-03-27 08:10:28,134] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:10:28,137] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.876528e-32], sampled 0.07212334267567122
[2019-03-27 08:11:06,021] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.06965118]
[2019-03-27 08:11:06,022] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [20.58333333333334, 96.50000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5652141157950543, 6.9112, 6.9112, 168.912956510431, 495910.2715004249, 495910.2715004249, 160862.9109233581]
[2019-03-27 08:11:06,023] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:11:06,026] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.8415486e-33], sampled 0.6474930792480826
[2019-03-27 08:11:35,480] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.06965118]
[2019-03-27 08:11:35,482] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.9, 58.0, 1.0, 2.0, 0.6970724432844356, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.00597533038827, 6.9112, 168.9119069931616, 1871032.120317514, 1803795.656791998, 384024.8251579698]
[2019-03-27 08:11:35,483] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:11:35,486] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999559e-01 8.8213535e-18 1.4790764e-15 9.9738822e-19 4.4377853e-06], sampled 0.427053956435955
[2019-03-27 08:11:35,488] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1871032.120317514 W.
[2019-03-27 08:11:50,547] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.06965118]
[2019-03-27 08:11:50,551] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.61666666666667, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 11.95267920141768, 6.9112, 168.8655609675729, 4433582.022301195, 857986.7257954545, 256457.7005705551]
[2019-03-27 08:11:50,552] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:11:50,554] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.0103371e-35 1.3702003e-37 1.8228632e-34 6.6934598e-22], sampled 0.8056957527048464
[2019-03-27 08:11:50,556] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 4433582.022301195 W.
[2019-03-27 08:12:19,138] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7251.6120 3319941553.4199 2206.0000
[2019-03-27 08:12:19,312] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.06965118]
[2019-03-27 08:12:19,313] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.76666666666667, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6290849590687146, 6.9112, 6.9112, 168.912956510431, 546648.5364049154, 546648.5364049154, 170637.4627158778]
[2019-03-27 08:12:19,313] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:12:19,316] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4015761e-29], sampled 0.7420965416807105
[2019-03-27 08:12:19,519] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7354.6991 3105556966.1370 1962.0000
[2019-03-27 08:12:19,746] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7913.6644 2989527436.4834 1580.0000
[2019-03-27 08:12:19,803] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7025.9580 3185632495.5698 2457.0000
[2019-03-27 08:12:19,879] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8065.7457 2938045111.6184 1357.0000
[2019-03-27 08:12:20,896] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 1850000, evaluation results [1850000.0, 7251.6119928815, 3319941553.4199104, 2206.0, 7354.699144199079, 3105556966.1370096, 1962.0, 8065.745700545215, 2938045111.618414, 1357.0, 7025.9580049993565, 3185632495.56983, 2457.0, 7913.66441955178, 2989527436.48336, 1580.0]
[2019-03-27 08:12:24,618] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.3832678e-31], sum to 1.0000
[2019-03-27 08:12:24,629] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6324
[2019-03-27 08:12:24,635] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.83333333333333, 83.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9200479126020166, 6.911199999999998, 6.9112, 168.912956510431, 754199.4960513128, 754199.496051314, 227926.8999661809], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5688600.0000, 
sim time next is 5689200.0000, 
raw observation next is [27.76666666666667, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9175338273102767, 6.911200000000001, 6.9112, 168.912956510431, 752259.380780187, 752259.3807801863, 227336.3022295547], 
processed observation next is [0.0, 0.8695652173913043, 0.515007898894155, 0.8366666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8994314967198496, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20896093910560748, 0.20896093910560729, 0.3393079137754548], 
reward next is 0.6607, 
noisyNet noise sample is [array([0.03442247], dtype=float32), 0.9582709]. 
=============================================
[2019-03-27 08:12:26,002] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.309466e-29], sum to 1.0000
[2019-03-27 08:12:26,011] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1440
[2019-03-27 08:12:26,015] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.95, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8835413273852828, 6.9112, 6.9112, 168.912956510431, 728283.417082659, 728283.417082659, 219602.0452577682], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5731800.0000, 
sim time next is 5732400.0000, 
raw observation next is [29.1, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8850626126749938, 6.9112, 6.9112, 168.912956510431, 729656.527181369, 729656.527181369, 219953.3970535265], 
processed observation next is [0.0, 0.34782608695652173, 0.5781990521327015, 0.73, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8598324544816995, 0.0, 0.0, 0.8294399451523027, 0.2026823686614914, 0.2026823686614914, 0.3282886523186963], 
reward next is 0.6717, 
noisyNet noise sample is [array([-0.9445458], dtype=float32), 0.21243745]. 
=============================================
[2019-03-27 08:12:31,745] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.5522122e-38 0.0000000e+00 1.9717265e-37 2.8011580e-23], sum to 1.0000
[2019-03-27 08:12:31,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8445
[2019-03-27 08:12:31,756] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.68333333333334, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.958746036473569, 6.911199999999999, 6.9112, 168.912956510431, 778481.0365817486, 778481.0365817493, 236956.8736005086], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5953800.0000, 
sim time next is 5954400.0000, 
raw observation next is [27.6, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9578920912473413, 6.9112, 6.9112, 168.912956510431, 777920.7148114762, 777920.7148114762, 236752.7639716079], 
processed observation next is [1.0, 0.9565217391304348, 0.5071090047393366, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9486488917650503, 0.0, 0.0, 0.8294399451523027, 0.21608908744763228, 0.21608908744763228, 0.35336233428598196], 
reward next is 0.6466, 
noisyNet noise sample is [array([-0.14637177], dtype=float32), 0.53585625]. 
=============================================
[2019-03-27 08:12:32,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.4660689e-01 1.0330280e-15 5.6759523e-13 2.4501747e-18 7.5339317e-01], sum to 1.0000
[2019-03-27 08:12:32,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0471
[2019-03-27 08:12:32,267] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2278579.991642016 W.
[2019-03-27 08:12:32,272] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [30.55, 72.0, 1.0, 2.0, 0.5431539199639919, 1.0, 2.0, 0.5431539199639919, 1.0, 2.0, 0.9432787352313101, 6.9112, 6.9112, 170.5573041426782, 2278579.991642016, 2278579.991642016, 446270.6154662368], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5823000.0000, 
sim time next is 5823600.0000, 
raw observation next is [30.7, 71.33333333333333, 1.0, 2.0, 0.8587868859736886, 1.0, 2.0, 0.8587868859736886, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2401911.029891308, 2401911.029891308, 449506.5662150355], 
processed observation next is [1.0, 0.391304347826087, 0.6540284360189573, 0.7133333333333333, 1.0, 1.0, 0.8298637180405887, 1.0, 1.0, 0.8298637180405887, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6671975083031411, 0.6671975083031411, 0.6709053227090083], 
reward next is 0.3291, 
noisyNet noise sample is [array([0.30825552], dtype=float32), 1.4282779]. 
=============================================
[2019-03-27 08:12:34,587] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.903474e-28], sum to 1.0000
[2019-03-27 08:12:34,592] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1564
[2019-03-27 08:12:34,603] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8949855613296378, 6.9112, 6.9112, 168.912956510431, 736296.1956722644, 736296.1956722644, 222171.6070202063], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6123600.0000, 
sim time next is 6124200.0000, 
raw observation next is [27.21666666666667, 86.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8972753401290802, 6.911199999999999, 6.9112, 168.912956510431, 737988.600777555, 737988.6007775556, 222693.1773171122], 
processed observation next is [1.0, 0.9130434782608695, 0.48894154818325447, 0.8616666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8747260245476586, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20499683354932083, 0.204996833549321, 0.33237787659270474], 
reward next is 0.6676, 
noisyNet noise sample is [array([-1.2860794], dtype=float32), 0.94224966]. 
=============================================
[2019-03-27 08:12:43,975] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.7033647e-34 1.1092216e-34 2.6576496e-33 4.0574748e-18], sum to 1.0000
[2019-03-27 08:12:43,989] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5735
[2019-03-27 08:12:43,992] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.6, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9108770400963777, 6.911199999999999, 6.9112, 168.912956510431, 747354.0466322583, 747354.046632259, 225790.3094108045], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6049200.0000, 
sim time next is 6049800.0000, 
raw observation next is [26.55, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9078185260801325, 6.911199999999999, 6.9112, 168.912956510431, 745140.7977649419, 745140.7977649425, 225085.492570618], 
processed observation next is [1.0, 0.0, 0.4573459715639811, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8875835683904053, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2069835549347061, 0.20698355493470624, 0.3359484963740567], 
reward next is 0.6641, 
noisyNet noise sample is [array([0.16873598], dtype=float32), -1.7660064]. 
=============================================
[2019-03-27 08:12:47,557] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [6.70355439e-01 9.66095505e-18 1.18347338e-16 1.13551356e-20
 3.29644561e-01], sum to 1.0000
[2019-03-27 08:12:47,562] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9827
[2019-03-27 08:12:47,570] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.63333333333333, 75.0, 1.0, 2.0, 0.4775605383813727, 1.0, 2.0, 0.4775605383813727, 1.0, 2.0, 0.829364723485064, 6.911199999999999, 6.9112, 170.5573041426782, 2003161.319952512, 2003161.319952513, 399974.954561782], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6176400.0000, 
sim time next is 6177000.0000, 
raw observation next is [29.71666666666667, 74.5, 1.0, 2.0, 0.4800888614215398, 1.0, 2.0, 0.4800888614215398, 1.0, 2.0, 0.8337555844766282, 6.911199999999999, 6.9112, 170.5573041426782, 2013776.516584398, 2013776.516584399, 401649.565082784], 
processed observation next is [1.0, 0.4782608695652174, 0.6074249605055293, 0.745, 1.0, 1.0, 0.3736010378572769, 1.0, 1.0, 0.3736010378572769, 1.0, 1.0, 0.7972629078983271, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5593823657178884, 0.5593823657178886, 0.5994769628101253], 
reward next is 0.4005, 
noisyNet noise sample is [array([1.8619783], dtype=float32), 0.28048283]. 
=============================================
[2019-03-27 08:12:47,589] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[30.052025]
 [29.722221]
 [30.26672 ]
 [31.176071]
 [30.094841]], R is [[30.61702538]
 [30.71387863]
 [30.40674019]
 [30.10267258]
 [30.23587608]].
[2019-03-27 08:12:53,242] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6482186e-37 1.4501326e-29], sum to 1.0000
[2019-03-27 08:12:53,248] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1294
[2019-03-27 08:12:53,255] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.3, 74.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6697275380311901, 6.911200000000001, 6.9112, 168.912956510431, 576521.8400158354, 576521.8400158347, 177420.6280974565], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6855600.0000, 
sim time next is 6856200.0000, 
raw observation next is [25.5, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.667274178226108, 6.911200000000001, 6.9112, 168.912956510431, 574733.5999963228, 574733.5999963222, 177000.0101665374], 
processed observation next is [0.0, 0.34782608695652173, 0.40758293838862564, 0.73, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5942368027147659, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15964822222120076, 0.15964822222120062, 0.26417911965154833], 
reward next is 0.7358, 
noisyNet noise sample is [array([0.39118072], dtype=float32), 0.3890283]. 
=============================================
[2019-03-27 08:12:55,887] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5676682e-29], sum to 1.0000
[2019-03-27 08:12:55,894] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2722
[2019-03-27 08:12:55,903] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.3, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8957713269698361, 6.911200000000001, 6.9112, 168.912956510431, 737455.4527830102, 737455.4527830096, 222373.1684001036], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6305400.0000, 
sim time next is 6306000.0000, 
raw observation next is [27.3, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8953912390954419, 6.9112, 6.9112, 168.912956510431, 737147.3669765517, 737147.3669765517, 222285.5656038262], 
processed observation next is [0.0, 1.0, 0.4928909952606636, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.872428340360295, 0.0, 0.0, 0.8294399451523027, 0.2047631574934866, 0.2047631574934866, 0.33176950090123314], 
reward next is 0.6682, 
noisyNet noise sample is [array([1.8489447], dtype=float32), 0.65072453]. 
=============================================
[2019-03-27 08:12:55,913] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[74.569756]
 [74.594246]
 [74.612236]
 [74.57715 ]
 [74.51528 ]], R is [[74.45205688]
 [74.37563324]
 [74.29969788]
 [74.22402191]
 [74.14833832]].
[2019-03-27 08:12:58,271] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.8689457e-28], sum to 1.0000
[2019-03-27 08:12:58,280] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.9641
[2019-03-27 08:12:58,287] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.6, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8605013934145584, 6.911199999999999, 6.9112, 168.912956510431, 712969.6614769972, 712969.6614769978, 214554.1145083395], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6278400.0000, 
sim time next is 6279000.0000, 
raw observation next is [30.56666666666667, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8613811511554436, 6.9112, 6.9112, 168.912956510431, 713745.3142059045, 713745.3142059045, 214750.927369121], 
processed observation next is [0.0, 0.6956521739130435, 0.6477093206951029, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8309526233602968, 0.0, 0.0, 0.8294399451523027, 0.19826258727941792, 0.19826258727941792, 0.3205237721927179], 
reward next is 0.6795, 
noisyNet noise sample is [array([0.44976604], dtype=float32), -0.24030106]. 
=============================================
[2019-03-27 08:12:58,300] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[73.958694]
 [73.79656 ]
 [73.74177 ]
 [73.70022 ]
 [73.63928 ]], R is [[74.03024292]
 [73.9697113 ]
 [73.90984344]
 [73.8508606 ]
 [73.79330444]].
[2019-03-27 08:13:04,261] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.5768604e-02 5.6881690e-17 1.3038169e-12 3.9659197e-20 9.7423142e-01], sum to 1.0000
[2019-03-27 08:13:04,268] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8341
[2019-03-27 08:13:04,270] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.21666666666667, 91.83333333333333, 1.0, 2.0, 0.2455737069020784, 1.0, 2.0, 0.2455737069020784, 1.0, 2.0, 0.4191461888991584, 6.9112, 6.9112, 170.5573041426782, 1029608.822422563, 1029608.822422563, 283345.8007478786], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6493800.0000, 
sim time next is 6494400.0000, 
raw observation next is [26.2, 92.0, 1.0, 2.0, 0.2419177637889693, 1.0, 2.0, 0.2419177637889693, 1.0, 2.0, 0.4128976002311493, 6.9112, 6.9112, 170.5573041426782, 1014273.420312306, 1014273.420312306, 282131.9958988085], 
processed observation next is [1.0, 0.17391304347826086, 0.44075829383886256, 0.92, 1.0, 1.0, 0.08664790817948106, 1.0, 1.0, 0.08664790817948106, 1.0, 1.0, 0.28402146369652354, 0.0, 0.0, 0.8375144448122397, 0.28174261675341833, 0.28174261675341833, 0.42109253119225154], 
reward next is 0.5789, 
noisyNet noise sample is [array([0.92117953], dtype=float32), 1.967183]. 
=============================================
[2019-03-27 08:13:07,609] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.2563417e-30 7.6205531e-31 8.3696674e-31 5.1007392e-14], sum to 1.0000
[2019-03-27 08:13:07,616] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6371
[2019-03-27 08:13:07,621] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.53333333333333, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8099551826216809, 6.911199999999999, 6.9112, 168.912956510431, 669838.4854206071, 669838.4854206078, 203643.3501317294], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6457200.0000, 
sim time next is 6457800.0000, 
raw observation next is [29.41666666666667, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8296543989700096, 6.9112, 6.9112, 168.912956510431, 686657.2836774791, 686657.2836774791, 207813.8351013126], 
processed observation next is [1.0, 0.7391304347826086, 0.5932069510268565, 0.695, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7922614621585483, 0.0, 0.0, 0.8294399451523027, 0.19073813435485532, 0.19073813435485532, 0.31016990313628745], 
reward next is 0.6898, 
noisyNet noise sample is [array([-0.8241649], dtype=float32), 1.1564628]. 
=============================================
[2019-03-27 08:13:12,275] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9995053e-01 2.4595808e-21 1.2894081e-18 8.0235323e-22 4.9457060e-05], sum to 1.0000
[2019-03-27 08:13:12,282] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4410
[2019-03-27 08:13:12,289] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1293452.897725281 W.
[2019-03-27 08:13:12,294] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.41666666666667, 85.16666666666667, 1.0, 2.0, 0.3084656580114237, 1.0, 2.0, 0.3084656580114237, 1.0, 2.0, 0.5290308729542145, 6.9112, 6.9112, 170.5573041426782, 1293452.897725281, 1293452.897725281, 307329.9046490116], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6509400.0000, 
sim time next is 6510000.0000, 
raw observation next is [27.63333333333334, 83.33333333333334, 1.0, 2.0, 0.3895043984245498, 1.0, 2.0, 0.3895043984245498, 1.0, 2.0, 0.6685351540172099, 6.9112, 6.9112, 170.5573041426782, 1633522.090469009, 1633522.090469009, 346079.3531048868], 
processed observation next is [1.0, 0.34782608695652173, 0.5086887835703005, 0.8333333333333335, 1.0, 1.0, 0.26446313063198773, 1.0, 1.0, 0.26446313063198773, 1.0, 1.0, 0.5957745780697681, 0.0, 0.0, 0.8375144448122397, 0.4537561362413914, 0.4537561362413914, 0.5165363479177415], 
reward next is 0.4835, 
noisyNet noise sample is [array([0.0004403], dtype=float32), 1.3201027]. 
=============================================
[2019-03-27 08:13:12,314] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[39.305336]
 [39.96483 ]
 [40.316788]
 [40.39155 ]
 [38.72412 ]], R is [[38.23793793]
 [38.39685822]
 [38.58206558]
 [38.78531647]
 [39.05076599]].
[2019-03-27 08:13:14,114] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3303603e-38 5.9266047e-26], sum to 1.0000
[2019-03-27 08:13:14,121] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4953
[2019-03-27 08:13:14,131] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.8, 75.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8228668859648702, 6.9112, 6.9112, 168.912956510431, 686945.8392241794, 686945.8392241794, 206546.5520207747], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6554400.0000, 
sim time next is 6555000.0000, 
raw observation next is [27.75, 76.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8261276160033323, 6.911200000000001, 6.9112, 168.912956510431, 689131.4580409565, 689131.458040956, 207225.0155654996], 
processed observation next is [1.0, 0.8695652173913043, 0.514218009478673, 0.7633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7879605073211369, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1914254050113768, 0.19142540501137664, 0.3092910680082084], 
reward next is 0.6907, 
noisyNet noise sample is [array([0.4512103], dtype=float32), -0.19473982]. 
=============================================
[2019-03-27 08:13:14,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[67.58039 ]
 [67.833855]
 [68.164185]
 [68.69926 ]
 [68.71345 ]], R is [[67.09542847]
 [67.11619568]
 [67.13800812]
 [67.16091156]
 [67.18497467]].
[2019-03-27 08:13:14,758] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-27 08:13:14,760] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:13:14,760] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:13:14,764] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:13:14,765] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:13:14,763] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:13:14,765] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:13:14,767] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:13:14,768] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:13:14,770] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:13:14,770] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:13:14,791] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run76
[2019-03-27 08:13:14,817] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run76
[2019-03-27 08:13:14,819] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run76
[2019-03-27 08:13:14,837] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run76
[2019-03-27 08:13:14,857] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run76
[2019-03-27 08:13:18,958] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07100714]
[2019-03-27 08:13:18,958] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.3, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.474153945817576, 6.9112, 6.9112, 168.912956510431, 423064.1454866691, 423064.1454866691, 148698.1800478335]
[2019-03-27 08:13:18,959] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:13:18,962] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.4027399e-38 1.3651197e-28], sampled 0.8904336806372596
[2019-03-27 08:13:46,427] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07100714]
[2019-03-27 08:13:46,428] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.96608256, 73.71336527, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9492577516262665, 6.9112, 6.9112, 168.912956510431, 790340.3054305678, 790340.3054305678, 235435.2250478816]
[2019-03-27 08:13:46,431] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:13:46,435] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 8.7430772e-38 0.0000000e+00 1.7088828e-36 8.8711740e-24], sampled 0.08534108325193213
[2019-03-27 08:14:00,943] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07100714]
[2019-03-27 08:14:00,944] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.55, 74.0, 1.0, 2.0, 0.6808807337808263, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990125559015334, 6.9112, 168.9124226681648, 1848374.512081511, 1792382.18106989, 381154.730421323]
[2019-03-27 08:14:00,946] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:14:00,948] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9999464e-01 1.8059900e-22 9.3945584e-21 4.5313945e-24 5.3724248e-06], sampled 0.9523139129943294
[2019-03-27 08:14:00,950] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1848374.512081511 W.
[2019-03-27 08:14:27,088] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07100714]
[2019-03-27 08:14:27,088] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.98307187666666, 69.93621870166666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8290891353822927, 6.9112, 6.9112, 168.912956510431, 693514.7062536197, 693514.7062536197, 207906.6419946966]
[2019-03-27 08:14:27,090] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:14:27,094] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3501105e-37 3.4138541e-27], sampled 0.3886778637673781
[2019-03-27 08:14:34,506] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02849418], dtype=float32), 0.07100714]
[2019-03-27 08:14:34,507] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.76666666666667, 66.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.021136476107426, 6.9112, 6.9112, 168.9127510175132, 824474.4653160743, 824474.4653160743, 252633.860720105]
[2019-03-27 08:14:34,509] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:14:34,511] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.4511128e-38 0.0000000e+00 6.2455151e-37 3.8322192e-24], sampled 0.7725220111958612
[2019-03-27 08:15:09,923] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8085.4565 2939182581.7163 1257.0000
[2019-03-27 08:15:10,769] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7008.0569 3188550463.9698 2415.0000
[2019-03-27 08:15:10,903] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7397.4654 3105397238.4027 1841.0000
[2019-03-27 08:15:11,051] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7900.6202 2991347567.0271 1556.0000
[2019-03-27 08:15:11,218] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7260.6975 3320873274.5942 2168.0000
[2019-03-27 08:15:12,236] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1875000, evaluation results [1875000.0, 7260.697475100212, 3320873274.594212, 2168.0, 7397.4654028608775, 3105397238.402685, 1841.0, 8085.456519650907, 2939182581.716316, 1257.0, 7008.05685565717, 3188550463.969801, 2415.0, 7900.620183006147, 2991347567.027085, 1556.0]
[2019-03-27 08:15:19,783] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.291397e-28], sum to 1.0000
[2019-03-27 08:15:19,791] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9170
[2019-03-27 08:15:19,794] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.81666666666667, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7866243646433512, 6.9112, 6.9112, 168.912956510431, 660139.3914418204, 660139.3914418204, 199120.0767709662], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6959400.0000, 
sim time next is 6960000.0000, 
raw observation next is [31.63333333333333, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7723361207295293, 6.9112, 6.9112, 168.912956510431, 649180.906625034, 649180.906625034, 196276.4116007656], 
processed observation next is [0.0, 0.5652173913043478, 0.6982622432859398, 0.52, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7223611228408893, 0.0, 0.0, 0.8294399451523027, 0.18032802961806502, 0.18032802961806502, 0.29294986806084417], 
reward next is 0.7071, 
noisyNet noise sample is [array([1.2206784], dtype=float32), 1.2728331]. 
=============================================
[2019-03-27 08:15:19,808] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[76.27857 ]
 [76.15677 ]
 [76.052574]
 [76.047966]
 [76.040794]], R is [[76.36050415]
 [76.29970551]
 [76.23820496]
 [76.17915344]
 [76.12225342]].
[2019-03-27 08:15:29,443] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.265548e-28], sum to 1.0000
[2019-03-27 08:15:29,454] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0282
[2019-03-27 08:15:29,459] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.9, 30.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4693677071879472, 6.9112, 6.9112, 168.912956510431, 419707.3587315264, 419707.3587315264, 148081.1735941965], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6876000.0000, 
sim time next is 6876600.0000, 
raw observation next is [29.86666666666667, 31.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4661693020018569, 6.911199999999999, 6.9112, 168.912956510431, 416885.9759888996, 416885.9759889003, 147709.884189609], 
processed observation next is [0.0, 0.6086956521739131, 0.6145339652448659, 0.3116666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.34898695366080107, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11580165999691655, 0.11580165999691674, 0.22046251371583434], 
reward next is 0.7795, 
noisyNet noise sample is [array([0.8747936], dtype=float32), -1.1252959]. 
=============================================
[2019-03-27 08:15:31,628] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2255584e-28], sum to 1.0000
[2019-03-27 08:15:31,634] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6112
[2019-03-27 08:15:31,638] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666667, 58.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.798068551826525, 6.911200000000001, 6.9112, 168.912956510431, 668084.6493509321, 668084.6493509315, 201417.0059252807], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6968400.0000, 
sim time next is 6969000.0000, 
raw observation next is [30.33333333333333, 60.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8004582799544973, 6.911199999999999, 6.9112, 168.912956510431, 669950.9147384089, 669950.9147384095, 201905.5133171407], 
processed observation next is [0.0, 0.6521739130434783, 0.6366508688783569, 0.6033333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7566564389688991, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1860974763162247, 0.18609747631622484, 0.30135151241364283], 
reward next is 0.6986, 
noisyNet noise sample is [array([-0.5504932], dtype=float32), -1.4085739]. 
=============================================
[2019-03-27 08:15:31,649] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[79.43825 ]
 [79.35484 ]
 [79.27758 ]
 [79.206856]
 [79.11111 ]], R is [[79.4360733 ]
 [79.34109497]
 [79.24771118]
 [79.15629578]
 [79.06707764]].
[2019-03-27 08:15:31,913] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0476173e-26], sum to 1.0000
[2019-03-27 08:15:31,916] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.9268
[2019-03-27 08:15:31,926] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.83333333333333, 74.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6992922119876569, 6.911200000000001, 6.9112, 168.912956510431, 598859.5032036089, 598859.5032036083, 182603.5346252321], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6905400.0000, 
sim time next is 6906000.0000, 
raw observation next is [25.76666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7019620794567092, 6.911200000000001, 6.9112, 168.912956510431, 600730.3323681555, 600730.3323681548, 183082.1231442405], 
processed observation next is [0.0, 0.9565217391304348, 0.42022116903633505, 0.7566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6365391212886697, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16686953676893207, 0.16686953676893188, 0.2732569002152843], 
reward next is 0.7267, 
noisyNet noise sample is [array([-1.4208609], dtype=float32), -2.3473141]. 
=============================================
[2019-03-27 08:15:31,952] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[81.77422 ]
 [81.76584 ]
 [81.73201 ]
 [81.8044  ]
 [81.887276]], R is [[81.63671875]
 [81.54780579]
 [81.46059418]
 [81.37521362]
 [81.29174042]].
[2019-03-27 08:15:33,602] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6767928e-37 4.0637159e-26], sum to 1.0000
[2019-03-27 08:15:33,609] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.5455
[2019-03-27 08:15:33,618] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.45, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7248452457954481, 6.911199999999999, 6.9112, 168.912956510431, 617252.3801111848, 617252.3801111855, 187254.5729365376], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6935400.0000, 
sim time next is 6936000.0000, 
raw observation next is [25.66666666666666, 79.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7277284390237901, 6.911199999999999, 6.9112, 168.912956510431, 619379.4756686519, 619379.4756686526, 187789.5756294445], 
processed observation next is [0.0, 0.2608695652173913, 0.4154818325434437, 0.7933333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6679615110046222, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1720498543524033, 0.1720498543524035, 0.28028294870066345], 
reward next is 0.7197, 
noisyNet noise sample is [array([1.0767735], dtype=float32), 0.021473411]. 
=============================================
[2019-03-27 08:15:33,639] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[72.32505 ]
 [72.41099 ]
 [72.478485]
 [72.48415 ]
 [72.447586]], R is [[72.21751404]
 [72.21585083]
 [72.21494293]
 [72.21457672]
 [72.21463013]].
[2019-03-27 08:15:33,983] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [6.4152896e-01 7.9027719e-18 5.4163941e-15 7.7220784e-21 3.5847104e-01], sum to 1.0000
[2019-03-27 08:15:33,991] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2590
[2019-03-27 08:15:34,002] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1824871.823252911 W.
[2019-03-27 08:15:34,007] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.2, 44.0, 1.0, 2.0, 0.4285753721298036, 1.0, 2.0, 0.4285753721298036, 1.0, 2.0, 0.7207292807555667, 6.911200000000001, 6.9112, 170.5573041426782, 1824871.823252911, 1824871.82325291, 367914.6366039268], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7048800.0000, 
sim time next is 7049400.0000, 
raw observation next is [31.98333333333333, 45.33333333333334, 1.0, 2.0, 0.6464844040724724, 1.0, 2.0, 0.6464844040724724, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1849313.284564646, 1849313.284564646, 357144.8414655937], 
processed observation next is [1.0, 0.6086956521739131, 0.7148499210110584, 0.4533333333333334, 1.0, 1.0, 0.574077595268039, 1.0, 1.0, 0.574077595268039, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5136981346012905, 0.5136981346012905, 0.5330520021874533], 
reward next is 0.4669, 
noisyNet noise sample is [array([0.15757273], dtype=float32), -1.6564583]. 
=============================================
[2019-03-27 08:15:41,676] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.5227662e-26 3.5246061e-24 7.9918951e-27 9.8644859e-10], sum to 1.0000
[2019-03-27 08:15:41,683] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0118
[2019-03-27 08:15:41,689] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.8, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9703467758422801, 6.911200000000001, 6.9112, 168.912956510422, 807537.8213144799, 807537.8213144793, 240671.8482232534], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7184400.0000, 
sim time next is 7185000.0000, 
raw observation next is [25.8, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9576457387145975, 6.9112, 6.9112, 168.912956510431, 797545.232665469, 797545.232665469, 237515.5114170093], 
processed observation next is [1.0, 0.13043478260869565, 0.42180094786729866, 0.8983333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9483484618470699, 0.0, 0.0, 0.8294399451523027, 0.22154034240707474, 0.22154034240707474, 0.35450076330896907], 
reward next is 0.6455, 
noisyNet noise sample is [array([-0.37562844], dtype=float32), -0.31829834]. 
=============================================
[2019-03-27 08:15:41,707] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[53.692997]
 [52.024403]
 [50.69651 ]
 [54.99308 ]
 [54.00188 ]], R is [[55.14002228]
 [55.22941208]
 [54.67712021]
 [54.73154831]
 [54.18423462]].
[2019-03-27 08:15:43,858] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.8913057e-38 4.6325102e-25], sum to 1.0000
[2019-03-27 08:15:43,865] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1033
[2019-03-27 08:15:43,873] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.55, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6481540106059044, 6.911200000000001, 6.9112, 168.912956510431, 560136.9997718789, 560136.9997718782, 173776.9147841069], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7245000.0000, 
sim time next is 7245600.0000, 
raw observation next is [22.53333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.64671534763227, 6.9112, 6.9112, 168.912956510431, 558996.2606867781, 558996.2606867781, 173538.4964516501], 
processed observation next is [1.0, 0.8695652173913043, 0.26698262243285936, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5691650580881341, 0.0, 0.0, 0.8294399451523027, 0.15527673907966058, 0.15527673907966058, 0.25901268127111954], 
reward next is 0.7410, 
noisyNet noise sample is [array([-1.5886319], dtype=float32), -0.09042006]. 
=============================================
[2019-03-27 08:15:44,576] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9754709e-01 7.3338859e-21 1.2310581e-17 5.7584265e-23 2.4529311e-03], sum to 1.0000
[2019-03-27 08:15:44,588] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.2289
[2019-03-27 08:15:44,598] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1590894.439596956 W.
[2019-03-27 08:15:44,602] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.85, 78.5, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.104377228662708, 6.9112, 168.9118245270586, 1590894.439596956, 1453848.783364861, 311346.4110330238], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 7133400.0000, 
sim time next is 7134000.0000, 
raw observation next is [26.73333333333333, 79.33333333333334, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 7.441018737751204, 6.9112, 168.9097459464877, 1829876.875298431, 1454012.372055204, 311346.4738079074], 
processed observation next is [1.0, 0.5652173913043478, 0.4660347551342811, 0.7933333333333334, 1.0, 1.0, 1.0481927710843375, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.05298187377512038, 0.0, 0.8294241798135386, 0.5082991320273419, 0.40389232557088994, 0.46469622956404083], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.36861444], dtype=float32), -1.7731998]. 
=============================================
[2019-03-27 08:15:44,611] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[44.817604]
 [47.385365]
 [50.897785]
 [51.318157]
 [51.459156]], R is [[41.82462311]
 [41.40637589]
 [40.99231339]
 [40.58238983]
 [40.17656708]].
[2019-03-27 08:15:45,666] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7739359e-38 1.1559642e-24], sum to 1.0000
[2019-03-27 08:15:45,676] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9460
[2019-03-27 08:15:45,680] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.1, 84.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.79779093682323, 6.9112, 6.9112, 168.912956510431, 668429.1565326115, 668429.1565326115, 201373.3288491789], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7151400.0000, 
sim time next is 7152000.0000, 
raw observation next is [26.1, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7969221627992001, 6.9112, 6.9112, 168.912956510431, 667916.3218073163, 667916.3218073163, 201199.8762268711], 
processed observation next is [1.0, 0.782608695652174, 0.4360189573459717, 0.8433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7523441009746342, 0.0, 0.0, 0.8294399451523027, 0.1855323116131434, 0.1855323116131434, 0.3002983227266733], 
reward next is 0.6997, 
noisyNet noise sample is [array([-0.01638065], dtype=float32), 0.11924563]. 
=============================================
[2019-03-27 08:15:45,694] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[69.38696 ]
 [69.018974]
 [68.53716 ]
 [67.68758 ]
 [66.38166 ]], R is [[70.15490723]
 [70.15280151]
 [70.15042877]
 [70.14871979]
 [70.14683533]].
[2019-03-27 08:15:53,386] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.3136555e-26], sum to 1.0000
[2019-03-27 08:15:53,394] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.2916
[2019-03-27 08:15:53,398] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5238438327868644, 6.911199999999999, 6.9112, 168.912956510431, 462798.8579883144, 462798.857988315, 155088.3014312651], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7414200.0000, 
sim time next is 7414800.0000, 
raw observation next is [21.56666666666667, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5239464263331018, 6.911199999999999, 6.9112, 168.912956510431, 462797.0075401866, 462797.0075401873, 155105.5028762795], 
processed observation next is [1.0, 0.8260869565217391, 0.22116903633491333, 0.8266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4194468613818315, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1285547243167185, 0.1285547243167187, 0.23150075056161118], 
reward next is 0.7685, 
noisyNet noise sample is [array([1.621437], dtype=float32), 0.77368987]. 
=============================================
[2019-03-27 08:15:54,111] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:15:54,111] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:15:54,186] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run10
[2019-03-27 08:15:55,417] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 8.4689748e-38 0.0000000e+00 4.0706752e-37 3.0004629e-22], sum to 1.0000
[2019-03-27 08:15:55,428] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6345
[2019-03-27 08:15:55,433] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.9, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6646818901387236, 6.9112, 6.9112, 168.912956510431, 572631.7549308765, 572631.7549308765, 176558.3713824236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7338600.0000, 
sim time next is 7339200.0000, 
raw observation next is [24.83333333333334, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6637679897902655, 6.9112, 6.9112, 168.912956510431, 571943.8332661325, 571943.8332661325, 176402.787477754], 
processed observation next is [1.0, 0.9565217391304348, 0.3759873617693526, 0.7733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5899609631588604, 0.0, 0.0, 0.8294399451523027, 0.15887328701837014, 0.15887328701837014, 0.26328774250411047], 
reward next is 0.7367, 
noisyNet noise sample is [array([0.38142943], dtype=float32), 0.17856918]. 
=============================================
[2019-03-27 08:16:00,473] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:16:00,474] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:00,536] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run10
[2019-03-27 08:16:03,339] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.1009454e-27 2.6223300e-27 9.7208533e-29 1.7352358e-12], sum to 1.0000
[2019-03-27 08:16:03,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1288
[2019-03-27 08:16:03,355] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1076529.444949148 W.
[2019-03-27 08:16:03,361] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.16666666666667, 80.0, 1.0, 1.0, 0.3504035159467847, 1.0, 1.0, 0.3504035159467847, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1076529.444949148, 1076529.444949148, 271767.9582195199], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 31200.0000, 
sim time next is 31800.0000, 
raw observation next is [23.38333333333333, 79.0, 1.0, 2.0, 0.3432621608049898, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6126395375356484, 6.911199999999999, 6.9112, 168.9129564513259, 1065321.09387083, 1065321.093870831, 246141.9273363715], 
processed observation next is [1.0, 0.34782608695652173, 0.30726698262243274, 0.79, 1.0, 1.0, 0.208749591331313, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.5276091921166444, -8.881784197001253e-17, 0.0, 0.8294399448620695, 0.29592252607523056, 0.29592252607523084, 0.3673760109498082], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.53781813], dtype=float32), -0.10978401]. 
=============================================
[2019-03-27 08:16:05,585] A3C_AGENT_WORKER-Thread-3 INFO:Evaluating...
[2019-03-27 08:16:05,586] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:16:05,588] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:16:05,588] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:05,589] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:16:05,590] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:16:05,589] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:05,591] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:05,591] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:16:05,592] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:05,597] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:16:05,625] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run77
[2019-03-27 08:16:05,646] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run77
[2019-03-27 08:16:05,647] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run77
[2019-03-27 08:16:05,685] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run77
[2019-03-27 08:16:05,704] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run77
[2019-03-27 08:16:14,056] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02852673], dtype=float32), 0.073139295]
[2019-03-27 08:16:14,058] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [17.6, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4057838040479443, 6.911200000000001, 6.9112, 168.912956510431, 367157.5882223534, 367157.5882223528, 140886.9694551349]
[2019-03-27 08:16:14,059] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:16:14,062] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3598063e-37 8.5128469e-27], sampled 0.13509886800410142
[2019-03-27 08:16:40,710] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02852673], dtype=float32), 0.073139295]
[2019-03-27 08:16:40,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.64158150999999, 67.933018525, 1.0, 2.0, 0.6829721064512396, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 954462.2843211143, 954462.2843211143, 217223.4856570421]
[2019-03-27 08:16:40,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:16:40,717] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.4503917e-30 1.1782020e-31 4.1593301e-30 3.3577057e-15], sampled 0.5145922542030787
[2019-03-27 08:16:40,720] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 954462.2843211143 W.
[2019-03-27 08:16:44,249] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02852673], dtype=float32), 0.073139295]
[2019-03-27 08:16:44,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7497060084074346, 6.9112, 6.9112, 168.912956510431, 634967.3739069798, 634967.3739069798, 191928.1107918513]
[2019-03-27 08:16:44,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:16:44,252] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.00000000e+00 4.94122894e-38 0.00000000e+00 1.06207375e-36
 9.06317088e-24], sampled 0.9558741377129824
[2019-03-27 08:16:54,633] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02852673], dtype=float32), 0.073139295]
[2019-03-27 08:16:54,634] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.93333333333334, 70.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9233166945746215, 6.9112, 6.9112, 168.912956510431, 757436.1320867295, 757436.1320867295, 228727.8663108781]
[2019-03-27 08:16:54,636] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:16:54,639] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.7756295e-38 0.0000000e+00 6.1577010e-37 1.5834317e-23], sampled 0.6656229822911645
[2019-03-27 08:17:16,283] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02852673], dtype=float32), 0.073139295]
[2019-03-27 08:17:16,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.9, 71.0, 1.0, 2.0, 0.8477595723827576, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1184883.36514702, 1184883.36514702, 255979.4793541012]
[2019-03-27 08:17:16,285] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:17:16,288] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 8.0995692e-25 2.3314461e-23 6.8699480e-26 4.2974623e-08], sampled 0.23061093518415854
[2019-03-27 08:17:16,289] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1184883.36514702 W.
[2019-03-27 08:18:00,525] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7255.9507 3320594580.4411 2174.0000
[2019-03-27 08:18:01,264] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8085.6670 2938440268.2043 1261.0000
[2019-03-27 08:18:01,416] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7903.8444 2990408172.9098 1549.0000
[2019-03-27 08:18:01,574] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7389.3965 3104828493.8304 1856.0000
[2019-03-27 08:18:01,861] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7019.3942 3187515161.8744 2411.0000
[2019-03-27 08:18:02,878] A3C_AGENT_WORKER-Thread-3 INFO:Global step: 1900000, evaluation results [1900000.0, 7255.950656461978, 3320594580.4410954, 2174.0, 7389.396513943975, 3104828493.8304305, 1856.0, 8085.667005237558, 2938440268.2043114, 1261.0, 7019.394192586285, 3187515161.874414, 2411.0, 7903.844361436103, 2990408172.9097567, 1549.0]
[2019-03-27 08:18:03,228] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.0651353e-34 1.2377337e-33 8.2478602e-32 2.6421358e-16], sum to 1.0000
[2019-03-27 08:18:03,240] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5082
[2019-03-27 08:18:03,245] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8240681474496278, 6.9112, 6.9112, 168.912956510431, 692191.7385777482, 692191.7385777482, 206902.3551889472], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7708800.0000, 
sim time next is 7709400.0000, 
raw observation next is [25.0, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8277076542712861, 6.9112, 6.9112, 168.912956510431, 694343.2761949665, 694343.2761949665, 207658.0369305971], 
processed observation next is [1.0, 0.21739130434782608, 0.38388625592417064, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7898873832576658, 0.0, 0.0, 0.8294399451523027, 0.1928731322763796, 0.1928731322763796, 0.30993736855313], 
reward next is 0.6901, 
noisyNet noise sample is [array([1.2965227], dtype=float32), -0.9872082]. 
=============================================
[2019-03-27 08:18:04,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:04,793] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:04,867] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run10
[2019-03-27 08:18:05,835] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.4756561e-38 0.0000000e+00 1.8970736e-37 6.1146948e-24], sum to 1.0000
[2019-03-27 08:18:05,839] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6299
[2019-03-27 08:18:05,844] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 62.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.743246124912313, 6.9112, 6.9112, 168.912956510431, 628318.0641375717, 628318.0641375717, 190673.3961116039], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7564200.0000, 
sim time next is 7564800.0000, 
raw observation next is [29.0, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7383392579668494, 6.9112, 6.9112, 168.912956510431, 625057.65067362, 625057.65067362, 189752.0247582757], 
processed observation next is [0.0, 0.5652173913043478, 0.5734597156398105, 0.6166666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6809015341059138, 0.0, 0.0, 0.8294399451523027, 0.17362712518711668, 0.17362712518711668, 0.28321197725115776], 
reward next is 0.7168, 
noisyNet noise sample is [array([-0.25369644], dtype=float32), 0.88036835]. 
=============================================
[2019-03-27 08:18:09,949] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.8315078e-01 1.1529483e-16 3.3562649e-12 1.4900279e-18 8.1684923e-01], sum to 1.0000
[2019-03-27 08:18:09,958] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2513
[2019-03-27 08:18:09,964] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.56666666666667, 77.0, 1.0, 2.0, 0.4444279850911186, 1.0, 2.0, 0.4444279850911186, 1.0, 2.0, 0.763680288815479, 6.9112, 6.9112, 170.5573041426782, 1864063.590375791, 1864063.590375791, 377553.3374876581], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7897200.0000, 
sim time next is 7897800.0000, 
raw observation next is [28.68333333333333, 76.5, 1.0, 2.0, 0.4418964835611704, 1.0, 2.0, 0.4418964835611704, 1.0, 2.0, 0.7595671600009765, 6.9112, 6.9112, 170.5573041426782, 1853436.53398267, 1853436.53398267, 376054.6023229771], 
processed observation next is [1.0, 0.391304347826087, 0.5584518167456555, 0.765, 1.0, 1.0, 0.32758612477249444, 1.0, 1.0, 0.32758612477249444, 1.0, 1.0, 0.7067892195133858, 0.0, 0.0, 0.8375144448122397, 0.5148434816618528, 0.5148434816618528, 0.5612755258551897], 
reward next is 0.4387, 
noisyNet noise sample is [array([-0.56964225], dtype=float32), -1.548833]. 
=============================================
[2019-03-27 08:18:13,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:13,882] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:13,954] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run10
[2019-03-27 08:18:14,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.6018052e-26 1.0735390e-23 5.6710378e-27 1.5331896e-09], sum to 1.0000
[2019-03-27 08:18:14,299] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2815
[2019-03-27 08:18:14,308] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1042456.594204267 W.
[2019-03-27 08:18:14,312] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.23333333333333, 85.5, 1.0, 1.0, 0.3729548421161707, 1.0, 1.0, 0.3729548421161707, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1042456.594204267, 1042456.594204267, 265528.3923785961], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7717800.0000, 
sim time next is 7718400.0000, 
raw observation next is [27.4, 85.0, 1.0, 2.0, 0.2228970688015545, 1.0, 2.0, 0.2228970688015545, 1.0, 1.0, 0.3813544738652444, 6.9112, 6.9112, 170.5573041426782, 934491.7988497737, 934491.7988497737, 276175.3493834909], 
processed observation next is [1.0, 0.34782608695652173, 0.4976303317535545, 0.85, 1.0, 1.0, 0.06373140819464396, 1.0, 1.0, 0.06373140819464396, 1.0, 0.5, 0.24555423642102975, 0.0, 0.0, 0.8375144448122397, 0.25958105523604824, 0.25958105523604824, 0.41220201400521034], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.2171567], dtype=float32), 0.4974984]. 
=============================================
[2019-03-27 08:18:14,513] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.0624184e-28 7.1827658e-28 4.0026921e-29 1.7881909e-13], sum to 1.0000
[2019-03-27 08:18:14,520] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2003
[2019-03-27 08:18:14,526] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6685871496167358, 6.9112, 6.9112, 168.912956510431, 574951.4300596697, 574951.4300596697, 177228.0554285317], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 150000.0000, 
sim time next is 150600.0000, 
raw observation next is [22.5, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6668832358693829, 6.911200000000001, 6.9112, 168.912956510431, 573499.0209116923, 573499.0209116916, 176937.3426047127], 
processed observation next is [1.0, 0.7391304347826086, 0.2654028436018958, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5937600437431498, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1593052835865812, 0.159305283586581, 0.2640855859771831], 
reward next is 0.7359, 
noisyNet noise sample is [array([-0.00921051], dtype=float32), -1.4067436]. 
=============================================
[2019-03-27 08:18:14,994] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 4.5264999e-37 0.0000000e+00 3.5869783e-36 6.6184540e-23], sum to 1.0000
[2019-03-27 08:18:15,002] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4791
[2019-03-27 08:18:15,005] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.8, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6426438968842011, 6.911199999999999, 6.9112, 168.912956510431, 556541.6207607378, 556541.6207607384, 172858.210708947], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 162000.0000, 
sim time next is 162600.0000, 
raw observation next is [21.7, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6364516434334057, 6.9112, 6.9112, 168.912956510431, 551781.4168478603, 551781.4168478603, 171842.0172806], 
processed observation next is [1.0, 0.9130434782608695, 0.2274881516587678, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5566483456504947, 0.0, 0.0, 0.8294399451523027, 0.15327261579107232, 0.15327261579107232, 0.2564806228068657], 
reward next is 0.7435, 
noisyNet noise sample is [array([-0.13663724], dtype=float32), -1.1969829]. 
=============================================
[2019-03-27 08:18:17,496] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:17,497] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:17,556] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run10
[2019-03-27 08:18:20,252] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:20,253] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:20,318] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run10
[2019-03-27 08:18:21,576] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:21,578] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:21,641] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run10
[2019-03-27 08:18:22,351] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:22,352] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:22,404] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run10
[2019-03-27 08:18:23,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:23,526] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:23,584] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run10
[2019-03-27 08:18:23,867] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [4.2788342e-01 6.1046046e-20 2.1301083e-14 1.2139703e-21 5.7211661e-01], sum to 1.0000
[2019-03-27 08:18:23,874] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3790
[2019-03-27 08:18:23,879] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2166390.758113115 W.
[2019-03-27 08:18:23,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.7, 72.0, 1.0, 2.0, 0.5164356876638576, 1.0, 2.0, 0.5164356876638576, 1.0, 2.0, 0.8921036337207874, 6.9112, 6.9112, 170.5573041426782, 2166390.758113115, 2166390.758113115, 425803.7700759502], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 7903800.0000, 
sim time next is 7904400.0000, 
raw observation next is [29.73333333333333, 72.0, 1.0, 2.0, 0.7179270921961545, 1.0, 2.0, 0.7179270921961545, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2007601.331348988, 2007601.331348988, 381891.9763389683], 
processed observation next is [1.0, 0.4782608695652174, 0.6082148499210109, 0.72, 1.0, 1.0, 0.660153123127897, 1.0, 1.0, 0.660153123127897, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.55766703648583, 0.55766703648583, 0.5699880243865199], 
reward next is 0.4300, 
noisyNet noise sample is [array([0.7823449], dtype=float32), -0.024104591]. 
=============================================
[2019-03-27 08:18:25,522] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:25,524] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:25,601] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run10
[2019-03-27 08:18:25,878] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:25,878] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:25,934] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run10
[2019-03-27 08:18:25,956] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:25,958] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:26,032] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run10
[2019-03-27 08:18:26,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:26,184] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:26,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:26,209] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:26,215] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run10
[2019-03-27 08:18:26,292] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run10
[2019-03-27 08:18:26,315] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:26,318] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:26,353] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run10
[2019-03-27 08:18:26,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:18:26,773] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:26,806] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run10
[2019-03-27 08:18:32,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.0366320e-38 0.0000000e+00 1.1399953e-36 8.6691214e-22], sum to 1.0000
[2019-03-27 08:18:32,931] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0766
[2019-03-27 08:18:32,935] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5402967140779606, 6.9112, 6.9112, 168.912956510431, 475836.7244059556, 475836.7244059556, 157338.4298057209], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 176400.0000, 
sim time next is 177000.0000, 
raw observation next is [20.16666666666666, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5395450716029457, 6.9112, 6.9112, 168.912956510431, 475323.1578026265, 475323.1578026265, 157231.274679956], 
processed observation next is [0.0, 0.043478260869565216, 0.15481832543443896, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.43846959951578746, 0.0, 0.0, 0.8294399451523027, 0.13203421050072958, 0.13203421050072958, 0.23467354429844178], 
reward next is 0.7653, 
noisyNet noise sample is [array([-0.7907467], dtype=float32), -0.8782666]. 
=============================================
[2019-03-27 08:18:32,950] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[77.70874 ]
 [76.95451 ]
 [76.233986]
 [75.08621 ]
 [74.494835]], R is [[78.52100372]
 [78.5009613 ]
 [78.48068237]
 [78.46014404]
 [78.43935394]].
[2019-03-27 08:18:35,713] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9999893e-01 2.0712334e-23 2.4727190e-22 8.9531601e-25 1.0269702e-06], sum to 1.0000
[2019-03-27 08:18:35,724] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4135
[2019-03-27 08:18:35,735] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1195891.129779981 W.
[2019-03-27 08:18:35,739] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [22.8, 96.0, 1.0, 2.0, 0.2737811579608461, 1.0, 1.0, 0.2737811579608461, 1.0, 2.0, 0.4686921229747344, 6.9112, 6.9112, 170.5573041426782, 1195891.129779981, 1195891.129779981, 298100.5452858916], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 135000.0000, 
sim time next is 135600.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.8228324612962895, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1216024.008744505, 1216024.008744505, 258750.0590026301], 
processed observation next is [1.0, 0.5652173913043478, 0.2796208530805688, 0.96, 1.0, 1.0, 0.7865451340919151, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3377844468734736, 0.3377844468734736, 0.38619411791437325], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6540192], dtype=float32), -0.9566473]. 
=============================================
[2019-03-27 08:18:50,277] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9712354e-01 1.0882637e-21 9.3704992e-17 1.2376496e-23 2.8763902e-03], sum to 1.0000
[2019-03-27 08:18:50,286] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.6661
[2019-03-27 08:18:50,294] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 936418.0374138003 W.
[2019-03-27 08:18:50,298] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [24.8, 53.33333333333334, 1.0, 2.0, 0.2857694836675517, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5255160655604905, 6.911200000000001, 6.9112, 168.912956510431, 936418.0374138003, 936418.0374137996, 228311.2272451561], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 490800.0000, 
sim time next is 491400.0000, 
raw observation next is [24.75, 53.5, 1.0, 2.0, 0.575280716425138, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 944144.3291702431, 944144.3291702424, 210399.5209017348], 
processed observation next is [1.0, 0.6956521739130435, 0.3720379146919432, 0.535, 1.0, 1.0, 0.48829001978932285, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.26226231365840086, 0.2622623136584007, 0.314029135674231], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.29638603], dtype=float32), 0.9110235]. 
=============================================
[2019-03-27 08:18:54,157] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:18:54,158] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:18:54,159] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:18:54,160] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:54,161] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:54,162] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:18:54,165] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:18:54,166] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:54,166] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:54,167] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:18:54,172] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:18:54,191] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run78
[2019-03-27 08:18:54,210] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run78
[2019-03-27 08:18:54,229] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run78
[2019-03-27 08:18:54,229] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run78
[2019-03-27 08:18:54,267] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run78
[2019-03-27 08:19:33,315] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0756404]
[2019-03-27 08:19:33,318] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.53333333333333, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8019988535683421, 6.911200000000001, 6.9112, 168.912956510431, 674705.6053810919, 674705.6053810914, 202298.2186987854]
[2019-03-27 08:19:33,321] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:19:33,323] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 3.2816134e-38 0.0000000e+00 4.0065258e-37 4.2605525e-21], sampled 0.3566272467234606
[2019-03-27 08:19:35,020] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0756404]
[2019-03-27 08:19:35,023] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.1, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.015576186712344, 6.9112, 6.9112, 168.912780527375, 821240.8598646887, 821240.8598646887, 251244.9063236211]
[2019-03-27 08:19:35,025] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:19:35,026] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.2304009e-38 0.0000000e+00 1.4841984e-37 4.5534847e-21], sampled 0.3238673922191183
[2019-03-27 08:20:38,865] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0756404]
[2019-03-27 08:20:38,866] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [27.76666666666667, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9636745175902336, 6.9112, 6.9112, 168.912956510431, 783464.277443288, 783464.277443288, 238227.5603052869]
[2019-03-27 08:20:38,866] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:20:38,868] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.9008964e-38 0.0000000e+00 6.0535457e-37 8.7192050e-21], sampled 0.09226843767590742
[2019-03-27 08:20:40,322] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0756404]
[2019-03-27 08:20:40,324] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.6, 85.0, 1.0, 2.0, 0.2708073910709043, 1.0, 2.0, 0.2708073910709043, 1.0, 2.0, 0.4703028809174168, 6.9112, 6.9112, 169.0403247858759, 1135466.675206884, 1135466.675206884, 292619.5421444052]
[2019-03-27 08:20:40,325] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:20:40,329] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [6.1692536e-01 3.0048051e-18 6.5953238e-14 7.3912232e-20 3.8307464e-01], sampled 0.6871459545223216
[2019-03-27 08:20:45,384] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0756404]
[2019-03-27 08:20:45,385] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.03333333333333, 81.66666666666666, 1.0, 2.0, 0.5715202324557345, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9750484268861241, 6.911200000000001, 6.9112, 168.912503532844, 1597897.56019564, 1597897.560195639, 345954.9247788945]
[2019-03-27 08:20:45,388] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:20:45,390] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9444783e-01 2.4472219e-21 5.4122026e-18 4.7411686e-23 5.5521810e-03], sampled 0.9360448863779469
[2019-03-27 08:20:45,391] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1597897.56019564 W.
[2019-03-27 08:20:47,016] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7287.8275 3322103597.1400 2070.0000
[2019-03-27 08:20:49,383] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7428.8727 3106388562.7290 1749.0000
[2019-03-27 08:20:49,858] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.2524 2993422458.9591 1470.0000
[2019-03-27 08:20:49,974] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8100.2431 2940634662.9204 1178.0000
[2019-03-27 08:20:49,992] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7029.3144 3190619044.8952 2304.0000
[2019-03-27 08:20:51,011] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 1925000, evaluation results [1925000.0, 7287.827528236326, 3322103597.140009, 2070.0, 7428.872680498866, 3106388562.7290206, 1749.0, 8100.243085181425, 2940634662.920391, 1178.0, 7029.314377378094, 3190619044.895237, 2304.0, 7915.252434412355, 2993422458.95908, 1470.0]
[2019-03-27 08:20:53,087] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3291615e-38 2.3101743e-21], sum to 1.0000
[2019-03-27 08:20:53,095] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5720
[2019-03-27 08:20:53,099] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.23333333333333, 72.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4483966253317703, 6.911200000000001, 6.9112, 168.912956510431, 401205.2548112686, 401205.254811268, 145695.6245825441], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 675600.0000, 
sim time next is 676200.0000, 
raw observation next is [21.01666666666667, 73.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4467853405442438, 6.9112, 6.9112, 168.912956510431, 399902.8632683962, 399902.8632683962, 145508.8757731521], 
processed observation next is [1.0, 0.8260869565217391, 0.1951026856240128, 0.7383333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.325347976273468, 0.0, 0.0, 0.8294399451523027, 0.1110841286856656, 0.1110841286856656, 0.21717742652709268], 
reward next is 0.7828, 
noisyNet noise sample is [array([-0.6951444], dtype=float32), -0.82992846]. 
=============================================
[2019-03-27 08:20:55,930] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.7711910e-36 2.1887721e-37 1.7703686e-34 5.5605427e-20], sum to 1.0000
[2019-03-27 08:20:55,939] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3191
[2019-03-27 08:20:55,942] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.43333333333333, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4767757439274012, 6.9112, 6.9112, 168.912956510431, 424664.7965696771, 424664.7965696771, 149050.433674738], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 783600.0000, 
sim time next is 784200.0000, 
raw observation next is [19.41666666666667, 91.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4771171325715619, 6.911200000000001, 6.9112, 168.912956510431, 424958.8554000512, 424958.8554000505, 149091.305795379], 
processed observation next is [0.0, 0.043478260869565216, 0.11927330173775699, 0.9183333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36233796655068523, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11804412650001422, 0.11804412650001403, 0.22252433700802837], 
reward next is 0.7775, 
noisyNet noise sample is [array([-0.6141442], dtype=float32), -1.5281214]. 
=============================================
[2019-03-27 08:20:57,033] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 6.9492198e-37 0.0000000e+00 1.7311138e-34 2.5521099e-22], sum to 1.0000
[2019-03-27 08:20:57,044] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.8974
[2019-03-27 08:20:57,051] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.5, 82.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5123396706203237, 6.911199999999999, 6.9112, 168.912956510431, 452917.6797387828, 452917.6797387835, 153586.6264936919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 804000.0000, 
sim time next is 804600.0000, 
raw observation next is [21.65, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.514867687563883, 6.9112, 6.9112, 168.912956510431, 454906.8589584904, 454906.8589584904, 153921.078997529], 
processed observation next is [0.0, 0.30434782608695654, 0.22511848341232227, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.40837522873644266, 0.0, 0.0, 0.8294399451523027, 0.12636301637735844, 0.12636301637735844, 0.2297329537276552], 
reward next is 0.7703, 
noisyNet noise sample is [array([-1.3391577], dtype=float32), 0.23075622]. 
=============================================
[2019-03-27 08:20:59,056] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.9866164e-01 4.9789992e-21 8.0094516e-17 5.5796589e-22 1.3383867e-03], sum to 1.0000
[2019-03-27 08:20:59,066] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9160
[2019-03-27 08:20:59,072] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.25, 60.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9471290594274475, 6.9112, 6.9112, 168.912956510431, 838051.9970337712, 838051.9970337712, 234623.0192733379], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 729000.0000, 
sim time next is 729600.0000, 
raw observation next is [24.43333333333333, 59.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.01016528962838, 7.079163551825238, 6.9112, 168.9120191884974, 1015241.485284, 896083.0219907342, 250453.0718744765], 
processed observation next is [1.0, 0.43478260869565216, 0.3570300157977882, 0.5966666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.012396694668756, 0.016796355182523825, 0.0, 0.8294353424725008, 0.28201152369, 0.2489119505529817, 0.3738105550365321], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.07092749], dtype=float32), 0.5285045]. 
=============================================
[2019-03-27 08:21:00,476] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9760407e-01 2.3806022e-20 8.7061376e-16 2.5926884e-21 2.3959056e-03], sum to 1.0000
[2019-03-27 08:21:00,482] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4890
[2019-03-27 08:21:00,487] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.06666666666667, 61.33333333333334, 1.0, 2.0, 0.2625007551846442, 0.0, 1.0, 0.0, 1.0, 2.0, 0.4800570711295335, 6.9112, 6.9112, 168.912956510431, 850059.8818592486, 850059.8818592486, 220352.7717977766], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 728400.0000, 
sim time next is 729000.0000, 
raw observation next is [24.25, 60.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.94583285329094, 6.9112, 6.9112, 168.912956510431, 838988.5037769752, 838988.5037769752, 234174.9087636948], 
processed observation next is [1.0, 0.43478260869565216, 0.3483412322274882, 0.605, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9339425040133413, 0.0, 0.0, 0.8294399451523027, 0.2330523621602709, 0.2330523621602709, 0.3495147891995445], 
reward next is 0.6505, 
noisyNet noise sample is [array([0.05704763], dtype=float32), -0.90902275]. 
=============================================
[2019-03-27 08:21:00,497] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 3.7835906e-37 0.0000000e+00 9.4822790e-36 5.0619995e-22], sum to 1.0000
[2019-03-27 08:21:00,505] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[53.878525]
 [53.00628 ]
 [53.769363]
 [54.70692 ]
 [57.143284]], R is [[57.22149658]
 [56.64928055]
 [56.08278656]
 [55.5219574 ]
 [54.96673965]].
[2019-03-27 08:21:00,511] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1011
[2019-03-27 08:21:00,516] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.01666666666667, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5276731002560157, 6.9112, 6.9112, 168.912956510431, 464791.6358541474, 464791.6358541474, 155645.100150721], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 813000.0000, 
sim time next is 813600.0000, 
raw observation next is [24.2, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5292231497389421, 6.9112, 6.9112, 168.912956510431, 466062.1251034748, 466062.1251034748, 155853.7274504398], 
processed observation next is [0.0, 0.43478260869565216, 0.3459715639810427, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42588188992553916, 0.0, 0.0, 0.8294399451523027, 0.12946170141763189, 0.12946170141763189, 0.23261750365737283], 
reward next is 0.7674, 
noisyNet noise sample is [array([0.5420662], dtype=float32), 0.3080449]. 
=============================================
[2019-03-27 08:21:04,417] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.5789489e-32 1.1807306e-31 5.1641020e-30 1.3587917e-13], sum to 1.0000
[2019-03-27 08:21:04,428] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1475
[2019-03-27 08:21:04,431] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.86666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7699390831499474, 6.911200000000001, 6.9112, 168.912956510431, 686689.8810980058, 686689.8810980052, 195110.3956520158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 721200.0000, 
sim time next is 721800.0000, 
raw observation next is [22.05, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8899822820658141, 6.9112, 6.9112, 168.912956510431, 793551.9730142583, 793551.9730142583, 220653.3509081877], 
processed observation next is [1.0, 0.34782608695652173, 0.24407582938388633, 0.71, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8658320512997733, 0.0, 0.0, 0.8294399451523027, 0.22043110361507176, 0.22043110361507176, 0.32933335956445925], 
reward next is 0.6707, 
noisyNet noise sample is [array([-1.0665936], dtype=float32), 1.8204602]. 
=============================================
[2019-03-27 08:21:07,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 1.5069318e-31 8.9512896e-33 3.2908891e-31 7.0959598e-16], sum to 1.0000
[2019-03-27 08:21:07,158] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.5400
[2019-03-27 08:21:07,164] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.51666666666667, 57.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4318183735183506, 6.9112, 6.9112, 168.912956510431, 386864.8557787214, 386864.8557787214, 143872.3649513926], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 755400.0000, 
sim time next is 756000.0000, 
raw observation next is [23.3, 59.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.439469097675564, 6.911199999999999, 6.9112, 168.912956510431, 393603.927885861, 393603.9278858616, 144696.2235643378], 
processed observation next is [1.0, 0.782608695652174, 0.3033175355450238, 0.59, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.31642572887263903, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.10933442441273918, 0.10933442441273933, 0.2159645127825937], 
reward next is 0.7840, 
noisyNet noise sample is [array([0.68649966], dtype=float32), 1.3866822]. 
=============================================
[2019-03-27 08:21:07,172] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[77.24997]
 [76.84139]
 [74.43789]
 [70.02114]
 [65.01284]], R is [[78.76629639]
 [78.76390076]
 [78.76243591]
 [78.76170349]
 [78.76036835]].
[2019-03-27 08:21:08,623] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 2.4162810e-36 3.5257139e-36 1.1668794e-34 1.3990665e-20], sum to 1.0000
[2019-03-27 08:21:08,632] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.4763
[2019-03-27 08:21:08,637] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4756686929651772, 6.9112, 6.9112, 168.912956510431, 423651.315598426, 423651.315598426, 148921.5480095236], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 787200.0000, 
sim time next is 787800.0000, 
raw observation next is [19.4, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4763041481993923, 6.9112, 6.9112, 168.912956510431, 424217.3553294067, 424217.3553294067, 148996.3897842847], 
processed observation next is [0.0, 0.08695652173913043, 0.11848341232227487, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.36134652219438085, 0.0, 0.0, 0.8294399451523027, 0.11783815425816853, 0.11783815425816853, 0.2223826713198279], 
reward next is 0.7776, 
noisyNet noise sample is [array([0.09254067], dtype=float32), 0.49834147]. 
=============================================
[2019-03-27 08:21:15,310] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.9121018e-36 1.2967847e-37 1.5598795e-34 6.1701664e-21], sum to 1.0000
[2019-03-27 08:21:15,315] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2873
[2019-03-27 08:21:15,321] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.21666666666667, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5515721712153084, 6.9112, 6.9112, 168.912956510431, 484784.5682728012, 484784.5682728012, 158918.1684768775], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1390200.0000, 
sim time next is 1390800.0000, 
raw observation next is [20.23333333333333, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5519606413982432, 6.9112, 6.9112, 168.912956510431, 485071.9430994448, 485071.9430994448, 158973.8243499171], 
processed observation next is [0.0, 0.08695652173913043, 0.15797788309636643, 0.98, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.45361053829054043, 0.0, 0.0, 0.8294399451523027, 0.13474220641651244, 0.13474220641651244, 0.23727436470136878], 
reward next is 0.7627, 
noisyNet noise sample is [array([-0.98597324], dtype=float32), 0.8786509]. 
=============================================
[2019-03-27 08:21:18,621] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999011e-01 3.7314612e-24 1.6430697e-19 5.6202882e-26 9.8864184e-06], sum to 1.0000
[2019-03-27 08:21:18,631] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4762
[2019-03-27 08:21:18,640] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 871975.2758612011 W.
[2019-03-27 08:21:18,646] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.93333333333333, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.006553162806479, 6.9112, 6.9112, 168.912956510431, 871975.2758612011, 871975.2758612011, 250345.1293512037], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 992400.0000, 
sim time next is 993000.0000, 
raw observation next is [21.91666666666666, 94.83333333333333, 1.0, 1.0, 0.2998684434381939, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5309459582472302, 6.9112, 6.9112, 168.912956510431, 918821.9658398599, 918821.9658398599, 228837.8269788649], 
processed observation next is [1.0, 0.4782608695652174, 0.23775671406003138, 0.9483333333333333, 1.0, 0.5, 0.1564680041424023, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42798287591125633, 0.0, 0.0, 0.8294399451523027, 0.2552283238444055, 0.2552283238444055, 0.34154899549084317], 
reward next is 0.6585, 
noisyNet noise sample is [array([2.5739183], dtype=float32), -2.1272104]. 
=============================================
[2019-03-27 08:21:18,658] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.63629 ]
 [65.43087 ]
 [63.774544]
 [62.172802]
 [61.509598]], R is [[65.1218338 ]
 [65.0969696 ]
 [64.44599915]
 [63.80154037]
 [63.82686234]].
[2019-03-27 08:21:19,336] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 3.6769713e-38 0.0000000e+00 2.7990856e-38 4.6151679e-19], sum to 1.0000
[2019-03-27 08:21:19,347] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6847
[2019-03-27 08:21:19,351] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.65, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8572498837917566, 6.911199999999999, 6.9112, 168.912956510431, 710266.2688861516, 710266.2688861522, 213833.8479620246], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1714200.0000, 
sim time next is 1714800.0000, 
raw observation next is [26.6, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8598561233725849, 6.911199999999999, 6.9112, 168.912956510431, 712269.9366325312, 712269.9366325319, 214405.5211106715], 
processed observation next is [1.0, 0.8695652173913043, 0.4597156398104266, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.829092833381201, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1978527601757031, 0.1978527601757033, 0.3200082404636888], 
reward next is 0.6800, 
noisyNet noise sample is [array([0.50394744], dtype=float32), 0.52006286]. 
=============================================
[2019-03-27 08:21:23,702] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.0934143e-01 1.3170293e-20 1.0907676e-15 4.5177284e-22 1.9065852e-01], sum to 1.0000
[2019-03-27 08:21:23,708] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.6495
[2019-03-27 08:21:23,718] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1036708.215164966 W.
[2019-03-27 08:21:23,724] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [25.7, 68.0, 1.0, 2.0, 0.3416718199644878, 1.0, 2.0, 0.3416718199644878, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1036708.215164966, 1036708.215164966, 268307.1092931227], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1090800.0000, 
sim time next is 1091400.0000, 
raw observation next is [25.7, 67.83333333333334, 1.0, 2.0, 0.4211945285069063, 1.0, 2.0, 0.4211945285069063, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1277843.109936713, 1277843.109936713, 289072.5210823392], 
processed observation next is [1.0, 0.6521739130434783, 0.4170616113744076, 0.6783333333333335, 1.0, 1.0, 0.30264401024928467, 1.0, 1.0, 0.30264401024928467, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.35495641942686473, 0.35495641942686473, 0.4314515240034914], 
reward next is 0.5685, 
noisyNet noise sample is [array([1.0356514], dtype=float32), 0.2941279]. 
=============================================
[2019-03-27 08:21:27,627] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.7304739e-29 8.3000455e-29 1.8233059e-29 8.8521914e-13], sum to 1.0000
[2019-03-27 08:21:27,639] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7359
[2019-03-27 08:21:27,643] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.63333333333334, 90.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6664244763500028, 6.9112, 6.9112, 168.912956510431, 588589.6711988825, 588589.6711988825, 176522.1966484313], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1145400.0000, 
sim time next is 1146000.0000, 
raw observation next is [20.76666666666667, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5607060618283979, 6.911200000000001, 6.9112, 168.912956510431, 494965.5690400402, 494965.5690400396, 160119.3040141547], 
processed observation next is [1.0, 0.2608695652173913, 0.18325434439178534, 0.8966666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.46427568515658274, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1374904358444556, 0.13749043584445544, 0.23898403584202196], 
reward next is 0.7610, 
noisyNet noise sample is [array([-2.154457], dtype=float32), -1.266289]. 
=============================================
[2019-03-27 08:21:27,657] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[71.30587 ]
 [72.02839 ]
 [71.95385 ]
 [72.010086]
 [72.0885  ]], R is [[71.36605072]
 [71.38892365]
 [71.44651031]
 [71.50359344]
 [71.56050873]].
[2019-03-27 08:21:29,191] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.2918920e-29 6.7555134e-29 7.5954524e-30 2.4388064e-10], sum to 1.0000
[2019-03-27 08:21:29,203] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7934
[2019-03-27 08:21:29,208] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.85, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9455247910300819, 6.9112, 6.9112, 168.912956510431, 802578.0055774815, 802578.0055774815, 234861.0499490848], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1319400.0000, 
sim time next is 1320000.0000, 
raw observation next is [23.76666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9171127203744724, 6.9112, 6.9112, 168.912956510431, 779058.4267126544, 779058.4267126544, 227997.9802775616], 
processed observation next is [1.0, 0.2608695652173913, 0.32543443917851517, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8989179516761859, 0.0, 0.0, 0.8294399451523027, 0.2164051185312929, 0.2164051185312929, 0.3402954929515845], 
reward next is 0.6597, 
noisyNet noise sample is [array([-0.8349362], dtype=float32), -0.3980105]. 
=============================================
[2019-03-27 08:21:29,228] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[67.862404]
 [68.46638 ]
 [68.91511 ]
 [69.57169 ]
 [69.40267 ]], R is [[67.90149689]
 [67.87194061]
 [67.85181427]
 [67.85090637]
 [67.88873291]].
[2019-03-27 08:21:30,996] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 4.1214963e-33 3.6623559e-31 9.2875809e-33 3.8694867e-13], sum to 1.0000
[2019-03-27 08:21:31,008] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6823
[2019-03-27 08:21:31,014] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.66666666666667, 96.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5709734913091493, 6.911199999999999, 6.9112, 168.912956510431, 500591.167613606, 500591.1676136066, 161698.8471202083], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1379400.0000, 
sim time next is 1380000.0000, 
raw observation next is [20.63333333333333, 96.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5721194055010194, 6.9112, 6.9112, 168.912956510431, 501664.4559588066, 501664.4559588066, 161862.1779876561], 
processed observation next is [1.0, 1.0, 0.17693522906793036, 0.9633333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47819439695246263, 0.0, 0.0, 0.8294399451523027, 0.13935123776633518, 0.13935123776633518, 0.24158534028008372], 
reward next is 0.7584, 
noisyNet noise sample is [array([0.86866045], dtype=float32), 0.17287368]. 
=============================================
[2019-03-27 08:21:31,024] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[76.46446]
 [76.39001]
 [76.27593]
 [76.2469 ]
 [76.21932]], R is [[76.47697449]
 [76.47086334]
 [76.46512604]
 [76.45960999]
 [76.45411682]].
[2019-03-27 08:21:34,092] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.6145810e-02 6.5080425e-23 4.3619599e-18 3.0476611e-25 9.8385412e-01], sum to 1.0000
[2019-03-27 08:21:34,101] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.4307
[2019-03-27 08:21:34,105] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.1, 74.66666666666667, 1.0, 2.0, 0.4960641974793019, 1.0, 2.0, 0.4960641974793019, 1.0, 2.0, 0.8435416475477392, 6.9112, 6.9112, 170.5573041426782, 2080851.601529595, 2080851.601529595, 409176.7962426816], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1266000.0000, 
sim time next is 1266600.0000, 
raw observation next is [28.05, 74.83333333333333, 1.0, 2.0, 0.4927476574950824, 1.0, 2.0, 0.4927476574950824, 1.0, 2.0, 0.837584813427391, 6.911199999999999, 6.9112, 170.5573041426782, 2066926.215611157, 2066926.215611158, 406896.6062747692], 
processed observation next is [1.0, 0.6521739130434783, 0.528436018957346, 0.7483333333333333, 1.0, 1.0, 0.38885259939166555, 1.0, 1.0, 0.38885259939166555, 1.0, 1.0, 0.8019326993016962, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5741461710030992, 0.5741461710030994, 0.6073083675742823], 
reward next is 0.3927, 
noisyNet noise sample is [array([0.24545836], dtype=float32), 0.13282429]. 
=============================================
[2019-03-27 08:21:34,836] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 3.5708486e-32 1.3509447e-30 1.4647243e-32 1.9545286e-11], sum to 1.0000
[2019-03-27 08:21:34,842] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1893
[2019-03-27 08:21:34,847] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.2, 78.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7714438325708262, 6.9112, 6.9112, 168.912956510431, 643790.0398299666, 643790.0398299666, 195994.3164541905], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1273200.0000, 
sim time next is 1273800.0000, 
raw observation next is [27.05, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7818782639374001, 6.9112, 6.9112, 168.912956510431, 653284.1257916833, 653284.1257916833, 198096.3883026446], 
processed observation next is [1.0, 0.7391304347826086, 0.4810426540284361, 0.7933333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7339978828504878, 0.0, 0.0, 0.8294399451523027, 0.18146781271991202, 0.18146781271991202, 0.295666251197977], 
reward next is 0.7043, 
noisyNet noise sample is [array([-0.09265504], dtype=float32), -1.2809367]. 
=============================================
[2019-03-27 08:21:39,002] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 2.4250350e-36 7.9765648e-37 9.8932084e-35 1.2543735e-20], sum to 1.0000
[2019-03-27 08:21:39,009] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6891
[2019-03-27 08:21:39,016] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.06666666666667, 96.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5767239985345034, 6.9112, 6.9112, 168.912956510431, 504130.242019396, 504130.242019396, 162571.1722910131], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1489200.0000, 
sim time next is 1489800.0000, 
raw observation next is [21.28333333333333, 95.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5834120949782879, 6.9112, 6.9112, 168.912956510431, 509261.1217800895, 509261.1217800895, 163568.1984000275], 
processed observation next is [0.0, 0.21739130434782608, 0.20774091627172192, 0.9566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49196596948571697, 0.0, 0.0, 0.8294399451523027, 0.14146142271669154, 0.14146142271669154, 0.24413163940302612], 
reward next is 0.7559, 
noisyNet noise sample is [array([0.8887126], dtype=float32), 1.9396933]. 
=============================================
[2019-03-27 08:21:42,413] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.5306512e-38 0.0000000e+00 2.1021611e-37 2.9830033e-21], sum to 1.0000
[2019-03-27 08:21:42,420] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3555
[2019-03-27 08:21:42,426] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.35, 89.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6145565495692572, 6.9112, 6.9112, 168.912956510431, 534035.2358530081, 534035.2358530081, 168341.0228216911], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1549800.0000, 
sim time next is 1550400.0000, 
raw observation next is [22.26666666666667, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.614356956597755, 6.9112, 6.9112, 168.912956510431, 533972.0111294887, 533972.0111294887, 168308.103087278], 
processed observation next is [0.0, 0.9565217391304348, 0.2543443917851502, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5297036056070182, 0.0, 0.0, 0.8294399451523027, 0.1483255586470802, 0.1483255586470802, 0.2512061240108627], 
reward next is 0.7488, 
noisyNet noise sample is [array([1.2062486], dtype=float32), 0.23403256]. 
=============================================
[2019-03-27 08:21:42,436] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 08:21:42,436] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:21:42,437] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:21:42,438] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:21:42,439] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:21:42,441] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:21:42,441] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:21:42,441] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:21:42,443] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:21:42,447] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:21:42,448] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:21:42,473] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run79
[2019-03-27 08:21:42,495] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run79
[2019-03-27 08:21:42,517] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run79
[2019-03-27 08:21:42,537] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run79
[2019-03-27 08:21:42,538] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run79
[2019-03-27 08:21:50,548] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:21:50,551] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.3, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5781946520707791, 6.911199999999999, 6.9112, 168.912956510431, 508107.1581177566, 508107.1581177572, 162710.3998323428]
[2019-03-27 08:21:50,553] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:21:50,555] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.8857385e-36 3.7416223e-37 3.4564017e-35 6.9729170e-19], sampled 0.10275609285424925
[2019-03-27 08:22:23,185] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:22:23,186] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.45, 77.5, 1.0, 2.0, 0.918408510741055, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1283686.563300167, 1283686.563300167, 275053.445348836]
[2019-03-27 08:22:23,188] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:22:23,190] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9920517e-01 1.9790270e-20 1.7357026e-16 2.6726472e-21 7.9479208e-04], sampled 0.053547565542277686
[2019-03-27 08:22:23,191] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1283686.563300167 W.
[2019-03-27 08:22:29,409] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:22:29,411] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.0, 83.0, 1.0, 2.0, 0.7373489222844153, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1072752.961333007, 1072752.961333008, 234798.9651062259]
[2019-03-27 08:22:29,411] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:22:29,415] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.1066885e-01 1.8504509e-19 1.3162502e-14 5.5383672e-21 8.9331172e-02], sampled 0.0019047405602815592
[2019-03-27 08:22:29,417] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1072752.961333007 W.
[2019-03-27 08:22:38,237] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:22:38,240] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [31.46666666666667, 64.0, 1.0, 2.0, 0.3163694872569949, 1.0, 2.0, 0.3163694872569949, 1.0, 2.0, 0.5462954660339803, 6.911200000000001, 6.9112, 169.0403247858759, 1326622.972170682, 1326622.972170682, 310807.7696593138]
[2019-03-27 08:22:38,242] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:22:38,244] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [2.5378801e-02 8.7813987e-21 8.8318135e-16 1.1445275e-22 9.7462124e-01], sampled 0.4369906840371979
[2019-03-27 08:22:44,030] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:22:44,032] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.96666666666667, 57.0, 1.0, 1.0, 0.6408071450308936, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9128284710212, 895511.3666932248, 895511.3666932248, 208590.7083481199]
[2019-03-27 08:22:44,034] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:22:44,040] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 4.4795114e-33 2.7310189e-34 8.2826963e-33 4.1823946e-14], sampled 0.9557029718768174
[2019-03-27 08:22:44,042] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 895511.3666932248 W.
[2019-03-27 08:22:47,237] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:22:47,238] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [37.0, 54.0, 1.0, 2.0, 0.8877510363164354, 1.0, 2.0, 0.7644655576724801, 1.0, 2.0, 1.03, 7.005112540822907, 6.9112, 170.5573041426782, 3208194.515736371, 3140921.142627005, 587192.8143721973]
[2019-03-27 08:22:47,241] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:22:47,245] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [6.3826383e-06 7.0107848e-23 1.9411938e-18 8.4121428e-26 9.9999356e-01], sampled 0.5741814584800488
[2019-03-27 08:23:03,533] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07671411]
[2019-03-27 08:23:03,534] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.24505442833333, 52.10299111, 1.0, 2.0, 0.7880723148730301, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1155682.985104122, 1155682.985104122, 248444.2632056903]
[2019-03-27 08:23:03,535] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:23:03,538] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9396461e-01 9.4345830e-21 1.2827516e-17 7.0264177e-22 6.0353442e-03], sampled 0.6099905933013431
[2019-03-27 08:23:03,540] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1155682.985104122 W.
[2019-03-27 08:23:37,981] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7957.7762 3001240510.5924 1141.0000
[2019-03-27 08:23:38,214] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7434.9127 3115802512.9564 1518.0000
[2019-03-27 08:23:38,983] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7410.3632 3326410828.7364 1561.0000
[2019-03-27 08:23:39,009] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7204.8619 3192549242.2143 1702.0000
[2019-03-27 08:23:39,046] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8142.7200 2953310367.7763 966.0000
[2019-03-27 08:23:40,064] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 1950000, evaluation results [1950000.0, 7410.363247170787, 3326410828.736414, 1561.0, 7434.912745391931, 3115802512.956447, 1518.0, 8142.720004957216, 2953310367.7763233, 966.0, 7204.861895634267, 3192549242.214295, 1702.0, 7957.776193473074, 3001240510.5924163, 1141.0]
[2019-03-27 08:23:41,306] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.1777583e-33 1.8253004e-32 2.3048272e-32 4.5721051e-15], sum to 1.0000
[2019-03-27 08:23:41,313] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-27 08:23:41,317] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8487905653473353, 6.911200000000001, 6.9112, 168.912956510431, 703931.6310894961, 703931.6310894954, 211996.1152238005], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2016000.0000, 
sim time next is 2016600.0000, 
raw observation next is [25.6, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8504365739604178, 6.9112, 6.9112, 168.912956510431, 704839.1949613115, 704839.1949613115, 212341.644796795], 
processed observation next is [0.0, 0.34782608695652173, 0.4123222748815167, 0.9400000000000002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8176055780005096, 0.0, 0.0, 0.8294399451523027, 0.19578866526703098, 0.19578866526703098, 0.3169278280549179], 
reward next is 0.6831, 
noisyNet noise sample is [array([-0.32951507], dtype=float32), -0.20767044]. 
=============================================
[2019-03-27 08:23:43,449] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 9.0175552e-37 5.1457541e-38 9.1210674e-37 2.3683905e-20], sum to 1.0000
[2019-03-27 08:23:43,458] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4453
[2019-03-27 08:23:43,461] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6438369893877388, 6.911200000000001, 6.9112, 168.912956510431, 556686.7973403676, 556686.797340367, 173063.3597049165], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1465200.0000, 
sim time next is 1465800.0000, 
raw observation next is [21.96666666666667, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6417395049046971, 6.9112, 6.9112, 168.912956510431, 555066.3779374347, 555066.3779374347, 172717.868484232], 
processed observation next is [0.0, 1.0, 0.24012638230647723, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5630969572008501, 0.0, 0.0, 0.8294399451523027, 0.15418510498262075, 0.15418510498262075, 0.2577878634093015], 
reward next is 0.7422, 
noisyNet noise sample is [array([0.10775293], dtype=float32), 0.6758315]. 
=============================================
[2019-03-27 08:23:49,242] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 2.0122528e-34 2.3171769e-33 3.8735730e-34 1.6919582e-15], sum to 1.0000
[2019-03-27 08:23:49,253] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3821
[2019-03-27 08:23:49,258] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.95, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8800747940698419, 6.9112, 6.9112, 168.912956510431, 726477.54367976, 726477.54367976, 218852.9366383034], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2158200.0000, 
sim time next is 2158800.0000, 
raw observation next is [25.9, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8781009346293883, 6.911200000000001, 6.9112, 168.912956510431, 725383.3341017362, 725383.3341017356, 218424.8860475997], 
processed observation next is [0.0, 1.0, 0.42654028436018954, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.851342603206571, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20149537058381561, 0.20149537058381545, 0.32600729260835776], 
reward next is 0.6740, 
noisyNet noise sample is [array([-0.40894693], dtype=float32), 0.69618505]. 
=============================================
[2019-03-27 08:23:51,092] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [4.6731633e-01 2.1803739e-24 6.8611856e-19 4.8580056e-25 5.3268367e-01], sum to 1.0000
[2019-03-27 08:23:51,102] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8431
[2019-03-27 08:23:51,107] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [23.96666666666667, 85.0, 1.0, 2.0, 0.1888710650761399, 1.0, 2.0, 0.1888710650761399, 1.0, 2.0, 0.3261168757308015, 6.9112, 6.9112, 170.5573041426782, 835370.3973026815, 835370.3973026815, 272051.9464810042], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1600800.0000, 
sim time next is 1601400.0000, 
raw observation next is [23.98333333333333, 85.0, 1.0, 2.0, 0.185946332519881, 1.0, 2.0, 0.185946332519881, 1.0, 2.0, 0.3211305377626867, 6.9112, 6.9112, 170.5573041426782, 822672.2259072639, 822672.2259072639, 271306.8365240953], 
processed observation next is [1.0, 0.5217391304347826, 0.3357030015797787, 0.85, 1.0, 1.0, 0.019212448819133712, 1.0, 1.0, 0.019212448819133712, 1.0, 1.0, 0.17211041190571547, 0.0, 0.0, 0.8375144448122397, 0.22852006275201775, 0.22852006275201775, 0.40493557690163484], 
reward next is 0.5951, 
noisyNet noise sample is [array([0.14288065], dtype=float32), -1.2757618]. 
=============================================
[2019-03-27 08:24:01,833] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.5002872e-01 6.5181372e-19 1.1509175e-14 2.3139111e-21 4.9971290e-02], sum to 1.0000
[2019-03-27 08:24:01,840] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.7520
[2019-03-27 08:24:01,849] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 956444.8508597258 W.
[2019-03-27 08:24:01,857] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [21.23333333333333, 90.66666666666667, 1.0, 2.0, 0.6050676292637067, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 956444.8508597258, 956444.8508597253, 214572.175874604], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1781400.0000, 
sim time next is 1782000.0000, 
raw observation next is [21.0, 92.0, 1.0, 2.0, 0.3011945422018245, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5441455824983608, 6.9112, 6.9112, 168.912956510431, 953895.8617036943, 953895.8617036943, 232093.2000383465], 
processed observation next is [1.0, 0.6521739130434783, 0.19431279620853087, 0.92, 1.0, 1.0, 0.1580657134961741, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.4440799786565375, 0.0, 0.0, 0.8294399451523027, 0.26497107269547066, 0.26497107269547066, 0.34640776125126344], 
reward next is 0.6536, 
noisyNet noise sample is [array([-0.12891054], dtype=float32), 1.4078853]. 
=============================================
[2019-03-27 08:24:01,886] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[58.779682]
 [59.578144]
 [58.55399 ]
 [57.899494]
 [56.812794]], R is [[58.53765869]
 [58.63202667]
 [58.65103531]
 [58.66599655]
 [58.07933807]].
[2019-03-27 08:24:02,511] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 4.4781252e-34 1.0970519e-34 1.4524486e-34 6.9965542e-18], sum to 1.0000
[2019-03-27 08:24:02,519] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0281
[2019-03-27 08:24:02,523] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.78333333333333, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8677380133114044, 6.9112, 6.9112, 168.912956510431, 717417.7760401964, 717417.7760401964, 216113.7136450761], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2033400.0000, 
sim time next is 2034000.0000, 
raw observation next is [26.9, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.87126737776848, 6.911200000000001, 6.9112, 168.912956510431, 720122.0626827726, 720122.062682772, 216897.3954042611], 
processed observation next is [0.0, 0.5652173913043478, 0.4739336492890995, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.843008997278634, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20003390630077017, 0.20003390630077, 0.3237274558272554], 
reward next is 0.6763, 
noisyNet noise sample is [array([0.44127277], dtype=float32), 1.0902561]. 
=============================================
[2019-03-27 08:24:02,536] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[70.64478]
 [70.68775]
 [70.72994]
 [70.7692 ]
 [70.80465]], R is [[70.66261292]
 [70.63343048]
 [70.60531616]
 [70.57751465]
 [70.55041504]].
[2019-03-27 08:24:24,821] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [5.6077063e-04 8.6009426e-20 2.7100086e-15 8.3619811e-22 9.9943918e-01], sum to 1.0000
[2019-03-27 08:24:24,831] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4983
[2019-03-27 08:24:24,837] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 81.0, 1.0, 2.0, 0.3562404007387534, 1.0, 2.0, 0.3562404007387534, 1.0, 2.0, 0.6153587723943594, 6.9112, 6.9112, 170.5573041426782, 1493920.725414498, 1493920.725414498, 329585.9746029191], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2190000.0000, 
sim time next is 2190600.0000, 
raw observation next is [28.6, 80.5, 1.0, 2.0, 0.3942719892782498, 1.0, 2.0, 0.3942719892782498, 1.0, 2.0, 0.6821283107383668, 6.911200000000001, 6.9112, 170.5573041426782, 1653532.065242687, 1653532.065242686, 349385.2691708663], 
processed observation next is [1.0, 0.34782608695652173, 0.5545023696682465, 0.805, 1.0, 1.0, 0.2702072159978913, 1.0, 1.0, 0.2702072159978913, 1.0, 1.0, 0.6123515984614228, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.45931446256741304, 0.4593144625674128, 0.5214705510012929], 
reward next is 0.4785, 
noisyNet noise sample is [array([-0.08348035], dtype=float32), 0.46660963]. 
=============================================
[2019-03-27 08:24:27,156] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.7747179e-31 4.9397840e-28 2.8047804e-32 4.3545510e-12], sum to 1.0000
[2019-03-27 08:24:27,164] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7577
[2019-03-27 08:24:27,173] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.25, 85.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8920974792183066, 6.9112, 6.9112, 168.912956510431, 734557.6458683423, 734557.6458683423, 221531.0975251436], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2243400.0000, 
sim time next is 2244000.0000, 
raw observation next is [27.2, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8864602203062296, 6.911199999999999, 6.9112, 168.912956510431, 730465.430000622, 730465.4300006226, 220259.5892565413], 
processed observation next is [1.0, 1.0, 0.4881516587677725, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8615368540319872, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20290706388906166, 0.20290706388906185, 0.3287456556067781], 
reward next is 0.6713, 
noisyNet noise sample is [array([-0.06345492], dtype=float32), -0.54110956]. 
=============================================
[2019-03-27 08:24:27,195] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.428566]
 [68.346954]
 [68.24537 ]
 [68.21635 ]
 [68.193855]], R is [[68.46394348]
 [68.4486618 ]
 [68.43192291]
 [68.41448975]
 [68.39648438]].
[2019-03-27 08:24:27,641] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.2937678e-01 6.5940481e-19 5.1898742e-15 5.5904202e-22 8.7062323e-01], sum to 1.0000
[2019-03-27 08:24:27,653] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2997
[2019-03-27 08:24:27,660] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.26666666666667, 89.0, 1.0, 2.0, 1.04, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 8.66659308942787, 6.9112, 168.9031309704342, 2699822.25393624, 1454558.420605671, 310093.9096674594], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2467200.0000, 
sim time next is 2467800.0000, 
raw observation next is [26.3, 89.0, 1.0, 2.0, 0.5198356406410303, 1.0, 1.0, 0.5198356406410303, 1.0, 1.0, 0.8874540411773371, 6.9112, 6.9112, 170.5573041426782, 2180667.703891556, 2180667.703891556, 426214.4387858054], 
processed observation next is [1.0, 0.5652173913043478, 0.4454976303317536, 0.89, 1.0, 1.0, 0.42148872366389184, 1.0, 0.5, 0.42148872366389184, 1.0, 0.5, 0.8627488307040696, 0.0, 0.0, 0.8375144448122397, 0.6057410288587655, 0.6057410288587655, 0.6361409534116499], 
reward next is 0.3639, 
noisyNet noise sample is [array([0.21609515], dtype=float32), -0.07526628]. 
=============================================
[2019-03-27 08:24:28,340] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.8484498e-01 1.4892795e-21 1.2062287e-16 2.6114025e-23 1.5155029e-02], sum to 1.0000
[2019-03-27 08:24:28,350] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0719
[2019-03-27 08:24:28,358] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1007996.042673069 W.
[2019-03-27 08:24:28,364] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.3, 86.0, 1.0, 2.0, 0.7212603875976414, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.9129565103286, 1007996.042673069, 1007996.042673069, 225498.5326600145], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2256000.0000, 
sim time next is 2256600.0000, 
raw observation next is [26.25, 86.0, 1.0, 2.0, 0.2290872154902313, 1.0, 1.0, 0.2290872154902313, 1.0, 1.0, 0.3864655248422905, 6.9112, 6.9112, 170.5573041426782, 960455.4951179838, 960455.4951179838, 277695.1567004023], 
processed observation next is [1.0, 0.08695652173913043, 0.4431279620853081, 0.86, 1.0, 1.0, 0.07118941625329073, 1.0, 0.5, 0.07118941625329073, 1.0, 0.5, 0.25178722541742743, 0.0, 0.0, 0.8375144448122397, 0.26679319308832883, 0.26679319308832883, 0.41447038313492884], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9075304], dtype=float32), -1.3731589]. 
=============================================
[2019-03-27 08:24:29,677] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [8.220401e-03 6.699113e-21 6.445437e-17 4.030730e-24 9.917796e-01], sum to 1.0000
[2019-03-27 08:24:29,685] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1182
[2019-03-27 08:24:29,690] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.43333333333334, 74.0, 1.0, 2.0, 0.5208185183244479, 1.0, 2.0, 0.5208185183244479, 1.0, 2.0, 0.900644635638046, 6.9112, 6.9112, 170.5573041426782, 2184794.999780844, 2184794.999780844, 429114.8255450091], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2564400.0000, 
sim time next is 2565000.0000, 
raw observation next is [29.35, 74.5, 1.0, 2.0, 0.4992343079232169, 1.0, 2.0, 0.4992343079232169, 1.0, 2.0, 0.8632176295117029, 6.9112, 6.9112, 170.5573041426782, 2094162.332816554, 2094162.332816554, 413934.5541321251], 
processed observation next is [1.0, 0.6956521739130435, 0.590047393364929, 0.745, 1.0, 1.0, 0.3966678408713456, 1.0, 1.0, 0.3966678408713456, 1.0, 1.0, 0.8331922311118328, 0.0, 0.0, 0.8375144448122397, 0.5817117591157095, 0.5817117591157095, 0.6178127673613808], 
reward next is 0.3822, 
noisyNet noise sample is [array([-0.8720105], dtype=float32), -1.5293223]. 
=============================================
[2019-03-27 08:24:29,702] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[53.95604 ]
 [53.73468 ]
 [52.518753]
 [52.39449 ]
 [52.619186]], R is [[54.16309738]
 [53.98099899]
 [53.82685089]
 [53.59931183]
 [53.3840332 ]].
[2019-03-27 08:24:33,742] A3C_AGENT_WORKER-Thread-2 INFO:Evaluating...
[2019-03-27 08:24:33,744] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:24:33,745] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:24:33,746] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:24:33,748] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:24:33,748] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:24:33,748] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:24:33,749] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:24:33,750] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:24:33,751] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:24:33,752] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:24:33,786] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run80
[2019-03-27 08:24:33,787] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run80
[2019-03-27 08:24:33,787] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run80
[2019-03-27 08:24:33,846] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run80
[2019-03-27 08:24:33,864] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run80
[2019-03-27 08:24:37,613] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:24:37,616] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [19.46298718, 95.51337135, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5210082137374757, 6.9112, 6.9112, 168.912956510431, 461171.6576694575, 461171.6576694575, 154680.1162543187]
[2019-03-27 08:24:37,617] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:24:37,622] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.6462580e-37 0.0000000e+00 9.1983265e-36 6.0397261e-23], sampled 0.5918733193243286
[2019-03-27 08:24:49,019] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:24:49,019] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.0, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5629426204503711, 6.911200000000001, 6.9112, 168.912956510431, 496892.3077179628, 496892.3077179621, 160437.3085194661]
[2019-03-27 08:24:49,020] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:24:49,023] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.5191844e-37 1.9862273e-38 4.6249974e-36 3.0672376e-22], sampled 0.2153713504823742
[2019-03-27 08:24:53,952] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:24:53,955] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.5, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6511216406126374, 6.9112, 6.9112, 168.912956510431, 561635.2414356708, 561635.2414356708, 174277.2819963759]
[2019-03-27 08:24:53,957] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:24:53,959] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.2162977e-37 1.7271659e-38 7.3774295e-36 3.0423467e-22], sampled 0.23783509333843267
[2019-03-27 08:25:01,094] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:25:01,096] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.4, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7164241509703791, 6.9112, 6.9112, 168.912956510431, 612651.0090158818, 612651.0090158818, 185710.3132453074]
[2019-03-27 08:25:01,097] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:25:01,098] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 2.7858674e-37 1.2384584e-37 1.6571150e-36 2.5072413e-20], sampled 0.7972213230699127
[2019-03-27 08:25:21,879] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:25:21,880] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.05, 62.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.98533663658395, 6.9112, 168.9123793987797, 881416.3400512295, 828821.4381699553, 254812.1601790203]
[2019-03-27 08:25:21,881] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:25:21,883] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 9.4503140e-30 1.8681337e-28 8.2019353e-30 7.7070707e-13], sampled 0.9788591702909809
[2019-03-27 08:25:21,884] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 881416.3400512295 W.
[2019-03-27 08:26:00,764] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:26:00,765] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.44382737, 92.70497624833334, 1.0, 2.0, 0.6356939330955533, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 888362.79690658, 888362.7969065793, 207574.7510325]
[2019-03-27 08:26:00,767] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:26:00,770] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9250960e-01 3.6567251e-19 1.6826713e-14 6.3318806e-21 7.4903760e-03], sampled 0.5049860745065899
[2019-03-27 08:26:00,771] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 888362.79690658 W.
[2019-03-27 08:26:07,497] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:26:07,498] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.06693066166666, 53.593105675, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8226251661421967, 6.911200000000001, 6.9112, 168.912956510431, 689322.1021640988, 689322.1021640982, 206558.6153165303]
[2019-03-27 08:26:07,499] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:26:07,503] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.7816742e-36 4.8991699e-37 2.1184083e-35 7.6747711e-20], sampled 0.6214693963506907
[2019-03-27 08:26:11,890] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07604909]
[2019-03-27 08:26:11,891] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.65734949666667, 85.79016844, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6748261909924383, 6.911199999999999, 6.9112, 168.912956510431, 582940.8289291788, 582940.8289291793, 178282.3698128553]
[2019-03-27 08:26:11,892] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:26:11,896] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 6.33628017e-35 1.51754966e-34 1.59277051e-34
 1.23607344e-17], sampled 0.29805384043531913
[2019-03-27 08:26:28,662] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7273.5955 3319231993.6134 2087.0000
[2019-03-27 08:26:29,387] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8089.9807 2938195287.7152 1225.0000
[2019-03-27 08:26:29,882] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7058.0527 3184964525.3061 2252.0000
[2019-03-27 08:26:29,938] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7920.0292 2990141397.1215 1501.0000
[2019-03-27 08:26:29,972] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7400.1534 3105091971.9119 1809.0000
[2019-03-27 08:26:30,989] A3C_AGENT_WORKER-Thread-2 INFO:Global step: 1975000, evaluation results [1975000.0, 7273.595512213795, 3319231993.6133504, 2087.0, 7400.153372040711, 3105091971.911949, 1809.0, 8089.9807130151385, 2938195287.715158, 1225.0, 7058.052686188737, 3184964525.306073, 2252.0, 7920.029166249396, 2990141397.121492, 1501.0]
[2019-03-27 08:26:32,999] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.6553382e-37 5.6865818e-38 5.6206613e-35 4.2902841e-21], sum to 1.0000
[2019-03-27 08:26:33,008] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0474
[2019-03-27 08:26:33,014] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.8, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7353763714021609, 6.9112, 6.9112, 168.912956510431, 625845.1367824596, 625845.1367824596, 189225.6106154411], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2611800.0000, 
sim time next is 2612400.0000, 
raw observation next is [23.76666666666667, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.73220718714058, 6.9112, 6.9112, 168.912956510431, 623238.8685320641, 623238.8685320641, 188629.1622829176], 
processed observation next is [0.0, 0.21739130434782608, 0.32543443917851517, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6734233989519268, 0.0, 0.0, 0.8294399451523027, 0.17312190792557336, 0.17312190792557336, 0.2815360631088322], 
reward next is 0.7185, 
noisyNet noise sample is [array([0.5304426], dtype=float32), 1.4882152]. 
=============================================
[2019-03-27 08:26:37,364] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 5.2156966e-37 5.3846457e-38 5.6009457e-36 6.0950723e-21], sum to 1.0000
[2019-03-27 08:26:37,372] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.8589
[2019-03-27 08:26:37,383] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7901726892606503, 6.911199999999999, 6.9112, 168.912956510431, 663739.5949625361, 663739.5949625368, 199853.1151999281], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2631600.0000, 
sim time next is 2632200.0000, 
raw observation next is [26.16666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7914489902937613, 6.911199999999999, 6.9112, 168.912956510431, 664644.4993947353, 664644.499394736, 200109.5106508911], 
processed observation next is [0.0, 0.4782608695652174, 0.4391785150078992, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7456695003582453, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18462347205409316, 0.18462347205409335, 0.29867091141924046], 
reward next is 0.7013, 
noisyNet noise sample is [array([0.7887438], dtype=float32), -0.7487703]. 
=============================================
[2019-03-27 08:26:46,205] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.3541660e-35 0.0000000e+00 2.4144488e-35 1.7904849e-20], sum to 1.0000
[2019-03-27 08:26:46,213] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5479
[2019-03-27 08:26:46,219] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.03333333333333, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7399117713559703, 6.911199999999999, 6.9112, 168.912956510431, 628352.3139503202, 628352.3139503209, 190072.9263776491], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2605200.0000, 
sim time next is 2605800.0000, 
raw observation next is [24.01666666666667, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7385810561938106, 6.9112, 6.9112, 168.912956510431, 627353.6987812736, 627353.6987812736, 189821.5498862286], 
processed observation next is [0.0, 0.13043478260869565, 0.33728278041074267, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.681196409992452, 0.0, 0.0, 0.8294399451523027, 0.17426491632813154, 0.17426491632813154, 0.2833157460988487], 
reward next is 0.7167, 
noisyNet noise sample is [array([0.8246432], dtype=float32), -0.24367905]. 
=============================================
[2019-03-27 08:26:52,501] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 9.1081025e-36 1.1945785e-34 4.4760419e-34 4.1154813e-17], sum to 1.0000
[2019-03-27 08:26:52,509] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6060
[2019-03-27 08:26:52,518] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5618448417769978, 6.911199999999999, 6.9112, 168.912956510431, 492264.0480448005, 492264.0480448011, 160403.7773475893], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2953800.0000, 
sim time next is 2954400.0000, 
raw observation next is [21.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5681684759815986, 6.9112, 6.9112, 168.912956510431, 497805.83781817, 497805.83781817, 161304.8158893351], 
processed observation next is [1.0, 0.17391304347826086, 0.19431279620853087, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47337619022146166, 0.0, 0.0, 0.8294399451523027, 0.13827939939393613, 0.13827939939393613, 0.24075345655124641], 
reward next is 0.7592, 
noisyNet noise sample is [array([-0.2892241], dtype=float32), 1.313558]. 
=============================================
[2019-03-27 08:26:57,336] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.6603475e-37 2.4828624e-38 4.5301621e-37 3.1115060e-19], sum to 1.0000
[2019-03-27 08:26:57,347] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1375
[2019-03-27 08:26:57,352] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6826372492624418, 6.9112, 6.9112, 168.912956510431, 586936.0112060449, 586936.0112060449, 179655.0908198253], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3099600.0000, 
sim time next is 3100200.0000, 
raw observation next is [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.674218305204624, 6.911199999999999, 6.9112, 168.912956510431, 579883.4486975231, 579883.4486975238, 178193.9350974869], 
processed observation next is [1.0, 0.9130434782608695, 0.2417061611374408, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6027052502495415, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.16107873574931197, 0.16107873574931217, 0.2659610971604282], 
reward next is 0.7340, 
noisyNet noise sample is [array([-0.9044075], dtype=float32), 0.29133254]. 
=============================================
[2019-03-27 08:26:57,637] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.3646210e-27 8.4501565e-24 3.8622532e-28 3.2157281e-09], sum to 1.0000
[2019-03-27 08:26:57,645] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-27 08:26:57,653] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8428593540170305, 6.9112, 6.9112, 168.912956510431, 735760.4571533712, 735760.4571533712, 210945.711478473], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2800800.0000, 
sim time next is 2801400.0000, 
raw observation next is [22.16666666666667, 87.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9617880482869832, 6.9112, 6.9112, 168.912956510431, 840160.1052626594, 840160.1052626594, 238724.5661779365], 
processed observation next is [1.0, 0.43478260869565216, 0.24960505529225935, 0.8716666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9534000588865649, 0.0, 0.0, 0.8294399451523027, 0.23337780701740538, 0.23337780701740538, 0.35630532265363657], 
reward next is 0.6437, 
noisyNet noise sample is [array([-1.3276292], dtype=float32), 0.2696901]. 
=============================================
[2019-03-27 08:27:02,499] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8148945e-03 2.5577741e-21 5.1533332e-17 8.8951672e-24 9.9618512e-01], sum to 1.0000
[2019-03-27 08:27:02,507] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8892
[2019-03-27 08:27:02,512] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.7459382337943845, 1.0, 2.0, 0.6935591564114549, 1.0, 2.0, 1.03, 7.00510135462259, 6.9112, 170.5573041426782, 2910278.461370898, 2843013.101391845, 536230.941631971], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3603000.0000, 
sim time next is 3603600.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.6524383984656812, 1.0, 2.0, 0.6468092387471033, 1.0, 2.0, 1.03, 7.005093982267666, 6.9112, 170.5573041426782, 2713895.691104874, 2646635.612243541, 506726.4501904757], 
processed observation next is [1.0, 0.7391304347826086, 0.7630331753554502, 0.63, 1.0, 1.0, 0.5812510824887726, 1.0, 1.0, 0.5744689623459075, 1.0, 1.0, 1.0365853658536586, 0.009389398226766588, 0.0, 0.8375144448122397, 0.7538599141957983, 0.7351765589565392, 0.7563081346126502], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7107515], dtype=float32), 0.47605166]. 
=============================================
[2019-03-27 08:27:08,525] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 6.2106304e-32 2.3480658e-30 1.2749221e-31 4.4568998e-15], sum to 1.0000
[2019-03-27 08:27:08,535] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4546
[2019-03-27 08:27:08,541] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6729833480930978, 6.9112, 6.9112, 168.912956510431, 583606.3098482878, 583606.3098482878, 177940.3273940858], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3136800.0000, 
sim time next is 3137400.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6877783041488011, 6.9112, 6.9112, 168.912956510431, 596439.9825081596, 596439.9825081596, 180513.43149738], 
processed observation next is [1.0, 0.30434782608695654, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6192418343278062, 0.0, 0.0, 0.8294399451523027, 0.1656777729189332, 0.1656777729189332, 0.2694230320856418], 
reward next is 0.7306, 
noisyNet noise sample is [array([1.0952762], dtype=float32), -0.234337]. 
=============================================
[2019-03-27 08:27:17,010] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0810792e-01 2.7324981e-20 3.1211068e-15 2.0748036e-22 8.9189208e-01], sum to 1.0000
[2019-03-27 08:27:17,018] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3904
[2019-03-27 08:27:17,022] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.0, 94.0, 1.0, 2.0, 0.2562896021133766, 1.0, 2.0, 0.2562896021133766, 1.0, 2.0, 0.438029408530389, 6.911199999999999, 6.9112, 170.5573041426782, 1074559.51684197, 1074559.516841971, 287055.0184560989], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3383400.0000, 
sim time next is 3384000.0000, 
raw observation next is [26.0, 94.0, 1.0, 2.0, 0.2572589998229967, 1.0, 2.0, 0.2572589998229967, 1.0, 2.0, 0.43968393989743, 6.911200000000001, 6.9112, 170.5573041426782, 1078626.008289569, 1078626.008289568, 287394.1583493822], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.94, 1.0, 1.0, 0.10513132508794784, 1.0, 1.0, 0.10513132508794784, 1.0, 1.0, 0.3166877315822317, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2996183356359914, 0.2996183356359911, 0.42894650499907794], 
reward next is 0.5711, 
noisyNet noise sample is [array([1.7640575], dtype=float32), -0.5769934]. 
=============================================
[2019-03-27 08:27:17,035] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[60.879875]
 [60.398617]
 [59.755165]
 [58.312702]
 [57.16744 ]], R is [[61.34508133]
 [61.30319214]
 [61.26047516]
 [60.64786911]
 [60.63708115]].
[2019-03-27 08:27:24,838] A3C_AGENT_WORKER-Thread-19 INFO:Evaluating...
[2019-03-27 08:27:24,840] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:27:24,841] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:27:24,841] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:27:24,841] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:27:24,842] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:27:24,843] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:27:24,843] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:27:24,845] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:27:24,843] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:27:24,848] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:27:25,829] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run81
[2019-03-27 08:27:25,845] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run81
[2019-03-27 08:27:25,863] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run81
[2019-03-27 08:27:25,864] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run81
[2019-03-27 08:27:25,864] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run81
[2019-03-27 08:28:07,547] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:28:07,551] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 92.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.053765519641043, 6.9112, 168.9121064017339, 995945.7673088515, 894805.3899729806, 256519.9585843116]
[2019-03-27 08:28:07,553] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:28:07,557] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.1475082e-24 1.2056055e-21 4.6658697e-25 3.7591818e-08], sampled 0.31208892652186815
[2019-03-27 08:28:07,558] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 995945.7673088515 W.
[2019-03-27 08:28:13,534] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:28:13,535] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [35.6, 53.0, 1.0, 2.0, 0.598538706863003, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.921938420493285, 6.9112, 168.912287299872, 1673497.320517027, 1665879.14561349, 364308.3493895169]
[2019-03-27 08:28:13,535] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:28:13,539] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9920076e-01 3.8851474e-21 5.8249910e-18 1.8730375e-22 7.9921226e-04], sampled 0.8320780851556522
[2019-03-27 08:28:13,540] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1673497.320517027 W.
[2019-03-27 08:28:22,596] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:28:22,597] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [34.866153125, 72.97690412, 1.0, 2.0, 0.7181935817550655, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1003708.008720336, 1003708.008720336, 224835.3797933751]
[2019-03-27 08:28:22,599] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:28:22,601] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9998915e-01 6.3643778e-22 4.1240917e-19 5.8615041e-23 1.0898931e-05], sampled 0.5760407875442648
[2019-03-27 08:28:22,605] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1003708.008720336 W.
[2019-03-27 08:28:41,289] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:28:41,292] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [29.23333333333333, 84.0, 1.0, 1.0, 0.6120239428276495, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128627280736, 855271.3924678591, 855271.3924678598, 203005.9416275416]
[2019-03-27 08:28:41,293] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:28:41,297] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9999976e-01 1.0100919e-20 3.6629644e-19 3.5466895e-21 2.0051058e-07], sampled 0.6263574980137631
[2019-03-27 08:28:46,502] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:28:46,504] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [37.07245482, 53.28210705, 1.0, 2.0, 0.3638040472659231, 1.0, 1.0, 0.3638040472659231, 1.0, 1.0, 0.6318073182640048, 6.911200000000001, 6.9112, 184.5923449428631, 1525579.464506767, 1525579.464506767, 337850.1445821844]
[2019-03-27 08:28:46,505] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:28:46,507] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.8294097e-01 5.2953418e-20 2.4282762e-16 1.2087346e-21 1.7059080e-02], sampled 0.6018695546354907
[2019-03-27 08:28:46,507] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1525579.464506767 W.
[2019-03-27 08:29:00,059] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:29:00,059] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666666, 82.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8966310770800667, 6.911199999999999, 6.9112, 168.912956510431, 738923.0824663937, 738923.0824663943, 222601.2586339726]
[2019-03-27 08:29:00,060] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:29:00,063] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.000000e+00 6.421075e-36 1.279445e-36 2.446453e-35 1.189164e-18], sampled 0.3319782069292647
[2019-03-27 08:29:07,959] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:29:07,961] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.1, 69.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 7.0712269476476, 6.9112, 168.9119305743863, 942373.1493460916, 828845.2145275458, 254812.5518890207]
[2019-03-27 08:29:07,963] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:29:07,967] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9983549e-01 7.6454288e-20 8.7690866e-17 9.6492517e-21 1.6454107e-04], sampled 0.4602356688007577
[2019-03-27 08:29:07,968] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 942373.1493460916 W.
[2019-03-27 08:29:21,526] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07535234]
[2019-03-27 08:29:21,529] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.43333333333334, 61.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5816656499299354, 6.9112, 6.9112, 168.912956510431, 510643.6042533359, 510643.6042533359, 163234.7068980014]
[2019-03-27 08:29:21,530] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:29:21,533] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.5093172e-36 6.8108594e-37 3.6776925e-35 1.2261536e-19], sampled 0.33506671834673496
[2019-03-27 08:29:22,303] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8115.7420 2947408340.3757 1051.0000
[2019-03-27 08:29:22,428] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7921.8886 2998676267.6797 1295.0000
[2019-03-27 08:29:22,757] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7327.7609 3325913254.0665 1812.0000
[2019-03-27 08:29:22,768] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7452.5269 3110135117.0583 1594.0000
[2019-03-27 08:29:22,971] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7094.4197 3191893146.5685 1989.0000
[2019-03-27 08:29:23,991] A3C_AGENT_WORKER-Thread-19 INFO:Global step: 2000000, evaluation results [2000000.0, 7327.760869466825, 3325913254.066477, 1812.0, 7452.526857705199, 3110135117.0582805, 1594.0, 8115.741992420801, 2947408340.3756914, 1051.0, 7094.419723230894, 3191893146.568505, 1989.0, 7921.888633296453, 2998676267.6796975, 1295.0]
[2019-03-27 08:29:25,265] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.2988073e-33 9.3732688e-37 7.4984513e-33 8.8875523e-20], sum to 1.0000
[2019-03-27 08:29:25,277] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8953
[2019-03-27 08:29:25,282] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7249548925321353, 6.911200000000001, 6.9112, 168.912956510431, 617734.3940748498, 617734.3940748491, 187277.5678328078], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3300600.0000, 
sim time next is 3301200.0000, 
raw observation next is [25.0, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7236516179871489, 6.9112, 6.9112, 168.912956510431, 616625.1432517284, 616625.1432517284, 187035.3388817623], 
processed observation next is [0.0, 0.21739130434782608, 0.38388625592417064, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6629897780331083, 0.0, 0.0, 0.8294399451523027, 0.17128476201436899, 0.17128476201436899, 0.2791572222115855], 
reward next is 0.7208, 
noisyNet noise sample is [array([0.61033815], dtype=float32), 0.55441326]. 
=============================================
[2019-03-27 08:29:28,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.1991023e-35 2.9399618e-36 5.6845736e-35 3.4740881e-20], sum to 1.0000
[2019-03-27 08:29:28,679] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6239
[2019-03-27 08:29:28,689] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8864458202326678, 6.911199999999999, 6.9112, 168.912956510431, 731026.848608408, 731026.8486084086, 220277.875611086], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3358800.0000, 
sim time next is 3359400.0000, 
raw observation next is [27.83333333333334, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8865274683763528, 6.9112, 6.9112, 168.912956510431, 731452.9336891326, 731452.9336891326, 220310.0646848565], 
processed observation next is [0.0, 0.9130434782608695, 0.5181674565560824, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8616188638736008, 0.0, 0.0, 0.8294399451523027, 0.20318137046920348, 0.20318137046920348, 0.32882099206695004], 
reward next is 0.6712, 
noisyNet noise sample is [array([0.7443999], dtype=float32), 0.8879751]. 
=============================================
[2019-03-27 08:29:36,486] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.2245032e-38 0.0000000e+00 3.3322884e-37 1.0050504e-18], sum to 1.0000
[2019-03-27 08:29:36,495] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9925
[2019-03-27 08:29:36,501] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 79.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9495784917694055, 6.9112, 6.9112, 168.912956510431, 772680.1891066232, 772680.1891066232, 234785.1483939911], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3528600.0000, 
sim time next is 3529200.0000, 
raw observation next is [29.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9458590523911372, 6.911200000000001, 6.9112, 168.912956510431, 769763.8218755071, 769763.8218755065, 233882.0725955374], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9339744541355331, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21382328385430754, 0.21382328385430738, 0.34907772029184686], 
reward next is 0.6509, 
noisyNet noise sample is [array([-0.12431003], dtype=float32), 0.987431]. 
=============================================
[2019-03-27 08:29:37,989] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.7390107e-34 7.6255392e-35 2.7037681e-33 1.3457946e-17], sum to 1.0000
[2019-03-27 08:29:37,997] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8393
[2019-03-27 08:29:38,001] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.66666666666666, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9658905053340293, 6.9112, 6.9112, 168.912956510431, 783898.3120010134, 783898.3120010134, 238709.1601364341], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3829800.0000, 
sim time next is 3830400.0000, 
raw observation next is [30.0, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9705435945483786, 6.9112, 6.9112, 168.912956510431, 786678.5443708338, 786678.5443708338, 239818.4120397762], 
processed observation next is [0.0, 0.34782608695652173, 0.6208530805687204, 0.75, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9640775543272908, 0.0, 0.0, 0.8294399451523027, 0.21852181788078717, 0.21852181788078717, 0.3579379284175764], 
reward next is 0.6421, 
noisyNet noise sample is [array([0.41164988], dtype=float32), -0.12840943]. 
=============================================
[2019-03-27 08:29:38,082] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.9263752e-32 4.5531485e-31 1.3408042e-31 1.5412339e-14], sum to 1.0000
[2019-03-27 08:29:38,089] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1580
[2019-03-27 08:29:38,094] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891851485928911, 6.911199999999999, 6.9112, 168.912956510431, 735356.7785158864, 735356.7785158871, 221512.872858764], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3619800.0000, 
sim time next is 3620400.0000, 
raw observation next is [28.33333333333333, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8916795291087476, 6.911199999999999, 6.9112, 168.912956510431, 735516.8935091477, 735516.8935091484, 221484.6687298602], 
processed observation next is [1.0, 0.9130434782608695, 0.541864139020537, 0.7733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8679018647667653, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20431024819698546, 0.20431024819698565, 0.3305741324326272], 
reward next is 0.6694, 
noisyNet noise sample is [array([-0.54387933], dtype=float32), -0.5735426]. 
=============================================
[2019-03-27 08:29:38,723] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 8.3544838e-31 3.3410082e-29 3.2267452e-31 3.4640995e-11], sum to 1.0000
[2019-03-27 08:29:38,737] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4087
[2019-03-27 08:29:38,745] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8777360071154697, 6.911199999999999, 6.9112, 168.912956510431, 724932.3796360098, 724932.3796360104, 218336.925618154], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3540000.0000, 
sim time next is 3540600.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8785040875910415, 6.9112, 6.9112, 168.912956510431, 725567.0093477033, 725567.0093477033, 218510.865751934], 
processed observation next is [1.0, 1.0, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8518342531598067, 0.0, 0.0, 0.8294399451523027, 0.20154639148547315, 0.20154639148547315, 0.3261356205252746], 
reward next is 0.6739, 
noisyNet noise sample is [array([-2.4185822], dtype=float32), -0.24440706]. 
=============================================
[2019-03-27 08:30:00,454] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 4.1359505e-35 6.1484324e-36 5.0513977e-34 2.5454911e-20], sum to 1.0000
[2019-03-27 08:30:00,466] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0976
[2019-03-27 08:30:00,470] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.16666666666667, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.964048432375662, 6.9112, 168.9124792157122, 866307.9362401863, 828815.5453521907, 254811.9795968772], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3913800.0000, 
sim time next is 3914400.0000, 
raw observation next is [29.33333333333334, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.011494194632213, 6.9112, 168.9121568937194, 899980.4958912109, 828828.6791863792, 254812.0190733683], 
processed observation next is [0.0, 0.30434782608695654, 0.5892575039494474, 0.8233333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.010029419463221334, 0.0, 0.8294360186681826, 0.24999458219200302, 0.2302301886628831, 0.38031644637816164], 
reward next is 0.1182, 
noisyNet noise sample is [array([-0.8053566], dtype=float32), -0.41465327]. 
=============================================
[2019-03-27 08:30:01,251] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 2.3637493e-29 7.9433090e-31 4.0490405e-29 3.2449121e-14], sum to 1.0000
[2019-03-27 08:30:01,260] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8735
[2019-03-27 08:30:01,269] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 918442.7261091601 W.
[2019-03-27 08:30:01,274] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.83333333333334, 60.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.037508139276663, 6.9112, 168.9120224929382, 918442.7261091601, 828835.8804064885, 254812.5212457373], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3930600.0000, 
sim time next is 3931200.0000, 
raw observation next is [34.0, 60.0, 1.0, 1.0, 0.3044461464543347, 1.0, 1.0, 0.3044461464543347, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 850890.0365934537, 850890.0365934537, 250753.3237417988], 
processed observation next is [0.0, 0.5217391304347826, 0.8104265402843602, 0.6, 1.0, 0.5, 0.16198330898112615, 1.0, 0.5, 0.16198330898112615, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.23635834349818158, 0.23635834349818158, 0.3742586921519385], 
reward next is 0.6257, 
noisyNet noise sample is [array([0.44590494], dtype=float32), 1.4144566]. 
=============================================
[2019-03-27 08:30:01,480] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 5.8175840e-34 4.5183271e-35 2.1513602e-33 5.2834699e-19], sum to 1.0000
[2019-03-27 08:30:01,489] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5329
[2019-03-27 08:30:01,495] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8651022886132279, 6.9112, 6.9112, 168.912956510431, 716860.9702976164, 716860.9702976164, 215580.343637255], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4519800.0000, 
sim time next is 4520400.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8657789520951605, 6.911199999999999, 6.9112, 168.912956510431, 717415.7373815287, 717415.7373815293, 215731.1732976086], 
processed observation next is [0.0, 0.30434782608695654, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8363157952380005, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19928214927264687, 0.19928214927264704, 0.32198682581732624], 
reward next is 0.6780, 
noisyNet noise sample is [array([0.82900935], dtype=float32), -0.2827064]. 
=============================================
[2019-03-27 08:30:05,036] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9998248e-01 1.4599717e-20 1.3612814e-17 1.7140366e-21 1.7572855e-05], sum to 1.0000
[2019-03-27 08:30:05,042] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6467
[2019-03-27 08:30:05,044] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 897692.7597030478 W.
[2019-03-27 08:30:05,054] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 71.0, 1.0, 2.0, 0.3211837200151928, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5577899045870888, 6.911200000000001, 6.9112, 168.912956510431, 897692.7597030478, 897692.7597030471, 229034.0011163757], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4449600.0000, 
sim time next is 4450200.0000, 
raw observation next is [33.0, 70.33333333333334, 1.0, 2.0, 0.2240091620118901, 1.0, 1.0, 0.2240091620118901, 1.0, 2.0, 0.3890298334527523, 6.911200000000001, 6.9112, 170.5573041426782, 939156.2704760096, 939156.2704760089, 276887.8674570537], 
processed observation next is [0.0, 0.5217391304347826, 0.7630331753554502, 0.7033333333333335, 1.0, 1.0, 0.06507127953239772, 1.0, 0.5, 0.06507127953239772, 1.0, 1.0, 0.2549144310399418, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.26087674179889153, 0.26087674179889137, 0.41326547381649803], 
reward next is 0.5867, 
noisyNet noise sample is [array([0.21925706], dtype=float32), -0.707674]. 
=============================================
[2019-03-27 08:30:10,417] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.0194562e-06 4.8005671e-18 5.5283923e-14 3.0914211e-21 9.9999094e-01], sum to 1.0000
[2019-03-27 08:30:10,424] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.0464
[2019-03-27 08:30:10,430] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666666, 73.66666666666666, 1.0, 2.0, 0.6743509657597992, 1.0, 2.0, 0.6577655223941622, 1.0, 2.0, 1.03, 7.005095709840664, 6.9112, 170.5573041426782, 2759917.073787845, 2692655.7573957, 513350.5659226681], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4099200.0000, 
sim time next is 4099800.0000, 
raw observation next is [31.83333333333333, 72.33333333333334, 1.0, 2.0, 0.7193595522805154, 1.0, 2.0, 0.6802698156545203, 1.0, 2.0, 1.03, 7.005099258688313, 6.9112, 170.5573041426782, 2854450.675718813, 2787186.817142739, 527514.0847932287], 
processed observation next is [1.0, 0.43478260869565216, 0.7077409162717218, 0.7233333333333334, 1.0, 1.0, 0.6618789786512234, 1.0, 1.0, 0.6147829104271328, 1.0, 1.0, 1.0365853658536586, 0.009389925868831295, 0.0, 0.8375144448122397, 0.7929029654774481, 0.7742185603174275, 0.7873344549152667], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.70368505], dtype=float32), -1.8336563]. 
=============================================
[2019-03-27 08:30:17,443] A3C_AGENT_WORKER-Thread-10 INFO:Evaluating...
[2019-03-27 08:30:17,444] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:30:17,444] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:30:17,444] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:30:17,445] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:30:17,447] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:30:17,447] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:30:17,448] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:30:17,449] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:30:17,450] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:30:17,451] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:30:17,471] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run82
[2019-03-27 08:30:17,472] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run82
[2019-03-27 08:30:17,505] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run82
[2019-03-27 08:30:17,523] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run82
[2019-03-27 08:30:17,523] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run82
[2019-03-27 08:30:40,872] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:30:40,874] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.539509735, 50.3563431, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5629731569449963, 6.9112, 6.9112, 168.912956510431, 495186.1869497689, 495186.1869497689, 160505.2493917179]
[2019-03-27 08:30:40,875] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:30:40,877] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.00000000e+00 1.06826619e-36 0.00000000e+00 1.16349626e-35
 1.58184992e-23], sampled 0.5480896755327824
[2019-03-27 08:30:44,315] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:30:44,317] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.0, 93.33333333333334, 1.0, 2.0, 0.5371679581402509, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 851030.6025076078, 851030.6025076078, 201084.4899458382]
[2019-03-27 08:30:44,320] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:30:44,323] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 6.3366846e-22 1.8154786e-20 1.5955411e-22 8.0531554e-10], sampled 0.006168510399017557
[2019-03-27 08:30:55,930] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:30:55,932] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8394340960661334, 6.911199999999999, 6.9112, 168.912956510431, 699274.8109756333, 699274.8109756339, 210054.7752324721]
[2019-03-27 08:30:55,933] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:30:55,937] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.0988140e-35 5.4225560e-37 4.1162127e-35 3.4211670e-20], sampled 0.5834261946598781
[2019-03-27 08:31:17,431] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:31:17,431] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 89.0, 1.0, 2.0, 0.6942198967193144, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 970188.3955506242, 970188.3955506242, 219602.7209451234]
[2019-03-27 08:31:17,433] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:31:17,436] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [5.4236954e-01 1.3662400e-15 3.1858247e-12 6.6985640e-18 4.5763046e-01], sampled 0.5225581831244055
[2019-03-27 08:31:17,439] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 970188.3955506242 W.
[2019-03-27 08:31:34,710] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:31:34,711] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.04151471666667, 73.96435619333333, 1.0, 2.0, 0.7147764820915357, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 998930.2113684318, 998930.2113684318, 224064.1367505404]
[2019-03-27 08:31:34,713] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:31:34,715] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999630e-01 1.4714161e-18 1.2113619e-16 9.9996759e-20 3.6381914e-06], sampled 0.84828504023983
[2019-03-27 08:31:34,718] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 998930.2113684318 W.
[2019-03-27 08:31:35,941] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:31:35,942] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [29.68256891666667, 96.58195191833335, 1.0, 2.0, 0.6287700612886594, 1.0, 2.0, 0.6287700612886594, 1.0, 2.0, 1.03, 6.975560385780556, 6.9112, 184.5923449428631, 2637914.883536463, 2588017.058499291, 502852.6987177326]
[2019-03-27 08:31:35,944] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:31:35,946] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [4.2845444e-03 3.5039026e-15 1.9792766e-11 7.3902690e-18 9.9571544e-01], sampled 0.3195070339881684
[2019-03-27 08:32:00,071] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:32:00,074] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.86872875333333, 73.86483240333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6421871068365516, 6.9112, 6.9112, 168.912956510431, 556073.6585905659, 556073.6585905659, 172784.3361358782]
[2019-03-27 08:32:00,075] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:32:00,078] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 1.11946135e-35 0.00000000e+00 1.40632299e-34
 1.77227053e-23], sampled 0.2866928061028755
[2019-03-27 08:32:12,126] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07134883]
[2019-03-27 08:32:12,130] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [25.1, 64.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5681983254018609, 6.911200000000001, 6.9112, 168.912956510431, 498251.1328497003, 498251.1328496996, 161297.4403095579]
[2019-03-27 08:32:12,131] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:32:12,133] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.0988649e-35 1.3301166e-38 1.6535300e-34 1.7522178e-23], sampled 0.019440849026399087
[2019-03-27 08:32:13,562] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7327.1903 3324356951.9213 1845.0000
[2019-03-27 08:32:14,051] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7436.6164 3110016648.3443 1630.0000
[2019-03-27 08:32:14,155] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7093.6127 3190969595.1186 2082.0000
[2019-03-27 08:32:14,287] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8119.6517 2945641867.7051 1066.0000
[2019-03-27 08:32:14,320] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7916.8138 2997579275.2356 1352.0000
[2019-03-27 08:32:15,338] A3C_AGENT_WORKER-Thread-10 INFO:Global step: 2025000, evaluation results [2025000.0, 7327.190309307891, 3324356951.921332, 1845.0, 7436.616416840516, 3110016648.3442545, 1630.0, 8119.651705766004, 2945641867.705051, 1066.0, 7093.612745605856, 3190969595.1186104, 2082.0, 7916.813801663689, 2997579275.2355804, 1352.0]
[2019-03-27 08:32:27,031] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0108003e-37 0.0000000e+00 2.1039031e-36 6.1743717e-24], sum to 1.0000
[2019-03-27 08:32:27,038] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1912
[2019-03-27 08:32:27,041] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.0, 51.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9001195203203345, 6.9112, 6.9112, 168.912956510431, 738152.332860504, 738152.332860504, 223263.3941624866], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4545000.0000, 
sim time next is 4545600.0000, 
raw observation next is [34.0, 52.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9074075412875995, 6.9112, 6.9112, 168.912956510431, 742972.9739560018, 742972.9739560018, 224911.732739799], 
processed observation next is [0.0, 0.6086956521739131, 0.8104265402843602, 0.52, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8870823674239018, 0.0, 0.0, 0.8294399451523027, 0.20638138165444495, 0.20638138165444495, 0.33568915334298355], 
reward next is 0.6643, 
noisyNet noise sample is [array([-0.4234166], dtype=float32), 0.71642995]. 
=============================================
[2019-03-27 08:32:28,863] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999309e-01 1.0714100e-20 7.3111284e-19 1.2701916e-21 6.8595091e-06], sum to 1.0000
[2019-03-27 08:32:28,869] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1732
[2019-03-27 08:32:28,874] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1204921.269443442 W.
[2019-03-27 08:32:28,882] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.33333333333334, 82.33333333333334, 1.0, 2.0, 0.4310440744057906, 0.0, 2.0, 0.0, 1.0, 2.0, 0.739568107972812, 6.911199999999999, 6.9112, 168.912956510431, 1204921.269443442, 1204921.269443443, 272078.9746659427], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4692000.0000, 
sim time next is 4692600.0000, 
raw observation next is [28.5, 81.5, 1.0, 2.0, 0.4323155777909212, 1.0, 1.0, 0.4323155777909212, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1208470.965287689, 1208470.965287689, 280576.6567387031], 
processed observation next is [1.0, 0.30434782608695654, 0.5497630331753555, 0.815, 1.0, 1.0, 0.31604286480833876, 1.0, 0.5, 0.31604286480833876, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.33568637924658024, 0.33568637924658024, 0.41877112946075085], 
reward next is 0.5812, 
noisyNet noise sample is [array([0.7606235], dtype=float32), 1.7933176]. 
=============================================
[2019-03-27 08:32:29,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5034205e-26], sum to 1.0000
[2019-03-27 08:32:29,235] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9434
[2019-03-27 08:32:29,244] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 82.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8485817923747239, 6.9112, 6.9112, 168.912956510431, 706588.3305639104, 706588.3305639104, 212037.0613730939], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5182800.0000, 
sim time next is 5183400.0000, 
raw observation next is [27.0, 83.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8558079716225674, 6.9112, 6.9112, 168.912956510431, 711383.3171582368, 711383.3171582368, 213589.1541899505], 
processed observation next is [0.0, 1.0, 0.4786729857819906, 0.8316666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8241560629543504, 0.0, 0.0, 0.8294399451523027, 0.1976064769883991, 0.1976064769883991, 0.31878978237306044], 
reward next is 0.6812, 
noisyNet noise sample is [array([-0.65620697], dtype=float32), -0.017737603]. 
=============================================
[2019-03-27 08:32:35,718] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6265748e-29], sum to 1.0000
[2019-03-27 08:32:35,726] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5823
[2019-03-27 08:32:35,730] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8285191063793423, 6.911200000000001, 6.9112, 168.912956510431, 690549.6347464543, 690549.6347464537, 207719.1527892686], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5029200.0000, 
sim time next is 5029800.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8333827131185261, 6.911199999999999, 6.9112, 168.912956510431, 693679.6201163708, 693679.6201163714, 208734.3486673482], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7968081867299098, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19268878336565856, 0.19268878336565873, 0.31154380398111675], 
reward next is 0.6885, 
noisyNet noise sample is [array([-1.4073812], dtype=float32), 0.07038643]. 
=============================================
[2019-03-27 08:32:41,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7866255e-27], sum to 1.0000
[2019-03-27 08:32:41,698] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5196
[2019-03-27 08:32:41,703] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 66.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.912601289725384, 6.9112, 168.9127160158547, 829795.4262952477, 828801.304550801, 254811.8388944024], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5141400.0000, 
sim time next is 5142000.0000, 
raw observation next is [32.0, 65.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.992650097702112, 6.911200000000001, 6.9112, 168.91295536944, 799432.5994167296, 799432.5994167291, 245124.9883573811], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.6566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9910367045147708, 8.881784197001253e-17, 0.0, 0.8294399395495146, 0.22206461094909158, 0.2220646109490914, 0.3658581915781808], 
reward next is 0.6341, 
noisyNet noise sample is [array([0.7606449], dtype=float32), 0.4986537]. 
=============================================
[2019-03-27 08:32:41,711] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.03963 ]
 [63.218086]
 [63.220417]
 [63.308895]
 [63.396816]], R is [[63.11505127]
 [63.09658051]
 [63.10253525]
 [63.11590576]
 [63.13611603]].
[2019-03-27 08:32:43,795] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.3378098e-02 1.7169370e-16 3.3426014e-14 1.6118658e-18 9.4662189e-01], sum to 1.0000
[2019-03-27 08:32:43,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7921
[2019-03-27 08:32:43,810] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.66666666666667, 68.0, 1.0, 2.0, 0.6020316328079158, 1.0, 2.0, 0.6020316328079158, 1.0, 2.0, 1.03, 6.928657963756848, 6.9112, 170.5573041426782, 2525826.966950573, 2513321.11736698, 488716.1610345613], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4724400.0000, 
sim time next is 4725000.0000, 
raw observation next is [31.5, 68.5, 1.0, 2.0, 0.5798254869801435, 1.0, 2.0, 0.5798254869801435, 1.0, 2.0, 1.006965119665834, 6.9112, 6.9112, 170.5573041426782, 2432570.275467234, 2432570.275467234, 474735.0576100307], 
processed observation next is [1.0, 0.6956521739130435, 0.6919431279620853, 0.685, 1.0, 1.0, 0.49376564696402825, 1.0, 1.0, 0.49376564696402825, 1.0, 1.0, 1.0084940483729683, 0.0, 0.0, 0.8375144448122397, 0.675713965407565, 0.675713965407565, 0.7085597874776578], 
reward next is 0.2914, 
noisyNet noise sample is [array([0.72579306], dtype=float32), -0.19550787]. 
=============================================
[2019-03-27 08:32:43,825] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[24.955524]
 [24.642738]
 [23.889065]
 [24.495419]
 [24.303268]], R is [[25.52584457]
 [25.45386887]
 [25.42897797]
 [25.17468834]
 [25.19281197]].
[2019-03-27 08:32:46,547] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.2346072e-04 1.4638453e-17 5.8541225e-14 2.6408672e-20 9.9987650e-01], sum to 1.0000
[2019-03-27 08:32:46,560] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.9627
[2019-03-27 08:32:46,566] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.46666666666667, 68.66666666666667, 1.0, 2.0, 0.7302239764730425, 1.0, 2.0, 0.6857020277507837, 1.0, 2.0, 1.03, 7.005100115409428, 6.9112, 170.5573041426782, 2877270.796842796, 2810006.324562538, 531046.7218401774], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5478600.0000, 
sim time next is 5479200.0000, 
raw observation next is [33.7, 68.0, 1.0, 2.0, 0.7081941987514976, 1.0, 2.0, 0.6746871388900113, 1.0, 2.0, 1.03, 7.005098378269816, 6.9112, 170.5573041426782, 2830998.903553504, 2763735.675657014, 523931.3938938551], 
processed observation next is [1.0, 0.43478260869565216, 0.7962085308056873, 0.68, 1.0, 1.0, 0.648426745483732, 1.0, 1.0, 0.6080567938433871, 1.0, 1.0, 1.0365853658536586, 0.009389837826981573, 0.0, 0.8375144448122397, 0.7863885843204178, 0.7677043543491705, 0.7819871550654554], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.7357609], dtype=float32), -0.66861933]. 
=============================================
[2019-03-27 08:32:47,512] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4405743e-26], sum to 1.0000
[2019-03-27 08:32:47,523] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6525
[2019-03-27 08:32:47,529] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.33333333333334, 72.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8968194483721684, 6.9112, 6.9112, 168.912956510431, 737324.5093424115, 737324.5093424115, 222576.1168663561], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5078400.0000, 
sim time next is 5079000.0000, 
raw observation next is [29.16666666666667, 73.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.894054990563967, 6.9112, 6.9112, 168.912956510431, 735575.9358176247, 735575.9358176247, 221958.7114802216], 
processed observation next is [0.0, 0.782608695652174, 0.581358609794629, 0.7333333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8707987689804475, 0.0, 0.0, 0.8294399451523027, 0.20432664883822907, 0.20432664883822907, 0.3312816589257039], 
reward next is 0.6687, 
noisyNet noise sample is [array([-0.8855964], dtype=float32), -0.3624267]. 
=============================================
[2019-03-27 08:32:47,537] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[67.71161]
 [67.65369]
 [67.62953]
 [67.57615]
 [67.47499]], R is [[67.76564789]
 [67.75578308]
 [67.74501801]
 [67.73355103]
 [67.72291565]].
[2019-03-27 08:32:52,979] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [3.9952609e-01 6.5358816e-17 3.7646898e-14 1.2644058e-19 6.0047394e-01], sum to 1.0000
[2019-03-27 08:32:52,986] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0775
[2019-03-27 08:32:52,987] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1858884.49889493 W.
[2019-03-27 08:32:52,991] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.4431942620176247, 1.0, 2.0, 0.4431942620176247, 1.0, 2.0, 0.7671025950735506, 6.9112, 6.9112, 170.5573041426782, 1858884.49889493, 1858884.49889493, 377682.0487987492], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4882800.0000, 
sim time next is 4883400.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 0.6361524051085886, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.982592619461792, 6.9112, 168.9125064297992, 1778752.292337923, 1728104.045903626, 371944.2634450931], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.66, 1.0, 1.0, 0.5616294037452875, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.007139261946179243, 0.0, 0.8294377350503528, 0.49409785898275643, 0.4800289016398961, 0.5551406917090942], 
reward next is 0.0879, 
noisyNet noise sample is [array([0.17123991], dtype=float32), -0.14047854]. 
=============================================
[2019-03-27 08:32:53,193] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9397731e-01 3.9101750e-19 5.0975952e-18 2.1019330e-21 6.0226507e-03], sum to 1.0000
[2019-03-27 08:32:53,203] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0789
[2019-03-27 08:32:53,213] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2304247.908017979 W.
[2019-03-27 08:32:53,217] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.33333333333334, 65.0, 1.0, 2.0, 0.5492668448858351, 1.0, 1.0, 0.5492668448858351, 1.0, 2.0, 0.9523067340723103, 6.911199999999999, 6.9112, 170.5573041426782, 2304247.908017979, 2304247.908017979, 450569.1398614065], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4886400.0000, 
sim time next is 4887000.0000, 
raw observation next is [31.5, 64.5, 1.0, 2.0, 0.8489487666956105, 1.0, 2.0, 0.8489487666956105, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2374368.996958924, 2374368.996958924, 444402.7406387767], 
processed observation next is [1.0, 0.5652173913043478, 0.6919431279620853, 0.645, 1.0, 1.0, 0.818010562283868, 1.0, 1.0, 0.818010562283868, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6595469435997011, 0.6595469435997011, 0.6632876725951891], 
reward next is 0.3367, 
noisyNet noise sample is [array([-0.2846059], dtype=float32), 0.21582475]. 
=============================================
[2019-03-27 08:32:53,233] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[26.443281]
 [27.788443]
 [29.631796]
 [30.783329]
 [31.018267]], R is [[25.94681931]
 [26.01486015]
 [25.75471115]
 [25.50259209]
 [25.24756622]].
[2019-03-27 08:32:53,980] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [3.0362552e-01 3.2837588e-17 5.7256886e-15 1.5305465e-19 6.9637448e-01], sum to 1.0000
[2019-03-27 08:32:53,987] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5759
[2019-03-27 08:32:53,991] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.76666666666667, 63.16666666666666, 1.0, 2.0, 0.5151449221947716, 1.0, 2.0, 0.5151449221947716, 1.0, 2.0, 0.883075080352527, 6.911199999999999, 6.9112, 170.5573041426782, 2160970.677510893, 2160970.677510893, 423604.9771053239], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4978200.0000, 
sim time next is 4978800.0000, 
raw observation next is [30.8, 63.0, 1.0, 2.0, 0.5299491741217663, 1.0, 2.0, 0.5299491741217663, 1.0, 2.0, 0.9086162108109108, 6.9112, 6.9112, 170.5573041426782, 2223135.614770486, 2223135.614770486, 434200.3929136576], 
processed observation next is [1.0, 0.6521739130434783, 0.6587677725118484, 0.63, 1.0, 1.0, 0.43367370376116426, 1.0, 1.0, 0.43367370376116426, 1.0, 1.0, 0.8885563546474522, 0.0, 0.0, 0.8375144448122397, 0.6175376707695794, 0.6175376707695794, 0.6480602879308323], 
reward next is 0.3519, 
noisyNet noise sample is [array([-0.2148933], dtype=float32), -0.13559449]. 
=============================================
[2019-03-27 08:32:55,469] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5894816e-38 8.7050878e-27], sum to 1.0000
[2019-03-27 08:32:55,480] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1910
[2019-03-27 08:32:55,484] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.75, 85.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8525588351227946, 6.9112, 6.9112, 168.912956510431, 707472.9337201746, 707472.9337201746, 212835.62421882], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5638200.0000, 
sim time next is 5638800.0000, 
raw observation next is [26.90000000000001, 84.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8554907738482034, 6.9112, 6.9112, 168.912956510431, 709590.0336350915, 709590.0336350915, 213471.060034466], 
processed observation next is [0.0, 0.2608695652173913, 0.4739336492891, 0.8433333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.823769236400248, 0.0, 0.0, 0.8294399451523027, 0.1971083426764143, 0.1971083426764143, 0.3186135224395015], 
reward next is 0.6814, 
noisyNet noise sample is [array([-1.018465], dtype=float32), -0.16255264]. 
=============================================
[2019-03-27 08:33:00,537] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 1.380372e-38 5.400745e-26], sum to 1.0000
[2019-03-27 08:33:00,548] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9677
[2019-03-27 08:33:00,552] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8269545034340698, 6.9112, 6.9112, 168.912956510431, 690783.4200185259, 690783.4200185259, 207426.6508542708], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5001600.0000, 
sim time next is 5002200.0000, 
raw observation next is [27.0, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8336743009758204, 6.9112, 6.9112, 168.912956510431, 695333.028532831, 695333.028532831, 208836.7148114491], 
processed observation next is [1.0, 0.9130434782608695, 0.4786729857819906, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7971637816778296, 0.0, 0.0, 0.8294399451523027, 0.19314806348134195, 0.19314806348134195, 0.31169658927081956], 
reward next is 0.6883, 
noisyNet noise sample is [array([-0.05594397], dtype=float32), 0.5433385]. 
=============================================
[2019-03-27 08:33:01,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5677467e-28], sum to 1.0000
[2019-03-27 08:33:01,107] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0807
[2019-03-27 08:33:01,112] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.5, 64.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8622041284106962, 6.9112, 6.9112, 168.912956510431, 713018.6215941465, 713018.6215941465, 214886.0404100509], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5049000.0000, 
sim time next is 5049600.0000, 
raw observation next is [30.66666666666666, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8666421691131913, 6.911199999999999, 6.9112, 168.912956510431, 716029.1678607106, 716029.1678607112, 215851.7565001187], 
processed observation next is [0.0, 0.43478260869565216, 0.6524486571879934, 0.64, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8373684989185258, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19889699107241962, 0.1988969910724198, 0.3221668007464458], 
reward next is 0.6778, 
noisyNet noise sample is [array([-0.5963671], dtype=float32), -0.43595767]. 
=============================================
[2019-03-27 08:33:04,545] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.6169037e-29], sum to 1.0000
[2019-03-27 08:33:04,555] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1962
[2019-03-27 08:33:04,563] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.83333333333334, 74.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8903052503884349, 6.9112, 6.9112, 168.912956510431, 733449.5574072966, 733449.5574072966, 221133.4160405538], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5080200.0000, 
sim time next is 5080800.0000, 
raw observation next is [28.66666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8880226689797064, 6.911200000000001, 6.9112, 168.912956510431, 731887.2968138687, 731887.2968138681, 220622.1829783354], 
processed observation next is [0.0, 0.8260869565217391, 0.5576619273301741, 0.7566666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8634422792435443, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2033020268927413, 0.20330202689274113, 0.3292868402661722], 
reward next is 0.6707, 
noisyNet noise sample is [array([-0.5560114], dtype=float32), -0.3593414]. 
=============================================
[2019-03-27 08:33:08,813] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 08:33:08,815] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:33:08,815] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:33:08,815] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:33:08,816] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:33:08,818] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:33:08,818] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:33:08,817] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:33:08,818] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:33:08,821] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:33:08,822] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:33:08,842] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run83
[2019-03-27 08:33:08,866] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run83
[2019-03-27 08:33:08,892] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run83
[2019-03-27 08:33:08,919] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run83
[2019-03-27 08:33:08,945] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run83
[2019-03-27 08:34:12,745] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072248794]
[2019-03-27 08:34:12,747] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 75.0, 1.0, 2.0, 0.9647796879788798, 1.0, 2.0, 0.8029798835037023, 1.0, 2.0, 1.03, 7.00511861908234, 6.9112, 170.5573041426782, 3370043.771664739, 3302766.044450894, 618019.2533160883]
[2019-03-27 08:34:12,749] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:34:12,754] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0657924e-02 2.5182143e-15 1.6757169e-12 6.8675161e-18 9.8934209e-01], sampled 0.0008766292912523177
[2019-03-27 08:34:12,756] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3370043.771664739 W.
[2019-03-27 08:35:05,397] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.0948 2989558482.7596 1571.0000
[2019-03-27 08:35:05,455] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7262.5515 3320236927.2360 2182.0000
[2019-03-27 08:35:05,529] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7375.7855 3104972257.2722 1911.0000
[2019-03-27 08:35:05,616] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8076.8493 2937997920.6754 1322.0000
[2019-03-27 08:35:05,653] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7026.2988 3185859638.5142 2441.0000
[2019-03-27 08:35:06,674] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2050000, evaluation results [2050000.0, 7262.551471972839, 3320236927.236039, 2182.0, 7375.785526840424, 3104972257.272219, 1911.0, 8076.849282804348, 2937997920.6754394, 1322.0, 7026.298821543552, 3185859638.514248, 2441.0, 7922.09484029315, 2989558482.759561, 1571.0]
[2019-03-27 08:35:16,367] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.5780565e-26 9.5526799e-28 1.5932927e-27 7.2150842e-14], sum to 1.0000
[2019-03-27 08:35:16,375] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3351
[2019-03-27 08:35:16,382] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.26666666666667, 83.66666666666667, 1.0, 1.0, 0.2989716056570734, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5192148076055019, 6.911200000000001, 6.9112, 168.9128880910935, 835586.567773338, 835586.5677733374, 221626.469248251], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5442000.0000, 
sim time next is 5442600.0000, 
raw observation next is [29.18333333333334, 84.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.956556393189777, 6.9112, 168.9125309697211, 860990.7767696356, 828813.471458395, 254812.2073283544], 
processed observation next is [1.0, 1.0, 0.5821484992101109, 0.8433333333333334, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.004535639318977669, 0.0, 0.8294378555526037, 0.23916410465823212, 0.2302259642939986, 0.38031672735575284], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.8365056], dtype=float32), 1.4139729]. 
=============================================
[2019-03-27 08:35:17,704] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 4.8943503e-37 0.0000000e+00 3.2634404e-36 3.3357045e-25], sum to 1.0000
[2019-03-27 08:35:17,712] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1238
[2019-03-27 08:35:17,720] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.33333333333333, 77.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8822007284026254, 6.911199999999999, 6.9112, 168.912956510431, 727809.5592404163, 727809.5592404169, 219320.5408352973], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5644200.0000, 
sim time next is 5644800.0000, 
raw observation next is [28.5, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.885662887766796, 6.9112, 6.9112, 168.912956510431, 730050.3925329782, 730050.3925329782, 220086.6965547656], 
processed observation next is [0.0, 0.34782608695652173, 0.5497630331753555, 0.77, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8605644972765806, 0.0, 0.0, 0.8294399451523027, 0.20279177570360507, 0.20279177570360507, 0.32848760679815764], 
reward next is 0.6715, 
noisyNet noise sample is [array([0.08535082], dtype=float32), 1.1635011]. 
=============================================
[2019-03-27 08:35:18,801] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9996197e-01 1.2584782e-17 2.0346249e-16 2.4643155e-20 3.8043490e-05], sum to 1.0000
[2019-03-27 08:35:18,809] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6157
[2019-03-27 08:35:18,817] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1120028.942460553 W.
[2019-03-27 08:35:18,823] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.36666666666667, 87.33333333333333, 1.0, 2.0, 0.2671287017689304, 1.0, 2.0, 0.2671287017689304, 1.0, 1.0, 0.4594482559407631, 6.9112, 6.9112, 170.5573041426782, 1120028.942460553, 1120028.942460553, 291169.1279413551], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5553600.0000, 
sim time next is 5554200.0000, 
raw observation next is [27.53333333333333, 86.66666666666667, 1.0, 2.0, 0.8074676157775447, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1128538.805378907, 1128538.805378907, 245752.6762990415], 
processed observation next is [1.0, 0.2608695652173913, 0.5039494470774091, 0.8666666666666667, 1.0, 1.0, 0.7680332720211381, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.3134830014941408, 0.3134830014941408, 0.3667950392523007], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4728475], dtype=float32), 1.2614648]. 
=============================================
[2019-03-27 08:35:23,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.4388608e-01 2.5414988e-18 7.6869828e-16 4.1801746e-21 1.5611395e-01], sum to 1.0000
[2019-03-27 08:35:23,996] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8084
[2019-03-27 08:35:24,004] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2103131.551092768 W.
[2019-03-27 08:35:24,011] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [33.6, 52.0, 1.0, 2.0, 0.5013704127120266, 1.0, 2.0, 0.5013704127120266, 1.0, 2.0, 0.86415245506659, 6.9112, 6.9112, 170.5573041426782, 2103131.551092768, 2103131.551092768, 414904.2211708117], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5576400.0000, 
sim time next is 5577000.0000, 
raw observation next is [33.7, 51.33333333333334, 1.0, 2.0, 0.6832302918689799, 1.0, 2.0, 0.6832302918689799, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1910489.171463397, 1910489.171463397, 367025.314766517], 
processed observation next is [1.0, 0.5652173913043478, 0.7962085308056873, 0.5133333333333334, 1.0, 1.0, 0.6183497492397347, 1.0, 1.0, 0.6183497492397347, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5306914365176103, 0.5306914365176103, 0.5477989772634583], 
reward next is 0.4522, 
noisyNet noise sample is [array([0.9686651], dtype=float32), 1.3599362]. 
=============================================
[2019-03-27 08:35:24,026] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[22.105907]
 [21.860197]
 [21.723183]
 [21.329073]
 [20.400797]], R is [[22.96631241]
 [23.11738777]
 [23.25555992]
 [23.39496803]
 [23.54772949]].
[2019-03-27 08:35:25,320] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [8.2237113e-01 1.0233353e-17 3.9622203e-16 5.5615412e-21 1.7762886e-01], sum to 1.0000
[2019-03-27 08:35:25,330] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3720
[2019-03-27 08:35:25,340] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2695055.950376566 W.
[2019-03-27 08:35:25,343] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [36.53333333333333, 50.0, 1.0, 2.0, 0.6434678334979396, 1.0, 2.0, 0.6423239562632324, 1.0, 1.0, 1.03, 7.005093275070672, 6.9112, 170.5573041426782, 2695055.950376566, 2627796.378109207, 504066.8275982693], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5491200.0000, 
sim time next is 5491800.0000, 
raw observation next is [36.65, 49.0, 1.0, 2.0, 1.004404687246659, 1.0, 2.0, 1.004404687246659, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 170.5573041426782, 2809642.302399098, 2809642.302399097, 531656.1009337334], 
processed observation next is [1.0, 0.5652173913043478, 0.9360189573459715, 0.49, 1.0, 1.0, 1.0053068521044084, 1.0, 1.0, 1.0053068521044084, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.7804561951108605, 0.7804561951108603, 0.793516568557811], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9219706], dtype=float32), -0.32073632]. 
=============================================
[2019-03-27 08:35:33,214] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1018473e-31], sum to 1.0000
[2019-03-27 08:35:33,225] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9907
[2019-03-27 08:35:33,231] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.48333333333333, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9837506080167358, 6.9112, 6.9112, 168.912956510431, 798832.3931301322, 798832.3931301322, 243220.6839054271], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5767800.0000, 
sim time next is 5768400.0000, 
raw observation next is [30.26666666666667, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9601157716080622, 6.9112, 6.9112, 168.912956510431, 780072.0220687708, 780072.0220687708, 237319.8208150098], 
processed observation next is [0.0, 0.782608695652174, 0.6334913112164299, 0.72, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9513606970830026, 0.0, 0.0, 0.8294399451523027, 0.21668667279688078, 0.21668667279688078, 0.3542086877835967], 
reward next is 0.6458, 
noisyNet noise sample is [array([0.6430458], dtype=float32), 0.061974272]. 
=============================================
[2019-03-27 08:35:36,025] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.0858591e-36 0.0000000e+00 2.7872069e-37 9.0809589e-24], sum to 1.0000
[2019-03-27 08:35:36,030] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6833
[2019-03-27 08:35:36,034] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8652143105947844, 6.911199999999999, 6.9112, 168.912956510431, 717425.8441861098, 717425.8441861104, 215620.9105848166], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6396600.0000, 
sim time next is 6397200.0000, 
raw observation next is [27.1, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8683389548757793, 6.9112, 6.9112, 168.912956510431, 720017.545643684, 720017.545643684, 216319.5623210992], 
processed observation next is [1.0, 0.043478260869565216, 0.4834123222748816, 0.83, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8394377498485112, 0.0, 0.0, 0.8294399451523027, 0.20000487378991222, 0.20000487378991222, 0.3228650183897003], 
reward next is 0.6771, 
noisyNet noise sample is [array([-0.6146799], dtype=float32), -0.88337547]. 
=============================================
[2019-03-27 08:35:37,718] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.646629e-29], sum to 1.0000
[2019-03-27 08:35:37,726] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0013
[2019-03-27 08:35:37,729] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.7, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8790429030684671, 6.911199999999999, 6.9112, 168.912956510431, 725651.6980632185, 725651.6980632192, 218619.8638606075], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5734800.0000, 
sim time next is 5735400.0000, 
raw observation next is [29.86666666666667, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8757454975156556, 6.911199999999999, 6.9112, 168.912956510431, 723031.3009158104, 723031.3009158111, 217877.6203730534], 
processed observation next is [0.0, 0.391304347826087, 0.6145339652448659, 0.6816666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8484701189215311, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20084202803216955, 0.20084202803216974, 0.3251904781687364], 
reward next is 0.6748, 
noisyNet noise sample is [array([0.63151526], dtype=float32), -0.11034437]. 
=============================================
[2019-03-27 08:35:43,598] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.2351621e-01 5.0529827e-17 8.0572091e-14 3.0072607e-20 5.7648379e-01], sum to 1.0000
[2019-03-27 08:35:43,607] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0855
[2019-03-27 08:35:43,616] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1308860.293095589 W.
[2019-03-27 08:35:43,624] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.15, 93.16666666666667, 1.0, 2.0, 0.4682067116926186, 1.0, 2.0, 0.4682067116926186, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1308860.293095589, 1308860.293095589, 290672.0084283782], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5803800.0000, 
sim time next is 5804400.0000, 
raw observation next is [26.1, 93.33333333333334, 1.0, 2.0, 0.4418244873565561, 0.0, 1.0, 0.0, 1.0, 1.0, 0.751720856438662, 6.9112, 6.9112, 168.912956510431, 1235073.87948004, 1235073.87948004, 276050.4471673333], 
processed observation next is [1.0, 0.17391304347826086, 0.4360189573459717, 0.9333333333333335, 1.0, 1.0, 0.3274993823572965, 0.0, 0.5, -0.20481927710843376, 1.0, 0.5, 0.6972205566325146, 0.0, 0.0, 0.8294399451523027, 0.3430760776333444, 0.3430760776333444, 0.41201559278706457], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.6178519], dtype=float32), 0.5368723]. 
=============================================
[2019-03-27 08:35:44,651] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7923783e-27], sum to 1.0000
[2019-03-27 08:35:44,662] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.7619
[2019-03-27 08:35:44,667] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.75, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8943514850697675, 6.911199999999999, 6.9112, 168.912956510431, 733954.1797674078, 733954.1797674084, 221951.8116140378], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6114600.0000, 
sim time next is 6115200.0000, 
raw observation next is [28.56666666666666, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8949473642729215, 6.911199999999999, 6.9112, 168.912956510431, 734641.2827991112, 734641.2827991118, 222097.3466237875], 
processed observation next is [1.0, 0.782608695652174, 0.5529225908372825, 0.78, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8718870296011239, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20406702299975313, 0.20406702299975327, 0.3314885770504291], 
reward next is 0.6685, 
noisyNet noise sample is [array([-0.5536965], dtype=float32), -2.3026307]. 
=============================================
[2019-03-27 08:35:53,765] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.9489272e-01 4.2734580e-20 3.3940789e-17 1.9322174e-21 5.1073092e-03], sum to 1.0000
[2019-03-27 08:35:53,774] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7284
[2019-03-27 08:35:53,779] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1051563.007325386 W.
[2019-03-27 08:35:53,784] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.23333333333333, 91.83333333333333, 1.0, 2.0, 0.7524188188870794, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104309, 1051563.007325386, 1051563.007325385, 232565.7493559126], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 5971800.0000, 
sim time next is 5972400.0000, 
raw observation next is [26.2, 92.0, 1.0, 2.0, 0.7353930690891236, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1027756.701604026, 1027756.701604027, 228669.375624542], 
processed observation next is [1.0, 0.13043478260869565, 0.44075829383886256, 0.92, 1.0, 1.0, 0.6811964687820766, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.28548797266778503, 0.28548797266778525, 0.3412975755590179], 
reward next is 0.6587, 
noisyNet noise sample is [array([0.9774754], dtype=float32), -0.38306138]. 
=============================================
[2019-03-27 08:35:59,981] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-27 08:35:59,982] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:35:59,983] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:35:59,983] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:35:59,983] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:35:59,984] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:35:59,984] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:35:59,984] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:35:59,984] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:35:59,986] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:35:59,986] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:36:00,002] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run84
[2019-03-27 08:36:00,024] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run84
[2019-03-27 08:36:00,025] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run84
[2019-03-27 08:36:00,053] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run84
[2019-03-27 08:36:00,075] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run84
[2019-03-27 08:36:19,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07181453]
[2019-03-27 08:36:19,854] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.21666666666667, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.841262999255527, 6.9112, 168.9080486764072, 1530259.361580705, 870459.8309091186, 256511.1469058331]
[2019-03-27 08:36:19,858] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:36:19,861] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.8118545e-37 0.0000000e+00 1.8886479e-36 1.6840816e-24], sampled 0.4477570894056756
[2019-03-27 08:36:19,866] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1530259.361580705 W.
[2019-03-27 08:37:05,121] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07181453]
[2019-03-27 08:37:05,121] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.57659555333333, 84.16768949833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9718871074708602, 6.911200000000001, 6.9112, 168.9129422241146, 792455.911610557, 792455.9116105563, 240391.3985153908]
[2019-03-27 08:37:05,122] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:37:05,125] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.1711275e-28 1.2009829e-29 2.1168245e-28 1.9289029e-16], sampled 0.23057281167296495
[2019-03-27 08:37:16,548] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07181453]
[2019-03-27 08:37:16,549] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8690096175748532, 6.911199999999999, 6.9112, 168.912956510431, 720175.6170638588, 720175.6170638594, 216456.7083527381]
[2019-03-27 08:37:16,550] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:37:16,554] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.6017834e-27], sampled 0.547119588219446
[2019-03-27 08:37:48,261] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07181453]
[2019-03-27 08:37:48,264] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.66666666666666, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6011192772246988, 6.911199999999999, 6.9112, 168.912956510431, 524635.574303105, 524635.5743031057, 166225.1636294071]
[2019-03-27 08:37:48,265] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:37:48,267] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7583723e-30], sampled 0.5437733119158323
[2019-03-27 08:37:51,859] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07181453]
[2019-03-27 08:37:51,863] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.9, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541971167068927, 6.9112, 6.9112, 168.912956510431, 638235.8368343628, 638235.8368343628, 192789.0903789737]
[2019-03-27 08:37:51,865] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:37:51,869] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 8.952599e-38 2.909474e-26], sampled 0.2623447592945498
[2019-03-27 08:37:56,287] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.0046 2989762419.3137 1574.0000
[2019-03-27 08:37:56,341] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8075.2049 2938087616.0573 1319.0000
[2019-03-27 08:37:56,551] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7366.8396 3105305193.2518 1930.0000
[2019-03-27 08:37:56,571] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7266.7735 3320131518.0179 2170.0000
[2019-03-27 08:37:56,654] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7033.2677 3186138917.5472 2440.0000
[2019-03-27 08:37:57,672] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2075000, evaluation results [2075000.0, 7266.773506094905, 3320131518.0178943, 2170.0, 7366.839623484763, 3105305193.2517886, 1930.0, 8075.20493067927, 2938087616.0573483, 1319.0, 7033.267692679513, 3186138917.5471654, 2440.0, 7915.004591418799, 2989762419.313696, 1574.0]
[2019-03-27 08:37:57,712] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6396282e-38 1.3381264e-24], sum to 1.0000
[2019-03-27 08:37:57,720] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7831
[2019-03-27 08:37:57,724] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.5, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8910064790333437, 6.911200000000001, 6.9112, 168.912956510431, 733037.909107554, 733037.9091075534, 221256.0676019304], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6231600.0000, 
sim time next is 6232200.0000, 
raw observation next is [26.5, 91.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8916335251553238, 6.911200000000001, 6.9112, 168.912956510431, 733448.9201955041, 733448.9201955035, 221396.0122684144], 
processed observation next is [0.0, 0.13043478260869565, 0.4549763033175356, 0.9100000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8678457623845413, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2037358111654178, 0.20373581116541764, 0.3304418093558424], 
reward next is 0.6696, 
noisyNet noise sample is [array([-0.44928873], dtype=float32), 0.4479901]. 
=============================================
[2019-03-27 08:37:58,338] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.00000000e+00 1.13496566e-37 0.00000000e+00 1.38682325e-36
 1.93310108e-24], sum to 1.0000
[2019-03-27 08:37:58,348] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8742
[2019-03-27 08:37:58,353] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.46666666666667, 73.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8775697441725387, 6.9112, 6.9112, 168.912956510431, 719378.128923879, 719378.128923879, 218088.9857349519], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6112200.0000, 
sim time next is 6112800.0000, 
raw observation next is [29.3, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.891223788807236, 6.9112, 6.9112, 168.912956510431, 730833.3393894561, 730833.3393894561, 221209.3379449639], 
processed observation next is [1.0, 0.782608695652174, 0.5876777251184835, 0.74, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8673460839112632, 0.0, 0.0, 0.8294399451523027, 0.20300926094151558, 0.20300926094151558, 0.3301631909626327], 
reward next is 0.6698, 
noisyNet noise sample is [array([0.5481141], dtype=float32), 0.23760672]. 
=============================================
[2019-03-27 08:37:59,086] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5182698e-31], sum to 1.0000
[2019-03-27 08:37:59,094] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.0570
[2019-03-27 08:37:59,100] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8934435027874157, 6.911200000000001, 6.9112, 168.912956510431, 733869.9326706474, 733869.9326706467, 221769.6971005451], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6116400.0000, 
sim time next is 6117000.0000, 
raw observation next is [28.03333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8936789764725237, 6.911199999999999, 6.9112, 168.912956510431, 734253.6139373208, 734253.6139373215, 221831.6439026488], 
processed observation next is [1.0, 0.8260869565217391, 0.5276461295418641, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8703402152103947, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20395933720481133, 0.20395933720481152, 0.33109200582484893], 
reward next is 0.6689, 
noisyNet noise sample is [array([1.2775685], dtype=float32), 1.5375348]. 
=============================================
[2019-03-27 08:37:59,115] A3C_AGENT_WORKER-Thread-16 DEBUG:Value prediction is [[62.593582]
 [62.149582]
 [61.254032]
 [60.333252]
 [59.126762]], R is [[63.35030746]
 [63.38580322]
 [63.42071533]
 [63.4550209 ]
 [63.48920059]].
[2019-03-27 08:38:01,851] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.8291612e-01 5.5756662e-19 4.1049763e-16 2.9702405e-20 1.7083859e-02], sum to 1.0000
[2019-03-27 08:38:01,859] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3059
[2019-03-27 08:38:01,866] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1031420.832863585 W.
[2019-03-27 08:38:01,870] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.63333333333333, 91.33333333333334, 1.0, 2.0, 0.3690068002872625, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6294975047106932, 6.911200000000001, 6.9112, 168.912956510431, 1031420.832863585, 1031420.832863585, 245252.4791930816], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6153600.0000, 
sim time next is 6154200.0000, 
raw observation next is [26.7, 91.0, 1.0, 2.0, 0.2399567589317898, 1.0, 1.0, 0.2399567589317898, 1.0, 2.0, 0.4114822279822631, 6.9112, 6.9112, 170.5573041426782, 1006047.781479926, 1006047.781479926, 281631.3117583587], 
processed observation next is [1.0, 0.21739130434782608, 0.46445497630331756, 0.91, 1.0, 1.0, 0.08428525172504794, 1.0, 0.5, 0.08428525172504794, 1.0, 1.0, 0.2822953999783696, 0.0, 0.0, 0.8375144448122397, 0.27945771707775724, 0.27945771707775724, 0.4203452414303861], 
reward next is 0.5797, 
noisyNet noise sample is [array([-0.84548813], dtype=float32), 3.0086994]. 
=============================================
[2019-03-27 08:38:19,348] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9999940e-01 1.3041800e-23 5.9854783e-23 7.4284961e-25 6.3686929e-07], sum to 1.0000
[2019-03-27 08:38:19,356] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9831
[2019-03-27 08:38:19,366] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.13333333333333, 72.66666666666667, 1.0, 2.0, 0.2262752815636838, 0.0, 1.0, 0.0, 1.0, 2.0, 0.3791921209448947, 6.9112, 6.9112, 168.912956510431, 632349.366140958, 632349.366140958, 200274.9335183106], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7060800.0000, 
sim time next is 7061400.0000, 
raw observation next is [28.0, 73.5, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7536506082814334, 6.9112, 6.9112, 168.912956510431, 629587.1656413132, 629587.1656413132, 192527.5084698922], 
processed observation next is [1.0, 0.7391304347826086, 0.5260663507109005, 0.735, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6995739125383335, 0.0, 0.0, 0.8294399451523027, 0.17488532378925367, 0.17488532378925367, 0.28735449025357046], 
reward next is 0.7126, 
noisyNet noise sample is [array([-0.32375172], dtype=float32), 1.805422]. 
=============================================
[2019-03-27 08:38:19,936] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.0041432e-01 2.7968873e-15 1.2679284e-12 1.6676960e-17 1.9958566e-01], sum to 1.0000
[2019-03-27 08:38:19,941] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1402
[2019-03-27 08:38:19,950] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1914047.228788654 W.
[2019-03-27 08:38:19,955] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.58333333333334, 67.66666666666666, 1.0, 2.0, 0.7278112059817594, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.972638573516683, 6.9112, 168.9125376834242, 1914047.228788654, 1870460.698258373, 391928.8982228514], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 6515400.0000, 
sim time next is 6516000.0000, 
raw observation next is [29.8, 66.0, 1.0, 2.0, 0.7674364097921904, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.971264461337936, 6.9112, 168.9125490599498, 1969500.396812647, 1926888.703468132, 401124.6244478405], 
processed observation next is [1.0, 0.43478260869565216, 0.6113744075829385, 0.66, 1.0, 1.0, 0.7198029033640848, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0060064461337936415, 0.0, 0.8294379443839084, 0.5470834435590687, 0.5352468620744811, 0.5986934693251351], 
reward next is 0.1010, 
noisyNet noise sample is [array([0.76596445], dtype=float32), -0.5851295]. 
=============================================
[2019-03-27 08:38:19,965] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[27.286423]
 [28.85054 ]
 [30.627228]
 [30.482231]
 [29.801739]], R is [[25.83576965]
 [25.68524933]
 [25.5269413 ]
 [25.2716713 ]
 [25.50425529]].
[2019-03-27 08:38:32,544] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [5.8855110e-01 7.2208988e-18 1.0517348e-14 5.5598144e-20 4.1144893e-01], sum to 1.0000
[2019-03-27 08:38:32,549] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9140
[2019-03-27 08:38:32,553] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.7, 75.0, 1.0, 2.0, 0.4151599494114698, 1.0, 2.0, 0.4151599494114698, 1.0, 2.0, 0.7107909757960149, 6.9112, 6.9112, 170.5573041426782, 1741204.973462928, 1741204.973462928, 359938.7199891233], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6690600.0000, 
sim time next is 6691200.0000, 
raw observation next is [28.86666666666667, 74.0, 1.0, 2.0, 0.420850245462413, 1.0, 2.0, 0.420850245462413, 1.0, 2.0, 0.7206422034882077, 6.9112, 6.9112, 170.5573041426782, 1765090.061769981, 1765090.061769981, 363201.6982558732], 
processed observation next is [1.0, 0.43478260869565216, 0.567140600315956, 0.74, 1.0, 1.0, 0.3022292114004976, 1.0, 1.0, 0.3022292114004976, 1.0, 1.0, 0.6593197603514728, 0.0, 0.0, 0.8375144448122397, 0.4903027949361058, 0.4903027949361058, 0.5420920869490645], 
reward next is 0.4579, 
noisyNet noise sample is [array([0.73051345], dtype=float32), -0.5439796]. 
=============================================
[2019-03-27 08:38:34,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 6.3185361e-36 6.0062735e-38 4.4026293e-35 6.0294022e-19], sum to 1.0000
[2019-03-27 08:38:34,257] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7643
[2019-03-27 08:38:34,262] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.96666666666667, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6105522492114864, 6.9112, 6.9112, 168.912956510431, 531305.4473124315, 531305.4473124315, 167705.5099687044], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6739800.0000, 
sim time next is 6740400.0000, 
raw observation next is [23.83333333333334, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6084843875137576, 6.9112, 6.9112, 168.912956510431, 529808.52405428, 529808.52405428, 167380.1167524434], 
processed observation next is [1.0, 0.0, 0.32859399684044266, 0.77, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5225419359923872, 0.0, 0.0, 0.8294399451523027, 0.14716903445952223, 0.14716903445952223, 0.24982106977976626], 
reward next is 0.7502, 
noisyNet noise sample is [array([1.5699133], dtype=float32), -0.26127315]. 
=============================================
[2019-03-27 08:38:34,431] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7226721e-30], sum to 1.0000
[2019-03-27 08:38:34,439] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.5063
[2019-03-27 08:38:34,444] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7532420606725545, 6.9112, 6.9112, 168.912956510431, 637637.6749049134, 637637.6749049134, 192606.7861651659], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6721200.0000, 
sim time next is 6721800.0000, 
raw observation next is [27.86666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7446736189271007, 6.911200000000001, 6.9112, 168.912956510431, 631364.9630658949, 631364.9630658942, 190969.8324500998], 
processed observation next is [1.0, 0.8260869565217391, 0.519747235387046, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6886263645452446, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17537915640719304, 0.17537915640719284, 0.2850296006717908], 
reward next is 0.7150, 
noisyNet noise sample is [array([1.0473362], dtype=float32), -0.65942365]. 
=============================================
[2019-03-27 08:38:37,430] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.00000000e+00 2.02571084e-31 1.13166994e-32 1.59940336e-31
 4.90353891e-17], sum to 1.0000
[2019-03-27 08:38:37,438] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.5636
[2019-03-27 08:38:37,444] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.75, 82.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.957382670850154, 6.9112, 6.9112, 168.912956510431, 809343.1546136421, 809343.1546136421, 237744.1907872454], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7019400.0000, 
sim time next is 7020000.0000, 
raw observation next is [25.9, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.981144024914748, 6.9112, 6.9112, 168.912956510431, 829710.3218437829, 829710.3218437829, 243736.0705348708], 
processed observation next is [1.0, 0.2608695652173913, 0.42654028436018954, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9770049084326193, 0.0, 0.0, 0.8294399451523027, 0.2304750894010508, 0.2304750894010508, 0.36378517990279224], 
reward next is 0.6362, 
noisyNet noise sample is [array([-0.73067576], dtype=float32), -1.0089732]. 
=============================================
[2019-03-27 08:38:37,459] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[55.77569 ]
 [52.4154  ]
 [49.799084]
 [47.598892]
 [49.26905 ]], R is [[56.85574722]
 [56.93234634]
 [57.00388718]
 [56.43384933]
 [56.54156876]].
[2019-03-27 08:38:41,014] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2044095e-28], sum to 1.0000
[2019-03-27 08:38:41,023] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0661
[2019-03-27 08:38:41,031] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.1, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7940299004770428, 6.9112, 6.9112, 168.912956510431, 665919.8240155568, 665919.8240155568, 200617.1320335865], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7153200.0000, 
sim time next is 7153800.0000, 
raw observation next is [26.1, 83.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7932588289215818, 6.911200000000001, 6.9112, 168.912956510431, 665486.6434327345, 665486.643432734, 200464.2604568777], 
processed observation next is [1.0, 0.8260869565217391, 0.4360189573459717, 0.8383333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7478766206360754, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18485740095353737, 0.1848574009535372, 0.29920038874160854], 
reward next is 0.7008, 
noisyNet noise sample is [array([0.07913087], dtype=float32), -1.0265392]. 
=============================================
[2019-03-27 08:38:46,293] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 6.6846533e-38 0.0000000e+00 9.1489445e-37 1.8999240e-25], sum to 1.0000
[2019-03-27 08:38:46,305] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8505
[2019-03-27 08:38:46,310] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.33333333333333, 92.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6876692450766698, 6.911200000000001, 6.9112, 168.912956510431, 588624.7158582052, 588624.7158582046, 180539.3006387778], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7527000.0000, 
sim time next is 7527600.0000, 
raw observation next is [23.3, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6852341824369153, 6.9112, 6.9112, 168.912956510431, 586920.5135751214, 586920.5135751214, 180112.0559486472], 
processed observation next is [0.0, 0.13043478260869565, 0.3033175355450238, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6161392468742869, 0.0, 0.0, 0.8294399451523027, 0.1630334759930893, 0.1630334759930893, 0.2688239641024585], 
reward next is 0.7312, 
noisyNet noise sample is [array([-0.5937985], dtype=float32), -0.8112395]. 
=============================================
[2019-03-27 08:38:48,391] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1056048e-29], sum to 1.0000
[2019-03-27 08:38:48,401] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6900
[2019-03-27 08:38:48,405] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.96666666666667, 56.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.690081434455713, 6.911199999999999, 6.9112, 168.912956510431, 591149.2877517611, 591149.2877517617, 180965.1120507776], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6981600.0000, 
sim time next is 6982200.0000, 
raw observation next is [28.9, 56.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6874088632717247, 6.911200000000001, 6.9112, 168.912956510431, 589670.6571792576, 589670.6571792569, 180494.0463840332], 
processed observation next is [0.0, 0.8260869565217391, 0.5687203791469194, 0.56, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6187912966728348, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.163797404772016, 0.1637974047720158, 0.26939409908064654], 
reward next is 0.7306, 
noisyNet noise sample is [array([-0.19442523], dtype=float32), 1.1753668]. 
=============================================
[2019-03-27 08:38:50,997] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 08:38:50,998] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:38:50,999] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:38:50,999] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:38:51,000] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:38:51,001] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:38:51,002] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:38:51,003] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:38:51,003] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:38:51,004] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:38:51,005] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:38:51,029] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run85
[2019-03-27 08:38:51,046] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run85
[2019-03-27 08:38:51,046] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run85
[2019-03-27 08:38:51,086] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run85
[2019-03-27 08:38:51,103] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run85
[2019-03-27 08:38:59,906] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07383549]
[2019-03-27 08:38:59,910] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [21.0, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4274986532834195, 6.911200000000001, 6.9112, 168.912956510431, 384344.268839059, 384344.2688390583, 143313.0198586281]
[2019-03-27 08:38:59,910] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:38:59,913] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4218339e-38 3.5514413e-29], sampled 0.3888877946298295
[2019-03-27 08:39:26,556] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07383549]
[2019-03-27 08:39:26,557] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [32.562566765, 59.84095863, 1.0, 2.0, 0.7862195531465203, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1098826.566949599, 1098826.566949599, 240557.6774594272]
[2019-03-27 08:39:26,558] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:39:26,559] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.4818894e-23 5.5755086e-23 5.1203743e-24 6.8086409e-10], sampled 0.5069009446529533
[2019-03-27 08:39:26,560] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1098826.566949599 W.
[2019-03-27 08:39:57,460] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07383549]
[2019-03-27 08:39:57,461] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.96218879333333, 84.28383177333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8318599160258544, 6.9112, 6.9112, 168.912956510431, 697332.2006766202, 697332.2006766202, 208535.4117575993]
[2019-03-27 08:39:57,463] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:39:57,467] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.6849504e-29], sampled 0.1974508599787662
[2019-03-27 08:40:12,052] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07383549]
[2019-03-27 08:40:12,054] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.0, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.01678436260721, 6.9112, 168.9121291761151, 903734.9574912854, 828830.1436094011, 254811.929395542]
[2019-03-27 08:40:12,057] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:40:12,059] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.6904445e-32 3.1284169e-35 1.8544064e-31 2.0768335e-19], sampled 0.7415128021243985
[2019-03-27 08:40:12,062] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 903734.9574912854 W.
[2019-03-27 08:40:26,477] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07383549]
[2019-03-27 08:40:26,478] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.86466780666667, 77.36167138666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8636264855369887, 6.9112, 6.9112, 168.912956510431, 718654.4160841871, 718654.4160841871, 215346.6990586784]
[2019-03-27 08:40:26,479] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:40:26,482] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0667946e-28], sampled 0.6714577207602878
[2019-03-27 08:40:47,031] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7262.2060 3321295204.4003 2168.0000
[2019-03-27 08:40:47,178] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7397.5156 3104811259.8292 1840.0000
[2019-03-27 08:40:47,213] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7022.6671 3188474948.0833 2411.0000
[2019-03-27 08:40:47,406] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8093.5725 2938775628.7604 1239.0000
[2019-03-27 08:40:47,518] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7915.7051 2990945607.9626 1535.0000
[2019-03-27 08:40:48,536] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2100000, evaluation results [2100000.0, 7262.205995175082, 3321295204.4002695, 2168.0, 7397.5155784502085, 3104811259.829224, 1840.0, 8093.572511037408, 2938775628.76044, 1239.0, 7022.667095326588, 3188474948.083262, 2411.0, 7915.705142374141, 2990945607.9626393, 1535.0]
[2019-03-27 08:40:51,724] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [7.1624801e-02 2.3352760e-18 5.9446953e-16 7.1939696e-21 9.2837518e-01], sum to 1.0000
[2019-03-27 08:40:51,737] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2761
[2019-03-27 08:40:51,743] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 70.0, 1.0, 2.0, 0.568979768186942, 1.0, 2.0, 0.568979768186942, 1.0, 2.0, 0.988129692856057, 6.9112, 6.9112, 170.5573041426782, 2387025.240955017, 2387025.240955017, 466123.8086584925], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7819200.0000, 
sim time next is 7819800.0000, 
raw observation next is [31.0, 70.0, 1.0, 2.0, 0.5285350634459048, 1.0, 2.0, 0.5285350634459048, 1.0, 2.0, 0.9178906159891194, 6.9112, 6.9112, 170.5573041426782, 2217198.161613202, 2217198.161613202, 435439.6401249816], 
processed observation next is [1.0, 0.5217391304347826, 0.6682464454976303, 0.7, 1.0, 1.0, 0.43196995595892146, 1.0, 1.0, 0.43196995595892146, 1.0, 1.0, 0.8998666048647798, 0.0, 0.0, 0.8375144448122397, 0.6158883782258895, 0.6158883782258895, 0.6499099106343009], 
reward next is 0.3501, 
noisyNet noise sample is [array([0.16925102], dtype=float32), 0.3506444]. 
=============================================
[2019-03-27 08:40:53,085] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.00000000e+00 2.31094534e-25 1.28993115e-23 1.62465642e-26
 3.99871913e-09], sum to 1.0000
[2019-03-27 08:40:53,093] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8728
[2019-03-27 08:40:53,100] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.6, 95.0, 1.0, 2.0, 0.3004929386677969, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5023415099750519, 6.911200000000001, 6.9112, 168.9129563085414, 839840.1756234339, 839840.1756234333, 220068.0639827424], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7698600.0000, 
sim time next is 7699200.0000, 
raw observation next is [24.6, 95.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9722876057248746, 6.9112, 6.9112, 168.9129565103806, 814857.2344241614, 814857.2344241614, 241328.1183364714], 
processed observation next is [1.0, 0.08695652173913043, 0.36492890995260674, 0.95, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9662043972254568, 0.0, 0.0, 0.8294399451520552, 0.22634923178448926, 0.22634923178448926, 0.36019122139771853], 
reward next is 0.6398, 
noisyNet noise sample is [array([0.15853737], dtype=float32), -1.6227164]. 
=============================================
[2019-03-27 08:41:00,235] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:00,236] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:00,305] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run11
[2019-03-27 08:41:01,962] A3C_AGENT_WORKER-Thread-13 INFO:Local step 132500, global step 2106325: loss 99.4896
[2019-03-27 08:41:01,964] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 132500, global step 2106325: learning rate 0.0000
[2019-03-27 08:41:02,881] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 1.1471321e-36 3.0748743e-38 1.7628806e-35 5.1176625e-23], sum to 1.0000
[2019-03-27 08:41:02,889] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8836
[2019-03-27 08:41:02,897] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.65, 89.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5807537661121471, 6.9112, 6.9112, 168.912956510431, 508478.1178813502, 508478.1178813502, 163139.7872768182], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7278600.0000, 
sim time next is 7279200.0000, 
raw observation next is [21.7, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5777374597961237, 6.911199999999999, 6.9112, 168.912956510431, 505796.1216798126, 505796.1216798131, 162699.4020125976], 
processed observation next is [1.0, 0.2608695652173913, 0.2274881516587678, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4850456826781996, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14049892268883685, 0.14049892268883696, 0.24283492837701134], 
reward next is 0.7572, 
noisyNet noise sample is [array([0.12533559], dtype=float32), -1.2350209]. 
=============================================
[2019-03-27 08:41:05,295] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.2526481e-05 4.8550096e-18 8.8701311e-14 5.2798955e-21 9.9995744e-01], sum to 1.0000
[2019-03-27 08:41:05,306] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9273
[2019-03-27 08:41:05,312] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.93333333333333, 78.0, 1.0, 2.0, 0.3491179705250851, 1.0, 2.0, 0.3491179705250851, 1.0, 2.0, 0.5868384818381016, 6.9112, 6.9112, 170.5573041426782, 1464031.883581847, 1464031.883581847, 324133.0527912418], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7636800.0000, 
sim time next is 7637400.0000, 
raw observation next is [27.2, 76.5, 1.0, 2.0, 0.3530290401932861, 1.0, 2.0, 0.3530290401932861, 1.0, 2.0, 0.5936525984952257, 6.9112, 6.9112, 170.5573041426782, 1480444.344542739, 1480444.344542739, 326005.246989804], 
processed observation next is [1.0, 0.391304347826087, 0.4881516587677725, 0.765, 1.0, 1.0, 0.22051691589552544, 1.0, 1.0, 0.22051691589552544, 1.0, 1.0, 0.5044543884088117, 0.0, 0.0, 0.8375144448122397, 0.41123454015076083, 0.41123454015076083, 0.4865749955071702], 
reward next is 0.5134, 
noisyNet noise sample is [array([0.95039976], dtype=float32), 0.49006414]. 
=============================================
[2019-03-27 08:41:08,385] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:08,386] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:08,455] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run11
[2019-03-27 08:41:10,152] A3C_AGENT_WORKER-Thread-20 INFO:Local step 132500, global step 2110269: loss 97.9270
[2019-03-27 08:41:10,157] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 132500, global step 2110270: learning rate 0.0000
[2019-03-27 08:41:14,409] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9371173e-38 1.7556551e-25], sum to 1.0000
[2019-03-27 08:41:14,418] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3069
[2019-03-27 08:41:14,424] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.85, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6980008086935361, 6.911199999999999, 6.9112, 168.912956510431, 595707.356162778, 595707.3561627786, 182366.332360592], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7500600.0000, 
sim time next is 7501200.0000, 
raw observation next is [24.73333333333333, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6967632876209275, 6.9112, 6.9112, 168.912956510431, 594801.6969995501, 594801.6969995501, 182146.0026527048], 
processed observation next is [0.0, 0.8260869565217391, 0.3712480252764612, 0.8366666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6301991312450336, 0.0, 0.0, 0.8294399451523027, 0.16522269361098613, 0.16522269361098613, 0.2718597054517982], 
reward next is 0.7281, 
noisyNet noise sample is [array([1.4164237], dtype=float32), -0.17770734]. 
=============================================
[2019-03-27 08:41:15,428] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:15,428] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:15,510] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run11
[2019-03-27 08:41:16,592] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.9509280e-01 2.0891043e-19 3.6641510e-15 5.5440019e-22 8.0490714e-01], sum to 1.0000
[2019-03-27 08:41:16,600] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.9928
[2019-03-27 08:41:16,607] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.8, 95.5, 1.0, 2.0, 0.9623188368413343, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1424284.097548017, 1424284.097548017, 299490.7416793756], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 127800.0000, 
sim time next is 128400.0000, 
raw observation next is [22.8, 95.66666666666667, 1.0, 2.0, 0.3115980756171408, 1.0, 1.0, 0.3115980756171408, 1.0, 1.0, 0.5324239050711713, 6.911199999999999, 6.9112, 170.5573041426782, 1357415.266398629, 1357415.26639863, 313105.745748081], 
processed observation next is [1.0, 0.4782608695652174, 0.2796208530805688, 0.9566666666666667, 1.0, 1.0, 0.17060009110498892, 1.0, 0.5, 0.17060009110498892, 1.0, 0.5, 0.42978525008679425, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.3770597962218414, 0.3770597962218417, 0.4673220085792254], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.67083824], dtype=float32), -0.3655889]. 
=============================================
[2019-03-27 08:41:17,426] A3C_AGENT_WORKER-Thread-22 INFO:Local step 132500, global step 2113760: loss 132.5701
[2019-03-27 08:41:17,430] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 132500, global step 2113760: learning rate 0.0000
[2019-03-27 08:41:18,353] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133000, global step 2114190: loss 0.0144
[2019-03-27 08:41:18,356] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133000, global step 2114191: learning rate 0.0000
[2019-03-27 08:41:20,978] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.2640359e-31 8.4955254e-34 1.0406360e-32 1.1098461e-15], sum to 1.0000
[2019-03-27 08:41:20,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.7471
[2019-03-27 08:41:20,997] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.36666666666667, 94.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7290706565105854, 6.9112, 6.9112, 168.912956510431, 622088.4001608702, 622088.4001608702, 188050.519606812], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7622400.0000, 
sim time next is 7623000.0000, 
raw observation next is [23.45, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7140371859497114, 6.911200000000001, 6.9112, 168.912956510431, 608823.8065641841, 608823.8065641836, 185264.9391191881], 
processed observation next is [1.0, 0.21739130434782608, 0.3104265402843602, 0.945, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6512648609142823, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1691177240456067, 0.16911772404560654, 0.27651483450625086], 
reward next is 0.7235, 
noisyNet noise sample is [array([-0.41066515], dtype=float32), 1.0251448]. 
=============================================
[2019-03-27 08:41:21,013] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[62.459713]
 [62.18746 ]
 [61.942547]
 [61.586567]
 [61.808903]], R is [[62.53185272]
 [62.62586212]
 [62.71704865]
 [62.79636383]
 [62.86126709]].
[2019-03-27 08:41:23,321] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:23,323] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:23,392] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run11
[2019-03-27 08:41:23,573] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [4.3066345e-02 1.5331612e-20 2.4196351e-17 6.2677107e-23 9.5693368e-01], sum to 1.0000
[2019-03-27 08:41:23,580] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8569
[2019-03-27 08:41:23,587] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.08333333333334, 64.83333333333334, 1.0, 2.0, 0.3855444299892922, 1.0, 2.0, 0.3855444299892922, 1.0, 2.0, 0.6561029362820482, 6.911200000000001, 6.9112, 170.5573041426782, 1616902.058099202, 1616902.058099201, 343205.5729100319], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7657800.0000, 
sim time next is 7658400.0000, 
raw observation next is [29.96666666666667, 65.66666666666667, 1.0, 2.0, 0.4314286402028117, 1.0, 2.0, 0.4314286402028117, 1.0, 2.0, 0.7348645436157426, 6.9112, 6.9112, 170.5573041426782, 1809494.419922088, 1809494.419922088, 368745.140770782], 
processed observation next is [1.0, 0.6521739130434783, 0.6192733017377569, 0.6566666666666667, 1.0, 1.0, 0.3149742653045924, 1.0, 1.0, 0.3149742653045924, 1.0, 1.0, 0.6766640775801739, 0.0, 0.0, 0.8375144448122397, 0.5026373388672467, 0.5026373388672467, 0.5503658817474358], 
reward next is 0.4496, 
noisyNet noise sample is [array([1.9470903], dtype=float32), 0.6120831]. 
=============================================
[2019-03-27 08:41:23,940] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [4.1218510e-01 6.2949070e-19 6.2980419e-15 5.5812684e-22 5.8781487e-01], sum to 1.0000
[2019-03-27 08:41:23,945] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7148
[2019-03-27 08:41:23,952] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.18333333333333, 90.16666666666666, 1.0, 2.0, 0.3773779702453616, 1.0, 1.0, 0.3773779702453616, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1054825.885404847, 1054825.885404847, 266574.7526874617], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7876200.0000, 
sim time next is 7876800.0000, 
raw observation next is [26.2, 90.0, 1.0, 2.0, 0.2460377233995214, 1.0, 2.0, 0.2460377233995214, 1.0, 1.0, 0.4182194373018699, 6.9112, 6.9112, 170.5573041426782, 1031555.224950332, 1031555.224950332, 283367.3005330351], 
processed observation next is [1.0, 0.17391304347826086, 0.44075829383886256, 0.9, 1.0, 1.0, 0.0916117149391824, 1.0, 1.0, 0.0916117149391824, 1.0, 0.5, 0.2905115089047194, 0.0, 0.0, 0.8375144448122397, 0.28654311804175886, 0.28654311804175886, 0.4229362694522911], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.2011667], dtype=float32), -0.033977065]. 
=============================================
[2019-03-27 08:41:24,185] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.5977109e-03 7.1442602e-19 2.2477629e-15 4.3895414e-21 9.9240232e-01], sum to 1.0000
[2019-03-27 08:41:24,192] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4478
[2019-03-27 08:41:24,197] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.6, 72.0, 1.0, 2.0, 0.4937856002272883, 1.0, 2.0, 0.4937856002272883, 1.0, 2.0, 0.8515931004069813, 6.9112, 6.9112, 170.5573041426782, 2071284.278119842, 2071284.278119842, 409814.5256853582], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7815600.0000, 
sim time next is 7816200.0000, 
raw observation next is [29.83333333333334, 71.66666666666667, 1.0, 2.0, 0.5380226332186783, 1.0, 2.0, 0.5380226332186783, 1.0, 2.0, 0.9303279252644607, 6.9112, 6.9112, 170.5573041426782, 2257034.339949252, 2257034.339949252, 441644.2949685188], 
processed observation next is [1.0, 0.4782608695652174, 0.6129541864139023, 0.7166666666666667, 1.0, 1.0, 0.44340076291407016, 1.0, 1.0, 0.44340076291407016, 1.0, 1.0, 0.9150340552005619, 0.0, 0.0, 0.8375144448122397, 0.6269539833192367, 0.6269539833192367, 0.6591705895052519], 
reward next is 0.3408, 
noisyNet noise sample is [array([-0.66794395], dtype=float32), -0.24077335]. 
=============================================
[2019-03-27 08:41:24,211] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.2384510e-34 8.0743548e-35 1.7328317e-34 6.7427072e-17], sum to 1.0000
[2019-03-27 08:41:24,218] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2649
[2019-03-27 08:41:24,222] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.7, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8154049325807352, 6.911200000000001, 6.9112, 168.912956510431, 682210.1289101572, 682210.1289101567, 205009.6041954944], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7682400.0000, 
sim time next is 7683000.0000, 
raw observation next is [25.66666666666667, 88.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8136718493816358, 6.911199999999999, 6.9112, 168.912956510431, 681068.175803685, 681068.1758036857, 204653.341150828], 
processed observation next is [1.0, 0.9565217391304348, 0.4154818325434442, 0.8800000000000001, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.772770548026385, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1891856043899125, 0.1891856043899127, 0.30545274798631045], 
reward next is 0.6945, 
noisyNet noise sample is [array([0.9933849], dtype=float32), -1.6744554]. 
=============================================
[2019-03-27 08:41:24,236] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[67.4466 ]
 [67.39138]
 [67.46492]
 [67.41672]
 [67.56894]], R is [[67.37664032]
 [67.39688873]
 [67.41722107]
 [67.43722534]
 [67.45613098]].
[2019-03-27 08:41:25,079] A3C_AGENT_WORKER-Thread-9 INFO:Local step 132500, global step 2117459: loss 104.6837
[2019-03-27 08:41:25,082] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 132500, global step 2117459: learning rate 0.0000
[2019-03-27 08:41:26,690] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8210338e-28], sum to 1.0000
[2019-03-27 08:41:26,698] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0390
[2019-03-27 08:41:26,703] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.6, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5734090475732164, 6.911200000000001, 6.9112, 168.912956510431, 500832.1816611232, 500832.1816611226, 162098.7177990802], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 311400.0000, 
sim time next is 312000.0000, 
raw observation next is [23.53333333333333, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5712133717710882, 6.911200000000001, 6.9112, 168.912956510431, 499111.3738603964, 499111.3738603957, 161776.8199846132], 
processed observation next is [0.0, 0.6086956521739131, 0.3143759873617693, 0.7666666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.47708947776961974, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13864204829455457, 0.13864204829455437, 0.24145794027554207], 
reward next is 0.7585, 
noisyNet noise sample is [array([-1.2810873], dtype=float32), 0.29647747]. 
=============================================
[2019-03-27 08:41:26,722] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[80.97246 ]
 [80.93117 ]
 [80.89579 ]
 [80.81478 ]
 [80.705246]], R is [[80.96335602]
 [80.91178894]
 [80.86022949]
 [80.8087616 ]
 [80.75778198]].
[2019-03-27 08:41:26,723] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133000, global step 2118223: loss 0.0011
[2019-03-27 08:41:26,726] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133000, global step 2118223: learning rate 0.0000
[2019-03-27 08:41:27,467] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:27,468] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:27,545] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run11
[2019-03-27 08:41:28,901] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:28,902] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:28,980] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run11
[2019-03-27 08:41:29,213] A3C_AGENT_WORKER-Thread-11 INFO:Local step 132500, global step 2119515: loss 105.2730
[2019-03-27 08:41:29,215] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 132500, global step 2119515: learning rate 0.0000
[2019-03-27 08:41:29,734] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.0267935e-38 5.9241980e-22], sum to 1.0000
[2019-03-27 08:41:29,742] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0077
[2019-03-27 08:41:29,746] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.58333333333334, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8445312484207929, 6.911199999999999, 6.9112, 168.912956510431, 697969.9755551813, 697969.975555182, 210985.76227982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7927800.0000, 
sim time next is 7928400.0000, 
raw observation next is [29.36666666666667, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8524686419248276, 6.9112, 6.9112, 168.912956510431, 704078.1035583878, 704078.1035583878, 212704.2736498237], 
processed observation next is [1.0, 0.782608695652174, 0.5908372827804109, 0.71, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8200837096644238, 0.0, 0.0, 0.8294399451523027, 0.19557725098844106, 0.19557725098844106, 0.3174690651489906], 
reward next is 0.6825, 
noisyNet noise sample is [array([-2.0552325], dtype=float32), -0.049048923]. 
=============================================
[2019-03-27 08:41:30,654] A3C_AGENT_WORKER-Thread-12 INFO:Local step 132500, global step 2120305: loss 103.3559
[2019-03-27 08:41:30,656] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 132500, global step 2120305: learning rate 0.0000
[2019-03-27 08:41:31,734] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:31,736] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:31,796] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run11
[2019-03-27 08:41:32,753] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133000, global step 2121384: loss 0.0123
[2019-03-27 08:41:32,756] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133000, global step 2121385: learning rate 0.0000
[2019-03-27 08:41:32,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:32,779] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:32,826] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run11
[2019-03-27 08:41:33,320] A3C_AGENT_WORKER-Thread-21 INFO:Local step 132500, global step 2121712: loss 96.3622
[2019-03-27 08:41:33,322] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 132500, global step 2121713: learning rate 0.0000
[2019-03-27 08:41:33,331] A3C_AGENT_WORKER-Thread-13 INFO:Local step 133500, global step 2121720: loss 0.3283
[2019-03-27 08:41:33,334] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 133500, global step 2121720: learning rate 0.0000
[2019-03-27 08:41:34,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:34,108] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:34,168] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run11
[2019-03-27 08:41:34,414] A3C_AGENT_WORKER-Thread-14 INFO:Local step 132500, global step 2122312: loss 94.6139
[2019-03-27 08:41:34,416] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 132500, global step 2122313: learning rate 0.0000
[2019-03-27 08:41:34,458] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.6858694e-38 1.0264190e-25], sum to 1.0000
[2019-03-27 08:41:34,463] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.8036
[2019-03-27 08:41:34,466] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.63333333333333, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5381385739901147, 6.9112, 6.9112, 168.912956510431, 473810.7724524142, 473810.7724524142, 157050.7509723108], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 207600.0000, 
sim time next is 208200.0000, 
raw observation next is [20.66666666666666, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5395154097589046, 6.9112, 6.9112, 168.912956510431, 474875.4220113505, 474875.4220113505, 157242.0753219616], 
processed observation next is [0.0, 0.391304347826087, 0.17851500789889393, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4384334265352494, 0.0, 0.0, 0.8294399451523027, 0.13190983944759738, 0.13190983944759738, 0.2346896646596442], 
reward next is 0.7653, 
noisyNet noise sample is [array([1.4476247], dtype=float32), 1.9018779]. 
=============================================
[2019-03-27 08:41:35,315] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.9427612e-01 3.0255585e-20 3.7284529e-18 4.3336393e-24 8.0572385e-01], sum to 1.0000
[2019-03-27 08:41:35,322] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6965
[2019-03-27 08:41:35,326] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.46666666666667, 66.0, 1.0, 2.0, 0.5017429790980776, 1.0, 2.0, 0.5017429790980776, 1.0, 2.0, 0.8630042242808321, 6.9112, 6.9112, 170.5573041426782, 2104695.915203586, 2104695.915203586, 414833.1147546609], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7917600.0000, 
sim time next is 7918200.0000, 
raw observation next is [30.5, 65.5, 1.0, 2.0, 0.5027105425743542, 1.0, 2.0, 0.5027105425743542, 1.0, 2.0, 0.8639202208795081, 6.911199999999999, 6.9112, 170.5573041426782, 2108758.61546166, 2108758.61546166, 415361.360776701], 
processed observation next is [1.0, 0.6521739130434783, 0.6445497630331753, 0.655, 1.0, 1.0, 0.40085607539078816, 1.0, 1.0, 0.40085607539078816, 1.0, 1.0, 0.8340490498530586, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5857662820726833, 0.5857662820726833, 0.6199423295174642], 
reward next is 0.3801, 
noisyNet noise sample is [array([-0.17913853], dtype=float32), 0.84530145]. 
=============================================
[2019-03-27 08:41:35,800] A3C_AGENT_WORKER-Thread-2 INFO:Local step 132500, global step 2123080: loss 85.2319
[2019-03-27 08:41:35,803] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 132500, global step 2123082: learning rate 0.0000
[2019-03-27 08:41:36,587] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:36,587] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:36,644] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run11
[2019-03-27 08:41:37,808] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:37,809] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:37,848] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run11
[2019-03-27 08:41:37,870] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:37,872] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:37,904] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run11
[2019-03-27 08:41:37,941] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:37,941] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:37,957] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run11
[2019-03-27 08:41:37,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:37,977] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:37,982] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run11
[2019-03-27 08:41:38,173] A3C_AGENT_WORKER-Thread-15 INFO:Local step 132500, global step 2124308: loss 109.5129
[2019-03-27 08:41:38,176] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 132500, global step 2124309: learning rate 0.0000
[2019-03-27 08:41:38,340] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:38,340] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:38,350] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run11
[2019-03-27 08:41:38,382] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 08:41:38,382] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:38,392] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run11
[2019-03-27 08:41:38,543] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133000, global step 2124476: loss 0.0016
[2019-03-27 08:41:38,552] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133000, global step 2124476: learning rate 0.0000
[2019-03-27 08:41:39,222] A3C_AGENT_WORKER-Thread-20 INFO:Local step 133500, global step 2124841: loss 0.2367
[2019-03-27 08:41:39,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 133500, global step 2124844: learning rate 0.0000
[2019-03-27 08:41:39,432] A3C_AGENT_WORKER-Thread-10 INFO:Local step 132500, global step 2124980: loss 96.9337
[2019-03-27 08:41:39,433] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 132500, global step 2124980: learning rate 0.0000
[2019-03-27 08:41:39,464] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:41:39,465] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:41:39,465] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:39,466] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:41:39,467] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:41:39,468] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:39,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:39,468] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:41:39,469] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:41:39,471] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:39,471] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:41:39,485] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run86
[2019-03-27 08:41:39,508] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run86
[2019-03-27 08:41:39,528] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run86
[2019-03-27 08:41:39,529] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run86
[2019-03-27 08:41:39,543] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run86
[2019-03-27 08:41:53,238] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:41:53,239] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.13333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6085404044965721, 6.9112, 6.9112, 168.912956510431, 530031.9003612985, 530031.9003612985, 167385.5267321101]
[2019-03-27 08:41:53,240] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:41:53,243] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.173432e-27], sampled 0.9725972205516177
[2019-03-27 08:42:08,061] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:42:08,062] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.0, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892293630326681, 6.9112, 6.9112, 168.912956510431, 592707.8376502629, 592707.8376502629, 180811.781219762]
[2019-03-27 08:42:08,063] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:42:08,067] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.342302e-26], sampled 0.9294686737784734
[2019-03-27 08:42:16,315] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:42:16,317] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.96666666666667, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7924567285739148, 6.9112, 6.9112, 168.912956510431, 669370.6562928376, 669370.6562928376, 200385.5931676538]
[2019-03-27 08:42:16,319] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:42:16,323] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.5424400e-38 1.6849886e-23], sampled 0.7882969819455082
[2019-03-27 08:42:20,278] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:42:20,280] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6276330152555836, 6.911200000000001, 6.9112, 168.912956510431, 543689.7888835866, 543689.788883586, 170429.0453488868]
[2019-03-27 08:42:20,283] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:42:20,287] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.6181145e-26], sampled 0.969879305432756
[2019-03-27 08:42:35,658] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:42:35,660] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.81987091666667, 68.66555419333334, 1.0, 2.0, 0.7241658044086534, 0.0, 2.0, 0.0, 1.0, 1.0, 1.03, 6.992687435390101, 6.9112, 168.9117416012159, 1908945.854968021, 1851136.279520515, 390482.230570773]
[2019-03-27 08:42:35,662] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:42:35,666] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9918109e-01 2.2818440e-20 2.0822624e-18 1.2027541e-21 8.1891468e-04], sampled 0.11832965038485688
[2019-03-27 08:42:35,668] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1908945.854968021 W.
[2019-03-27 08:42:59,233] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:42:59,234] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.84840342666667, 86.34480009666667, 1.0, 1.0, 0.5491373833090534, 1.0, 1.0, 0.5491373833090534, 1.0, 2.0, 0.9536700323001164, 6.9112, 6.9112, 171.5212843490159, 2303692.365545446, 2303692.365545446, 450993.9393530249]
[2019-03-27 08:42:59,235] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:42:59,238] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.3117201e-26 5.1361536e-27 2.2921032e-26 2.6314690e-12], sampled 0.9166076254668487
[2019-03-27 08:42:59,239] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2303692.365545446 W.
[2019-03-27 08:43:09,167] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:43:09,167] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [33.2, 58.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9822571964545287, 6.9112, 6.9112, 168.912956510431, 795026.8367916627, 795026.8367916627, 242704.7682332242]
[2019-03-27 08:43:09,169] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:43:09,174] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 3.3296777e-33 6.2419490e-35 9.6678033e-33 2.1564791e-18], sampled 0.358027952808439
[2019-03-27 08:43:31,731] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.076703504]
[2019-03-27 08:43:31,732] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.37926883, 86.32767786, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7181586240179951, 6.9112, 6.9112, 168.912956510431, 611434.79168547, 611434.79168547, 186015.71514911]
[2019-03-27 08:43:31,733] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:43:31,735] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.3087576e-26], sampled 0.8594688107008903
[2019-03-27 08:43:36,005] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7398.1705 3104924518.2184 1845.0000
[2019-03-27 08:43:36,124] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7032.6647 3187516854.2778 2381.0000
[2019-03-27 08:43:36,338] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8081.4023 2938466300.9597 1244.0000
[2019-03-27 08:43:36,351] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7268.9149 3320480024.4356 2156.0000
[2019-03-27 08:43:36,424] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.1225 2990555403.5467 1525.0000
[2019-03-27 08:43:37,442] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2125000, evaluation results [2125000.0, 7268.914875301509, 3320480024.4355836, 2156.0, 7398.170525041901, 3104924518.218375, 1845.0, 8081.402323319952, 2938466300.9597244, 1244.0, 7032.664696278638, 3187516854.277754, 2381.0, 7922.1225172336535, 2990555403.5467243, 1525.0]
[2019-03-27 08:43:37,767] A3C_AGENT_WORKER-Thread-19 INFO:Local step 132500, global step 2125155: loss 105.4170
[2019-03-27 08:43:37,768] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 132500, global step 2125155: learning rate 0.0000
[2019-03-27 08:43:37,895] A3C_AGENT_WORKER-Thread-16 INFO:Local step 132500, global step 2125217: loss 102.6204
[2019-03-27 08:43:37,898] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 132500, global step 2125219: learning rate 0.0000
[2019-03-27 08:43:37,908] A3C_AGENT_WORKER-Thread-17 INFO:Local step 132500, global step 2125224: loss 104.0003
[2019-03-27 08:43:37,910] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 132500, global step 2125224: learning rate 0.0000
[2019-03-27 08:43:38,068] A3C_AGENT_WORKER-Thread-18 INFO:Local step 132500, global step 2125296: loss 112.5186
[2019-03-27 08:43:38,070] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 132500, global step 2125297: learning rate 0.0000
[2019-03-27 08:43:38,077] A3C_AGENT_WORKER-Thread-3 INFO:Local step 132500, global step 2125300: loss 106.9869
[2019-03-27 08:43:38,086] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 132500, global step 2125303: learning rate 0.0000
[2019-03-27 08:43:40,526] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133000, global step 2126444: loss 0.0029
[2019-03-27 08:43:40,528] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133000, global step 2126444: learning rate 0.0000
[2019-03-27 08:43:42,200] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133000, global step 2127232: loss 0.0013
[2019-03-27 08:43:42,205] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133000, global step 2127234: learning rate 0.0000
[2019-03-27 08:43:44,186] A3C_AGENT_WORKER-Thread-22 INFO:Local step 133500, global step 2128298: loss 0.2534
[2019-03-27 08:43:44,187] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 133500, global step 2128298: learning rate 0.0000
[2019-03-27 08:43:44,756] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134000, global step 2128625: loss 0.0189
[2019-03-27 08:43:44,757] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134000, global step 2128625: learning rate 0.0000
[2019-03-27 08:43:44,943] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133000, global step 2128735: loss 0.0062
[2019-03-27 08:43:44,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133000, global step 2128737: learning rate 0.0000
[2019-03-27 08:43:46,240] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133000, global step 2129407: loss 0.0019
[2019-03-27 08:43:46,243] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133000, global step 2129407: learning rate 0.0000
[2019-03-27 08:43:48,037] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133000, global step 2130245: loss 0.0012
[2019-03-27 08:43:48,038] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133000, global step 2130245: learning rate 0.0000
[2019-03-27 08:43:48,136] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 6.6696318e-36 2.8784697e-37 2.8521528e-35 3.0014894e-17], sum to 1.0000
[2019-03-27 08:43:48,144] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6630
[2019-03-27 08:43:48,148] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.85, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4590225643547137, 6.9112, 6.9112, 168.912956510431, 410050.3107986607, 410050.3107986607, 146925.0217591359], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 426600.0000, 
sim time next is 427200.0000, 
raw observation next is [19.8, 85.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4570278152561281, 6.9112, 6.9112, 168.912956510431, 408293.7364843456, 408293.7364843456, 146698.408922395], 
processed observation next is [1.0, 0.9565217391304348, 0.13744075829383895, 0.8533333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.33783879909283915, 0.0, 0.0, 0.8294399451523027, 0.1134149268012071, 0.1134149268012071, 0.21895284913790297], 
reward next is 0.7810, 
noisyNet noise sample is [array([0.7241146], dtype=float32), -0.15362607]. 
=============================================
[2019-03-27 08:43:51,955] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133000, global step 2132077: loss 0.0044
[2019-03-27 08:43:51,958] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133000, global step 2132078: learning rate 0.0000
[2019-03-27 08:43:52,159] A3C_AGENT_WORKER-Thread-9 INFO:Local step 133500, global step 2132173: loss 0.2215
[2019-03-27 08:43:52,163] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 133500, global step 2132175: learning rate 0.0000
[2019-03-27 08:43:53,659] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134000, global step 2132878: loss 0.0131
[2019-03-27 08:43:53,661] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134000, global step 2132878: learning rate 0.0000
[2019-03-27 08:43:53,993] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133000, global step 2133034: loss 0.0029
[2019-03-27 08:43:53,995] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133000, global step 2133035: learning rate 0.0000
[2019-03-27 08:43:54,407] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133000, global step 2133228: loss 0.0027
[2019-03-27 08:43:54,410] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133000, global step 2133228: learning rate 0.0000
[2019-03-27 08:43:54,535] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133000, global step 2133287: loss 0.0011
[2019-03-27 08:43:54,540] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133000, global step 2133287: learning rate 0.0000
[2019-03-27 08:43:54,551] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133000, global step 2133295: loss 0.0012
[2019-03-27 08:43:54,554] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133000, global step 2133296: learning rate 0.0000
[2019-03-27 08:43:54,645] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133000, global step 2133336: loss 0.0011
[2019-03-27 08:43:54,647] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133000, global step 2133336: learning rate 0.0000
[2019-03-27 08:43:54,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133000, global step 2133362: loss 0.0011
[2019-03-27 08:43:54,712] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133000, global step 2133362: learning rate 0.0000
[2019-03-27 08:43:57,146] A3C_AGENT_WORKER-Thread-11 INFO:Local step 133500, global step 2134504: loss 0.1943
[2019-03-27 08:43:57,151] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 133500, global step 2134505: learning rate 0.0000
[2019-03-27 08:43:58,756] A3C_AGENT_WORKER-Thread-12 INFO:Local step 133500, global step 2135253: loss 0.1669
[2019-03-27 08:43:58,759] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 133500, global step 2135255: learning rate 0.0000
[2019-03-27 08:44:01,191] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8337787e-26], sum to 1.0000
[2019-03-27 08:44:01,203] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.3787
[2019-03-27 08:44:01,213] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.2, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5494241933914591, 6.9112, 6.9112, 168.912956510431, 481904.677424536, 481904.677424536, 158650.8410666224], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 910800.0000, 
sim time next is 911400.0000, 
raw observation next is [24.33333333333334, 69.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5508623148532761, 6.911199999999999, 6.9112, 168.912956510431, 483001.4010990513, 483001.401099052, 158854.6108599663], 
processed observation next is [0.0, 0.5652173913043478, 0.35229067930489766, 0.6933333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4522711156747269, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13416705586084757, 0.13416705586084776, 0.23709643411935272], 
reward next is 0.7629, 
noisyNet noise sample is [array([-0.48505846], dtype=float32), -1.4156729]. 
=============================================
[2019-03-27 08:44:01,247] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134000, global step 2136421: loss 0.0393
[2019-03-27 08:44:01,248] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134000, global step 2136421: learning rate 0.0000
[2019-03-27 08:44:01,901] A3C_AGENT_WORKER-Thread-13 INFO:Local step 134500, global step 2136729: loss 9.1512
[2019-03-27 08:44:01,907] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 134500, global step 2136729: learning rate 0.0000
[2019-03-27 08:44:02,033] A3C_AGENT_WORKER-Thread-21 INFO:Local step 133500, global step 2136788: loss 0.1312
[2019-03-27 08:44:02,034] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 133500, global step 2136788: learning rate 0.0000
[2019-03-27 08:44:03,474] A3C_AGENT_WORKER-Thread-14 INFO:Local step 133500, global step 2137465: loss 0.1404
[2019-03-27 08:44:03,476] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 133500, global step 2137466: learning rate 0.0000
[2019-03-27 08:44:05,059] A3C_AGENT_WORKER-Thread-2 INFO:Local step 133500, global step 2138204: loss 0.1433
[2019-03-27 08:44:05,060] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 133500, global step 2138204: learning rate 0.0000
[2019-03-27 08:44:06,279] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.6978587e-01 2.1475006e-19 2.6526735e-16 8.5217568e-21 3.0214155e-02], sum to 1.0000
[2019-03-27 08:44:06,287] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.7654
[2019-03-27 08:44:06,291] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1032138.163945605 W.
[2019-03-27 08:44:06,294] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [26.0, 48.0, 1.0, 2.0, 0.6296065250033993, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1032138.163945605, 1032138.163945605, 222103.6319606201], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 741600.0000, 
sim time next is 742200.0000, 
raw observation next is [25.91666666666667, 48.16666666666666, 1.0, 2.0, 0.611447474215871, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1003030.436615776, 1003030.436615775, 218083.4304451043], 
processed observation next is [1.0, 0.6086956521739131, 0.4273301737756717, 0.4816666666666666, 1.0, 1.0, 0.5318644267661096, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.27861956572660446, 0.2786195657266042, 0.3254976573807527], 
reward next is 0.6745, 
noisyNet noise sample is [array([0.5414926], dtype=float32), -0.32626748]. 
=============================================
[2019-03-27 08:44:08,309] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 5.727904e-38 4.915861e-25], sum to 1.0000
[2019-03-27 08:44:08,316] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3274
[2019-03-27 08:44:08,320] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.6, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5237419961022112, 6.9112, 6.9112, 168.912956510431, 461785.5987357184, 461785.5987357184, 155110.8440276092], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 808200.0000, 
sim time next is 808800.0000, 
raw observation next is [22.76666666666667, 75.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5236056378538033, 6.9112, 6.9112, 168.912956510431, 461659.3873965534, 461659.3873965534, 155093.1851059447], 
processed observation next is [0.0, 0.34782608695652173, 0.2780410742496052, 0.7533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.41903126567536986, 0.0, 0.0, 0.8294399451523027, 0.12823871872126483, 0.12823871872126483, 0.2314823658297682], 
reward next is 0.7685, 
noisyNet noise sample is [array([0.05077567], dtype=float32), 0.20058282]. 
=============================================
[2019-03-27 08:44:08,618] A3C_AGENT_WORKER-Thread-15 INFO:Local step 133500, global step 2139988: loss 0.2121
[2019-03-27 08:44:08,620] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 133500, global step 2139988: learning rate 0.0000
[2019-03-27 08:44:09,070] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134000, global step 2140192: loss 0.0056
[2019-03-27 08:44:09,074] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134000, global step 2140193: learning rate 0.0000
[2019-03-27 08:44:10,635] A3C_AGENT_WORKER-Thread-20 INFO:Local step 134500, global step 2140928: loss 8.8190
[2019-03-27 08:44:10,641] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 134500, global step 2140934: learning rate 0.0000
[2019-03-27 08:44:10,787] A3C_AGENT_WORKER-Thread-10 INFO:Local step 133500, global step 2140997: loss 0.1308
[2019-03-27 08:44:10,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 133500, global step 2140998: learning rate 0.0000
[2019-03-27 08:44:11,147] A3C_AGENT_WORKER-Thread-16 INFO:Local step 133500, global step 2141167: loss 0.1052
[2019-03-27 08:44:11,149] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 133500, global step 2141168: learning rate 0.0000
[2019-03-27 08:44:11,223] A3C_AGENT_WORKER-Thread-19 INFO:Local step 133500, global step 2141205: loss 0.1039
[2019-03-27 08:44:11,225] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 133500, global step 2141205: learning rate 0.0000
[2019-03-27 08:44:11,244] A3C_AGENT_WORKER-Thread-17 INFO:Local step 133500, global step 2141213: loss 0.1049
[2019-03-27 08:44:11,249] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 133500, global step 2141215: learning rate 0.0000
[2019-03-27 08:44:11,371] A3C_AGENT_WORKER-Thread-3 INFO:Local step 133500, global step 2141272: loss 0.1251
[2019-03-27 08:44:11,375] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 133500, global step 2141274: learning rate 0.0000
[2019-03-27 08:44:11,430] A3C_AGENT_WORKER-Thread-18 INFO:Local step 133500, global step 2141299: loss 0.1231
[2019-03-27 08:44:11,431] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 133500, global step 2141299: learning rate 0.0000
[2019-03-27 08:44:13,678] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 4.4550016e-35 4.4708300e-37 3.1830585e-34 8.5495910e-19], sum to 1.0000
[2019-03-27 08:44:13,683] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2584
[2019-03-27 08:44:13,687] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.53333333333333, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4696521806839055, 6.911199999999999, 6.9112, 168.912956510431, 419011.686924542, 419011.6869245426, 148175.6030738199], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 765600.0000, 
sim time next is 766200.0000, 
raw observation next is [20.46666666666667, 81.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4706081578773489, 6.911200000000001, 6.9112, 168.912956510431, 419868.8159036694, 419868.8159036688, 148286.3379984931], 
processed observation next is [1.0, 0.8695652173913043, 0.16903633491311232, 0.815, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.3544001925333523, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11663022663990817, 0.116630226639908, 0.22132289253506435], 
reward next is 0.7787, 
noisyNet noise sample is [array([0.18453261], dtype=float32), 0.2712963]. 
=============================================
[2019-03-27 08:44:13,857] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134000, global step 2142514: loss 0.0064
[2019-03-27 08:44:13,859] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134000, global step 2142516: learning rate 0.0000
[2019-03-27 08:44:14,446] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.5957297e-37 0.0000000e+00 1.4616802e-35 1.7310377e-23], sum to 1.0000
[2019-03-27 08:44:14,453] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9452
[2019-03-27 08:44:14,456] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5327682382793294, 6.911199999999999, 6.9112, 168.912956510431, 468681.2068542926, 468681.2068542932, 156342.8635673564], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 898200.0000, 
sim time next is 898800.0000, 
raw observation next is [22.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5332130436903474, 6.9112, 6.9112, 168.912956510431, 469072.5909474737, 469072.5909474737, 156402.3381152526], 
processed observation next is [0.0, 0.391304347826087, 0.2654028436018958, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4307476142565212, 0.0, 0.0, 0.8294399451523027, 0.1302979419298538, 0.1302979419298538, 0.23343632554515314], 
reward next is 0.7666, 
noisyNet noise sample is [array([0.83282226], dtype=float32), -0.29255098]. 
=============================================
[2019-03-27 08:44:15,226] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134000, global step 2143203: loss 0.0149
[2019-03-27 08:44:15,232] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134000, global step 2143206: learning rate 0.0000
[2019-03-27 08:44:16,122] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.7150904e-37 1.4524297e-22], sum to 1.0000
[2019-03-27 08:44:16,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3619
[2019-03-27 08:44:16,137] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.15, 77.16666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5605001910699381, 6.9112, 6.9112, 168.912956510431, 491231.2380670637, 491231.2380670637, 160209.5712127585], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 841800.0000, 
sim time next is 842400.0000, 
raw observation next is [23.0, 78.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5613115436100753, 6.911200000000001, 6.9112, 168.912956510431, 492077.1015525088, 492077.1015525082, 160320.529328531], 
processed observation next is [0.0, 0.782608695652174, 0.28909952606635075, 0.78, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4650140775732625, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13668808376458577, 0.1366880837645856, 0.23928437213213583], 
reward next is 0.7607, 
noisyNet noise sample is [array([-0.5118882], dtype=float32), 1.2986475]. 
=============================================
[2019-03-27 08:44:17,603] A3C_AGENT_WORKER-Thread-22 INFO:Local step 134500, global step 2144456: loss 8.3176
[2019-03-27 08:44:17,606] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 134500, global step 2144456: learning rate 0.0000
[2019-03-27 08:44:17,740] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.0990985e-37 0.0000000e+00 4.3937994e-37 4.7494661e-24], sum to 1.0000
[2019-03-27 08:44:17,752] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4710
[2019-03-27 08:44:17,757] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5333679419784662, 6.911199999999999, 6.9112, 168.912956510431, 469208.8858034216, 469208.8858034223, 156423.0619590638], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 902400.0000, 
sim time next is 903000.0000, 
raw observation next is [22.5, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5337671925779909, 6.9112, 6.9112, 168.912956510431, 469560.1879819987, 469560.1879819987, 156476.507466713], 
processed observation next is [0.0, 0.43478260869565216, 0.2654028436018958, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4314234055829157, 0.0, 0.0, 0.8294399451523027, 0.1304333855505552, 0.1304333855505552, 0.2335470260697209], 
reward next is 0.7665, 
noisyNet noise sample is [array([-0.64281297], dtype=float32), -0.8847132]. 
=============================================
[2019-03-27 08:44:17,772] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[77.75859 ]
 [77.72284 ]
 [77.676414]
 [77.621185]
 [77.50385 ]], R is [[77.78747559]
 [77.77613068]
 [77.76493835]
 [77.75386047]
 [77.74285889]].
[2019-03-27 08:44:18,042] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135000, global step 2144661: loss 0.2062
[2019-03-27 08:44:18,044] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135000, global step 2144662: learning rate 0.0000
[2019-03-27 08:44:18,267] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134000, global step 2144762: loss 0.0126
[2019-03-27 08:44:18,269] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134000, global step 2144763: learning rate 0.0000
[2019-03-27 08:44:19,667] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134000, global step 2145459: loss 0.0142
[2019-03-27 08:44:19,672] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134000, global step 2145461: learning rate 0.0000
[2019-03-27 08:44:21,024] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134000, global step 2146207: loss 0.0089
[2019-03-27 08:44:21,027] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134000, global step 2146209: learning rate 0.0000
[2019-03-27 08:44:21,097] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.0452263e-37 0.0000000e+00 4.8901168e-36 1.3511873e-22], sum to 1.0000
[2019-03-27 08:44:21,107] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7181
[2019-03-27 08:44:21,114] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.45, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4934729678595544, 6.9112, 6.9112, 168.912956510431, 437923.1044617129, 437923.1044617129, 151144.3445096104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 799800.0000, 
sim time next is 800400.0000, 
raw observation next is [20.6, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4957588152689543, 6.9112, 6.9112, 168.912956510431, 439714.3510270267, 439714.3510270267, 151437.0546698155], 
processed observation next is [0.0, 0.2608695652173913, 0.17535545023696694, 0.8666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.38507172593774913, 0.0, 0.0, 0.8294399451523027, 0.1221428752852852, 0.1221428752852852, 0.22602545473106792], 
reward next is 0.7740, 
noisyNet noise sample is [array([1.3180482], dtype=float32), -0.4404458]. 
=============================================
[2019-03-27 08:44:23,995] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134000, global step 2147989: loss 0.0026
[2019-03-27 08:44:23,996] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134000, global step 2147989: learning rate 0.0000
[2019-03-27 08:44:24,426] A3C_AGENT_WORKER-Thread-9 INFO:Local step 134500, global step 2148266: loss 7.9418
[2019-03-27 08:44:24,427] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 134500, global step 2148266: learning rate 0.0000
[2019-03-27 08:44:24,437] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 1.0191855e-32 1.0072458e-33 2.6867624e-33 1.9610837e-13], sum to 1.0000
[2019-03-27 08:44:24,445] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.5258
[2019-03-27 08:44:24,449] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.75, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6334322134584884, 6.911199999999999, 6.9112, 168.912956510431, 548965.748357719, 548965.7483577196, 171356.574119861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1017000.0000, 
sim time next is 1017600.0000, 
raw observation next is [21.76666666666667, 96.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6319469320381428, 6.9112, 6.9112, 168.912956510431, 547699.3542263196, 547699.3542263196, 171117.1270697522], 
processed observation next is [1.0, 0.782608695652174, 0.23064770932069528, 0.9633333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5511547951684668, 0.0, 0.0, 0.8294399451523027, 0.152138709507311, 0.152138709507311, 0.2553986971190331], 
reward next is 0.7446, 
noisyNet noise sample is [array([0.59174955], dtype=float32), -0.7928097]. 
=============================================
[2019-03-27 08:44:25,568] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135000, global step 2148963: loss 0.1718
[2019-03-27 08:44:25,573] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135000, global step 2148963: learning rate 0.0000
[2019-03-27 08:44:25,694] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134000, global step 2149022: loss 0.0203
[2019-03-27 08:44:25,696] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134000, global step 2149023: learning rate 0.0000
[2019-03-27 08:44:25,978] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134000, global step 2149154: loss 0.0169
[2019-03-27 08:44:25,980] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134000, global step 2149154: learning rate 0.0000
[2019-03-27 08:44:26,074] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134000, global step 2149207: loss 0.0184
[2019-03-27 08:44:26,078] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134000, global step 2149209: learning rate 0.0000
[2019-03-27 08:44:26,082] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134000, global step 2149212: loss 0.0155
[2019-03-27 08:44:26,085] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134000, global step 2149213: learning rate 0.0000
[2019-03-27 08:44:26,156] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134000, global step 2149258: loss 0.0220
[2019-03-27 08:44:26,161] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134000, global step 2149258: learning rate 0.0000
[2019-03-27 08:44:26,290] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134000, global step 2149337: loss 0.0161
[2019-03-27 08:44:26,291] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134000, global step 2149337: learning rate 0.0000
[2019-03-27 08:44:27,145] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.3953900e-01 4.0446274e-22 1.5173481e-19 2.7566170e-23 8.6046106e-01], sum to 1.0000
[2019-03-27 08:44:27,153] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.9705
[2019-03-27 08:44:27,159] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.3, 58.66666666666667, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1963129092474134, 6.911200000000001, 6.9112, 170.5573041426782, 508413.5084962913, 508413.5084962907, 231838.5777899119], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1185600.0000, 
sim time next is 1186200.0000, 
raw observation next is [27.15, 59.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 2.0, 0.1936459599091312, 6.911200000000001, 6.9112, 170.5573041426782, 501844.085930512, 501844.0859305114, 230904.4968403739], 
processed observation next is [1.0, 0.7391304347826086, 0.485781990521327, 0.595, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.01664141452333073, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.13940113498069778, 0.13940113498069762, 0.3446335773736924], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.0444638], dtype=float32), -1.3145065]. 
=============================================
[2019-03-27 08:44:27,377] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 08:44:27,381] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:44:27,381] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:44:27,385] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:44:27,386] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:44:27,387] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:44:27,389] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:44:27,389] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:44:27,390] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:44:27,391] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:44:27,393] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:44:27,422] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run87
[2019-03-27 08:44:27,445] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run87
[2019-03-27 08:44:27,467] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run87
[2019-03-27 08:44:27,468] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run87
[2019-03-27 08:44:27,484] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run87
[2019-03-27 08:44:29,412] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:44:29,413] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.46666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541124856251331, 6.9112, 6.9112, 168.912956510431, 640652.8635694357, 640652.8635694357, 192801.4422040166]
[2019-03-27 08:44:29,416] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:44:29,419] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.673356e-26], sampled 0.667687194428036
[2019-03-27 08:44:39,413] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:44:39,416] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [24.371313205, 54.27382826, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7527260226298443, 6.9112, 6.9112, 168.912956510431, 674182.7308108519, 674182.7308108519, 191541.018723149]
[2019-03-27 08:44:39,418] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:44:39,421] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.0939149e-36 1.1953875e-38 3.0896351e-35 5.9663878e-20], sampled 0.28860682331661713
[2019-03-27 08:44:45,938] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:44:45,939] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.1, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4660176218285882, 6.911200000000001, 6.9112, 168.912956510431, 416450.4133599662, 416450.4133599656, 147712.4512211637]
[2019-03-27 08:44:45,940] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:44:45,945] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.3519864e-37 0.0000000e+00 1.8906952e-36 2.4773966e-21], sampled 0.046266746586520746
[2019-03-27 08:46:01,431] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:46:01,432] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.92918214, 59.20357398666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7342227447278117, 6.911200000000001, 6.9112, 168.912956510431, 625692.5487410538, 625692.5487410532, 189013.7604153784]
[2019-03-27 08:46:01,433] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:46:01,435] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 2.0660294e-36 0.0000000e+00 1.4803322e-35 3.4889912e-19], sampled 0.1302317264695344
[2019-03-27 08:46:11,228] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:46:11,231] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.3, 81.0, 1.0, 2.0, 0.8169364279693762, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1141779.791192395, 1141779.791192396, 248113.497045366]
[2019-03-27 08:46:11,232] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:46:11,235] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.98555124e-01 1.07901394e-19 6.99404832e-17 7.28213945e-21
 1.44489482e-03], sampled 0.3581015965388893
[2019-03-27 08:46:11,236] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1141779.791192395 W.
[2019-03-27 08:46:20,206] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07803634]
[2019-03-27 08:46:20,209] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.63333333333333, 66.5, 1.0, 1.0, 0.625781963026426, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9128136691972, 874505.4200629633, 874505.420062964, 205646.0362932226]
[2019-03-27 08:46:20,210] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:46:20,212] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 5.1712267e-27 5.8566832e-27 2.4504235e-27 5.0129517e-10], sampled 0.21517569273314296
[2019-03-27 08:46:20,214] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 874505.4200629633 W.
[2019-03-27 08:46:23,792] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7393.8013 3330553108.2640 1680.0000
[2019-03-27 08:46:23,982] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7982.9008 3005543252.5290 1205.0000
[2019-03-27 08:46:24,057] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7447.2463 3114378285.3397 1605.0000
[2019-03-27 08:46:24,068] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7169.8003 3194850330.2619 1865.0000
[2019-03-27 08:46:24,210] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8139.5358 2954178557.3261 997.0000
[2019-03-27 08:46:25,228] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2150000, evaluation results [2150000.0, 7393.801289834988, 3330553108.264042, 1680.0, 7447.2462797425615, 3114378285.3396626, 1605.0, 8139.535817914554, 2954178557.3260536, 997.0, 7169.800261953512, 3194850330.261924, 1865.0, 7982.900831794597, 3005543252.5290046, 1205.0]
[2019-03-27 08:46:26,423] A3C_AGENT_WORKER-Thread-11 INFO:Local step 134500, global step 2150566: loss 7.4965
[2019-03-27 08:46:26,424] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 134500, global step 2150568: learning rate 0.0000
[2019-03-27 08:46:26,661] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9999928e-01 2.3105622e-27 1.4950599e-25 2.7448537e-28 6.7719805e-07], sum to 1.0000
[2019-03-27 08:46:26,670] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.0147
[2019-03-27 08:46:26,673] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7894493563487136, 6.911199999999999, 6.9112, 168.912956510431, 662885.1596225568, 662885.1596225575, 199700.9024289722], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1735200.0000, 
sim time next is 1735800.0000, 
raw observation next is [24.58333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.54835120119339, 6.9112, 168.9097871286073, 1317675.861734228, 865667.3519325174, 256409.085231308], 
processed observation next is [1.0, 0.08695652173913043, 0.3641390205371251, 0.9400000000000002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.06371512011933902, 0.0, 0.829424382036599, 0.36602107270395223, 0.24046315331458815, 0.38270012721090746], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.5385479], dtype=float32), 0.31452328]. 
=============================================
[2019-03-27 08:46:27,450] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.1304693e-33 1.3356527e-32 1.9035518e-32 1.1959067e-13], sum to 1.0000
[2019-03-27 08:46:27,460] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.0361
[2019-03-27 08:46:27,468] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.61666666666667, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6319649442395094, 6.9112, 6.9112, 168.912956510431, 548170.3150592564, 548170.3150592564, 171114.0114868382], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1201800.0000, 
sim time next is 1202400.0000, 
raw observation next is [23.5, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6301939849261565, 6.9112, 6.9112, 168.912956510431, 546761.3378697922, 546761.3378697922, 170827.8564216586], 
processed observation next is [1.0, 0.9565217391304348, 0.31279620853080575, 0.82, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5490170547879958, 0.0, 0.0, 0.8294399451523027, 0.15187814940827563, 0.15187814940827563, 0.2549669498830725], 
reward next is 0.7450, 
noisyNet noise sample is [array([-1.8378339], dtype=float32), 0.52380943]. 
=============================================
[2019-03-27 08:46:27,979] A3C_AGENT_WORKER-Thread-12 INFO:Local step 134500, global step 2151294: loss 7.9529
[2019-03-27 08:46:27,985] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 134500, global step 2151294: learning rate 0.0000
[2019-03-27 08:46:28,024] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 2.3530950e-31 1.4306441e-28 2.6244863e-31 5.3993932e-12], sum to 1.0000
[2019-03-27 08:46:28,035] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5780
[2019-03-27 08:46:28,040] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.06666666666667, 97.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6543514988466458, 6.911200000000001, 6.9112, 168.912956510431, 564311.300097655, 564311.3000976543, 174815.6791246153], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1034400.0000, 
sim time next is 1035000.0000, 
raw observation next is [22.1, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6548948975354306, 6.9112, 6.9112, 168.912956510431, 564686.0933807458, 564686.0933807458, 174907.0575510617], 
processed observation next is [1.0, 1.0, 0.24644549763033188, 0.975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5791401189456471, 0.0, 0.0, 0.8294399451523027, 0.1568572481613183, 0.1568572481613183, 0.261055309777704], 
reward next is 0.7389, 
noisyNet noise sample is [array([-0.45574802], dtype=float32), -0.9653357]. 
=============================================
[2019-03-27 08:46:28,052] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[73.766495]
 [73.77408 ]
 [73.73163 ]
 [73.64786 ]
 [73.61441 ]], R is [[73.76330566]
 [73.76475525]
 [73.76644897]
 [73.76882935]
 [73.77334595]].
[2019-03-27 08:46:28,745] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999988e-01 6.9046542e-26 3.8249893e-24 3.5499702e-26 1.3243265e-07], sum to 1.0000
[2019-03-27 08:46:28,756] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8865
[2019-03-27 08:46:28,764] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 934089.7355568776 W.
[2019-03-27 08:46:28,775] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [21.6, 96.0, 1.0, 2.0, 0.6070028074622376, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 934089.7355568776, 934089.7355568776, 212489.6648092423], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1001400.0000, 
sim time next is 1002000.0000, 
raw observation next is [21.6, 96.0, 1.0, 2.0, 0.5820921919214419, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 900300.282358302, 900300.2823583026, 207879.0554370047], 
processed observation next is [1.0, 0.6086956521739131, 0.22274881516587688, 0.96, 1.0, 1.0, 0.49649661677282153, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.25008341176619503, 0.2500834117661952, 0.3102672469209025], 
reward next is 0.6897, 
noisyNet noise sample is [array([0.77372164], dtype=float32), 0.32331675]. 
=============================================
[2019-03-27 08:46:28,784] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[57.253124]
 [60.89227 ]
 [63.967705]
 [68.56815 ]
 [68.969   ]], R is [[56.36893463]
 [55.80524445]
 [55.83337784]
 [55.93941116]
 [56.00831223]].
[2019-03-27 08:46:29,115] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9676347e-01 7.4726847e-22 9.6300398e-19 2.3984554e-23 3.2365294e-03], sum to 1.0000
[2019-03-27 08:46:29,123] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1536
[2019-03-27 08:46:29,128] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 97.66666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.634403261078867, 6.911199999999999, 6.9112, 168.912956510431, 547516.2493092454, 547516.249309246, 171535.9129471114], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1012800.0000, 
sim time next is 1013400.0000, 
raw observation next is [21.7, 97.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.630394560183549, 6.911200000000001, 6.9112, 168.912956510431, 545365.695659187, 545365.6956591863, 170879.031237696], 
processed observation next is [1.0, 0.7391304347826086, 0.2274881516587678, 0.975, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5492616587604255, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15149047101644084, 0.15149047101644064, 0.25504333020551645], 
reward next is 0.7450, 
noisyNet noise sample is [array([-0.36342806], dtype=float32), 0.09092234]. 
=============================================
[2019-03-27 08:46:29,995] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [9.4197220e-01 1.7149375e-21 4.7433456e-18 5.4892571e-24 5.8027852e-02], sum to 1.0000
[2019-03-27 08:46:30,003] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0775
[2019-03-27 08:46:30,012] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1179876.196233139 W.
[2019-03-27 08:46:30,018] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 67.5, 1.0, 2.0, 0.2628995472644088, 1.0, 2.0, 0.2628995472644088, 1.0, 2.0, 0.4583230841256858, 6.9112, 6.9112, 170.5573041426782, 1179876.196233139, 1179876.196233139, 297654.3097421921], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1164600.0000, 
sim time next is 1165200.0000, 
raw observation next is [26.1, 67.0, 1.0, 2.0, 0.381584645661009, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6712428388114701, 6.911199999999999, 6.9112, 168.912956510431, 1157503.400703926, 1157503.400703927, 259347.163644743], 
processed observation next is [1.0, 0.4782608695652174, 0.4360189573459717, 0.67, 1.0, 1.0, 0.254921259832541, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.5990766326969147, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.32152872241775726, 0.3215287224177575, 0.38708531887275077], 
reward next is 0.6129, 
noisyNet noise sample is [array([-1.0350978], dtype=float32), 0.9975442]. 
=============================================
[2019-03-27 08:46:30,431] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135000, global step 2152404: loss 0.1516
[2019-03-27 08:46:30,432] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135000, global step 2152405: learning rate 0.0000
[2019-03-27 08:46:31,117] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [3.2765549e-01 8.1492241e-23 1.0857605e-19 4.1045372e-24 6.7234451e-01], sum to 1.0000
[2019-03-27 08:46:31,128] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0713
[2019-03-27 08:46:31,136] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1349367.952902066 W.
[2019-03-27 08:46:31,144] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [27.6, 57.33333333333334, 1.0, 2.0, 0.2995962066289588, 1.0, 2.0, 0.2995962066289588, 1.0, 2.0, 0.5234975974469197, 6.9112, 6.9112, 170.5573041426782, 1349367.952902066, 1349367.952902066, 313022.7749569517], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 1183200.0000, 
sim time next is 1183800.0000, 
raw observation next is [27.6, 57.16666666666666, 1.0, 2.0, 0.4459311609107046, 1.0, 2.0, 0.4459311609107046, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1349330.995866964, 1349330.995866964, 295995.5229277802], 
processed observation next is [1.0, 0.6956521739130435, 0.5071090047393366, 0.5716666666666665, 1.0, 1.0, 0.332447181820126, 1.0, 1.0, 0.332447181820126, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.37481416551860114, 0.37481416551860114, 0.44178436257877646], 
reward next is 0.5582, 
noisyNet noise sample is [array([0.77598864], dtype=float32), -2.2915545]. 
=============================================
[2019-03-27 08:46:31,228] A3C_AGENT_WORKER-Thread-13 INFO:Local step 135500, global step 2152779: loss 0.0022
[2019-03-27 08:46:31,233] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 135500, global step 2152779: learning rate 0.0000
[2019-03-27 08:46:31,283] A3C_AGENT_WORKER-Thread-21 INFO:Local step 134500, global step 2152805: loss 8.7843
[2019-03-27 08:46:31,287] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 134500, global step 2152805: learning rate 0.0000
[2019-03-27 08:46:32,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.3315400e-04 5.7179319e-22 6.8833574e-18 2.2158050e-24 9.9986684e-01], sum to 1.0000
[2019-03-27 08:46:32,479] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.0933
[2019-03-27 08:46:32,488] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.93333333333333, 92.0, 1.0, 2.0, 0.2894333395642295, 1.0, 2.0, 0.2894333395642295, 1.0, 2.0, 0.4857489343365062, 6.9112, 6.9112, 170.5573041426782, 1213601.735741725, 1213601.735741725, 298499.1380772512], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1676400.0000, 
sim time next is 1677000.0000, 
raw observation next is [25.06666666666667, 91.5, 1.0, 2.0, 0.2948412635348264, 1.0, 2.0, 0.2948412635348264, 1.0, 2.0, 0.495340989339151, 6.9112, 6.9112, 170.5573041426782, 1236290.379895723, 1236290.379895723, 300668.7428971879], 
processed observation next is [1.0, 0.391304347826087, 0.38704581358609813, 0.915, 1.0, 1.0, 0.15041116088533305, 1.0, 1.0, 0.15041116088533305, 1.0, 1.0, 0.3845621821209158, 0.0, 0.0, 0.8375144448122397, 0.3434139944154786, 0.3434139944154786, 0.44875931775699685], 
reward next is 0.5512, 
noisyNet noise sample is [array([1.1190425], dtype=float32), 0.2187057]. 
=============================================
[2019-03-27 08:46:32,521] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[64.149445]
 [63.707397]
 [62.658817]
 [60.92006 ]
 [58.710907]], R is [[64.81421661]
 [64.72055817]
 [64.63204193]
 [64.55047607]
 [64.46736908]].
[2019-03-27 08:46:32,699] A3C_AGENT_WORKER-Thread-14 INFO:Local step 134500, global step 2153468: loss 8.5494
[2019-03-27 08:46:32,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 134500, global step 2153469: learning rate 0.0000
[2019-03-27 08:46:34,286] A3C_AGENT_WORKER-Thread-2 INFO:Local step 134500, global step 2154208: loss 7.7668
[2019-03-27 08:46:34,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 134500, global step 2154209: learning rate 0.0000
[2019-03-27 08:46:38,240] A3C_AGENT_WORKER-Thread-15 INFO:Local step 134500, global step 2156055: loss 8.1999
[2019-03-27 08:46:38,243] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 134500, global step 2156055: learning rate 0.0000
[2019-03-27 08:46:38,546] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135000, global step 2156198: loss 0.2016
[2019-03-27 08:46:38,549] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135000, global step 2156199: learning rate 0.0000
[2019-03-27 08:46:39,731] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.4135624e-38 1.9492033e-20], sum to 1.0000
[2019-03-27 08:46:39,738] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.1915
[2019-03-27 08:46:39,746] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.4, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6195539139947321, 6.9112, 6.9112, 168.912956510431, 538040.5242832855, 538040.5242832855, 169129.7007037265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1192800.0000, 
sim time next is 1193400.0000, 
raw observation next is [25.25, 70.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6211252331110075, 6.9112, 6.9112, 168.912956510431, 539337.7304043786, 539337.7304043786, 169378.4559254661], 
processed observation next is [1.0, 0.8260869565217391, 0.39573459715639814, 0.7, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5379576013548872, 0.0, 0.0, 0.8294399451523027, 0.1498160362234385, 0.1498160362234385, 0.2528036655603972], 
reward next is 0.7472, 
noisyNet noise sample is [array([1.1461138], dtype=float32), -1.0454354]. 
=============================================
[2019-03-27 08:46:40,213] A3C_AGENT_WORKER-Thread-10 INFO:Local step 134500, global step 2156975: loss 8.1227
[2019-03-27 08:46:40,216] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 134500, global step 2156977: learning rate 0.0000
[2019-03-27 08:46:40,277] A3C_AGENT_WORKER-Thread-20 INFO:Local step 135500, global step 2157000: loss 0.0035
[2019-03-27 08:46:40,279] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 135500, global step 2157000: learning rate 0.0000
[2019-03-27 08:46:40,587] A3C_AGENT_WORKER-Thread-17 INFO:Local step 134500, global step 2157145: loss 7.7069
[2019-03-27 08:46:40,590] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 134500, global step 2157145: learning rate 0.0000
[2019-03-27 08:46:40,678] A3C_AGENT_WORKER-Thread-19 INFO:Local step 134500, global step 2157189: loss 7.9515
[2019-03-27 08:46:40,679] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 134500, global step 2157190: learning rate 0.0000
[2019-03-27 08:46:40,811] A3C_AGENT_WORKER-Thread-16 INFO:Local step 134500, global step 2157246: loss 7.5377
[2019-03-27 08:46:40,813] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 134500, global step 2157247: learning rate 0.0000
[2019-03-27 08:46:40,879] A3C_AGENT_WORKER-Thread-3 INFO:Local step 134500, global step 2157283: loss 7.6102
[2019-03-27 08:46:40,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 134500, global step 2157283: learning rate 0.0000
[2019-03-27 08:46:41,088] A3C_AGENT_WORKER-Thread-18 INFO:Local step 134500, global step 2157381: loss 7.4745
[2019-03-27 08:46:41,092] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 134500, global step 2157381: learning rate 0.0000
[2019-03-27 08:46:41,581] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 3.6707844e-34 3.7765411e-36 3.0903926e-33 4.4359139e-17], sum to 1.0000
[2019-03-27 08:46:41,587] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.2263
[2019-03-27 08:46:41,593] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 96.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.597172884762986, 6.9112, 6.9112, 168.912956510431, 520395.3048499784, 520395.3048499784, 165642.5687994323], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1477800.0000, 
sim time next is 1478400.0000, 
raw observation next is [21.13333333333333, 96.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5956716291767595, 6.9112, 6.9112, 168.912956510431, 519339.8942545966, 519339.8942545966, 165410.6495674691], 
processed observation next is [0.0, 0.08695652173913043, 0.20063191153238533, 0.9666666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5069166209472676, 0.0, 0.0, 0.8294399451523027, 0.14426108173738794, 0.14426108173738794, 0.24688156651861062], 
reward next is 0.7531, 
noisyNet noise sample is [array([0.03294198], dtype=float32), -1.0101051]. 
=============================================
[2019-03-27 08:46:43,516] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135000, global step 2158518: loss 0.3132
[2019-03-27 08:46:43,520] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135000, global step 2158521: learning rate 0.0000
[2019-03-27 08:46:44,942] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135000, global step 2159186: loss 0.3201
[2019-03-27 08:46:44,944] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135000, global step 2159186: learning rate 0.0000
[2019-03-27 08:46:45,981] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.2951161e-36 6.7016578e-38 9.6209225e-35 1.4146259e-18], sum to 1.0000
[2019-03-27 08:46:45,989] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4015
[2019-03-27 08:46:45,995] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7874806760243767, 6.9112, 6.9112, 168.912956510431, 661551.4432295044, 661551.4432295044, 199308.019183201], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2068800.0000, 
sim time next is 2069400.0000, 
raw observation next is [24.65, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7870086429542078, 6.911199999999999, 6.9112, 168.912956510431, 661211.2445657694, 661211.2445657701, 199213.5239338503], 
processed observation next is [0.0, 0.9565217391304348, 0.3672985781990521, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7402544426270827, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18366979015715817, 0.18366979015715837, 0.29733361781171685], 
reward next is 0.7027, 
noisyNet noise sample is [array([1.9043008], dtype=float32), 1.3605945]. 
=============================================
[2019-03-27 08:46:46,403] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.3618517e-33 1.8000264e-33 3.2275299e-33 7.9760756e-15], sum to 1.0000
[2019-03-27 08:46:46,410] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8297
[2019-03-27 08:46:46,416] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.43333333333333, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7793979119293686, 6.9112, 6.9112, 168.912956510431, 655661.7408489607, 655661.7408489607, 197696.3425977274], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2076000.0000, 
sim time next is 2076600.0000, 
raw observation next is [24.41666666666666, 94.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.779389744867293, 6.9112, 6.9112, 168.912956510431, 655613.2064257066, 655613.2064257066, 197693.9096637248], 
processed observation next is [0.0, 0.0, 0.35624012638230623, 0.9483333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7309631034966986, 0.0, 0.0, 0.8294399451523027, 0.18211477956269628, 0.18211477956269628, 0.2950655368115295], 
reward next is 0.7049, 
noisyNet noise sample is [array([0.6401041], dtype=float32), -0.51778007]. 
=============================================
[2019-03-27 08:46:47,689] A3C_AGENT_WORKER-Thread-22 INFO:Local step 135500, global step 2160452: loss 0.0334
[2019-03-27 08:46:47,693] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 135500, global step 2160454: learning rate 0.0000
[2019-03-27 08:46:48,393] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136000, global step 2160782: loss 0.0411
[2019-03-27 08:46:48,396] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136000, global step 2160782: learning rate 0.0000
[2019-03-27 08:46:48,416] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135000, global step 2160787: loss 0.2711
[2019-03-27 08:46:48,421] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135000, global step 2160787: learning rate 0.0000
[2019-03-27 08:46:49,600] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135000, global step 2161340: loss 0.2759
[2019-03-27 08:46:49,603] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135000, global step 2161341: learning rate 0.0000
[2019-03-27 08:46:50,929] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 5.1677349e-35 1.2375989e-37 2.4196963e-34 2.1463004e-20], sum to 1.0000
[2019-03-27 08:46:50,939] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4575
[2019-03-27 08:46:50,945] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 73.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7296946298475693, 6.9112, 6.9112, 168.912956510431, 618914.8134678677, 618914.8134678677, 188137.3494705246], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1431600.0000, 
sim time next is 1432200.0000, 
raw observation next is [27.0, 72.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.728562493462996, 6.9112, 6.9112, 168.912956510431, 618066.4080205412, 618066.4080205412, 187926.7225794476], 
processed observation next is [0.0, 0.5652173913043478, 0.4786729857819906, 0.7233333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6689786505646292, 0.0, 0.0, 0.8294399451523027, 0.1716851133390392, 0.1716851133390392, 0.28048764564096657], 
reward next is 0.7195, 
noisyNet noise sample is [array([-1.4743223], dtype=float32), -0.10943535]. 
=============================================
[2019-03-27 08:46:51,311] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135000, global step 2162140: loss 0.2895
[2019-03-27 08:46:51,313] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135000, global step 2162141: learning rate 0.0000
[2019-03-27 08:46:54,895] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.0915189e-30 7.6112563e-31 2.5963172e-30 1.3885545e-13], sum to 1.0000
[2019-03-27 08:46:54,905] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2809
[2019-03-27 08:46:54,910] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.9, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5649173350387993, 6.9112, 6.9112, 168.912956510431, 494165.2074130083, 494165.2074130083, 160860.8124507396], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1575000.0000, 
sim time next is 1575600.0000, 
raw observation next is [22.0, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5686307254572384, 6.9112, 6.9112, 168.912956510431, 497034.0225844909, 497034.0225844909, 161401.0810661423], 
processed observation next is [1.0, 0.21739130434782608, 0.2417061611374408, 0.8833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4739399090941931, 0.0, 0.0, 0.8294399451523027, 0.13806500627346968, 0.13806500627346968, 0.24089713591961537], 
reward next is 0.7591, 
noisyNet noise sample is [array([-1.629212], dtype=float32), -2.0820308]. 
=============================================
[2019-03-27 08:46:55,415] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135000, global step 2164061: loss 0.2756
[2019-03-27 08:46:55,418] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135000, global step 2164061: learning rate 0.0000
[2019-03-27 08:46:55,898] A3C_AGENT_WORKER-Thread-9 INFO:Local step 135500, global step 2164287: loss 0.0092
[2019-03-27 08:46:55,902] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 135500, global step 2164288: learning rate 0.0000
[2019-03-27 08:46:57,335] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136000, global step 2164953: loss 0.0492
[2019-03-27 08:46:57,337] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136000, global step 2164953: learning rate 0.0000
[2019-03-27 08:46:57,394] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135000, global step 2164976: loss 0.2810
[2019-03-27 08:46:57,399] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135000, global step 2164976: learning rate 0.0000
[2019-03-27 08:46:57,661] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135000, global step 2165102: loss 0.2670
[2019-03-27 08:46:57,662] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135000, global step 2165102: learning rate 0.0000
[2019-03-27 08:46:57,782] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135000, global step 2165160: loss 0.2717
[2019-03-27 08:46:57,786] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135000, global step 2165160: learning rate 0.0000
[2019-03-27 08:46:57,840] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135000, global step 2165184: loss 0.2629
[2019-03-27 08:46:57,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135000, global step 2165185: learning rate 0.0000
[2019-03-27 08:46:57,896] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135000, global step 2165208: loss 0.2586
[2019-03-27 08:46:57,896] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135000, global step 2165208: learning rate 0.0000
[2019-03-27 08:46:58,310] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135000, global step 2165405: loss 0.2308
[2019-03-27 08:46:58,312] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135000, global step 2165405: learning rate 0.0000
[2019-03-27 08:46:59,610] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 3.0190541e-35 2.9855404e-37 8.6125010e-35 4.4686054e-18], sum to 1.0000
[2019-03-27 08:46:59,617] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5792
[2019-03-27 08:46:59,622] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.58333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.852502541252131, 6.9112, 6.9112, 168.912956510431, 706441.4263932309, 706441.4263932309, 212791.3608108014], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2020200.0000, 
sim time next is 2020800.0000, 
raw observation next is [25.56666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8528925113225189, 6.9112, 6.9112, 168.912956510431, 706908.1948985343, 706908.1948985343, 212881.7717580082], 
processed observation next is [0.0, 0.391304347826087, 0.41074249605055313, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8206006235640473, 0.0, 0.0, 0.8294399451523027, 0.1963633874718151, 0.1963633874718151, 0.3177339876985197], 
reward next is 0.6823, 
noisyNet noise sample is [array([-0.39697888], dtype=float32), -1.0360087]. 
=============================================
[2019-03-27 08:47:00,970] A3C_AGENT_WORKER-Thread-11 INFO:Local step 135500, global step 2166626: loss 0.0331
[2019-03-27 08:47:00,973] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 135500, global step 2166627: learning rate 0.0000
[2019-03-27 08:47:02,311] A3C_AGENT_WORKER-Thread-12 INFO:Local step 135500, global step 2167260: loss 0.0098
[2019-03-27 08:47:02,314] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 135500, global step 2167261: learning rate 0.0000
[2019-03-27 08:47:04,625] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136000, global step 2168339: loss 0.0402
[2019-03-27 08:47:04,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136000, global step 2168341: learning rate 0.0000
[2019-03-27 08:47:05,577] A3C_AGENT_WORKER-Thread-13 INFO:Local step 136500, global step 2168789: loss 12.3659
[2019-03-27 08:47:05,581] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 136500, global step 2168790: learning rate 0.0000
[2019-03-27 08:47:05,947] A3C_AGENT_WORKER-Thread-21 INFO:Local step 135500, global step 2168960: loss 0.0241
[2019-03-27 08:47:05,950] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 135500, global step 2168960: learning rate 0.0000
[2019-03-27 08:47:07,015] A3C_AGENT_WORKER-Thread-14 INFO:Local step 135500, global step 2169460: loss 0.0117
[2019-03-27 08:47:07,018] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 135500, global step 2169461: learning rate 0.0000
[2019-03-27 08:47:08,673] A3C_AGENT_WORKER-Thread-2 INFO:Local step 135500, global step 2170226: loss 0.0178
[2019-03-27 08:47:08,676] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 135500, global step 2170229: learning rate 0.0000
[2019-03-27 08:47:12,718] A3C_AGENT_WORKER-Thread-15 INFO:Local step 135500, global step 2172118: loss 0.0238
[2019-03-27 08:47:12,720] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 135500, global step 2172118: learning rate 0.0000
[2019-03-27 08:47:12,854] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136000, global step 2172181: loss 0.0321
[2019-03-27 08:47:12,858] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136000, global step 2172182: learning rate 0.0000
[2019-03-27 08:47:14,390] A3C_AGENT_WORKER-Thread-20 INFO:Local step 136500, global step 2172897: loss 23.2494
[2019-03-27 08:47:14,395] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 136500, global step 2172898: learning rate 0.0000
[2019-03-27 08:47:14,471] A3C_AGENT_WORKER-Thread-10 INFO:Local step 135500, global step 2172934: loss 0.0160
[2019-03-27 08:47:14,474] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 135500, global step 2172935: learning rate 0.0000
[2019-03-27 08:47:14,937] A3C_AGENT_WORKER-Thread-17 INFO:Local step 135500, global step 2173153: loss 0.0076
[2019-03-27 08:47:14,941] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 135500, global step 2173154: learning rate 0.0000
[2019-03-27 08:47:14,961] A3C_AGENT_WORKER-Thread-19 INFO:Local step 135500, global step 2173166: loss 0.0082
[2019-03-27 08:47:14,962] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 135500, global step 2173166: learning rate 0.0000
[2019-03-27 08:47:15,169] A3C_AGENT_WORKER-Thread-3 INFO:Local step 135500, global step 2173257: loss 0.0051
[2019-03-27 08:47:15,174] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 135500, global step 2173262: learning rate 0.0000
[2019-03-27 08:47:15,214] A3C_AGENT_WORKER-Thread-16 INFO:Local step 135500, global step 2173285: loss 0.0072
[2019-03-27 08:47:15,219] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 135500, global step 2173286: learning rate 0.0000
[2019-03-27 08:47:15,690] A3C_AGENT_WORKER-Thread-18 INFO:Local step 135500, global step 2173508: loss 0.0091
[2019-03-27 08:47:15,692] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 135500, global step 2173508: learning rate 0.0000
[2019-03-27 08:47:17,151] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.6532791e-36 0.0000000e+00 2.4520697e-34 6.6796607e-22], sum to 1.0000
[2019-03-27 08:47:17,158] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.6006
[2019-03-27 08:47:17,163] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 95.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8007256812319501, 6.911199999999999, 6.9112, 168.912956510431, 670709.4949860022, 670709.4949860029, 201973.2014105286], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2010000.0000, 
sim time next is 2010600.0000, 
raw observation next is [24.75, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8043203539601399, 6.911199999999999, 6.9112, 168.912956510431, 673145.3152481278, 673145.3152481284, 202702.5136582995], 
processed observation next is [0.0, 0.2608695652173913, 0.3720379146919432, 0.955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7613662853172437, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18698480979114662, 0.18698480979114676, 0.30254106516164103], 
reward next is 0.6975, 
noisyNet noise sample is [array([0.01696671], dtype=float32), -0.2617051]. 
=============================================
[2019-03-27 08:47:17,183] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9999988e-01 5.4274020e-28 2.2757508e-25 1.5337097e-28 9.5644985e-08], sum to 1.0000
[2019-03-27 08:47:17,189] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1235
[2019-03-27 08:47:17,195] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9186261816176503, 6.9112, 6.9112, 168.912956510431, 752814.0882196674, 752814.0882196674, 227580.3080076669], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2334600.0000, 
sim time next is 2335200.0000, 
raw observation next is [28.16666666666667, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9154576434328505, 6.9112, 6.9112, 168.912956510431, 750590.1287718669, 750590.1287718669, 226846.9596840832], 
processed observation next is [1.0, 0.0, 0.5339652448657191, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8968995651620129, 0.0, 0.0, 0.8294399451523027, 0.20849725799218524, 0.20849725799218524, 0.3385775517672884], 
reward next is 0.6614, 
noisyNet noise sample is [array([0.9657114], dtype=float32), -0.3184508]. 
=============================================
[2019-03-27 08:47:17,521] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136000, global step 2174481: loss 0.0409
[2019-03-27 08:47:17,521] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136000, global step 2174481: learning rate 0.0000
[2019-03-27 08:47:17,616] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [4.5708954e-04 3.2913958e-22 3.4692999e-18 2.7693145e-25 9.9954295e-01], sum to 1.0000
[2019-03-27 08:47:17,630] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.6032
[2019-03-27 08:47:17,633] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.45, 82.0, 1.0, 2.0, 0.2436137215330466, 1.0, 2.0, 0.2436137215330466, 1.0, 2.0, 0.4146962756177102, 6.911199999999999, 6.9112, 170.5573041426782, 1021387.342345061, 1021387.342345062, 282608.6163183828], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2345400.0000, 
sim time next is 2346000.0000, 
raw observation next is [27.4, 82.0, 1.0, 2.0, 0.2303319784383549, 1.0, 2.0, 0.2303319784383549, 1.0, 2.0, 0.3917319356159413, 6.9112, 6.9112, 170.5573041426782, 965676.5534645966, 965676.5534645966, 278309.6231980541], 
processed observation next is [1.0, 0.13043478260869565, 0.4976303317535545, 0.82, 1.0, 1.0, 0.07268913064862036, 1.0, 1.0, 0.07268913064862036, 1.0, 1.0, 0.2582096775804162, 0.0, 0.0, 0.8375144448122397, 0.26824348707349904, 0.26824348707349904, 0.4153874973105285], 
reward next is 0.5846, 
noisyNet noise sample is [array([-0.73963314], dtype=float32), 0.4197399]. 
=============================================
[2019-03-27 08:47:17,639] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[66.565186]
 [65.83064 ]
 [65.37103 ]
 [63.837982]
 [61.905586]], R is [[67.10813141]
 [67.01524353]
 [66.9230423 ]
 [66.82570648]
 [66.73130798]].
[2019-03-27 08:47:18,539] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:47:18,542] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:47:18,542] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:47:18,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:47:18,544] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:47:18,546] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:47:18,545] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:47:18,547] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:47:18,548] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:47:18,549] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:47:18,554] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:47:18,571] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run88
[2019-03-27 08:47:18,572] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run88
[2019-03-27 08:47:18,611] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run88
[2019-03-27 08:47:18,628] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run88
[2019-03-27 08:47:18,647] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run88
[2019-03-27 08:47:20,177] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:20,179] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 66.5, 1.0, 2.0, 0.5334830882404829, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9198540470311642, 6.911200000000001, 6.9112, 168.9126882083106, 1570324.737793731, 1570324.737793731, 331322.1434368143]
[2019-03-27 08:47:20,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:47:20,184] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9974221e-01 1.9381514e-20 5.4645214e-18 1.2212388e-21 2.5783971e-04], sampled 0.7242227916928303
[2019-03-27 08:47:20,185] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1570324.737793731 W.
[2019-03-27 08:47:23,811] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:23,812] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.9, 58.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.511631982338309, 6.9112, 6.9112, 168.912956510431, 453541.8551649512, 453541.8551649512, 153440.5034028472]
[2019-03-27 08:47:23,812] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:47:23,815] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.3530519e-37 0.0000000e+00 4.5218941e-36 5.1467551e-23], sampled 0.4858039950406182
[2019-03-27 08:47:26,871] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:26,873] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.28217629666667, 61.0183294, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6093914006477978, 6.9112, 6.9112, 168.912956510431, 545541.9805006133, 545541.9805006133, 166868.2947996748]
[2019-03-27 08:47:26,877] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:47:26,879] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 8.3164925e-37 0.0000000e+00 7.7869484e-36 2.6446804e-21], sampled 0.5062182064646109
[2019-03-27 08:47:46,209] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:46,209] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.66222439, 92.24193104666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6644873038146432, 6.911199999999999, 6.9112, 168.912956510431, 573659.7841161839, 573659.7841161845, 176517.3266594328]
[2019-03-27 08:47:46,210] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:47:46,213] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.5376822e-35 1.4798177e-36 4.0643796e-35 1.1872287e-18], sampled 0.5412493070651279
[2019-03-27 08:47:57,096] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:57,097] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.03333333333333, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8153873375007487, 6.911200000000001, 6.9112, 168.912956510431, 682706.1949369672, 682706.1949369666, 205018.1700628797]
[2019-03-27 08:47:57,098] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:47:57,100] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.4820127e-32 1.4484884e-32 8.2757477e-33 3.8649852e-14], sampled 0.18913881724906267
[2019-03-27 08:47:59,828] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:47:59,829] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.95, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.989890425677145, 6.9112, 6.9112, 168.912956510431, 801968.9641919662, 801968.9641919662, 244685.9125056363]
[2019-03-27 08:47:59,830] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:47:59,831] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 6.7082926e-35 1.2211024e-35 6.8353849e-35 2.6796004e-16], sampled 0.30313334942262393
[2019-03-27 08:48:06,409] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:06,412] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [30.93333333333333, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.967284038497343, 6.9112, 6.9112, 168.912956510431, 785741.2779215304, 785741.2779215304, 239092.7864252922]
[2019-03-27 08:48:06,415] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:48:06,418] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.3923742e-33 3.6015981e-34 3.6898092e-33 4.3216852e-16], sampled 0.49483944886611664
[2019-03-27 08:48:07,595] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:07,596] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.66666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8111421191678084, 6.9112, 6.9112, 168.912956510431, 678400.1444755488, 678400.1444755488, 204110.606876046]
[2019-03-27 08:48:07,598] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:48:07,600] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.1754234e-35 5.7386450e-37 2.1419991e-34 2.3676871e-19], sampled 0.9931654603820382
[2019-03-27 08:48:13,038] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:13,039] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.758548635, 75.27035244000001, 1.0, 2.0, 0.7822032529096472, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1093210.465038999, 1093210.465038999, 239590.9842189876]
[2019-03-27 08:48:13,041] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:48:13,045] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [8.1074101e-01 9.4874432e-19 6.2905482e-15 1.6365636e-20 1.8925902e-01], sampled 0.596763409070922
[2019-03-27 08:48:13,046] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1093210.465038999 W.
[2019-03-27 08:48:22,142] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:22,143] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [36.43022303333333, 66.58049874833334, 1.0, 2.0, 0.755225921798009, 1.0, 2.0, 0.6982030004132671, 1.0, 2.0, 1.03, 7.004573725157476, 6.9112, 171.5212843490159, 2929768.27101178, 2862502.829705238, 539552.6904255501]
[2019-03-27 08:48:22,145] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:48:22,148] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [2.1223107e-03 2.6813455e-19 9.6896355e-16 1.1674351e-21 9.9787772e-01], sampled 0.4564393394992202
[2019-03-27 08:48:23,774] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:23,775] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.920918585401219, 6.9112, 168.9127071221501, 835698.2955183352, 828803.6067263606, 254811.926671997]
[2019-03-27 08:48:23,776] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:48:23,781] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.1565247e-29 4.8605027e-31 6.3967235e-29 4.0421844e-16], sampled 0.5494654717316223
[2019-03-27 08:48:27,549] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:27,552] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [31.53278783333333, 60.32988210000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9312680300405732, 6.911200000000001, 6.9112, 168.912956510431, 760143.4317718936, 760143.4317718929, 230459.8446724945]
[2019-03-27 08:48:27,552] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:48:27,556] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0926161e-22], sampled 0.8695545076687902
[2019-03-27 08:48:31,384] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:31,386] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.59456225333333, 86.52649142833333, 1.0, 2.0, 0.7966215864507467, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.9129565104304, 1113372.151261491, 1113372.151261491, 243079.0813702566]
[2019-03-27 08:48:31,387] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:48:31,392] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.99893427e-01 5.12307678e-22 6.36734490e-20 2.80991308e-23
 1.06614956e-04], sampled 0.3902995496064392
[2019-03-27 08:48:31,392] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1113372.151261491 W.
[2019-03-27 08:48:50,613] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:48:50,613] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.0, 78.0, 1.0, 1.0, 0.599106325099573, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129031428046, 837212.5838527177, 837212.5838527177, 200578.4350968783]
[2019-03-27 08:48:50,616] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:48:50,620] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9995828e-01 2.9813300e-22 2.8708411e-20 1.3575002e-23 4.1679250e-05], sampled 0.36449050457189913
[2019-03-27 08:49:10,325] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077985734]
[2019-03-27 08:49:10,328] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.61666666666667, 68.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.013258845250491, 6.9112, 6.9112, 168.9128597381398, 815973.5837130497, 815973.5837130497, 250444.0396123556]
[2019-03-27 08:49:10,331] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:49:10,337] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.3056271e-34 9.2458894e-36 2.3674341e-34 6.3674987e-17], sampled 0.41910148100115685
[2019-03-27 08:49:14,771] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7343.6738 3322190842.9863 1794.0000
[2019-03-27 08:49:14,986] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8112.2655 2944768422.5838 1049.0000
[2019-03-27 08:49:15,066] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7101.6201 3189444203.4512 1991.0000
[2019-03-27 08:49:15,175] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7945.2491 2995407398.1468 1300.0000
[2019-03-27 08:49:15,249] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7440.5705 3108275762.5342 1643.0000
[2019-03-27 08:49:16,267] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2175000, evaluation results [2175000.0, 7343.673839879816, 3322190842.9862795, 1794.0, 7440.570544509618, 3108275762.5342293, 1643.0, 8112.265517867266, 2944768422.5838246, 1049.0, 7101.6201355179255, 3189444203.451159, 1991.0, 7945.24912414684, 2995407398.1467543, 1300.0]
[2019-03-27 08:49:16,373] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136000, global step 2175051: loss 0.0261
[2019-03-27 08:49:16,376] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136000, global step 2175052: learning rate 0.0000
[2019-03-27 08:49:17,336] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.7766929e-32 2.5769465e-31 3.2586312e-33 1.0863095e-12], sum to 1.0000
[2019-03-27 08:49:17,344] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6957
[2019-03-27 08:49:17,351] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7652404910790512, 6.9112, 6.9112, 168.912956510431, 646514.4292675435, 646514.4292675435, 194931.1941267917], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1893600.0000, 
sim time next is 1894200.0000, 
raw observation next is [24.65, 90.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7640737573668033, 6.9112, 6.9112, 168.912956510431, 645650.7652913006, 645650.7652913006, 194703.5863013199], 
processed observation next is [1.0, 0.9565217391304348, 0.3672985781990521, 0.9033333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7122850699595162, 0.0, 0.0, 0.8294399451523027, 0.17934743480313906, 0.17934743480313906, 0.29060236761391034], 
reward next is 0.7094, 
noisyNet noise sample is [array([-0.51555973], dtype=float32), -1.8057517]. 
=============================================
[2019-03-27 08:49:19,257] A3C_AGENT_WORKER-Thread-22 INFO:Local step 136500, global step 2176403: loss 12.1330
[2019-03-27 08:49:19,258] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 136500, global step 2176404: learning rate 0.0000
[2019-03-27 08:49:20,065] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137000, global step 2176780: loss 0.2194
[2019-03-27 08:49:20,071] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137000, global step 2176780: learning rate 0.0000
[2019-03-27 08:49:20,276] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136000, global step 2176877: loss 0.0592
[2019-03-27 08:49:20,280] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136000, global step 2176879: learning rate 0.0000
[2019-03-27 08:49:21,141] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136000, global step 2177276: loss 0.0555
[2019-03-27 08:49:21,143] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136000, global step 2177276: learning rate 0.0000
[2019-03-27 08:49:21,908] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.2176747e-38 0.0000000e+00 1.6266371e-38 3.2777541e-19], sum to 1.0000
[2019-03-27 08:49:21,922] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1002
[2019-03-27 08:49:21,928] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.78333333333333, 72.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001206950381169, 6.9112, 6.9112, 168.9128536055835, 805936.6565948715, 805936.6565948715, 247298.5521262293], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2315400.0000, 
sim time next is 2316000.0000, 
raw observation next is [30.66666666666667, 73.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9922212188885599, 6.9112, 6.9112, 168.912956510431, 798390.376201984, 798390.376201984, 244975.1398915977], 
processed observation next is [1.0, 0.8260869565217391, 0.6524486571879939, 0.7366666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9905136815714143, 0.0, 0.0, 0.8294399451523027, 0.2217751045005511, 0.2217751045005511, 0.36563453715163835], 
reward next is 0.6344, 
noisyNet noise sample is [array([0.08768719], dtype=float32), -0.09427479]. 
=============================================
[2019-03-27 08:49:21,941] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[70.304344]
 [70.80867 ]
 [71.0564  ]
 [71.50942 ]
 [71.71454 ]], R is [[69.72296906]
 [69.6566391 ]
 [69.5942688 ]
 [69.53421021]
 [69.47503662]].
[2019-03-27 08:49:22,788] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136000, global step 2178045: loss 0.0349
[2019-03-27 08:49:22,790] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136000, global step 2178046: learning rate 0.0000
[2019-03-27 08:49:26,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [6.5780962e-01 4.7804797e-20 1.6857576e-16 5.7143691e-22 3.4219041e-01], sum to 1.0000
[2019-03-27 08:49:26,085] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6753
[2019-03-27 08:49:26,090] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.83333333333334, 84.0, 1.0, 2.0, 0.274092739416039, 1.0, 2.0, 0.274092739416039, 1.0, 2.0, 0.4627608979160783, 6.9112, 6.9112, 170.5573041426782, 1173360.093733349, 1173360.093733349, 295335.7294309089], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2819400.0000, 
sim time next is 2820000.0000, 
raw observation next is [24.66666666666667, 85.0, 1.0, 2.0, 0.2321796342948698, 1.0, 2.0, 0.2321796342948698, 1.0, 2.0, 0.3929166689514887, 6.9112, 6.9112, 170.5573041426782, 997213.3057217851, 997213.3057217851, 281306.3484037627], 
processed observation next is [1.0, 0.6521739130434783, 0.36808846761453423, 0.85, 1.0, 1.0, 0.07491522204201179, 1.0, 1.0, 0.07491522204201179, 1.0, 1.0, 0.25965447433108374, 0.0, 0.0, 0.8375144448122397, 0.2770036960338292, 0.2770036960338292, 0.4198602214981533], 
reward next is 0.5801, 
noisyNet noise sample is [array([1.4504243], dtype=float32), -0.76646334]. 
=============================================
[2019-03-27 08:49:26,105] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[57.126595]
 [56.09062 ]
 [54.317543]
 [53.70468 ]
 [52.64661 ]], R is [[59.20820999]
 [59.1753273 ]
 [59.13673401]
 [59.09730911]
 [59.05899429]].
[2019-03-27 08:49:27,109] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136000, global step 2180067: loss 0.0729
[2019-03-27 08:49:27,112] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136000, global step 2180068: learning rate 0.0000
[2019-03-27 08:49:27,645] A3C_AGENT_WORKER-Thread-9 INFO:Local step 136500, global step 2180318: loss -2.1701
[2019-03-27 08:49:27,653] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 136500, global step 2180319: learning rate 0.0000
[2019-03-27 08:49:28,911] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137000, global step 2180906: loss 0.3309
[2019-03-27 08:49:28,912] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137000, global step 2180906: learning rate 0.0000
[2019-03-27 08:49:29,054] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136000, global step 2180970: loss 0.0208
[2019-03-27 08:49:29,060] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136000, global step 2180971: learning rate 0.0000
[2019-03-27 08:49:29,321] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136000, global step 2181098: loss 0.0187
[2019-03-27 08:49:29,324] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136000, global step 2181099: learning rate 0.0000
[2019-03-27 08:49:29,413] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136000, global step 2181143: loss 0.0193
[2019-03-27 08:49:29,418] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136000, global step 2181143: learning rate 0.0000
[2019-03-27 08:49:29,622] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136000, global step 2181241: loss 0.0163
[2019-03-27 08:49:29,623] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136000, global step 2181241: learning rate 0.0000
[2019-03-27 08:49:29,672] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136000, global step 2181262: loss 0.0150
[2019-03-27 08:49:29,676] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136000, global step 2181263: learning rate 0.0000
[2019-03-27 08:49:30,062] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136000, global step 2181441: loss 0.0147
[2019-03-27 08:49:30,065] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136000, global step 2181441: learning rate 0.0000
[2019-03-27 08:49:32,637] A3C_AGENT_WORKER-Thread-11 INFO:Local step 136500, global step 2182642: loss 2.3804
[2019-03-27 08:49:32,639] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 136500, global step 2182642: learning rate 0.0000
[2019-03-27 08:49:33,737] A3C_AGENT_WORKER-Thread-12 INFO:Local step 136500, global step 2183162: loss -16.2552
[2019-03-27 08:49:33,741] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 136500, global step 2183163: learning rate 0.0000
[2019-03-27 08:49:34,588] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0805949e-02 7.8510820e-22 2.8252606e-18 1.1874263e-23 9.7919410e-01], sum to 1.0000
[2019-03-27 08:49:34,594] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.2141
[2019-03-27 08:49:34,600] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.8, 66.0, 1.0, 2.0, 0.5989030022993606, 1.0, 2.0, 0.5989030022993606, 1.0, 2.0, 1.03, 6.922549922928754, 6.9112, 170.5573041426782, 2512687.582641256, 2504557.171162043, 487580.5580147826], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2208600.0000, 
sim time next is 2209200.0000, 
raw observation next is [31.9, 65.66666666666666, 1.0, 2.0, 0.5829296026988289, 1.0, 2.0, 0.5829296026988289, 1.0, 2.0, 1.012355942122436, 6.911199999999999, 6.9112, 170.5573041426782, 2445605.868048687, 2445605.868048687, 477229.2096056221], 
processed observation next is [1.0, 0.5652173913043478, 0.7109004739336492, 0.6566666666666666, 1.0, 1.0, 0.49750554542027575, 1.0, 1.0, 0.49750554542027575, 1.0, 1.0, 1.0150682221005316, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6793349633468575, 0.6793349633468575, 0.7122824023964509], 
reward next is 0.2877, 
noisyNet noise sample is [array([-0.8670205], dtype=float32), 0.4568227]. 
=============================================
[2019-03-27 08:49:36,590] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137000, global step 2184475: loss 0.3364
[2019-03-27 08:49:36,593] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137000, global step 2184475: learning rate 0.0000
[2019-03-27 08:49:36,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.8972446e-35 1.4361986e-37 1.3612928e-35 9.0673088e-19], sum to 1.0000
[2019-03-27 08:49:36,686] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1602
[2019-03-27 08:49:36,692] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7353812175648464, 6.9112, 6.9112, 168.912956510431, 624868.7322546768, 624868.7322546768, 189218.166768819], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2713200.0000, 
sim time next is 2713800.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7345178396523152, 6.911200000000001, 6.9112, 168.912956510431, 624140.126048276, 624140.1260482754, 189055.2802516758], 
processed observation next is [0.0, 0.391304347826087, 0.28909952606635075, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.676241267868677, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1733722572356322, 0.17337225723563204, 0.2821720600771281], 
reward next is 0.7178, 
noisyNet noise sample is [array([-1.4508516], dtype=float32), -2.4675152]. 
=============================================
[2019-03-27 08:49:37,189] A3C_AGENT_WORKER-Thread-13 INFO:Local step 137500, global step 2184753: loss 0.3321
[2019-03-27 08:49:37,194] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 137500, global step 2184753: learning rate 0.0000
[2019-03-27 08:49:37,540] A3C_AGENT_WORKER-Thread-21 INFO:Local step 136500, global step 2184914: loss 8.2145
[2019-03-27 08:49:37,544] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 136500, global step 2184915: learning rate 0.0000
[2019-03-27 08:49:38,608] A3C_AGENT_WORKER-Thread-14 INFO:Local step 136500, global step 2185413: loss 9.4253
[2019-03-27 08:49:38,613] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 136500, global step 2185416: learning rate 0.0000
[2019-03-27 08:49:39,910] A3C_AGENT_WORKER-Thread-2 INFO:Local step 136500, global step 2186017: loss 7.3358
[2019-03-27 08:49:39,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 136500, global step 2186018: learning rate 0.0000
[2019-03-27 08:49:42,651] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6207696e-01 3.4078965e-21 7.1633515e-19 2.1228081e-23 3.7923034e-02], sum to 1.0000
[2019-03-27 08:49:42,659] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5342
[2019-03-27 08:49:42,666] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1659488.031247942 W.
[2019-03-27 08:49:42,673] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.5, 63.5, 1.0, 2.0, 0.3956910447927437, 1.0, 2.0, 0.3956910447927437, 1.0, 2.0, 0.6871844877768702, 6.9112, 6.9112, 170.5573041426782, 1659488.031247942, 1659488.031247942, 350516.3486619884], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2377800.0000, 
sim time next is 2378400.0000, 
raw observation next is [32.53333333333333, 63.33333333333334, 1.0, 2.0, 0.383246149250176, 1.0, 2.0, 0.383246149250176, 1.0, 2.0, 0.665571819809276, 6.9112, 6.9112, 170.5573041426782, 1607256.266012264, 1607256.266012264, 343808.3445620325], 
processed observation next is [1.0, 0.5217391304347826, 0.7409162717219588, 0.6333333333333334, 1.0, 1.0, 0.25692307138575426, 1.0, 1.0, 0.25692307138575426, 1.0, 1.0, 0.5921607558649707, 0.0, 0.0, 0.8375144448122397, 0.44646007389229553, 0.44646007389229553, 0.5131467829284067], 
reward next is 0.4869, 
noisyNet noise sample is [array([1.4384212], dtype=float32), 0.96367455]. 
=============================================
[2019-03-27 08:49:44,085] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.8735994e-28 1.4748322e-26 7.6989856e-29 4.4227463e-08], sum to 1.0000
[2019-03-27 08:49:44,093] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9646
[2019-03-27 08:49:44,099] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.66666666666666, 94.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9404658788038569, 6.911199999999999, 6.9112, 168.912956510431, 766350.0565213942, 766350.0565213948, 232618.3823423622], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2506200.0000, 
sim time next is 2506800.0000, 
raw observation next is [26.63333333333333, 94.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9392497097696552, 6.9112, 6.9112, 168.912956510431, 765500.8184588561, 765500.8184588561, 232330.5433196622], 
processed observation next is [1.0, 0.0, 0.46129541864139006, 0.9433333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9259142802068964, 0.0, 0.0, 0.8294399451523027, 0.21263911623857112, 0.21263911623857112, 0.3467620049547197], 
reward next is 0.6532, 
noisyNet noise sample is [array([0.30715218], dtype=float32), -1.1591423]. 
=============================================
[2019-03-27 08:49:44,549] A3C_AGENT_WORKER-Thread-15 INFO:Local step 136500, global step 2188177: loss -35.2128
[2019-03-27 08:49:44,552] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 136500, global step 2188178: learning rate 0.0000
[2019-03-27 08:49:44,723] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137000, global step 2188258: loss 0.3097
[2019-03-27 08:49:44,730] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137000, global step 2188259: learning rate 0.0000
[2019-03-27 08:49:45,867] A3C_AGENT_WORKER-Thread-20 INFO:Local step 137500, global step 2188794: loss 0.7776
[2019-03-27 08:49:45,871] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 137500, global step 2188795: learning rate 0.0000
[2019-03-27 08:49:46,093] A3C_AGENT_WORKER-Thread-10 INFO:Local step 136500, global step 2188897: loss 7.6824
[2019-03-27 08:49:46,095] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 136500, global step 2188898: learning rate 0.0000
[2019-03-27 08:49:46,601] A3C_AGENT_WORKER-Thread-17 INFO:Local step 136500, global step 2189135: loss -1.9156
[2019-03-27 08:49:46,605] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 136500, global step 2189136: learning rate 0.0000
[2019-03-27 08:49:46,671] A3C_AGENT_WORKER-Thread-19 INFO:Local step 136500, global step 2189174: loss 11.6299
[2019-03-27 08:49:46,678] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 136500, global step 2189174: learning rate 0.0000
[2019-03-27 08:49:46,686] A3C_AGENT_WORKER-Thread-16 INFO:Local step 136500, global step 2189180: loss 8.1862
[2019-03-27 08:49:46,688] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 136500, global step 2189180: learning rate 0.0000
[2019-03-27 08:49:46,853] A3C_AGENT_WORKER-Thread-3 INFO:Local step 136500, global step 2189254: loss 6.3475
[2019-03-27 08:49:46,857] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 136500, global step 2189256: learning rate 0.0000
[2019-03-27 08:49:47,333] A3C_AGENT_WORKER-Thread-18 INFO:Local step 136500, global step 2189482: loss 0.0908
[2019-03-27 08:49:47,338] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 136500, global step 2189486: learning rate 0.0000
[2019-03-27 08:49:49,244] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2133079e-01 6.7708605e-19 3.0104067e-16 7.4431356e-22 8.7866926e-01], sum to 1.0000
[2019-03-27 08:49:49,250] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.2969
[2019-03-27 08:49:49,258] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.4, 88.0, 1.0, 2.0, 0.4457216014130425, 1.0, 2.0, 0.4457216014130425, 1.0, 2.0, 0.7606350526156134, 6.911200000000001, 6.9112, 170.5573041426782, 1869494.13681471, 1869494.13681471, 377489.5851506018], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2455200.0000, 
sim time next is 2455800.0000, 
raw observation next is [26.28333333333333, 88.16666666666667, 1.0, 2.0, 0.4402347740256898, 1.0, 2.0, 0.4402347740256898, 1.0, 2.0, 0.7502380106612024, 6.911199999999999, 6.9112, 170.5573041426782, 1846460.857422295, 1846460.857422296, 374016.9512546217], 
processed observation next is [1.0, 0.43478260869565216, 0.4447077409162717, 0.8816666666666667, 1.0, 1.0, 0.3255840650911925, 1.0, 1.0, 0.3255840650911925, 1.0, 1.0, 0.6954122081234175, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5129057937284153, 0.5129057937284155, 0.5582342556039129], 
reward next is 0.4418, 
noisyNet noise sample is [array([1.0182503], dtype=float32), 0.5267599]. 
=============================================
[2019-03-27 08:49:49,389] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.7396888e-35 9.3329608e-35 2.1367995e-35 5.9255917e-17], sum to 1.0000
[2019-03-27 08:49:49,396] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.6258
[2019-03-27 08:49:49,402] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.78333333333333, 92.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.801041387654207, 6.9112, 6.9112, 168.912956510431, 672381.9153298624, 672381.9153298624, 202069.5001513046], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2595000.0000, 
sim time next is 2595600.0000, 
raw observation next is [24.7, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7960190331151052, 6.9112, 6.9112, 168.912956510431, 668719.214149378, 668719.214149378, 201048.2599541073], 
processed observation next is [0.0, 0.043478260869565216, 0.3696682464454976, 0.93, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7512427233111039, 0.0, 0.0, 0.8294399451523027, 0.18575533726371612, 0.18575533726371612, 0.3000720297822497], 
reward next is 0.6999, 
noisyNet noise sample is [array([-0.09780482], dtype=float32), 0.12793708]. 
=============================================
[2019-03-27 08:49:49,534] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137000, global step 2190499: loss 0.2650
[2019-03-27 08:49:49,537] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137000, global step 2190500: learning rate 0.0000
[2019-03-27 08:49:50,794] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137000, global step 2191083: loss 0.2570
[2019-03-27 08:49:50,797] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137000, global step 2191083: learning rate 0.0000
[2019-03-27 08:49:53,419] A3C_AGENT_WORKER-Thread-22 INFO:Local step 137500, global step 2192311: loss 0.9737
[2019-03-27 08:49:53,423] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 137500, global step 2192312: learning rate 0.0000
[2019-03-27 08:49:54,067] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138000, global step 2192613: loss 0.1287
[2019-03-27 08:49:54,068] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138000, global step 2192613: learning rate 0.0000
[2019-03-27 08:49:54,413] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137000, global step 2192777: loss 0.2370
[2019-03-27 08:49:54,415] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137000, global step 2192778: learning rate 0.0000
[2019-03-27 08:49:55,697] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137000, global step 2193352: loss 0.2466
[2019-03-27 08:49:55,703] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137000, global step 2193353: learning rate 0.0000
[2019-03-27 08:49:55,812] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 9.583362e-38 0.000000e+00 4.747207e-37 2.263944e-22], sum to 1.0000
[2019-03-27 08:49:55,817] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.2588
[2019-03-27 08:49:55,824] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7345178396523152, 6.911200000000001, 6.9112, 168.912956510431, 624140.126048276, 624140.1260482754, 189055.2802516758], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2713800.0000, 
sim time next is 2714400.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.732394700174857, 6.911199999999999, 6.9112, 168.912956510431, 622337.012059926, 622337.0120599266, 188655.4746401174], 
processed observation next is [0.0, 0.43478260869565216, 0.28909952606635075, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6736520733839719, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17287139223886835, 0.17287139223886852, 0.28157533528375733], 
reward next is 0.7184, 
noisyNet noise sample is [array([0.5711323], dtype=float32), 1.066737]. 
=============================================
[2019-03-27 08:49:56,909] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137000, global step 2193926: loss 0.1744
[2019-03-27 08:49:56,911] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137000, global step 2193927: learning rate 0.0000
[2019-03-27 08:50:01,201] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.321347e-24], sum to 1.0000
[2019-03-27 08:50:01,209] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8839
[2019-03-27 08:50:01,214] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6892225252512192, 6.911199999999999, 6.9112, 168.912956510431, 590966.8437370453, 590966.8437370459, 180813.7544057624], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2674200.0000, 
sim time next is 2674800.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.689095361915469, 6.911200000000001, 6.9112, 168.912956510431, 590857.7785036261, 590857.7785036255, 180791.323971712], 
processed observation next is [0.0, 1.0, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6208480023359377, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1641271606954517, 0.16412716069545155, 0.2698377969727045], 
reward next is 0.7302, 
noisyNet noise sample is [array([2.7074502], dtype=float32), 0.32908848]. 
=============================================
[2019-03-27 08:50:01,453] A3C_AGENT_WORKER-Thread-9 INFO:Local step 137500, global step 2196246: loss 0.5385
[2019-03-27 08:50:01,457] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 137500, global step 2196248: learning rate 0.0000
[2019-03-27 08:50:01,541] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137000, global step 2196298: loss 0.1924
[2019-03-27 08:50:01,542] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137000, global step 2196298: learning rate 0.0000
[2019-03-27 08:50:02,469] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138000, global step 2196738: loss 0.1366
[2019-03-27 08:50:02,470] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138000, global step 2196738: learning rate 0.0000
[2019-03-27 08:50:03,162] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137000, global step 2197063: loss 0.2329
[2019-03-27 08:50:03,166] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137000, global step 2197065: learning rate 0.0000
[2019-03-27 08:50:03,507] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137000, global step 2197228: loss 0.2114
[2019-03-27 08:50:03,512] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137000, global step 2197230: learning rate 0.0000
[2019-03-27 08:50:03,598] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137000, global step 2197274: loss 0.2069
[2019-03-27 08:50:03,600] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137000, global step 2197275: learning rate 0.0000
[2019-03-27 08:50:03,641] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137000, global step 2197289: loss 0.2015
[2019-03-27 08:50:03,645] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137000, global step 2197289: learning rate 0.0000
[2019-03-27 08:50:03,700] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137000, global step 2197312: loss 0.1864
[2019-03-27 08:50:03,705] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137000, global step 2197315: learning rate 0.0000
[2019-03-27 08:50:04,140] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137000, global step 2197520: loss 0.1676
[2019-03-27 08:50:04,145] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137000, global step 2197520: learning rate 0.0000
[2019-03-27 08:50:04,347] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 1.2562938e-35 2.4115215e-35 5.6189032e-35 1.5481377e-17], sum to 1.0000
[2019-03-27 08:50:04,355] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4279
[2019-03-27 08:50:04,358] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.66666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6442629758691751, 6.911199999999999, 6.9112, 168.912956510431, 556863.0691090797, 556863.0691090804, 173135.0884262031], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2848800.0000, 
sim time next is 2849400.0000, 
raw observation next is [22.5, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6395626580612356, 6.911199999999999, 6.9112, 168.912956510431, 553177.8879240341, 553177.8879240347, 172362.604723088], 
processed observation next is [1.0, 1.0, 0.2654028436018958, 0.915, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.560442265928336, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.15366052442334283, 0.153660524423343, 0.2572576189896836], 
reward next is 0.7427, 
noisyNet noise sample is [array([0.88211167], dtype=float32), 0.96174556]. 
=============================================
[2019-03-27 08:50:06,090] A3C_AGENT_WORKER-Thread-11 INFO:Local step 137500, global step 2198435: loss 1.1922
[2019-03-27 08:50:06,092] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 137500, global step 2198435: learning rate 0.0000
[2019-03-27 08:50:07,495] A3C_AGENT_WORKER-Thread-12 INFO:Local step 137500, global step 2199183: loss 1.7497
[2019-03-27 08:50:07,496] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 137500, global step 2199183: learning rate 0.0000
[2019-03-27 08:50:09,067] A3C_AGENT_WORKER-Thread-14 INFO:Evaluating...
[2019-03-27 08:50:09,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:50:09,069] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:50:09,069] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:50:09,070] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:50:09,071] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:50:09,072] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:50:09,072] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:50:09,073] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:50:09,073] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:50:09,074] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:50:09,107] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run89
[2019-03-27 08:50:09,130] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run89
[2019-03-27 08:50:09,152] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run89
[2019-03-27 08:50:09,153] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run89
[2019-03-27 08:50:09,171] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run89
[2019-03-27 08:50:32,565] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:50:32,567] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.6, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5886931417141765, 6.911199999999999, 6.9112, 168.912956510431, 512497.8895576037, 512497.8895576044, 164378.6877831642]
[2019-03-27 08:50:32,569] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:50:32,574] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.5192908e-37 2.5035171e-25], sampled 0.3719138947073296
[2019-03-27 08:50:36,866] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:50:36,867] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [22.26666666666667, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6610070491759513, 6.911199999999999, 6.9112, 168.912956510431, 571673.26645935, 571673.2664593506, 175919.1304386232]
[2019-03-27 08:50:36,868] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:50:36,871] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.3945034e-38 0.0000000e+00 2.3336539e-37 1.1418041e-24], sampled 0.6076188766554792
[2019-03-27 08:50:38,115] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:50:38,117] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [21.72549834333334, 93.10773632833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6482745814234209, 6.911200000000001, 6.9112, 168.912956510431, 562325.8089034447, 562325.8089034441, 173772.5398147197]
[2019-03-27 08:50:38,118] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:50:38,126] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 4.3054453e-38 0.0000000e+00 4.9048549e-37 1.3457596e-23], sampled 0.9433835319440144
[2019-03-27 08:50:47,858] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:50:47,861] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.60936401333333, 93.52970072000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8867629688405665, 6.911199999999999, 6.9112, 168.912956510431, 733140.7398320133, 733140.7398320138, 220417.9830420703]
[2019-03-27 08:50:47,862] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:50:47,863] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 3.1287954e-37 1.5949317e-38 1.0917320e-36 1.9399975e-20], sampled 0.03197757922034283
[2019-03-27 08:50:54,784] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:50:54,785] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6729416924626109, 6.911199999999999, 6.9112, 168.912956510431, 578860.9898432888, 578860.9898432894, 177973.8723942736]
[2019-03-27 08:50:54,786] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:50:54,788] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0167127e-23], sampled 0.3608459653916888
[2019-03-27 08:51:02,082] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:51:02,083] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.66666666666667, 83.66666666666666, 1.0, 2.0, 0.7029088551933537, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.984736116259848, 6.9112, 168.9124558401992, 1879199.320887913, 1827030.423728228, 386057.4212697289]
[2019-03-27 08:51:02,088] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:51:02,090] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [8.9654964e-01 4.9162947e-20 8.2277002e-17 3.5763939e-22 1.0345034e-01], sampled 0.2883182859708795
[2019-03-27 08:51:02,094] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1879199.320887913 W.
[2019-03-27 08:51:07,390] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:51:07,392] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.9, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9006666151297285, 6.9112, 6.9112, 168.912956510431, 742090.6848591759, 742090.6848591759, 223530.9055161836]
[2019-03-27 08:51:07,394] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:51:07,396] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.6382947e-38 0.0000000e+00 1.9194502e-37 8.5359144e-24], sampled 0.3623069825805676
[2019-03-27 08:51:32,046] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:51:32,047] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.75, 91.5, 1.0, 2.0, 0.6225069594209897, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129565104195, 869926.8580876687, 869926.8580876692, 205013.5626243595]
[2019-03-27 08:51:32,048] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:51:32,050] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.7036267e-25 1.8868375e-24 7.5037719e-26 5.9758337e-11], sampled 0.05567260568591759
[2019-03-27 08:51:32,052] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 869926.8580876687 W.
[2019-03-27 08:51:50,400] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:51:50,404] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.57339327833333, 75.26194864666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6966920245287468, 6.9112, 6.9112, 168.912956510431, 599104.7834266871, 599104.7834266871, 182136.0439973085]
[2019-03-27 08:51:50,406] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 08:51:50,409] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.6586982e-26], sampled 0.5763855406571995
[2019-03-27 08:52:03,916] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.077669136]
[2019-03-27 08:52:03,917] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.1, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6328349270896059, 6.911200000000001, 6.9112, 168.912956510431, 556157.1953618758, 556157.1953618752, 171086.5208130961]
[2019-03-27 08:52:03,918] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:52:03,922] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.8112838e-38 0.0000000e+00 3.8355871e-37 5.4214515e-25], sampled 0.6737995081085707
[2019-03-27 08:52:05,410] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7262.2209 3319431990.6714 2170.0000
[2019-03-27 08:52:05,647] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8071.6237 2937575230.6907 1311.0000
[2019-03-27 08:52:05,747] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7025.6360 3185536932.7477 2441.0000
[2019-03-27 08:52:05,757] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.1289 2989312720.2474 1568.0000
[2019-03-27 08:52:05,792] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7373.9386 3105074910.3632 1920.0000
[2019-03-27 08:52:06,808] A3C_AGENT_WORKER-Thread-14 INFO:Global step: 2200000, evaluation results [2200000.0, 7262.220934772679, 3319431990.6713905, 2170.0, 7373.938612229056, 3105074910.3632226, 1920.0, 8071.623675890913, 2937575230.6907177, 1311.0, 7025.635996058329, 3185536932.7477317, 2441.0, 7923.128901001688, 2989312720.247356, 1568.0]
[2019-03-27 08:52:07,405] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138000, global step 2200286: loss 0.1686
[2019-03-27 08:52:07,407] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138000, global step 2200286: learning rate 0.0000
[2019-03-27 08:52:08,477] A3C_AGENT_WORKER-Thread-21 INFO:Local step 137500, global step 2200784: loss 0.7549
[2019-03-27 08:52:08,478] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 137500, global step 2200784: learning rate 0.0000
[2019-03-27 08:52:08,814] A3C_AGENT_WORKER-Thread-13 INFO:Local step 138500, global step 2200944: loss 0.6362
[2019-03-27 08:52:08,817] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 138500, global step 2200944: learning rate 0.0000
[2019-03-27 08:52:09,754] A3C_AGENT_WORKER-Thread-14 INFO:Local step 137500, global step 2201381: loss 1.4603
[2019-03-27 08:52:09,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 137500, global step 2201381: learning rate 0.0000
[2019-03-27 08:52:11,064] A3C_AGENT_WORKER-Thread-2 INFO:Local step 137500, global step 2201994: loss 1.0568
[2019-03-27 08:52:11,068] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 137500, global step 2201995: learning rate 0.0000
[2019-03-27 08:52:12,508] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1354464e-22], sum to 1.0000
[2019-03-27 08:52:12,513] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8306
[2019-03-27 08:52:12,519] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9454134259297284, 6.9112, 6.9112, 168.912956510431, 769433.0526470358, 769433.0526470358, 233775.0336804223], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3529800.0000, 
sim time next is 3530400.0000, 
raw observation next is [29.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9457591763662511, 6.9112, 6.9112, 168.912956510431, 769723.77337572, 769723.77337572, 233859.7472337086], 
processed observation next is [1.0, 0.8695652173913043, 0.5734597156398105, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9338526541051841, 0.0, 0.0, 0.8294399451523027, 0.21381215927103334, 0.21381215927103334, 0.34904439885628147], 
reward next is 0.6510, 
noisyNet noise sample is [array([0.5206078], dtype=float32), -2.2507095]. 
=============================================
[2019-03-27 08:52:14,784] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 7.4527196e-38 0.0000000e+00 1.8535662e-37 2.2754073e-22], sum to 1.0000
[2019-03-27 08:52:14,792] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.1139
[2019-03-27 08:52:14,797] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7958925375884771, 6.9112, 6.9112, 168.912956510431, 668545.7355885248, 668545.7355885248, 201020.9984415036], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3292200.0000, 
sim time next is 3292800.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.794808224686744, 6.9112, 6.9112, 168.912956510431, 667634.6350104392, 667634.6350104392, 200798.9237870202], 
processed observation next is [0.0, 0.08695652173913043, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7497661276667608, 0.0, 0.0, 0.8294399451523027, 0.18545406528067757, 0.18545406528067757, 0.2996998862492839], 
reward next is 0.7003, 
noisyNet noise sample is [array([-1.181898], dtype=float32), -0.17777777]. 
=============================================
[2019-03-27 08:52:15,811] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138000, global step 2204210: loss 0.1696
[2019-03-27 08:52:15,813] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138000, global step 2204210: learning rate 0.0000
[2019-03-27 08:52:15,988] A3C_AGENT_WORKER-Thread-15 INFO:Local step 137500, global step 2204290: loss 0.4212
[2019-03-27 08:52:15,990] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 137500, global step 2204291: learning rate 0.0000
[2019-03-27 08:52:17,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.8118043e-01 3.8873349e-18 6.9970605e-15 1.5300329e-19 1.8819619e-02], sum to 1.0000
[2019-03-27 08:52:17,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.0486
[2019-03-27 08:52:17,282] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1134758.908805782 W.
[2019-03-27 08:52:17,287] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 74.83333333333334, 1.0, 2.0, 0.4059599464708203, 1.0, 1.0, 0.4059599464708203, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1134758.908805782, 1134758.908805782, 273631.322182922], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3484200.0000, 
sim time next is 3484800.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.4088146226904952, 1.0, 2.0, 0.4088146226904952, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1142742.690423773, 1142742.690423773, 274361.6925331262], 
processed observation next is [1.0, 0.34782608695652173, 0.5260663507109005, 0.74, 1.0, 1.0, 0.28772846107288574, 1.0, 1.0, 0.28772846107288574, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3174285251177147, 0.3174285251177147, 0.40949506348227793], 
reward next is 0.5905, 
noisyNet noise sample is [array([0.23802157], dtype=float32), -0.60236895]. 
=============================================
[2019-03-27 08:52:17,345] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 3.5043031e-27 2.1908644e-26 2.5153069e-28 1.2769069e-10], sum to 1.0000
[2019-03-27 08:52:17,349] A3C_AGENT_WORKER-Thread-20 INFO:Local step 138500, global step 2204927: loss 1.2020
[2019-03-27 08:52:17,352] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 138500, global step 2204928: learning rate 0.0000
[2019-03-27 08:52:17,355] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.2365
[2019-03-27 08:52:17,366] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 887973.0309510449 W.
[2019-03-27 08:52:17,372] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 75.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 6.994575222761476, 6.9112, 168.9123363328907, 887973.0309510449, 828823.9955415971, 254812.522693387], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3340200.0000, 
sim time next is 3340800.0000, 
raw observation next is [31.0, 75.0, 1.0, 1.0, 0.3026998334628809, 1.0, 1.0, 0.3026998334628809, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 846007.378621601, 846007.378621601, 250411.8221536471], 
processed observation next is [0.0, 0.6956521739130435, 0.6682464454976303, 0.75, 1.0, 0.5, 0.15987931742515768, 1.0, 0.5, 0.15987931742515768, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2350020496171114, 0.2350020496171114, 0.37374898828902553], 
reward next is 0.0000, 
noisyNet noise sample is [array([2.4697163], dtype=float32), 0.5806955]. 
=============================================
[2019-03-27 08:52:17,672] A3C_AGENT_WORKER-Thread-10 INFO:Local step 137500, global step 2205074: loss 1.0698
[2019-03-27 08:52:17,678] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 137500, global step 2205075: learning rate 0.0000
[2019-03-27 08:52:17,789] A3C_AGENT_WORKER-Thread-19 INFO:Local step 137500, global step 2205130: loss 1.5126
[2019-03-27 08:52:17,796] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 137500, global step 2205130: learning rate 0.0000
[2019-03-27 08:52:17,935] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000000e+00 1.22054885e-34 9.82595957e-35 1.01819306e-35
 1.38716400e-18], sum to 1.0000
[2019-03-27 08:52:17,945] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3801
[2019-03-27 08:52:17,955] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5529982390478029, 6.9112, 6.9112, 168.912956510431, 485966.2386615312, 485966.2386615312, 159118.6082633739], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3016200.0000, 
sim time next is 3016800.0000, 
raw observation next is [20.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5541855337319791, 6.911200000000001, 6.9112, 168.912956510431, 487009.8538300132, 487009.8538300126, 159284.0033731791], 
processed observation next is [1.0, 0.9565217391304348, 0.1469194312796209, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.45632382162436474, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13528051495278146, 0.1352805149527813, 0.23773731846743149], 
reward next is 0.7623, 
noisyNet noise sample is [array([-0.18666705], dtype=float32), -0.008867338]. 
=============================================
[2019-03-27 08:52:17,992] A3C_AGENT_WORKER-Thread-16 INFO:Local step 137500, global step 2205224: loss 1.7532
[2019-03-27 08:52:17,995] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 137500, global step 2205224: learning rate 0.0000
[2019-03-27 08:52:17,998] A3C_AGENT_WORKER-Thread-3 INFO:Local step 137500, global step 2205225: loss 1.4844
[2019-03-27 08:52:17,999] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 137500, global step 2205225: learning rate 0.0000
[2019-03-27 08:52:18,040] A3C_AGENT_WORKER-Thread-17 INFO:Local step 137500, global step 2205242: loss 1.6090
[2019-03-27 08:52:18,042] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 137500, global step 2205242: learning rate 0.0000
[2019-03-27 08:52:18,680] A3C_AGENT_WORKER-Thread-18 INFO:Local step 137500, global step 2205501: loss 1.1691
[2019-03-27 08:52:18,683] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 137500, global step 2205502: learning rate 0.0000
[2019-03-27 08:52:19,477] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.7125590e-01 2.4990055e-20 4.7692815e-17 8.9700451e-24 2.8744088e-02], sum to 1.0000
[2019-03-27 08:52:19,485] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2282
[2019-03-27 08:52:19,492] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 82.33333333333334, 1.0, 2.0, 0.1985029586351187, 1.0, 2.0, 0.1985029586351187, 1.0, 2.0, 0.3312068037317293, 6.9112, 6.9112, 170.5573041426782, 832180.2672699664, 832180.2672699664, 268669.633778774], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3156000.0000, 
sim time next is 3156600.0000, 
raw observation next is [26.0, 83.16666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9850858521113497, 6.9112, 6.9112, 168.912956510431, 826664.4036146069, 826664.4036146069, 244609.4552912643], 
processed observation next is [1.0, 0.5217391304347826, 0.4312796208530806, 0.8316666666666666, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9818120147699386, 0.0, 0.0, 0.8294399451523027, 0.22962900100405748, 0.22962900100405748, 0.365088739240693], 
reward next is 0.6349, 
noisyNet noise sample is [array([-1.158638], dtype=float32), -1.5377594]. 
=============================================
[2019-03-27 08:52:20,512] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138000, global step 2206362: loss 0.1385
[2019-03-27 08:52:20,514] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138000, global step 2206362: learning rate 0.0000
[2019-03-27 08:52:22,069] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138000, global step 2207081: loss 0.0943
[2019-03-27 08:52:22,072] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138000, global step 2207081: learning rate 0.0000
[2019-03-27 08:52:22,729] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 3.6779132e-37 0.0000000e+00 3.4219875e-36 1.1921145e-21], sum to 1.0000
[2019-03-27 08:52:22,733] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 3.3465960e-36 1.2277097e-38 4.0551628e-36 2.5354608e-20], sum to 1.0000
[2019-03-27 08:52:22,737] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.1524
[2019-03-27 08:52:22,742] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8464
[2019-03-27 08:52:22,745] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7056984764531717, 6.911199999999999, 6.9112, 168.912956510431, 603477.5571900024, 603477.557190003, 183754.8266865265], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3095400.0000, 
sim time next is 3096000.0000, 
raw observation next is [23.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7016700098842391, 6.911200000000001, 6.9112, 168.912956510431, 600927.3924241631, 600927.3924241625, 183030.1265415012], 
processed observation next is [1.0, 0.8695652173913043, 0.28909952606635075, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6361829388832183, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1669242756733786, 0.16692427567337847, 0.2731792933455242], 
reward next is 0.7268, 
noisyNet noise sample is [array([-0.3698426], dtype=float32), -1.340809]. 
=============================================
[2019-03-27 08:52:22,747] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7394773886540175, 6.9112, 6.9112, 168.912956510431, 628357.4160136356, 628357.4160136356, 189994.0059085919], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3090600.0000, 
sim time next is 3091200.0000, 
raw observation next is [23.0, 100.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7339829762337936, 6.911199999999999, 6.9112, 168.912956510431, 623687.5206354492, 623687.5206354499, 188954.461366571], 
processed observation next is [1.0, 0.782608695652174, 0.28909952606635075, 1.0, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6755889954070653, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.173246533509847, 0.1732465335098472, 0.2820215841292104], 
reward next is 0.7180, 
noisyNet noise sample is [array([0.05642825], dtype=float32), -1.1743891]. 
=============================================
[2019-03-27 08:52:22,760] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[68.58974 ]
 [68.55328 ]
 [68.447624]
 [68.2898  ]
 [68.12533 ]], R is [[69.04473114]
 [69.08002472]
 [69.11343384]
 [69.14414215]
 [69.17266846]].
[2019-03-27 08:52:23,742] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.6760801e-28 4.8295895e-28 8.6136446e-29 1.8160141e-10], sum to 1.0000
[2019-03-27 08:52:23,754] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.1918
[2019-03-27 08:52:23,763] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 892953.4979507468 W.
[2019-03-27 08:52:23,769] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [31.0, 75.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00159286831069, 6.9112, 168.9122925611083, 892953.4979507468, 828825.9381571085, 254812.5233513816], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3340200.0000, 
sim time next is 3340800.0000, 
raw observation next is [31.0, 75.0, 1.0, 1.0, 0.303087076059691, 1.0, 1.0, 0.303087076059691, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 847090.0996526786, 847090.0996526786, 250487.2779193515], 
processed observation next is [0.0, 0.6956521739130435, 0.6682464454976303, 0.75, 1.0, 0.5, 0.16034587477071202, 1.0, 0.5, 0.16034587477071202, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.2353028054590774, 0.2353028054590774, 0.373861608834853], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.10879483], dtype=float32), -0.5093482]. 
=============================================
[2019-03-27 08:52:24,057] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [3.7186901e-04 1.7571360e-21 6.3285922e-18 1.5416581e-24 9.9962807e-01], sum to 1.0000
[2019-03-27 08:52:24,061] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1075
[2019-03-27 08:52:24,066] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 61.0, 1.0, 2.0, 0.6345916875039417, 1.0, 2.0, 0.6345916875039417, 1.0, 2.0, 1.03, 6.992228928930611, 6.9112, 170.5573041426782, 2662578.409136225, 2604534.091297135, 500861.5451325925], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3598200.0000, 
sim time next is 3598800.0000, 
raw observation next is [33.0, 61.66666666666667, 1.0, 2.0, 0.5999347768833622, 1.0, 2.0, 0.5999347768833622, 1.0, 2.0, 1.03, 6.924564254464963, 6.9112, 170.5573041426782, 2517020.735747586, 2507447.376651219, 487954.6881587687], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.6166666666666667, 1.0, 1.0, 0.5179937070883881, 1.0, 1.0, 0.5179937070883881, 1.0, 1.0, 1.0365853658536586, 0.0013364254464963033, 0.0, 0.8375144448122397, 0.6991724265965517, 0.6965131601808942, 0.7282905793414458], 
reward next is 0.2049, 
noisyNet noise sample is [array([0.34861365], dtype=float32), 9.803502e-05]. 
=============================================
[2019-03-27 08:52:24,783] A3C_AGENT_WORKER-Thread-22 INFO:Local step 138500, global step 2208341: loss 1.1216
[2019-03-27 08:52:24,785] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 138500, global step 2208341: learning rate 0.0000
[2019-03-27 08:52:25,648] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138000, global step 2208747: loss 0.0857
[2019-03-27 08:52:25,653] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138000, global step 2208747: learning rate 0.0000
[2019-03-27 08:52:26,074] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139000, global step 2208943: loss 0.0555
[2019-03-27 08:52:26,078] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139000, global step 2208943: learning rate 0.0000
[2019-03-27 08:52:26,093] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.6014554e-01 4.8678387e-20 1.0355168e-14 9.4885969e-23 8.3985442e-01], sum to 1.0000
[2019-03-27 08:52:26,098] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.4372
[2019-03-27 08:52:26,103] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.0, 83.0, 1.0, 2.0, 0.2502726215287389, 1.0, 2.0, 0.2502726215287389, 1.0, 2.0, 0.4233530364566623, 6.911200000000001, 6.9112, 170.5573041426782, 1074293.866906634, 1074293.866906633, 287194.8712070927], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3150000.0000, 
sim time next is 3150600.0000, 
raw observation next is [25.16666666666667, 82.33333333333334, 1.0, 2.0, 0.2613299791367139, 1.0, 2.0, 0.2613299791367139, 1.0, 2.0, 0.4409142631293985, 6.9112, 6.9112, 170.5573041426782, 1117605.61064409, 1117605.61064409, 290545.5005132142], 
processed observation next is [1.0, 0.4782608695652174, 0.39178515007898923, 0.8233333333333335, 1.0, 1.0, 0.11003611944182398, 1.0, 1.0, 0.11003611944182398, 1.0, 1.0, 0.31818812576755917, 0.0, 0.0, 0.8375144448122397, 0.31044600295669167, 0.31044600295669167, 0.43365000076599136], 
reward next is 0.5663, 
noisyNet noise sample is [array([-0.78636223], dtype=float32), 1.1228428]. 
=============================================
[2019-03-27 08:52:26,825] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138000, global step 2209294: loss 0.0652
[2019-03-27 08:52:26,826] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138000, global step 2209294: learning rate 0.0000
[2019-03-27 08:52:26,923] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.6462063e-02 3.1699472e-18 8.2243590e-16 2.4178761e-20 9.0353793e-01], sum to 1.0000
[2019-03-27 08:52:26,931] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7545
[2019-03-27 08:52:26,936] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.3592982146922583, 1.0, 1.0, 0.3592982146922583, 1.0, 2.0, 0.611433265578006, 6.9112, 6.9112, 170.5573041426782, 1506752.909977491, 1506752.909977491, 329938.9935844836], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3168600.0000, 
sim time next is 3169200.0000, 
raw observation next is [27.0, 84.0, 1.0, 2.0, 0.3625454924479267, 1.0, 2.0, 0.3625454924479267, 1.0, 2.0, 0.6175604647536244, 6.911199999999999, 6.9112, 170.5573041426782, 1520380.351827299, 1520380.3518273, 331607.0443226667], 
processed observation next is [1.0, 0.6956521739130435, 0.4786729857819906, 0.84, 1.0, 1.0, 0.23198252102159844, 1.0, 1.0, 0.23198252102159844, 1.0, 1.0, 0.5336103228702735, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.42232787550758305, 0.42232787550758333, 0.4949358870487563], 
reward next is 0.5051, 
noisyNet noise sample is [array([-0.98449665], dtype=float32), -0.29409868]. 
=============================================
[2019-03-27 08:52:28,143] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138000, global step 2209913: loss 0.0628
[2019-03-27 08:52:28,147] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138000, global step 2209915: learning rate 0.0000
[2019-03-27 08:52:33,073] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138000, global step 2212230: loss 0.0171
[2019-03-27 08:52:33,075] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138000, global step 2212231: learning rate 0.0000
[2019-03-27 08:52:33,089] A3C_AGENT_WORKER-Thread-9 INFO:Local step 138500, global step 2212235: loss 0.3642
[2019-03-27 08:52:33,093] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 138500, global step 2212236: learning rate 0.0000
[2019-03-27 08:52:33,716] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.0533728e-35 4.7492355e-37 6.0610588e-36 8.7643994e-19], sum to 1.0000
[2019-03-27 08:52:33,726] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.4355
[2019-03-27 08:52:33,733] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.83333333333333, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.808051234673425, 6.9112, 6.9112, 168.912956510431, 676689.9161190981, 676689.9161190981, 203487.0290809524], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3283800.0000, 
sim time next is 3284400.0000, 
raw observation next is [26.66666666666667, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8055752662493155, 6.911200000000001, 6.9112, 168.912956510431, 674903.1520813071, 674903.1520813066, 202979.164001731], 
processed observation next is [0.0, 0.0, 0.4628751974723541, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7628966661577018, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1874730978003631, 0.18747309780036292, 0.30295397612198655], 
reward next is 0.6970, 
noisyNet noise sample is [array([1.3206929], dtype=float32), 0.9325235]. 
=============================================
[2019-03-27 08:52:34,430] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139000, global step 2212845: loss 0.0410
[2019-03-27 08:52:34,432] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139000, global step 2212846: learning rate 0.0000
[2019-03-27 08:52:34,883] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138000, global step 2213058: loss 0.0322
[2019-03-27 08:52:34,885] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138000, global step 2213058: learning rate 0.0000
[2019-03-27 08:52:34,951] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138000, global step 2213085: loss 0.0345
[2019-03-27 08:52:34,955] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138000, global step 2213085: learning rate 0.0000
[2019-03-27 08:52:35,356] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138000, global step 2213283: loss 0.0336
[2019-03-27 08:52:35,361] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138000, global step 2213284: learning rate 0.0000
[2019-03-27 08:52:35,379] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138000, global step 2213291: loss 0.0293
[2019-03-27 08:52:35,384] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138000, global step 2213295: learning rate 0.0000
[2019-03-27 08:52:35,450] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138000, global step 2213323: loss 0.0315
[2019-03-27 08:52:35,452] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138000, global step 2213324: learning rate 0.0000
[2019-03-27 08:52:35,708] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138000, global step 2213442: loss 0.0335
[2019-03-27 08:52:35,709] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138000, global step 2213442: learning rate 0.0000
[2019-03-27 08:52:37,479] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 4.4189648e-36 0.0000000e+00 8.3013147e-36 9.9588174e-22], sum to 1.0000
[2019-03-27 08:52:37,494] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.3508
[2019-03-27 08:52:37,500] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9399550713965141, 6.911200000000001, 6.9112, 168.912956510431, 767159.5323086148, 767159.5323086142, 232552.5008370108], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3355200.0000, 
sim time next is 3355800.0000, 
raw observation next is [28.0, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9339211375350522, 6.9112, 6.9112, 168.912956510431, 763123.1049005303, 763123.1049005303, 231135.7944968149], 
processed observation next is [0.0, 0.8695652173913043, 0.5260663507109005, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9194160213842101, 0.0, 0.0, 0.8294399451523027, 0.21197864025014732, 0.21197864025014732, 0.34497879775644014], 
reward next is 0.6550, 
noisyNet noise sample is [array([1.9592665], dtype=float32), 2.3788996]. 
=============================================
[2019-03-27 08:52:37,695] A3C_AGENT_WORKER-Thread-11 INFO:Local step 138500, global step 2214369: loss 0.2066
[2019-03-27 08:52:37,699] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 138500, global step 2214371: learning rate 0.0000
[2019-03-27 08:52:39,391] A3C_AGENT_WORKER-Thread-12 INFO:Local step 138500, global step 2215161: loss 0.0663
[2019-03-27 08:52:39,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 138500, global step 2215161: learning rate 0.0000
[2019-03-27 08:52:40,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.8850686e-35 2.3238820e-37 1.2134076e-36 1.9824749e-21], sum to 1.0000
[2019-03-27 08:52:40,279] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5158
[2019-03-27 08:52:40,285] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.013828354978864, 6.9112, 6.9112, 168.9128767434061, 816263.9081732858, 816263.9081732858, 250582.9191681969], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3884400.0000, 
sim time next is 3885000.0000, 
raw observation next is [29.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.921760888614536, 6.9112, 168.9127203939597, 836296.087231984, 828803.8398442171, 254811.9300892851], 
processed observation next is [0.0, 1.0, 0.5734597156398105, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.0010560888614535636, 0.0, 0.829438785712334, 0.2323044686755511, 0.23022328884561585, 0.3803163135660972], 
reward next is 0.5669, 
noisyNet noise sample is [array([0.44416398], dtype=float32), -1.1156235]. 
=============================================
[2019-03-27 08:52:40,297] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[63.21328 ]
 [63.299786]
 [63.51723 ]
 [63.689156]
 [63.853207]], R is [[62.98935318]
 [62.98545456]
 [62.98566818]
 [62.99358749]
 [63.00470734]].
[2019-03-27 08:52:41,848] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139000, global step 2216305: loss 0.0845
[2019-03-27 08:52:41,851] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139000, global step 2216305: learning rate 0.0000
[2019-03-27 08:52:42,777] A3C_AGENT_WORKER-Thread-21 INFO:Local step 138500, global step 2216737: loss 0.0814
[2019-03-27 08:52:42,780] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 138500, global step 2216739: learning rate 0.0000
[2019-03-27 08:52:43,668] A3C_AGENT_WORKER-Thread-13 INFO:Local step 139500, global step 2217154: loss 140.4294
[2019-03-27 08:52:43,674] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 139500, global step 2217157: learning rate 0.0000
[2019-03-27 08:52:43,818] A3C_AGENT_WORKER-Thread-14 INFO:Local step 138500, global step 2217221: loss 0.0823
[2019-03-27 08:52:43,822] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 138500, global step 2217225: learning rate 0.0000
[2019-03-27 08:52:45,287] A3C_AGENT_WORKER-Thread-2 INFO:Local step 138500, global step 2217907: loss 0.0315
[2019-03-27 08:52:45,291] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 138500, global step 2217909: learning rate 0.0000
[2019-03-27 08:52:50,192] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139000, global step 2220186: loss 0.0616
[2019-03-27 08:52:50,196] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139000, global step 2220186: learning rate 0.0000
[2019-03-27 08:52:50,324] A3C_AGENT_WORKER-Thread-15 INFO:Local step 138500, global step 2220245: loss 0.0160
[2019-03-27 08:52:50,327] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 138500, global step 2220245: learning rate 0.0000
[2019-03-27 08:52:51,868] A3C_AGENT_WORKER-Thread-20 INFO:Local step 139500, global step 2220967: loss 184.1511
[2019-03-27 08:52:51,870] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 139500, global step 2220967: learning rate 0.0000
[2019-03-27 08:52:52,041] A3C_AGENT_WORKER-Thread-10 INFO:Local step 138500, global step 2221048: loss 0.0157
[2019-03-27 08:52:52,044] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 138500, global step 2221050: learning rate 0.0000
[2019-03-27 08:52:52,074] A3C_AGENT_WORKER-Thread-19 INFO:Local step 138500, global step 2221062: loss 0.0388
[2019-03-27 08:52:52,075] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 138500, global step 2221062: learning rate 0.0000
[2019-03-27 08:52:52,316] A3C_AGENT_WORKER-Thread-3 INFO:Local step 138500, global step 2221174: loss 0.0392
[2019-03-27 08:52:52,318] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 138500, global step 2221175: learning rate 0.0000
[2019-03-27 08:52:52,515] A3C_AGENT_WORKER-Thread-16 INFO:Local step 138500, global step 2221268: loss 0.4282
[2019-03-27 08:52:52,518] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 138500, global step 2221270: learning rate 0.0000
[2019-03-27 08:52:52,622] A3C_AGENT_WORKER-Thread-17 INFO:Local step 138500, global step 2221321: loss 0.0265
[2019-03-27 08:52:52,623] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 138500, global step 2221322: learning rate 0.0000
[2019-03-27 08:52:52,883] A3C_AGENT_WORKER-Thread-18 INFO:Local step 138500, global step 2221439: loss 0.0119
[2019-03-27 08:52:52,885] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 138500, global step 2221439: learning rate 0.0000
[2019-03-27 08:52:53,905] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 5.8344230e-29 1.6457014e-27 3.7319282e-30 1.2346263e-10], sum to 1.0000
[2019-03-27 08:52:53,917] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9164
[2019-03-27 08:52:53,924] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8342836706643492, 6.9112, 6.9112, 168.912956510431, 695177.6276825194, 695177.6276825194, 208949.1452203861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3634800.0000, 
sim time next is 3635400.0000, 
raw observation next is [27.0, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8264647810969853, 6.911199999999999, 6.9112, 168.912956510431, 689840.2678328209, 689840.2678328215, 207308.1180362128], 
processed observation next is [1.0, 0.043478260869565216, 0.4786729857819906, 0.7983333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7883716842646161, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19162229662022803, 0.19162229662022817, 0.3094151015465863], 
reward next is 0.6906, 
noisyNet noise sample is [array([-0.6538913], dtype=float32), 1.0593704]. 
=============================================
[2019-03-27 08:52:54,747] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139000, global step 2222309: loss 0.0703
[2019-03-27 08:52:54,752] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139000, global step 2222309: learning rate 0.0000
[2019-03-27 08:52:55,266] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.406228e-26], sum to 1.0000
[2019-03-27 08:52:55,274] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.0461
[2019-03-27 08:52:55,280] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666667, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9245379534176663, 6.9112, 6.9112, 168.912956510431, 753974.2050768668, 753974.2050768668, 228819.8401185166], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3784800.0000, 
sim time next is 3785400.0000, 
raw observation next is [30.5, 70.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9306735968790353, 6.9112, 6.9112, 168.912956510431, 757898.1602936431, 757898.1602936431, 230235.1338132506], 
processed observation next is [1.0, 0.8260869565217391, 0.6445497630331753, 0.705, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9154556059500429, 0.0, 0.0, 0.8294399451523027, 0.21052726674823422, 0.21052726674823422, 0.34363452807947853], 
reward next is 0.6564, 
noisyNet noise sample is [array([-0.38185716], dtype=float32), 0.77067834]. 
=============================================
[2019-03-27 08:52:56,094] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [5.2531544e-02 1.3927116e-18 9.7822975e-18 7.0445355e-23 9.4746846e-01], sum to 1.0000
[2019-03-27 08:52:56,103] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8100
[2019-03-27 08:52:56,108] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 59.0, 1.0, 2.0, 0.596933246980587, 1.0, 2.0, 0.596933246980587, 1.0, 2.0, 1.03, 6.918704392786211, 6.9112, 170.5573041426782, 2504415.225037994, 2499039.52322605, 486868.3902716095], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3682800.0000, 
sim time next is 3683400.0000, 
raw observation next is [33.0, 59.0, 1.0, 2.0, 0.6673424720993818, 1.0, 2.0, 0.6542612755639535, 1.0, 2.0, 1.03, 7.005095157281602, 6.9112, 170.5573041426782, 2745197.45626134, 2677936.535689728, 511211.209264596], 
processed observation next is [1.0, 0.6521739130434783, 0.7630331753554502, 0.59, 1.0, 1.0, 0.5992077977100986, 1.0, 1.0, 0.5834473199565705, 1.0, 1.0, 1.0365853658536586, 0.00938951572816018, 0.0, 0.8375144448122397, 0.7625548489614834, 0.7438712599138133, 0.7630018048725313], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.87983286], dtype=float32), -0.672161]. 
=============================================
[2019-03-27 08:52:56,457] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139000, global step 2223109: loss 0.0745
[2019-03-27 08:52:56,459] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139000, global step 2223109: learning rate 0.0000
[2019-03-27 08:52:56,480] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 7.1283358e-36 2.1650647e-36 1.3367568e-35 3.4689517e-19], sum to 1.0000
[2019-03-27 08:52:56,491] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.8265
[2019-03-27 08:52:56,496] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8756855738875992, 6.9112, 6.9112, 168.912956510431, 723238.3915178634, 723238.3915178634, 217873.3677376734], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3807000.0000, 
sim time next is 3807600.0000, 
raw observation next is [28.0, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8751014005590695, 6.911199999999999, 6.9112, 168.912956510431, 722755.7521721631, 722755.7521721637, 217741.5055253577], 
processed observation next is [0.0, 0.043478260869565216, 0.5260663507109005, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8476846348281334, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20076548671448974, 0.2007654867144899, 0.32498732167963834], 
reward next is 0.6750, 
noisyNet noise sample is [array([0.7633331], dtype=float32), 1.7238184]. 
=============================================
[2019-03-27 08:52:57,911] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.804722e-37 4.320205e-22], sum to 1.0000
[2019-03-27 08:52:57,919] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.8128
[2019-03-27 08:52:57,926] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8886306940212644, 6.911199999999999, 6.9112, 168.912956510431, 732327.4355252552, 732327.4355252557, 220759.1481187861], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3702000.0000, 
sim time next is 3702600.0000, 
raw observation next is [28.5, 76.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.886394257167543, 6.9112, 6.9112, 168.912956510431, 730827.7827572296, 730827.7827572296, 220260.2994404231], 
processed observation next is [1.0, 0.8695652173913043, 0.5497630331753555, 0.765, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8614564111799304, 0.0, 0.0, 0.8294399451523027, 0.2030077174325638, 0.2030077174325638, 0.32874671558272106], 
reward next is 0.6713, 
noisyNet noise sample is [array([-1.3207843], dtype=float32), -0.02496261]. 
=============================================
[2019-03-27 08:52:59,117] A3C_AGENT_WORKER-Thread-22 INFO:Local step 139500, global step 2224544: loss 461.1092
[2019-03-27 08:52:59,123] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 139500, global step 2224544: learning rate 0.0000
[2019-03-27 08:52:59,176] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139000, global step 2224570: loss 0.0795
[2019-03-27 08:52:59,178] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139000, global step 2224571: learning rate 0.0000
[2019-03-27 08:53:00,135] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:53:00,136] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:53:00,137] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:53:00,138] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:53:00,139] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:53:00,139] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:53:00,141] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:53:00,141] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:53:00,143] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:53:00,142] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:53:00,147] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:53:00,167] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run90
[2019-03-27 08:53:00,187] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run90
[2019-03-27 08:53:00,207] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run90
[2019-03-27 08:53:00,208] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run90
[2019-03-27 08:53:00,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run90
[2019-03-27 08:53:25,627] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07496085]
[2019-03-27 08:53:25,631] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.87603298, 97.52440813999999, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7728713870550614, 6.9112, 6.9112, 168.912956510431, 651014.0689206104, 651014.0689206104, 196408.7103775382]
[2019-03-27 08:53:25,632] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:53:25,636] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 9.5040799e-36 2.2842507e-38 3.1867623e-35 4.0270736e-22], sampled 0.22493731229223568
[2019-03-27 08:53:46,668] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07496085]
[2019-03-27 08:53:46,671] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.0, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7519909211639766, 6.9112, 6.9112, 168.912956510431, 647176.0835598018, 647176.0835598018, 192413.8388092519]
[2019-03-27 08:53:46,672] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:53:46,676] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 4.0640694e-35 4.1029772e-37 1.2394860e-34 1.2812766e-21], sampled 0.588603561260112
[2019-03-27 08:54:24,624] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07496085]
[2019-03-27 08:54:24,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.33333333333334, 93.66666666666667, 1.0, 2.0, 0.6211115859993694, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.9129564607914, 867976.086608837, 867976.0866088377, 204744.3917341245]
[2019-03-27 08:54:24,625] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:54:24,631] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.2718032e-24 4.7069358e-24 4.9321092e-25 9.8234511e-12], sampled 0.8900463083616746
[2019-03-27 08:54:56,644] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7406.4777 3105027187.2644 1829.0000
[2019-03-27 08:54:56,655] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07496085]
[2019-03-27 08:54:56,655] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [30.07368320333333, 87.65196144000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.155238452997764, 6.9112, 168.9114788608207, 1001996.235312361, 828868.4721343728, 254813.8454086639]
[2019-03-27 08:54:56,657] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:54:56,660] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.487908e-26], sampled 0.20849809712759637
[2019-03-27 08:54:56,661] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1001996.235312361 W.
[2019-03-27 08:54:56,679] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8086.1941 2938186495.3331 1238.0000
[2019-03-27 08:54:56,700] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7257.9799 3320074517.7523 2135.0000
[2019-03-27 08:54:56,727] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7918.5982 2990678905.5920 1548.0000
[2019-03-27 08:54:56,899] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7022.5174 3187412277.2325 2398.0000
[2019-03-27 08:54:57,917] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2225000, evaluation results [2225000.0, 7257.979890767607, 3320074517.7522755, 2135.0, 7406.477691552672, 3105027187.264395, 1829.0, 8086.194106862896, 2938186495.333078, 1238.0, 7022.517434886968, 3187412277.232457, 2398.0, 7918.5981514144, 2990678905.591961, 1548.0]
[2019-03-27 08:54:58,043] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139000, global step 2225061: loss 0.0940
[2019-03-27 08:54:58,046] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139000, global step 2225061: learning rate 0.0000
[2019-03-27 08:54:58,487] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140000, global step 2225268: loss 0.2158
[2019-03-27 08:54:58,493] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140000, global step 2225270: learning rate 0.0000
[2019-03-27 08:54:58,826] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 2.0680361e-25 2.1630048e-25 2.6582776e-26 6.2717973e-12], sum to 1.0000
[2019-03-27 08:54:58,837] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7584
[2019-03-27 08:54:58,848] A3C_AGENT_WORKER-Thread-14 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 882033.5293394026 W.
[2019-03-27 08:54:58,851] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [32.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.986206313185753, 6.9112, 168.9122904609472, 882033.5293394026, 828821.6790706085, 254811.9896959117], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3924000.0000, 
sim time next is 3924600.0000, 
raw observation next is [32.16666666666667, 66.33333333333334, 1.0, 1.0, 0.6019529672826881, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9128954273149, 841192.1586247352, 841192.1586247346, 201109.1501556461], 
processed observation next is [0.0, 0.43478260869565216, 0.7235387045813588, 0.6633333333333334, 1.0, 0.5, 0.5204252617863712, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294396452062387, 0.23366448850687088, 0.23366448850687072, 0.3001629106800688], 
reward next is 0.6998, 
noisyNet noise sample is [array([-2.244636], dtype=float32), 1.3210237]. 
=============================================
[2019-03-27 08:54:59,590] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139000, global step 2225782: loss 0.1064
[2019-03-27 08:54:59,591] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139000, global step 2225782: learning rate 0.0000
[2019-03-27 08:55:04,573] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139000, global step 2228109: loss 0.1205
[2019-03-27 08:55:04,574] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139000, global step 2228109: learning rate 0.0000
[2019-03-27 08:55:05,173] A3C_AGENT_WORKER-Thread-9 INFO:Local step 139500, global step 2228388: loss 491.6709
[2019-03-27 08:55:05,175] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 139500, global step 2228389: learning rate 0.0000
[2019-03-27 08:55:05,691] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [2.4302382e-02 1.8534194e-17 5.4069717e-15 5.8775545e-20 9.7569764e-01], sum to 1.0000
[2019-03-27 08:55:05,702] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.5146
[2019-03-27 08:55:05,707] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 71.33333333333334, 1.0, 2.0, 0.5947661824945989, 1.0, 2.0, 0.5947661824945989, 1.0, 2.0, 1.026689108860919, 6.911200000000001, 6.9112, 170.5573041426782, 2495314.293780278, 2495314.293780277, 485499.4908573985], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4011600.0000, 
sim time next is 4012200.0000, 
raw observation next is [30.0, 70.0, 1.0, 2.0, 0.5968365004919695, 1.0, 2.0, 0.5968365004919695, 1.0, 2.0, 1.03, 6.913145158164522, 6.9112, 170.5573041426782, 2504008.921390174, 2502615.525472953, 487057.7244140576], 
processed observation next is [1.0, 0.43478260869565216, 0.6208530805687204, 0.7, 1.0, 1.0, 0.5142608439662283, 1.0, 1.0, 0.5142608439662283, 1.0, 1.0, 1.0365853658536586, 0.00019451581645215654, 0.0, 0.8375144448122397, 0.6955580337194928, 0.6951709792980425, 0.726951827483668], 
reward next is 0.2633, 
noisyNet noise sample is [array([-0.5924686], dtype=float32), -1.05902]. 
=============================================
[2019-03-27 08:55:06,293] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139000, global step 2228910: loss 0.0861
[2019-03-27 08:55:06,298] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139000, global step 2228912: learning rate 0.0000
[2019-03-27 08:55:06,318] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139000, global step 2228921: loss 0.0881
[2019-03-27 08:55:06,321] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139000, global step 2228922: learning rate 0.0000
[2019-03-27 08:55:06,727] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139000, global step 2229116: loss 0.0756
[2019-03-27 08:55:06,729] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139000, global step 2229116: learning rate 0.0000
[2019-03-27 08:55:06,782] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140000, global step 2229147: loss 0.1312
[2019-03-27 08:55:06,785] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140000, global step 2229147: learning rate 0.0000
[2019-03-27 08:55:06,874] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139000, global step 2229183: loss 0.0746
[2019-03-27 08:55:06,877] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139000, global step 2229184: learning rate 0.0000
[2019-03-27 08:55:07,077] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139000, global step 2229278: loss 0.0640
[2019-03-27 08:55:07,080] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139000, global step 2229279: learning rate 0.0000
[2019-03-27 08:55:07,141] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139000, global step 2229311: loss 0.0677
[2019-03-27 08:55:07,143] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139000, global step 2229311: learning rate 0.0000
[2019-03-27 08:55:09,454] A3C_AGENT_WORKER-Thread-11 INFO:Local step 139500, global step 2230370: loss 577.3039
[2019-03-27 08:55:09,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 139500, global step 2230370: learning rate 0.0000
[2019-03-27 08:55:09,980] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.0832392e-23 2.7702031e-23 1.0127981e-25 1.0990947e-10], sum to 1.0000
[2019-03-27 08:55:09,990] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4659
[2019-03-27 08:55:09,997] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.5, 81.5, 1.0, 2.0, 0.3104331845569807, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5391197797525777, 6.911199999999999, 6.9112, 168.912956510431, 867633.2668428647, 867633.2668428653, 225382.6275826569], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3972600.0000, 
sim time next is 3973200.0000, 
raw observation next is [30.33333333333334, 82.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.161814761210817, 6.9112, 168.9114547371519, 1006663.449100141, 828870.2927423045, 254813.1949323603], 
processed observation next is [0.0, 1.0, 0.6366508688783573, 0.8233333333333335, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.02506147612108167, 0.0, 0.8294325707579875, 0.2796287358611503, 0.23024174798397348, 0.3803182013915825], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.059606], dtype=float32), -0.33024246]. 
=============================================
[2019-03-27 08:55:10,297] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1631903e-27], sum to 1.0000
[2019-03-27 08:55:10,307] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0125
[2019-03-27 08:55:10,311] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [36.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001820475624099, 6.911199999999999, 6.9112, 168.9128567121509, 806117.3452119743, 806117.3452119749, 247438.6908671318], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4301400.0000, 
sim time next is 4302000.0000, 
raw observation next is [36.0, 50.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.993896894040938, 6.9112, 6.9112, 168.912956510431, 799739.2150915159, 799739.2150915159, 245403.6512753319], 
processed observation next is [1.0, 0.8260869565217391, 0.9052132701421801, 0.5, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9925571878548023, 0.0, 0.0, 0.8294399451523027, 0.22214978196986554, 0.22214978196986554, 0.3662741063810924], 
reward next is 0.6337, 
noisyNet noise sample is [array([1.6602011], dtype=float32), 0.59217405]. 
=============================================
[2019-03-27 08:55:10,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[51.636566]
 [51.81623 ]
 [51.534813]
 [51.377758]
 [50.78221 ]], R is [[51.8867569 ]
 [51.99857712]
 [52.11318588]
 [52.22081375]
 [52.3312645 ]].
[2019-03-27 08:55:11,250] A3C_AGENT_WORKER-Thread-12 INFO:Local step 139500, global step 2231206: loss 484.8852
[2019-03-27 08:55:11,254] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 139500, global step 2231208: learning rate 0.0000
[2019-03-27 08:55:11,375] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [9.9517906e-01 5.1761425e-20 2.8791050e-17 2.8978514e-22 4.8209061e-03], sum to 1.0000
[2019-03-27 08:55:11,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.0546
[2019-03-27 08:55:11,393] A3C_AGENT_WORKER-Thread-9 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 871136.4831079381 W.
[2019-03-27 08:55:11,398] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.2077915527586608, 1.0, 2.0, 0.2077915527586608, 1.0, 2.0, 0.3608652094252283, 6.9112, 6.9112, 170.5573041426782, 871136.4831079381, 871136.4831079381, 272042.413739019], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4320000.0000, 
sim time next is 4320600.0000, 
raw observation next is [30.83333333333334, 79.83333333333334, 1.0, 2.0, 0.6256238803617878, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 874284.4145929803, 874284.4145929803, 205616.9842402485], 
processed observation next is [1.0, 0.0, 0.6603475513428123, 0.7983333333333335, 1.0, 1.0, 0.5489444341708287, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.2428567818313834, 0.2428567818313834, 0.3068910212541022], 
reward next is 0.6931, 
noisyNet noise sample is [array([1.2390423], dtype=float32), 1.3065215]. 
=============================================
[2019-03-27 08:55:11,947] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.6301116e-01 1.2593379e-16 9.7616143e-14 2.5521420e-19 8.3698881e-01], sum to 1.0000
[2019-03-27 08:55:11,956] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8774
[2019-03-27 08:55:11,961] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 84.0, 1.0, 2.0, 0.4459372732454481, 1.0, 2.0, 0.4459372732454481, 1.0, 2.0, 0.7617615046197992, 6.9112, 6.9112, 170.5573041426782, 1870399.520694425, 1870399.520694425, 377743.843105801], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4006800.0000, 
sim time next is 4007400.0000, 
raw observation next is [27.33333333333333, 82.33333333333333, 1.0, 2.0, 0.4862117659989613, 1.0, 2.0, 0.4862117659989613, 1.0, 2.0, 0.831096789783627, 6.911199999999999, 6.9112, 170.5573041426782, 2039484.045597957, 2039484.045597957, 403395.4497022202], 
processed observation next is [1.0, 0.391304347826087, 0.494470774091627, 0.8233333333333333, 1.0, 1.0, 0.3809780313240497, 1.0, 1.0, 0.3809780313240497, 1.0, 1.0, 0.7940204753458866, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.5665233459994325, 0.5665233459994325, 0.6020827607495824], 
reward next is 0.3979, 
noisyNet noise sample is [array([-0.47051525], dtype=float32), -0.07229672]. 
=============================================
[2019-03-27 08:55:12,751] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [2.6571628e-02 1.2951596e-14 1.7899950e-12 1.1400681e-17 9.7342843e-01], sum to 1.0000
[2019-03-27 08:55:12,757] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.7707
[2019-03-27 08:55:12,761] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 75.0, 1.0, 2.0, 0.7600059273871962, 1.0, 2.0, 0.7005930032078607, 1.0, 1.0, 1.03, 7.005102464044643, 6.9112, 170.5573041426782, 2939828.272664697, 2872562.1179615, 540953.6907050832], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4266000.0000, 
sim time next is 4266600.0000, 
raw observation next is [33.16666666666666, 74.33333333333333, 1.0, 2.0, 0.7664308033591265, 1.0, 2.0, 0.7038054411938259, 1.0, 2.0, 1.03, 7.005102970747787, 6.9112, 170.5573041426782, 2953324.240763664, 2886057.723088392, 543134.0979066682], 
processed observation next is [1.0, 0.391304347826087, 0.7709320695102682, 0.7433333333333333, 1.0, 1.0, 0.7185913293483451, 1.0, 1.0, 0.6431390857756939, 1.0, 1.0, 1.0365853658536586, 0.009390297074778698, 0.0, 0.8375144448122397, 0.8203678446565733, 0.8016827008578867, 0.8106479073233854], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.06792786], dtype=float32), -0.19754805]. 
=============================================
[2019-03-27 08:55:14,238] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140000, global step 2232582: loss 0.3414
[2019-03-27 08:55:14,243] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140000, global step 2232582: learning rate 0.0000
[2019-03-27 08:55:14,318] A3C_AGENT_WORKER-Thread-21 INFO:Local step 139500, global step 2232614: loss 542.7711
[2019-03-27 08:55:14,324] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 139500, global step 2232618: learning rate 0.0000
[2019-03-27 08:55:15,476] A3C_AGENT_WORKER-Thread-14 INFO:Local step 139500, global step 2233151: loss 536.4627
[2019-03-27 08:55:15,477] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 139500, global step 2233152: learning rate 0.0000
[2019-03-27 08:55:15,585] A3C_AGENT_WORKER-Thread-13 INFO:Local step 140500, global step 2233202: loss 84.1757
[2019-03-27 08:55:15,589] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 140500, global step 2233203: learning rate 0.0000
[2019-03-27 08:55:17,099] A3C_AGENT_WORKER-Thread-2 INFO:Local step 139500, global step 2233913: loss 536.6412
[2019-03-27 08:55:17,101] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 139500, global step 2233914: learning rate 0.0000
[2019-03-27 08:55:22,007] A3C_AGENT_WORKER-Thread-15 INFO:Local step 139500, global step 2236197: loss 539.0509
[2019-03-27 08:55:22,009] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 139500, global step 2236198: learning rate 0.0000
[2019-03-27 08:55:22,472] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140000, global step 2236412: loss 0.3180
[2019-03-27 08:55:22,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140000, global step 2236412: learning rate 0.0000
[2019-03-27 08:55:23,048] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [6.1177120e-02 9.5196352e-14 1.4147018e-12 1.9069989e-17 9.3882293e-01], sum to 1.0000
[2019-03-27 08:55:23,055] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.3736
[2019-03-27 08:55:23,060] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [35.0, 57.33333333333333, 1.0, 2.0, 0.883356172974307, 1.0, 2.0, 0.7622681260014161, 1.0, 2.0, 1.03, 7.005112194075796, 6.9112, 170.5573041426782, 3198960.8523745, 3131687.727654194, 585499.7588927263], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4185600.0000, 
sim time next is 4186200.0000, 
raw observation next is [35.0, 56.66666666666667, 1.0, 2.0, 0.8671401291376266, 1.0, 2.0, 0.7541601040830759, 1.0, 2.0, 1.03, 7.005110914702338, 6.9112, 170.5573041426782, 3164891.330253477, 3097619.122000421, 579319.2230972915], 
processed observation next is [1.0, 0.43478260869565216, 0.8578199052132701, 0.5666666666666668, 1.0, 1.0, 0.8399278664308755, 1.0, 1.0, 0.7038073543169588, 1.0, 1.0, 1.0365853658536586, 0.009391091470233804, 0.0, 0.8375144448122397, 0.8791364806259659, 0.860449756111228, 0.8646555568616292], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.61770433], dtype=float32), -0.4087099]. 
=============================================
[2019-03-27 08:55:23,539] A3C_AGENT_WORKER-Thread-20 INFO:Local step 140500, global step 2236906: loss 3.4572
[2019-03-27 08:55:23,540] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 140500, global step 2236906: learning rate 0.0000
[2019-03-27 08:55:23,576] A3C_AGENT_WORKER-Thread-19 INFO:Local step 139500, global step 2236921: loss 534.2783
[2019-03-27 08:55:23,581] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 139500, global step 2236922: learning rate 0.0000
[2019-03-27 08:55:23,700] A3C_AGENT_WORKER-Thread-10 INFO:Local step 139500, global step 2236979: loss 601.6184
[2019-03-27 08:55:23,702] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 139500, global step 2236980: learning rate 0.0000
[2019-03-27 08:55:24,129] A3C_AGENT_WORKER-Thread-3 INFO:Local step 139500, global step 2237179: loss 322.3616
[2019-03-27 08:55:24,130] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 139500, global step 2237179: learning rate 0.0000
[2019-03-27 08:55:24,144] A3C_AGENT_WORKER-Thread-16 INFO:Local step 139500, global step 2237185: loss 538.5231
[2019-03-27 08:55:24,148] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 139500, global step 2237186: learning rate 0.0000
[2019-03-27 08:55:24,461] A3C_AGENT_WORKER-Thread-18 INFO:Local step 139500, global step 2237332: loss 546.9266
[2019-03-27 08:55:24,464] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 139500, global step 2237332: learning rate 0.0000
[2019-03-27 08:55:24,594] A3C_AGENT_WORKER-Thread-17 INFO:Local step 139500, global step 2237392: loss 563.7105
[2019-03-27 08:55:24,596] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 139500, global step 2237392: learning rate 0.0000
[2019-03-27 08:55:26,805] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140000, global step 2238419: loss 0.3655
[2019-03-27 08:55:26,807] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140000, global step 2238419: learning rate 0.0000
[2019-03-27 08:55:28,831] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140000, global step 2239358: loss 0.3339
[2019-03-27 08:55:28,837] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140000, global step 2239361: learning rate 0.0000
[2019-03-27 08:55:30,293] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.7399629e-37 0.0000000e+00 1.1324228e-37 8.5750043e-26], sum to 1.0000
[2019-03-27 08:55:30,303] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.9539
[2019-03-27 08:55:30,306] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.66666666666666, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9402218121118385, 6.911199999999999, 6.9112, 168.912956510431, 766139.8200219937, 766139.8200219943, 232558.7520961105], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4538400.0000, 
sim time next is 4539000.0000, 
raw observation next is [31.83333333333333, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9441823642151638, 6.9112, 6.9112, 168.912956510431, 768634.6933793763, 768634.6933793763, 233485.2671962066], 
processed observation next is [0.0, 0.5217391304347826, 0.7077409162717218, 0.635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9319297124575167, 0.0, 0.0, 0.8294399451523027, 0.21350963704982676, 0.21350963704982676, 0.34848547342717406], 
reward next is 0.6515, 
noisyNet noise sample is [array([0.56898654], dtype=float32), 0.52800906]. 
=============================================
[2019-03-27 08:55:30,323] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[55.482876]
 [55.526363]
 [55.557594]
 [55.577034]
 [55.60121 ]], R is [[55.54455948]
 [55.64200974]
 [55.73963547]
 [55.83670044]
 [55.93017578]].
[2019-03-27 08:55:31,262] A3C_AGENT_WORKER-Thread-22 INFO:Local step 140500, global step 2240490: loss 50.0317
[2019-03-27 08:55:31,264] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 140500, global step 2240490: learning rate 0.0000
[2019-03-27 08:55:31,714] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140000, global step 2240691: loss 0.2197
[2019-03-27 08:55:31,717] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140000, global step 2240695: learning rate 0.0000
[2019-03-27 08:55:32,265] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141000, global step 2240951: loss 0.1830
[2019-03-27 08:55:32,266] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141000, global step 2240951: learning rate 0.0000
[2019-03-27 08:55:32,590] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140000, global step 2241101: loss 0.1539
[2019-03-27 08:55:32,595] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140000, global step 2241104: learning rate 0.0000
[2019-03-27 08:55:34,439] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140000, global step 2241955: loss 0.0989
[2019-03-27 08:55:34,441] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140000, global step 2241955: learning rate 0.0000
[2019-03-27 08:55:35,519] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 8.1862102e-38 2.5656776e-30], sum to 1.0000
[2019-03-27 08:55:35,527] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4188
[2019-03-27 08:55:35,534] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.66666666666666, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9129034563075115, 6.911199999999999, 6.9112, 168.912956510431, 748198.9319862392, 748198.9319862397, 226232.3338853914], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4531200.0000, 
sim time next is 4531800.0000, 
raw observation next is [28.83333333333334, 79.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9250541536692772, 6.911200000000001, 6.9112, 168.912956510431, 756290.5553582255, 756290.5553582249, 229029.7911289223], 
processed observation next is [0.0, 0.43478260869565216, 0.5655608214849924, 0.79, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9086026264259477, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2100807098217293, 0.21008070982172913, 0.34183550914764527], 
reward next is 0.6582, 
noisyNet noise sample is [array([-1.0070732], dtype=float32), 1.2578334]. 
=============================================
[2019-03-27 08:55:39,338] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140000, global step 2244239: loss 0.1065
[2019-03-27 08:55:39,339] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140000, global step 2244239: learning rate 0.0000
[2019-03-27 08:55:39,470] A3C_AGENT_WORKER-Thread-9 INFO:Local step 140500, global step 2244302: loss 74.2693
[2019-03-27 08:55:39,473] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 140500, global step 2244302: learning rate 0.0000
[2019-03-27 08:55:39,995] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.8242386e-36 0.0000000e+00 1.0004319e-36 4.9314767e-22], sum to 1.0000
[2019-03-27 08:55:40,004] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.1785
[2019-03-27 08:55:40,009] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.66666666666667, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7999232957130867, 6.9112, 6.9112, 168.912956510431, 672172.116678605, 672172.116678605, 201854.2930630072], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4659600.0000, 
sim time next is 4660200.0000, 
raw observation next is [24.75, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8045296407145317, 6.9112, 6.9112, 168.912956510431, 675281.3501446685, 675281.3501446685, 202790.3333543635], 
processed observation next is [1.0, 0.9565217391304348, 0.3720379146919432, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.761621513066502, 0.0, 0.0, 0.8294399451523027, 0.18757815281796347, 0.18757815281796347, 0.3026721393348709], 
reward next is 0.6973, 
noisyNet noise sample is [array([-1.6961668], dtype=float32), -0.95137596]. 
=============================================
[2019-03-27 08:55:40,110] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.5858997e-32], sum to 1.0000
[2019-03-27 08:55:40,118] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6880
[2019-03-27 08:55:40,122] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 72.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.83126016694094, 6.9112, 6.9112, 168.912956510431, 692315.0894553369, 692315.0894553369, 208290.5866433808], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4822200.0000, 
sim time next is 4822800.0000, 
raw observation next is [28.33333333333333, 72.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8259980321283401, 6.9112, 6.9112, 168.912956510431, 688417.0314402839, 688417.0314402839, 207180.743997184], 
processed observation next is [1.0, 0.8260869565217391, 0.541864139020537, 0.7266666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7878024782052927, 0.0, 0.0, 0.8294399451523027, 0.19122695317785662, 0.19122695317785662, 0.30922499104057316], 
reward next is 0.6908, 
noisyNet noise sample is [array([1.1935418], dtype=float32), 1.2907281]. 
=============================================
[2019-03-27 08:55:40,409] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141000, global step 2244736: loss 0.0440
[2019-03-27 08:55:40,416] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141000, global step 2244737: learning rate 0.0000
[2019-03-27 08:55:41,024] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140000, global step 2245020: loss 0.0557
[2019-03-27 08:55:41,025] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140000, global step 2245021: learning rate 0.0000
[2019-03-27 08:55:41,086] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140000, global step 2245046: loss 0.0552
[2019-03-27 08:55:41,090] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140000, global step 2245047: learning rate 0.0000
[2019-03-27 08:55:41,630] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140000, global step 2245301: loss 0.0434
[2019-03-27 08:55:41,632] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140000, global step 2245301: learning rate 0.0000
[2019-03-27 08:55:41,659] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140000, global step 2245312: loss 0.0522
[2019-03-27 08:55:41,661] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140000, global step 2245314: learning rate 0.0000
[2019-03-27 08:55:42,039] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140000, global step 2245486: loss 0.0288
[2019-03-27 08:55:42,042] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140000, global step 2245486: learning rate 0.0000
[2019-03-27 08:55:42,299] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140000, global step 2245607: loss 0.0318
[2019-03-27 08:55:42,303] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140000, global step 2245611: learning rate 0.0000
[2019-03-27 08:55:44,197] A3C_AGENT_WORKER-Thread-11 INFO:Local step 140500, global step 2246475: loss 10.4048
[2019-03-27 08:55:44,200] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 140500, global step 2246476: learning rate 0.0000
[2019-03-27 08:55:44,335] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 9.2527300e-22 2.3400200e-21 2.2979023e-23 5.6469629e-10], sum to 1.0000
[2019-03-27 08:55:44,343] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5072
[2019-03-27 08:55:44,349] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1203318.489988973 W.
[2019-03-27 08:55:44,355] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 79.5, 1.0, 2.0, 0.8609420534813838, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1203318.489988973, 1203318.489988973, 259421.2153701783], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4779000.0000, 
sim time next is 4779600.0000, 
raw observation next is [29.33333333333334, 78.0, 1.0, 2.0, 0.4078071649641614, 1.0, 1.0, 0.4078071649641614, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1139925.088273654, 1139925.088273654, 274116.559746764], 
processed observation next is [1.0, 0.30434782608695654, 0.5892575039494474, 0.78, 1.0, 1.0, 0.28651465658332703, 1.0, 0.5, 0.28651465658332703, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3166458578537928, 0.3166458578537928, 0.4091291936518866], 
reward next is 0.5909, 
noisyNet noise sample is [array([0.49343097], dtype=float32), -0.3054968]. 
=============================================
[2019-03-27 08:55:45,845] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.2816668e-36 8.0335113e-38 1.6400669e-35 4.0015484e-21], sum to 1.0000
[2019-03-27 08:55:45,853] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1391
[2019-03-27 08:55:45,858] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9635136046675982, 6.9112, 6.9112, 168.912956510431, 783400.7262489481, 783400.7262489481, 238191.0360838163], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4581000.0000, 
sim time next is 4581600.0000, 
raw observation next is [28.0, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9742052775370188, 6.9112, 6.9112, 168.912956510431, 790573.5802289916, 790573.5802289916, 240784.5200926034], 
processed observation next is [1.0, 0.0, 0.5260663507109005, 0.8733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9685430213866082, 0.0, 0.0, 0.8294399451523027, 0.219603772285831, 0.219603772285831, 0.359379880735229], 
reward next is 0.6406, 
noisyNet noise sample is [array([1.2001778], dtype=float32), -0.1860766]. 
=============================================
[2019-03-27 08:55:46,337] A3C_AGENT_WORKER-Thread-12 INFO:Local step 140500, global step 2247466: loss -36.7272
[2019-03-27 08:55:46,340] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 140500, global step 2247466: learning rate 0.0000
[2019-03-27 08:55:48,450] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141000, global step 2248458: loss 0.0870
[2019-03-27 08:55:48,455] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141000, global step 2248459: learning rate 0.0000
[2019-03-27 08:55:48,995] A3C_AGENT_WORKER-Thread-21 INFO:Local step 140500, global step 2248790: loss 26.2222
[2019-03-27 08:55:48,998] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 140500, global step 2248790: learning rate 0.0000
[2019-03-27 08:55:49,273] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9900299e-01 8.3410266e-17 1.5244138e-15 4.5377707e-19 9.9705928e-04], sum to 1.0000
[2019-03-27 08:55:49,283] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6346
[2019-03-27 08:55:49,289] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1159901.607780538 W.
[2019-03-27 08:55:49,291] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [27.66666666666666, 85.66666666666667, 1.0, 2.0, 0.8298953984078029, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1159901.607780538, 1159901.607780538, 251381.8678612421], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 4689600.0000, 
sim time next is 4690200.0000, 
raw observation next is [27.83333333333334, 84.83333333333333, 1.0, 2.0, 0.7939861741289208, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1109686.928667472, 1109686.928667471, 242440.665546567], 
processed observation next is [1.0, 0.2608695652173913, 0.5181674565560824, 0.8483333333333333, 1.0, 1.0, 0.7517905712396636, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.30824636907429775, 0.30824636907429753, 0.3618517396217418], 
reward next is 0.6381, 
noisyNet noise sample is [array([2.2486658], dtype=float32), -0.31420526]. 
=============================================
[2019-03-27 08:55:49,362] A3C_AGENT_WORKER-Thread-13 INFO:Local step 141500, global step 2249018: loss -4.6400
[2019-03-27 08:55:49,364] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 141500, global step 2249018: learning rate 0.0000
[2019-03-27 08:55:49,469] A3C_AGENT_WORKER-Thread-14 INFO:Local step 140500, global step 2249092: loss 41.5889
[2019-03-27 08:55:49,471] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 140500, global step 2249094: learning rate 0.0000
[2019-03-27 08:55:50,884] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [8.6674988e-01 2.1241511e-16 4.6745190e-15 1.2304878e-20 1.3325013e-01], sum to 1.0000
[2019-03-27 08:55:50,891] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.9466
[2019-03-27 08:55:50,896] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 69.0, 1.0, 2.0, 0.7808732874438727, 1.0, 2.0, 0.7808732874438727, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 2183802.616250894, 2183802.616250895, 410666.8060459362], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4717200.0000, 
sim time next is 4717800.0000, 
raw observation next is [30.5, 70.5, 1.0, 2.0, 0.5215977302408609, 1.0, 2.0, 0.5215977302408609, 1.0, 1.0, 0.9058427624231065, 6.911200000000001, 6.9112, 170.5573041426782, 2188067.074528265, 2188067.074528264, 430402.2987973898], 
processed observation next is [1.0, 0.6086956521739131, 0.6445497630331753, 0.705, 1.0, 1.0, 0.42361172318176005, 1.0, 1.0, 0.42361172318176005, 1.0, 0.5, 0.8851741005159836, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6077964095911846, 0.6077964095911844, 0.6423914907423728], 
reward next is 0.3576, 
noisyNet noise sample is [array([-1.7857908], dtype=float32), 1.4902061]. 
=============================================
[2019-03-27 08:55:51,411] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 08:55:51,413] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:55:51,414] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:55:51,415] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:55:51,416] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:55:51,416] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:55:51,418] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:55:51,417] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:55:51,420] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:55:51,418] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:55:51,422] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:55:51,443] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run91
[2019-03-27 08:55:51,460] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run91
[2019-03-27 08:55:51,462] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run91
[2019-03-27 08:55:51,513] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run91
[2019-03-27 08:55:51,530] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run91
[2019-03-27 08:56:33,912] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07318291]
[2019-03-27 08:56:33,914] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.15, 77.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8823801539507972, 6.911199999999999, 6.9112, 168.912956510431, 729474.0881988334, 729474.0881988341, 219416.3146953299]
[2019-03-27 08:56:33,916] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:56:33,918] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.4152321e-38 0.0000000e+00 4.4338869e-38 1.0933928e-25], sampled 0.4952601998772934
[2019-03-27 08:57:23,055] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07318291]
[2019-03-27 08:57:23,057] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [29.63333333333333, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.001566077248094, 6.911200000000001, 6.9112, 168.9128582814801, 810729.6093834537, 810729.609383453, 247646.1378449108]
[2019-03-27 08:57:23,059] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 08:57:23,061] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.6428854e-29], sampled 0.825268011515681
[2019-03-27 08:57:31,172] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07318291]
[2019-03-27 08:57:31,173] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.04255256666666, 77.20053428, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5484660464136779, 6.911200000000001, 6.9112, 168.912956510431, 484485.3256159449, 484485.3256159443, 158399.831594433]
[2019-03-27 08:57:31,176] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:57:31,178] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.7554635e-29], sampled 0.8772744468908317
[2019-03-27 08:57:40,854] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07318291]
[2019-03-27 08:57:40,856] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.75, 65.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7802093806661992, 6.911200000000001, 6.9112, 168.912956510431, 658542.600417164, 658542.6004171633, 197897.8599036606]
[2019-03-27 08:57:40,857] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:57:40,860] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.374987e-32], sampled 0.28708003224668643
[2019-03-27 08:57:42,853] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07318291]
[2019-03-27 08:57:42,854] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.0, 84.5, 1.0, 2.0, 0.8950237216749858, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1250981.700016791, 1250981.700016791, 268573.4669357252]
[2019-03-27 08:57:42,855] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:57:42,858] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9326599e-01 2.2217347e-17 1.9365411e-14 5.7076658e-20 6.7339800e-03], sampled 0.7537422345019226
[2019-03-27 08:57:42,860] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1250981.700016791 W.
[2019-03-27 08:57:47,654] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7027.9907 3185267171.0019 2463.0000
[2019-03-27 08:57:47,768] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7360.4997 3105690826.2206 1985.0000
[2019-03-27 08:57:48,066] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7286.8220 3319359046.8727 2137.0000
[2019-03-27 08:57:48,165] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.0500 2989296073.9139 1574.0000
[2019-03-27 08:57:48,299] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8067.6716 2937877233.4491 1368.0000
[2019-03-27 08:57:49,317] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2250000, evaluation results [2250000.0, 7286.8219968356925, 3319359046.872718, 2137.0, 7360.49970829519, 3105690826.2205944, 1985.0, 8067.671586880403, 2937877233.4491076, 1368.0, 7027.990651158192, 3185267171.0018682, 2463.0, 7922.04999212989, 2989296073.9138775, 1574.0]
[2019-03-27 08:57:49,453] A3C_AGENT_WORKER-Thread-2 INFO:Local step 140500, global step 2250065: loss -99.4837
[2019-03-27 08:57:49,455] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 140500, global step 2250066: learning rate 0.0000
[2019-03-27 08:57:54,104] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141000, global step 2252222: loss 0.1329
[2019-03-27 08:57:54,106] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141000, global step 2252222: learning rate 0.0000
[2019-03-27 08:57:54,233] A3C_AGENT_WORKER-Thread-15 INFO:Local step 140500, global step 2252284: loss 0.4909
[2019-03-27 08:57:54,235] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 140500, global step 2252284: learning rate 0.0000
[2019-03-27 08:57:54,245] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.9664347e-32], sum to 1.0000
[2019-03-27 08:57:54,255] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5529
[2019-03-27 08:57:54,259] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7995927774533711, 6.9112, 6.9112, 168.912956510431, 671654.9019920448, 671654.9019920448, 201781.2239054657], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5114400.0000, 
sim time next is 5115000.0000, 
raw observation next is [26.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7998798772523904, 6.9112, 6.9112, 168.912956510431, 671896.143399213, 671896.143399213, 201840.364077364], 
processed observation next is [0.0, 0.17391304347826086, 0.4312796208530806, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7559510698199882, 0.0, 0.0, 0.8294399451523027, 0.1866378176108925, 0.1866378176108925, 0.30125427474233435], 
reward next is 0.6987, 
noisyNet noise sample is [array([0.07558853], dtype=float32), -0.80888104]. 
=============================================
[2019-03-27 08:57:54,269] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[63.106033]
 [63.156784]
 [63.166157]
 [63.212616]
 [63.195583]], R is [[63.20166779]
 [63.26848602]
 [63.33418655]
 [63.39875412]
 [63.46233368]].
[2019-03-27 08:57:55,345] A3C_AGENT_WORKER-Thread-20 INFO:Local step 141500, global step 2252797: loss -7.0842
[2019-03-27 08:57:55,346] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 141500, global step 2252797: learning rate 0.0000
[2019-03-27 08:57:55,745] A3C_AGENT_WORKER-Thread-19 INFO:Local step 140500, global step 2252983: loss 120.8568
[2019-03-27 08:57:55,746] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 140500, global step 2252983: learning rate 0.0000
[2019-03-27 08:57:55,758] A3C_AGENT_WORKER-Thread-10 INFO:Local step 140500, global step 2252987: loss 5.1345
[2019-03-27 08:57:55,760] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 140500, global step 2252987: learning rate 0.0000
[2019-03-27 08:57:56,188] A3C_AGENT_WORKER-Thread-16 INFO:Local step 140500, global step 2253192: loss 28.1396
[2019-03-27 08:57:56,190] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 140500, global step 2253192: learning rate 0.0000
[2019-03-27 08:57:56,414] A3C_AGENT_WORKER-Thread-3 INFO:Local step 140500, global step 2253294: loss -39.9088
[2019-03-27 08:57:56,415] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 140500, global step 2253294: learning rate 0.0000
[2019-03-27 08:57:56,948] A3C_AGENT_WORKER-Thread-18 INFO:Local step 140500, global step 2253463: loss -62.1431
[2019-03-27 08:57:56,953] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 140500, global step 2253463: learning rate 0.0000
[2019-03-27 08:57:57,089] A3C_AGENT_WORKER-Thread-17 INFO:Local step 140500, global step 2253529: loss -14.6680
[2019-03-27 08:57:57,091] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 140500, global step 2253529: learning rate 0.0000
[2019-03-27 08:57:58,876] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141000, global step 2254367: loss 0.0398
[2019-03-27 08:57:58,878] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141000, global step 2254367: learning rate 0.0000
[2019-03-27 08:58:00,977] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141000, global step 2255345: loss 0.0418
[2019-03-27 08:58:00,981] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141000, global step 2255346: learning rate 0.0000
[2019-03-27 08:58:01,374] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 6.4938312e-24 5.6298800e-23 3.2955080e-26 1.8849933e-08], sum to 1.0000
[2019-03-27 08:58:01,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.7191
[2019-03-27 08:58:01,395] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1110115.417157964 W.
[2019-03-27 08:58:01,404] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.2647655334291035, 1.0, 2.0, 0.2647655334291035, 1.0, 2.0, 0.4487911481816121, 6.911199999999999, 6.9112, 170.5573041426782, 1110115.417157964, 1110115.417157965, 289743.046952599], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4933800.0000, 
sim time next is 4934400.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.3742669403919587, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6306168221032565, 6.911199999999999, 6.9112, 168.9129565103187, 1046130.833974872, 1046130.833974873, 246231.3607868667], 
processed observation next is [1.0, 0.08695652173913043, 0.4312796208530806, 0.89, 1.0, 1.0, 0.24610474746019118, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.5495327098820202, -8.881784197001253e-17, 0.0, 0.8294399451517512, 0.29059189832635335, 0.29059189832635357, 0.3675094937117413], 
reward next is 0.6325, 
noisyNet noise sample is [array([0.09989532], dtype=float32), -0.5437017]. 
=============================================
[2019-03-27 08:58:03,281] A3C_AGENT_WORKER-Thread-22 INFO:Local step 141500, global step 2256419: loss -89.5593
[2019-03-27 08:58:03,284] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 141500, global step 2256419: learning rate 0.0000
[2019-03-27 08:58:03,645] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141000, global step 2256593: loss 0.0290
[2019-03-27 08:58:03,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141000, global step 2256593: learning rate 0.0000
[2019-03-27 08:58:04,195] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142000, global step 2256843: loss 2.2783
[2019-03-27 08:58:04,199] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142000, global step 2256845: learning rate 0.0000
[2019-03-27 08:58:04,378] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141000, global step 2256927: loss 0.0439
[2019-03-27 08:58:04,380] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141000, global step 2256927: learning rate 0.0000
[2019-03-27 08:58:06,397] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141000, global step 2257861: loss 0.0606
[2019-03-27 08:58:06,401] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141000, global step 2257862: learning rate 0.0000
[2019-03-27 08:58:11,486] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141000, global step 2260235: loss 0.0273
[2019-03-27 08:58:11,489] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141000, global step 2260237: learning rate 0.0000
[2019-03-27 08:58:11,844] A3C_AGENT_WORKER-Thread-9 INFO:Local step 141500, global step 2260405: loss -15.7578
[2019-03-27 08:58:11,846] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 141500, global step 2260405: learning rate 0.0000
[2019-03-27 08:58:12,841] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142000, global step 2260868: loss 2.2579
[2019-03-27 08:58:12,848] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142000, global step 2260869: learning rate 0.0000
[2019-03-27 08:58:12,974] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141000, global step 2260929: loss 0.0432
[2019-03-27 08:58:12,981] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141000, global step 2260930: learning rate 0.0000
[2019-03-27 08:58:13,054] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 3.0639181e-36 1.3864409e-38 1.1162802e-35 4.4854015e-22], sum to 1.0000
[2019-03-27 08:58:13,063] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7484
[2019-03-27 08:58:13,067] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9370877318618301, 6.9112, 6.9112, 168.912956510431, 764851.5724996116, 764851.5724996116, 231860.1820904314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5263200.0000, 
sim time next is 5263800.0000, 
raw observation next is [28.5, 81.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9415768170507317, 6.9112, 6.9112, 168.912956510431, 768191.4446982025, 768191.4446982025, 232932.3130443644], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8133333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9287522159155265, 0.0, 0.0, 0.8294399451523027, 0.21338651241616738, 0.21338651241616738, 0.34766016872293193], 
reward next is 0.6523, 
noisyNet noise sample is [array([-0.08489811], dtype=float32), 0.2470423]. 
=============================================
[2019-03-27 08:58:13,145] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [2.9209298e-01 1.5523922e-16 3.8271282e-15 3.3099351e-20 7.0790702e-01], sum to 1.0000
[2019-03-27 08:58:13,153] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4389
[2019-03-27 08:58:13,157] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.1, 53.0, 1.0, 2.0, 0.7923422563244715, 1.0, 2.0, 0.7167611676764983, 1.0, 2.0, 1.03, 7.005105014386977, 6.9112, 170.5573041426782, 3007754.809236809, 2940486.827619656, 552081.8375960211], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5322600.0000, 
sim time next is 5323200.0000, 
raw observation next is [36.1, 53.0, 1.0, 2.0, 0.8072283814499, 1.0, 2.0, 0.7242042302392127, 1.0, 2.0, 1.03, 7.005106188537843, 6.9112, 170.5573041426782, 3039026.233992071, 2971757.411282891, 557336.3458655212], 
processed observation next is [1.0, 0.6086956521739131, 0.9099526066350712, 0.53, 1.0, 1.0, 0.7677450378914457, 1.0, 1.0, 0.6677159400472441, 1.0, 1.0, 1.0365853658536586, 0.009390618853784272, 0.0, 0.8375144448122397, 0.8441739538866864, 0.8254881698008031, 0.8318452923365989], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.96793187], dtype=float32), 0.45132527]. 
=============================================
[2019-03-27 08:58:13,159] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141000, global step 2261013: loss 0.0375
[2019-03-27 08:58:13,163] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141000, global step 2261014: learning rate 0.0000
[2019-03-27 08:58:13,612] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141000, global step 2261226: loss 0.0515
[2019-03-27 08:58:13,615] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141000, global step 2261226: learning rate 0.0000
[2019-03-27 08:58:14,044] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141000, global step 2261428: loss 0.0644
[2019-03-27 08:58:14,047] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141000, global step 2261428: learning rate 0.0000
[2019-03-27 08:58:14,183] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141000, global step 2261492: loss 0.0531
[2019-03-27 08:58:14,185] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141000, global step 2261493: learning rate 0.0000
[2019-03-27 08:58:14,321] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141000, global step 2261557: loss 0.0479
[2019-03-27 08:58:14,325] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141000, global step 2261560: learning rate 0.0000
[2019-03-27 08:58:16,376] A3C_AGENT_WORKER-Thread-11 INFO:Local step 141500, global step 2262510: loss -30.8274
[2019-03-27 08:58:16,382] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 141500, global step 2262511: learning rate 0.0000
[2019-03-27 08:58:18,562] A3C_AGENT_WORKER-Thread-12 INFO:Local step 141500, global step 2263526: loss -27.8695
[2019-03-27 08:58:18,565] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 141500, global step 2263527: learning rate 0.0000
[2019-03-27 08:58:20,551] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142000, global step 2264453: loss 2.9523
[2019-03-27 08:58:20,553] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142000, global step 2264453: learning rate 0.0000
[2019-03-27 08:58:20,988] A3C_AGENT_WORKER-Thread-21 INFO:Local step 141500, global step 2264660: loss 0.1850
[2019-03-27 08:58:20,990] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 141500, global step 2264660: learning rate 0.0000
[2019-03-27 08:58:21,548] A3C_AGENT_WORKER-Thread-13 INFO:Local step 142500, global step 2264915: loss -269.9087
[2019-03-27 08:58:21,551] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 142500, global step 2264917: learning rate 0.0000
[2019-03-27 08:58:21,671] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.2879649e-01 8.0639183e-18 1.3063798e-16 4.0403211e-20 8.7120354e-01], sum to 1.0000
[2019-03-27 08:58:21,680] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.5405
[2019-03-27 08:58:21,685] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.83333333333334, 67.5, 1.0, 2.0, 0.6323827045143311, 1.0, 2.0, 0.6323827045143311, 1.0, 2.0, 1.03, 6.987915842271191, 6.9112, 170.5573041426782, 2653300.260703744, 2598345.582283946, 500018.6811819429], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5242200.0000, 
sim time next is 5242800.0000, 
raw observation next is [31.66666666666667, 68.0, 1.0, 2.0, 0.7153652240292404, 1.0, 2.0, 0.6782726515288829, 1.0, 2.0, 1.03, 7.005098943720871, 6.9112, 170.5573041426782, 2846060.915322626, 2778797.282370544, 526225.7023246664], 
processed observation next is [1.0, 0.6956521739130435, 0.6998420221169038, 0.68, 1.0, 1.0, 0.6570665349749885, 1.0, 1.0, 0.6123766885890156, 1.0, 1.0, 1.0365853658536586, 0.00938989437208706, 0.0, 0.8375144448122397, 0.7905724764785073, 0.7718881339918178, 0.7854114960069648], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.122236], dtype=float32), -0.54847926]. 
=============================================
[2019-03-27 08:58:21,872] A3C_AGENT_WORKER-Thread-14 INFO:Local step 141500, global step 2265065: loss -60.2678
[2019-03-27 08:58:21,876] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 141500, global step 2265065: learning rate 0.0000
[2019-03-27 08:58:22,849] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 5.2379931e-35 5.8651493e-37 1.9804879e-35 3.4601858e-21], sum to 1.0000
[2019-03-27 08:58:22,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2508
[2019-03-27 08:58:22,863] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9610462295364609, 6.911200000000001, 6.9112, 168.912956510431, 779565.8059736987, 779565.8059736982, 237485.6770766158], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5269200.0000, 
sim time next is 5269800.0000, 
raw observation next is [28.5, 83.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9627109673002654, 6.9112, 6.9112, 168.912956510431, 780600.503488506, 780600.503488506, 237881.8523740785], 
processed observation next is [1.0, 1.0, 0.5497630331753555, 0.8383333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9545255698783724, 0.0, 0.0, 0.8294399451523027, 0.21683347319125165, 0.21683347319125165, 0.3550475408568336], 
reward next is 0.6450, 
noisyNet noise sample is [array([0.62779063], dtype=float32), 0.9683446]. 
=============================================
[2019-03-27 08:58:23,923] A3C_AGENT_WORKER-Thread-2 INFO:Local step 141500, global step 2266023: loss -52.8771
[2019-03-27 08:58:23,924] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 141500, global step 2266023: learning rate 0.0000
[2019-03-27 08:58:26,870] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 1.411359e-26], sum to 1.0000
[2019-03-27 08:58:26,878] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1605
[2019-03-27 08:58:26,883] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [34.16666666666667, 62.33333333333334, 1.0, 1.0, 0.3089221219618043, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5364955637407928, 6.911200000000001, 6.9112, 168.9128534523635, 863408.2642780005, 863408.2642779998, 224883.5110492128], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5335800.0000, 
sim time next is 5336400.0000, 
raw observation next is [33.93333333333334, 63.66666666666667, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.07479908382215, 6.9112, 168.9119060615032, 944908.3023443462, 828846.2034154234, 254813.3641345014], 
processed observation next is [1.0, 0.782608695652174, 0.807266982622433, 0.6366666666666667, 0.0, 0.5, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01635990838221497, 0.0, 0.8294347869671695, 0.26247452842898505, 0.23023505650428427, 0.3803184539320916], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.74616086], dtype=float32), 0.098560125]. 
=============================================
[2019-03-27 08:58:26,910] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9979740e-01 5.1970701e-20 9.4925272e-19 6.1964637e-21 2.0263290e-04], sum to 1.0000
[2019-03-27 08:58:26,916] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.2178
[2019-03-27 08:58:26,927] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 870774.3274751453 W.
[2019-03-27 08:58:26,932] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 79.0, 1.0, 2.0, 0.3115565738232382, 0.0, 1.0, 0.0, 1.0, 2.0, 0.5410707353975598, 6.9112, 6.9112, 168.912956510431, 870774.3274751453, 870774.3274751453, 225758.6810682016], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5346000.0000, 
sim time next is 5346600.0000, 
raw observation next is [30.9, 79.33333333333334, 1.0, 2.0, 0.3126172490136955, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5429127774327385, 6.9112, 6.9112, 168.912956510431, 873740.0444910671, 873740.0444910671, 226112.6338900113], 
processed observation next is [1.0, 0.9130434782608695, 0.6635071090047393, 0.7933333333333334, 1.0, 1.0, 0.17182801085987406, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.442576557844803, 0.0, 0.0, 0.8294399451523027, 0.2427055679141853, 0.2427055679141853, 0.33748154311941986], 
reward next is 0.6625, 
noisyNet noise sample is [array([-0.03847653], dtype=float32), -0.4272564]. 
=============================================
[2019-03-27 08:58:28,628] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142000, global step 2268199: loss 3.5242
[2019-03-27 08:58:28,629] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142000, global step 2268201: learning rate 0.0000
[2019-03-27 08:58:28,634] A3C_AGENT_WORKER-Thread-15 INFO:Local step 141500, global step 2268202: loss -45.9366
[2019-03-27 08:58:28,636] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 141500, global step 2268202: learning rate 0.0000
[2019-03-27 08:58:28,809] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 4.7201147e-32 5.5945881e-34 3.2730579e-33 8.8606826e-18], sum to 1.0000
[2019-03-27 08:58:28,816] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.3366
[2019-03-27 08:58:28,821] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.7, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9280320977213011, 6.9112, 6.9112, 168.912956510431, 759076.5392937136, 759076.5392937136, 229756.776801685], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5533200.0000, 
sim time next is 5533800.0000, 
raw observation next is [26.63333333333333, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.926363864871843, 6.9112, 6.9112, 168.912956510431, 757951.0718281247, 757951.0718281247, 229368.603155699], 
processed observation next is [1.0, 0.043478260869565216, 0.46129541864139006, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9101998352095645, 0.0, 0.0, 0.8294399451523027, 0.2105419643967013, 0.2105419643967013, 0.34234119873984925], 
reward next is 0.6577, 
noisyNet noise sample is [array([1.800782], dtype=float32), -0.0743852]. 
=============================================
[2019-03-27 08:58:29,930] A3C_AGENT_WORKER-Thread-20 INFO:Local step 142500, global step 2268807: loss -298.7130
[2019-03-27 08:58:29,932] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 142500, global step 2268809: learning rate 0.0000
[2019-03-27 08:58:30,140] A3C_AGENT_WORKER-Thread-19 INFO:Local step 141500, global step 2268908: loss 0.4893
[2019-03-27 08:58:30,144] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 141500, global step 2268908: learning rate 0.0000
[2019-03-27 08:58:30,346] A3C_AGENT_WORKER-Thread-10 INFO:Local step 141500, global step 2269004: loss -40.6276
[2019-03-27 08:58:30,349] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 141500, global step 2269005: learning rate 0.0000
[2019-03-27 08:58:30,838] A3C_AGENT_WORKER-Thread-16 INFO:Local step 141500, global step 2269231: loss -3.6136
[2019-03-27 08:58:30,842] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 141500, global step 2269231: learning rate 0.0000
[2019-03-27 08:58:31,054] A3C_AGENT_WORKER-Thread-3 INFO:Local step 141500, global step 2269331: loss -49.9531
[2019-03-27 08:58:31,058] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 141500, global step 2269331: learning rate 0.0000
[2019-03-27 08:58:31,338] A3C_AGENT_WORKER-Thread-18 INFO:Local step 141500, global step 2269464: loss -26.8103
[2019-03-27 08:58:31,342] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 141500, global step 2269465: learning rate 0.0000
[2019-03-27 08:58:31,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 141500, global step 2269567: loss -49.7965
[2019-03-27 08:58:31,559] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 141500, global step 2269567: learning rate 0.0000
[2019-03-27 08:58:33,282] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142000, global step 2270373: loss 2.9559
[2019-03-27 08:58:33,284] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142000, global step 2270373: learning rate 0.0000
[2019-03-27 08:58:34,656] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.8875921e-33 1.0946272e-34 1.4910566e-33 1.5603631e-17], sum to 1.0000
[2019-03-27 08:58:34,668] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.4136
[2019-03-27 08:58:34,676] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9209927372680318, 6.911200000000001, 6.9112, 168.912956510431, 753796.3866914505, 753796.3866914499, 228099.9665319984], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5963400.0000, 
sim time next is 5964000.0000, 
raw observation next is [26.76666666666667, 91.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9179349056617474, 6.911200000000001, 6.9112, 168.912956510431, 751684.5762346104, 751684.5762346097, 227392.2107003499], 
processed observation next is [1.0, 0.0, 0.46761453396524505, 0.91, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8999206166606676, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20880127117628067, 0.20880127117628047, 0.3393913592542536], 
reward next is 0.6606, 
noisyNet noise sample is [array([1.371089], dtype=float32), 0.46376064]. 
=============================================
[2019-03-27 08:58:34,692] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[49.949696]
 [50.293865]
 [50.84817 ]
 [52.852833]
 [55.64153 ]], R is [[50.16690445]
 [50.32479095]
 [50.48009491]
 [50.63299179]
 [50.78323364]].
[2019-03-27 08:58:35,397] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142000, global step 2271359: loss 2.6938
[2019-03-27 08:58:35,400] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142000, global step 2271359: learning rate 0.0000
[2019-03-27 08:58:37,673] A3C_AGENT_WORKER-Thread-22 INFO:Local step 142500, global step 2272415: loss -18.5187
[2019-03-27 08:58:37,676] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 142500, global step 2272416: learning rate 0.0000
[2019-03-27 08:58:37,837] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142000, global step 2272493: loss 2.2968
[2019-03-27 08:58:37,839] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142000, global step 2272493: learning rate 0.0000
[2019-03-27 08:58:38,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9999762e-01 7.2568526e-23 1.6221672e-21 1.9077714e-24 2.3668119e-06], sum to 1.0000
[2019-03-27 08:58:38,538] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6621
[2019-03-27 08:58:38,550] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2319312.551417332 W.
[2019-03-27 08:58:38,555] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.23333333333333, 95.0, 1.0, 1.0, 0.5528544961772969, 1.0, 1.0, 0.5528544961772969, 1.0, 2.0, 0.9580898591797419, 6.911199999999999, 6.9112, 170.5573041426782, 2319312.551417332, 2319312.551417333, 453209.6804967345], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5538000.0000, 
sim time next is 5538600.0000, 
raw observation next is [26.2, 95.0, 1.0, 2.0, 0.3483225202697217, 1.0, 2.0, 0.3483225202697217, 1.0, 2.0, 0.6006826137544196, 6.911199999999999, 6.9112, 170.5573041426782, 1460693.877080185, 1460693.877080186, 325626.1150633323], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.95, 1.0, 1.0, 0.21484640996352014, 1.0, 1.0, 0.21484640996352014, 1.0, 1.0, 0.5130275777492921, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4057482991889403, 0.40574829918894056, 0.4860091269601975], 
reward next is 0.5140, 
noisyNet noise sample is [array([-0.1403751], dtype=float32), 0.43673658]. 
=============================================
[2019-03-27 08:58:38,582] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143000, global step 2272831: loss 0.2425
[2019-03-27 08:58:38,586] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143000, global step 2272831: learning rate 0.0000
[2019-03-27 08:58:38,887] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142000, global step 2272971: loss 2.6173
[2019-03-27 08:58:38,891] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142000, global step 2272971: learning rate 0.0000
[2019-03-27 08:58:40,641] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142000, global step 2273973: loss 2.4579
[2019-03-27 08:58:40,644] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142000, global step 2273974: learning rate 0.0000
[2019-03-27 08:58:42,124] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9960917e-01 6.3000912e-20 3.3347912e-20 4.7734380e-22 3.9086555e-04], sum to 1.0000
[2019-03-27 08:58:42,134] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6803
[2019-03-27 08:58:42,140] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1938811.78343051 W.
[2019-03-27 08:58:42,144] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [32.6, 63.0, 1.0, 2.0, 0.4622332567679305, 1.0, 2.0, 0.4622332567679305, 1.0, 2.0, 0.8027463041320005, 6.911200000000001, 6.9112, 170.5573041426782, 1938811.78343051, 1938811.783430509, 390012.4911736057], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 5835600.0000, 
sim time next is 5836200.0000, 
raw observation next is [32.65, 62.66666666666666, 1.0, 2.0, 0.9962520730295009, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.005993116599766, 6.9112, 168.912393130089, 2289756.135576991, 2222506.860433063, 462140.1483310584], 
processed observation next is [1.0, 0.5652173913043478, 0.7464454976303317, 0.6266666666666666, 1.0, 1.0, 0.9954844253367481, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.009479311659976642, 0.0, 0.8294371786969068, 0.6360433709936086, 0.6173630167869619, 0.6897614154194901], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8192395], dtype=float32), 0.2782949]. 
=============================================
[2019-03-27 08:58:42,868] A3C_AGENT_WORKER-Thread-21 INFO:Evaluating...
[2019-03-27 08:58:42,872] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 08:58:42,873] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:58:42,875] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 08:58:42,876] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 08:58:42,878] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 08:58:42,877] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 08:58:42,878] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:58:42,879] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:58:42,880] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:58:42,881] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 08:58:42,958] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run92
[2019-03-27 08:58:42,981] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run92
[2019-03-27 08:58:42,982] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run92
[2019-03-27 08:58:43,001] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run92
[2019-03-27 08:58:43,022] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run92
[2019-03-27 08:59:04,885] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 08:59:04,887] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.6, 71.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5075418077491487, 6.9112, 6.9112, 168.912956510431, 450402.3704334512, 450402.3704334512, 152897.1978302512]
[2019-03-27 08:59:04,888] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 08:59:04,890] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.193979e-38], sampled 0.30115144829223317
[2019-03-27 08:59:05,192] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 08:59:05,194] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.8, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7398476988380956, 6.911199999999999, 6.9112, 168.912956510431, 625911.7252979735, 625911.7252979741, 190032.882222214]
[2019-03-27 08:59:05,195] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:59:05,197] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2164648e-35], sampled 0.10277349557292181
[2019-03-27 08:59:10,945] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 08:59:10,946] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.42015090666667, 94.62618638500001, 1.0, 2.0, 0.8988884419552362, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1256386.646070945, 1256386.646070945, 269630.0657555165]
[2019-03-27 08:59:10,947] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 08:59:10,949] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.7670607e-21 4.2684281e-20 5.7132172e-23 1.7772432e-08], sampled 0.5261942918119485
[2019-03-27 08:59:10,950] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1256386.646070945 W.
[2019-03-27 08:59:43,936] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 08:59:43,937] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [34.0, 67.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.914280012121044, 6.9112, 170.5573041426782, 3628713.820633279, 2910166.805264844, 547868.8677280677]
[2019-03-27 08:59:43,939] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:59:43,942] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9999869e-01 1.4101790e-18 1.0571422e-19 3.4205883e-20 1.3524237e-06], sampled 0.23755585060077888
[2019-03-27 08:59:43,943] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 0, 0, 1] for the demand 3628713.820633279 W.
[2019-03-27 08:59:45,570] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 08:59:45,571] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [31.0, 79.0, 1.0, 2.0, 0.6253095733433646, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 873845.0023829468, 873845.0023829468, 205556.1514635404]
[2019-03-27 08:59:45,572] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 08:59:45,575] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 9.5397155e-28 9.9052044e-30 5.1000122e-28 2.0484012e-16], sampled 0.7228269511531404
[2019-03-27 08:59:45,576] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 873845.0023829468 W.
[2019-03-27 09:00:10,799] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 09:00:10,800] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.35, 95.83333333333333, 1.0, 2.0, 0.9914886188349746, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912889046797, 1385899.45122641, 1385899.45122641, 296344.1369939674]
[2019-03-27 09:00:10,802] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:00:10,804] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9786049e-01 5.0380964e-17 1.1993144e-14 2.3169417e-19 2.1395700e-03], sampled 0.9466076744592475
[2019-03-27 09:00:10,808] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1385899.45122641 W.
[2019-03-27 09:00:22,025] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 09:00:22,029] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.75, 83.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9673784018057185, 6.9112, 6.9112, 168.912956510431, 806929.2664542738, 806929.2664542738, 239984.5353388353]
[2019-03-27 09:00:22,030] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:00:22,032] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0032205e-31], sampled 0.2205113360644796
[2019-03-27 09:00:30,770] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 09:00:30,770] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [33.1, 67.0, 1.0, 2.0, 0.6033144521488355, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.931349437045384, 6.9112, 168.9127808970668, 1686860.777418248, 1672566.088149894, 365201.0353717346]
[2019-03-27 09:00:30,771] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:00:30,775] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 5.0857071e-23 5.5596191e-24 1.1487293e-23 1.3876365e-12], sampled 0.6819671179952709
[2019-03-27 09:00:30,778] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1686860.777418248 W.
[2019-03-27 09:00:37,615] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.072718374]
[2019-03-27 09:00:37,618] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [26.05, 62.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7751404760783795, 6.911200000000001, 6.9112, 168.912956510431, 676620.5694590979, 676620.5694590972, 196826.5254796116]
[2019-03-27 09:00:37,618] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:00:37,621] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.7297347e-34], sampled 0.35561848085949166
[2019-03-27 09:00:38,919] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.3333 3185040186.1099 2465.0000
[2019-03-27 09:00:39,188] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7353.8558 3105995326.8303 2008.0000
[2019-03-27 09:00:39,493] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8065.8661 2938222288.5475 1373.0000
[2019-03-27 09:00:39,496] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7284.4536 3319760010.1910 2151.0000
[2019-03-27 09:00:39,520] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7920.7946 2989468772.4128 1576.0000
[2019-03-27 09:00:40,702] A3C_AGENT_WORKER-Thread-21 INFO:Global step: 2275000, evaluation results [2275000.0, 7284.453589386649, 3319760010.19099, 2151.0, 7353.855761628734, 3105995326.8302846, 2008.0, 8065.8660668569555, 2938222288.5475326, 1373.0, 7030.33334555637, 3185040186.109877, 2465.0, 7920.794623623305, 2989468772.412763, 1576.0]
[2019-03-27 09:00:43,166] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142000, global step 2276165: loss 2.1570
[2019-03-27 09:00:43,169] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142000, global step 2276166: learning rate 0.0000
[2019-03-27 09:00:43,411] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [8.1063694e-01 5.8665057e-16 4.1198175e-15 8.7522657e-19 1.8936309e-01], sum to 1.0000
[2019-03-27 09:00:43,422] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.9753
[2019-03-27 09:00:43,426] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [32.75, 62.0, 1.0, 2.0, 0.7731369806312829, 1.0, 2.0, 0.707158529829904, 1.0, 2.0, 1.03, 7.005103499647665, 6.9112, 170.5573041426782, 2967411.260381711, 2900144.363833943, 545423.4679077717], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5837400.0000, 
sim time next is 5838000.0000, 
raw observation next is [32.8, 61.66666666666667, 1.0, 2.0, 0.7778309192860418, 1.0, 2.0, 0.7095054991572834, 1.0, 2.0, 1.03, 7.005103869854273, 6.9112, 170.5573041426782, 2977271.458987772, 2910004.29724595, 547037.8333679503], 
processed observation next is [1.0, 0.5652173913043478, 0.7535545023696681, 0.6166666666666667, 1.0, 1.0, 0.7323264087783635, 1.0, 1.0, 0.650006625490703, 1.0, 1.0, 1.0365853658536586, 0.009390386985427313, 0.0, 0.8375144448122397, 0.8270198497188256, 0.8083345270127639, 0.8164743781611198], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.6177298], dtype=float32), 1.2764593]. 
=============================================
[2019-03-27 09:00:43,440] A3C_AGENT_WORKER-Thread-14 DEBUG:Value prediction is [[14.176898]
 [15.490194]
 [18.974392]
 [21.695118]
 [23.064682]], R is [[13.77833271]
 [13.64054966]
 [13.50414467]
 [13.36910343]
 [13.2354126 ]].
[2019-03-27 09:00:43,533] A3C_AGENT_WORKER-Thread-9 INFO:Local step 142500, global step 2276330: loss -265.0391
[2019-03-27 09:00:43,539] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 142500, global step 2276331: learning rate 0.0000
[2019-03-27 09:00:44,519] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143000, global step 2276791: loss 0.3718
[2019-03-27 09:00:44,524] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143000, global step 2276793: learning rate 0.0000
[2019-03-27 09:00:44,892] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142000, global step 2276967: loss 1.8908
[2019-03-27 09:00:44,894] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142000, global step 2276967: learning rate 0.0000
[2019-03-27 09:00:44,947] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142000, global step 2276991: loss 1.9852
[2019-03-27 09:00:44,948] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142000, global step 2276991: learning rate 0.0000
[2019-03-27 09:00:45,515] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142000, global step 2277258: loss 2.1500
[2019-03-27 09:00:45,517] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142000, global step 2277258: learning rate 0.0000
[2019-03-27 09:00:45,881] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142000, global step 2277430: loss 2.2058
[2019-03-27 09:00:45,882] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142000, global step 2277431: learning rate 0.0000
[2019-03-27 09:00:46,088] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.3969414e-37], sum to 1.0000
[2019-03-27 09:00:46,095] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.5408
[2019-03-27 09:00:46,098] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.5, 66.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9693647967179332, 6.9112, 6.9112, 168.912956510431, 784796.3819184309, 784796.3819184309, 239474.6512510632], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5764800.0000, 
sim time next is 5765400.0000, 
raw observation next is [31.3, 67.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9655962004460013, 6.911200000000001, 6.9112, 168.912956510431, 782136.294792859, 782136.2947928584, 238556.309298288], 
processed observation next is [0.0, 0.7391304347826086, 0.6824644549763034, 0.675, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9580441468853674, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21726008188690527, 0.21726008188690513, 0.3560541929825194], 
reward next is 0.6439, 
noisyNet noise sample is [array([0.66893584], dtype=float32), 1.7800497]. 
=============================================
[2019-03-27 09:00:46,198] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142000, global step 2277574: loss 2.3131
[2019-03-27 09:00:46,202] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142000, global step 2277574: learning rate 0.0000
[2019-03-27 09:00:46,250] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142000, global step 2277598: loss 2.3995
[2019-03-27 09:00:46,258] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142000, global step 2277599: learning rate 0.0000
[2019-03-27 09:00:48,311] A3C_AGENT_WORKER-Thread-11 INFO:Local step 142500, global step 2278557: loss -246.8108
[2019-03-27 09:00:48,314] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 142500, global step 2278559: learning rate 0.0000
[2019-03-27 09:00:50,574] A3C_AGENT_WORKER-Thread-12 INFO:Local step 142500, global step 2279606: loss 62.8209
[2019-03-27 09:00:50,576] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 142500, global step 2279606: learning rate 0.0000
[2019-03-27 09:00:52,193] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.6472892e-01 3.8971057e-16 3.7039062e-16 1.4903811e-19 8.3527106e-01], sum to 1.0000
[2019-03-27 09:00:52,202] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.7995
[2019-03-27 09:00:52,207] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.0, 68.0, 1.0, 2.0, 0.7995604813246954, 1.0, 1.0, 0.7995604813246954, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2236114.569181982, 2236114.569181982, 419651.266529889], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6447000.0000, 
sim time next is 6447600.0000, 
raw observation next is [30.0, 68.0, 1.0, 2.0, 0.5373460756583457, 1.0, 2.0, 0.5373460756583457, 1.0, 1.0, 0.9228204620231525, 6.9112, 6.9112, 170.5573041426782, 2254193.584394112, 2254193.584394112, 439893.4036447958], 
processed observation next is [1.0, 0.6521739130434783, 0.6208530805687204, 0.68, 1.0, 1.0, 0.442585633323308, 1.0, 1.0, 0.442585633323308, 1.0, 0.5, 0.9058786122233565, 0.0, 0.0, 0.8375144448122397, 0.62616488455392, 0.62616488455392, 0.6565573188728295], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.87655973], dtype=float32), -0.38592896]. 
=============================================
[2019-03-27 09:00:52,497] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143000, global step 2280499: loss 0.1059
[2019-03-27 09:00:52,500] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143000, global step 2280500: learning rate 0.0000
[2019-03-27 09:00:52,598] A3C_AGENT_WORKER-Thread-21 INFO:Local step 142500, global step 2280547: loss -254.3256
[2019-03-27 09:00:52,601] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 142500, global step 2280547: learning rate 0.0000
[2019-03-27 09:00:53,638] A3C_AGENT_WORKER-Thread-13 INFO:Local step 143500, global step 2281034: loss 281.8800
[2019-03-27 09:00:53,642] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 143500, global step 2281034: learning rate 0.0000
[2019-03-27 09:00:53,783] A3C_AGENT_WORKER-Thread-14 INFO:Local step 142500, global step 2281099: loss -123.9414
[2019-03-27 09:00:53,788] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 142500, global step 2281101: learning rate 0.0000
[2019-03-27 09:00:55,831] A3C_AGENT_WORKER-Thread-2 INFO:Local step 142500, global step 2282058: loss -69.5423
[2019-03-27 09:00:55,836] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 142500, global step 2282058: learning rate 0.0000
[2019-03-27 09:00:59,634] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [2.0245227e-01 1.6120911e-17 5.5766049e-15 1.4174798e-19 7.9754776e-01], sum to 1.0000
[2019-03-27 09:00:59,643] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.8335
[2019-03-27 09:00:59,647] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [26.2, 92.0, 1.0, 2.0, 0.3677995848042798, 1.0, 2.0, 0.3677995848042798, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1028040.081594603, 1028040.081594603, 264318.095954493], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5972400.0000, 
sim time next is 5973000.0000, 
raw observation next is [26.18333333333333, 92.16666666666667, 1.0, 2.0, 0.2639096376336084, 1.0, 2.0, 0.2639096376336084, 1.0, 1.0, 0.4504962931152095, 6.9112, 6.9112, 170.5573041426782, 1106524.944549714, 1106524.944549714, 289709.5848253373], 
processed observation next is [1.0, 0.13043478260869565, 0.4399684044233806, 0.9216666666666667, 1.0, 1.0, 0.11314414172723905, 1.0, 1.0, 0.11314414172723905, 1.0, 0.5, 0.32987352818927984, 0.0, 0.0, 0.8375144448122397, 0.3073680401526983, 0.3073680401526983, 0.4324023654109512], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.7935726], dtype=float32), -1.2239888]. 
=============================================
[2019-03-27 09:00:59,660] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[31.658457]
 [31.39261 ]
 [31.442972]
 [32.949707]
 [34.172043]], R is [[31.54042816]
 [31.22502327]
 [30.91277313]
 [31.24695587]
 [30.93448639]].
[2019-03-27 09:00:59,927] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 1.9847297e-36 0.0000000e+00 2.6043127e-37 7.4955761e-22], sum to 1.0000
[2019-03-27 09:00:59,934] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8206
[2019-03-27 09:00:59,937] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.15, 91.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9569464401218463, 6.911199999999999, 6.9112, 168.912956510431, 777355.048049889, 777355.0480498896, 236529.6720447715], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5958600.0000, 
sim time next is 5959200.0000, 
raw observation next is [27.1, 91.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9520211206735012, 6.9112, 6.9112, 168.912956510431, 774101.5132409654, 774101.5132409654, 235355.7137961942], 
processed observation next is [1.0, 1.0, 0.4834123222748816, 0.9166666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9414891715530502, 0.0, 0.0, 0.8294399451523027, 0.2150281981224904, 0.2150281981224904, 0.3512771847704391], 
reward next is 0.6487, 
noisyNet noise sample is [array([0.8736174], dtype=float32), -0.63958836]. 
=============================================
[2019-03-27 09:01:00,352] A3C_AGENT_WORKER-Thread-15 INFO:Local step 142500, global step 2284159: loss -218.9038
[2019-03-27 09:01:00,357] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 142500, global step 2284159: learning rate 0.0000
[2019-03-27 09:01:00,617] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143000, global step 2284280: loss 0.2196
[2019-03-27 09:01:00,621] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143000, global step 2284280: learning rate 0.0000
[2019-03-27 09:01:01,821] A3C_AGENT_WORKER-Thread-20 INFO:Local step 143500, global step 2284833: loss 165.9184
[2019-03-27 09:01:01,823] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 143500, global step 2284834: learning rate 0.0000
[2019-03-27 09:01:01,990] A3C_AGENT_WORKER-Thread-19 INFO:Local step 142500, global step 2284913: loss 51.3389
[2019-03-27 09:01:01,991] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 142500, global step 2284913: learning rate 0.0000
[2019-03-27 09:01:02,055] A3C_AGENT_WORKER-Thread-10 INFO:Local step 142500, global step 2284941: loss -84.9966
[2019-03-27 09:01:02,058] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 142500, global step 2284941: learning rate 0.0000
[2019-03-27 09:01:02,680] A3C_AGENT_WORKER-Thread-16 INFO:Local step 142500, global step 2285232: loss -198.0069
[2019-03-27 09:01:02,683] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 142500, global step 2285233: learning rate 0.0000
[2019-03-27 09:01:03,026] A3C_AGENT_WORKER-Thread-3 INFO:Local step 142500, global step 2285393: loss -117.0589
[2019-03-27 09:01:03,028] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 142500, global step 2285395: learning rate 0.0000
[2019-03-27 09:01:03,196] A3C_AGENT_WORKER-Thread-18 INFO:Local step 142500, global step 2285476: loss 98.5529
[2019-03-27 09:01:03,198] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 142500, global step 2285476: learning rate 0.0000
[2019-03-27 09:01:03,322] A3C_AGENT_WORKER-Thread-17 INFO:Local step 142500, global step 2285537: loss 86.7199
[2019-03-27 09:01:03,324] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 142500, global step 2285537: learning rate 0.0000
[2019-03-27 09:01:03,346] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.07988816e-32], sum to 1.0000
[2019-03-27 09:01:03,356] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.3034
[2019-03-27 09:01:03,358] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8965773223074617, 6.9112, 6.9112, 168.912956510431, 737044.3890597225, 737044.3890597225, 222516.8497207677], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6364200.0000, 
sim time next is 6364800.0000, 
raw observation next is [31.0, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8913631713452873, 6.911200000000001, 6.9112, 168.912956510431, 733743.4330258347, 733743.433025834, 221354.0630983642], 
processed observation next is [0.0, 0.6956521739130435, 0.6682464454976303, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.867516062616204, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2038176202849541, 0.2038176202849539, 0.3303791986542749], 
reward next is 0.6696, 
noisyNet noise sample is [array([0.3319902], dtype=float32), -1.4297742]. 
=============================================
[2019-03-27 09:01:05,230] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143000, global step 2286428: loss 0.2727
[2019-03-27 09:01:05,231] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143000, global step 2286428: learning rate 0.0000
[2019-03-27 09:01:07,450] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143000, global step 2287464: loss 0.2897
[2019-03-27 09:01:07,452] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143000, global step 2287464: learning rate 0.0000
[2019-03-27 09:01:09,628] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143000, global step 2288475: loss 0.3844
[2019-03-27 09:01:09,629] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143000, global step 2288475: learning rate 0.0000
[2019-03-27 09:01:09,681] A3C_AGENT_WORKER-Thread-22 INFO:Local step 143500, global step 2288497: loss 126.7420
[2019-03-27 09:01:09,687] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 143500, global step 2288500: learning rate 0.0000
[2019-03-27 09:01:10,047] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.6235389e-01 1.9905853e-17 3.5516763e-17 1.3174475e-20 3.7646122e-02], sum to 1.0000
[2019-03-27 09:01:10,058] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0184
[2019-03-27 09:01:10,065] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1954729.390829089 W.
[2019-03-27 09:01:10,071] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.46666666666667, 76.0, 1.0, 2.0, 0.466024724104293, 1.0, 2.0, 0.466024724104293, 1.0, 2.0, 0.8093308290378539, 6.911200000000001, 6.9112, 170.5573041426782, 1954729.390829089, 1954729.390829088, 392446.1538070288], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6175200.0000, 
sim time next is 6175800.0000, 
raw observation next is [29.55, 75.5, 1.0, 2.0, 0.4776917724014975, 1.0, 2.0, 0.4776917724014975, 1.0, 2.0, 0.8295926335782672, 6.9112, 6.9112, 170.5573041426782, 2003712.305076965, 2003712.305076965, 400061.657383363], 
processed observation next is [1.0, 0.4782608695652174, 0.5995260663507109, 0.755, 1.0, 1.0, 0.37071297879698495, 1.0, 1.0, 0.37071297879698495, 1.0, 1.0, 0.7921861385100818, 0.0, 0.0, 0.8375144448122397, 0.556586751410268, 0.556586751410268, 0.5971069513184523], 
reward next is 0.4029, 
noisyNet noise sample is [array([1.6957029], dtype=float32), 0.9685198]. 
=============================================
[2019-03-27 09:01:10,609] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144000, global step 2288928: loss 11.4332
[2019-03-27 09:01:10,610] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144000, global step 2288928: learning rate 0.0000
[2019-03-27 09:01:10,737] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143000, global step 2288991: loss 0.2792
[2019-03-27 09:01:10,741] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143000, global step 2288992: learning rate 0.0000
[2019-03-27 09:01:11,367] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.2927978e-32], sum to 1.0000
[2019-03-27 09:01:11,377] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8586
[2019-03-27 09:01:11,382] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.25, 69.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9171440247313454, 6.9112, 6.9112, 168.912956510431, 751240.2758638058, 751240.2758638058, 227214.0115163591], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6343800.0000, 
sim time next is 6344400.0000, 
raw observation next is [30.4, 68.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9199347958841663, 6.911199999999999, 6.9112, 168.912956510431, 753197.3754166673, 753197.3754166679, 227860.6671449768], 
processed observation next is [0.0, 0.43478260869565216, 0.6398104265402843, 0.6866666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9023595071758124, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20922149317129649, 0.20922149317129665, 0.3400905479775773], 
reward next is 0.6599, 
noisyNet noise sample is [array([-0.3709104], dtype=float32), -0.73827595]. 
=============================================
[2019-03-27 09:01:12,724] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143000, global step 2289921: loss 0.2729
[2019-03-27 09:01:12,727] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143000, global step 2289924: learning rate 0.0000
[2019-03-27 09:01:17,447] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143000, global step 2292135: loss 0.3811
[2019-03-27 09:01:17,451] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143000, global step 2292136: learning rate 0.0000
[2019-03-27 09:01:17,817] A3C_AGENT_WORKER-Thread-9 INFO:Local step 143500, global step 2292307: loss 130.7919
[2019-03-27 09:01:17,819] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 143500, global step 2292307: learning rate 0.0000
[2019-03-27 09:01:18,652] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144000, global step 2292690: loss 11.8757
[2019-03-27 09:01:18,652] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144000, global step 2292690: learning rate 0.0000
[2019-03-27 09:01:18,729] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.0369933e-31], sum to 1.0000
[2019-03-27 09:01:18,736] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.4289
[2019-03-27 09:01:18,740] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.61666666666667, 62.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8603093755949257, 6.9112, 6.9112, 168.912956510431, 712962.4017829741, 712962.4017829741, 214516.5469014432], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6277800.0000, 
sim time next is 6278400.0000, 
raw observation next is [30.6, 63.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8605013934145584, 6.911199999999999, 6.9112, 168.912956510431, 712969.6614769972, 712969.6614769978, 214554.1145083395], 
processed observation next is [0.0, 0.6956521739130435, 0.6492890995260664, 0.63, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8298797480665348, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19804712818805478, 0.19804712818805495, 0.32023002165423803], 
reward next is 0.6798, 
noisyNet noise sample is [array([0.61477536], dtype=float32), 1.4022007]. 
=============================================
[2019-03-27 09:01:19,141] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143000, global step 2292919: loss 0.3004
[2019-03-27 09:01:19,143] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143000, global step 2292919: learning rate 0.0000
[2019-03-27 09:01:19,246] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143000, global step 2292970: loss 0.2862
[2019-03-27 09:01:19,249] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143000, global step 2292971: learning rate 0.0000
[2019-03-27 09:01:19,308] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7171461e-32], sum to 1.0000
[2019-03-27 09:01:19,316] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0691
[2019-03-27 09:01:19,323] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.7, 76.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8879238815485201, 6.9112, 6.9112, 168.912956510431, 731605.5632036045, 731605.5632036045, 220592.0170334174], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6289200.0000, 
sim time next is 6289800.0000, 
raw observation next is [28.55, 77.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8935919171138564, 6.911199999999999, 6.9112, 168.912956510431, 735718.1373429636, 735718.1373429642, 221872.560134357], 
processed observation next is [0.0, 0.8260869565217391, 0.552132701421801, 0.7716666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8702340452608005, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20436614926193433, 0.2043661492619345, 0.3311530748273985], 
reward next is 0.6688, 
noisyNet noise sample is [array([2.6108525], dtype=float32), -0.8857544]. 
=============================================
[2019-03-27 09:01:19,750] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143000, global step 2293203: loss 0.2512
[2019-03-27 09:01:19,752] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143000, global step 2293203: learning rate 0.0000
[2019-03-27 09:01:20,129] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143000, global step 2293378: loss 0.2093
[2019-03-27 09:01:20,132] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143000, global step 2293379: learning rate 0.0000
[2019-03-27 09:01:20,546] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143000, global step 2293570: loss 0.1959
[2019-03-27 09:01:20,547] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143000, global step 2293570: learning rate 0.0000
[2019-03-27 09:01:20,601] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143000, global step 2293598: loss 0.2037
[2019-03-27 09:01:20,603] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143000, global step 2293598: learning rate 0.0000
[2019-03-27 09:01:22,893] A3C_AGENT_WORKER-Thread-11 INFO:Local step 143500, global step 2294670: loss 258.1102
[2019-03-27 09:01:22,895] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 143500, global step 2294671: learning rate 0.0000
[2019-03-27 09:01:24,874] A3C_AGENT_WORKER-Thread-12 INFO:Local step 143500, global step 2295591: loss 58.3234
[2019-03-27 09:01:24,875] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 143500, global step 2295591: learning rate 0.0000
[2019-03-27 09:01:26,896] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144000, global step 2296533: loss 11.1254
[2019-03-27 09:01:26,897] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144000, global step 2296533: learning rate 0.0000
[2019-03-27 09:01:27,071] A3C_AGENT_WORKER-Thread-21 INFO:Local step 143500, global step 2296616: loss 81.4544
[2019-03-27 09:01:27,075] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 143500, global step 2296617: learning rate 0.0000
[2019-03-27 09:01:27,704] A3C_AGENT_WORKER-Thread-13 INFO:Local step 144500, global step 2296907: loss -0.0346
[2019-03-27 09:01:27,709] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 144500, global step 2296907: learning rate 0.0000
[2019-03-27 09:01:27,782] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [2.1705119e-01 1.5369363e-18 2.7900491e-17 1.9079947e-20 7.8294885e-01], sum to 1.0000
[2019-03-27 09:01:27,791] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.4191
[2019-03-27 09:01:27,801] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.5, 80.5, 1.0, 2.0, 0.7417987009918705, 1.0, 2.0, 0.7417987009918705, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2074420.197659697, 2074420.197659697, 392530.7295538479], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6623400.0000, 
sim time next is 6624000.0000, 
raw observation next is [28.0, 84.0, 1.0, 2.0, 0.4782199903668443, 1.0, 2.0, 0.4782199903668443, 1.0, 1.0, 0.8279405194014796, 6.9112, 6.9112, 170.5573041426782, 2005930.027411324, 2005930.027411324, 399970.8011800571], 
processed observation next is [1.0, 0.6956521739130435, 0.5260663507109005, 0.84, 1.0, 1.0, 0.3713493859841498, 1.0, 1.0, 0.3713493859841498, 1.0, 0.5, 0.7901713651237555, 0.0, 0.0, 0.8375144448122397, 0.5572027853920344, 0.5572027853920344, 0.5969713450448614], 
reward next is 0.4030, 
noisyNet noise sample is [array([2.5978863], dtype=float32), -0.21824747]. 
=============================================
[2019-03-27 09:01:27,825] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[26.606241]
 [25.283829]
 [26.509308]
 [26.71776 ]
 [27.268053]], R is [[27.27693939]
 [27.41830254]
 [27.55778503]
 [27.28509903]
 [27.02751541]].
[2019-03-27 09:01:27,986] A3C_AGENT_WORKER-Thread-14 INFO:Local step 143500, global step 2297037: loss 79.9499
[2019-03-27 09:01:27,988] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 143500, global step 2297037: learning rate 0.0000
[2019-03-27 09:01:30,130] A3C_AGENT_WORKER-Thread-2 INFO:Local step 143500, global step 2298032: loss 69.2454
[2019-03-27 09:01:30,133] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 143500, global step 2298033: learning rate 0.0000
[2019-03-27 09:01:30,804] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0187575e-01 1.6045489e-15 4.7796337e-13 3.6195170e-18 7.9812419e-01], sum to 1.0000
[2019-03-27 09:01:30,811] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.5181
[2019-03-27 09:01:30,816] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.36666666666667, 69.33333333333334, 1.0, 2.0, 0.4395596170670081, 1.0, 2.0, 0.4395596170670081, 1.0, 2.0, 0.7498963830091879, 6.911199999999999, 6.9112, 170.5573041426782, 1843626.634646991, 1843626.634646992, 373743.4398759793], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6514800.0000, 
sim time next is 6515400.0000, 
raw observation next is [29.58333333333334, 67.66666666666666, 1.0, 2.0, 0.4460254170207913, 1.0, 2.0, 0.4460254170207913, 1.0, 2.0, 0.760289697772916, 6.9112, 6.9112, 170.5573041426782, 1870769.545838185, 1870769.545838185, 377532.8470603269], 
processed observation next is [1.0, 0.391304347826087, 0.6011058451816749, 0.6766666666666665, 1.0, 1.0, 0.33256074339854375, 1.0, 1.0, 0.33256074339854375, 1.0, 1.0, 0.7076703631377024, 0.0, 0.0, 0.8375144448122397, 0.5196582071772736, 0.5196582071772736, 0.56348186128407], 
reward next is 0.4365, 
noisyNet noise sample is [array([0.93402565], dtype=float32), -0.184295]. 
=============================================
[2019-03-27 09:01:30,822] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 2.6762586e-32 1.8607456e-34 2.7726538e-32 5.1746864e-17], sum to 1.0000
[2019-03-27 09:01:30,827] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4484
[2019-03-27 09:01:30,830] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.2, 67.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7635804023648789, 6.9112, 6.9112, 168.912956510431, 636717.6100685508, 636717.6100685508, 194431.4745928326], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6715800.0000, 
sim time next is 6716400.0000, 
raw observation next is [29.06666666666667, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7736264026280448, 6.911200000000001, 6.9112, 168.912956510431, 646354.0395752633, 646354.0395752627, 196446.0517713877], 
processed observation next is [1.0, 0.7391304347826086, 0.5766192733017379, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7239346373512742, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.17954278877090646, 0.1795427887709063, 0.29320306234535476], 
reward next is 0.7068, 
noisyNet noise sample is [array([1.7769176], dtype=float32), 1.123571]. 
=============================================
[2019-03-27 09:01:34,002] A3C_AGENT_WORKER-Thread-20 INFO:Evaluating...
[2019-03-27 09:01:34,003] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:01:34,004] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:01:34,005] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:01:34,005] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:01:34,009] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:01:34,007] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:01:34,009] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:01:34,011] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:01:34,011] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:01:34,013] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:01:34,039] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run93
[2019-03-27 09:01:34,059] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run93
[2019-03-27 09:01:34,080] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run93
[2019-03-27 09:01:34,110] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run93
[2019-03-27 09:01:34,111] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run93
[2019-03-27 09:01:40,112] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:01:40,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [21.4, 75.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4602147976085612, 6.9112, 6.9112, 168.912956510431, 410582.0505286108, 410582.0505286108, 147093.6505736902]
[2019-03-27 09:01:40,116] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:01:40,120] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.1832183e-33], sampled 0.08794493803331116
[2019-03-27 09:02:00,872] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:02:00,874] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [22.23829329333334, 86.68066828333335, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7499151397524947, 6.9112, 6.9112, 168.912956510431, 652446.0401840691, 652446.0401840691, 191930.3051462649]
[2019-03-27 09:02:00,875] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:02:00,879] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.1338833e-35], sampled 0.3690471849475401
[2019-03-27 09:02:14,364] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:02:14,365] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [32.53333333333333, 61.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9626141770401134, 6.9112, 6.9112, 168.912956510431, 781460.7651337695, 781460.7651337695, 237906.3440621005]
[2019-03-27 09:02:14,366] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:02:14,368] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.728558e-29], sampled 0.2805229452751157
[2019-03-27 09:02:49,412] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:02:49,415] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.44915396, 56.34781365, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8957468185482157, 6.9112, 6.9112, 168.912956510431, 737417.414863517, 737417.414863517, 222367.7891689141]
[2019-03-27 09:02:49,417] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:02:49,421] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.418202e-33], sampled 0.8164839302794845
[2019-03-27 09:03:07,350] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:03:07,351] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [28.8, 77.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9274070095213867, 6.9112, 6.9112, 168.912956510431, 760582.8348248418, 760582.8348248418, 229695.6785598615]
[2019-03-27 09:03:07,355] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:03:07,359] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.4111067e-30], sampled 0.7027244669262398
[2019-03-27 09:03:14,444] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:03:14,445] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.86666666666667, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6042840302378486, 6.9112, 6.9112, 168.912956510431, 527164.0548596551, 527164.0548596551, 166713.8464079702]
[2019-03-27 09:03:14,447] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:03:14,450] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5890058e-29], sampled 0.4061885472637353
[2019-03-27 09:03:27,005] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.07440851]
[2019-03-27 09:03:27,010] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [33.211779645, 64.094696435, 1.0, 2.0, 0.9771039232622473, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1365779.637704696, 1365779.637704696, 292032.4788058901]
[2019-03-27 09:03:27,012] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:03:27,015] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9011856e-01 7.5944531e-17 1.5996903e-14 6.2652050e-19 9.8814843e-03], sampled 0.6551068099581152
[2019-03-27 09:03:27,016] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1365779.637704696 W.
[2019-03-27 09:03:30,048] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7919.4814 2989907726.3185 1566.0000
[2019-03-27 09:03:30,483] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7027.5099 3186157667.9155 2446.0000
[2019-03-27 09:03:30,585] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7273.7275 3320080710.3697 2159.0000
[2019-03-27 09:03:30,705] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8086.6894 2937509115.0990 1281.0000
[2019-03-27 09:03:30,808] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7384.5741 3104959812.2577 1904.0000
[2019-03-27 09:03:31,829] A3C_AGENT_WORKER-Thread-20 INFO:Global step: 2300000, evaluation results [2300000.0, 7273.727535114224, 3320080710.3697014, 2159.0, 7384.574083913593, 3104959812.2576585, 1904.0, 8086.689359736863, 2937509115.098999, 1281.0, 7027.509940714642, 3186157667.9155483, 2446.0, 7919.481353738597, 2989907726.3185263, 1566.0]
[2019-03-27 09:03:32,198] A3C_AGENT_WORKER-Thread-15 INFO:Local step 143500, global step 2300170: loss 88.4165
[2019-03-27 09:03:32,202] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 143500, global step 2300171: learning rate 0.0000
[2019-03-27 09:03:32,297] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144000, global step 2300217: loss 12.0044
[2019-03-27 09:03:32,299] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144000, global step 2300217: learning rate 0.0000
[2019-03-27 09:03:32,545] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.4504079e-32 2.7933525e-34 5.3758545e-33 4.1115562e-18], sum to 1.0000
[2019-03-27 09:03:32,555] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8973
[2019-03-27 09:03:32,563] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.25, 89.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.869944388692145, 6.9112, 6.9112, 168.912956510431, 719729.7029269831, 719729.7029269831, 216624.9064841985], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6573000.0000, 
sim time next is 6573600.0000, 
raw observation next is [26.2, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8669827831674768, 6.9112, 6.9112, 168.912956510431, 717557.7162522693, 717557.7162522693, 215971.263905295], 
processed observation next is [1.0, 0.08695652173913043, 0.44075829383886256, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8377838819115571, 0.0, 0.0, 0.8294399451523027, 0.1993215878478526, 0.1993215878478526, 0.32234517000790297], 
reward next is 0.6777, 
noisyNet noise sample is [array([-1.6234306], dtype=float32), 0.017435879]. 
=============================================
[2019-03-27 09:03:32,944] A3C_AGENT_WORKER-Thread-20 INFO:Local step 144500, global step 2300518: loss -178.8162
[2019-03-27 09:03:32,945] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 144500, global step 2300518: learning rate 0.0000
[2019-03-27 09:03:33,899] A3C_AGENT_WORKER-Thread-10 INFO:Local step 143500, global step 2300969: loss 13.3674
[2019-03-27 09:03:33,902] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 143500, global step 2300969: learning rate 0.0000
[2019-03-27 09:03:33,980] A3C_AGENT_WORKER-Thread-19 INFO:Local step 143500, global step 2301000: loss 28.9578
[2019-03-27 09:03:33,982] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 143500, global step 2301000: learning rate 0.0000
[2019-03-27 09:03:34,439] A3C_AGENT_WORKER-Thread-16 INFO:Local step 143500, global step 2301214: loss 98.6449
[2019-03-27 09:03:34,443] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 143500, global step 2301214: learning rate 0.0000
[2019-03-27 09:03:34,853] A3C_AGENT_WORKER-Thread-3 INFO:Local step 143500, global step 2301407: loss 116.7540
[2019-03-27 09:03:34,856] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 143500, global step 2301408: learning rate 0.0000
[2019-03-27 09:03:35,170] A3C_AGENT_WORKER-Thread-18 INFO:Local step 143500, global step 2301556: loss 267.8565
[2019-03-27 09:03:35,171] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 143500, global step 2301556: learning rate 0.0000
[2019-03-27 09:03:35,305] A3C_AGENT_WORKER-Thread-17 INFO:Local step 143500, global step 2301620: loss 90.3316
[2019-03-27 09:03:35,307] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 143500, global step 2301620: learning rate 0.0000
[2019-03-27 09:03:37,370] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144000, global step 2302579: loss 12.6652
[2019-03-27 09:03:37,374] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144000, global step 2302579: learning rate 0.0000
[2019-03-27 09:03:39,362] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144000, global step 2303505: loss 12.7426
[2019-03-27 09:03:39,365] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144000, global step 2303507: learning rate 0.0000
[2019-03-27 09:03:41,545] A3C_AGENT_WORKER-Thread-22 INFO:Local step 144500, global step 2304491: loss 23.8592
[2019-03-27 09:03:41,547] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 144500, global step 2304493: learning rate 0.0000
[2019-03-27 09:03:41,655] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144000, global step 2304543: loss 12.7557
[2019-03-27 09:03:41,658] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144000, global step 2304543: learning rate 0.0000
[2019-03-27 09:03:41,819] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 1.3524166e-34 4.6081613e-36 4.8305329e-34 3.1409247e-20], sum to 1.0000
[2019-03-27 09:03:41,832] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8676
[2019-03-27 09:03:41,835] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.0, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5878917990872685, 6.9112, 6.9112, 168.912956510431, 513667.982898969, 513667.982898969, 164220.6011840683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6744000.0000, 
sim time next is 6744600.0000, 
raw observation next is [22.85, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5857183844578365, 6.9112, 6.9112, 168.912956510431, 512050.2102336512, 512050.2102336512, 163891.2694844784], 
processed observation next is [1.0, 0.043478260869565216, 0.28199052132701435, 0.81, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.49477851763150793, 0.0, 0.0, 0.8294399451523027, 0.14223616950934756, 0.14223616950934756, 0.24461383505146028], 
reward next is 0.7554, 
noisyNet noise sample is [array([0.94405794], dtype=float32), -0.13791296]. 
=============================================
[2019-03-27 09:03:42,320] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145000, global step 2304857: loss 0.0981
[2019-03-27 09:03:42,327] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145000, global step 2304857: learning rate 0.0000
[2019-03-27 09:03:42,451] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144000, global step 2304915: loss 12.6874
[2019-03-27 09:03:42,454] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144000, global step 2304915: learning rate 0.0000
[2019-03-27 09:03:44,681] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144000, global step 2305956: loss 12.7766
[2019-03-27 09:03:44,685] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144000, global step 2305956: learning rate 0.0000
[2019-03-27 09:03:49,135] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.8375818e-32], sum to 1.0000
[2019-03-27 09:03:49,145] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8789
[2019-03-27 09:03:49,152] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.9, 69.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6596033514003978, 6.9112, 6.9112, 168.912956510431, 568896.106408441, 568896.106408441, 175695.7794126432], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6857400.0000, 
sim time next is 6858000.0000, 
raw observation next is [26.1, 68.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.655307534228726, 6.9112, 6.9112, 168.912956510431, 565620.250718045, 565620.250718045, 174971.8625850313], 
processed observation next is [0.0, 0.391304347826087, 0.4360189573459717, 0.68, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5796433344252756, 0.0, 0.0, 0.8294399451523027, 0.15711673631056808, 0.15711673631056808, 0.261152033709002], 
reward next is 0.7388, 
noisyNet noise sample is [array([-0.8816621], dtype=float32), -1.121994]. 
=============================================
[2019-03-27 09:03:49,170] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[77.26162]
 [77.2587 ]
 [77.27574]
 [77.29734]
 [77.32872]], R is [[77.35485077]
 [77.31907654]
 [77.28262329]
 [77.24562073]
 [77.20835876]].
[2019-03-27 09:03:49,354] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144000, global step 2308126: loss 12.5486
[2019-03-27 09:03:49,356] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144000, global step 2308127: learning rate 0.0000
[2019-03-27 09:03:49,531] A3C_AGENT_WORKER-Thread-9 INFO:Local step 144500, global step 2308212: loss -127.1928
[2019-03-27 09:03:49,533] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 144500, global step 2308213: learning rate 0.0000
[2019-03-27 09:03:50,248] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145000, global step 2308543: loss 0.1014
[2019-03-27 09:03:50,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145000, global step 2308545: learning rate 0.0000
[2019-03-27 09:03:51,247] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144000, global step 2309006: loss 12.4009
[2019-03-27 09:03:51,250] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144000, global step 2309007: learning rate 0.0000
[2019-03-27 09:03:51,411] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144000, global step 2309084: loss 12.2095
[2019-03-27 09:03:51,413] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144000, global step 2309084: learning rate 0.0000
[2019-03-27 09:03:51,479] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144000, global step 2309112: loss 12.1148
[2019-03-27 09:03:51,482] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144000, global step 2309112: learning rate 0.0000
[2019-03-27 09:03:52,151] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144000, global step 2309430: loss 11.9723
[2019-03-27 09:03:52,153] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144000, global step 2309430: learning rate 0.0000
[2019-03-27 09:03:52,694] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144000, global step 2309677: loss 11.5484
[2019-03-27 09:03:52,696] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144000, global step 2309677: learning rate 0.0000
[2019-03-27 09:03:52,791] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144000, global step 2309721: loss 11.4495
[2019-03-27 09:03:52,792] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144000, global step 2309721: learning rate 0.0000
[2019-03-27 09:03:53,574] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.4933449e-33 7.6559938e-36 3.3537195e-33 1.0266229e-17], sum to 1.0000
[2019-03-27 09:03:53,583] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.1019
[2019-03-27 09:03:53,589] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.83333333333334, 93.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8240681474516505, 6.9112, 6.9112, 168.912956510431, 692191.7385777482, 692191.7385777482, 206902.355189341], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7708800.0000, 
sim time next is 7709400.0000, 
raw observation next is [25.0, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8277076542718759, 6.9112, 6.9112, 168.912956510431, 694343.2761949665, 694343.2761949665, 207658.0369307119], 
processed observation next is [1.0, 0.21739130434782608, 0.38388625592417064, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.789887383258385, 0.0, 0.0, 0.8294399451523027, 0.1928731322763796, 0.1928731322763796, 0.30993736855330134], 
reward next is 0.6901, 
noisyNet noise sample is [array([-1.2568021], dtype=float32), 0.39071432]. 
=============================================
[2019-03-27 09:03:54,575] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9967897e-28], sum to 1.0000
[2019-03-27 09:03:54,584] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1195
[2019-03-27 09:03:54,596] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.2, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7456237537866844, 6.911199999999999, 6.9112, 168.912956510431, 631996.9600349625, 631996.9600349631, 191149.8249772356], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6944400.0000, 
sim time next is 6945000.0000, 
raw observation next is [28.35, 65.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7454135854515163, 6.9112, 6.9112, 168.912956510431, 631599.922484929, 631599.922484929, 191106.9539358968], 
processed observation next is [0.0, 0.391304347826087, 0.5426540284360191, 0.6533333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6895287627457516, 0.0, 0.0, 0.8294399451523027, 0.17544442291248027, 0.17544442291248027, 0.2852342596058161], 
reward next is 0.7148, 
noisyNet noise sample is [array([-0.7227892], dtype=float32), 0.5917073]. 
=============================================
[2019-03-27 09:03:54,601] A3C_AGENT_WORKER-Thread-11 INFO:Local step 144500, global step 2310564: loss -45.4957
[2019-03-27 09:03:54,606] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 144500, global step 2310565: learning rate 0.0000
[2019-03-27 09:03:54,614] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.54297]
 [74.38796]
 [74.3535 ]
 [74.34144]
 [74.33207]], R is [[74.63009644]
 [74.59849548]
 [74.56771851]
 [74.53762817]
 [74.50804138]].
[2019-03-27 09:03:56,748] A3C_AGENT_WORKER-Thread-12 INFO:Local step 144500, global step 2311565: loss 0.0436
[2019-03-27 09:03:56,751] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 144500, global step 2311567: learning rate 0.0000
[2019-03-27 09:03:58,464] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [2.2594213e-02 2.9033783e-18 3.7666953e-17 4.2765914e-22 9.7740585e-01], sum to 1.0000
[2019-03-27 09:03:58,475] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.5519
[2019-03-27 09:03:58,482] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.46666666666667, 62.0, 1.0, 2.0, 0.4925200732848399, 1.0, 2.0, 0.4925200732848399, 1.0, 2.0, 0.8381380732195786, 6.9112, 6.9112, 170.5573041426782, 2065970.648677055, 2065970.648677055, 406917.3044218846], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7656000.0000, 
sim time next is 7656600.0000, 
raw observation next is [30.33333333333333, 63.0, 1.0, 2.0, 0.4918388883049808, 1.0, 2.0, 0.4918388883049808, 1.0, 2.0, 0.8376326162404149, 6.9112, 6.9112, 170.5573041426782, 2063110.535126926, 2063110.535126926, 406582.2307403086], 
processed observation next is [1.0, 0.6086956521739131, 0.6366508688783569, 0.63, 1.0, 1.0, 0.3877576967529889, 1.0, 1.0, 0.3877576967529889, 1.0, 1.0, 0.8019909954151401, 0.0, 0.0, 0.8375144448122397, 0.5730862597574794, 0.5730862597574794, 0.6068391503586695], 
reward next is 0.3932, 
noisyNet noise sample is [array([0.832022], dtype=float32), -0.3081009]. 
=============================================
[2019-03-27 09:03:58,808] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145000, global step 2312523: loss 0.0601
[2019-03-27 09:03:58,811] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145000, global step 2312523: learning rate 0.0000
[2019-03-27 09:03:58,848] A3C_AGENT_WORKER-Thread-21 INFO:Local step 144500, global step 2312540: loss -1.1252
[2019-03-27 09:03:58,850] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 144500, global step 2312540: learning rate 0.0000
[2019-03-27 09:03:59,484] A3C_AGENT_WORKER-Thread-13 INFO:Local step 145500, global step 2312836: loss 0.9104
[2019-03-27 09:03:59,485] A3C_AGENT_WORKER-Thread-13 DEBUG:Local step 145500, global step 2312836: learning rate 0.0000
[2019-03-27 09:03:59,753] A3C_AGENT_WORKER-Thread-14 INFO:Local step 144500, global step 2312960: loss -153.6746
[2019-03-27 09:03:59,757] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 144500, global step 2312960: learning rate 0.0000
[2019-03-27 09:04:01,958] A3C_AGENT_WORKER-Thread-2 INFO:Local step 144500, global step 2313995: loss -29.9068
[2019-03-27 09:04:01,959] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 144500, global step 2313995: learning rate 0.0000
[2019-03-27 09:04:06,526] A3C_AGENT_WORKER-Thread-15 INFO:Local step 144500, global step 2316137: loss 0.1111
[2019-03-27 09:04:06,532] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 144500, global step 2316139: learning rate 0.0000
[2019-03-27 09:04:06,598] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145000, global step 2316167: loss 0.1434
[2019-03-27 09:04:06,601] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145000, global step 2316167: learning rate 0.0000
[2019-03-27 09:04:07,248] A3C_AGENT_WORKER-Thread-20 INFO:Local step 145500, global step 2316471: loss 0.2446
[2019-03-27 09:04:07,252] A3C_AGENT_WORKER-Thread-20 DEBUG:Local step 145500, global step 2316471: learning rate 0.0000
[2019-03-27 09:04:08,238] A3C_AGENT_WORKER-Thread-10 INFO:Local step 144500, global step 2316935: loss -2.8503
[2019-03-27 09:04:08,239] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 144500, global step 2316935: learning rate 0.0000
[2019-03-27 09:04:08,313] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:04:08,314] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:08,391] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-13_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res8/Eplus-env-sub_run12
[2019-03-27 09:04:08,513] A3C_AGENT_WORKER-Thread-19 INFO:Local step 144500, global step 2317050: loss -56.6494
[2019-03-27 09:04:08,514] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 144500, global step 2317050: learning rate 0.0000
[2019-03-27 09:04:08,608] A3C_AGENT_WORKER-Thread-16 INFO:Local step 144500, global step 2317103: loss -303.5547
[2019-03-27 09:04:08,611] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 144500, global step 2317105: learning rate 0.0000
[2019-03-27 09:04:09,007] A3C_AGENT_WORKER-Thread-3 INFO:Local step 144500, global step 2317335: loss -271.3853
[2019-03-27 09:04:09,009] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 144500, global step 2317336: learning rate 0.0000
[2019-03-27 09:04:09,381] A3C_AGENT_WORKER-Thread-18 INFO:Local step 144500, global step 2317553: loss -60.5130
[2019-03-27 09:04:09,386] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 144500, global step 2317555: learning rate 0.0000
[2019-03-27 09:04:09,393] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 4.2388572e-38 4.9708113e-25], sum to 1.0000
[2019-03-27 09:04:09,396] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6757
[2019-03-27 09:04:09,399] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.38333333333333, 91.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.564998760545832, 6.9112, 6.9112, 168.912956510431, 494844.2001520861, 494844.2001520861, 160856.7662470466], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7438200.0000, 
sim time next is 7438800.0000, 
raw observation next is [21.36666666666667, 91.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5648620509011754, 6.9112, 6.9112, 168.912956510431, 494711.8894483713, 494711.8894483713, 160837.6228105339], 
processed observation next is [0.0, 0.08695652173913043, 0.21169036334913136, 0.9133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4693439645136285, 0.0, 0.0, 0.8294399451523027, 0.13741996929121425, 0.13741996929121425, 0.24005615344855807], 
reward next is 0.7599, 
noisyNet noise sample is [array([-0.31409875], dtype=float32), 0.43442646]. 
=============================================
[2019-03-27 09:04:09,545] A3C_AGENT_WORKER-Thread-17 INFO:Local step 144500, global step 2317652: loss -132.1338
[2019-03-27 09:04:09,547] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 144500, global step 2317652: learning rate 0.0000
[2019-03-27 09:04:09,558] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [2.1807174e-01 4.8974002e-17 6.9208741e-15 1.9537051e-19 7.8192830e-01], sum to 1.0000
[2019-03-27 09:04:09,568] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8585
[2019-03-27 09:04:09,571] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [24.36666666666666, 81.83333333333333, 1.0, 2.0, 0.2943745894403081, 1.0, 1.0, 0.2943745894403081, 1.0, 1.0, 0.5066403402382511, 6.9112, 6.9112, 170.5573041426782, 1296040.262031978, 1296040.262031978, 307448.045561758], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7231800.0000, 
sim time next is 7232400.0000, 
raw observation next is [24.4, 81.0, 1.0, 2.0, 0.2919970397974454, 1.0, 2.0, 0.2919970397974454, 1.0, 2.0, 0.5027214892601752, 6.9112, 6.9112, 170.5573041426782, 1286221.86876405, 1286221.86876405, 306541.7207807761], 
processed observation next is [1.0, 0.7391304347826086, 0.3554502369668246, 0.81, 1.0, 1.0, 0.146984385298127, 1.0, 1.0, 0.146984385298127, 1.0, 1.0, 0.39356279178070147, 0.0, 0.0, 0.8375144448122397, 0.35728385243445837, 0.35728385243445837, 0.4575249563892181], 
reward next is 0.5425, 
noisyNet noise sample is [array([2.1775007], dtype=float32), 0.22149926]. 
=============================================
[2019-03-27 09:04:11,141] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145000, global step 2318398: loss 0.1535
[2019-03-27 09:04:11,146] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145000, global step 2318398: learning rate 0.0000
[2019-03-27 09:04:13,367] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145000, global step 2319438: loss 0.1478
[2019-03-27 09:04:13,370] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145000, global step 2319438: learning rate 0.0000
[2019-03-27 09:04:15,232] A3C_AGENT_WORKER-Thread-22 INFO:Local step 145500, global step 2320314: loss 1.2747
[2019-03-27 09:04:15,234] A3C_AGENT_WORKER-Thread-22 DEBUG:Local step 145500, global step 2320315: learning rate 0.0000
[2019-03-27 09:04:15,346] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145000, global step 2320366: loss 0.1281
[2019-03-27 09:04:15,348] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145000, global step 2320366: learning rate 0.0000
[2019-03-27 09:04:15,938] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:04:15,940] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:16,008] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-20_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res15/Eplus-env-sub_run12
[2019-03-27 09:04:16,336] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145000, global step 2320841: loss 0.0886
[2019-03-27 09:04:16,337] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145000, global step 2320841: learning rate 0.0000
[2019-03-27 09:04:18,396] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145000, global step 2321912: loss 0.1016
[2019-03-27 09:04:18,399] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145000, global step 2321914: learning rate 0.0000
[2019-03-27 09:04:22,320] A3C_AGENT_WORKER-Thread-9 INFO:Local step 145500, global step 2323937: loss 0.7851
[2019-03-27 09:04:22,324] A3C_AGENT_WORKER-Thread-9 DEBUG:Local step 145500, global step 2323938: learning rate 0.0000
[2019-03-27 09:04:22,431] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.6130956e-32], sum to 1.0000
[2019-03-27 09:04:22,439] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.6050
[2019-03-27 09:04:22,443] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.2, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5792414220171778, 6.9112, 6.9112, 168.912956510431, 505903.6909419874, 505903.6909419874, 162948.6904473472], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7448400.0000, 
sim time next is 7449000.0000, 
raw observation next is [21.21666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5801903004573374, 6.911199999999999, 6.9112, 168.912956510431, 506686.1879506209, 506686.1879506215, 163088.805302286], 
processed observation next is [0.0, 0.21739130434782608, 0.20458135860979476, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.48803695177724077, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.14074616331961692, 0.1407461633196171, 0.24341612731684478], 
reward next is 0.7566, 
noisyNet noise sample is [array([-0.09800791], dtype=float32), 0.8837046]. 
=============================================
[2019-03-27 09:04:22,466] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[76.61209]
 [76.4769 ]
 [76.45178]
 [76.54558]
 [76.43153]], R is [[76.67769623]
 [76.66770935]
 [76.65778351]
 [76.64790344]
 [76.63809204]].
[2019-03-27 09:04:22,562] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145000, global step 2324048: loss 0.0791
[2019-03-27 09:04:22,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145000, global step 2324051: learning rate 0.0000
[2019-03-27 09:04:23,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:04:23,376] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:23,449] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-22_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res17/Eplus-env-sub_run12
[2019-03-27 09:04:24,195] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145000, global step 2324837: loss 0.0463
[2019-03-27 09:04:24,197] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145000, global step 2324839: learning rate 0.0000
[2019-03-27 09:04:24,327] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145000, global step 2324911: loss 0.0547
[2019-03-27 09:04:24,329] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145000, global step 2324911: learning rate 0.0000
[2019-03-27 09:04:24,468] A3C_AGENT_WORKER-Thread-13 INFO:Evaluating...
[2019-03-27 09:04:24,468] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:04:24,469] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:24,470] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:04:24,472] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:04:24,473] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:24,473] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:24,474] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:04:24,474] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:04:24,475] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:24,476] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:04:24,501] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run94
[2019-03-27 09:04:24,516] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run94
[2019-03-27 09:04:24,534] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run94
[2019-03-27 09:04:24,549] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run94
[2019-03-27 09:04:24,550] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run94
[2019-03-27 09:04:26,348] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:04:26,350] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.3, 66.5, 1.0, 2.0, 0.5334815937914804, 0.0, 2.0, 0.0, 1.0, 1.0, 0.919851493109548, 6.911199999999999, 6.9112, 168.9126882295539, 1570320.393546921, 1570320.393546922, 331321.277054458]
[2019-03-27 09:04:26,352] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:04:26,354] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 1.7726019e-23 3.2993874e-23 3.0822127e-24 1.3338989e-09], sampled 0.13799194423322725
[2019-03-27 09:04:26,357] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1570320.393546921 W.
[2019-03-27 09:04:49,967] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:04:49,970] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [27.8, 74.66666666666667, 1.0, 2.0, 0.6705050808381928, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 937031.7698532401, 937031.7698532401, 214604.4574724857]
[2019-03-27 09:04:49,971] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:04:49,973] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9919778e-01 2.2982895e-19 2.2212603e-16 3.6043519e-21 8.0223387e-04], sampled 0.483276684896236
[2019-03-27 09:04:49,974] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 937031.7698532401 W.
[2019-03-27 09:04:52,026] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:04:52,027] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [22.2, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6408825035778021, 6.9112, 6.9112, 168.912956510431, 554562.8403753098, 554562.8403753098, 172575.3669942252]
[2019-03-27 09:04:52,029] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:04:52,033] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 2.8099767e-38 4.0235777e-27], sampled 0.010989741459330848
[2019-03-27 09:04:59,857] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:04:59,858] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.93333333333334, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9604415821880583, 6.9112, 6.9112, 168.912956510431, 779410.8681605118, 779410.8681605118, 237353.2333212982]
[2019-03-27 09:04:59,859] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:04:59,863] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.6471326e-38 1.5367835e-22], sampled 0.6795161295863895
[2019-03-27 09:05:19,731] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:05:19,732] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.23333333333333, 64.83333333333334, 1.0, 2.0, 0.772573911009225, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.990318416722383, 6.9112, 168.912421280517, 1976690.244608067, 1920561.094594941, 401764.3435595966]
[2019-03-27 09:05:19,733] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:05:19,734] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [9.9870050e-01 2.4743187e-21 1.8566340e-19 1.3991183e-23 1.2994893e-03], sampled 0.2868522963901129
[2019-03-27 09:05:19,735] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1976690.244608067 W.
[2019-03-27 09:05:30,627] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:05:30,629] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.53333333333333, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9961829544854037, 6.911200000000001, 6.9112, 168.9128873845619, 807847.0753413802, 807847.0753413795, 246339.1372215763]
[2019-03-27 09:05:30,631] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:05:30,633] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 8.0592679e-37 0.0000000e+00 3.9465644e-36 4.6630121e-22], sampled 0.0788703550010802
[2019-03-27 09:05:37,938] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:05:37,940] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [30.75, 68.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9471839019368311, 6.9112, 6.9112, 168.912956510431, 772718.2100819068, 772718.2100819068, 234295.6119797683]
[2019-03-27 09:05:37,942] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:05:37,945] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.237361e-28], sampled 0.3017929622500688
[2019-03-27 09:05:42,528] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:05:42,529] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [30.83333333333334, 70.83333333333334, 1.0, 2.0, 0.3544690006102695, 1.0, 1.0, 0.3544690006102695, 1.0, 2.0, 0.615595429370238, 6.911199999999999, 6.9112, 170.5573041426782, 1486487.075482427, 1486487.075482428, 329116.5363159435]
[2019-03-27 09:05:42,531] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:05:42,533] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [9.9952614e-01 1.1497552e-21 1.4635812e-20 8.2133492e-24 4.7390084e-04], sampled 0.46074052229858475
[2019-03-27 09:05:42,533] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1486487.075482427 W.
[2019-03-27 09:06:02,843] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:06:02,846] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.06666666666667, 86.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8459528103326007, 6.9112, 6.9112, 168.912956510431, 705823.9558203967, 705823.9558203967, 211502.4793110054]
[2019-03-27 09:06:02,848] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:06:02,850] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4133223e-38 2.0715754e-23], sampled 0.7204941820774002
[2019-03-27 09:06:11,295] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02881642], dtype=float32), 0.0766479]
[2019-03-27 09:06:11,300] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.43333333333334, 69.33333333333334, 1.0, 1.0, 0.6386741973506169, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912809703627, 892529.3752109045, 892529.3752109045, 208168.4086073567]
[2019-03-27 09:06:11,301] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:06:11,303] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.000000e+00 3.445817e-35 0.000000e+00 4.709945e-35 6.721382e-20], sampled 0.6552672794466445
[2019-03-27 09:06:11,304] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 892529.3752109045 W.
[2019-03-27 09:06:20,317] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7036.3436 3187804215.2575 2379.0000
[2019-03-27 09:06:20,740] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7408.8870 3105074236.6028 1844.0000
[2019-03-27 09:06:20,899] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8090.5227 2938583364.2124 1234.0000
[2019-03-27 09:06:21,017] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7909.1178 2991616042.8682 1532.0000
[2019-03-27 09:06:21,030] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7283.4313 3320763075.2951 2139.0000
[2019-03-27 09:06:22,051] A3C_AGENT_WORKER-Thread-13 INFO:Global step: 2325000, evaluation results [2325000.0, 7283.431265852143, 3320763075.2951427, 2139.0, 7408.886969225456, 3105074236.6027613, 1844.0, 8090.522680182637, 2938583364.2123575, 1234.0, 7036.343574974459, 3187804215.2575183, 2379.0, 7909.117797674196, 2991616042.8681545, 1532.0]
[2019-03-27 09:06:22,111] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145000, global step 2325037: loss 0.0594
[2019-03-27 09:06:22,113] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145000, global step 2325037: learning rate 0.0000
[2019-03-27 09:06:22,511] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145000, global step 2325222: loss 0.0304
[2019-03-27 09:06:22,514] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145000, global step 2325222: learning rate 0.0000
[2019-03-27 09:06:23,191] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145000, global step 2325538: loss 0.0466
[2019-03-27 09:06:23,194] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145000, global step 2325539: learning rate 0.0000
[2019-03-27 09:06:23,291] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145000, global step 2325584: loss 0.0544
[2019-03-27 09:06:23,293] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145000, global step 2325584: learning rate 0.0000
[2019-03-27 09:06:23,782] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.00000e+00 0.00000e+00 0.00000e+00 0.00000e+00 2.01444e-28], sum to 1.0000
[2019-03-27 09:06:23,791] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.3325
[2019-03-27 09:06:23,796] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.2, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7219642709495262, 6.9112, 6.9112, 168.912956510431, 613192.212126483, 613192.212126483, 186706.4133173114], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7549200.0000, 
sim time next is 7549800.0000, 
raw observation next is [25.43333333333333, 83.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276688827408528, 6.911200000000001, 6.9112, 168.912956510431, 617267.7866510114, 617267.7866510109, 187759.4113559326], 
processed observation next is [0.0, 0.391304347826087, 0.40442338072669815, 0.8316666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.667888881391284, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1714632740697254, 0.17146327406972522, 0.28023792739691433], 
reward next is 0.7198, 
noisyNet noise sample is [array([0.07024541], dtype=float32), 0.33395195]. 
=============================================
[2019-03-27 09:06:24,556] A3C_AGENT_WORKER-Thread-11 INFO:Local step 145500, global step 2326173: loss 0.4600
[2019-03-27 09:06:24,560] A3C_AGENT_WORKER-Thread-11 DEBUG:Local step 145500, global step 2326174: learning rate 0.0000
[2019-03-27 09:06:25,067] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.4455164e-29], sum to 1.0000
[2019-03-27 09:06:25,077] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6416
[2019-03-27 09:06:25,082] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.7, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.685352617562232, 6.911199999999999, 6.9112, 168.912956510431, 586627.6564882618, 586627.6564882625, 180132.3932996487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7544400.0000, 
sim time next is 7545000.0000, 
raw observation next is [23.75, 90.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6884050561368654, 6.9112, 6.9112, 168.912956510431, 588892.3818033922, 588892.3818033922, 180668.2388245137], 
processed observation next is [0.0, 0.30434782608695654, 0.3246445497630332, 0.9, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6200061660205675, 0.0, 0.0, 0.8294399451523027, 0.16358121716760896, 0.16358121716760896, 0.26965408779778166], 
reward next is 0.7303, 
noisyNet noise sample is [array([1.7066239], dtype=float32), -0.5251558]. 
=============================================
[2019-03-27 09:06:25,106] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[76.1174  ]
 [76.14736 ]
 [76.16854 ]
 [76.179665]
 [76.11989 ]], R is [[76.07034302]
 [76.04078674]
 [76.01255035]
 [75.98547363]
 [75.95924377]].
[2019-03-27 09:06:27,040] A3C_AGENT_WORKER-Thread-12 INFO:Local step 145500, global step 2327310: loss -39.1693
[2019-03-27 09:06:27,045] A3C_AGENT_WORKER-Thread-12 DEBUG:Local step 145500, global step 2327311: learning rate 0.0000
[2019-03-27 09:06:28,138] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 5.7707571e-31 5.1662474e-31 1.9836913e-30 2.8185873e-15], sum to 1.0000
[2019-03-27 09:06:28,146] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2104
[2019-03-27 09:06:28,149] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.06666666666666, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.970696295327652, 6.9112, 6.9112, 168.912956510431, 808077.9169170875, 808077.9169170875, 240768.0185704373], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7797000.0000, 
sim time next is 7797600.0000, 
raw observation next is [26.2, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.035435180283303, 6.9112, 168.9121988838621, 944939.9551211391, 856803.6377035192, 256150.8370652261], 
processed observation next is [1.0, 0.2608695652173913, 0.44075829383886256, 0.88, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.01242351802833026, 0.0, 0.8294362248590064, 0.26248332086698306, 0.23800101047319977, 0.3823146821869046], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.9736828], dtype=float32), 1.6244004]. 
=============================================
[2019-03-27 09:06:28,660] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:28,661] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:28,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-9_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res4/Eplus-env-sub_run12
[2019-03-27 09:06:28,858] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.7679644e-30 9.0520382e-33 2.4492117e-32 4.4948384e-15], sum to 1.0000
[2019-03-27 09:06:28,866] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7708
[2019-03-27 09:06:28,871] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.9, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7541971167068927, 6.9112, 6.9112, 168.912956510431, 638235.8368343628, 638235.8368343628, 192789.0903789737], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7610400.0000, 
sim time next is 7611000.0000, 
raw observation next is [23.86666666666667, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.332058850261001, 6.9112, 168.9110849819868, 1170873.940971971, 872305.4958801704, 256545.7381168591], 
processed observation next is [1.0, 0.08695652173913043, 0.33017377567140627, 0.95, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.04208588502610011, 0.0, 0.8294307550908522, 0.3252427613811031, 0.2423070821889362, 0.3829040867415808], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.2782875], dtype=float32), -0.624869]. 
=============================================
[2019-03-27 09:06:28,882] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[59.621037]
 [59.250072]
 [59.04063 ]
 [59.233593]
 [59.26023 ]], R is [[57.8621521 ]
 [57.99578476]
 [58.12693024]
 [58.25548172]
 [58.38152313]].
[2019-03-27 09:06:28,933] A3C_AGENT_WORKER-Thread-21 INFO:Local step 145500, global step 2328190: loss 0.8573
[2019-03-27 09:06:28,935] A3C_AGENT_WORKER-Thread-21 DEBUG:Local step 145500, global step 2328190: learning rate 0.0000
[2019-03-27 09:06:29,617] A3C_AGENT_WORKER-Thread-14 INFO:Local step 145500, global step 2328591: loss 2.4203
[2019-03-27 09:06:29,621] A3C_AGENT_WORKER-Thread-14 DEBUG:Local step 145500, global step 2328592: learning rate 0.0000
[2019-03-27 09:06:30,492] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.067306e-38 6.241198e-24], sum to 1.0000
[2019-03-27 09:06:30,501] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.5206
[2019-03-27 09:06:30,505] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.55, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8555067798740963, 6.9112, 6.9112, 168.912956510431, 709496.2445251246, 709496.2445251246, 213471.0877888211], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7673400.0000, 
sim time next is 7674000.0000, 
raw observation next is [26.4, 87.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8523152137266827, 6.9112, 6.9112, 168.912956510431, 707144.6917831575, 707144.6917831575, 212778.0180367426], 
processed observation next is [1.0, 0.8260869565217391, 0.45023696682464454, 0.8733333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8198966021057107, 0.0, 0.0, 0.8294399451523027, 0.19642908105087709, 0.19642908105087709, 0.31757913139812327], 
reward next is 0.6824, 
noisyNet noise sample is [array([0.37066314], dtype=float32), -1.3548748]. 
=============================================
[2019-03-27 09:06:30,526] A3C_AGENT_WORKER-Thread-10 DEBUG:Value prediction is [[68.75406 ]
 [69.2248  ]
 [69.350296]
 [69.77899 ]
 [70.13782 ]], R is [[68.22400665]
 [68.22315979]
 [68.22121429]
 [68.21866608]
 [68.21645355]].
[2019-03-27 09:06:32,113] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 9.7659878e-34 3.6111852e-35 7.4492995e-33 4.0070098e-17], sum to 1.0000
[2019-03-27 09:06:32,121] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.3889
[2019-03-27 09:06:32,126] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.03333333333333, 70.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8267408757286904, 6.911200000000001, 6.9112, 168.912956510431, 737800.8058433089, 737800.8058433083, 206672.1543542104], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 468600.0000, 
sim time next is 469200.0000, 
raw observation next is [22.16666666666667, 69.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8777407630538419, 6.911200000000001, 6.9112, 168.912956510431, 783268.0159423116, 783268.0159423109, 217822.042299695], 
processed observation next is [1.0, 0.43478260869565216, 0.24960505529225935, 0.6933333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.850903369577856, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21757444887286434, 0.21757444887286415, 0.3251075258204403], 
reward next is 0.6749, 
noisyNet noise sample is [array([-0.2673687], dtype=float32), -0.08365504]. 
=============================================
[2019-03-27 09:06:32,167] A3C_AGENT_WORKER-Thread-2 INFO:Local step 145500, global step 2329826: loss -0.0721
[2019-03-27 09:06:32,174] A3C_AGENT_WORKER-Thread-2 DEBUG:Local step 145500, global step 2329827: learning rate 0.0000
[2019-03-27 09:06:33,106] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:33,106] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:33,178] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-11_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res6/Eplus-env-sub_run12
[2019-03-27 09:06:34,531] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [3.1091174e-01 1.1046370e-19 6.8447366e-19 1.2480643e-21 6.8908828e-01], sum to 1.0000
[2019-03-27 09:06:34,541] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6552
[2019-03-27 09:06:34,548] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.93333333333334, 60.33333333333334, 1.0, 2.0, 0.6094333725948311, 1.0, 1.0, 0.6094333725948311, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1703969.758591648, 1703969.758591648, 337761.9907434231], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 7737600.0000, 
sim time next is 7738200.0000, 
raw observation next is [32.0, 60.0, 1.0, 2.0, 0.4109212637576057, 1.0, 2.0, 0.4109212637576057, 1.0, 1.0, 0.7062928986762308, 6.9112, 6.9112, 170.5573041426782, 1723413.383804066, 1723413.383804066, 357954.1914814143], 
processed observation next is [1.0, 0.5652173913043478, 0.7156398104265403, 0.6, 1.0, 1.0, 0.2902665828404888, 1.0, 1.0, 0.2902665828404888, 1.0, 0.5, 0.6418206081417448, 0.0, 0.0, 0.8375144448122397, 0.47872593994557394, 0.47872593994557394, 0.534259987285693], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.45238638], dtype=float32), 0.7072529]. 
=============================================
[2019-03-27 09:06:35,101] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:35,102] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:35,179] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-12_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res7/Eplus-env-sub_run12
[2019-03-27 09:06:35,441] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 3.5145338e-33 1.8486332e-34 2.8050465e-33 2.1177571e-17], sum to 1.0000
[2019-03-27 09:06:35,450] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.3960
[2019-03-27 09:06:35,460] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.86666666666666, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9683875847094235, 6.9112, 6.9112, 168.912956510431, 855930.9029342425, 855930.9029342425, 239946.2004694596], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 395400.0000, 
sim time next is 396000.0000, 
raw observation next is [22.9, 73.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9840014837316896, 6.911200000000001, 6.9112, 168.9128929857789, 869495.7771212879, 869495.7771212872, 243908.055294982], 
processed observation next is [1.0, 0.6086956521739131, 0.2843601895734597, 0.73, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9804896143069384, 8.881784197001253e-17, 0.0, 0.8294396332171792, 0.2415266047559133, 0.24152660475591312, 0.3640418735746], 
reward next is 0.6360, 
noisyNet noise sample is [array([0.33796316], dtype=float32), -2.3128033]. 
=============================================
[2019-03-27 09:06:35,474] A3C_AGENT_WORKER-Thread-20 DEBUG:Value prediction is [[65.057304]
 [65.618484]
 [66.42032 ]
 [67.09119 ]
 [67.948166]], R is [[64.73316193]
 [64.72769928]
 [64.73059845]
 [64.75868225]
 [64.8021698 ]].
[2019-03-27 09:06:35,790] A3C_AGENT_WORKER-Thread-15 INFO:Local step 145500, global step 2331685: loss 0.1928
[2019-03-27 09:06:35,793] A3C_AGENT_WORKER-Thread-15 DEBUG:Local step 145500, global step 2331686: learning rate 0.0000
[2019-03-27 09:06:36,883] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:36,884] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:36,970] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-21_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res16/Eplus-env-sub_run12
[2019-03-27 09:06:37,330] A3C_AGENT_WORKER-Thread-19 INFO:Local step 145500, global step 2332508: loss 0.0471
[2019-03-27 09:06:37,332] A3C_AGENT_WORKER-Thread-19 DEBUG:Local step 145500, global step 2332508: learning rate 0.0000
[2019-03-27 09:06:37,373] A3C_AGENT_WORKER-Thread-10 INFO:Local step 145500, global step 2332532: loss 0.5102
[2019-03-27 09:06:37,374] A3C_AGENT_WORKER-Thread-10 DEBUG:Local step 145500, global step 2332532: learning rate 0.0000
[2019-03-27 09:06:37,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:37,560] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:37,597] A3C_AGENT_WORKER-Thread-16 INFO:Local step 145500, global step 2332660: loss 0.1575
[2019-03-27 09:06:37,603] A3C_AGENT_WORKER-Thread-16 DEBUG:Local step 145500, global step 2332663: learning rate 0.0000
[2019-03-27 09:06:37,611] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-14_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res9/Eplus-env-sub_run12
[2019-03-27 09:06:37,901] A3C_AGENT_WORKER-Thread-3 INFO:Local step 145500, global step 2332828: loss 0.7936
[2019-03-27 09:06:37,904] A3C_AGENT_WORKER-Thread-3 DEBUG:Local step 145500, global step 2332828: learning rate 0.0000
[2019-03-27 09:06:38,394] A3C_AGENT_WORKER-Thread-18 INFO:Local step 145500, global step 2333130: loss -64.2964
[2019-03-27 09:06:38,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Local step 145500, global step 2333130: learning rate 0.0000
[2019-03-27 09:06:38,555] A3C_AGENT_WORKER-Thread-17 INFO:Local step 145500, global step 2333227: loss 1.6878
[2019-03-27 09:06:38,558] A3C_AGENT_WORKER-Thread-17 DEBUG:Local step 145500, global step 2333227: learning rate 0.0000
[2019-03-27 09:06:39,314] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 1.3156651e-36 2.4684324e-38 3.2201477e-35 6.9142524e-25], sum to 1.0000
[2019-03-27 09:06:39,320] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5142
[2019-03-27 09:06:39,326] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [18.3, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.3942792400000382, 6.9112, 6.9112, 168.912956510431, 355961.4437501484, 355961.4437501484, 139863.0627968248], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 626400.0000, 
sim time next is 627000.0000, 
raw observation next is [18.51666666666667, 85.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.396395921537533, 6.9112, 6.9112, 168.912956510431, 357625.0040675116, 357625.0040675116, 140089.3097693451], 
processed observation next is [1.0, 0.2608695652173913, 0.07661927330173794, 0.85, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.2638974652896744, 0.0, 0.0, 0.8294399451523027, 0.0993402789076421, 0.0993402789076421, 0.20908852204379866], 
reward next is 0.7909, 
noisyNet noise sample is [array([0.87622386], dtype=float32), -0.11341356]. 
=============================================
[2019-03-27 09:06:39,339] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[71.73046 ]
 [71.68864 ]
 [71.689735]
 [71.72233 ]
 [71.8232  ]], R is [[71.76777649]
 [71.84135437]
 [71.91478729]
 [71.98718262]
 [72.05702972]].
[2019-03-27 09:06:39,466] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 2.078685e-22], sum to 1.0000
[2019-03-27 09:06:39,471] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7264
[2019-03-27 09:06:39,476] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.75, 85.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9216516891611242, 6.911200000000001, 6.9112, 168.912956510431, 753035.8593542437, 753035.8593542431, 228198.4650725437], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 7846200.0000, 
sim time next is 7846800.0000, 
raw observation next is [27.6, 86.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9253668506587956, 6.9112, 6.9112, 168.912956510431, 755795.6329067578, 755795.6329067578, 229070.2248406637], 
processed observation next is [1.0, 0.8260869565217391, 0.5071090047393366, 0.8666666666666666, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9089839642180434, 0.0, 0.0, 0.8294399451523027, 0.20994323136298826, 0.20994323136298826, 0.34189585797113986], 
reward next is 0.6581, 
noisyNet noise sample is [array([-1.0477513], dtype=float32), 0.040260732]. 
=============================================
[2019-03-27 09:06:39,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:39,543] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:39,600] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-2_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res2/Eplus-env-sub_run12
[2019-03-27 09:06:42,464] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.000000e+00 8.210479e-38 0.000000e+00 7.904473e-37 7.574928e-25], sum to 1.0000
[2019-03-27 09:06:42,470] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4054
[2019-03-27 09:06:42,475] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5192829102648093, 6.9112, 6.9112, 168.912956510431, 458158.2345127119, 458158.2345127119, 154517.3587339385], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 265200.0000, 
sim time next is 265800.0000, 
raw observation next is [20.5, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5190167409532722, 6.9112, 6.9112, 168.912956510431, 457923.3451514558, 457923.3451514558, 154482.7936942496], 
processed observation next is [0.0, 0.043478260869565216, 0.1706161137440759, 0.92, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4134350499430149, 0.0, 0.0, 0.8294399451523027, 0.1272009292087377, 0.1272009292087377, 0.2305713338720143], 
reward next is 0.7694, 
noisyNet noise sample is [array([-0.24597381], dtype=float32), 1.8875636]. 
=============================================
[2019-03-27 09:06:43,281] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:43,282] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:43,351] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-15_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res10/Eplus-env-sub_run12
[2019-03-27 09:06:44,511] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.0348301e-35 6.2344912e-38 2.6256626e-35 4.3278894e-23], sum to 1.0000
[2019-03-27 09:06:44,517] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.9039
[2019-03-27 09:06:44,521] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.7, 82.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4200317219392387, 6.911199999999999, 6.9112, 168.912956510431, 376631.9645493028, 376631.9645493035, 142622.4006686039], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 450000.0000, 
sim time next is 450600.0000, 
raw observation next is [19.73333333333333, 82.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4351704736393098, 6.911199999999999, 6.9112, 168.912956510431, 390202.8409977127, 390202.8409977134, 144202.9153784397], 
processed observation next is [1.0, 0.21739130434782608, 0.13428120063191146, 0.8200000000000002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.31118350443818266, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1083896780549202, 0.10838967805492039, 0.21522823190811896], 
reward next is 0.7848, 
noisyNet noise sample is [array([1.8280274], dtype=float32), 0.6637417]. 
=============================================
[2019-03-27 09:06:45,025] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:45,025] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:45,072] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-19_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res14/Eplus-env-sub_run12
[2019-03-27 09:06:45,096] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:45,097] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:45,167] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-10_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res5/Eplus-env-sub_run12
[2019-03-27 09:06:45,233] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:45,234] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:45,285] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-16_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res11/Eplus-env-sub_run12
[2019-03-27 09:06:45,454] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:45,455] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:45,498] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-3_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res3/Eplus-env-sub_run12
[2019-03-27 09:06:45,952] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:45,952] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:45,987] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-18_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res13/Eplus-env-sub_run12
[2019-03-27 09:06:45,988] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.594062e-30], sum to 1.0000
[2019-03-27 09:06:46,014] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6504
[2019-03-27 09:06:46,022] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.43333333333334, 89.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.559459768816648, 6.9112, 6.9112, 168.912956510431, 490924.9593247549, 490924.9593247549, 160045.5007784782], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 217200.0000, 
sim time next is 217800.0000, 
raw observation next is [21.5, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5601270929551376, 6.9112, 6.9112, 168.912956510431, 491389.417390003, 491389.417390003, 160143.170051234], 
processed observation next is [0.0, 0.5217391304347826, 0.21800947867298584, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4635696255550459, 0.0, 0.0, 0.8294399451523027, 0.13649706038611195, 0.13649706038611195, 0.23901965679288656], 
reward next is 0.7610, 
noisyNet noise sample is [array([-1.1781328], dtype=float32), -0.5691032]. 
=============================================
[2019-03-27 09:06:46,156] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Last EnergyPlus process has been closed. 
[2019-03-27 09:06:46,156] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:06:46,197] EPLUS_ENV_Part3-NA-Shg-Train-v1_Thread-17_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res12/Eplus-env-sub_run12
[2019-03-27 09:06:49,557] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 4.0339012e-29 2.0921287e-30 2.5951684e-30 2.7743931e-14], sum to 1.0000
[2019-03-27 09:06:49,566] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6639
[2019-03-27 09:06:49,572] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1046708.540963396 W.
[2019-03-27 09:06:49,575] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [22.8, 96.0, 1.0, 1.0, 0.2405026846864386, 1.0, 1.0, 0.2405026846864386, 1.0, 2.0, 0.4107180738695541, 6.911200000000001, 6.9112, 170.5573041426782, 1046708.540963396, 1046708.540963396, 285698.4111003644], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 133800.0000, 
sim time next is 134400.0000, 
raw observation next is [22.8, 96.0, 1.0, 2.0, 0.3902771095902318, 0.0, 1.0, 0.0, 1.0, 2.0, 0.6734685704261842, 6.9112, 6.9112, 168.9129564473137, 1149925.243176158, 1149925.243176158, 259046.7079174535], 
processed observation next is [1.0, 0.5652173913043478, 0.2796208530805688, 0.96, 1.0, 1.0, 0.2653941079400383, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.6017909395441271, 0.0, 0.0, 0.8294399448423678, 0.3194236786600439, 0.3194236786600439, 0.38663687748873654], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.34658554], dtype=float32), 1.4032888]. 
=============================================
[2019-03-27 09:06:54,939] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8440723e-23], sum to 1.0000
[2019-03-27 09:06:54,946] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.8748
[2019-03-27 09:06:54,953] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6731076379116421, 6.9112, 6.9112, 168.912956510431, 579520.9411866262, 579520.9411866262, 178000.2018454009], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 156000.0000, 
sim time next is 156600.0000, 
raw observation next is [22.4, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.670977651288394, 6.9112, 6.9112, 168.912956510431, 577691.8573886231, 577691.8573886231, 177634.3560929763], 
processed observation next is [1.0, 0.8260869565217391, 0.2606635071090047, 0.96, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5987532332785293, 0.0, 0.0, 0.8294399451523027, 0.16046996038572864, 0.16046996038572864, 0.2651259046163825], 
reward next is 0.7349, 
noisyNet noise sample is [array([0.8101417], dtype=float32), -1.960573]. 
=============================================
[2019-03-27 09:07:03,650] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.909019e-26], sum to 1.0000
[2019-03-27 09:07:03,662] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.6155
[2019-03-27 09:07:03,669] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.53333333333333, 76.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5712133717710882, 6.911200000000001, 6.9112, 168.912956510431, 499111.3738603964, 499111.3738603957, 161776.8199846132], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 312000.0000, 
sim time next is 312600.0000, 
raw observation next is [23.46666666666667, 76.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5692313986549722, 6.911200000000001, 6.9112, 168.912956510431, 497579.1848846037, 497579.1848846031, 161486.7818232598], 
processed observation next is [0.0, 0.6086956521739131, 0.31121642969984215, 0.7683333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4746724373841124, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13821644024572324, 0.13821644024572308, 0.2410250474974027], 
reward next is 0.7590, 
noisyNet noise sample is [array([0.5887554], dtype=float32), -0.36647323]. 
=============================================
[2019-03-27 09:07:04,515] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.500649e-26], sum to 1.0000
[2019-03-27 09:07:04,527] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.3311
[2019-03-27 09:07:04,535] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.7, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5312264873690793, 6.9112, 6.9112, 168.912956510431, 467795.4244397502, 467795.4244397502, 156121.0885415383], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 327600.0000, 
sim time next is 328200.0000, 
raw observation next is [21.63333333333333, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.528294676229604, 6.9112, 6.9112, 168.912956510431, 465296.2872185719, 465296.2872185719, 155728.8301061547], 
processed observation next is [0.0, 0.8260869565217391, 0.2243285939968403, 0.8433333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.42474960515805366, 0.0, 0.0, 0.8294399451523027, 0.12924896867182553, 0.12924896867182553, 0.23243108971067866], 
reward next is 0.7676, 
noisyNet noise sample is [array([-0.27820337], dtype=float32), 1.2377845]. 
=============================================
[2019-03-27 09:07:05,181] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0677037e-26], sum to 1.0000
[2019-03-27 09:07:05,189] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7949
[2019-03-27 09:07:05,195] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.33333333333334, 80.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5373415855120155, 6.9112, 6.9112, 168.912956510431, 472566.5188263085, 472566.5188263085, 156961.4812730635], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 322800.0000, 
sim time next is 323400.0000, 
raw observation next is [22.26666666666667, 80.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5361644893236424, 6.911200000000001, 6.9112, 168.912956510431, 471619.8540841079, 471619.8540841072, 156799.9625186562], 
processed observation next is [0.0, 0.7391304347826086, 0.2543443917851502, 0.8066666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4343469381995638, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1310055150233633, 0.1310055150233631, 0.23402979480396446], 
reward next is 0.7660, 
noisyNet noise sample is [array([-0.382503], dtype=float32), 1.2638372]. 
=============================================
[2019-03-27 09:07:06,171] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [1.0000000e+00 1.9311887e-35 1.3197813e-37 1.8706588e-35 1.2066414e-20], sum to 1.0000
[2019-03-27 09:07:06,182] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.7789
[2019-03-27 09:07:06,186] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.2, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4699680779368596, 6.9112, 6.9112, 168.912956510431, 417437.4633412592, 417437.4633412592, 148316.302975383], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 366000.0000, 
sim time next is 366600.0000, 
raw observation next is [20.25, 87.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4708413482603907, 6.9112, 6.9112, 168.912956510431, 418251.4206480645, 418251.4206480645, 148416.0307794948], 
processed observation next is [1.0, 0.21739130434782608, 0.1587677725118484, 0.875, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.35468457104925694, 0.0, 0.0, 0.8294399451523027, 0.11618095018001792, 0.11618095018001792, 0.2215164638499922], 
reward next is 0.7785, 
noisyNet noise sample is [array([1.0235535], dtype=float32), -0.41871545]. 
=============================================
[2019-03-27 09:07:10,666] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [7.6140177e-01 5.2519260e-18 1.9142086e-14 1.0649638e-19 2.3859817e-01], sum to 1.0000
[2019-03-27 09:07:10,675] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6229
[2019-03-27 09:07:10,687] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.86666666666667, 57.5, 1.0, 2.0, 0.17, 1.0, 2.0, 0.17, 1.0, 1.0, 0.3022760490345478, 6.9112, 6.9112, 170.5573041426782, 799659.5721062919, 799659.5721062919, 271581.6625121803], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 731400.0000, 
sim time next is 732000.0000, 
raw observation next is [24.93333333333333, 57.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 0.9854999462304124, 6.9112, 6.9112, 168.912956510431, 871545.0634847828, 871545.0634847828, 244247.6550072498], 
processed observation next is [1.0, 0.4782608695652174, 0.38072669826224315, 0.57, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 0.9823170075980638, 0.0, 0.0, 0.8294399451523027, 0.24209585096799524, 0.24209585096799524, 0.36454873881679073], 
reward next is 0.6355, 
noisyNet noise sample is [array([1.3712388], dtype=float32), 0.61285174]. 
=============================================
[2019-03-27 09:07:10,701] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[54.48893 ]
 [54.543327]
 [55.33941 ]
 [58.218063]
 [55.8358  ]], R is [[55.58877945]
 [55.03289032]
 [55.09589767]
 [55.1485939 ]
 [54.59710693]].
[2019-03-27 09:07:12,129] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 5.0514413e-32 1.5334494e-32 1.5215691e-31 1.6095574e-16], sum to 1.0000
[2019-03-27 09:07:12,137] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8556
[2019-03-27 09:07:12,140] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 62.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9229249961515594, 6.9112, 6.9112, 168.912956510431, 823132.6356550305, 823132.6356550305, 228318.4645276018], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 474000.0000, 
sim time next is 474600.0000, 
raw observation next is [23.45, 61.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9500722800940797, 6.9112, 6.9112, 168.912956510431, 847277.6678214751, 847277.6678214751, 234872.8006658693], 
processed observation next is [1.0, 0.4782608695652174, 0.3104265402843602, 0.6183333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9391125367000972, 0.0, 0.0, 0.8294399451523027, 0.2353549077281875, 0.2353549077281875, 0.3505564189042825], 
reward next is 0.6494, 
noisyNet noise sample is [array([0.05142227], dtype=float32), -0.10676117]. 
=============================================
[2019-03-27 09:07:12,366] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 09:07:12,369] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:07:12,370] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:07:12,370] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:07:12,371] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:07:12,371] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:07:12,370] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:07:12,373] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:07:12,375] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:07:12,373] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:07:12,378] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:07:12,401] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run95
[2019-03-27 09:07:12,425] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run95
[2019-03-27 09:07:12,425] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run95
[2019-03-27 09:07:12,481] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run95
[2019-03-27 09:07:12,482] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run95
[2019-03-27 09:07:16,055] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:07:16,056] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [20.83520102333334, 94.53677161333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6088731730330339, 6.911199999999999, 6.9112, 168.912956510431, 529706.3384125535, 529706.3384125541, 167447.3526536804]
[2019-03-27 09:07:16,058] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:07:16,060] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.6646727e-37 0.0000000e+00 1.4677417e-36 6.2600619e-23], sampled 0.16860507259893975
[2019-03-27 09:07:17,037] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:07:17,038] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.1, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5403801601275874, 6.911199999999999, 6.9112, 168.912956510431, 475638.0772194005, 475638.0772194011, 157359.2187289603]
[2019-03-27 09:07:17,040] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:07:17,043] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2194329e-25], sampled 0.29384863696628905
[2019-03-27 09:07:17,468] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:07:17,470] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [20.7, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.479176932725853, 6.911199999999999, 6.9112, 168.912956510431, 427395.153746268, 427395.1537462687, 149299.4538415133]
[2019-03-27 09:07:17,472] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:07:17,474] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.5561295e-38 3.3096794e-27], sampled 0.3466417932140802
[2019-03-27 09:07:32,607] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:07:32,608] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [19.33333333333333, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4214433634887901, 6.9112, 6.9112, 168.912956510431, 379012.6130046913, 379012.6130046913, 142677.6096561777]
[2019-03-27 09:07:32,609] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:07:32,613] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 5.1121795e-38 3.3851173e-27], sampled 0.9646463706552316
[2019-03-27 09:07:58,543] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:07:58,544] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.36666666666667, 66.33333333333333, 1.0, 2.0, 0.4408891676623731, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7596603503515275, 6.911199999999999, 6.9112, 168.9128875559564, 1232457.774447811, 1232457.774447811, 277155.5291940242]
[2019-03-27 09:07:58,545] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:07:58,548] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 2.5707856e-27 2.0980780e-27 1.5339791e-28 7.4949966e-09], sampled 0.9695318710629084
[2019-03-27 09:07:58,549] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1232457.774447811 W.
[2019-03-27 09:08:36,749] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:08:36,751] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [28.46666666666667, 93.0, 1.0, 1.0, 0.6469639339291595, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.9127551152178, 904118.9818767434, 904118.9818767427, 209819.6424371607]
[2019-03-27 09:08:36,751] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:08:36,757] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 1.4057462e-23 5.3183614e-23 2.6299980e-24 1.0827160e-09], sampled 0.43228544854676443
[2019-03-27 09:08:36,758] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 904118.9818767434 W.
[2019-03-27 09:08:46,016] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:08:46,017] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [25.76666666666667, 90.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.872113559665924, 6.9112, 6.9112, 168.912956510431, 724729.0153223927, 724729.0153223927, 217217.6425768236]
[2019-03-27 09:08:46,019] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:08:46,022] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 3.9427382e-38 1.1765776e-21], sampled 0.6045571771659017
[2019-03-27 09:08:59,503] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07920568]
[2019-03-27 09:08:59,504] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [21.73333333333333, 88.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5733743390185716, 6.911199999999999, 6.9112, 168.912956510431, 501836.8215141516, 501836.8215141523, 162068.7516663857]
[2019-03-27 09:08:59,507] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:08:59,510] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.2582855e-37 0.0000000e+00 1.9181703e-36 8.1731360e-23], sampled 0.5249772368477008
[2019-03-27 09:09:08,660] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8093.9837 2941095108.0839 1175.0000
[2019-03-27 09:09:08,743] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7396.6840 3106099825.7853 1814.0000
[2019-03-27 09:09:09,015] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7280.7035 3323115685.0407 2097.0000
[2019-03-27 09:09:09,107] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7042.5323 3190327777.7448 2318.0000
[2019-03-27 09:09:09,133] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.4441 2993851651.1081 1476.0000
[2019-03-27 09:09:10,147] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2350000, evaluation results [2350000.0, 7280.703468062757, 3323115685.040712, 2097.0, 7396.684049684425, 3106099825.785289, 1814.0, 8093.983692424145, 2941095108.083878, 1175.0, 7042.532323599908, 3190327777.7448187, 2318.0, 7923.444112070233, 2993851651.1080728, 1476.0]
[2019-03-27 09:09:12,814] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.2507879e-38 2.4085575e-23], sum to 1.0000
[2019-03-27 09:09:12,823] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.9704
[2019-03-27 09:09:12,827] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [19.96666666666667, 80.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4445611401857149, 6.9112, 6.9112, 168.912956510431, 398606.4369118143, 398606.4369118143, 145215.1704183066], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 506400.0000, 
sim time next is 507000.0000, 
raw observation next is [19.88333333333333, 80.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.4436298896297894, 6.911200000000001, 6.9112, 168.912956510431, 397823.2113646199, 397823.2113646193, 145109.9376455278], 
processed observation next is [1.0, 0.8695652173913043, 0.14139020537124788, 0.805, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.32149986540218217, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.11050644760128331, 0.11050644760128314, 0.21658199648586238], 
reward next is 0.7834, 
noisyNet noise sample is [array([1.4049166], dtype=float32), 0.57064855]. 
=============================================
[2019-03-27 09:09:12,848] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[77.52652]
 [77.45611]
 [77.62489]
 [77.19136]
 [77.45933]], R is [[77.68255615]
 [77.68899536]
 [77.69540405]
 [77.70183563]
 [77.70831299]].
[2019-03-27 09:09:17,466] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9992120e-01 1.2566021e-20 3.1163107e-18 4.4893251e-23 7.8756653e-05], sum to 1.0000
[2019-03-27 09:09:17,478] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7220
[2019-03-27 09:09:17,490] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1007714.744419057 W.
[2019-03-27 09:09:17,495] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.01666666666667, 50.0, 1.0, 2.0, 0.3077102224463367, 1.0, 1.0, 0.3077102224463367, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1007714.744419057, 1007714.744419057, 266100.3169200055], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 749400.0000, 
sim time next is 750000.0000, 
raw observation next is [24.93333333333334, 50.0, 1.0, 2.0, 0.1940572866071813, 1.0, 2.0, 0.1940572866071813, 1.0, 1.0, 0.3564270936227338, 6.9112, 6.9112, 170.5573041426782, 951200.579684816, 951200.579684816, 281610.9029018736], 
processed observation next is [1.0, 0.6956521739130435, 0.3807266982622437, 0.5, 1.0, 1.0, 0.028984682659254565, 1.0, 1.0, 0.028984682659254565, 1.0, 0.5, 0.21515499222284606, 0.0, 0.0, 0.8375144448122397, 0.26422238324578223, 0.26422238324578223, 0.4203147804505576], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.14112483], dtype=float32), 0.15461376]. 
=============================================
[2019-03-27 09:09:17,507] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[54.764942]
 [55.026066]
 [55.09413 ]
 [54.71666 ]
 [54.6124  ]], R is [[55.49285507]
 [54.93792725]
 [54.3885498 ]
 [53.84466553]
 [53.30622101]].
[2019-03-27 09:09:24,299] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [1.0000000e+00 1.6574635e-35 1.4827787e-36 3.2422747e-34 5.6878601e-16], sum to 1.0000
[2019-03-27 09:09:24,301] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.4916
[2019-03-27 09:09:24,306] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.36666666666667, 97.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5573060579983845, 6.9112, 6.9112, 168.912956510431, 489481.0402173451, 489481.0402173451, 159729.0525342601], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1386600.0000, 
sim time next is 1387200.0000, 
raw observation next is [20.33333333333334, 97.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5567844816559927, 6.911200000000001, 6.9112, 168.912956510431, 489091.8437951748, 489091.8437951742, 159653.7527335], 
processed observation next is [0.0, 0.043478260869565216, 0.16271721958925783, 0.9733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4594932703121862, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.13585884549865967, 0.1358588454986595, 0.23828918318432837], 
reward next is 0.7617, 
noisyNet noise sample is [array([1.4297723], dtype=float32), 0.09193064]. 
=============================================
[2019-03-27 09:09:28,975] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 3.779218e-38 9.572324e-24], sum to 1.0000
[2019-03-27 09:09:28,977] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.4405
[2019-03-27 09:09:28,981] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5485539170343042, 6.911199999999999, 6.9112, 168.912956510431, 481905.6715583483, 481905.6715583489, 158507.7481476913], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 853200.0000, 
sim time next is 853800.0000, 
raw observation next is [21.96666666666667, 84.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5492825494986079, 6.9112, 6.9112, 168.912956510431, 482440.7962521837, 482440.7962521837, 158611.5920968626], 
processed observation next is [0.0, 0.9130434782608695, 0.24012638230647723, 0.8433333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4503445725592779, 0.0, 0.0, 0.8294399451523027, 0.13401133229227324, 0.13401133229227324, 0.2367337195475561], 
reward next is 0.7633, 
noisyNet noise sample is [array([0.7805977], dtype=float32), -0.17646192]. 
=============================================
[2019-03-27 09:09:40,636] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [4.0918577e-01 6.1445317e-22 5.5130600e-19 4.2030436e-23 5.9081423e-01], sum to 1.0000
[2019-03-27 09:09:40,646] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.5164
[2019-03-27 09:09:40,650] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [25.16666666666667, 81.33333333333333, 1.0, 2.0, 0.8005224462712288, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.9129563346837, 1163798.191655643, 1163798.191655643, 250278.9459451694], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1240800.0000, 
sim time next is 1241400.0000, 
raw observation next is [25.38333333333333, 80.66666666666667, 1.0, 2.0, 0.2703425490363913, 1.0, 1.0, 0.2703425490363913, 1.0, 1.0, 0.4566158233971175, 6.911199999999999, 6.9112, 170.5573041426782, 1157978.349605547, 1157978.349605547, 294028.7631298563], 
processed observation next is [1.0, 0.34782608695652173, 0.4020537124802526, 0.8066666666666668, 1.0, 1.0, 0.12089463739324255, 1.0, 0.5, 0.12089463739324255, 1.0, 0.5, 0.3373363699964847, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.32166065266820754, 0.32166065266820754, 0.4388489001938154], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.4472565], dtype=float32), -1.127335]. 
=============================================
[2019-03-27 09:09:40,947] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 3.1977563e-29 3.8846257e-27 8.2036250e-30 2.2651327e-10], sum to 1.0000
[2019-03-27 09:09:40,954] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6766
[2019-03-27 09:09:40,960] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.3, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6622508661880673, 6.9112, 6.9112, 168.912956510431, 570211.8655197289, 570211.8655197289, 176148.216799224], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1038600.0000, 
sim time next is 1039200.0000, 
raw observation next is [22.33333333333333, 97.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6644440148083247, 6.9112, 6.9112, 168.912956510431, 571882.005666602, 571882.005666602, 176520.7402666984], 
processed observation next is [1.0, 0.0, 0.2575039494470772, 0.97, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5907853839125911, 0.0, 0.0, 0.8294399451523027, 0.15885611268516725, 0.15885611268516725, 0.26346379144283344], 
reward next is 0.7365, 
noisyNet noise sample is [array([-0.57922626], dtype=float32), 0.2084114]. 
=============================================
[2019-03-27 09:09:46,824] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 6.2282139e-31 2.4844075e-30 2.6882827e-31 3.5494352e-15], sum to 1.0000
[2019-03-27 09:09:46,834] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1877
[2019-03-27 09:09:46,843] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [20.0, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5181631606873247, 6.9112, 6.9112, 168.912956510431, 458312.5188377349, 458312.5188377349, 154325.782612651], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1136400.0000, 
sim time next is 1137000.0000, 
raw observation next is [19.95, 93.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5131457735794475, 6.911200000000001, 6.9112, 168.912956510431, 453996.2622211641, 453996.2622211634, 153674.2260642993], 
processed observation next is [1.0, 0.13043478260869565, 0.14454976303317538, 0.9383333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.4062753336334725, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.12611007283921224, 0.12611007283921205, 0.22936451651387954], 
reward next is 0.7706, 
noisyNet noise sample is [array([-0.70601135], dtype=float32), -0.63017666]. 
=============================================
[2019-03-27 09:09:46,855] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[74.01444 ]
 [74.256874]
 [74.34685 ]
 [74.62229 ]
 [75.05096 ]], R is [[73.95891571]
 [73.98899078]
 [74.01690674]
 [74.04266357]
 [74.0585556 ]].
[2019-03-27 09:09:52,666] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0952793e-02 2.5343083e-21 1.9081753e-17 7.7076690e-25 9.8904723e-01], sum to 1.0000
[2019-03-27 09:09:52,672] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.7686
[2019-03-27 09:09:52,675] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [28.13333333333334, 71.33333333333334, 1.0, 2.0, 0.4026847306219558, 1.0, 2.0, 0.4026847306219558, 1.0, 2.0, 0.6785599262719496, 6.911199999999999, 6.9112, 170.5573041426782, 1688841.950713306, 1688841.950713306, 351381.5591914645], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1250400.0000, 
sim time next is 1251000.0000, 
raw observation next is [28.15, 71.5, 1.0, 2.0, 0.3795370967850235, 1.0, 2.0, 0.3795370967850235, 1.0, 2.0, 0.6397559283749336, 6.911200000000001, 6.9112, 170.5573041426782, 1591689.704677386, 1591689.704677385, 339242.8527130769], 
processed observation next is [1.0, 0.4782608695652174, 0.533175355450237, 0.715, 1.0, 1.0, 0.25245433347593194, 1.0, 1.0, 0.25245433347593194, 1.0, 1.0, 0.5606779614328458, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.4421360290770517, 0.4421360290770514, 0.5063326159896671], 
reward next is 0.4937, 
noisyNet noise sample is [array([-1.7833449], dtype=float32), 0.45674402]. 
=============================================
[2019-03-27 09:09:52,690] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[64.038025]
 [63.993034]
 [63.291096]
 [63.30779 ]
 [62.898563]], R is [[64.09284973]
 [63.92747498]
 [63.77451324]
 [63.5887146 ]
 [63.41363144]].
[2019-03-27 09:10:01,191] A3C_AGENT_WORKER-Thread-22 INFO:Evaluating...
[2019-03-27 09:10:01,193] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:10:01,193] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:10:01,194] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:10:01,195] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:10:01,196] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:10:01,197] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:10:01,198] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:10:01,200] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:10:01,201] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:10:01,201] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:10:01,226] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run96
[2019-03-27 09:10:01,246] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run96
[2019-03-27 09:10:01,277] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run96
[2019-03-27 09:10:01,279] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run96
[2019-03-27 09:10:01,317] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run96
[2019-03-27 09:10:26,583] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:10:26,585] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [28.2422, 79.096461735, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 1.0, 1.015548884582811, 6.9112, 6.9112, 168.9127755969416, 834049.8614168514, 834049.8614168514, 251886.40868092]
[2019-03-27 09:10:26,586] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:10:26,590] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [9.9993169e-01 1.4158491e-22 1.9528890e-19 4.9958324e-24 6.8338290e-05], sampled 0.07048290362591825
[2019-03-27 09:10:27,098] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:10:27,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.85, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8605529963143494, 6.9112, 6.9112, 168.912956510431, 712673.9413427857, 712673.9413427857, 214554.2644955112]
[2019-03-27 09:10:27,100] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:10:27,103] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.7843007e-33 2.8062024e-33 1.2638609e-33 2.2665240e-14], sampled 0.35502073886968255
[2019-03-27 09:10:27,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:10:27,790] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.00762464, 95.82951137500001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7973970261615017, 6.9112, 6.9112, 168.912956510429, 684433.3306649833, 684433.3306649833, 201478.1017004183]
[2019-03-27 09:10:27,791] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:10:27,793] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 4.0287957e-29 3.0863698e-29 1.8693518e-29 1.5155382e-13], sampled 0.3420077475313199
[2019-03-27 09:10:30,682] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:10:30,683] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.038351025, 82.745157185, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6090125703482833, 6.9112, 6.9112, 168.912956510431, 530024.940474704, 530024.940474704, 167466.1267693198]
[2019-03-27 09:10:30,684] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:10:30,688] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 7.4629439e-35 2.0191557e-36 2.5690020e-34 6.1478059e-19], sampled 0.9359662661489173
[2019-03-27 09:11:15,066] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:11:15,068] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [28.33333333333333, 77.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.881969484898185, 6.9112, 6.9112, 168.912956510431, 727501.7203321009, 727501.7203321009, 219263.5189050996]
[2019-03-27 09:11:15,070] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:11:15,074] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 7.311443e-23], sampled 0.6262681224165852
[2019-03-27 09:11:15,945] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:11:15,948] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.36850098333333, 86.09220186000002, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9180957088980867, 6.911199999999999, 6.9112, 168.912956510431, 751791.7455760901, 751791.7455760906, 227429.0840894886]
[2019-03-27 09:11:15,949] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:11:15,951] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 2.8112503e-32 1.8508648e-32 1.8935573e-32 1.6724322e-14], sampled 0.30206862445574045
[2019-03-27 09:11:26,784] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:11:26,785] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [27.19217447166666, 87.21973883, 1.0, 2.0, 0.4718712965243504, 1.0, 2.0, 0.4718712965243504, 1.0, 2.0, 0.8142977358424958, 6.9112, 6.9112, 184.5923449428631, 1979136.355899273, 1979136.355899273, 399486.914994331]
[2019-03-27 09:11:26,787] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:11:26,790] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.5919385e-02 1.4712305e-20 2.5995984e-16 2.5252375e-23 9.8408061e-01], sampled 0.8392921230652847
[2019-03-27 09:11:49,494] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.080242306]
[2019-03-27 09:11:49,496] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.6, 73.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.679005070232263, 6.9112, 6.9112, 168.912956510431, 583848.2853143984, 583848.2853143984, 179022.5116301032]
[2019-03-27 09:11:49,497] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:11:49,499] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.3539625e-38 7.9374573e-25], sampled 0.5096299908496912
[2019-03-27 09:11:57,346] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7176.8452 3188589941.0017 1811.0000
[2019-03-27 09:11:57,922] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8129.6353 2948981497.0640 984.0000
[2019-03-27 09:11:58,069] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7391.3129 3322611286.4056 1631.0000
[2019-03-27 09:11:58,085] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7432.7737 3111812158.7076 1608.0000
[2019-03-27 09:11:58,156] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7980.3316 2998239901.1517 1196.0000
[2019-03-27 09:11:59,174] A3C_AGENT_WORKER-Thread-22 INFO:Global step: 2375000, evaluation results [2375000.0, 7391.312882047891, 3322611286.405601, 1631.0, 7432.773701042655, 3111812158.7076354, 1608.0, 8129.635345556322, 2948981497.064031, 984.0, 7176.8452296935975, 3188589941.001729, 1811.0, 7980.331625299962, 2998239901.1516623, 1196.0]
[2019-03-27 09:12:00,100] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [8.0902779e-01 3.1867234e-21 1.0536382e-16 3.2985181e-23 1.9097218e-01], sum to 1.0000
[2019-03-27 09:12:00,107] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.3238
[2019-03-27 09:12:00,115] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1051808.905192253 W.
[2019-03-27 09:12:00,123] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [23.06666666666667, 95.33333333333333, 1.0, 2.0, 0.7141985550769232, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1051808.905192253, 1051808.905192254, 231029.1792426554], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 1615800.0000, 
sim time next is 1616400.0000, 
raw observation next is [23.0, 96.0, 1.0, 2.0, 0.7752594364452398, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1146259.049048872, 1146259.049048872, 246428.0151874244], 
processed observation next is [1.0, 0.7391304347826086, 0.28909952606635075, 0.96, 1.0, 1.0, 0.7292282366810118, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8294399451523027, 0.31840529140246443, 0.31840529140246443, 0.36780300774242447], 
reward next is 0.6322, 
noisyNet noise sample is [array([-1.1057956], dtype=float32), 0.46742138]. 
=============================================
[2019-03-27 09:12:02,903] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 2.6327522e-36 8.3397751e-38 1.6972094e-35 9.0384688e-20], sum to 1.0000
[2019-03-27 09:12:02,916] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.8969
[2019-03-27 09:12:02,921] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.5, 94.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.660275406505353, 6.911199999999999, 6.9112, 168.912956510431, 568786.0975120612, 568786.0975120618, 175813.2230350501], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1459800.0000, 
sim time next is 1460400.0000, 
raw observation next is [22.43333333333333, 94.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6572227484006518, 6.9112, 6.9112, 168.912956510431, 566450.1328268448, 566450.1328268448, 175298.246514565], 
processed observation next is [0.0, 0.9130434782608695, 0.2622432859399683, 0.9466666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5819789614642095, 0.0, 0.0, 0.8294399451523027, 0.157347259118568, 0.157347259118568, 0.2616391739023358], 
reward next is 0.7384, 
noisyNet noise sample is [array([-0.00890591], dtype=float32), 1.0763093]. 
=============================================
[2019-03-27 09:12:10,178] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 1.9624577e-31 2.7519886e-33 4.7240776e-32 5.0948346e-15], sum to 1.0000
[2019-03-27 09:12:10,187] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8096
[2019-03-27 09:12:10,194] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.8, 74.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9384628739148089, 6.911199999999999, 6.9112, 168.912956510431, 763088.7591808831, 763088.7591808836, 232054.4750305633], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2112600.0000, 
sim time next is 2113200.0000, 
raw observation next is [30.0, 74.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9421718400865763, 6.9112, 6.9112, 168.912956510431, 765437.2362863581, 765437.2362863581, 232919.7265598233], 
processed observation next is [0.0, 0.4782608695652174, 0.6208530805687204, 0.74, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9294778537641173, 0.0, 0.0, 0.8294399451523027, 0.21262145452398837, 0.21262145452398837, 0.3476413829251094], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.8960696], dtype=float32), 0.38287082]. 
=============================================
[2019-03-27 09:12:11,928] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [6.4868850e-01 1.4480691e-19 7.0135133e-16 3.9130954e-21 3.5131150e-01], sum to 1.0000
[2019-03-27 09:12:11,930] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.7403
[2019-03-27 09:12:11,940] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [22.65, 84.5, 1.0, 2.0, 0.237311475887056, 1.0, 1.0, 0.237311475887056, 1.0, 1.0, 0.4204956676505121, 6.911200000000001, 6.9112, 170.5573041426782, 1092078.123268351, 1092078.12326835, 291342.9558403016], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 1776600.0000, 
sim time next is 1777200.0000, 
raw observation next is [22.56666666666667, 84.33333333333334, 1.0, 2.0, 0.2258180230327952, 1.0, 2.0, 0.2258180230327952, 1.0, 2.0, 0.4005036286912045, 6.911200000000001, 6.9112, 170.5573041426782, 1040695.780388948, 1040695.780388947, 287563.0174097312], 
processed observation next is [1.0, 0.5652173913043478, 0.26856240126382325, 0.8433333333333334, 1.0, 1.0, 0.06725063015999419, 1.0, 1.0, 0.06725063015999419, 1.0, 1.0, 0.26890686425756644, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.28908216121915226, 0.2890821612191519, 0.42919853344736003], 
reward next is 0.5708, 
noisyNet noise sample is [array([-0.3010852], dtype=float32), 0.7159082]. 
=============================================
[2019-03-27 09:12:12,478] A3C_AGENT_WORKER-Thread-10 DEBUG:Policy network output: [9.9999988e-01 1.0459357e-27 1.9870361e-25 1.1649487e-27 9.6178425e-08], sum to 1.0000
[2019-03-27 09:12:12,487] A3C_AGENT_WORKER-Thread-10 DEBUG:Softmax action selection sampled number: 0.1685
[2019-03-27 09:12:12,491] A3C_AGENT_WORKER-Thread-10 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [23.3, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7276398903821674, 6.911199999999999, 6.9112, 168.912956510431, 616870.4574160738, 616870.4574160744, 187749.7600449007], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1654800.0000, 
sim time next is 1655400.0000, 
raw observation next is [23.3, 99.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7279797666795325, 6.911200000000001, 6.9112, 168.912956510431, 617158.4046353626, 617158.404635362, 187813.2308921466], 
processed observation next is [1.0, 0.13043478260869565, 0.3033175355450238, 0.99, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6682680081457714, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.1714328901764896, 0.17143289017648944, 0.28031825506290536], 
reward next is 0.7197, 
noisyNet noise sample is [array([0.5384616], dtype=float32), 0.8522009]. 
=============================================
[2019-03-27 09:12:13,800] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9999988e-01 5.8677296e-27 2.1512210e-25 8.6973194e-27 9.3481951e-08], sum to 1.0000
[2019-03-27 09:12:13,809] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.8701
[2019-03-27 09:12:13,819] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1625947.916334139 W.
[2019-03-27 09:12:13,824] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [23.93333333333333, 96.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.976838659612213, 6.9112, 168.9072875225111, 1625947.916334139, 869972.5473424015, 256501.1813542906], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 1671600.0000, 
sim time next is 1672200.0000, 
raw observation next is [24.05, 96.0, 1.0, 1.0, 0.487755205522202, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8167688598170054, 6.9112, 6.9112, 168.91208881843, 1375904.581529113, 1375904.581529113, 296977.4651043892], 
processed observation next is [1.0, 0.34782608695652173, 0.3388625592417062, 0.96, 1.0, 0.5, 0.38283759701470116, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7765473900207382, 0.0, 0.0, 0.8294356843873466, 0.38219571709142025, 0.38219571709142025, 0.4432499479169988], 
reward next is 0.5568, 
noisyNet noise sample is [array([-0.5017514], dtype=float32), 1.8120892]. 
=============================================
[2019-03-27 09:12:16,263] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.4698720e-02 6.5497639e-22 6.3599936e-18 1.9588286e-25 9.0530133e-01], sum to 1.0000
[2019-03-27 09:12:16,272] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.5385
[2019-03-27 09:12:16,275] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.81666666666667, 67.83333333333334, 1.0, 2.0, 0.4775333510437439, 1.0, 2.0, 0.4775333510437439, 1.0, 2.0, 0.8293175080705929, 6.9112, 6.9112, 170.5573041426782, 2003047.174139236, 2003047.174139236, 399957.9053692083], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2220600.0000, 
sim time next is 2221200.0000, 
raw observation next is [31.8, 68.0, 1.0, 2.0, 0.562645816562465, 1.0, 2.0, 0.562645816562465, 1.0, 2.0, 0.9771297135541511, 6.911200000000001, 6.9112, 170.5573041426782, 2360427.490842477, 2360427.490842476, 461170.175447409], 
processed observation next is [1.0, 0.7391304347826086, 0.7061611374407584, 0.68, 1.0, 1.0, 0.47306724887043977, 1.0, 1.0, 0.47306724887043977, 1.0, 1.0, 0.9721094067733549, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.6556743030117992, 0.6556743030117989, 0.6883136946976254], 
reward next is 0.3117, 
noisyNet noise sample is [array([1.660296], dtype=float32), -0.1891361]. 
=============================================
[2019-03-27 09:12:19,972] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [8.5953251e-02 7.7055487e-20 9.5239941e-17 1.9477902e-22 9.1404670e-01], sum to 1.0000
[2019-03-27 09:12:19,978] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.8684
[2019-03-27 09:12:19,984] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.9, 62.5, 1.0, 2.0, 0.4684112186788703, 1.0, 2.0, 0.4684112186788703, 1.0, 1.0, 0.8120423855965415, 6.911199999999999, 6.9112, 170.5573041426782, 1964748.663092783, 1964748.663092784, 393749.233254476], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2285400.0000, 
sim time next is 2286000.0000, 
raw observation next is [32.1, 62.0, 1.0, 2.0, 0.4754242003601153, 1.0, 2.0, 0.4754242003601153, 1.0, 2.0, 0.8256546108399194, 6.9112, 6.9112, 170.5573041426782, 1994191.959422099, 1994191.959422099, 398566.8504966593], 
processed observation next is [1.0, 0.4782608695652174, 0.7203791469194314, 0.62, 1.0, 1.0, 0.36798096428929555, 1.0, 1.0, 0.36798096428929555, 1.0, 1.0, 0.7873836717559993, 0.0, 0.0, 0.8375144448122397, 0.553942210950583, 0.553942210950583, 0.5948758962636705], 
reward next is 0.4051, 
noisyNet noise sample is [array([1.2343261], dtype=float32), -0.27589065]. 
=============================================
[2019-03-27 09:12:20,003] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[54.758965]
 [55.480953]
 [55.770863]
 [57.718517]
 [57.869877]], R is [[54.98122406]
 [54.43141174]
 [53.88709641]
 [53.66652298]
 [53.61084366]].
[2019-03-27 09:12:22,148] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 1.0767784e-32 1.0105986e-32 2.6046275e-32 1.7574781e-17], sum to 1.0000
[2019-03-27 09:12:22,157] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.0982
[2019-03-27 09:12:22,162] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.33333333333334, 95.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7807763461280366, 6.9112, 6.9112, 168.912956510431, 656816.7985855665, 656816.7985855665, 197972.9202025432], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 1999200.0000, 
sim time next is 1999800.0000, 
raw observation next is [24.3, 95.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7797299113546825, 6.911199999999999, 6.9112, 168.912956510431, 656049.2768892684, 656049.2768892691, 197764.9765871247], 
processed observation next is [0.0, 0.13043478260869565, 0.3507109004739337, 0.955, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7313779406764421, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.18223591024701902, 0.1822359102470192, 0.29517160684645477], 
reward next is 0.7048, 
noisyNet noise sample is [array([-0.30468902], dtype=float32), 0.07189784]. 
=============================================
[2019-03-27 09:12:26,241] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 7.9093938e-36 2.4634305e-36 1.1272568e-34 1.5209648e-17], sum to 1.0000
[2019-03-27 09:12:26,249] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.0954
[2019-03-27 09:12:26,252] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.85, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.78917913557771, 6.911200000000001, 6.9112, 168.912956510431, 662807.1135258737, 662807.1135258732, 199649.1371711135], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2067000.0000, 
sim time next is 2067600.0000, 
raw observation next is [24.8, 92.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7874520228735928, 6.9112, 6.9112, 168.912956510431, 661416.11784795, 661416.11784795, 199299.936297275], 
processed observation next is [0.0, 0.9565217391304348, 0.3744075829383887, 0.9266666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7407951498458449, 0.0, 0.0, 0.8294399451523027, 0.18372669940220832, 0.18372669940220832, 0.29746259148847015], 
reward next is 0.7025, 
noisyNet noise sample is [array([-2.1854506], dtype=float32), -1.1542352]. 
=============================================
[2019-03-27 09:12:28,796] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.0000000e+00 2.0297754e-35 8.6839868e-36 8.8197008e-35 2.1664665e-16], sum to 1.0000
[2019-03-27 09:12:28,806] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.4869
[2019-03-27 09:12:28,816] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.6, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7859831583392329, 6.9112, 6.9112, 168.912956510431, 660407.1712579873, 660407.1712579873, 199007.1138873405], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2070000.0000, 
sim time next is 2070600.0000, 
raw observation next is [24.58333333333334, 94.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7845418790047456, 6.9112, 6.9112, 168.912956510431, 659292.5582719819, 659292.5582719819, 198717.787070367], 
processed observation next is [0.0, 1.0, 0.3641390205371251, 0.9400000000000002, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7372461939082263, 0.0, 0.0, 0.8294399451523027, 0.18313682174221718, 0.18313682174221718, 0.29659371204532387], 
reward next is 0.7034, 
noisyNet noise sample is [array([-0.03184585], dtype=float32), -0.031676684]. 
=============================================
[2019-03-27 09:12:34,209] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.9273887e-36 1.5632904e-37 9.5657682e-36 9.2701214e-20], sum to 1.0000
[2019-03-27 09:12:34,217] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.6844
[2019-03-27 09:12:34,225] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.5, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7933959020294942, 6.9112, 6.9112, 168.912956510431, 665673.8767111677, 665673.8767111677, 200493.879907854], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2008800.0000, 
sim time next is 2009400.0000, 
raw observation next is [24.58333333333334, 95.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7971704836622235, 6.9112, 6.9112, 168.912956510431, 668295.3233105442, 668295.3233105442, 201254.7315867398], 
processed observation next is [0.0, 0.2608695652173913, 0.3641390205371251, 0.9583333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7526469312953946, 0.0, 0.0, 0.8294399451523027, 0.18563758980848452, 0.18563758980848452, 0.3003801963981191], 
reward next is 0.6996, 
noisyNet noise sample is [array([0.9799858], dtype=float32), -0.40032575]. 
=============================================
[2019-03-27 09:12:39,296] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0311386e-02 1.3730999e-20 1.2688126e-17 2.3782634e-23 9.8968863e-01], sum to 1.0000
[2019-03-27 09:12:39,303] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.7533
[2019-03-27 09:12:39,311] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.81666666666667, 64.83333333333334, 1.0, 2.0, 0.551902361018578, 1.0, 2.0, 0.551902361018578, 1.0, 2.0, 0.9584718841894594, 6.911199999999999, 6.9112, 170.5573041426782, 2315314.492805202, 2315314.492805202, 452892.9072418798], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 2296200.0000, 
sim time next is 2296800.0000, 
raw observation next is [31.8, 65.0, 1.0, 2.0, 0.5492521755258609, 1.0, 2.0, 0.5492521755258609, 1.0, 2.0, 0.9538693884183449, 6.9112, 6.9112, 170.5573041426782, 2304186.311357224, 2304186.311357224, 450875.6666504973], 
processed observation next is [1.0, 0.6086956521739131, 0.7061611374407584, 0.65, 1.0, 1.0, 0.45693033195886856, 1.0, 1.0, 0.45693033195886856, 1.0, 1.0, 0.9437431566077377, 0.0, 0.0, 0.8375144448122397, 0.6400517531547845, 0.6400517531547845, 0.6729487561947721], 
reward next is 0.3271, 
noisyNet noise sample is [array([-0.6894609], dtype=float32), -0.1868705]. 
=============================================
[2019-03-27 09:12:40,865] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.000000e+00 2.324654e-29 9.516630e-29 7.299263e-31 3.446901e-09], sum to 1.0000
[2019-03-27 09:12:40,876] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2677
[2019-03-27 09:12:40,881] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.3, 79.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9726425645308954, 6.9112, 6.9112, 168.912956510431, 786894.0305718322, 786894.0305718322, 240264.6271167764], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2324400.0000, 
sim time next is 2325000.0000, 
raw observation next is [29.2, 79.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9697075761751651, 6.911200000000001, 6.9112, 168.912956510431, 785080.09815109, 785080.0981510893, 239560.5677603419], 
processed observation next is [1.0, 0.9130434782608695, 0.5829383886255924, 0.7966666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.963058019725811, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21807780504196944, 0.21807780504196925, 0.3575530862094655], 
reward next is 0.6424, 
noisyNet noise sample is [array([1.4557624], dtype=float32), -0.85505295]. 
=============================================
[2019-03-27 09:12:40,895] A3C_AGENT_WORKER-Thread-21 DEBUG:Value prediction is [[66.65602]
 [66.31934]
 [66.05744]
 [65.55611]
 [65.07158]], R is [[66.86737061]
 [66.84009552]
 [66.81127167]
 [66.78114319]
 [66.74977112]].
[2019-03-27 09:12:45,349] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9999666e-01 4.2624593e-27 3.6954746e-25 2.7991851e-29 3.3136073e-06], sum to 1.0000
[2019-03-27 09:12:45,357] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3306
[2019-03-27 09:12:45,364] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.85, 93.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9492284273487003, 6.9112, 6.9112, 168.912956510431, 772537.7822034658, 772537.7822034658, 234706.4960100973], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2500200.0000, 
sim time next is 2500800.0000, 
raw observation next is [26.83333333333334, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9530463701569707, 6.9112, 6.9112, 168.912956510431, 775571.0519174506, 775571.0519174506, 235638.9452174524], 
processed observation next is [1.0, 0.9565217391304348, 0.4707740916271725, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9427394758011838, 0.0, 0.0, 0.8294399451523027, 0.21543640331040295, 0.21543640331040295, 0.3516999182350036], 
reward next is 0.6483, 
noisyNet noise sample is [array([-1.3657966], dtype=float32), -0.08211853]. 
=============================================
[2019-03-27 09:12:52,628] A3C_AGENT_WORKER-Thread-17 INFO:Evaluating...
[2019-03-27 09:12:52,629] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:12:52,631] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:12:52,631] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:12:52,632] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:12:52,632] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:12:52,633] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:12:52,634] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:12:52,634] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:12:52,634] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:12:52,636] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:12:52,670] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run97
[2019-03-27 09:12:52,671] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run97
[2019-03-27 09:12:52,712] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run97
[2019-03-27 09:12:52,730] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run97
[2019-03-27 09:12:52,749] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run97
[2019-03-27 09:12:58,485] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07936488]
[2019-03-27 09:12:58,486] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.68408012666667, 86.19071168333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6639860096115971, 6.911200000000001, 6.9112, 168.912956510431, 571277.4073560556, 571277.4073560549, 176443.8712342685]
[2019-03-27 09:12:58,488] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:12:58,492] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 1.8347191e-38 1.7182399e-25], sampled 0.4384332489250028
[2019-03-27 09:13:22,111] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07936488]
[2019-03-27 09:13:22,112] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [25.98674787, 83.28260869, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9325415344784516, 6.9112, 6.9112, 168.912956510431, 787170.5916569948, 787170.5916569948, 231628.0534304409]
[2019-03-27 09:13:22,112] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:13:22,114] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 3.0414332e-35 1.0065644e-36 1.6101200e-34 3.7861915e-21], sampled 0.44124809817317545
[2019-03-27 09:13:45,173] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07936488]
[2019-03-27 09:13:45,174] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [33.0, 63.00000000000001, 1.0, 2.0, 0.5815370065921057, 1.0, 2.0, 0.5815370065921057, 1.0, 2.0, 1.009937463223628, 6.911199999999999, 6.9112, 170.5573041426782, 2439757.707306295, 2439757.707306295, 476109.1119301094]
[2019-03-27 09:13:45,174] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:13:45,177] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [8.0272096e-01 2.5564130e-20 1.8520749e-17 3.3794003e-23 1.9727904e-01], sampled 0.20355113117585166
[2019-03-27 09:13:45,180] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2439757.707306295 W.
[2019-03-27 09:14:07,190] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07936488]
[2019-03-27 09:14:07,191] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.50340075, 65.840563535, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8255321837673874, 6.9112, 6.9112, 168.912956510431, 691741.6978860769, 691741.6978860769, 207176.7415316869]
[2019-03-27 09:14:07,193] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:14:07,198] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.6204686e-38 0.0000000e+00 2.3634692e-37 2.4242173e-24], sampled 0.4830799971935975
[2019-03-27 09:14:37,788] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07936488]
[2019-03-27 09:14:37,789] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [24.0, 95.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8685463134582484, 6.911200000000001, 6.9112, 168.912956510431, 734205.7616544196, 734205.7616544189, 216711.5677616021]
[2019-03-27 09:14:37,789] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:14:37,793] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.9906599e-36 2.2209249e-38 1.5304258e-35 7.0682467e-22], sampled 0.6980790601882418
[2019-03-27 09:14:49,102] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.6713 2989212695.1241 1565.0000
[2019-03-27 09:14:49,370] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8068.8568 2937920697.2469 1320.0000
[2019-03-27 09:14:49,516] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7371.2830 3105406275.4444 1938.0000
[2019-03-27 09:14:49,615] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7038.2096 3184869812.9371 2422.0000
[2019-03-27 09:14:49,653] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7270.0482 3318896568.7386 2151.0000
[2019-03-27 09:14:50,670] A3C_AGENT_WORKER-Thread-17 INFO:Global step: 2400000, evaluation results [2400000.0, 7270.048194915459, 3318896568.738603, 2151.0, 7371.283010409682, 3105406275.444368, 1938.0, 8068.856769161227, 2937920697.2468762, 1320.0, 7038.20955999741, 3184869812.937074, 2422.0, 7922.6713067969695, 2989212695.1240597, 1565.0]
[2019-03-27 09:14:57,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9879104e-01 6.7867471e-19 2.6083064e-16 7.4741302e-22 1.2089937e-03], sum to 1.0000
[2019-03-27 09:14:57,394] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.4515
[2019-03-27 09:14:57,401] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1046095.744134905 W.
[2019-03-27 09:14:57,407] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [26.46666666666667, 93.33333333333334, 1.0, 2.0, 0.3742543927247129, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6398782054770786, 6.911199999999999, 6.9112, 168.912956510431, 1046095.744134905, 1046095.744134905, 247496.3207056962], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 2533200.0000, 
sim time next is 2533800.0000, 
raw observation next is [26.48333333333333, 93.16666666666666, 1.0, 2.0, 0.3891824554407307, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6649530426883901, 6.9112, 6.9112, 168.912956510431, 1087843.234691754, 1087843.234691754, 253451.699769962], 
processed observation next is [1.0, 0.30434782608695654, 0.4541864139020536, 0.9316666666666665, 1.0, 1.0, 0.26407524751895267, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5914061496199878, 0.0, 0.0, 0.8294399451523027, 0.302178676303265, 0.302178676303265, 0.37828611905964477], 
reward next is 0.6217, 
noisyNet noise sample is [array([0.6834749], dtype=float32), 1.8245599]. 
=============================================
[2019-03-27 09:15:01,048] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [9.9260908e-01 1.5262498e-17 1.4819517e-14 5.3169583e-19 7.3909252e-03], sum to 1.0000
[2019-03-27 09:15:01,055] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.8437
[2019-03-27 09:15:01,063] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1880652.13488566 W.
[2019-03-27 09:15:01,069] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.9, 90.33333333333333, 1.0, 2.0, 0.6725693093809487, 1.0, 1.0, 0.6725693093809487, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 170.5573041426782, 1880652.13488566, 1880652.134885661, 362601.9993644594], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 2536800.0000, 
sim time next is 2537400.0000, 
raw observation next is [27.0, 89.66666666666667, 1.0, 2.0, 0.6701388687649229, 1.0, 2.0, 0.6701388687649229, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1873850.144005495, 1873850.144005495, 361602.3877417895], 
processed observation next is [1.0, 0.34782608695652173, 0.4786729857819906, 0.8966666666666667, 1.0, 1.0, 0.6025769503191842, 1.0, 1.0, 0.6025769503191842, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.5205139288904153, 0.5205139288904153, 0.5397050563310292], 
reward next is 0.4603, 
noisyNet noise sample is [array([-0.0833253], dtype=float32), 1.6819375]. 
=============================================
[2019-03-27 09:15:02,055] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [9.9834108e-01 2.5140581e-20 9.4079197e-18 1.5914183e-22 1.6589194e-03], sum to 1.0000
[2019-03-27 09:15:02,064] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.2371
[2019-03-27 09:15:02,071] A3C_AGENT_WORKER-Thread-22 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 935190.5584336953 W.
[2019-03-27 09:15:02,077] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [22.0, 100.0, 1.0, 2.0, 0.3116527032818512, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5444065856869084, 6.911200000000001, 6.9112, 168.9129565066038, 935190.5584336953, 935190.5584336946, 230856.2003386171], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3059400.0000, 
sim time next is 3060000.0000, 
raw observation next is [22.0, 100.0, 1.0, 2.0, 0.3011745222118745, 1.0, 1.0, 0.3011745222118745, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 896322.4498741351, 896322.4498741351, 257212.9756933929], 
processed observation next is [1.0, 0.43478260869565216, 0.2417061611374408, 1.0, 1.0, 1.0, 0.15804159302635484, 1.0, 0.5, 0.15804159302635484, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.24897845829837087, 0.24897845829837087, 0.38389996372148194], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.8990258], dtype=float32), -0.15632819]. 
=============================================
[2019-03-27 09:15:02,089] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[56.548855]
 [57.092106]
 [58.356922]
 [56.641136]
 [56.008793]], R is [[54.90497589]
 [54.35592651]
 [53.81236649]
 [53.79709244]
 [53.25912094]].
[2019-03-27 09:15:07,321] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 5.6477664e-34 3.0248179e-35 8.3515355e-35 1.6625874e-19], sum to 1.0000
[2019-03-27 09:15:07,327] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.8716
[2019-03-27 09:15:07,332] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6955308127333586, 6.911200000000001, 6.9112, 168.912956510431, 593853.7226833516, 593853.722683351, 181926.7627234611], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2829600.0000, 
sim time next is 2830200.0000, 
raw observation next is [24.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7046544068690133, 6.9112, 6.9112, 168.912956510431, 601657.3465114563, 601657.3465114563, 183563.0034145885], 
processed observation next is [1.0, 0.782608695652174, 0.3364928909952607, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.6398224474012357, 0.0, 0.0, 0.8294399451523027, 0.16712704069762674, 0.16712704069762674, 0.2739746319620724], 
reward next is 0.7260, 
noisyNet noise sample is [array([-2.1062539], dtype=float32), -0.012944569]. 
=============================================
[2019-03-27 09:15:14,610] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [1.0000000e+00 2.3682809e-36 2.3795825e-36 1.0580230e-34 7.8192147e-21], sum to 1.0000
[2019-03-27 09:15:14,618] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.9049
[2019-03-27 09:15:14,625] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [21.16666666666667, 99.00000000000001, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6393455431794524, 6.9112, 6.9112, 168.912956510431, 555958.1000476147, 555958.1000476147, 172287.0054224781], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2779800.0000, 
sim time next is 2780400.0000, 
raw observation next is [21.33333333333334, 98.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6088618398437631, 6.9112, 6.9112, 168.912956510431, 529250.0020647112, 529250.0020647112, 167453.9540172025], 
processed observation next is [1.0, 0.17391304347826086, 0.2101105845181678, 0.98, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5230022437119062, 0.0, 0.0, 0.8294399451523027, 0.14701388946241978, 0.14701388946241978, 0.24993127465254103], 
reward next is 0.7501, 
noisyNet noise sample is [array([-1.314035], dtype=float32), 0.7853102]. 
=============================================
[2019-03-27 09:15:14,954] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.0000000e+00 2.8628258e-34 9.0310292e-34 1.2376067e-32 6.6076415e-20], sum to 1.0000
[2019-03-27 09:15:14,967] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.1296
[2019-03-27 09:15:14,973] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6177314798968467, 6.9112, 6.9112, 168.912956510431, 535680.1998126784, 535680.1998126784, 168854.225285934], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 2770800.0000, 
sim time next is 2771400.0000, 
raw observation next is [22.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6172250553120617, 6.9112, 6.9112, 168.912956510431, 535240.9313666883, 535240.9313666883, 168774.761485755], 
processed observation next is [1.0, 0.043478260869565216, 0.2417061611374408, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.5332012869659289, 0.0, 0.0, 0.8294399451523027, 0.14867803649074676, 0.14867803649074676, 0.2519026290832164], 
reward next is 0.7481, 
noisyNet noise sample is [array([1.1089112], dtype=float32), 0.0052990774]. 
=============================================
[2019-03-27 09:15:25,685] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.4826671e-34 1.1766557e-33 7.7908781e-34 1.2937556e-15], sum to 1.0000
[2019-03-27 09:15:25,691] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.3083
[2019-03-27 09:15:25,694] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [25.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8130955374421435, 6.9112, 6.9112, 168.912956510431, 679502.5692020761, 679502.5692020761, 204505.942948258], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3199800.0000, 
sim time next is 3200400.0000, 
raw observation next is [25.0, 94.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8124837111681447, 6.9112, 6.9112, 168.912956510431, 678991.1046314024, 678991.1046314024, 204377.8556459822], 
processed observation next is [0.0, 0.043478260869565216, 0.38388625592417064, 0.94, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.7713215989855423, 0.0, 0.0, 0.8294399451523027, 0.18860864017538956, 0.18860864017538956, 0.3050415755910182], 
reward next is 0.6950, 
noisyNet noise sample is [array([-0.32518348], dtype=float32), 0.63610625]. 
=============================================
[2019-03-27 09:15:29,723] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.0227777e-37 0.0000000e+00 3.5992165e-37 2.2090727e-21], sum to 1.0000
[2019-03-27 09:15:29,738] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.0671
[2019-03-27 09:15:29,743] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.16666666666667, 69.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9703248210923755, 6.9112, 6.9112, 168.912956510431, 784616.6793167648, 784616.6793167648, 239663.1580082476], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3323400.0000, 
sim time next is 3324000.0000, 
raw observation next is [31.33333333333334, 69.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9783489253256389, 6.911199999999999, 6.9112, 168.912956510431, 789946.9347181612, 789946.9347181619, 241612.888529183], 
processed observation next is [0.0, 0.4782608695652174, 0.6840442338072673, 0.69, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9735962503971205, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2194297040883781, 0.2194297040883783, 0.360616251536094], 
reward next is 0.6394, 
noisyNet noise sample is [array([1.7922506], dtype=float32), 0.30413038]. 
=============================================
[2019-03-27 09:15:29,760] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[69.57716 ]
 [69.69303 ]
 [69.766045]
 [69.93345 ]
 [70.091446]], R is [[69.37696075]
 [69.32548523]
 [69.27884674]
 [69.23827362]
 [69.20342255]].
[2019-03-27 09:15:38,219] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [1.00000000e+00 1.92091518e-37 0.00000000e+00 1.23564185e-36
 1.40862884e-23], sum to 1.0000
[2019-03-27 09:15:38,228] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.1377
[2019-03-27 09:15:38,232] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.022185219216001, 6.9112, 6.9112, 168.9127439409431, 822510.2318775085, 822510.2318775085, 252745.8834339217], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3326400.0000, 
sim time next is 3327000.0000, 
raw observation next is [32.0, 67.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.96632897086481, 6.9112, 168.9124855862652, 867926.4568802501, 828816.1765945813, 254812.0006521428], 
processed observation next is [0.0, 0.5217391304347826, 0.7156398104265403, 0.67, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.005512897086480973, 0.0, 0.8294376326990586, 0.24109068246673615, 0.23022671572071704, 0.38031641888379525], 
reward next is 0.3440, 
noisyNet noise sample is [array([-0.44487056], dtype=float32), 0.39293993]. 
=============================================
[2019-03-27 09:15:38,242] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[66.0295  ]
 [66.12011 ]
 [66.19814 ]
 [66.354256]
 [66.485374]], R is [[65.495224  ]
 [65.46303558]
 [65.44141388]
 [65.41952515]
 [65.40271759]].
[2019-03-27 09:15:44,198] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 09:15:44,200] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:15:44,201] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:15:44,202] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:15:44,202] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:15:44,203] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:15:44,203] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:15:44,204] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:15:44,204] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:15:44,206] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:15:44,205] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:15:44,236] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run98
[2019-03-27 09:15:44,260] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run98
[2019-03-27 09:15:44,261] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run98
[2019-03-27 09:15:44,261] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run98
[2019-03-27 09:15:44,280] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run98
[2019-03-27 09:16:30,563] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07817475]
[2019-03-27 09:16:30,564] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [23.0, 96.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 8.02442852345844, 6.9112, 168.9070188364318, 1671690.317411231, 881955.4504508304, 256635.2355735164]
[2019-03-27 09:16:30,566] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:16:30,572] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.1706385e-36 0.0000000e+00 3.1113266e-35 1.8185861e-25], sampled 0.09226243803921708
[2019-03-27 09:16:30,573] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1671690.317411231 W.
[2019-03-27 09:16:36,424] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07817475]
[2019-03-27 09:16:36,424] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [32.54661213, 61.515581315, 1.0, 2.0, 0.7527918653969283, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.001579455362695, 6.9112, 168.9123423123468, 1949005.873218267, 1884887.810108914, 396679.0620800949]
[2019-03-27 09:16:36,426] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:16:36,429] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [9.9999309e-01 2.2838354e-22 2.2534019e-20 4.4338708e-24 6.8978125e-06], sampled 0.1365614764217017
[2019-03-27 09:16:36,431] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 1949005.873218267 W.
[2019-03-27 09:17:40,525] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7927.1455 2989881657.8242 1544.0000
[2019-03-27 09:17:40,653] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7030.8644 3185621741.9990 2367.0000
[2019-03-27 09:17:40,808] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8079.3086 2937855519.9718 1273.0000
[2019-03-27 09:17:40,979] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7395.1646 3104594192.9966 1865.0000
[2019-03-27 09:17:41,073] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7274.2527 3320032557.8592 2122.0000
[2019-03-27 09:17:42,093] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2425000, evaluation results [2425000.0, 7274.252671076637, 3320032557.8592234, 2122.0, 7395.1645889243555, 3104594192.9966116, 1865.0, 8079.308628994475, 2937855519.971755, 1273.0, 7030.864422568185, 3185621741.9990325, 2367.0, 7927.14548765965, 2989881657.8242345, 1544.0]
[2019-03-27 09:17:46,440] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [9.9981707e-01 2.3890797e-20 7.7116692e-18 1.0248405e-21 1.8289423e-04], sum to 1.0000
[2019-03-27 09:17:46,449] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.6405
[2019-03-27 09:17:46,456] A3C_AGENT_WORKER-Thread-11 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 1111091.742238006 W.
[2019-03-27 09:17:46,462] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.83333333333334, 74.83333333333334, 1.0, 2.0, 0.7949907991887735, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 1111091.742238006, 1111091.742238005, 242681.8208175359], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3653400.0000, 
sim time next is 3654000.0000, 
raw observation next is [28.0, 74.0, 1.0, 2.0, 0.238032954037794, 1.0, 1.0, 0.238032954037794, 1.0, 1.0, 0.4010461445735028, 6.911199999999999, 6.9112, 170.5573041426782, 997978.2430761819, 997978.2430761826, 280467.8087995288], 
processed observation next is [1.0, 0.30434782608695654, 0.5260663507109005, 0.74, 1.0, 1.0, 0.08196741450336627, 1.0, 0.5, 0.08196741450336627, 1.0, 0.5, 0.2695684689920766, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2772161786322727, 0.27721617863227294, 0.41860866985004297], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.96005845], dtype=float32), -0.66119164]. 
=============================================
[2019-03-27 09:17:46,478] A3C_AGENT_WORKER-Thread-11 DEBUG:Value prediction is [[38.37161 ]
 [39.893604]
 [39.095963]
 [39.681534]
 [40.86776 ]], R is [[39.26311874]
 [39.50827408]
 [39.74146271]
 [39.34404755]
 [39.5691185 ]].
[2019-03-27 09:17:47,072] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [4.1747141e-01 1.7470343e-16 2.9768760e-13 1.4349601e-19 5.8252865e-01], sum to 1.0000
[2019-03-27 09:17:47,079] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4217
[2019-03-27 09:17:47,083] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [29.66666666666667, 67.66666666666667, 1.0, 2.0, 0.4607366158466166, 1.0, 2.0, 0.4607366158466166, 1.0, 2.0, 0.7858376679109256, 6.911200000000001, 6.9112, 170.5573041426782, 1932528.544340682, 1932528.544340681, 386675.0987312155], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3748800.0000, 
sim time next is 3749400.0000, 
raw observation next is [30.0, 66.5, 1.0, 2.0, 0.4516549054875954, 1.0, 2.0, 0.4516549054875954, 1.0, 2.0, 0.7716708986790276, 6.911199999999999, 6.9112, 170.5573041426782, 1894402.2482482, 1894402.248248201, 381261.3469589656], 
processed observation next is [1.0, 0.391304347826087, 0.6208530805687204, 0.665, 1.0, 1.0, 0.33934325962360895, 1.0, 1.0, 0.33934325962360895, 1.0, 1.0, 0.7215498764378384, -8.881784197001253e-17, 0.0, 0.8375144448122397, 0.526222846735611, 0.5262228467356114, 0.5690467865059188], 
reward next is 0.4310, 
noisyNet noise sample is [array([0.0398735], dtype=float32), -0.48457685]. 
=============================================
[2019-03-27 09:17:48,377] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [2.1657221e-02 6.0903874e-20 1.4929373e-17 1.7498159e-22 9.7834271e-01], sum to 1.0000
[2019-03-27 09:17:48,386] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.4255
[2019-03-27 09:17:48,390] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [33.0, 63.0, 1.0, 2.0, 0.7426595232786062, 1.0, 2.0, 0.6919198011535658, 1.0, 1.0, 1.03, 7.005101096060822, 6.9112, 170.5573041426782, 2903391.48566966, 2836126.310908919, 535141.3669098958], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 3772800.0000, 
sim time next is 3773400.0000, 
raw observation next is [33.0, 63.0, 1.0, 2.0, 0.7410343263931025, 1.0, 2.0, 0.6911072027108137, 1.0, 2.0, 1.03, 7.005100967897536, 6.9112, 170.5573041426782, 2899977.751746957, 2832712.668794791, 534602.7501143926], 
processed observation next is [1.0, 0.6956521739130435, 0.7630331753554502, 0.63, 1.0, 1.0, 0.6879931643290391, 1.0, 1.0, 0.6278400032660406, 1.0, 1.0, 1.0365853658536586, 0.0093900967897536, 0.0, 0.8375144448122397, 0.8055493754852658, 0.7868646302207754, 0.7979145524095412], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.0719734], dtype=float32), 1.197205]. 
=============================================
[2019-03-27 09:17:51,213] A3C_AGENT_WORKER-Thread-20 DEBUG:Policy network output: [9.9998188e-01 8.8927157e-20 6.5019162e-17 5.1855071e-22 1.8086439e-05], sum to 1.0000
[2019-03-27 09:17:51,224] A3C_AGENT_WORKER-Thread-20 DEBUG:Softmax action selection sampled number: 0.8250
[2019-03-27 09:17:51,231] A3C_AGENT_WORKER-Thread-20 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 960034.4041571531 W.
[2019-03-27 09:17:51,235] A3C_AGENT_WORKER-Thread-20 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.0, 89.0, 1.0, 2.0, 0.3434787370483323, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5861419656464958, 6.911200000000001, 6.9112, 168.912956510431, 960034.4041571531, 960034.4041571524, 235714.1242680455], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4081200.0000, 
sim time next is 4081800.0000, 
raw observation next is [27.0, 89.0, 1.0, 2.0, 0.2345131985516491, 1.0, 1.0, 0.2345131985516491, 1.0, 2.0, 0.4021896374043916, 6.911200000000001, 6.9112, 170.5573041426782, 983214.531973183, 983214.5319731825, 279868.3252479], 
processed observation next is [1.0, 0.21739130434782608, 0.4786729857819906, 0.89, 1.0, 1.0, 0.0777267452429507, 1.0, 0.5, 0.0777267452429507, 1.0, 1.0, 0.27096297244438, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.27311514777032864, 0.27311514777032847, 0.41771391828044774], 
reward next is 0.5823, 
noisyNet noise sample is [array([0.3426899], dtype=float32), -0.6762208]. 
=============================================
[2019-03-27 09:17:51,890] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.1116336e-31 5.6677148e-32 2.0170812e-32 4.3350739e-17], sum to 1.0000
[2019-03-27 09:17:51,898] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.5194
[2019-03-27 09:17:51,903] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [32.66666666666666, 67.5, 1.0, 1.0, 0.2016694427913548, 1.0, 1.0, 0.2016694427913548, 1.0, 2.0, 0.3502331290247219, 6.9112, 6.9112, 170.5573041426782, 845460.2924258512, 845460.2924258512, 270308.0103779431], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3837000.0000, 
sim time next is 3837600.0000, 
raw observation next is [33.0, 67.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.043403931962408, 6.9112, 168.9120924071501, 922627.0519574295, 828837.5123140934, 254813.0836035803], 
processed observation next is [0.0, 0.43478260869565216, 0.7630331753554502, 0.67, 0.0, 0.5, -0.20481927710843376, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.013220393196240821, 0.0, 0.8294357020096054, 0.2562852922103971, 0.23023264230947038, 0.38031803522922436], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.4037954], dtype=float32), 0.013505937]. 
=============================================
[2019-03-27 09:17:58,512] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [9.9146312e-01 9.1204769e-18 1.6805877e-16 4.3675094e-20 8.5368445e-03], sum to 1.0000
[2019-03-27 09:17:58,523] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.4793
[2019-03-27 09:17:58,531] A3C_AGENT_WORKER-Thread-13 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1363421.948405353 W.
[2019-03-27 09:17:58,536] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.5, 86.5, 1.0, 2.0, 0.4877121531391428, 1.0, 1.0, 0.4877121531391428, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1363421.948405353, 1363421.948405353, 296495.4672385629], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4343400.0000, 
sim time next is 4344000.0000, 
raw observation next is [29.66666666666667, 85.66666666666667, 1.0, 2.0, 0.4887304985524097, 1.0, 2.0, 0.4887304985524097, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1366270.594484833, 1366270.594484833, 296804.9255670618], 
processed observation next is [1.0, 0.2608695652173913, 0.6050552922590839, 0.8566666666666667, 1.0, 1.0, 0.38401264885832487, 1.0, 1.0, 0.38401264885832487, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3795196095791203, 0.3795196095791203, 0.44299242621949525], 
reward next is 0.5570, 
noisyNet noise sample is [array([-0.93182194], dtype=float32), -0.90534467]. 
=============================================
[2019-03-27 09:17:58,556] A3C_AGENT_WORKER-Thread-13 DEBUG:Value prediction is [[36.19843 ]
 [35.83358 ]
 [36.706696]
 [36.300163]
 [38.02453 ]], R is [[37.28508759]
 [36.91223526]
 [36.54311371]
 [36.17768478]
 [35.81590652]].
[2019-03-27 09:18:00,227] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.0000000e+00 1.6252317e-35 5.9867641e-37 1.0728166e-34 2.3770409e-22], sum to 1.0000
[2019-03-27 09:18:00,238] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3724
[2019-03-27 09:18:00,243] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.16666666666667, 93.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9901249210021027, 6.9112, 6.9112, 168.912956510431, 801568.5352677332, 801568.5352677332, 244713.8972648631], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 3897600.0000, 
sim time next is 3898200.0000, 
raw observation next is [27.08333333333333, 93.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9893863262396765, 6.9112, 6.9112, 168.9129219231814, 801456.4886341365, 801456.4886341365, 244551.6757723911], 
processed observation next is [0.0, 0.08695652173913043, 0.4826224328593995, 0.9366666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9870564954142396, 0.0, 0.0, 0.829439775313073, 0.22262680239837127, 0.22262680239837127, 0.36500250115282257], 
reward next is 0.6350, 
noisyNet noise sample is [array([-1.2819924], dtype=float32), 0.22653538]. 
=============================================
[2019-03-27 09:18:03,008] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 2.9422432e-26 1.1671384e-25 2.6206386e-28 2.6287428e-10], sum to 1.0000
[2019-03-27 09:18:03,014] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.7733
[2019-03-27 09:18:03,017] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9925337732828776, 6.911200000000001, 6.9112, 168.912956508796, 800560.0629439206, 800560.0629439199, 245165.1952927262], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4150800.0000, 
sim time next is 4151400.0000, 
raw observation next is [28.16666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.003895572192251, 6.9112, 6.9112, 168.9128445086066, 809809.5654472751, 809809.5654472751, 248091.3512466181], 
processed observation next is [1.0, 0.043478260869565216, 0.5339652448657191, 0.8816666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 1.004750697795428, 0.0, 0.0, 0.8294393951720702, 0.22494710151313196, 0.22494710151313196, 0.3702855988755494], 
reward next is 0.6297, 
noisyNet noise sample is [array([1.2588726], dtype=float32), 0.53116477]. 
=============================================
[2019-03-27 09:18:08,338] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 5.9705709e-37 0.0000000e+00 4.6209060e-36 3.0365533e-27], sum to 1.0000
[2019-03-27 09:18:08,351] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.5259
[2019-03-27 09:18:08,355] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.16666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8505111983827214, 6.911200000000001, 6.9112, 168.912956510431, 707345.3380824025, 707345.3380824019, 212434.6845390982], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4515000.0000, 
sim time next is 4515600.0000, 
raw observation next is [26.33333333333334, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8530954013188214, 6.9112, 6.9112, 168.912956510431, 709083.5651957099, 709083.5651957099, 212989.9409435794], 
processed observation next is [0.0, 0.2608695652173913, 0.44707740916271754, 0.8733333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8208480503888067, 0.0, 0.0, 0.8294399451523027, 0.1969676569988083, 0.1969676569988083, 0.31789543424414834], 
reward next is 0.6821, 
noisyNet noise sample is [array([1.1523235], dtype=float32), 1.0110455]. 
=============================================
[2019-03-27 09:18:12,888] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [7.6127845e-01 3.4036365e-15 2.2781852e-13 5.3759701e-18 2.3872156e-01], sum to 1.0000
[2019-03-27 09:18:12,899] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.8706
[2019-03-27 09:18:12,902] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.33333333333333, 68.66666666666667, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 8.07904093144353, 6.9112, 168.906475691231, 3124842.858244223, 2296368.09547224, 473899.510427318], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4012800.0000, 
sim time next is 4013400.0000, 
raw observation next is [30.66666666666667, 67.33333333333333, 1.0, 2.0, 0.681079029339726, 1.0, 1.0, 0.6611295541841256, 1.0, 2.0, 1.03, 7.001749137710905, 6.9112, 170.5573041426782, 2774047.880056796, 2709183.849411048, 515559.4526710489], 
processed observation next is [1.0, 0.43478260869565216, 0.6524486571879939, 0.6733333333333333, 1.0, 1.0, 0.6157578666743686, 1.0, 0.5, 0.5917223544387055, 1.0, 1.0, 1.0365853658536586, 0.009054913771090512, 0.0, 0.8375144448122397, 0.7705688555713323, 0.7525510692808467, 0.7694917204045506], 
reward next is 0.0000, 
noisyNet noise sample is [array([-1.6147585], dtype=float32), 0.054084886]. 
=============================================
[2019-03-27 09:18:15,328] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [1.0000000e+00 5.1639944e-26 2.3193518e-26 2.4278693e-27 5.8203740e-14], sum to 1.0000
[2019-03-27 09:18:15,337] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.1262
[2019-03-27 09:18:15,345] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 1 for the demand 1008386.454944988 W.
[2019-03-27 09:18:15,351] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 1, 
current raw observation is [34.83333333333334, 60.33333333333334, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.164242554826569, 6.9112, 168.911444090213, 1008386.454944988, 828870.9648664502, 254813.5649023824], 
current ob forecast is [], 
actual action is [0, 1, 0, 0, 0], 
sim time this is 3850800.0000, 
sim time next is 3851400.0000, 
raw observation next is [34.91666666666666, 60.16666666666666, 1.0, 1.0, 0.6502836422494714, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 6.911199999999999, 6.9112, 168.9127504723414, 908760.1917617472, 908760.1917617478, 210487.3544951084], 
processed observation next is [0.0, 0.5652173913043478, 0.8538704581358605, 0.6016666666666666, 1.0, 0.5, 0.5786549906620138, 0.0, 1.0, -0.20481927710843376, 0.0, 0.5, -0.2195121951219512, -8.881784197001253e-17, 0.0, 0.8294389334109581, 0.25243338660048537, 0.25243338660048553, 0.31416023058971404], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.70598006], dtype=float32), 0.7112614]. 
=============================================
[2019-03-27 09:18:18,363] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [9.9986041e-01 5.1070379e-17 1.1241524e-14 4.0039846e-20 1.3952146e-04], sum to 1.0000
[2019-03-27 09:18:18,373] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.6506
[2019-03-27 09:18:18,384] A3C_AGENT_WORKER-Thread-15 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1810151.259418325 W.
[2019-03-27 09:18:18,391] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [29.0, 84.0, 1.0, 2.0, 0.4315851149647953, 1.0, 2.0, 0.4315851149647953, 1.0, 1.0, 0.7495206173153285, 6.9112, 6.9112, 170.5573041426782, 1810151.259418325, 1810151.259418325, 371062.2016026351], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 3990000.0000, 
sim time next is 3990600.0000, 
raw observation next is [29.0, 84.0, 1.0, 2.0, 0.6303098422928273, 1.0, 2.0, 0.6303098422928273, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1762388.163761332, 1762388.163761332, 345724.8087795535], 
processed observation next is [1.0, 0.17391304347826086, 0.5734597156398105, 0.84, 1.0, 1.0, 0.5545901714371413, 1.0, 1.0, 0.5545901714371413, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.4895522677114811, 0.4895522677114811, 0.5160071772829157], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.20765662], dtype=float32), -0.6911088]. 
=============================================
[2019-03-27 09:18:29,641] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [7.8988916e-01 2.4377691e-14 9.5362104e-12 3.5760970e-17 2.1011084e-01], sum to 1.0000
[2019-03-27 09:18:29,647] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.1697
[2019-03-27 09:18:29,657] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2665118.505283266 W.
[2019-03-27 09:18:29,661] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.16666666666666, 79.00000000000001, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 1.0, 1.03, 7.448381379613197, 6.9112, 168.9104272756065, 2665118.505283266, 2284029.252592414, 474916.9815385562], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4093800.0000, 
sim time next is 4094400.0000, 
raw observation next is [30.33333333333334, 79.0, 1.0, 2.0, 0.6225546771059258, 1.0, 1.0, 0.6225546771059258, 1.0, 2.0, 1.03, 6.968726795860266, 6.9112, 170.5573041426782, 2612021.512708706, 2570812.728793554, 496302.1751707947], 
processed observation next is [1.0, 0.391304347826087, 0.6366508688783573, 0.79, 1.0, 1.0, 0.5452465989228021, 1.0, 0.5, 0.5452465989228021, 1.0, 1.0, 1.0365853658536586, 0.005752679586026588, 0.0, 0.8375144448122397, 0.7255615313079739, 0.7141146468870984, 0.7407495151802906], 
reward next is 0.0000, 
noisyNet noise sample is [array([-0.20967618], dtype=float32), -1.3567184]. 
=============================================
[2019-03-27 09:18:30,673] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [9.9997890e-01 9.0932047e-18 4.8797960e-16 4.4875687e-21 2.1125494e-05], sum to 1.0000
[2019-03-27 09:18:30,678] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.2804
[2019-03-27 09:18:30,682] A3C_AGENT_WORKER-Thread-21 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 871915.6920908358 W.
[2019-03-27 09:18:30,685] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [30.66666666666667, 80.66666666666667, 1.0, 2.0, 0.3119660120801943, 1.0, 1.0, 0.3119660120801943, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 871915.6920908358, 871915.6920908358, 252245.4745984115], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4321200.0000, 
sim time next is 4321800.0000, 
raw observation next is [30.5, 81.5, 1.0, 2.0, 0.2071327148586072, 1.0, 2.0, 0.2071327148586072, 1.0, 1.0, 0.3597210258738581, 6.911200000000001, 6.9112, 170.5573041426782, 868373.2808211071, 868373.2808211065, 271853.2071875167], 
processed observation next is [1.0, 0.0, 0.6445497630331753, 0.815, 1.0, 1.0, 0.04473821067302072, 1.0, 1.0, 0.04473821067302072, 1.0, 0.5, 0.2191719827729977, 8.881784197001253e-17, 0.0, 0.8375144448122397, 0.2412148002280853, 0.24121480022808514, 0.40575105550375623], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.3740532], dtype=float32), -0.12144938]. 
=============================================
[2019-03-27 09:18:31,829] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [9.9969733e-01 7.2019751e-17 4.9671524e-15 1.2317730e-19 3.0269133e-04], sum to 1.0000
[2019-03-27 09:18:31,840] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2965
[2019-03-27 09:18:31,855] A3C_AGENT_WORKER-Thread-3 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1307248.690431899 W.
[2019-03-27 09:18:31,862] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [28.0, 89.0, 1.0, 2.0, 0.4676305589928174, 1.0, 2.0, 0.4676305589928174, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1307248.690431899, 1307248.690431899, 290512.9677716107], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 4167000.0000, 
sim time next is 4167600.0000, 
raw observation next is [28.0, 89.0, 1.0, 2.0, 0.4504237475060811, 1.0, 2.0, 0.4504237475060811, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1259119.262412893, 1259119.262412893, 285582.2772198921], 
processed observation next is [1.0, 0.21739130434782608, 0.5260663507109005, 0.89, 1.0, 1.0, 0.33785993675431464, 1.0, 1.0, 0.33785993675431464, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.34975535067024804, 0.34975535067024804, 0.42624220480580904], 
reward next is 0.5738, 
noisyNet noise sample is [array([1.0944039], dtype=float32), 1.0493326]. 
=============================================
[2019-03-27 09:18:32,797] A3C_AGENT_WORKER-Thread-19 DEBUG:Policy network output: [2.0038250e-01 3.8431687e-16 3.1297484e-15 1.6918765e-19 7.9961747e-01], sum to 1.0000
[2019-03-27 09:18:32,803] A3C_AGENT_WORKER-Thread-19 DEBUG:Softmax action selection sampled number: 0.0334
[2019-03-27 09:18:32,808] A3C_AGENT_WORKER-Thread-19 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 3652713.428884469 W.
[2019-03-27 09:18:32,813] A3C_AGENT_WORKER-Thread-19 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [36.0, 55.66666666666667, 1.0, 2.0, 1.04, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 7.947744083204874, 6.9112, 170.5573041426782, 3652713.428884469, 2910194.738167307, 547645.091557619], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 4196400.0000, 
sim time next is 4197000.0000, 
raw observation next is [36.0, 56.33333333333333, 1.0, 2.0, 0.9586759264366653, 1.0, 2.0, 0.7999280027325951, 1.0, 1.0, 1.03, 7.005118137382734, 6.9112, 170.5573041426782, 3357218.047811428, 3289940.665658605, 615494.7887455429], 
processed observation next is [1.0, 0.5652173913043478, 0.9052132701421801, 0.5633333333333332, 1.0, 1.0, 0.9502119595622474, 1.0, 1.0, 0.7589494008826447, 1.0, 0.5, 1.0365853658536586, 0.009391813738273403, 0.0, 0.8375144448122397, 0.9325605688365078, 0.9138724071273903, 0.9186489384261833], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.4858451], dtype=float32), -1.001361]. 
=============================================
[2019-03-27 09:18:32,824] A3C_AGENT_WORKER-Thread-19 DEBUG:Value prediction is [[17.108736]
 [16.35837 ]
 [15.600943]
 [15.878571]
 [18.338015]], R is [[17.72350693]
 [17.54627228]
 [17.37080956]
 [17.19710159]
 [17.02513123]].
[2019-03-27 09:18:35,726] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 09:18:35,728] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:18:35,729] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:18:35,729] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:18:35,730] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:18:35,731] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:18:35,733] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:18:35,734] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:18:35,736] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:18:35,731] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:18:35,739] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:18:35,760] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run99
[2019-03-27 09:18:35,785] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run99
[2019-03-27 09:18:35,785] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run99
[2019-03-27 09:18:35,786] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run99
[2019-03-27 09:18:35,814] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run99
[2019-03-27 09:18:59,669] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:18:59,670] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [24.96666666666667, 79.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6868216301086542, 6.9112, 6.9112, 168.912956510431, 589174.2942074097, 589174.2942074097, 180390.890658293]
[2019-03-27 09:18:59,672] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:18:59,674] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 1.5661607e-38 0.0000000e+00 1.1802857e-37 3.3503523e-28], sampled 0.04729243660657656
[2019-03-27 09:19:09,964] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:19:09,967] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [31.14469994, 68.13564068666668, 1.0, 2.0, 0.684600268896247, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 956738.687149238, 956738.6871492387, 217558.3992808431]
[2019-03-27 09:19:09,970] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:19:09,973] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 1.2886740e-20 1.6589011e-18 3.3846354e-22 1.9455602e-08], sampled 0.9747671006532591
[2019-03-27 09:19:09,976] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 956738.687149238 W.
[2019-03-27 09:19:25,473] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:19:25,474] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [31.1, 61.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8832959017103817, 6.911199999999999, 6.9112, 168.912956510431, 729706.2959127949, 729706.2959127956, 219606.1363935536]
[2019-03-27 09:19:25,474] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:19:25,477] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0041955e-26], sampled 0.7645651321181838
[2019-03-27 09:19:53,300] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:19:53,303] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [34.73333333333333, 57.83333333333333, 1.0, 2.0, 1.02469580510538, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.00599468323496, 6.9112, 168.9123159186434, 2329568.782034998, 2262318.426210635, 471000.3761324474]
[2019-03-27 09:19:53,306] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:19:53,310] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [9.9987102e-01 4.1288597e-20 6.4376417e-19 7.2626902e-23 1.2892349e-04], sampled 0.6117702400976109
[2019-03-27 09:19:53,313] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2329568.782034998 W.
[2019-03-27 09:20:11,321] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:20:11,323] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [23.07302112, 79.04925133833333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5833592321071721, 6.9112, 6.9112, 168.912956510431, 514006.0422144882, 514006.0422144882, 163421.1769845827]
[2019-03-27 09:20:11,324] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:20:11,328] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.4667119e-36 0.0000000e+00 2.4885733e-36 1.8236445e-24], sampled 0.4893410660016775
[2019-03-27 09:20:18,070] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.073997684]
[2019-03-27 09:20:18,072] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [29.76117738, 61.54025163, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7893365272096444, 6.9112, 6.9112, 168.912956510431, 663481.4451345849, 663481.4451345849, 199692.1454834732]
[2019-03-27 09:20:18,073] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:20:18,077] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 1.1963545e-38 0.0000000e+00 1.0345024e-37 1.4491987e-28], sampled 0.5771009499995855
[2019-03-27 09:20:31,134] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8064.8701 2937981240.9488 1377.0000
[2019-03-27 09:20:31,708] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7288.2259 3319593314.9616 2142.0000
[2019-03-27 09:20:31,759] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7345.3340 3106009844.4900 2007.0000
[2019-03-27 09:20:31,899] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7029.8662 3185172673.9410 2464.0000
[2019-03-27 09:20:31,971] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7924.6819 2989322958.0886 1566.0000
[2019-03-27 09:20:32,993] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2450000, evaluation results [2450000.0, 7288.225867690675, 3319593314.9615836, 2142.0, 7345.333976629473, 3106009844.489984, 2007.0, 8064.870110154895, 2937981240.9488177, 1377.0, 7029.8661889920195, 3185172673.94103, 2464.0, 7924.681917215527, 2989322958.0886335, 1566.0]
[2019-03-27 09:20:34,386] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [9.9985707e-01 1.9798669e-18 5.0687471e-17 3.7276135e-21 1.4293949e-04], sum to 1.0000
[2019-03-27 09:20:34,393] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.9467
[2019-03-27 09:20:34,401] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 1494608.725293375 W.
[2019-03-27 09:20:34,407] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [29.66666666666667, 79.0, 1.0, 2.0, 0.5346028942838045, 0.0, 2.0, 0.0, 1.0, 1.0, 0.9282131501559471, 6.911200000000001, 6.9112, 168.912956510431, 1494608.725293375, 1494608.725293375, 327506.925500536], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4257600.0000, 
sim time next is 4258200.0000, 
raw observation next is [29.83333333333333, 79.0, 1.0, 2.0, 0.5492892209305078, 0.0, 2.0, 0.0, 1.0, 2.0, 0.953933724035114, 6.911200000000001, 6.9112, 168.912956510431, 1535697.523962648, 1535697.523962647, 336174.7988727387], 
processed observation next is [1.0, 0.2608695652173913, 0.6129541864139019, 0.79, 1.0, 1.0, 0.4569749649765154, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9438216146769683, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.42658264554518, 0.4265826455451797, 0.5017534311533414], 
reward next is 0.4982, 
noisyNet noise sample is [array([-2.4345024], dtype=float32), -0.8650211]. 
=============================================
[2019-03-27 09:20:41,273] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0732644e-31], sum to 1.0000
[2019-03-27 09:20:41,278] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.1745
[2019-03-27 09:20:41,284] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.0, 79.83333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8891760124415102, 6.9112, 6.9112, 168.912956510431, 733794.9561776905, 733794.9561776905, 220922.4972501996], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4569000.0000, 
sim time next is 4569600.0000, 
raw observation next is [28.0, 80.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8963487449759698, 6.911200000000001, 6.9112, 168.912956510431, 738554.5687871417, 738554.5687871411, 222530.8778561812], 
processed observation next is [0.0, 0.9130434782608695, 0.5260663507109005, 0.8066666666666668, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8735960304584997, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20515404688531713, 0.20515404688531697, 0.33213563859131523], 
reward next is 0.6679, 
noisyNet noise sample is [array([-0.9429975], dtype=float32), 1.2590008]. 
=============================================
[2019-03-27 09:20:47,355] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 2.9863962e-36 5.2398440e-38 1.7307102e-35 2.3625498e-22], sum to 1.0000
[2019-03-27 09:20:47,363] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.6803
[2019-03-27 09:20:47,373] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.5, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9370877318618301, 6.9112, 6.9112, 168.912956510431, 764851.5724996116, 764851.5724996116, 231860.1820904314], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5263200.0000, 
sim time next is 5263800.0000, 
raw observation next is [28.5, 81.33333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9415768170507317, 6.9112, 6.9112, 168.912956510431, 768191.4446982025, 768191.4446982025, 232932.3130443644], 
processed observation next is [1.0, 0.9565217391304348, 0.5497630331753555, 0.8133333333333332, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9287522159155265, 0.0, 0.0, 0.8294399451523027, 0.21338651241616738, 0.21338651241616738, 0.34766016872293193], 
reward next is 0.6523, 
noisyNet noise sample is [array([-0.5696859], dtype=float32), 1.8479673]. 
=============================================
[2019-03-27 09:20:51,156] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5316823e-34], sum to 1.0000
[2019-03-27 09:20:51,164] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.0317
[2019-03-27 09:20:51,169] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8493945178324049, 6.9112, 6.9112, 168.912956510431, 706635.1091571717, 706635.1091571717, 212196.4233700231], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4513200.0000, 
sim time next is 4513800.0000, 
raw observation next is [26.0, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8493674589424794, 6.911200000000001, 6.9112, 168.912956510431, 706608.0258309717, 706608.0258309711, 212190.3599080629], 
processed observation next is [0.0, 0.21739130434782608, 0.4312796208530806, 0.89, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8163017791981455, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.19628000717526992, 0.19628000717526975, 0.31670202971352673], 
reward next is 0.6833, 
noisyNet noise sample is [array([-0.3280261], dtype=float32), -1.2012776]. 
=============================================
[2019-03-27 09:20:51,948] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.178504e-37], sum to 1.0000
[2019-03-27 09:20:51,953] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.2975
[2019-03-27 09:20:51,958] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.83333333333333, 70.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9085806905527071, 6.911200000000001, 6.9112, 168.912956510431, 745589.5043003226, 745589.504300322, 225256.6138807232], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 4558200.0000, 
sim time next is 4558800.0000, 
raw observation next is [29.66666666666667, 71.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9061764829223855, 6.9112, 6.9112, 168.912956510431, 744022.9855377565, 744022.9855377565, 224710.9699504896], 
processed observation next is [0.0, 0.782608695652174, 0.6050552922590839, 0.7133333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8855810767346165, 0.0, 0.0, 0.8294399451523027, 0.20667305153826568, 0.20667305153826568, 0.3353895073887905], 
reward next is 0.6646, 
noisyNet noise sample is [array([0.3619423], dtype=float32), -1.3723359]. 
=============================================
[2019-03-27 09:20:57,087] A3C_AGENT_WORKER-Thread-2 DEBUG:Policy network output: [9.9928063e-01 1.3841958e-17 1.1978627e-16 5.2967501e-21 7.1940274e-04], sum to 1.0000
[2019-03-27 09:20:57,096] A3C_AGENT_WORKER-Thread-2 DEBUG:Softmax action selection sampled number: 0.2665
[2019-03-27 09:20:57,105] A3C_AGENT_WORKER-Thread-2 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 2370934.317594174 W.
[2019-03-27 09:20:57,110] A3C_AGENT_WORKER-Thread-2 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [31.0, 66.0, 1.0, 2.0, 0.5651479139410636, 1.0, 2.0, 0.5651479139410636, 1.0, 1.0, 0.9791285085552148, 6.911199999999999, 6.9112, 170.5573041426782, 2370934.317594174, 2370934.317594174, 462635.4229827631], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4793400.0000, 
sim time next is 4794000.0000, 
raw observation next is [31.0, 66.0, 1.0, 2.0, 1.04, 0.0, 1.0, 0.0, 1.0, 2.0, 1.03, 7.034191378533366, 6.9112, 168.9120301997369, 2379905.903317349, 2292652.064847782, 476247.6107358997], 
processed observation next is [1.0, 0.4782608695652174, 0.6682464454976303, 0.66, 1.0, 1.0, 1.0481927710843375, 0.0, 0.5, -0.20481927710843376, 1.0, 1.0, 1.0365853658536586, 0.012299137853336629, 0.0, 0.8294353965427278, 0.6610849731437081, 0.6368477957910504, 0.7108173294565667], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.41669732], dtype=float32), 0.06772073]. 
=============================================
[2019-03-27 09:20:57,119] A3C_AGENT_WORKER-Thread-2 DEBUG:Value prediction is [[29.386227]
 [30.362354]
 [30.207745]
 [29.61854 ]
 [28.489986]], R is [[27.08855438]
 [27.12716866]
 [27.22174072]
 [26.94952393]
 [26.68002892]].
[2019-03-27 09:21:09,198] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.476194e-36], sum to 1.0000
[2019-03-27 09:21:09,205] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.3763
[2019-03-27 09:21:09,210] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [31.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9272235978710114, 6.9112, 6.9112, 168.912956510431, 757327.4045932451, 757327.4045932451, 229514.1502672735], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5158800.0000, 
sim time next is 5159400.0000, 
raw observation next is [31.0, 66.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9412008810683581, 6.9112, 6.9112, 168.912956510431, 769182.6136442873, 769182.6136442873, 232901.2700750477], 
processed observation next is [0.0, 0.7391304347826086, 0.6682464454976303, 0.66, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9282937574004367, 0.0, 0.0, 0.8294399451523027, 0.21366183712341316, 0.21366183712341316, 0.347613835932907], 
reward next is 0.6524, 
noisyNet noise sample is [array([-0.48390648], dtype=float32), -0.7897413]. 
=============================================
[2019-03-27 09:21:10,640] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 2.0061299e-33 2.0953101e-35 1.2993425e-33 2.5534771e-19], sum to 1.0000
[2019-03-27 09:21:10,649] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.6316
[2019-03-27 09:21:10,657] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.58333333333334, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9981618585038831, 6.9112, 6.9112, 168.9128822541782, 805077.491289768, 805077.491289768, 246606.7502347398], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5273400.0000, 
sim time next is 5274000.0000, 
raw observation next is [28.6, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9944494536782204, 6.9112, 6.9112, 168.912956510431, 801201.4567463752, 801201.4567463752, 245603.7362689815], 
processed observation next is [1.0, 0.043478260869565216, 0.5545023696682465, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9932310410710002, 0.0, 0.0, 0.8294399451523027, 0.22255596020732643, 0.22255596020732643, 0.3665727406999724], 
reward next is 0.6334, 
noisyNet noise sample is [array([1.0643588], dtype=float32), 0.61443985]. 
=============================================
[2019-03-27 09:21:10,668] A3C_AGENT_WORKER-Thread-9 DEBUG:Value prediction is [[52.136684]
 [52.398975]
 [52.419502]
 [52.73461 ]
 [53.24613 ]], R is [[52.12598801]
 [52.23666   ]
 [52.35060501]
 [52.46517181]
 [52.58000183]].
[2019-03-27 09:21:11,453] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [9.9999809e-01 1.1508485e-18 7.3744442e-18 2.1872261e-20 1.9357940e-06], sum to 1.0000
[2019-03-27 09:21:11,465] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9409
[2019-03-27 09:21:11,472] A3C_AGENT_WORKER-Thread-17 DEBUG:Action function: raw action 0 has been changed to 2 for the demand 958572.1247231202 W.
[2019-03-27 09:21:11,476] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 2, 
current raw observation is [27.5, 84.0, 1.0, 2.0, 0.6859116046537626, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 958572.1247231202, 958572.1247231197, 217833.2171218132], 
current ob forecast is [], 
actual action is [0, 0, 1, 0, 0], 
sim time this is 4865400.0000, 
sim time next is 4866000.0000, 
raw observation next is [27.66666666666666, 82.33333333333334, 1.0, 2.0, 0.3350652149789768, 0.0, 2.0, 0.0, 1.0, 1.0, 0.5693139610505537, 6.911200000000001, 6.9112, 168.912956510431, 936507.9638877199, 936507.9638877192, 232420.2235310301], 
processed observation next is [1.0, 0.30434782608695654, 0.5102685624012636, 0.8233333333333335, 1.0, 1.0, 0.19887375298671903, 0.0, 1.0, -0.20481927710843376, 1.0, 0.5, 0.47477312323238247, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.2601411010799222, 0.260141101079922, 0.34689585601646283], 
reward next is 0.0000, 
noisyNet noise sample is [array([0.04669533], dtype=float32), -0.6916214]. 
=============================================
[2019-03-27 09:21:11,487] A3C_AGENT_WORKER-Thread-17 DEBUG:Value prediction is [[29.902287]
 [30.753443]
 [30.919258]
 [31.981441]
 [31.37059 ]], R is [[29.89067078]
 [29.59176445]
 [29.29584694]
 [29.00288963]
 [29.29779816]].
[2019-03-27 09:21:11,948] A3C_AGENT_WORKER-Thread-21 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3509206e-32], sum to 1.0000
[2019-03-27 09:21:11,958] A3C_AGENT_WORKER-Thread-21 DEBUG:Softmax action selection sampled number: 0.9873
[2019-03-27 09:21:11,963] A3C_AGENT_WORKER-Thread-21 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.871255033016148, 6.9112, 6.9112, 168.912956510431, 721952.4598670284, 721952.4598670284, 216957.9125066667], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5097000.0000, 
sim time next is 5097600.0000, 
raw observation next is [27.0, 84.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.874186687700572, 6.9112, 6.9112, 168.912956510431, 724382.5602774939, 724382.5602774939, 217618.0203507729], 
processed observation next is [0.0, 0.0, 0.4786729857819906, 0.84, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8465691313421609, 0.0, 0.0, 0.8294399451523027, 0.2012173778548594, 0.2012173778548594, 0.32480301544891477], 
reward next is 0.6752, 
noisyNet noise sample is [array([1.661644], dtype=float32), -1.8214154]. 
=============================================
[2019-03-27 09:21:14,204] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [9.9949467e-01 1.7276026e-17 7.0469889e-15 3.7093163e-20 5.0526409e-04], sum to 1.0000
[2019-03-27 09:21:14,214] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.5685
[2019-03-27 09:21:14,220] A3C_AGENT_WORKER-Thread-12 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 1150033.659136037 W.
[2019-03-27 09:21:14,224] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [26.0, 89.0, 1.0, 2.0, 0.8228388234155525, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 6.9112, 6.9112, 168.912956510431, 1150033.659136037, 1150033.659136037, 249591.6535667179], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5198400.0000, 
sim time next is 5199000.0000, 
raw observation next is [26.0, 89.0, 1.0, 2.0, 0.4024994809369359, 1.0, 1.0, 0.4024994809369359, 0.0, 2.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 1125080.97287073, 1125080.97287073, 272751.9161067909], 
processed observation next is [1.0, 0.17391304347826086, 0.4312796208530806, 0.89, 1.0, 1.0, 0.2801198565505252, 1.0, 0.5, 0.2801198565505252, 0.0, 1.0, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.3125224924640917, 0.3125224924640917, 0.4070924120996879], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.9949877], dtype=float32), 0.7239042]. 
=============================================
[2019-03-27 09:21:14,233] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[34.624195]
 [36.193394]
 [36.63199 ]
 [37.451523]
 [37.610874]], R is [[34.33483124]
 [33.99148178]
 [33.65156555]
 [33.9093399 ]
 [33.57024765]].
[2019-03-27 09:21:20,346] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.5495685e-34], sum to 1.0000
[2019-03-27 09:21:20,357] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6364
[2019-03-27 09:21:20,361] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.66666666666666, 64.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8666421691131913, 6.911199999999999, 6.9112, 168.912956510431, 716029.1678607106, 716029.1678607112, 215851.7565001187], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5049600.0000, 
sim time next is 5050200.0000, 
raw observation next is [30.83333333333334, 63.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8707271189811538, 6.9112, 6.9112, 168.912956510431, 718741.8941740311, 718741.8941740311, 216742.6666820238], 
processed observation next is [0.0, 0.43478260869565216, 0.6603475513428123, 0.635, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8423501450989681, 0.0, 0.0, 0.8294399451523027, 0.19965052615945308, 0.19965052615945308, 0.3234965174358564], 
reward next is 0.6765, 
noisyNet noise sample is [array([0.710845], dtype=float32), 0.3255566]. 
=============================================
[2019-03-27 09:21:26,321] A3C_AGENT_WORKER-Thread-9 DEBUG:Policy network output: [1.0000000e+00 1.9203331e-33 2.1605199e-35 2.7652781e-34 3.7947825e-20], sum to 1.0000
[2019-03-27 09:21:26,329] A3C_AGENT_WORKER-Thread-9 DEBUG:Softmax action selection sampled number: 0.9969
[2019-03-27 09:21:26,335] A3C_AGENT_WORKER-Thread-9 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.7, 92.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9280320977213011, 6.9112, 6.9112, 168.912956510431, 759076.5392937136, 759076.5392937136, 229756.776801685], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5533200.0000, 
sim time next is 5533800.0000, 
raw observation next is [26.63333333333333, 92.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.926363864871843, 6.9112, 6.9112, 168.912956510431, 757951.0718281247, 757951.0718281247, 229368.603155699], 
processed observation next is [1.0, 0.043478260869565216, 0.46129541864139006, 0.925, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9101998352095645, 0.0, 0.0, 0.8294399451523027, 0.2105419643967013, 0.2105419643967013, 0.34234119873984925], 
reward next is 0.6577, 
noisyNet noise sample is [array([-0.38670048], dtype=float32), 0.45681196]. 
=============================================
[2019-03-27 09:21:26,419] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0966717e-33], sum to 1.0000
[2019-03-27 09:21:26,433] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.2659
[2019-03-27 09:21:26,440] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [29.45, 81.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9965547173658996, 6.9112, 6.9112, 168.9128806108486, 801878.6402490415, 801878.6402490415, 246084.1320436652], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5941800.0000, 
sim time next is 5942400.0000, 
raw observation next is [29.33333333333334, 81.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9852548972369437, 6.9112, 6.9112, 168.912956510431, 792782.8365916209, 792782.8365916209, 243202.8852018217], 
processed observation next is [1.0, 0.782608695652174, 0.5892575039494474, 0.8133333333333335, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9820181673621264, 0.0, 0.0, 0.8294399451523027, 0.22021745460878359, 0.22021745460878359, 0.36298938089824134], 
reward next is 0.6370, 
noisyNet noise sample is [array([0.5891288], dtype=float32), 0.32114148]. 
=============================================
[2019-03-27 09:21:26,465] A3C_AGENT_WORKER-Thread-11 INFO:Evaluating...
[2019-03-27 09:21:26,466] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:21:26,467] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:21:26,467] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:21:26,468] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:21:26,468] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:21:26,469] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:21:26,469] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:21:26,470] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:21:26,471] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:21:26,473] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:21:26,504] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run100
[2019-03-27 09:21:26,524] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run100
[2019-03-27 09:21:26,546] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run100
[2019-03-27 09:21:26,547] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run100
[2019-03-27 09:21:26,595] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run100
[2019-03-27 09:21:39,076] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:21:39,078] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.06666666666667, 92.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7510059160757475, 6.9112, 6.9112, 168.912956510431, 637394.714790827, 637394.714790827, 192194.1478343874]
[2019-03-27 09:21:39,079] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:21:39,082] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7738339e-37], sampled 0.18376108125536128
[2019-03-27 09:21:39,989] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:21:39,990] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [23.4402142, 81.17522138, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6089480142592443, 6.9112, 6.9112, 168.912956510431, 530422.7109590578, 530422.7109590578, 167447.9961030041]
[2019-03-27 09:21:39,991] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:21:39,993] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0780432e-38], sampled 0.9727953969929337
[2019-03-27 09:21:59,781] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:21:59,782] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [27.86012012, 69.899607585, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.016055202810708, 6.9112, 6.9112, 168.9128239913921, 860625.0925757682, 860625.0925757682, 252832.9024951141]
[2019-03-27 09:21:59,785] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:21:59,788] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 8.5055605e-38 3.4747997e-30], sampled 0.6957615830002538
[2019-03-27 09:22:50,858] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:22:50,859] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [30.43960427, 76.591006025, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 7.010894197440998, 6.9112, 168.9121677840839, 899554.6777028616, 828828.5130807969, 254812.2061146382]
[2019-03-27 09:22:50,860] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:22:50,864] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 5.646517e-34], sampled 0.12408709586652744
[2019-03-27 09:22:50,865] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 899554.6777028616 W.
[2019-03-27 09:23:07,249] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:23:07,251] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [25.55039204666667, 65.45297047, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5998872158517718, 6.9112, 6.9112, 168.912956510431, 523906.287670573, 523906.287670573, 166030.2125051128]
[2019-03-27 09:23:07,252] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:23:07,254] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1. 0. 0. 0. 0.], sampled 0.04256880889774739
[2019-03-27 09:23:13,554] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.074037574]
[2019-03-27 09:23:13,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [22.03333333333333, 89.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.5973165732247417, 6.911199999999999, 6.9112, 168.912956510431, 520838.4301610519, 520838.4301610525, 165657.9394785351]
[2019-03-27 09:23:13,557] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:23:13,560] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2376167e-33], sampled 0.5564655488416682
[2019-03-27 09:23:22,907] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8060.9964 2937946329.7821 1382.0000
[2019-03-27 09:23:23,175] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7029.8919 3185219386.8708 2464.0000
[2019-03-27 09:23:23,213] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7288.9996 3319521307.1094 2143.0000
[2019-03-27 09:23:23,244] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7923.8959 2989439343.3515 1566.0000
[2019-03-27 09:23:23,279] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7347.3812 3105715657.6887 2012.0000
[2019-03-27 09:23:24,298] A3C_AGENT_WORKER-Thread-11 INFO:Global step: 2475000, evaluation results [2475000.0, 7288.999644938805, 3319521307.1093755, 2143.0, 7347.38123576133, 3105715657.688687, 2012.0, 8060.996422916334, 2937946329.782127, 1382.0, 7029.891904325195, 3185219386.870774, 2464.0, 7923.895922674136, 2989439343.3514833, 1566.0]
[2019-03-27 09:23:27,572] A3C_AGENT_WORKER-Thread-16 DEBUG:Policy network output: [8.1488532e-01 5.7249792e-15 3.2655326e-14 1.0615415e-17 1.8511467e-01], sum to 1.0000
[2019-03-27 09:23:27,580] A3C_AGENT_WORKER-Thread-16 DEBUG:Softmax action selection sampled number: 0.6391
[2019-03-27 09:23:27,590] A3C_AGENT_WORKER-Thread-16 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2681792.909873202 W.
[2019-03-27 09:23:27,594] A3C_AGENT_WORKER-Thread-16 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.16666666666667, 69.5, 1.0, 2.0, 0.6391663094341351, 1.0, 1.0, 0.6391663094341351, 1.0, 2.0, 1.03, 7.001161078104458, 6.9112, 170.5573041426782, 2681792.909873202, 2617350.130244288, 502616.0265809698], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5224200.0000, 
sim time next is 5224800.0000, 
raw observation next is [31.33333333333334, 69.0, 1.0, 2.0, 0.6201914975060914, 1.0, 2.0, 0.6201914975060914, 1.0, 2.0, 1.03, 6.964112824731147, 6.9112, 170.5573041426782, 2602096.113419217, 2564192.504708199, 495415.7530612848], 
processed observation next is [1.0, 0.4782608695652174, 0.6840442338072673, 0.69, 1.0, 1.0, 0.5423993945856522, 1.0, 1.0, 0.5423993945856522, 1.0, 1.0, 1.0365853658536586, 0.0052912824731146555, 0.0, 0.8375144448122397, 0.7228044759497825, 0.7122756957522774, 0.7394264971063952], 
reward next is 0.0000, 
noisyNet noise sample is [array([1.071625], dtype=float32), -1.1290509]. 
=============================================
[2019-03-27 09:23:28,227] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [3.0651811e-01 1.2783757e-14 3.4800347e-13 5.2324943e-18 6.9348186e-01], sum to 1.0000
[2019-03-27 09:23:28,236] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.0667
[2019-03-27 09:23:28,250] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 4 for the demand 2402837.956037069 W.
[2019-03-27 09:23:28,254] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [31.0, 68.66666666666667, 1.0, 2.0, 0.5727453225060096, 1.0, 2.0, 0.5727453225060096, 1.0, 2.0, 0.9946692154204351, 6.911200000000001, 6.9112, 170.5573041426782, 2402837.956037069, 2402837.956037068, 469094.9028845339], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 5222400.0000, 
sim time next is 5223000.0000, 
raw observation next is [31.0, 69.33333333333333, 1.0, 2.0, 0.5746145721794855, 1.0, 2.0, 0.5746145721794855, 1.0, 2.0, 0.9979154839329494, 6.9112, 6.9112, 170.5573041426782, 2410687.5818426, 2410687.5818426, 470577.2710378616], 
processed observation next is [1.0, 0.43478260869565216, 0.6682464454976303, 0.6933333333333332, 1.0, 1.0, 0.4874874363608259, 1.0, 1.0, 0.4874874363608259, 1.0, 1.0, 0.9974579072353041, 0.0, 0.0, 0.8375144448122397, 0.6696354394007222, 0.6696354394007222, 0.7023541358774054], 
reward next is 0.2976, 
noisyNet noise sample is [array([0.19855624], dtype=float32), -1.418903]. 
=============================================
[2019-03-27 09:23:28,269] A3C_AGENT_WORKER-Thread-18 DEBUG:Value prediction is [[22.117622]
 [21.2446  ]
 [20.65903 ]
 [19.798302]
 [21.92318 ]], R is [[22.4595108 ]
 [22.53477478]
 [22.60915947]
 [22.66454887]
 [22.43790436]].
[2019-03-27 09:23:40,895] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 8.279502e-34], sum to 1.0000
[2019-03-27 09:23:40,905] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.4230
[2019-03-27 09:23:40,910] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.8, 86.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8844267384275852, 6.911200000000001, 6.9112, 168.912956510431, 730723.7028315716, 730723.7028315709, 219866.9220236707], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5697000.0000, 
sim time next is 5697600.0000, 
raw observation next is [26.73333333333333, 86.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.880848802879142, 6.911199999999999, 6.9112, 168.912956510431, 728217.5156115143, 728217.5156115149, 219068.345196364], 
processed observation next is [0.0, 0.9565217391304348, 0.4660347551342811, 0.8666666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.854693662047734, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20228264322542064, 0.2022826432254208, 0.3269676793975582], 
reward next is 0.6730, 
noisyNet noise sample is [array([-0.20939395], dtype=float32), -0.870782]. 
=============================================
[2019-03-27 09:23:42,947] A3C_AGENT_WORKER-Thread-14 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.285077e-34], sum to 1.0000
[2019-03-27 09:23:42,957] A3C_AGENT_WORKER-Thread-14 DEBUG:Softmax action selection sampled number: 0.7341
[2019-03-27 09:23:42,961] A3C_AGENT_WORKER-Thread-14 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [28.76666666666667, 77.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9106678376034217, 6.911199999999999, 6.9112, 168.912956510431, 747542.0174871245, 747542.0174871251, 225756.2509997613], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5685600.0000, 
sim time next is 5686200.0000, 
raw observation next is [28.55, 78.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9116645433754836, 6.9112, 6.9112, 168.912956510431, 748061.0315799187, 748061.0315799187, 225977.9756907407], 
processed observation next is [0.0, 0.8260869565217391, 0.552132701421801, 0.785, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.892273833384736, 0.0, 0.0, 0.8294399451523027, 0.20779473099442186, 0.20779473099442186, 0.33728056073244883], 
reward next is 0.6627, 
noisyNet noise sample is [array([-0.07596105], dtype=float32), -0.2063389]. 
=============================================
[2019-03-27 09:23:51,669] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5049375e-32], sum to 1.0000
[2019-03-27 09:23:51,677] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.0879
[2019-03-27 09:23:51,682] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.5, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8739200056937145, 6.911199999999999, 6.9112, 168.912956510431, 724772.7613659343, 724772.761365935, 217578.1457620178], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5705400.0000, 
sim time next is 5706000.0000, 
raw observation next is [26.5, 87.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8709078800237916, 6.911199999999999, 6.9112, 168.912956510431, 722274.8581099614, 722274.8581099621, 216900.0821913087], 
processed observation next is [0.0, 0.043478260869565216, 0.4549763033175356, 0.87, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8425705853948677, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20063190503054482, 0.200631905030545, 0.32373146595717717], 
reward next is 0.6763, 
noisyNet noise sample is [array([0.4419818], dtype=float32), -0.07793476]. 
=============================================
[2019-03-27 09:23:51,694] A3C_AGENT_WORKER-Thread-15 DEBUG:Value prediction is [[66.90285]
 [67.08526]
 [67.08907]
 [67.39811]
 [67.89202]], R is [[66.83125305]
 [66.8381958 ]
 [66.84464264]
 [66.85214233]
 [66.86103058]].
[2019-03-27 09:23:52,670] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 1.6139786e-38 0.0000000e+00 1.1353987e-37 3.6011200e-25], sum to 1.0000
[2019-03-27 09:23:52,678] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.9916
[2019-03-27 09:23:52,683] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [26.15, 91.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8838825103490255, 6.9112, 6.9112, 168.912956510431, 729840.9116384251, 729840.9116384251, 219727.1107332793], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5617800.0000, 
sim time next is 5618400.0000, 
raw observation next is [26.1, 91.66666666666666, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8833966453732549, 6.9112, 6.9112, 168.912956510431, 729732.2027074888, 729732.2027074888, 219626.9823085113], 
processed observation next is [0.0, 0.0, 0.4360189573459717, 0.9166666666666665, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8578007870405547, 0.0, 0.0, 0.8294399451523027, 0.2027033896409691, 0.2027033896409691, 0.3278014661321064], 
reward next is 0.6722, 
noisyNet noise sample is [array([0.22121167], dtype=float32), 0.9472598]. 
=============================================
[2019-03-27 09:23:55,517] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 1.3923407e-37 0.0000000e+00 3.7304774e-37 2.1453148e-23], sum to 1.0000
[2019-03-27 09:23:55,525] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6274
[2019-03-27 09:23:55,529] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.76666666666667, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9604454574212189, 6.9112, 6.9112, 168.912956510431, 779733.7933461386, 779733.7933461386, 237370.6225569642], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5953200.0000, 
sim time next is 5953800.0000, 
raw observation next is [27.68333333333334, 88.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.958746036473569, 6.911199999999999, 6.9112, 168.912956510431, 778481.0365817486, 778481.0365817493, 236956.8736005086], 
processed observation next is [1.0, 0.9130434782608695, 0.511058451816746, 0.885, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9496902883824011, -8.881784197001253e-17, 0.0, 0.8294399451523027, 0.21624473238381905, 0.21624473238381925, 0.3536669755231472], 
reward next is 0.6463, 
noisyNet noise sample is [array([1.2390665], dtype=float32), -0.34199005]. 
=============================================
[2019-03-27 09:23:58,363] A3C_AGENT_WORKER-Thread-22 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2317036e-35], sum to 1.0000
[2019-03-27 09:23:58,373] A3C_AGENT_WORKER-Thread-22 DEBUG:Softmax action selection sampled number: 0.1754
[2019-03-27 09:23:58,378] A3C_AGENT_WORKER-Thread-22 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.76666666666667, 85.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9258735013884417, 6.9112, 6.9112, 168.912956510431, 755950.0212551517, 755950.0212551517, 229179.2079852443], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6248400.0000, 
sim time next is 6249000.0000, 
raw observation next is [27.83333333333333, 85.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9269161332094704, 6.9112, 6.9112, 168.912956510431, 756599.7782903083, 756599.7782903083, 229418.8627362465], 
processed observation next is [0.0, 0.30434782608695654, 0.518167456556082, 0.8533333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.910873333182281, 0.0, 0.0, 0.8294399451523027, 0.2101666050806412, 0.2101666050806412, 0.34241621303917386], 
reward next is 0.6576, 
noisyNet noise sample is [array([-0.07121635], dtype=float32), 1.5477536]. 
=============================================
[2019-03-27 09:23:58,390] A3C_AGENT_WORKER-Thread-22 DEBUG:Value prediction is [[68.04174 ]
 [68.07072 ]
 [68.09895 ]
 [68.12562 ]
 [68.086784]], R is [[68.01506042]
 [67.99285126]
 [67.97174072]
 [67.95166779]
 [67.93229675]].
[2019-03-27 09:24:00,377] A3C_AGENT_WORKER-Thread-15 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 6.7785186e-35], sum to 1.0000
[2019-03-27 09:24:00,386] A3C_AGENT_WORKER-Thread-15 DEBUG:Softmax action selection sampled number: 0.1215
[2019-03-27 09:24:00,392] A3C_AGENT_WORKER-Thread-15 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.0, 75.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9646659703669374, 6.9112, 6.9112, 168.912956510431, 779700.9950523225, 779700.9950523225, 238235.1277830683], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5856000.0000, 
sim time next is 5856600.0000, 
raw observation next is [29.8, 76.83333333333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9653882983297468, 6.9112, 6.9112, 168.912956510431, 780287.216868281, 780287.216868281, 238414.6781251295], 
processed observation next is [1.0, 0.782608695652174, 0.6113744075829385, 0.7683333333333333, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9577906077192034, 0.0, 0.0, 0.8294399451523027, 0.21674644913007807, 0.21674644913007807, 0.35584280317183503], 
reward next is 0.6442, 
noisyNet noise sample is [array([0.8219278], dtype=float32), 1.1006254]. 
=============================================
[2019-03-27 09:24:00,476] A3C_AGENT_WORKER-Thread-3 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 3.609874e-29], sum to 1.0000
[2019-03-27 09:24:00,486] A3C_AGENT_WORKER-Thread-3 DEBUG:Softmax action selection sampled number: 0.0711
[2019-03-27 09:24:00,490] A3C_AGENT_WORKER-Thread-3 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.06666666666667, 88.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9189504034929938, 6.911199999999999, 6.9112, 168.912956510431, 753924.6429807743, 753924.6429807749, 227693.2291183141], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 5789400.0000, 
sim time next is 5790000.0000, 
raw observation next is [27.03333333333333, 88.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9184900210282764, 6.911200000000001, 6.9112, 168.912956510431, 753623.7166893919, 753623.7166893913, 227587.3586955448], 
processed observation next is [1.0, 0.0, 0.48025276461295413, 0.8833333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9005975866198491, 8.881784197001253e-17, 0.0, 0.8294399451523027, 0.20933992130260887, 0.2093399213026087, 0.3396826249187236], 
reward next is 0.6603, 
noisyNet noise sample is [array([0.13112703], dtype=float32), -0.05710696]. 
=============================================
[2019-03-27 09:24:00,505] A3C_AGENT_WORKER-Thread-3 DEBUG:Value prediction is [[59.970833]
 [64.53212 ]
 [69.62874 ]
 [69.64843 ]
 [69.68586 ]], R is [[57.9850502 ]
 [58.06536102]
 [58.14547348]
 [58.22477341]
 [58.30325317]].
[2019-03-27 09:24:02,913] A3C_AGENT_WORKER-Thread-11 DEBUG:Policy network output: [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 4.670969e-30], sum to 1.0000
[2019-03-27 09:24:02,920] A3C_AGENT_WORKER-Thread-11 DEBUG:Softmax action selection sampled number: 0.1600
[2019-03-27 09:24:02,929] A3C_AGENT_WORKER-Thread-11 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8932401011804012, 6.9112, 6.9112, 168.912956510431, 734846.3587202758, 734846.3587202758, 221768.6542964487], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6121200.0000, 
sim time next is 6121800.0000, 
raw observation next is [27.2, 86.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8927000847456311, 6.9112, 6.9112, 168.912956510431, 734411.5238320105, 734411.5238320105, 221644.6962855715], 
processed observation next is [1.0, 0.8695652173913043, 0.4881516587677725, 0.86, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8691464448117452, 0.0, 0.0, 0.8294399451523027, 0.20400320106444736, 0.20400320106444736, 0.3308129795307037], 
reward next is 0.6692, 
noisyNet noise sample is [array([-1.0441027], dtype=float32), 0.6875742]. 
=============================================
[2019-03-27 09:24:03,219] A3C_AGENT_WORKER-Thread-13 DEBUG:Policy network output: [3.8176370e-01 4.3123997e-15 2.2273582e-14 6.5126316e-18 6.1823636e-01], sum to 1.0000
[2019-03-27 09:24:03,228] A3C_AGENT_WORKER-Thread-13 DEBUG:Softmax action selection sampled number: 0.8289
[2019-03-27 09:24:03,233] A3C_AGENT_WORKER-Thread-13 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 4, 
current raw observation is [27.75, 84.5, 1.0, 2.0, 0.5570254072781223, 1.0, 2.0, 0.5570254072781223, 1.0, 2.0, 0.9644057898529046, 6.9112, 6.9112, 170.5573041426782, 2336826.546589436, 2336826.546589436, 456217.365783594], 
current ob forecast is [], 
actual action is [0, 0, 0, 0, 1], 
sim time this is 6625800.0000, 
sim time next is 6626400.0000, 
raw observation next is [27.66666666666666, 84.66666666666667, 1.0, 2.0, 0.4773406784284728, 1.0, 2.0, 0.4773406784284728, 1.0, 2.0, 0.8247129066575837, 6.9112, 6.9112, 170.5573041426782, 2002238.240098258, 2002238.240098258, 399098.5562245997], 
processed observation next is [1.0, 0.6956521739130435, 0.5102685624012636, 0.8466666666666667, 1.0, 1.0, 0.3702899740102082, 1.0, 1.0, 0.3702899740102082, 1.0, 1.0, 0.7862352520214434, 0.0, 0.0, 0.8375144448122397, 0.5561772889161828, 0.5561772889161828, 0.5956694869023876], 
reward next is 0.4043, 
noisyNet noise sample is [array([0.613952], dtype=float32), 0.108413644]. 
=============================================
[2019-03-27 09:24:03,387] A3C_AGENT_WORKER-Thread-18 DEBUG:Policy network output: [9.5613617e-01 4.5806642e-17 2.2428781e-16 6.2136431e-20 4.3863840e-02], sum to 1.0000
[2019-03-27 09:24:03,396] A3C_AGENT_WORKER-Thread-18 DEBUG:Softmax action selection sampled number: 0.7066
[2019-03-27 09:24:03,404] A3C_AGENT_WORKER-Thread-18 DEBUG:Action function: raw action 0 has been changed to 3 for the demand 2487105.768921023 W.
[2019-03-27 09:24:03,410] A3C_AGENT_WORKER-Thread-18 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 3, 
current raw observation is [32.2, 65.0, 1.0, 2.0, 0.5928115994511922, 1.0, 2.0, 0.5928115994511922, 1.0, 2.0, 1.029517702455027, 6.9112, 6.9112, 170.5573041426782, 2487105.768921023, 2487105.768921023, 485258.2767823617], 
current ob forecast is [], 
actual action is [0, 0, 0, 1, 0], 
sim time this is 5832000.0000, 
sim time next is 5832600.0000, 
raw observation next is [32.26666666666667, 64.66666666666667, 1.0, 2.0, 0.9225539332558174, 1.0, 2.0, 0.9225539332558174, 0.0, 1.0, 0.0, 6.9112, 6.9112, 170.5573041426782, 2580443.012540728, 2580443.012540728, 483946.7831444296], 
processed observation next is [1.0, 0.5217391304347826, 0.7282780410742499, 0.6466666666666667, 1.0, 1.0, 0.9066914858503824, 1.0, 1.0, 0.9066914858503824, 0.0, 0.5, -0.2195121951219512, 0.0, 0.0, 0.8375144448122397, 0.7167897257057577, 0.7167897257057577, 0.7223086315588502], 
reward next is 0.2777, 
noisyNet noise sample is [array([-1.8318479], dtype=float32), -0.16111423]. 
=============================================
[2019-03-27 09:24:13,878] A3C_AGENT_WORKER-Thread-12 DEBUG:Policy network output: [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 4.6378333e-32], sum to 1.0000
[2019-03-27 09:24:13,884] A3C_AGENT_WORKER-Thread-12 DEBUG:Softmax action selection sampled number: 0.6690
[2019-03-27 09:24:13,890] A3C_AGENT_WORKER-Thread-12 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [30.68333333333333, 62.16666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8535360062328288, 6.911200000000001, 6.9112, 168.912956510431, 707850.029151847, 707850.0291518463, 213036.5864590602], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6275400.0000, 
sim time next is 6276000.0000, 
raw observation next is [30.66666666666667, 62.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8532846048061774, 6.9112, 6.9112, 168.912956510431, 707564.8236539173, 707564.8236539173, 212978.8063716499], 
processed observation next is [0.0, 0.6521739130434783, 0.6524486571879939, 0.6233333333333334, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.8210787863489967, 0.0, 0.0, 0.8294399451523027, 0.19654578434831035, 0.19654578434831035, 0.31787881548007446], 
reward next is 0.6821, 
noisyNet noise sample is [array([-0.1077984], dtype=float32), 0.009593881]. 
=============================================
[2019-03-27 09:24:13,918] A3C_AGENT_WORKER-Thread-12 DEBUG:Value prediction is [[71.15377 ]
 [71.014656]
 [70.78605 ]
 [70.674095]
 [70.57758 ]], R is [[71.19048309]
 [71.16061401]
 [71.13156891]
 [71.10209656]
 [71.07216644]].
[2019-03-27 09:24:16,039] A3C_AGENT_WORKER-Thread-17 DEBUG:Policy network output: [1.0000000e+00 4.1327287e-37 0.0000000e+00 2.1355259e-37 2.4127037e-24], sum to 1.0000
[2019-03-27 09:24:16,047] A3C_AGENT_WORKER-Thread-17 DEBUG:Softmax action selection sampled number: 0.7933
[2019-03-27 09:24:16,051] A3C_AGENT_WORKER-Thread-17 DEBUG:TRAINING DEBUG INFO ======>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Current H regulation is 0.0000, 
Environment debug: raw action idx is 0, 
current raw observation is [27.33333333333334, 87.33333333333334, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9221302562148067, 6.911199999999999, 6.9112, 168.912956510431, 754741.616140158, 754741.6161401586, 228370.9017777036], 
current ob forecast is [], 
actual action is [1, 0, 0, 0, 0], 
sim time this is 6039600.0000, 
sim time next is 6040200.0000, 
raw observation next is [27.26666666666667, 87.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9224194646567175, 6.9112, 6.9112, 168.912956510431, 755187.160740262, 755187.160740262, 228448.8674201323], 
processed observation next is [1.0, 0.9130434782608695, 0.4913112164297, 0.8766666666666667, 0.0, 1.0, -0.20481927710843376, 0.0, 1.0, -0.20481927710843376, 1.0, 1.0, 0.9053895910447773, 0.0, 0.0, 0.8294399451523027, 0.20977421131673946, 0.20977421131673946, 0.34096845883601834], 
reward next is 0.6590, 
noisyNet noise sample is [array([-2.772603], dtype=float32), -1.6455162]. 
=============================================
[2019-03-27 09:24:17,813] A3C_AGENT_WORKER-Thread-16 INFO:Evaluating...
[2019-03-27 09:24:17,816] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation job starts!
[2019-03-27 09:24:17,816] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:24:17,817] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation job starts!
[2019-03-27 09:24:17,819] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation job starts!
[2019-03-27 09:24:17,820] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation job starts!
[2019-03-27 09:24:17,821] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:24:17,823] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:24:17,822] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation job starts!
[2019-03-27 09:24:17,823] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:24:17,826] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:Creating EnergyPlus simulation environment...
[2019-03-27 09:24:18,754] EPLUS_ENV_Part3-NA-Shg-Test-v3_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v3-res1/Eplus-env-sub_run101
[2019-03-27 09:24:18,774] EPLUS_ENV_Part3-NA-Shg-Train-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Train-v1-res1/Eplus-env-sub_run101
[2019-03-27 09:24:18,797] EPLUS_ENV_Part3-NA-Shg-Test-v4_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v4-res1/Eplus-env-sub_run101
[2019-03-27 09:24:18,818] EPLUS_ENV_Part3-NA-Shg-Test-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v1-res1/Eplus-env-sub_run101
[2019-03-27 09:24:18,819] EPLUS_ENV_Part3-NA-Shg-Test-v2_MainThread_ROOT INFO:EnergyPlus working directory is in /home/zhiangz/Documents/HVAC-RL-Control/src/runs/rl_parametric_part3_shg_na/11/Eplus-env-Part3-NA-Shg-Test-v2-res1/Eplus-env-sub_run101
[2019-03-27 09:24:32,567] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:24:32,568] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [23.1, 83.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6145306959643808, 6.911199999999999, 6.9112, 168.912956510431, 534245.1568984874, 534245.1568984879, 168333.2404024163]
[2019-03-27 09:24:32,570] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:24:32,573] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4030468e-37], sampled 0.017315871028918295
[2019-03-27 09:24:33,251] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:24:33,252] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [26.25114063666667, 75.82258578666668, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6996093896393186, 6.911200000000001, 6.9112, 168.912956510431, 597712.8575837327, 597712.8575837321, 182657.2939422775]
[2019-03-27 09:24:33,253] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:24:33,256] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 9.952281e-38], sampled 0.05110762361569099
[2019-03-27 09:24:43,914] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:24:43,916] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.85732241333334, 89.27080268333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6262878911041793, 6.9112, 6.9112, 168.912956510431, 545012.7268023409, 545012.7268023409, 170178.0021668651]
[2019-03-27 09:24:43,920] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:24:43,926] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.9214404e-32], sampled 0.0021227805820555057
[2019-03-27 09:24:49,269] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:24:49,270] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [25.4, 89.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7961160263951329, 6.9112, 6.9112, 168.912956510431, 667475.9174238405, 667475.9174238405, 201039.8266292408]
[2019-03-27 09:24:49,272] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:24:49,275] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.0755007e-35], sampled 0.36174589196383455
[2019-03-27 09:24:52,963] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:24:52,964] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.94942291666667, 75.01605521333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.879048225227213, 6.911199999999999, 6.9112, 168.912956510431, 747322.0132581277, 747322.0132581283, 219142.4002134724]
[2019-03-27 09:24:52,966] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:24:52,968] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 1.465044e-38 6.049060e-32], sampled 0.5826396241117059
[2019-03-27 09:25:04,006] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:25:04,007] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [26.1, 89.66666666666667, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.8959947105449615, 6.911200000000001, 6.9112, 168.912956510431, 743549.4184822445, 743549.4184822439, 222637.6483556606]
[2019-03-27 09:25:04,008] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:25:04,012] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.3883188e-32], sampled 0.29860901133042084
[2019-03-27 09:25:07,911] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:25:07,912] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation this: [32.75, 59.5, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.9605512557321189, 6.9112, 6.9112, 168.912956510431, 780824.8613141669, 780824.8613141669, 237447.8070821475]
[2019-03-27 09:25:07,914] A3C_EVAL-Part3-NA-Shg-Test-v1 DEBUG:Observation forecast: []
[2019-03-27 09:25:07,916] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.0304346e-34], sampled 0.6321951768978065
[2019-03-27 09:25:40,247] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:25:40,249] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [27.88333333333333, 85.33333333333334, 1.0, 2.0, 0.8302677065363072, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911199999999999, 6.9112, 168.912956510431, 1160422.247817472, 1160422.247817473, 251477.0291355819]
[2019-03-27 09:25:40,250] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:25:40,255] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 3.8573724e-24 1.1544565e-25 1.3971756e-24 1.5106082e-14], sampled 0.8174884129927301
[2019-03-27 09:25:40,258] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 1, 0, 0, 0] for the demand 1160422.247817472 W.
[2019-03-27 09:25:50,708] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:25:50,710] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [28.68452719, 84.96907488333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.027686981787047, 6.9112, 6.9112, 168.9127737308044, 828168.0157394637, 828168.0157394637, 254271.5975480595]
[2019-03-27 09:25:50,711] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:25:50,715] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00
 1.27819325e-33], sampled 0.17648796381828247
[2019-03-27 09:25:58,328] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:25:58,328] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation this: [22.28186188666666, 87.38650403000001, 1.0, 2.0, 0.5358145548072129, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 6.911200000000001, 6.9112, 168.912956510431, 835762.6493443276, 835762.649344327, 199630.8770703967]
[2019-03-27 09:25:58,332] A3C_EVAL-Part3-NA-Shg-Test-v2 DEBUG:Observation forecast: []
[2019-03-27 09:25:58,334] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Softmax [1.0000000e+00 9.7765167e-23 9.4331672e-23 1.1692430e-23 6.3284551e-12], sampled 0.04158990459802692
[2019-03-27 09:26:00,107] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:26:00,111] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation this: [24.4, 88.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.7605308921612405, 6.9112, 6.9112, 168.912956510431, 647220.0278652996, 647220.0278652996, 194061.3637648301]
[2019-03-27 09:26:00,113] A3C_EVAL-Part3-NA-Shg-Test-v3 DEBUG:Observation forecast: []
[2019-03-27 09:26:00,116] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Softmax [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2253913e-34], sampled 0.3528755632479942
[2019-03-27 09:26:06,986] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:26:06,987] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation this: [26.05727597666667, 71.63222812333333, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0, 1.0, 2.0, 0.6599145090530536, 6.9112, 6.9112, 168.912956510431, 569177.4447443136, 569177.4447443136, 175748.5290696289]
[2019-03-27 09:26:06,992] A3C_EVAL-Part3-NA-Shg-Test-v4 DEBUG:Observation forecast: []
[2019-03-27 09:26:06,996] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Softmax [1.000000e+00 0.000000e+00 0.000000e+00 0.000000e+00 6.223247e-32], sampled 0.19311658100685802
[2019-03-27 09:26:11,710] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:NoisyNet noise sample: [array([0.02883013], dtype=float32), 0.07384216]
[2019-03-27 09:26:11,711] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation this: [32.1, 59.16666666666667, 1.0, 2.0, 0.8632549129566635, 0.0, 2.0, 0.0, 1.0, 2.0, 1.03, 6.986056654432534, 6.9112, 168.9124494546263, 2103604.799687102, 2050499.072082755, 424799.9068784961]
[2019-03-27 09:26:11,712] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Observation forecast: []
[2019-03-27 09:26:11,713] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Softmax [1.0000000e+00 2.6659564e-25 2.3088017e-27 6.0470217e-27 1.8803976e-11], sampled 0.6590912218960836
[2019-03-27 09:26:11,714] A3C_EVAL-Part3-NA-Shg-Train-v1 DEBUG:Action function: raw action [1, 0, 0, 0, 0] has been changed to [0, 0, 1, 0, 0] for the demand 2103604.799687102 W.
[2019-03-27 09:26:14,676] A3C_EVAL-Part3-NA-Shg-Train-v1 INFO:Evaluation: average rewards by now are 7285.4853 3319599841.8163 2137.0000
[2019-03-27 09:26:14,851] A3C_EVAL-Part3-NA-Shg-Test-v3 INFO:Evaluation: average rewards by now are 7028.9335 3185259861.4652 2466.0000
[2019-03-27 09:26:15,006] A3C_EVAL-Part3-NA-Shg-Test-v1 INFO:Evaluation: average rewards by now are 7350.6349 3106087850.4899 2002.0000
[2019-03-27 09:26:15,091] A3C_EVAL-Part3-NA-Shg-Test-v2 INFO:Evaluation: average rewards by now are 8067.2244 2938025867.3071 1363.0000
[2019-03-27 09:26:15,096] A3C_EVAL-Part3-NA-Shg-Test-v4 INFO:Evaluation: average rewards by now are 7922.3682 2989320179.1958 1575.0000
[2019-03-27 09:26:16,115] A3C_AGENT_WORKER-Thread-16 INFO:Global step: 2500000, evaluation results [2500000.0, 7285.485297194363, 3319599841.8163314, 2137.0, 7350.634947841772, 3106087850.4899354, 2002.0, 8067.224381732526, 2938025867.3071084, 1363.0, 7028.933476454228, 3185259861.465179, 2466.0, 7922.368216525996, 2989320179.195841, 1575.0]
